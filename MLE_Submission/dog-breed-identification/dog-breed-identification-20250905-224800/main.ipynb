{
  "cells": [
    {
      "id": "1f6f0e0b-5e06-4f74-9759-46df0b25ea08",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install required packages and verify GPU\n",
        "import sys, subprocess, importlib, os, glob, pandas as pd\n",
        "\n",
        "def ensure(pkg, import_name=None, extra=None):\n",
        "    imp = import_name or pkg\n",
        "    try:\n",
        "        importlib.import_module(imp)\n",
        "        print(f\"OK: {pkg}\")\n",
        "    except Exception:\n",
        "        cmd = [sys.executable, '-m', 'pip', 'install', pkg] + (extra or [])\n",
        "        print('Installing', pkg, '...')\n",
        "        subprocess.check_call(cmd)\n",
        "        importlib.import_module(imp)\n",
        "        print(f\"Installed: {pkg}\")\n",
        "\n",
        "ensure('torch')\n",
        "ensure('torchvision')\n",
        "ensure('timm')\n",
        "ensure('albumentations')\n",
        "ensure('opencv-python', import_name='cv2')\n",
        "ensure('scikit-learn', import_name='sklearn')\n",
        "\n",
        "import torch\n",
        "print('GPU Available:', torch.cuda.is_available())\n",
        "print('GPU Count:', torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
        "    props = torch.cuda.get_device_properties(0)\n",
        "    print('GPU Memory (GB):', round(props.total_memory/1024**3, 2))\n",
        "\n",
        "# Quick dataset sanity checks\n",
        "train_imgs = glob.glob('train/*.jpg')\n",
        "test_imgs = glob.glob('test/*.jpg')\n",
        "print('Train images:', len(train_imgs))\n",
        "print('Test images:', len(test_imgs))\n",
        "\n",
        "labels = pd.read_csv('labels.csv')\n",
        "print('Labels shape:', labels.shape)\n",
        "print('Unique breeds:', labels['breed'].nunique())\n",
        "print(labels.head())\n",
        "\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "print('Sample submission shape:', ss.shape)\n",
        "print(ss.head())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: torch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: torchvision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: timm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: albumentations\nOK: opencv-python\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: scikit-learn\nGPU Available: True\nGPU Count: 1\nGPU Name: Tesla V100-SXM2-16GB\nGPU Memory (GB): 15.77\nTrain images: 9199\nTest images: 1023\nLabels shape: (9199, 2)\nUnique breeds: 120\n                                 id                        breed\n0  8406d837b2d7fac1c3cd621abb4c4f9e  west_highland_white_terrier\n1  e270622b5ffec8294d7e7628c4ff6c1e             brittany_spaniel\n2  41295c36303043fc587e791b14ef2272                       basset\n3  b63b0200ddbb97df81972b26574959ab                        boxer\n4  2c64e362c9aa29450082291264dcba29        flat-coated_retriever\nSample submission shape: (1023, 121)\n                                 id  affenpinscher  afghan_hound  \\\n0  9f68d045a396679a778eb54c5ed29038       0.008333      0.008333   \n1  f375e6363bc21dcd3cb65637c7855e9c       0.008333      0.008333   \n2  010e87fdf252645a827e37470e65e842       0.008333      0.008333   \n3  ad2dfa0202d8ea3766fea1e743cd5166       0.008333      0.008333   \n4  a579a1802c57cfbc31b79781f6f37a39       0.008333      0.008333   \n\n   african_hunting_dog  airedale  american_staffordshire_terrier  appenzeller  \\\n0             0.008333  0.008333                        0.008333     0.008333   \n1             0.008333  0.008333                        0.008333     0.008333   \n2             0.008333  0.008333                        0.008333     0.008333   \n3             0.008333  0.008333                        0.008333     0.008333   \n4             0.008333  0.008333                        0.008333     0.008333   \n\n   australian_terrier   basenji    basset  ...  toy_poodle  toy_terrier  \\\n0            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n1            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n2            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n3            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n4            0.008333  0.008333  0.008333  ...    0.008333     0.008333   \n\n     vizsla  walker_hound  weimaraner  welsh_springer_spaniel  \\\n0  0.008333      0.008333    0.008333                0.008333   \n1  0.008333      0.008333    0.008333                0.008333   \n2  0.008333      0.008333    0.008333                0.008333   \n3  0.008333      0.008333    0.008333                0.008333   \n4  0.008333      0.008333    0.008333                0.008333   \n\n   west_highland_white_terrier   whippet  wire-haired_fox_terrier  \\\n0                     0.008333  0.008333                 0.008333   \n1                     0.008333  0.008333                 0.008333   \n2                     0.008333  0.008333                 0.008333   \n3                     0.008333  0.008333                 0.008333   \n4                     0.008333  0.008333                 0.008333   \n\n   yorkshire_terrier  \n0           0.008333  \n1           0.008333  \n2           0.008333  \n3           0.008333  \n4           0.008333  \n\n[5 rows x 121 columns]\n"
          ]
        }
      ]
    },
    {
      "id": "c56f42bd-5c9a-4abe-bf42-d028f750c376",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dog Breed Identification - Improved training with ConvNeXt + Mixup + AMP + StratifiedKFold\n",
        "import os, gc, random, time, math, json, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from timm.data import Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy\n",
        "from timm.utils import ModelEmaV2\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ========== Config ========== \n",
        "class CFG:\n",
        "    seed = 42\n",
        "    img_size = 448\n",
        "    n_folds = 5\n",
        "    epochs = 3  # smoke test here; full 5-fold cell will set higher\n",
        "    train_bs = 8\n",
        "    valid_bs = 16\n",
        "    num_workers = 8\n",
        "    model_name = 'convnext_base.fb_in22k_ft_in1k'\n",
        "    lr = 1e-4\n",
        "    weight_decay = 1e-4\n",
        "    label_smoothing = 0.0  # disable when using mixup\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    tta = True\n",
        "    tta_hflip = True\n",
        "    out_dir = 'outputs'\n",
        "    mixup_alpha = 0.2\n",
        "    cutmix_alpha = 0.0\n",
        "    mixup_prob = 0.3\n",
        "    mixup_switch_prob = 0.0\n",
        "    warmup_epochs = 3\n",
        "    ema_decay = 0.9998\n",
        "    grad_clip = 1.0\n",
        "    early_stop_patience = 6\n",
        "\n",
        "os.makedirs(CFG.out_dir, exist_ok=True)\n",
        "\n",
        "# ========== Utils ========== \n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "set_seed(CFG.seed)\n",
        "\n",
        "def read_data():\n",
        "    labels = pd.read_csv('labels.csv')\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    # label order must match sample_submission columns (excluding id)\n",
        "    class_names = [c for c in ss.columns if c != 'id']\n",
        "    class2idx = {c:i for i,c in enumerate(class_names)}\n",
        "    idx2class = {i:c for c,i in class2idx.items()}\n",
        "    labels['filepath'] = labels['id'].apply(lambda x: f'train/{x}.jpg')\n",
        "    labels['target'] = labels['breed'].map(class2idx)\n",
        "    assert labels['target'].notnull().all(), 'Found breed not in sample_submission columns order'\n",
        "    # Folds\n",
        "    skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
        "    labels['fold'] = -1\n",
        "    for f, (_, val_idx) in enumerate(skf.split(labels, labels['breed'])):\n",
        "        labels.loc[val_idx, 'fold'] = f\n",
        "    return labels, ss, class_names, class2idx, idx2class\n",
        "\n",
        "train_tfms = A.Compose([\n",
        "    A.RandomResizedCrop(size=(CFG.img_size, CFG.img_size), scale=(0.85, 1.0), ratio=(0.75, 1.333), p=1.0),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Affine(scale=(0.95, 1.05), translate_percent=(0.0, 0.02), rotate=(-10, 10), shear=(-2, 2), fit_output=False, border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05, p=0.5),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "valid_tfms = A.Compose([\n",
        "    A.Resize(height=CFG.img_size, width=CFG.img_size),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "class DogDataset(Dataset):\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transforms = transforms\n",
        "        self.is_test = 'target' not in self.df.columns\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = cv2.imread(row['filepath'])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)['image']\n",
        "        if self.is_test:\n",
        "            return img, row['id']\n",
        "        else:\n",
        "            return img, int(row['target'])\n",
        "\n",
        "def build_model(num_classes):\n",
        "    model = timm.create_model(CFG.model_name, pretrained=True, num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "def _maybe_channels_last(x):\n",
        "    return x.to(memory_format=torch.channels_last)\n",
        "\n",
        "def train_one_fold(fold, labels, num_classes):\n",
        "    print(f'\\n===== Fold {fold} =====')\n",
        "    trn_df = labels[labels.fold != fold][['filepath','target']].copy()\n",
        "    val_df = labels[labels.fold == fold][['filepath','target']].copy()\n",
        "\n",
        "    train_ds = DogDataset(trn_df, transforms=train_tfms)\n",
        "    valid_ds = DogDataset(val_df, transforms=valid_tfms)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=CFG.train_bs, shuffle=True, num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "\n",
        "    model = build_model(num_classes).to(CFG.device)\n",
        "    ema = ModelEmaV2(model, decay=CFG.ema_decay) if CFG.device=='cuda' else None\n",
        "\n",
        "    # Mixup config + losses\n",
        "    mixup_base = CFG.mixup_prob if (CFG.mixup_alpha > 0 or CFG.cutmix_alpha > 0) else 0.0\n",
        "    mixup_fn = Mixup(\n",
        "        mixup_alpha=CFG.mixup_alpha, cutmix_alpha=CFG.cutmix_alpha, prob=mixup_base,\n",
        "        switch_prob=CFG.mixup_switch_prob, mode='batch', num_classes=num_classes\n",
        "    ) if mixup_base > 0 else None\n",
        "\n",
        "    criterion_hard = nn.CrossEntropyLoss(label_smoothing=CFG.label_smoothing).to(CFG.device)\n",
        "    criterion_soft = SoftTargetCrossEntropy().to(CFG.device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
        "    # Warmup + Cosine\n",
        "    warmup_epochs = min(CFG.warmup_epochs, max(1, CFG.epochs//5))\n",
        "    cosine_epochs = max(1, CFG.epochs - warmup_epochs)\n",
        "    cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cosine_epochs)\n",
        "    warmup = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, total_iters=warmup_epochs)\n",
        "    scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_epochs])\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(CFG.device=='cuda'))\n",
        "\n",
        "    best_val = 1e9\n",
        "    best_path = os.path.join(CFG.out_dir, f'fold{fold}_best.pth')\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(1, CFG.epochs+1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        n = 0\n",
        "        t0 = time.time()\n",
        "\n",
        "        # Mixup prob decays linearly to 0 by 90% of total epochs\n",
        "        if mixup_fn is not None:\n",
        "            frac = (epoch - 1) / max(1, CFG.epochs * 0.9)\n",
        "            decay = max(0.0, 1.0 - min(1.0, frac))\n",
        "            mixup_fn.mixup_prob = mixup_base * decay\n",
        "\n",
        "        for imgs, targets in train_loader:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True)\n",
        "            imgs = _maybe_channels_last(imgs)\n",
        "            targets = targets.to(CFG.device, non_blocking=True)\n",
        "            if mixup_fn is not None and mixup_fn.mixup_prob > 0:\n",
        "                imgs, targets = mixup_fn(imgs, targets)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "                logits = model(imgs)\n",
        "                if targets.dtype.is_floating_point:\n",
        "                    loss = criterion_soft(logits, targets)\n",
        "                else:\n",
        "                    loss = criterion_hard(logits, targets)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            if CFG.grad_clip is not None and CFG.grad_clip > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            if ema is not None:\n",
        "                ema.update(model)\n",
        "            running_loss += loss.item() * imgs.size(0)\n",
        "            n += imgs.size(0)\n",
        "        train_loss = running_loss / max(1,n)\n",
        "\n",
        "        # validation (strict CE, no smoothing)\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        m = 0\n",
        "        val_criterion = nn.CrossEntropyLoss().to(CFG.device)\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "            for imgs, targets in valid_loader:\n",
        "                imgs = imgs.to(CFG.device, non_blocking=True)\n",
        "                imgs = _maybe_channels_last(imgs)\n",
        "                targets = targets.to(CFG.device, non_blocking=True)\n",
        "                logits = ema.module(imgs) if ema is not None else model(imgs)\n",
        "                loss = val_criterion(logits, targets)\n",
        "                val_loss += loss.item() * imgs.size(0)\n",
        "                m += imgs.size(0)\n",
        "        val_loss /= max(1,m)\n",
        "        scheduler.step()\n",
        "        dt = time.time()-t0\n",
        "        print(f'Epoch {epoch}/{CFG.epochs} - train {train_loss:.4f} - val {val_loss:.4f} - time {dt:.1f}s - mixup_p {mixup_fn.mixup_prob if mixup_fn else 0:.2f}')\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            to_save = ema.module.state_dict() if ema is not None else model.state_dict()\n",
        "            torch.save({'model': to_save}, best_path)\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= CFG.early_stop_patience:\n",
        "                print('Early stopping triggered')\n",
        "                break\n",
        "\n",
        "    # Load best and produce OOF preds\n",
        "    ckpt = torch.load(best_path, map_location=CFG.device)\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    oof_logits = []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, targets in valid_loader:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True)\n",
        "            imgs = _maybe_channels_last(imgs)\n",
        "            logits = model(imgs)\n",
        "            oof_logits.append(logits.detach().cpu().float())\n",
        "    oof_logits = torch.cat(oof_logits, dim=0).numpy()\n",
        "\n",
        "    # Cleanup\n",
        "    del model, optimizer, scaler\n",
        "    if 'ema' in locals() and ema is not None:\n",
        "        del ema\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return best_path, oof_logits, val_df.index.values\n",
        "\n",
        "def predict_test_single_model(ckpt_path, num_classes):\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    test_df = ss[['id']].copy()\n",
        "    test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "    test_ds = DogDataset(test_df[['id','filepath']], transforms=valid_tfms)\n",
        "    test_loader = DataLoader(test_ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    model = build_model(num_classes).to(CFG.device)\n",
        "    ckpt = torch.load(ckpt_path, map_location=CFG.device)\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, _ids in test_loader:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True)\n",
        "            imgs = _maybe_channels_last(imgs)\n",
        "            logits = model(imgs)\n",
        "            if CFG.tta and CFG.tta_hflip:\n",
        "                imgs_flipped = torch.flip(imgs, dims=[3])\n",
        "                logits_f = model(imgs_flipped)\n",
        "                logits = (logits + logits_f) / 2.0\n",
        "            all_logits.append(logits.detach().cpu().float())\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    probs = torch.softmax(all_logits, dim=1).numpy()\n",
        "    # Cleanup\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return probs\n",
        "\n",
        "def save_submission(test_probs, class_names):\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    probs = np.clip(test_probs, 1e-7, 1-1e-7)\n",
        "    probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "    sub = pd.DataFrame(probs, columns=class_names)\n",
        "    sub.insert(0, 'id', ss['id'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv with shape', sub.shape)\n",
        "\n",
        "# ========== Run quick sanity: Train fold 0 only (can be skipped for full CV cell) ==========\n",
        "labels, ss, class_names, class2idx, idx2class = read_data()\n",
        "num_classes = len(class_names)\n",
        "\n",
        "best_path, oof_logits, oof_index = train_one_fold(0, labels, num_classes)\n",
        "test_probs = predict_test_single_model(best_path, num_classes)\n",
        "save_submission(test_probs, class_names)\n",
        "\n",
        "exp_log = {\n",
        "    'model': CFG.model_name,\n",
        "    'img_size': CFG.img_size,\n",
        "    'epochs': CFG.epochs,\n",
        "    'folds_trained': [0],\n",
        "    'tta_hflip': CFG.tta_hflip,\n",
        "    'mixup': {'mixup_alpha': CFG.mixup_alpha, 'cutmix_alpha': CFG.cutmix_alpha, 'prob': CFG.mixup_prob},\n",
        "}\n",
        "with open(os.path.join(CFG.out_dir, 'exp_log.json'), 'w') as f:\n",
        "    json.dump(exp_log, f, indent=2)\n",
        "print('Sanity fold complete. Ready to run full CV in next cell.')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n===== Fold 0 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - train 3.4707 - val 4.7265 - time 135.2s - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 - train 1.7037 - val 3.8991 - time 135.4s - mixup_p 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 - train 0.7016 - val 2.8320 - time 135.2s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv with shape (1023, 121)\nSanity fold complete. Ready to run full CV in next cell.\n"
          ]
        }
      ]
    },
    {
      "id": "7037ed33-c33f-428a-919e-fddee2cebf0f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 5-Fold Training + Ensembling Submission (updated recipe)\n",
        "from sklearn.metrics import log_loss\n",
        "import numpy as np, json, os, torch\n",
        "\n",
        "# Set full-run epochs per expert recipe\n",
        "CFG.epochs = 30\n",
        "\n",
        "# Ensure fresh data and correct functions from cell 1 are used\n",
        "labels, ss, class_names, class2idx, idx2class = read_data()\n",
        "num_classes = len(class_names)\n",
        "\n",
        "all_oof_logits = np.zeros((len(labels), num_classes), dtype=np.float32)\n",
        "all_val_indices = []\n",
        "ckpts = []\n",
        "\n",
        "for fold in range(CFG.n_folds):\n",
        "    best_path, oof_logits, val_idx = train_one_fold(fold, labels, num_classes)\n",
        "    all_oof_logits[val_idx] = oof_logits\n",
        "    all_val_indices.extend(val_idx.tolist())\n",
        "    ckpts.append(best_path)\n",
        "\n",
        "# OOF logloss\n",
        "oof_probs = torch.softmax(torch.tensor(all_oof_logits), dim=1).numpy()\n",
        "oof_loss = log_loss(labels.loc[all_val_indices, 'target'].values, oof_probs[all_val_indices])\n",
        "print('OOF logloss:', oof_loss)\n",
        "\n",
        "# Test-time ensemble (average probs over folds)\n",
        "test_probs_sum = None\n",
        "for p in ckpts:\n",
        "    probs = predict_test_single_model(p, num_classes)\n",
        "    if test_probs_sum is None:\n",
        "        test_probs_sum = probs\n",
        "    else:\n",
        "        test_probs_sum += probs\n",
        "test_probs_avg = test_probs_sum / len(ckpts)\n",
        "save_submission(test_probs_avg, class_names)\n",
        "\n",
        "# Save metrics/log\n",
        "metrics = {\n",
        "    'oof_logloss': float(oof_loss),\n",
        "    'folds': CFG.n_folds,\n",
        "    'epochs': CFG.epochs,\n",
        "    'model': CFG.model_name,\n",
        "    'img_size': CFG.img_size,\n",
        "    'mixup': {'alpha': CFG.mixup_alpha, 'prob': CFG.mixup_prob},\n",
        "    'weight_decay': CFG.weight_decay\n",
        "}\n",
        "with open(os.path.join(CFG.out_dir, 'metrics.json'), 'w') as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "print('5-fold training complete. Submission saved.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n===== Fold 0 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - train 3.4651 - val 4.7522 - time 135.8s - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - train 1.5517 - val 4.1412 - time 135.3s - mixup_p 0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - train 1.3573 - val 3.2413 - time 135.5s - mixup_p 0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - train 1.3011 - val 2.2952 - time 135.0s - mixup_p 0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - train 1.1946 - val 1.5658 - time 135.8s - mixup_p 0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - train 1.0963 - val 1.0945 - time 135.8s - mixup_p 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - train 1.0408 - val 0.8195 - time 136.2s - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - train 0.9937 - val 0.6620 - time 135.5s - mixup_p 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - train 1.0021 - val 0.5714 - time 135.2s - mixup_p 0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - train 0.9916 - val 0.5234 - time 135.4s - mixup_p 0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - train 0.9778 - val 0.4975 - time 135.9s - mixup_p 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - train 0.9799 - val 0.4884 - time 135.7s - mixup_p 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - train 0.9744 - val 0.4883 - time 136.1s - mixup_p 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - train 0.9779 - val 0.4960 - time 135.6s - mixup_p 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - train 0.9481 - val 0.5058 - time 136.3s - mixup_p 0.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - train 0.4462 - val 0.5017 - time 135.4s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - train 0.4435 - val 0.5061 - time 136.3s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - train 0.4443 - val 0.5155 - time 135.2s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 - train 0.4435 - val 0.5262 - time 134.9s - mixup_p 0.00\nEarly stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n===== Fold 1 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - train 3.3460 - val 4.7194 - time 135.4s - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - train 1.5600 - val 4.1189 - time 135.5s - mixup_p 0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - train 1.3502 - val 3.2270 - time 135.9s - mixup_p 0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - train 1.3047 - val 2.2879 - time 135.8s - mixup_p 0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - train 1.1751 - val 1.5592 - time 134.9s - mixup_p 0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - train 1.1182 - val 1.1021 - time 135.7s - mixup_p 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - train 1.0862 - val 0.8378 - time 136.3s - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - train 1.0301 - val 0.6946 - time 136.4s - mixup_p 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - train 1.0077 - val 0.6162 - time 135.7s - mixup_p 0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - train 0.9660 - val 0.5777 - time 135.6s - mixup_p 0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - train 0.9705 - val 0.5627 - time 136.2s - mixup_p 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - train 0.9875 - val 0.5590 - time 135.3s - mixup_p 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - train 0.9892 - val 0.5654 - time 135.3s - mixup_p 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - train 0.9565 - val 0.5750 - time 135.5s - mixup_p 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - train 0.9755 - val 0.5875 - time 135.8s - mixup_p 0.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - train 0.4442 - val 0.5899 - time 136.1s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - train 0.4396 - val 0.5965 - time 135.7s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - train 0.4457 - val 0.6084 - time 136.2s - mixup_p 0.00\nEarly stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n===== Fold 2 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - train 3.3875 - val 4.7171 - time 135.5s - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - train 1.5122 - val 4.1185 - time 134.9s - mixup_p 0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - train 1.3649 - val 3.2430 - time 135.6s - mixup_p 0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - train 1.2991 - val 2.3142 - time 135.7s - mixup_p 0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - train 1.1799 - val 1.5884 - time 135.3s - mixup_p 0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - train 1.1107 - val 1.1288 - time 135.5s - mixup_p 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - train 1.0600 - val 0.8669 - time 135.8s - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - train 1.0048 - val 0.7204 - time 136.0s - mixup_p 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - train 0.9927 - val 0.6395 - time 135.4s - mixup_p 0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - train 0.9811 - val 0.5906 - time 135.1s - mixup_p 0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - train 0.9779 - val 0.5678 - time 135.5s - mixup_p 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - train 0.9827 - val 0.5582 - time 135.5s - mixup_p 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - train 0.9793 - val 0.5617 - time 136.2s - mixup_p 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - train 0.9415 - val 0.5695 - time 135.1s - mixup_p 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - train 0.9766 - val 0.5791 - time 135.6s - mixup_p 0.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - train 0.4435 - val 0.5796 - time 135.9s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - train 0.4443 - val 0.5879 - time 134.8s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - train 0.4421 - val 0.5966 - time 135.1s - mixup_p 0.00\nEarly stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n===== Fold 3 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - train 3.3530 - val 4.6588 - time 135.5s - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - train 1.5114 - val 4.0433 - time 135.4s - mixup_p 0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - train 1.3247 - val 3.1624 - time 135.5s - mixup_p 0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - train 1.2659 - val 2.2496 - time 135.6s - mixup_p 0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - train 1.1844 - val 1.5613 - time 135.4s - mixup_p 0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - train 1.1230 - val 1.1349 - time 135.2s - mixup_p 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - train 1.0547 - val 0.8870 - time 136.3s - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - train 1.0157 - val 0.7458 - time 135.5s - mixup_p 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - train 0.9723 - val 0.6675 - time 135.3s - mixup_p 0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - train 0.9732 - val 0.6296 - time 135.3s - mixup_p 0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - train 0.9814 - val 0.6166 - time 135.9s - mixup_p 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - train 0.9722 - val 0.6154 - time 135.5s - mixup_p 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - train 0.9701 - val 0.6189 - time 136.1s - mixup_p 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - train 0.9755 - val 0.6298 - time 136.7s - mixup_p 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - train 0.9708 - val 0.6407 - time 135.9s - mixup_p 0.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - train 0.4454 - val 0.6438 - time 135.4s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - train 0.4396 - val 0.6538 - time 135.5s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - train 0.4404 - val 0.6657 - time 135.8s - mixup_p 0.00\nEarly stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n===== Fold 4 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - train 3.3765 - val 4.7112 - time 135.3s - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - train 1.5081 - val 4.1131 - time 135.4s - mixup_p 0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - train 1.3240 - val 3.2337 - time 135.0s - mixup_p 0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - train 1.2874 - val 2.3085 - time 135.4s - mixup_p 0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - train 1.1555 - val 1.5929 - time 135.5s - mixup_p 0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - train 1.1034 - val 1.1419 - time 135.7s - mixup_p 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - train 1.0957 - val 0.8742 - time 135.7s - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - train 1.0369 - val 0.7225 - time 135.4s - mixup_p 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - train 0.9811 - val 0.6386 - time 135.2s - mixup_p 0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - train 0.9817 - val 0.5940 - time 135.5s - mixup_p 0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - train 1.0115 - val 0.5757 - time 135.2s - mixup_p 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - train 0.9999 - val 0.5714 - time 135.4s - mixup_p 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - train 0.9733 - val 0.5721 - time 135.8s - mixup_p 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - train 0.9838 - val 0.5797 - time 135.4s - mixup_p 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - train 0.9347 - val 0.5895 - time 135.4s - mixup_p 0.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - train 0.4395 - val 0.5912 - time 135.0s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - train 0.4420 - val 0.6019 - time 134.8s - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - train 0.4407 - val 0.6141 - time 134.5s - mixup_p 0.00\nEarly stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF logloss: 0.5584536029048021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv with shape (1023, 121)\n5-fold training complete. Submission saved.\n"
          ]
        }
      ]
    },
    {
      "id": "85398cc2-4c9d-4ca0-8480-b67356a1e4f6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 5-Fold Training with tf_efficientnet_b4_ns @512 (alternative strong baseline)\n",
        "from sklearn.metrics import log_loss\n",
        "import numpy as np, json, os, torch\n",
        "\n",
        "# Reconfigure CFG for EfficientNet-B4 strong baseline (fixed hyperparams per action plan)\n",
        "CFG.model_name = 'tf_efficientnet_b4_ns'\n",
        "CFG.img_size = 512\n",
        "CFG.train_bs = 8\n",
        "CFG.valid_bs = 16\n",
        "CFG.epochs = 35\n",
        "CFG.lr = 1e-4\n",
        "CFG.weight_decay = 1e-4\n",
        "CFG.mixup_alpha = 0.2\n",
        "CFG.cutmix_alpha = 0.0\n",
        "CFG.mixup_prob = 0.3\n",
        "CFG.mixup_switch_prob = 0.0\n",
        "CFG.ema_decay = 0.9998\n",
        "# Per strategy A: reduce early stopping patience to avoid overfitting\n",
        "CFG.early_stop_patience = 3\n",
        "\n",
        "# Update transforms to new resolution (add border_mode to avoid black borders)\n",
        "train_tfms = A.Compose([\n",
        "    A.RandomResizedCrop(size=(CFG.img_size, CFG.img_size), scale=(0.85, 1.0), ratio=(0.75, 1.333), p=1.0),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Affine(scale=(0.95, 1.05), translate_percent=(0.0, 0.02), rotate=(-10, 10), shear=(-2, 2), fit_output=False, border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05, p=0.5),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "valid_tfms = A.Compose([\n",
        "    A.Resize(height=CFG.img_size, width=CFG.img_size),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Fresh data\n",
        "labels, ss, class_names, class2idx, idx2class = read_data()\n",
        "num_classes = len(class_names)\n",
        "\n",
        "all_oof_logits = np.zeros((len(labels), num_classes), dtype=np.float32)\n",
        "all_val_indices = []\n",
        "ckpts = []\n",
        "\n",
        "for fold in range(CFG.n_folds):\n",
        "    best_path, oof_logits, val_idx = train_one_fold(fold, labels, num_classes)\n",
        "    all_oof_logits[val_idx] = oof_logits\n",
        "    all_val_indices.extend(val_idx.tolist())\n",
        "    ckpts.append(best_path)\n",
        "\n",
        "# OOF logloss\n",
        "oof_probs = torch.softmax(torch.tensor(all_oof_logits), dim=1).numpy()\n",
        "oof_loss = log_loss(labels.loc[all_val_indices, 'target'].values, oof_probs[all_val_indices])\n",
        "print('OOF logloss (EffNet-B4 512):', oof_loss)\n",
        "\n",
        "# Ensemble test predictions\n",
        "test_probs_sum = None\n",
        "for p in ckpts:\n",
        "    probs = predict_test_single_model(p, num_classes)\n",
        "    test_probs_sum = probs if test_probs_sum is None else (test_probs_sum + probs)\n",
        "test_probs_avg = test_probs_sum / len(ckpts)\n",
        "save_submission(test_probs_avg, class_names)\n",
        "\n",
        "metrics = {\n",
        "    'oof_logloss': float(oof_loss),\n",
        "    'folds': CFG.n_folds,\n",
        "    'epochs': CFG.epochs,\n",
        "    'model': CFG.model_name,\n",
        "    'img_size': CFG.img_size,\n",
        "    'mixup': {'alpha': CFG.mixup_alpha, 'prob': CFG.mixup_prob},\n",
        "    'weight_decay': CFG.weight_decay,\n",
        "    'early_stop_patience': CFG.early_stop_patience\n",
        "}\n",
        "with open(os.path.join(CFG.out_dir, 'metrics.json'), 'w') as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "print('5-fold EfficientNet-B4 run complete. Submission saved.')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n===== Fold 0 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35 - train 4.5266 - val 4.8111 - time 137.0s - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/35 - train 2.5996 - val 4.5192 - time 136.6s - mixup_p 0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/35 - train 1.7003 - val 3.9949 - time 137.1s - mixup_p 0.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/35 - train 1.4892 - val 3.3604 - time 139.3s - mixup_p 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/35 - train 1.3685 - val 2.6937 - time 137.6s - mixup_p 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/35 - train 1.2731 - val 2.0587 - time 137.6s - mixup_p 0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/35 - train 1.2448 - val 1.5281 - time 137.7s - mixup_p 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/35 - train 1.1635 - val 1.1313 - time 138.4s - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/35 - train 1.1404 - val 0.8606 - time 139.0s - mixup_p 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/35 - train 1.1307 - val 0.6925 - time 136.0s - mixup_p 0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/35 - train 1.0912 - val 0.5899 - time 137.7s - mixup_p 0.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/35 - train 1.0806 - val 0.5323 - time 137.5s - mixup_p 0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/35 - train 1.0772 - val 0.4983 - time 141.2s - mixup_p 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/35 - train 1.0504 - val 0.4819 - time 139.7s - mixup_p 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/35 - train 1.0282 - val 0.4773 - time 139.5s - mixup_p 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/35 - train 1.0328 - val 0.4809 - time 138.6s - mixup_p 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/35 - train 1.0521 - val 0.4879 - time 138.5s - mixup_p 0.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/35 - train 1.0120 - val 0.4978 - time 138.9s - mixup_p 0.01\nEarly stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n===== Fold 1 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35 - train 4.4862 - val 4.7684 - time 137.2s - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/35 - train 2.5350 - val 4.4629 - time 138.3s - mixup_p 0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/35 - train 1.6514 - val 3.9290 - time 138.9s - mixup_p 0.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/35 - train 1.4598 - val 3.2928 - time 137.8s - mixup_p 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/35 - train 1.3812 - val 2.6233 - time 139.8s - mixup_p 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/35 - train 1.2890 - val 2.0059 - time 141.1s - mixup_p 0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/35 - train 1.2158 - val 1.4946 - time 138.4s - mixup_p 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/35 - train 1.1584 - val 1.1075 - time 137.8s - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/35 - train 1.1411 - val 0.8508 - time 139.9s - mixup_p 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/35 - train 1.0954 - val 0.6934 - time 139.0s - mixup_p 0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/35 - train 1.0873 - val 0.6047 - time 136.8s - mixup_p 0.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/35 - train 1.0806 - val 0.5577 - time 138.1s - mixup_p 0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/35 - train 1.0907 - val 0.5345 - time 138.4s - mixup_p 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/35 - train 1.0691 - val 0.5232 - time 138.8s - mixup_p 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/35 - train 1.0415 - val 0.5236 - time 139.4s - mixup_p 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/35 - train 1.0610 - val 0.5315 - time 142.2s - mixup_p 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/35 - train 1.0268 - val 0.5391 - time 143.5s - mixup_p 0.03\nEarly stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n===== Fold 2 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35 - train 4.5121 - val 4.7809 - time 139.6s - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/35 - train 2.6038 - val 4.4883 - time 139.9s - mixup_p 0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/35 - train 1.7103 - val 3.9646 - time 139.4s - mixup_p 0.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/35 - train 1.5400 - val 3.3294 - time 141.5s - mixup_p 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/35 - train 1.3626 - val 2.6650 - time 143.0s - mixup_p 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/35 - train 1.2481 - val 2.0436 - time 139.7s - mixup_p 0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/35 - train 1.1837 - val 1.5348 - time 143.7s - mixup_p 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/35 - train 1.1321 - val 1.1519 - time 141.4s - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/35 - train 1.1656 - val 0.8897 - time 142.2s - mixup_p 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/35 - train 1.1253 - val 0.7246 - time 141.2s - mixup_p 0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/35 - train 1.1465 - val 0.6306 - time 140.6s - mixup_p 0.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/35 - train 1.1224 - val 0.5767 - time 140.7s - mixup_p 0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/35 - train 1.0559 - val 0.5480 - time 140.6s - mixup_p 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/35 - train 1.0734 - val 0.5401 - time 141.0s - mixup_p 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/35 - train 1.0638 - val 0.5408 - time 139.5s - mixup_p 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/35 - train 1.0508 - val 0.5457 - time 141.9s - mixup_p 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/35 - train 1.0185 - val 0.5555 - time 141.9s - mixup_p 0.03\nEarly stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n===== Fold 3 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35 - train 4.5048 - val 4.7946 - time 142.0s - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/35 - train 2.5736 - val 4.4963 - time 142.1s - mixup_p 0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/35 - train 1.6541 - val 3.9674 - time 140.3s - mixup_p 0.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/35 - train 1.4610 - val 3.3373 - time 141.7s - mixup_p 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/35 - train 1.3735 - val 2.6852 - time 139.9s - mixup_p 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/35 - train 1.2770 - val 2.0762 - time 144.0s - mixup_p 0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/35 - train 1.2078 - val 1.5851 - time 140.8s - mixup_p 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/35 - train 1.1376 - val 1.2155 - time 141.8s - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/35 - train 1.1418 - val 0.9556 - time 140.4s - mixup_p 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/35 - train 1.1163 - val 0.7844 - time 143.2s - mixup_p 0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/35 - train 1.0841 - val 0.6804 - time 142.6s - mixup_p 0.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/35 - train 1.0314 - val 0.6228 - time 142.7s - mixup_p 0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/35 - train 1.0411 - val 0.5934 - time 140.0s - mixup_p 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/35 - train 1.0297 - val 0.5803 - time 140.7s - mixup_p 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/35 - train 1.0459 - val 0.5793 - time 139.3s - mixup_p 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/35 - train 1.0354 - val 0.5845 - time 141.4s - mixup_p 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/35 - train 1.0694 - val 0.5933 - time 140.9s - mixup_p 0.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/35 - train 1.0343 - val 0.6009 - time 143.0s - mixup_p 0.01\nEarly stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n===== Fold 4 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35 - train 4.4672 - val 4.7599 - time 140.7s - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/35 - train 2.5122 - val 4.4578 - time 142.3s - mixup_p 0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/35 - train 1.6578 - val 3.9375 - time 142.1s - mixup_p 0.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/35 - train 1.4761 - val 3.3194 - time 141.4s - mixup_p 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/35 - train 1.3312 - val 2.6777 - time 142.5s - mixup_p 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/35 - train 1.2337 - val 2.0812 - time 140.9s - mixup_p 0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/35 - train 1.1938 - val 1.5871 - time 143.5s - mixup_p 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/35 - train 1.1364 - val 1.2084 - time 141.4s - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/35 - train 1.1374 - val 0.9421 - time 143.3s - mixup_p 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/35 - train 1.0867 - val 0.7720 - time 141.9s - mixup_p 0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/35 - train 1.0973 - val 0.6692 - time 143.0s - mixup_p 0.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/35 - train 1.0557 - val 0.6085 - time 143.1s - mixup_p 0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/35 - train 1.0471 - val 0.5800 - time 145.3s - mixup_p 0.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/35 - train 1.0423 - val 0.5708 - time 142.9s - mixup_p 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/35 - train 1.0259 - val 0.5741 - time 143.4s - mixup_p 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/35 - train 1.0196 - val 0.5814 - time 141.0s - mixup_p 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/35 - train 1.0320 - val 0.5961 - time 141.8s - mixup_p 0.03\nEarly stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF logloss (EffNet-B4 512): 0.5381454578467637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv with shape (1023, 121)\n5-fold EfficientNet-B4 run complete. Submission saved.\n"
          ]
        }
      ]
    },
    {
      "id": "18ef1a14-67ce-4c19-b6c0-92ada7a5a64c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Temperature scaling using OOF logits, then re-infer test with scaled logits\n",
        "import torch, numpy as np, pandas as pd, os, gc\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "assert 'all_oof_logits' in globals() and 'all_val_indices' in globals(), 'Run 5-fold cell to populate OOF logits first.'\n",
        "\n",
        "# Fit temperature T to minimize OOF logloss\n",
        "y_true = labels.loc[all_val_indices, 'target'].values\n",
        "oof_logits_tensor = torch.tensor(all_oof_logits[all_val_indices], dtype=torch.float32, device=CFG.device)\n",
        "T = torch.tensor([1.0], dtype=torch.float32, device=CFG.device, requires_grad=True)\n",
        "optimizer = torch.optim.LBFGS([T], lr=0.1, max_iter=100, line_search_fn='strong_wolfe')\n",
        "\n",
        "def _nll():\n",
        "    optimizer.zero_grad()\n",
        "    scaled = oof_logits_tensor / torch.clamp(T, min=1e-3)\n",
        "    log_probs = torch.log_softmax(scaled, dim=1)\n",
        "    nll = -log_probs[torch.arange(len(y_true), device=CFG.device), torch.tensor(y_true, device=CFG.device)].mean()\n",
        "    nll.backward()\n",
        "    return nll\n",
        "\n",
        "optimizer.step(_nll)\n",
        "T_opt = float(T.detach().clamp(min=1e-3).cpu().item())\n",
        "oof_probs_scaled = torch.softmax(oof_logits_tensor / T_opt, dim=1).cpu().numpy()\n",
        "oof_loss_scaled = log_loss(y_true, oof_probs_scaled)\n",
        "print(f'Fitted temperature: {T_opt:.4f} | OOF logloss (scaled): {oof_loss_scaled:.6f}')\n",
        "\n",
        "# Re-run test inference to collect logits per fold and apply temperature scaling\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "test_df = ss[['id']].copy()\n",
        "test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "test_ds = DogDataset(test_df[['id','filepath']], transforms=valid_tfms)\n",
        "test_loader = DataLoader(test_ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "\n",
        "def predict_test_logits(ckpt_path, num_classes):\n",
        "    model = build_model(num_classes).to(CFG.device)\n",
        "    ckpt = torch.load(ckpt_path, map_location=CFG.device)\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, _ids in test_loader:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True)\n",
        "            imgs = imgs.to(memory_format=torch.channels_last)\n",
        "            logits = model(imgs)\n",
        "            if CFG.tta and CFG.tta_hflip:\n",
        "                imgs_flipped = torch.flip(imgs, dims=[3])\n",
        "                logits_f = model(imgs_flipped)\n",
        "                logits = (logits + logits_f) / 2.0\n",
        "            all_logits.append(logits.detach().cpu().float())\n",
        "    logits_cat = torch.cat(all_logits, dim=0)\n",
        "    del model\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "    return logits_cat\n",
        "\n",
        "num_classes = len(class_names)\n",
        "test_logits_sum = None\n",
        "for p in ckpts:\n",
        "    logits = predict_test_logits(p, num_classes)\n",
        "    test_logits_sum = logits if test_logits_sum is None else (test_logits_sum + logits)\n",
        "test_logits_avg = test_logits_sum / len(ckpts)\n",
        "test_probs_scaled = torch.softmax(test_logits_avg / T_opt, dim=1).numpy()\n",
        "\n",
        "# Save scaled submission\n",
        "probs = np.clip(test_probs_scaled, 1e-9, 1-1e-9)\n",
        "probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "sub = pd.DataFrame(probs, columns=class_names)\n",
        "sub.insert(0, 'id', ss['id'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved temperature-scaled submission.csv with shape', sub.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitted temperature: 0.7941 | OOF logloss (scaled): 0.472534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved temperature-scaled submission.csv with shape (1023, 121)\n"
          ]
        }
      ]
    },
    {
      "id": "0fbca447-a75b-44aa-bdc6-5076fd089699",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Multi-scale TTA with temperature scaling (no retraining)\n",
        "import torch, numpy as np, pandas as pd, gc\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "assert 'ckpts' in globals() and len(ckpts) == CFG.n_folds, 'Run 5-fold training to populate ckpts'\n",
        "assert 'T_opt' in globals(), 'Run temperature scaling cell to compute T_opt'\n",
        "\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "test_df = ss[['id']].copy()\n",
        "test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "\n",
        "def make_tta_tfms(size):\n",
        "    return A.Compose([\n",
        "        A.Resize(height=size, width=size),\n",
        "        A.CenterCrop(height=CFG.img_size, width=CFG.img_size, p=1.0) if size > CFG.img_size else A.NoOp(),\n",
        "        A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def predict_test_logits_with_tfms(ckpt_path, tfms):\n",
        "    ds = DogDataset(test_df[['id','filepath']], transforms=tfms)\n",
        "    dl = DataLoader(ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    model = build_model(len(class_names)).to(CFG.device)\n",
        "    ckpt = torch.load(ckpt_path, map_location=CFG.device)\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    outs = []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, _ids in dl:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            logits = model(imgs)\n",
        "            if CFG.tta and CFG.tta_hflip:\n",
        "                logits = (logits + model(torch.flip(imgs, dims=[3]))) / 2.0\n",
        "            outs.append(logits.detach().cpu().float())\n",
        "    logits_cat = torch.cat(outs, dim=0)\n",
        "    del model; torch.cuda.empty_cache(); gc.collect()\n",
        "    return logits_cat\n",
        "\n",
        "# Define multi-scale sizes around training size\n",
        "scales = [int(CFG.img_size*0.9), CFG.img_size, int(CFG.img_size*1.15)]\n",
        "scales = sorted(list(set([max(224, s) for s in scales])))\n",
        "print('TTA scales:', scales, '| base size:', CFG.img_size)\n",
        "\n",
        "fold_logits_sum = None\n",
        "for p in ckpts:\n",
        "    scale_logits_sum = None\n",
        "    for s in scales:\n",
        "        tfms = make_tta_tfms(s)\n",
        "        logits = predict_test_logits_with_tfms(p, tfms)\n",
        "        scale_logits_sum = logits if scale_logits_sum is None else (scale_logits_sum + logits)\n",
        "    logits_avg_scales = scale_logits_sum / len(scales)\n",
        "    fold_logits_sum = logits_avg_scales if fold_logits_sum is None else (fold_logits_sum + logits_avg_scales)\n",
        "\n",
        "test_logits_ens = fold_logits_sum / len(ckpts)\n",
        "test_probs_scaled = torch.softmax(test_logits_ens / T_opt, dim=1).numpy()\n",
        "\n",
        "# Save submission\n",
        "probs = np.clip(test_probs_scaled, 1e-9, 1-1e-9)\n",
        "probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "sub = pd.DataFrame(probs, columns=class_names)\n",
        "sub.insert(0, 'id', ss['id'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved multi-scale TTA + temp-scaled submission.csv with shape', sub.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TTA scales: [460, 512, 588] | base size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved multi-scale TTA + temp-scaled submission.csv with shape (1023, 121)\n"
          ]
        }
      ]
    },
    {
      "id": "e4c95040-a606-47ea-ac2d-3d4903163463",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Per-fold temperature scaling and ensemble (no retraining)\n",
        "import torch, numpy as np, pandas as pd, gc\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "assert 'labels' in globals() and 'ckpts' in globals() and 'all_oof_logits' in globals(), 'Run 5-fold training cell first.'\n",
        "\n",
        "per_fold_T = []\n",
        "for f in range(CFG.n_folds):\n",
        "    val_idx_f = labels.index[labels.fold == f].values\n",
        "    y_true_f = labels.loc[val_idx_f, 'target'].values\n",
        "    oof_logits_f = torch.tensor(all_oof_logits[val_idx_f], dtype=torch.float32, device=CFG.device)\n",
        "    T = torch.tensor([1.0], dtype=torch.float32, device=CFG.device, requires_grad=True)\n",
        "    opt = torch.optim.LBFGS([T], lr=0.1, max_iter=100, line_search_fn='strong_wolfe')\n",
        "    def _closure():\n",
        "        opt.zero_grad()\n",
        "        scaled = oof_logits_f / torch.clamp(T, min=1e-3)\n",
        "        log_probs = torch.log_softmax(scaled, dim=1)\n",
        "        idx = torch.arange(len(y_true_f), device=CFG.device)\n",
        "        y_t = torch.tensor(y_true_f, device=CFG.device)\n",
        "        nll = -log_probs[idx, y_t].mean()\n",
        "        nll.backward()\n",
        "        return nll\n",
        "    opt.step(_closure)\n",
        "    T_val = float(T.detach().clamp(min=1e-3).cpu().item())\n",
        "    per_fold_T.append(T_val)\n",
        "    with torch.no_grad():\n",
        "        probs_f = torch.softmax(oof_logits_f / T_val, dim=1).cpu().numpy()\n",
        "    print(f'Fold {f}: T={T_val:.4f}, OOF logloss (scaled)={log_loss(y_true_f, probs_f):.6f}')\n",
        "\n",
        "# Build test logits per fold, apply per-fold temperature, then average probabilities\n",
        "def predict_test_logits_once(ckpt_path, num_classes):\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    test_df = ss[['id']].copy()\n",
        "    test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "    test_ds = DogDataset(test_df[['id','filepath']], transforms=valid_tfms)\n",
        "    test_loader = DataLoader(test_ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    model = build_model(num_classes).to(CFG.device)\n",
        "    ckpt = torch.load(ckpt_path, map_location=CFG.device)\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    outs = []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, _ids in test_loader:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            logits = model(imgs)\n",
        "            if CFG.tta and CFG.tta_hflip:\n",
        "                logits = (logits + model(torch.flip(imgs, dims=[3]))) / 2.0\n",
        "            outs.append(logits.detach().cpu().float())\n",
        "    logits_cat = torch.cat(outs, dim=0)\n",
        "    del model; torch.cuda.empty_cache(); gc.collect()\n",
        "    return logits_cat\n",
        "\n",
        "num_classes = len(class_names)\n",
        "probs_sum = None\n",
        "for f, (p, Tf) in enumerate(zip(ckpts, per_fold_T)):\n",
        "    logits = predict_test_logits_once(p, num_classes)\n",
        "    probs = torch.softmax(logits / Tf, dim=1).numpy()\n",
        "    probs_sum = probs if probs_sum is None else (probs_sum + probs)\n",
        "probs_avg = probs_sum / len(ckpts)\n",
        "\n",
        "# Save submission\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "probs = np.clip(probs_avg, 1e-9, 1-1e-9)\n",
        "probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "sub = pd.DataFrame(probs, columns=class_names)\n",
        "sub.insert(0, 'id', ss['id'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved per-fold temp-scaled submission.csv with shape', sub.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: T=0.7861, OOF logloss (scaled)=0.414481\nFold 1: T=0.8036, OOF logloss (scaled)=0.455294\nFold 2: T=0.7986, OOF logloss (scaled)=0.475274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3: T=0.7979, OOF logloss (scaled)=0.517592\nFold 4: T=0.7845, OOF logloss (scaled)=0.499581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved per-fold temp-scaled submission.csv with shape (1023, 121)\n"
          ]
        }
      ]
    },
    {
      "id": "1d660c96-9d59-4574-b8bf-5fad2a5bc0bc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Multi-scale TTA + per-fold temperature scaling (average logits per scale, then temp & softmax)\n",
        "import torch, numpy as np, pandas as pd, gc\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "assert 'ckpts' in globals() and len(ckpts) == CFG.n_folds, 'Run 5-fold training to populate ckpts'\n",
        "assert 'labels' in globals() and 'all_oof_logits' in globals(), 'Need OOF logits and labels for per-fold T'\n",
        "\n",
        "# Ensure per_fold_T is available; if not, fit it\n",
        "if 'per_fold_T' not in globals():\n",
        "    per_fold_T = []\n",
        "    for f in range(CFG.n_folds):\n",
        "        val_idx_f = labels.index[labels.fold == f].values\n",
        "        y_true_f = labels.loc[val_idx_f, 'target'].values\n",
        "        oof_logits_f = torch.tensor(all_oof_logits[val_idx_f], dtype=torch.float32, device=CFG.device)\n",
        "        T = torch.tensor([1.0], dtype=torch.float32, device=CFG.device, requires_grad=True)\n",
        "        opt = torch.optim.LBFGS([T], lr=0.1, max_iter=100, line_search_fn='strong_wolfe')\n",
        "        def _closure():\n",
        "            opt.zero_grad()\n",
        "            scaled = oof_logits_f / torch.clamp(T, min=1e-3)\n",
        "            log_probs = torch.log_softmax(scaled, dim=1)\n",
        "            idx = torch.arange(len(y_true_f), device=CFG.device)\n",
        "            y_t = torch.tensor(y_true_f, device=CFG.device)\n",
        "            nll = -log_probs[idx, y_t].mean()\n",
        "            nll.backward()\n",
        "            return nll\n",
        "        opt.step(_closure)\n",
        "        T_val = float(T.detach().clamp(min=1e-3).cpu().item())\n",
        "        per_fold_T.append(T_val)\n",
        "\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "test_df = ss[['id']].copy()\n",
        "test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "\n",
        "def make_tta_tfms(size):\n",
        "    return A.Compose([\n",
        "        A.Resize(height=size, width=size),\n",
        "        A.CenterCrop(height=CFG.img_size, width=CFG.img_size, p=1.0) if size > CFG.img_size else A.NoOp(),\n",
        "        A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def predict_test_logits_with_tfms(ckpt_path, tfms):\n",
        "    ds = DogDataset(test_df[['id','filepath']], transforms=tfms)\n",
        "    dl = DataLoader(ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    model = build_model(len(class_names)).to(CFG.device)\n",
        "    ckpt = torch.load(ckpt_path, map_location=CFG.device)\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    outs = []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, _ids in dl:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            logits = model(imgs)\n",
        "            if CFG.tta and CFG.tta_hflip:\n",
        "                logits = (logits + model(torch.flip(imgs, dims=[3]))) / 2.0\n",
        "            outs.append(logits.detach().cpu().float())\n",
        "    logits_cat = torch.cat(outs, dim=0)\n",
        "    del model; torch.cuda.empty_cache(); gc.collect()\n",
        "    return logits_cat\n",
        "\n",
        "# Define scales and run per-fold multi-scale logits averaging, then temp scale and softmax\n",
        "scales = [int(CFG.img_size*0.9), CFG.img_size, int(CFG.img_size*1.15)]\n",
        "scales = sorted(list(set([max(224, s) for s in scales])))\n",
        "print('Per-fold TTA scales:', scales, '| base size:', CFG.img_size)\n",
        "\n",
        "probs_sum = None\n",
        "for f, (p, Tf) in enumerate(zip(ckpts, per_fold_T)):\n",
        "    scale_logits_sum = None\n",
        "    for s in scales:\n",
        "        tfms = make_tta_tfms(s)\n",
        "        logits = predict_test_logits_with_tfms(p, tfms)\n",
        "        scale_logits_sum = logits if scale_logits_sum is None else (scale_logits_sum + logits)\n",
        "    logits_avg_scales = scale_logits_sum / len(scales)\n",
        "    probs_f = torch.softmax(logits_avg_scales / Tf, dim=1).numpy()\n",
        "    probs_sum = probs_f if probs_sum is None else (probs_sum + probs_f)\n",
        "\n",
        "probs_avg = probs_sum / len(ckpts)\n",
        "probs = np.clip(probs_avg, 1e-9, 1-1e-9)\n",
        "probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "sub = pd.DataFrame(probs, columns=class_names)\n",
        "sub.insert(0, 'id', ss['id'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved per-fold TTA+temp-scaled submission.csv with shape', sub.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per-fold TTA scales: [460, 512, 588] | base size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved per-fold TTA+temp-scaled submission.csv with shape (1023, 121)\n"
          ]
        }
      ]
    },
    {
      "id": "45356b44-e246-4b5e-94d4-6c6485cd84a8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Strategy 3: Feature Extraction + Fast Classifier (XGBoost GPU) using xgb.train\n",
        "import os, gc, numpy as np, pandas as pd, torch, timm, cv2, sys, importlib, subprocess\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "def ensure(pkg, import_name=None):\n",
        "    imp = import_name or pkg\n",
        "    try:\n",
        "        importlib.import_module(imp)\n",
        "    except Exception:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
        "        importlib.import_module(imp)\n",
        "\n",
        "ensure('xgboost')\n",
        "import xgboost as xgb\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, df, size):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transforms = A.Compose([\n",
        "            A.Resize(height=size, width=size),\n",
        "            A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = cv2.imread(row['filepath'])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.transforms(image=img)['image']\n",
        "        return img, row['id'] if 'id' in row else idx\n",
        "\n",
        "def build_backbone_feat_extractor(model_name, size):\n",
        "    model = timm.create_model(model_name, pretrained=True, num_classes=0, global_pool='avg')\n",
        "    model.eval().to(CFG.device)\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_features(df, size, model_name, batch_size=32):\n",
        "    ds = SimpleImageDataset(df[['id','filepath']], size=size)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    model = build_backbone_feat_extractor(model_name, size)\n",
        "    feats = []\n",
        "    with torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, _ in dl:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            f = model(imgs)\n",
        "            feats.append(f.detach().cpu().float())\n",
        "    feats = torch.cat(feats, dim=0).numpy()\n",
        "    del model; torch.cuda.empty_cache(); gc.collect()\n",
        "    return feats\n",
        "\n",
        "# Config for feature pipeline\n",
        "FE = {\n",
        "    'model_name': 'convnext_base.fb_in22k_ft_in1k',\n",
        "    'img_size': 448,\n",
        "    'batch_size': 32\n",
        "}\n",
        "\n",
        "# Prepare dataframes\n",
        "labels_df = labels.copy() if 'labels' in globals() else pd.read_csv('labels.csv')\n",
        "if 'filepath' not in labels_df.columns:\n",
        "    labels_df['filepath'] = labels_df['id'].apply(lambda x: f'train/{x}.jpg')\n",
        "if 'fold' not in labels_df.columns:\n",
        "    skf_tmp = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    labels_df['fold'] = -1\n",
        "    for f, (_, vi) in enumerate(skf_tmp.split(labels_df, labels_df['breed'])):\n",
        "        labels_df.loc[vi, 'fold'] = f\n",
        "\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "test_df = ss[['id']].copy()\n",
        "test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "class_names_fe = [c for c in ss.columns if c != 'id']\n",
        "class2idx_fe = {c:i for i,c in enumerate(class_names_fe)}\n",
        "labels_df['target'] = labels_df['breed'].map(class2idx_fe)\n",
        "\n",
        "# Extract or load cached features\n",
        "train_feats_path = os.path.join(CFG.out_dir, f'train_feats_{FE[\"model_name\"]}_{FE[\"img_size\"]}.npy')\n",
        "test_feats_path  = os.path.join(CFG.out_dir, f'test_feats_{FE[\"model_name\"]}_{FE[\"img_size\"]}.npy')\n",
        "os.makedirs(CFG.out_dir, exist_ok=True)\n",
        "\n",
        "if os.path.exists(train_feats_path) and os.path.exists(test_feats_path):\n",
        "    X_train = np.load(train_feats_path)\n",
        "    X_test = np.load(test_feats_path)\n",
        "else:\n",
        "    X_train = extract_features(labels_df[['id','filepath']], FE['img_size'], FE['model_name'], batch_size=FE['batch_size'])\n",
        "    X_test = extract_features(test_df[['id','filepath']], FE['img_size'], FE['model_name'], batch_size=FE['batch_size'])\n",
        "    np.save(train_feats_path, X_train)\n",
        "    np.save(test_feats_path, X_test)\n",
        "y_train = labels_df['target'].values.astype(int)\n",
        "\n",
        "# Ensure correct dtypes\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "\n",
        "# CV with xgboost.train (GPU) on features\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof = np.zeros((len(labels_df), len(class_names_fe)), dtype=np.float32)\n",
        "test_pred_sum = np.zeros((len(test_df), len(class_names_fe)), dtype=np.float32)\n",
        "oof_idx_all = []\n",
        "\n",
        "num_classes = len(class_names_fe)\n",
        "xgb_params = {\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'predictor': 'gpu_predictor',\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': num_classes,\n",
        "    'max_depth': 6,\n",
        "    'eta': 0.03,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'lambda': 8.0,\n",
        "    'alpha': 0.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'verbosity': 0\n",
        "}\n",
        "\n",
        "num_boost_round = 4000\n",
        "early_stopping_rounds = 200\n",
        "\n",
        "for f, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
        "    X_tr, X_va = X_train[trn_idx], X_train[val_idx]\n",
        "    y_tr, y_va = y_train[trn_idx], y_train[val_idx]\n",
        "    dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
        "    dvalid = xgb.DMatrix(X_va, label=y_va)\n",
        "    dtest = xgb.DMatrix(X_test)\n",
        "    bst = xgb.train(\n",
        "        params=xgb_params,\n",
        "        dtrain=dtrain,\n",
        "        num_boost_round=num_boost_round,\n",
        "        evals=[(dvalid, 'valid')],\n",
        "        early_stopping_rounds=early_stopping_rounds,\n",
        "        verbose_eval=False\n",
        "    )\n",
        "    # Predictions (use best_iteration if available)\n",
        "    try:\n",
        "        pred_val = bst.predict(dvalid, iteration_range=(0, bst.best_iteration + 1))\n",
        "        pred_test = bst.predict(dtest, iteration_range=(0, bst.best_iteration + 1))\n",
        "    except Exception:\n",
        "        ntree = getattr(bst, 'best_ntree_limit', 0) or bst.num_boosted_rounds()\n",
        "        pred_val = bst.predict(dvalid, ntree_limit=ntree)\n",
        "        pred_test = bst.predict(dtest, ntree_limit=ntree)\n",
        "    oof[val_idx] = pred_val.astype(np.float32)\n",
        "    test_pred_sum += pred_test.astype(np.float32)\n",
        "    oof_idx_all.extend(val_idx.tolist())\n",
        "    fold_loss = log_loss(y_va, oof[val_idx])\n",
        "    print(f'FE-XGB(train) Fold {f} logloss: {fold_loss:.6f}')\n",
        "\n",
        "oof_loss = log_loss(y_train[oof_idx_all], oof[oof_idx_all])\n",
        "print('FE-XGB(train) OOF logloss:', oof_loss)\n",
        "\n",
        "# Build submission\n",
        "test_probs = test_pred_sum / skf.n_splits\n",
        "probs = np.clip(test_probs, 1e-9, 1-1e-9)\n",
        "probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "sub = pd.DataFrame(probs, columns=class_names_fe)\n",
        "sub.insert(0, 'id', test_df['id'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved FE-XGB(train) submission.csv with shape', sub.shape)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "id": "ad82a92c-5d9f-42a7-9419-b214280e0c32",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Strategy 3b: Feature Extraction already cached -> Fast SGDClassifier (multinomial logistic) on ConvNeXt features\n",
        "import os, numpy as np, pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Paths\n",
        "out_dir = 'outputs'\n",
        "train_feats_path = os.path.join(out_dir, 'train_feats_convnext_base.fb_in22k_ft_in1k_448.npy')\n",
        "test_feats_path = os.path.join(out_dir, 'test_feats_convnext_base.fb_in22k_ft_in1k_448.npy')\n",
        "\n",
        "# Load cached features\n",
        "X_train = np.load(train_feats_path).astype(np.float32)\n",
        "X_test = np.load(test_feats_path).astype(np.float32)\n",
        "\n",
        "# Prepare labels\n",
        "labels_df = labels.copy() if 'labels' in globals() else pd.read_csv('labels.csv')\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "class_names_fe = [c for c in ss.columns if c != 'id']\n",
        "class2idx_fe = {c:i for i,c in enumerate(class_names_fe)}\n",
        "labels_df['target'] = labels_df['breed'].map(class2idx_fe).astype(int)\n",
        "y_train = labels_df['target'].values\n",
        "\n",
        "# 5-fold CV with fast SGDClassifier (multinomial logistic regression approximation)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof = np.zeros((len(labels_df), len(class_names_fe)), dtype=np.float32)\n",
        "test_pred_sum = np.zeros((len(ss), len(class_names_fe)), dtype=np.float32)\n",
        "oof_idx_all = []\n",
        "\n",
        "for f, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
        "    X_tr, X_va = X_train[trn_idx], X_train[val_idx]\n",
        "    y_tr, y_va = y_train[trn_idx], y_train[val_idx]\n",
        "    clf = Pipeline([\n",
        "        ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
        "        ('sgd', SGDClassifier(loss='log_loss', penalty='l2', alpha=1e-4,\n",
        "                              learning_rate='optimal', max_iter=2000, tol=1e-4,\n",
        "                              early_stopping=True, n_iter_no_change=5,\n",
        "                              random_state=42, n_jobs=-1))\n",
        "    ])\n",
        "    clf.fit(X_tr, y_tr)\n",
        "    oof_fold = clf.predict_proba(X_va).astype(np.float32)\n",
        "    test_fold = clf.predict_proba(X_test).astype(np.float32)\n",
        "    # Stabilize probabilities: replace NaNs/Infs and renormalize\n",
        "    oof_fold = np.nan_to_num(oof_fold, nan=1e-9, posinf=1e9, neginf=0.0)\n",
        "    oof_fold = oof_fold / np.clip(oof_fold.sum(axis=1, keepdims=True), 1e-12, None)\n",
        "    test_fold = np.nan_to_num(test_fold, nan=1e-9, posinf=1e9, neginf=0.0)\n",
        "    test_fold = test_fold / np.clip(test_fold.sum(axis=1, keepdims=True), 1e-12, None)\n",
        "    oof[val_idx] = oof_fold\n",
        "    test_pred_sum += test_fold\n",
        "    oof_idx_all.extend(val_idx.tolist())\n",
        "    fold_loss = log_loss(y_va, oof[val_idx])\n",
        "    print(f'SGD-Logit Fold {f} logloss: {fold_loss:.6f}')\n",
        "\n",
        "oof_loss = log_loss(y_train[oof_idx_all], oof[oof_idx_all])\n",
        "print('SGD-Logit OOF logloss:', oof_loss)\n",
        "\n",
        "# Submission\n",
        "test_probs = test_pred_sum / skf.n_splits\n",
        "probs = np.clip(test_probs, 1e-9, 1-1e-9)\n",
        "probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "sub = pd.DataFrame(probs, columns=class_names_fe)\n",
        "sub.insert(0, 'id', ss['id'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved SGD-Logit FE submission.csv with shape', sub.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py:403: RuntimeWarning: invalid value encountered in divide\n  prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py:403: RuntimeWarning: invalid value encountered in divide\n  prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD-Logit Fold 0 logloss: 1.341019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py:403: RuntimeWarning: invalid value encountered in divide\n  prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py:403: RuntimeWarning: invalid value encountered in divide\n  prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD-Logit Fold 1 logloss: 1.471068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py:403: RuntimeWarning: invalid value encountered in divide\n  prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py:403: RuntimeWarning: invalid value encountered in divide\n  prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD-Logit Fold 2 logloss: 1.432442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py:403: RuntimeWarning: invalid value encountered in divide\n  prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py:403: RuntimeWarning: invalid value encountered in divide\n  prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD-Logit Fold 3 logloss: 1.610691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py:403: RuntimeWarning: invalid value encountered in divide\n  prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_base.py:403: RuntimeWarning: invalid value encountered in divide\n  prob /= prob.sum(axis=1).reshape((prob.shape[0], -1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD-Logit Fold 4 logloss: 1.347397\nSGD-Logit OOF logloss: 1.4405337187877858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved SGD-Logit FE submission.csv with shape (1023, 121)\n"
          ]
        }
      ]
    },
    {
      "id": "282fbc78-568f-49e3-aedd-6372b4b06b4e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Strategy 1: Downsize + Two-Stage Training with aggressive ES (EffNet-B2 @384)\n",
        "import os, gc, time, numpy as np, pandas as pd, torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Reconfigure CFG for smaller model to reduce overfitting and train faster\n",
        "CFG.model_name = 'tf_efficientnet_b2_ns'\n",
        "CFG.img_size = 384\n",
        "CFG.train_bs = 16\n",
        "CFG.valid_bs = 32\n",
        "CFG.lr = 1e-4\n",
        "CFG.weight_decay = 1e-4\n",
        "CFG.mixup_alpha = 0.2\n",
        "CFG.cutmix_alpha = 0.0\n",
        "CFG.mixup_prob = 0.3\n",
        "CFG.mixup_switch_prob = 0.0\n",
        "CFG.ema_decay = 0.9998\n",
        "CFG.early_stop_patience = 3  # aggressive ES as advised\n",
        "\n",
        "# Update transforms for new resolution\n",
        "train_tfms = A.Compose([\n",
        "    A.RandomResizedCrop(size=(CFG.img_size, CFG.img_size), scale=(0.85, 1.0), ratio=(0.75, 1.333), p=1.0),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Affine(scale=(0.95, 1.05), translate_percent=(0.0, 0.02), rotate=(-10, 10), shear=(-2, 2), fit_output=False, border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05, p=0.5),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "valid_tfms = A.Compose([\n",
        "    A.Resize(height=CFG.img_size, width=CFG.img_size),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "def train_two_stage_fold(fold, labels, num_classes, stage1_epochs=6, stage2_epochs=6):\n",
        "    # Data\n",
        "    trn_df = labels[labels.fold != fold][['filepath','target']].copy()\n",
        "    val_df = labels[labels.fold == fold][['filepath','target']].copy()\n",
        "    train_ds = DogDataset(trn_df, transforms=train_tfms)\n",
        "    valid_ds = DogDataset(val_df, transforms=valid_tfms)\n",
        "    train_loader = DataLoader(train_ds, batch_size=CFG.train_bs, shuffle=True, num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "\n",
        "    # Model\n",
        "    model = build_model(num_classes).to(CFG.device)\n",
        "    ema = ModelEmaV2(model, decay=CFG.ema_decay) if CFG.device=='cuda' else None\n",
        "\n",
        "    # Mixup + losses\n",
        "    mixup_base = CFG.mixup_prob if (CFG.mixup_alpha > 0 or CFG.cutmix_alpha > 0) else 0.0\n",
        "    mixup_fn = Mixup(\n",
        "        mixup_alpha=CFG.mixup_alpha, cutmix_alpha=CFG.cutmix_alpha, prob=mixup_base,\n",
        "        switch_prob=CFG.mixup_switch_prob, mode='batch', num_classes=num_classes\n",
        "    ) if mixup_base > 0 else None\n",
        "    criterion_hard = nn.CrossEntropyLoss(label_smoothing=0.0).to(CFG.device)  # no LS\n",
        "    criterion_soft = SoftTargetCrossEntropy().to(CFG.device)\n",
        "\n",
        "    def run_training(epochs, lr, use_mixup):\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=CFG.weight_decay)\n",
        "        warmup_epochs = max(1, min(3, epochs//5))\n",
        "        cosine_epochs = max(1, epochs - warmup_epochs)\n",
        "        cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cosine_epochs)\n",
        "        warmup = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, total_iters=warmup_epochs)\n",
        "        scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_epochs])\n",
        "        scaler = torch.amp.GradScaler('cuda', enabled=(CFG.device=='cuda'))\n",
        "\n",
        "        best_val = 1e9\n",
        "        no_improve = 0\n",
        "        for epoch in range(1, epochs+1):\n",
        "            model.train()\n",
        "            # decay mixup with floor if enabled\n",
        "            if use_mixup and mixup_fn is not None:\n",
        "                frac = (epoch - 1) / max(1, epochs * 0.9)\n",
        "                decay = max(0.05, 1.0 - min(1.0, frac))  # keep small floor\n",
        "                mixup_fn.mixup_prob = mixup_base * decay\n",
        "            else:\n",
        "                if mixup_fn is not None:\n",
        "                    mixup_fn.mixup_prob = 0.0\n",
        "\n",
        "            train_loss, n = 0.0, 0\n",
        "            for imgs, targets in train_loader:\n",
        "                imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                targets = targets.to(CFG.device, non_blocking=True)\n",
        "                if use_mixup and mixup_fn is not None and mixup_fn.mixup_prob > 0:\n",
        "                    imgs, targets = mixup_fn(imgs, targets)\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                with torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "                    logits = model(imgs)\n",
        "                    loss = criterion_soft(logits, targets) if targets.dtype.is_floating_point else criterion_hard(logits, targets)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.unscale_(optimizer)\n",
        "                if CFG.grad_clip:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.grad_clip)\n",
        "                scaler.step(optimizer); scaler.update()\n",
        "                if ema is not None: ema.update(model)\n",
        "                train_loss += loss.item() * imgs.size(0); n += imgs.size(0)\n",
        "            train_loss /= max(1,n)\n",
        "\n",
        "            # validation\n",
        "            model.eval()\n",
        "            val_loss, m = 0.0, 0\n",
        "            with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "                for imgs, targets in valid_loader:\n",
        "                    imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                    targets = targets.to(CFG.device, non_blocking=True)\n",
        "                    logits = ema.module(imgs) if ema is not None else model(imgs)\n",
        "                    loss = criterion_hard(logits, targets)\n",
        "                    val_loss += loss.item() * imgs.size(0); m += imgs.size(0)\n",
        "            val_loss /= max(1,m)\n",
        "            scheduler.step()\n",
        "            print(f'Epoch {epoch}/{epochs} - train {train_loss:.4f} - val {val_loss:.4f} - mixup_p {mixup_fn.mixup_prob if (use_mixup and mixup_fn) else 0:.2f}')\n",
        "            # ES\n",
        "            improved = val_loss < getattr(run_training, 'best_val', 1e9) - 1e-5\n",
        "            if improved:\n",
        "                run_training.best_val = val_loss\n",
        "                run_training.best_state = (ema.module.state_dict() if ema is not None else model.state_dict())\n",
        "                no_improve = 0\n",
        "            else:\n",
        "                no_improve += 1\n",
        "                if no_improve >= CFG.early_stop_patience:\n",
        "                    print('Early stopping')\n",
        "                    break\n",
        "\n",
        "        # load best\n",
        "        if hasattr(run_training, 'best_state'):\n",
        "            model.load_state_dict(run_training.best_state, strict=False)\n",
        "\n",
        "    # Stage 1: train with mixup\n",
        "    print(f'Fold {fold} - Stage 1 training with mixup, epochs={stage1_epochs}')\n",
        "    run_training(stage1_epochs, lr=CFG.lr, use_mixup=True)\n",
        "\n",
        "    # Stage 2: fine-tune without mixup at lower LR\n",
        "    print(f'Fold {fold} - Stage 2 fine-tune no-mixup, epochs={stage2_epochs}')\n",
        "    run_training(stage2_epochs, lr=1e-5, use_mixup=False)\n",
        "\n",
        "    # Save best checkpoint\n",
        "    best_path = os.path.join(CFG.out_dir, f'fold{fold}_b2_two_stage_best.pth')\n",
        "    torch.save({'model': (ema.module.state_dict() if ema is not None else model.state_dict())}, best_path)\n",
        "\n",
        "    # OOF logits\n",
        "    model.eval()\n",
        "    valid_loader = DataLoader(valid_ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    oof_logits = []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, targets in valid_loader:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            logits = model(imgs)\n",
        "            oof_logits.append(logits.detach().cpu().float())\n",
        "    oof_logits = torch.cat(oof_logits, dim=0).numpy()\n",
        "\n",
        "    # cleanup\n",
        "    del model\n",
        "    if ema is not None: del ema\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "    return best_path, oof_logits, val_df.index.values\n",
        "\n",
        "# Fresh data and run a short CV (first fold only to gauge quickly)\n",
        "labels, ss, class_names, class2idx, idx2class = read_data()\n",
        "num_classes = len(class_names)\n",
        "folds_to_run = [0]  # run one fold quickly\n",
        "all_oof_logits_b2 = np.zeros((len(labels), num_classes), dtype=np.float32)\n",
        "all_val_idx_b2 = []\n",
        "ckpts_b2 = []\n",
        "\n",
        "for f in folds_to_run:\n",
        "    p, oof_l, val_idx = train_two_stage_fold(f, labels, num_classes, stage1_epochs=6, stage2_epochs=6)\n",
        "    all_oof_logits_b2[val_idx] = oof_l\n",
        "    all_val_idx_b2.extend(val_idx.tolist())\n",
        "    ckpts_b2.append(p)\n",
        "\n",
        "if len(all_val_idx_b2) > 0:\n",
        "    oof_probs_b2 = torch.softmax(torch.tensor(all_oof_logits_b2[all_val_idx_b2]), dim=1).numpy()\n",
        "    oof_loss_b2 = log_loss(labels.loc[all_val_idx_b2, 'target'].values, oof_probs_b2)\n",
        "    print('EffNet-B2 two-stage partial OOF logloss:', oof_loss_b2)\n",
        "\n",
        "# Quick test-time average over available folds\n",
        "if len(ckpts_b2) > 0:\n",
        "    test_df = ss[['id']].copy()\n",
        "    test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "    test_ds = DogDataset(test_df[['id','filepath']], transforms=valid_tfms)\n",
        "    test_loader = DataLoader(test_ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    def infer_ckpt(pth):\n",
        "        m = build_model(num_classes).to(CFG.device)\n",
        "        ck = torch.load(pth, map_location=CFG.device)\n",
        "        m.load_state_dict(ck['model'], strict=False); m.eval()\n",
        "        outs = []\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "            for imgs, _ids in test_loader:\n",
        "                imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                logits = m(imgs)\n",
        "                if CFG.tta and CFG.tta_hflip:\n",
        "                    logits = (logits + m(torch.flip(imgs, dims=[3]))) / 2.0\n",
        "                outs.append(logits.detach().cpu().float())\n",
        "        logits = torch.cat(outs, dim=0); del m; torch.cuda.empty_cache(); gc.collect(); return logits\n",
        "    sum_probs = None\n",
        "    for p in ckpts_b2:\n",
        "        lg = infer_ckpt(p)\n",
        "        pr = torch.softmax(lg, dim=1).numpy()\n",
        "        sum_probs = pr if sum_probs is None else (sum_probs + pr)\n",
        "    avg_probs = sum_probs / len(ckpts_b2)\n",
        "    probs = np.clip(avg_probs, 1e-9, 1-1e-9); probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "    sub = pd.DataFrame(probs, columns=class_names)\n",
        "    sub.insert(0, 'id', ss['id'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Saved B2 two-stage partial-fold submission.csv with shape', sub.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b2_ns to current tf_efficientnet_b2.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 - Stage 1 training with mixup, epochs=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 - train 4.7333 - val 4.8298 - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/6 - train 2.8073 - val 4.6771 - mixup_p 0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/6 - train 1.6856 - val 4.4105 - mixup_p 0.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/6 - train 1.4607 - val 4.1067 - mixup_p 0.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/6 - train 1.3399 - val 3.7889 - mixup_p 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 - train 1.2845 - val 3.4694 - mixup_p 0.02\nFold 0 - Stage 2 fine-tune no-mixup, epochs=6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 - train 3.4556 - val 3.4570 - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/6 - train 2.7004 - val 3.3874 - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/6 - train 1.8098 - val 3.2533 - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/6 - train 1.3923 - val 3.0861 - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/6 - train 1.1919 - val 2.9039 - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 - train 1.1190 - val 2.7196 - mixup_p 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EffNet-B2 two-stage partial OOF logloss: 2.7196442919473403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b2_ns to current tf_efficientnet_b2.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved B2 two-stage partial-fold submission.csv with shape (1023, 121)\n"
          ]
        }
      ]
    },
    {
      "id": "d6082c92-ccce-4a72-b46a-2494f8e7a6eb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Per-fold weighted ensemble with multi-scale TTA and per-fold temperature (force B4 checkpoints/model)\n",
        "import torch, numpy as np, pandas as pd, gc, timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "assert 'ckpts' in globals() and len(ckpts) == 5, 'Need ckpts from 5-fold training (B4)'\n",
        "assert 'all_oof_logits' in globals() and 'labels' in globals(), 'Need OOF logits & labels'\n",
        "\n",
        "# Use the architecture and size that produced ckpts (EffNet-B4 @512)\n",
        "BASE_MODEL_NAME = 'tf_efficientnet_b4_ns'\n",
        "BASE_SIZE = 512\n",
        "\n",
        "# Ensure per-fold temperatures exist; if not, fit them\n",
        "if 'per_fold_T' not in globals():\n",
        "    per_fold_T = []\n",
        "    for f in range(5):\n",
        "        val_idx_f = labels.index[labels.fold == f].values\n",
        "        y_true_f = labels.loc[val_idx_f, 'target'].values\n",
        "        oof_logits_f = torch.tensor(all_oof_logits[val_idx_f], dtype=torch.float32, device=CFG.device)\n",
        "        T = torch.tensor([1.0], dtype=torch.float32, device=CFG.device, requires_grad=True)\n",
        "        opt = torch.optim.LBFGS([T], lr=0.1, max_iter=100, line_search_fn='strong_wolfe')\n",
        "        def _closure():\n",
        "            opt.zero_grad()\n",
        "            scaled = oof_logits_f / torch.clamp(T, min=1e-3)\n",
        "            log_probs = torch.log_softmax(scaled, dim=1)\n",
        "            idx = torch.arange(len(y_true_f), device=CFG.device)\n",
        "            y_t = torch.tensor(y_true_f, device=CFG.device)\n",
        "            nll = -log_probs[idx, y_t].mean()\n",
        "            nll.backward()\n",
        "            return nll\n",
        "        opt.step(_closure)\n",
        "        per_fold_T.append(float(T.detach().clamp(min=1e-3).cpu().item()))\n",
        "\n",
        "# Compute per-fold OOF logloss after temperature to derive weights\n",
        "per_fold_loss = []\n",
        "for f, Tf in enumerate(per_fold_T):\n",
        "    val_idx_f = labels.index[labels.fold == f].values\n",
        "    y_true_f = labels.loc[val_idx_f, 'target'].values\n",
        "    oof_logits_f = torch.tensor(all_oof_logits[val_idx_f], dtype=torch.float32, device='cpu')\n",
        "    probs_f = torch.softmax(oof_logits_f / Tf, dim=1).numpy()\n",
        "    loss_f = log_loss(y_true_f, probs_f)\n",
        "    per_fold_loss.append(loss_f)\n",
        "per_fold_loss = np.array(per_fold_loss, dtype=np.float64)\n",
        "w = np.exp(-per_fold_loss); w = w / w.sum()\n",
        "print('Per-fold losses:', per_fold_loss, 'weights:', w)\n",
        "\n",
        "# Multi-scale TTA helpers\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "test_df = ss[['id']].copy()\n",
        "test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "num_classes = len([c for c in ss.columns if c != 'id'])\n",
        "\n",
        "def make_tta_tfms(size):\n",
        "    return A.Compose([\n",
        "        A.Resize(height=size, width=size),\n",
        "        A.CenterCrop(height=BASE_SIZE, width=BASE_SIZE, p=1.0) if size > BASE_SIZE else A.NoOp(),\n",
        "        A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def predict_test_logits_with_tfms(ckpt_path, tfms):\n",
        "    ds = DogDataset(test_df[['id','filepath']], transforms=tfms)\n",
        "    dl = DataLoader(ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    model = timm.create_model(BASE_MODEL_NAME, pretrained=False, num_classes=num_classes).to(CFG.device)\n",
        "    ckpt = torch.load(ckpt_path, map_location=CFG.device)\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    outs = []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, _ids in dl:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            logits = model(imgs)\n",
        "            if CFG.tta and CFG.tta_hflip:\n",
        "                logits = (logits + model(torch.flip(imgs, dims=[3]))) / 2.0\n",
        "            outs.append(logits.detach().cpu().float())\n",
        "    logits_cat = torch.cat(outs, dim=0)\n",
        "    del model; torch.cuda.empty_cache(); gc.collect()\n",
        "    return logits_cat\n",
        "\n",
        "scales = [int(BASE_SIZE*0.9), BASE_SIZE, int(BASE_SIZE*1.15)]\n",
        "scales = sorted(list(set([max(224, s) for s in scales])))\n",
        "print('Weighted TTA scales:', scales, '| base size:', BASE_SIZE)\n",
        "\n",
        "# Weighted average over folds: avg logits across scales per fold -> temp -> softmax -> weighted sum\n",
        "probs_weighted = None\n",
        "for f, (p, Tf) in enumerate(zip(ckpts, per_fold_T)):\n",
        "    scale_logits_sum = None\n",
        "    for s in scales:\n",
        "        tfms = make_tta_tfms(s)\n",
        "        logits = predict_test_logits_with_tfms(p, tfms)\n",
        "        scale_logits_sum = logits if scale_logits_sum is None else (scale_logits_sum + logits)\n",
        "    logits_avg_scales = scale_logits_sum / len(scales)\n",
        "    probs_f = torch.softmax(logits_avg_scales / Tf, dim=1).numpy()\n",
        "    probs_weighted = probs_f * w[f] if probs_weighted is None else (probs_weighted + probs_f * w[f])\n",
        "\n",
        "probs = np.clip(probs_weighted, 1e-9, 1-1e-9)\n",
        "probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "sub = pd.DataFrame(probs, columns=[c for c in ss.columns if c != 'id'])\n",
        "sub.insert(0, 'id', ss['id'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved weighted per-fold TTA+temp submission.csv with shape', sub.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per-fold losses: [0.39534907 0.44786684 0.4686756  0.523403   0.49069849] weights: [0.21427059 0.20330797 0.19912109 0.18851654 0.19478381]\nWeighted TTA scales: [460, 512, 588] | base size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved weighted per-fold TTA+temp submission.csv with shape (1023, 121)\n"
          ]
        }
      ]
    },
    {
      "id": "109b439a-c5d8-4f54-a47d-aac52d753969",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extended multi-scale TTA + per-fold temperature + per-fold weighting (denser scales)\n",
        "import torch, numpy as np, pandas as pd, gc, timm, albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "assert 'ckpts' in globals() and len(ckpts) == 5, 'Need ckpts from 5-fold training (B4)'\n",
        "assert 'all_oof_logits' in globals() and 'labels' in globals(), 'Need OOF logits & labels'\n",
        "\n",
        "BASE_MODEL_NAME = 'tf_efficientnet_b4_ns'\n",
        "BASE_SIZE = 512\n",
        "\n",
        "# Ensure per_fold_T exists; compute if missing\n",
        "if 'per_fold_T' not in globals():\n",
        "    per_fold_T = []\n",
        "    for f in range(5):\n",
        "        val_idx_f = labels.index[labels.fold == f].values\n",
        "        y_true_f = labels.loc[val_idx_f, 'target'].values\n",
        "        oof_logits_f = torch.tensor(all_oof_logits[val_idx_f], dtype=torch.float32, device=CFG.device)\n",
        "        T = torch.tensor([1.0], dtype=torch.float32, device=CFG.device, requires_grad=True)\n",
        "        opt = torch.optim.LBFGS([T], lr=0.1, max_iter=100, line_search_fn='strong_wolfe')\n",
        "        def _closure():\n",
        "            opt.zero_grad()\n",
        "            scaled = oof_logits_f / torch.clamp(T, min=1e-3)\n",
        "            log_probs = torch.log_softmax(scaled, dim=1)\n",
        "            idx = torch.arange(len(y_true_f), device=CFG.device)\n",
        "            y_t = torch.tensor(y_true_f, device=CFG.device)\n",
        "            nll = -log_probs[idx, y_t].mean()\n",
        "            nll.backward()\n",
        "            return nll\n",
        "        opt.step(_closure)\n",
        "        per_fold_T.append(float(T.detach().clamp(min=1e-3).cpu().item()))\n",
        "\n",
        "# Per-fold weights from temp-scaled OOF\n",
        "per_fold_loss = []\n",
        "for f, Tf in enumerate(per_fold_T):\n",
        "    val_idx_f = labels.index[labels.fold == f].values\n",
        "    y_true_f = labels.loc[val_idx_f, 'target'].values\n",
        "    oof_logits_f = torch.tensor(all_oof_logits[val_idx_f], dtype=torch.float32, device='cpu')\n",
        "    probs_f = torch.softmax(oof_logits_f / Tf, dim=1).numpy()\n",
        "    per_fold_loss.append(log_loss(y_true_f, probs_f))\n",
        "per_fold_loss = np.array(per_fold_loss, dtype=np.float64)\n",
        "w = np.exp(-per_fold_loss); w = w / w.sum()\n",
        "print('Per-fold losses:', per_fold_loss, 'weights:', w)\n",
        "\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "test_df = ss[['id']].copy()\n",
        "test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "num_classes = len([c for c in ss.columns if c != 'id'])\n",
        "\n",
        "def make_tta_tfms(size):\n",
        "    return A.Compose([\n",
        "        A.Resize(height=size, width=size),\n",
        "        A.CenterCrop(height=BASE_SIZE, width=BASE_SIZE, p=1.0) if size > BASE_SIZE else A.NoOp(),\n",
        "        A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def predict_test_logits_with_tfms(ckpt_path, tfms, batch_size):\n",
        "    ds = DogDataset(test_df[['id','filepath']], transforms=tfms)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    model = timm.create_model(BASE_MODEL_NAME, pretrained=False, num_classes=num_classes).to(CFG.device)\n",
        "    ckpt = torch.load(ckpt_path, map_location=CFG.device)\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    outs = []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, _ids in dl:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            logits = model(imgs)\n",
        "            if CFG.tta and CFG.tta_hflip:\n",
        "                logits = (logits + model(torch.flip(imgs, dims=[3]))) / 2.0\n",
        "            outs.append(logits.detach().cpu().float())\n",
        "    logits_cat = torch.cat(outs, dim=0)\n",
        "    del model; torch.cuda.empty_cache(); gc.collect()\n",
        "    return logits_cat\n",
        "\n",
        "# Denser scale set; adjust batch for memory at larger scales\n",
        "scales = sorted(list(set([int(BASE_SIZE*x) for x in [0.85, 0.9, 0.95, 1.0, 1.08, 1.15]])))\n",
        "print('Extended TTA scales:', scales, '| base size:', BASE_SIZE)\n",
        "\n",
        "def batch_for_size(size):\n",
        "    # heuristic: reduce batch when > BASE_SIZE\n",
        "    if size <= BASE_SIZE: return CFG.valid_bs\n",
        "    if size <= int(BASE_SIZE*1.08): return max(8, CFG.valid_bs//2)\n",
        "    return max(4, CFG.valid_bs//4)\n",
        "\n",
        "probs_weighted = None\n",
        "for f, (p, Tf) in enumerate(zip(ckpts, per_fold_T)):\n",
        "    scale_logits_sum = None\n",
        "    for s in scales:\n",
        "        tfms = make_tta_tfms(s)\n",
        "        bs = batch_for_size(s)\n",
        "        logits = predict_test_logits_with_tfms(p, tfms, bs)\n",
        "        scale_logits_sum = logits if scale_logits_sum is None else (scale_logits_sum + logits)\n",
        "    logits_avg_scales = scale_logits_sum / len(scales)\n",
        "    probs_f = torch.softmax(logits_avg_scales / Tf, dim=1).numpy()\n",
        "    probs_weighted = probs_f * w[f] if probs_weighted is None else (probs_weighted + probs_f * w[f])\n",
        "\n",
        "probs = np.clip(probs_weighted, 1e-9, 1-1e-9)\n",
        "probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "sub = pd.DataFrame(probs, columns=[c for c in ss.columns if c != 'id'])\n",
        "sub.insert(0, 'id', ss['id'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved extended-TTA weighted per-fold temp submission.csv with shape', sub.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per-fold losses: [0.39534907 0.44786684 0.4686756  0.523403   0.49069849] weights: [0.21427059 0.20330797 0.19912109 0.18851654 0.19478381]\nExtended TTA scales: [435, 460, 486, 512, 552, 588] | base size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved extended-TTA weighted per-fold temp submission.csv with shape (1023, 121)\n"
          ]
        }
      ]
    },
    {
      "id": "d34f6cd3-eebd-4bb8-816b-5ca4f00f9e9b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Strategy A (fast pivot): Corrected retraining with stronger regularization (folds 0-1) and fresh submission\n",
        "import os, gc, time, math, json\n",
        "import numpy as np, pandas as pd, torch, torch.nn as nn, albumentations as A, timm, cv2\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Configure for B4 @512 with stronger regularization\n",
        "CFG.model_name = 'tf_efficientnet_b4_ns'\n",
        "CFG.img_size = 512\n",
        "CFG.train_bs = 8\n",
        "CFG.valid_bs = 16\n",
        "CFG.epochs = 25\n",
        "CFG.lr = 1e-4\n",
        "CFG.weight_decay = 1e-4\n",
        "CFG.early_stop_patience = 2  # tighter ES to catch peak\n",
        "\n",
        "# Augmentations: stronger + CoarseDropout; keep normalization\n",
        "train_tfms = A.Compose([\n",
        "    A.RandomResizedCrop(size=(CFG.img_size, CFG.img_size), scale=(0.7, 1.0), ratio=(0.75, 1.333), p=1.0),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Affine(scale=(0.95, 1.05), translate_percent=(0.0, 0.03), rotate=(-12, 12), shear=(-3, 3), fit_output=False, border_mode=cv2.BORDER_REFLECT_101, p=0.6),\n",
        "    A.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.05, p=0.5),\n",
        "    A.CoarseDropout(max_holes=1, max_height=int(0.25*CFG.img_size), max_width=int(0.25*CFG.img_size), min_holes=1, min_height=int(0.1*CFG.img_size), min_width=int(0.1*CFG.img_size), fill_value=0, p=0.5),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "valid_tfms = A.Compose([\n",
        "    A.Resize(height=CFG.img_size, width=CFG.img_size),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "def build_model_b4(num_classes):\n",
        "    m = timm.create_model(CFG.model_name, pretrained=True, num_classes=num_classes)\n",
        "    return m\n",
        "\n",
        "def train_one_fold_v2(fold, labels, num_classes):\n",
        "    print(f'\\n=== Fast Retrain Fold {fold} ===')\n",
        "    trn_df = labels[labels.fold != fold][['filepath','target']].copy()\n",
        "    val_df = labels[labels.fold == fold][['filepath','target']].copy()\n",
        "    train_ds = DogDataset(trn_df, transforms=train_tfms)\n",
        "    valid_ds = DogDataset(val_df, transforms=valid_tfms)\n",
        "    train_loader = DataLoader(train_ds, batch_size=CFG.train_bs, shuffle=True, num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "\n",
        "    model = build_model_b4(num_classes).to(CFG.device)\n",
        "    ema = ModelEmaV2(model, decay=CFG.ema_decay) if CFG.device=='cuda' else None\n",
        "\n",
        "    # Mixup with floor (do not decay to 0)\n",
        "    mixup_base = CFG.mixup_prob if (CFG.mixup_alpha > 0 or CFG.cutmix_alpha > 0) else 0.0\n",
        "    mixup_fn = Mixup(\n",
        "        mixup_alpha=CFG.mixup_alpha, cutmix_alpha=CFG.cutmix_alpha, prob=mixup_base,\n",
        "        switch_prob=CFG.mixup_switch_prob, mode='batch', num_classes=num_classes\n",
        "    ) if mixup_base > 0 else None\n",
        "\n",
        "    criterion_hard = nn.CrossEntropyLoss().to(CFG.device)\n",
        "    criterion_soft = SoftTargetCrossEntropy().to(CFG.device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
        "    # 5-epoch warmup, cosine after; manual LR drop at epoch 8\n",
        "    warmup_epochs = min(5, max(1, CFG.epochs//6))\n",
        "    cosine_epochs = max(1, CFG.epochs - warmup_epochs)\n",
        "    cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cosine_epochs)\n",
        "    warmup = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.2, total_iters=warmup_epochs)\n",
        "    scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_epochs])\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(CFG.device=='cuda'))\n",
        "\n",
        "    best_val = 1e9; best_state = None; no_improve = 0\n",
        "    for epoch in range(1, CFG.epochs+1):\n",
        "        model.train(); t0=time.time()\n",
        "        if mixup_fn is not None:\n",
        "            frac = (epoch - 1) / max(1, CFG.epochs * 0.9)\n",
        "            decay = max(0.0, 1.0 - min(1.0, frac))\n",
        "            mixup_fn.mixup_prob = max(0.05, mixup_base * decay)  # floor at 0.05\n",
        "        if epoch == 8:\n",
        "            for g in optimizer.param_groups:\n",
        "                g['lr'] = 5e-5\n",
        "\n",
        "        run_loss = 0.0; n=0\n",
        "        for imgs, targets in train_loader:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            targets = targets.to(CFG.device, non_blocking=True)\n",
        "            if mixup_fn is not None and mixup_fn.mixup_prob > 0:\n",
        "                imgs, targets = mixup_fn(imgs, targets)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "                logits = model(imgs)\n",
        "                loss = criterion_soft(logits, targets) if targets.dtype.is_floating_point else criterion_hard(logits, targets)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            if CFG.grad_clip and CFG.grad_clip>0:\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), CFG.grad_clip)\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            if ema is not None: ema.update(model)\n",
        "            run_loss += loss.item()*imgs.size(0); n+=imgs.size(0)\n",
        "        train_loss = run_loss/max(1,n)\n",
        "\n",
        "        # validate\n",
        "        model.eval(); val_loss=0.0; m=0; val_crit = nn.CrossEntropyLoss().to(CFG.device)\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "            for imgs, targets in valid_loader:\n",
        "                imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                targets = targets.to(CFG.device, non_blocking=True)\n",
        "                logits = (ema.module(imgs) if ema is not None else model(imgs))\n",
        "                l = val_crit(logits, targets)\n",
        "                val_loss += l.item()*imgs.size(0); m+=imgs.size(0)\n",
        "        val_loss/=max(1,m); scheduler.step()\n",
        "        print(f'Epoch {epoch}/{CFG.epochs} - train {train_loss:.4f} - val {val_loss:.4f} - mixup_p {mixup_fn.mixup_prob if mixup_fn else 0:.2f}')\n",
        "        if val_loss < best_val - 1e-6:\n",
        "            best_val = val_loss; best_state = (ema.module.state_dict() if ema is not None else model.state_dict()); no_improve=0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= CFG.early_stop_patience:\n",
        "                print('Early stopping'); break\n",
        "\n",
        "    if best_state is not None: model.load_state_dict(best_state, strict=False)\n",
        "    best_path = os.path.join(CFG.out_dir, f'fold{fold}_fastfix_best.pth')\n",
        "    torch.save({'model': model.state_dict()}, best_path)\n",
        "\n",
        "    # OOF logits\n",
        "    model.eval(); oof_logits=[]\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, targets in valid_loader:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            logits = model(imgs)\n",
        "            oof_logits.append(logits.detach().cpu().float())\n",
        "    oof_logits = torch.cat(oof_logits, dim=0).numpy()\n",
        "\n",
        "    del model, optimizer, scaler\n",
        "    if ema is not None: del ema\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "    return best_path, oof_logits, val_df.index.values\n",
        "\n",
        "# Fresh data\n",
        "labels, ss, class_names, class2idx, idx2class = read_data()\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Train 1-2 folds (time-bounded)\n",
        "folds_to_run = [0,1]\n",
        "ckpts_fast = []; all_oof_logits_fast = np.zeros((len(labels), num_classes), dtype=np.float32); all_val_idx_fast=[]\n",
        "for f in folds_to_run:\n",
        "    p, oof_l, val_idx = train_one_fold_v2(f, labels, num_classes)\n",
        "    ckpts_fast.append(p); all_oof_logits_fast[val_idx] = oof_l; all_val_idx_fast.extend(val_idx.tolist())\n",
        "\n",
        "if len(all_val_idx_fast)>0:\n",
        "    oof_probs_fast = torch.softmax(torch.tensor(all_oof_logits_fast[all_val_idx_fast]), dim=1).numpy()\n",
        "    print('Fast OOF logloss (partial folds):', log_loss(labels.loc[all_val_idx_fast, 'target'].values, oof_probs_fast))\n",
        "\n",
        "# Per-fold temperature for new folds\n",
        "per_fold_T_fast = {}\n",
        "for f in folds_to_run:\n",
        "    val_idx_f = labels.index[labels.fold == f].values\n",
        "    y_true_f = labels.loc[val_idx_f, 'target'].values\n",
        "    logits_f = torch.tensor(all_oof_logits_fast[val_idx_f], dtype=torch.float32, device=CFG.device)\n",
        "    T = torch.tensor([1.0], dtype=torch.float32, device=CFG.device, requires_grad=True)\n",
        "    opt = torch.optim.LBFGS([T], lr=0.1, max_iter=100, line_search_fn='strong_wolfe')\n",
        "    def _closure():\n",
        "        opt.zero_grad()\n",
        "        scaled = logits_f / torch.clamp(T, min=1e-3)\n",
        "        idx = torch.arange(len(y_true_f), device=CFG.device)\n",
        "        nll = -torch.log_softmax(scaled, dim=1)[idx, torch.tensor(y_true_f, device=CFG.device)].mean()\n",
        "        nll.backward(); return nll\n",
        "    opt.step(_closure)\n",
        "    per_fold_T_fast[f] = float(T.detach().clamp(min=1e-3).cpu().item())\n",
        "\n",
        "# Inference with 3-scale TTA and per-fold temp for the new folds only\n",
        "def make_tta_tfms(size, base=CFG.img_size):\n",
        "    return A.Compose([\n",
        "        A.Resize(height=size, width=size),\n",
        "        A.CenterCrop(height=base, width=base, p=1.0) if size > base else A.NoOp(),\n",
        "        A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def predict_test_logits_ckpt(ckpt_path, size_list):\n",
        "    ss_local = pd.read_csv('sample_submission.csv')\n",
        "    test_df = ss_local[['id']].copy(); test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "    probs_sum = None\n",
        "    for s in size_list:\n",
        "        ds = DogDataset(test_df[['id','filepath']], transforms=make_tta_tfms(s))\n",
        "        dl = DataLoader(ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "        model = timm.create_model(CFG.model_name, pretrained=False, num_classes=num_classes).to(CFG.device)\n",
        "        ckpt = torch.load(ckpt_path, map_location=CFG.device)\n",
        "        model.load_state_dict(ckpt['model'], strict=False); model.eval()\n",
        "        outs = []\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "            for imgs, _ids in dl:\n",
        "                imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                logits = model(imgs)\n",
        "                if CFG.tta and CFG.tta_hflip:\n",
        "                    logits = (logits + model(torch.flip(imgs, dims=[3]))) / 2.0\n",
        "                outs.append(logits.detach().cpu().float())\n",
        "        logits_cat = torch.cat(outs, dim=0); del model; torch.cuda.empty_cache(); gc.collect()\n",
        "        probs = torch.softmax(logits_cat, dim=1).numpy()\n",
        "        probs_sum = probs if probs_sum is None else (probs_sum + probs)\n",
        "    return probs_sum / len(size_list)\n",
        "\n",
        "scales = sorted(list(set([int(CFG.img_size*0.9), CFG.img_size, int(CFG.img_size*1.15)])))\n",
        "print('Fast-TTA scales:', scales)\n",
        "\n",
        "ss_local = pd.read_csv('sample_submission.csv')\n",
        "blend = None\n",
        "for f, p in zip(folds_to_run, ckpts_fast):\n",
        "    probs = predict_test_logits_ckpt(p, scales)\n",
        "    T = per_fold_T_fast[f]\n",
        "    logits = torch.log(torch.tensor(probs)).float()  # invert-softmax approx to scale by T\n",
        "    probs_scaled = torch.softmax(logits / T, dim=1).numpy()\n",
        "    blend = probs_scaled if blend is None else (blend + probs_scaled)\n",
        "blend = blend / len(folds_to_run)\n",
        "blend = np.clip(blend, 1e-9, 1-1e-9); blend = blend / blend.sum(axis=1, keepdims=True)\n",
        "sub = pd.DataFrame(blend, columns=[c for c in ss_local.columns if c != 'id'])\n",
        "sub.insert(0, 'id', ss_local['id']); sub.to_csv('submission.csv', index=False)\n",
        "print('Saved fast-pivot submission.csv', sub.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_298/913718981.py:24: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(max_holes=1, max_height=int(0.25*CFG.img_size), max_width=int(0.25*CFG.img_size), min_holes=1, min_height=int(0.1*CFG.img_size), min_width=int(0.1*CFG.img_size), fill_value=0, p=0.5),\n/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n=== Fast Retrain Fold 0 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25 - train 3.9793 - val 4.7247 - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/25 - train 2.1537 - val 4.3571 - mixup_p 0.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/25 - train 1.6104 - val 3.8160 - mixup_p 0.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/25 - train 1.4752 - val 3.1868 - mixup_p 0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/25 - train 1.3752 - val 2.5444 - mixup_p 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/25 - train 1.3186 - val 1.9430 - mixup_p 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/25 - train 1.2353 - val 1.4477 - mixup_p 0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/25 - train 1.1467 - val 1.0826 - mixup_p 0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/25 - train 1.1324 - val 0.8422 - mixup_p 0.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/25 - train 1.0603 - val 0.6936 - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/25 - train 1.0784 - val 0.6022 - mixup_p 0.17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/25 - train 1.0544 - val 0.5469 - mixup_p 0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/25 - train 1.0605 - val 0.5157 - mixup_p 0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/25 - train 1.0386 - val 0.4984 - mixup_p 0.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/25 - train 1.0219 - val 0.4924 - mixup_p 0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/25 - train 1.0521 - val 0.4926 - mixup_p 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/25 - train 1.0539 - val 0.4951 - mixup_p 0.09\nEarly stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n=== Fast Retrain Fold 1 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25 - train 4.0248 - val 4.7278 - mixup_p 0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/25 - train 2.1440 - val 4.3622 - mixup_p 0.29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/25 - train 1.6035 - val 3.8230 - mixup_p 0.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/25 - train 1.4672 - val 3.1976 - mixup_p 0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/25 - train 1.4119 - val 2.5500 - mixup_p 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/25 - train 1.3231 - val 1.9571 - mixup_p 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/25 - train 1.1995 - val 1.4556 - mixup_p 0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/25 - train 1.1406 - val 1.0924 - mixup_p 0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/25 - train 1.1131 - val 0.8595 - mixup_p 0.19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/25 - train 1.0782 - val 0.7190 - mixup_p 0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/25 - train 1.0570 - val 0.6380 - mixup_p 0.17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/25 - train 1.0871 - val 0.5924 - mixup_p 0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/25 - train 1.0740 - val 0.5683 - mixup_p 0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/25 - train 1.0447 - val 0.5568 - mixup_p 0.13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/25 - train 1.0822 - val 0.5532 - mixup_p 0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/25 - train 1.0629 - val 0.5546 - mixup_p 0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/25 - train 1.0545 - val 0.5596 - mixup_p 0.09\nEarly stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast OOF logloss (partial folds): 0.5273450143491253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fast-TTA scales: [460, 512, 588]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved fast-pivot submission.csv (1023, 121)\n"
          ]
        }
      ]
    },
    {
      "id": "766cc832-660a-4e20-923b-db3903f90ef1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final push: Fix regularization bug, retrain a single fold with custom Cutout, generate standalone and 50/50 blend submissions\n",
        "import os, gc, time, math, json\n",
        "import numpy as np, pandas as pd, torch, torch.nn as nn, albumentations as A, timm, cv2\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import log_loss\n",
        "from timm.data import Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy\n",
        "from timm.utils import ModelEmaV2\n",
        "\n",
        "# Config for single-fold retrain using B4 @512 with aggressive regularization\n",
        "CFG.model_name = 'tf_efficientnet_b4_ns'\n",
        "CFG.img_size = 512\n",
        "CFG.train_bs = 8\n",
        "CFG.valid_bs = 16\n",
        "CFG.epochs = 25\n",
        "CFG.lr = 1e-4\n",
        "CFG.weight_decay = 1e-4\n",
        "CFG.early_stop_patience = 3\n",
        "CFG.mixup_alpha = 0.2\n",
        "CFG.cutmix_alpha = 0.0\n",
        "CFG.mixup_prob = 0.6  # stronger mixup prob\n",
        "CFG.mixup_switch_prob = 0.0\n",
        "CFG.ema_decay = 0.9998\n",
        "CFG.num_workers = 0  # avoid multiprocessing issues with custom transforms\n",
        "\n",
        "# Custom numpy Cutout to avoid albumentations API differences\n",
        "def cutout_np(image, num_holes=8, max_h=64, max_w=64):\n",
        "    h, w = image.shape[:2]\n",
        "    img = image.copy()\n",
        "    for _ in range(num_holes):\n",
        "        ch = np.random.randint(max_h//2, max_h+1)\n",
        "        cw = np.random.randint(max_w//2, max_w+1)\n",
        "        cy = np.random.randint(0, h)\n",
        "        cx = np.random.randint(0, w)\n",
        "        y1 = max(0, cy - ch//2); y2 = min(h, cy + ch//2)\n",
        "        x1 = max(0, cx - cw//2); x2 = min(w, cx + cw//2)\n",
        "        img[y1:y2, x1:x2, :] = 0\n",
        "    return img\n",
        "\n",
        "class CutoutNP(A.ImageOnlyTransform):\n",
        "    def __init__(self, num_holes=8, max_h=64, max_w=64, always_apply=False, p=0.5):\n",
        "        super().__init__(always_apply=always_apply, p=p)\n",
        "        self.num_holes = num_holes\n",
        "        self.max_h = max_h\n",
        "        self.max_w = max_w\n",
        "    def apply(self, image, **params):\n",
        "        return cutout_np(image, self.num_holes, self.max_h, self.max_w)\n",
        "\n",
        "# Albumentations: widened RRC scale + custom Cutout\n",
        "train_tfms = A.Compose([\n",
        "    A.RandomResizedCrop(size=(CFG.img_size, CFG.img_size), scale=(0.6, 1.0), ratio=(0.75, 1.333), p=1.0),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Affine(scale=(0.95, 1.05), translate_percent=(0.0, 0.03), rotate=(-12, 12), shear=(-3, 3), fit_output=False, border_mode=cv2.BORDER_REFLECT_101, p=0.6),\n",
        "    A.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.05, p=0.5),\n",
        "    CutoutNP(num_holes=8, max_h=64, max_w=64, p=0.5),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "valid_tfms = A.Compose([\n",
        "    A.Resize(height=CFG.img_size, width=CFG.img_size),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "def build_model_final(num_classes):\n",
        "    return timm.create_model(CFG.model_name, pretrained=True, num_classes=num_classes)\n",
        "\n",
        "def train_one_fold_final(fold, labels, num_classes):\n",
        "    print(f'\\n=== Final Fix Retrain Fold {fold} ===')\n",
        "    trn_df = labels[labels.fold != fold][['filepath','target']].copy()\n",
        "    val_df = labels[labels.fold == fold][['filepath','target']].copy()\n",
        "    train_ds = DogDataset(trn_df, transforms=train_tfms)\n",
        "    valid_ds = DogDataset(val_df, transforms=valid_tfms)\n",
        "    train_loader = DataLoader(train_ds, batch_size=CFG.train_bs, shuffle=True, num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "\n",
        "    model = build_model_final(num_classes).to(CFG.device)\n",
        "    ema = ModelEmaV2(model, decay=CFG.ema_decay) if CFG.device=='cuda' else None\n",
        "\n",
        "    mixup_base = CFG.mixup_prob if (CFG.mixup_alpha > 0 or CFG.cutmix_alpha > 0) else 0.0\n",
        "    mixup_fn = Mixup(\n",
        "        mixup_alpha=CFG.mixup_alpha, cutmix_alpha=CFG.cutmix_alpha, prob=mixup_base,\n",
        "        switch_prob=CFG.mixup_switch_prob, mode='batch', num_classes=num_classes\n",
        "    ) if mixup_base > 0 else None\n",
        "\n",
        "    criterion_hard = nn.CrossEntropyLoss(label_smoothing=0.1).to(CFG.device)  # add LS as regularizer\n",
        "    criterion_soft = SoftTargetCrossEntropy().to(CFG.device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
        "    warmup_epochs = min(5, max(1, CFG.epochs//6))\n",
        "    cosine_epochs = max(1, CFG.epochs - warmup_epochs)\n",
        "    cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cosine_epochs)\n",
        "    warmup = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.2, total_iters=warmup_epochs)\n",
        "    scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[warmup, cosine], milestones=[warmup_epochs])\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(CFG.device=='cuda'))\n",
        "\n",
        "    best_val = 1e9; best_state = None; no_improve = 0\n",
        "    for epoch in range(1, CFG.epochs+1):\n",
        "        model.train()\n",
        "        # decay mixup but keep a floor of 0.05\n",
        "        if mixup_fn is not None:\n",
        "            frac = (epoch - 1) / max(1, CFG.epochs * 0.9)\n",
        "            decay = max(0.0, 1.0 - min(1.0, frac))\n",
        "            mixup_fn.mixup_prob = max(0.05, mixup_base * decay)\n",
        "\n",
        "        run_loss = 0.0; n = 0\n",
        "        for imgs, targets in train_loader:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            targets = targets.to(CFG.device, non_blocking=True)\n",
        "            if mixup_fn is not None and mixup_fn.mixup_prob > 0:\n",
        "                imgs, targets = mixup_fn(imgs, targets)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "                logits = model(imgs)\n",
        "                loss = criterion_soft(logits, targets) if targets.dtype.is_floating_point else criterion_hard(logits, targets)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            if CFG.grad_clip and CFG.grad_clip>0:\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), CFG.grad_clip)\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            if ema is not None: ema.update(model)\n",
        "            run_loss += loss.item() * imgs.size(0); n += imgs.size(0)\n",
        "        train_loss = run_loss / max(1,n)\n",
        "\n",
        "        # validation with strict CE (no mixup, use EMA)\n",
        "        model.eval(); val_loss=0.0; m=0; val_crit = nn.CrossEntropyLoss().to(CFG.device)\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "            for imgs, targets in valid_loader:\n",
        "                imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                targets = targets.to(CFG.device, non_blocking=True)\n",
        "                logits = (ema.module(imgs) if ema is not None else model(imgs))\n",
        "                l = val_crit(logits, targets)\n",
        "                val_loss += l.item() * imgs.size(0); m += imgs.size(0)\n",
        "        val_loss /= max(1,m); scheduler.step()\n",
        "        print(f'Epoch {epoch}/{CFG.epochs} - train {train_loss:.4f} - val {val_loss:.4f} - mixup_p {mixup_fn.mixup_prob if mixup_fn else 0:.2f}')\n",
        "        if val_loss < best_val - 1e-6:\n",
        "            best_val = val_loss; best_state = (ema.module.state_dict() if ema is not None else model.state_dict()); no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= CFG.early_stop_patience:\n",
        "                print('Early stopping'); break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state, strict=False)\n",
        "    best_path = os.path.join(CFG.out_dir, f'fold{fold}_finalfix_best.pth')\n",
        "    torch.save({'model': model.state_dict()}, best_path)\n",
        "\n",
        "    # OOF logits for this fold\n",
        "    model.eval(); oof_logits = []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "        for imgs, targets in valid_loader:\n",
        "            imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            logits = model(imgs)\n",
        "            oof_logits.append(logits.detach().cpu().float())\n",
        "    oof_logits = torch.cat(oof_logits, dim=0).numpy()\n",
        "\n",
        "    del model, optimizer, scaler\n",
        "    if ema is not None: del ema\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "    return best_path, oof_logits, val_df.index.values, float(best_val)\n",
        "\n",
        "# Prepare data\n",
        "labels_final, ss_final, class_names_final, class2idx_final, idx2class_final = read_data()\n",
        "num_classes_final = len(class_names_final)\n",
        "folds_to_run = [0]\n",
        "\n",
        "# Train a single fold\n",
        "ckpts_final = []; all_oof_logits_final = np.zeros((len(labels_final), num_classes_final), dtype=np.float32); all_val_idx_final = [];\n",
        "best_paths = []; best_vals = []\n",
        "for f in folds_to_run:\n",
        "    p, oof_l, val_idx, best_v = train_one_fold_final(f, labels_final, num_classes_final)\n",
        "    ckpts_final.append(p); best_paths.append(p); best_vals.append(best_v)\n",
        "    all_oof_logits_final[val_idx] = oof_l; all_val_idx_final.extend(val_idx.tolist())\n",
        "\n",
        "if len(all_val_idx_final) > 0:\n",
        "    oof_probs_final = torch.softmax(torch.tensor(all_oof_logits_final[all_val_idx_final]), dim=1).numpy()\n",
        "    print('Final single-fold OOF logloss:', log_loss(labels_final.loc[all_val_idx_final, 'target'].values, oof_probs_final))\n",
        "\n",
        "# Per-fold temperature for the new fold\n",
        "val_idx_f0 = labels_final.index[labels_final.fold == folds_to_run[0]].values\n",
        "y_true_f0 = labels_final.loc[val_idx_f0, 'target'].values\n",
        "logits_f0 = torch.tensor(all_oof_logits_final[val_idx_f0], dtype=torch.float32, device=CFG.device)\n",
        "T = torch.tensor([1.0], dtype=torch.float32, device=CFG.device, requires_grad=True)\n",
        "opt = torch.optim.LBFGS([T], lr=0.1, max_iter=100, line_search_fn='strong_wolfe')\n",
        "def _closure_T():\n",
        "    opt.zero_grad()\n",
        "    scaled = logits_f0 / torch.clamp(T, min=1e-3)\n",
        "    idx = torch.arange(len(y_true_f0), device=CFG.device)\n",
        "    nll = -torch.log_softmax(scaled, dim=1)[idx, torch.tensor(y_true_f0, device=CFG.device)].mean()\n",
        "    nll.backward(); return nll\n",
        "opt.step(_closure_T)\n",
        "T_newfold = float(T.detach().clamp(min=1e-3).cpu().item())\n",
        "print('New fold temperature:', T_newfold)\n",
        "\n",
        "# Inference helpers\n",
        "def make_tta_tfms_final(size, base=CFG.img_size):\n",
        "    return A.Compose([\n",
        "        A.Resize(height=size, width=size),\n",
        "        A.CenterCrop(height=base, width=base, p=1.0) if size > base else A.NoOp(),\n",
        "        A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def predict_test_probs_ckpt(ckpt_path, size_list, hflip=True):\n",
        "    ss_loc = pd.read_csv('sample_submission.csv')\n",
        "    test_df = ss_loc[['id']].copy(); test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "    probs_sum = None\n",
        "    for s in size_list:\n",
        "        ds = DogDataset(test_df[['id','filepath']], transforms=make_tta_tfms_final(s))\n",
        "        dl = DataLoader(ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "        model = timm.create_model(CFG.model_name, pretrained=False, num_classes=num_classes_final).to(CFG.device)\n",
        "        ckpt = torch.load(ckpt_path, map_location=CFG.device)\n",
        "        model.load_state_dict(ckpt['model'], strict=False); model.eval()\n",
        "        outs = []\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "            for imgs, _ids in dl:\n",
        "                imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                logits = model(imgs)\n",
        "                if hflip:\n",
        "                    logits = (logits + model(torch.flip(imgs, dims=[3]))) / 2.0\n",
        "                outs.append(logits.detach().cpu().float())\n",
        "        logits_cat = torch.cat(outs, dim=0)\n",
        "        probs = torch.softmax(logits_cat, dim=1).numpy()\n",
        "        probs_sum = probs if probs_sum is None else (probs_sum + probs)\n",
        "        del model; torch.cuda.empty_cache(); gc.collect()\n",
        "    return probs_sum / len(size_list)\n",
        "\n",
        "# Generate Submission A: standalone new fold with temp scaling\n",
        "scales_final = sorted(list(set([int(CFG.img_size*0.9), CFG.img_size, int(CFG.img_size*1.15)])))\n",
        "print('TTA scales for new fold:', scales_final)\n",
        "new_probs = predict_test_probs_ckpt(ckpts_final[0], scales_final, hflip=CFG.tta_hflip)\n",
        "# temperature-scale the new probs: approximate by scaling logits\n",
        "new_logits_approx = torch.log(torch.tensor(new_probs)).float()\n",
        "new_probs_scaled = torch.softmax(new_logits_approx / T_newfold, dim=1).numpy()\n",
        "subA = pd.DataFrame(np.clip(new_probs_scaled / new_probs_scaled.sum(axis=1, keepdims=True), 1e-9, 1-1e-9), columns=class_names_final)\n",
        "subA.insert(0, 'id', pd.read_csv('sample_submission.csv')['id'])\n",
        "subA.to_csv('submission_new_singlefold.csv', index=False)\n",
        "print('Saved Submission A: submission_new_singlefold.csv', subA.shape)\n",
        "\n",
        "# Generate Submission B: 50/50 blend with best existing 5-fold ensemble (recompute old best using ckpts & per-fold T/weights if available)\n",
        "def compute_old_best_probs():\n",
        "    assert 'ckpts' in globals() and len(ckpts) == CFG.n_folds, 'Need existing 5-fold ckpts from B4 run'\n",
        "    # per-fold temperature\n",
        "    if 'per_fold_T' not in globals():\n",
        "        perT = []\n",
        "        for f in range(CFG.n_folds):\n",
        "            val_idx_f = labels.index[labels.fold == f].values\n",
        "            y_true_f = labels.loc[val_idx_f, 'target'].values\n",
        "            oof_logits_f = torch.tensor(all_oof_logits[val_idx_f], dtype=torch.float32, device=CFG.device)\n",
        "            Tt = torch.tensor([1.0], dtype=torch.float32, device=CFG.device, requires_grad=True)\n",
        "            optT = torch.optim.LBFGS([Tt], lr=0.1, max_iter=100, line_search_fn='strong_wolfe')\n",
        "            def _cl():\n",
        "                optT.zero_grad()\n",
        "                sc = oof_logits_f / torch.clamp(Tt, min=1e-3)\n",
        "                idx = torch.arange(len(y_true_f), device=CFG.device)\n",
        "                nll = -torch.log_softmax(sc, dim=1)[idx, torch.tensor(y_true_f, device=CFG.device)].mean()\n",
        "                nll.backward(); return nll\n",
        "            optT.step(_cl)\n",
        "            perT.append(float(Tt.detach().clamp(min=1e-3).cpu().item()))\n",
        "    else:\n",
        "        perT = per_fold_T\n",
        "    # per-fold weights from temp-scaled OOF\n",
        "    per_loss = []\n",
        "    for f, Tf in enumerate(perT):\n",
        "        val_idx_f = labels.index[labels.fold == f].values\n",
        "        y_true_f = labels.loc[val_idx_f, 'target'].values\n",
        "        oof_logits_f = torch.tensor(all_oof_logits[val_idx_f], dtype=torch.float32, device='cpu')\n",
        "        probs_f = torch.softmax(oof_logits_f / Tf, dim=1).numpy()\n",
        "        per_loss.append(log_loss(y_true_f, probs_f))\n",
        "    per_loss = np.array(per_loss, dtype=np.float64)\n",
        "    weights = np.exp(-per_loss); weights = weights / weights.sum()\n",
        "    # inference per fold with 3-scale TTA\n",
        "    ss_loc = pd.read_csv('sample_submission.csv')\n",
        "    test_df = ss_loc[['id']].copy(); test_df['filepath'] = test_df['id'].apply(lambda x: f'test/{x}.jpg')\n",
        "    def make_tta_tfms_old(size):\n",
        "        return A.Compose([\n",
        "            A.Resize(height=size, width=size),\n",
        "            A.CenterCrop(height=CFG.img_size, width=CFG.img_size, p=1.0) if size > CFG.img_size else A.NoOp(),\n",
        "            A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    def predict_logits_once(ckpt_path, tfms):\n",
        "        ds = DogDataset(test_df[['id','filepath']], transforms=tfms)\n",
        "        dl = DataLoader(ds, batch_size=CFG.valid_bs, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "        model = timm.create_model(CFG.model_name, pretrained=False, num_classes=num_classes_final).to(CFG.device)\n",
        "        ckpt = torch.load(ckpt_path, map_location=CFG.device)\n",
        "        model.load_state_dict(ckpt['model'], strict=False); model.eval()\n",
        "        outs = []\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda', enabled=(CFG.device=='cuda')):\n",
        "            for imgs, _ids in dl:\n",
        "                imgs = imgs.to(CFG.device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                logits = model(imgs)\n",
        "                if CFG.tta and CFG.tta_hflip:\n",
        "                    logits = (logits + model(torch.flip(imgs, dims=[3]))) / 2.0\n",
        "                outs.append(logits.detach().cpu().float())\n",
        "        lg = torch.cat(outs, dim=0); del model; torch.cuda.empty_cache(); gc.collect(); return lg\n",
        "    scales_old = sorted(list(set([int(CFG.img_size*0.9), CFG.img_size, int(CFG.img_size*1.15)])))\n",
        "    probs_weighted = None\n",
        "    for f, (p, Tf) in enumerate(zip(ckpts, perT)):\n",
        "        scale_logits_sum = None\n",
        "        for s in scales_old:\n",
        "            tfms = make_tta_tfms_old(s)\n",
        "            logits = predict_logits_once(p, tfms)\n",
        "            scale_logits_sum = logits if scale_logits_sum is None else (scale_logits_sum + logits)\n",
        "        logits_avg = scale_logits_sum / len(scales_old)\n",
        "        probs_f = torch.softmax(logits_avg / Tf, dim=1).numpy()\n",
        "        probs_weighted = probs_f * weights[f] if probs_weighted is None else (probs_weighted + probs_f * weights[f])\n",
        "    return probs_weighted\n",
        "\n",
        "old_probs = compute_old_best_probs()\n",
        "blend_probs = 0.5 * new_probs_scaled + 0.5 * old_probs\n",
        "blend_probs = np.clip(blend_probs, 1e-9, 1-1e-9)\n",
        "blend_probs = blend_probs / blend_probs.sum(axis=1, keepdims=True)\n",
        "subB = pd.DataFrame(blend_probs, columns=class_names_final)\n",
        "subB.insert(0, 'id', pd.read_csv('sample_submission.csv')['id'])\n",
        "subB.to_csv('submission_blend_new_old.csv', index=False)\n",
        "print('Saved Submission B (blend): submission_blend_new_old.csv', subB.shape)\n",
        "\n",
        "# Default to safer blend for final submission.csv\n",
        "subB.to_csv('submission.csv', index=False)\n",
        "print('submission.csv overwritten with blended submission.')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_298/3172708818.py:43: UserWarning: Argument(s) 'always_apply' are not valid for transform BasicTransform\n  super().__init__(always_apply=always_apply, p=p)\n/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n=== Final Fix Retrain Fold 0 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25 - train 4.1237 - val 4.7378 - mixup_p 0.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/25 - train 2.3990 - val 4.3758 - mixup_p 0.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/25 - train 1.8717 - val 3.8403 - mixup_p 0.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:209: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/25 - train 1.7236 - val 3.2203 - mixup_p 0.52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/25 - train 1.6488 - val 2.5760 - mixup_p 0.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/25 - train 1.5168 - val 1.9766 - mixup_p 0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/25 - train 1.4405 - val 1.4769 - mixup_p 0.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/25 - train 1.4099 - val 1.1050 - mixup_p 0.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/25 - train 1.3858 - val 0.8495 - mixup_p 0.39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/25 - train 1.3155 - val 0.6868 - mixup_p 0.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/25 - train 1.3219 - val 0.5894 - mixup_p 0.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/25 - train 1.2431 - val 0.5297 - mixup_p 0.31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/25 - train 1.2642 - val 0.5013 - mixup_p 0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/25 - train 1.2660 - val 0.4880 - mixup_p 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/25 - train 1.2391 - val 0.4835 - mixup_p 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/25 - train 1.2261 - val 0.4845 - mixup_p 0.20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/25 - train 1.1990 - val 0.4882 - mixup_p 0.17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/25 - train 1.1953 - val 0.4958 - mixup_p 0.15\nEarly stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final single-fold OOF logloss: 0.49576659368712045\nNew fold temperature: 0.7695773243904114\nTTA scales for new fold: [460, 512, 588]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Submission A: submission_new_singlefold.csv (1023, 121)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Submission B (blend): submission_blend_new_old.csv (1023, 121)\nsubmission.csv overwritten with blended submission.\n"
          ]
        }
      ]
    },
    {
      "id": "94e84a6a-f963-498b-ac62-f7bbc2890960",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Overwrite submission.csv with standalone new single-fold submission\n",
        "import shutil, os\n",
        "src = 'submission_new_singlefold.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f\"Source not found: {src}\"\n",
        "shutil.copyfile(src, dst)\n",
        "print('submission.csv replaced with', src)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv replaced with submission_new_singlefold.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}