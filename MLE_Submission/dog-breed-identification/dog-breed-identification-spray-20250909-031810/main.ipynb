{
  "cells": [
    {
      "id": "dd89ecf1-3d7d-42ca-b92f-2fa61acbefb2",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dog Breed Identification \u2014 Medal Plan\n",
        "\n",
        "Goal: Achieve a medal-worthy multi-class log loss on Kaggle's Dog Breed Identification.\n",
        "\n",
        "Strategy:\n",
        "- Use strong pretrained CNN via timm (e.g., convnext_tiny or efficientnetv2_s) with ImageNet weights.\n",
        "- Single-label, 120 classes; optimize CrossEntropy with label smoothing.\n",
        "- Mixed precision training (AMP) for speed; AdamW + cosine schedule with warmup.\n",
        "- Data pipeline: RandomResizedCrop 384, RandAug/ColorJitter, CutMix/MixUp optional; validation: Resize/CenterCrop.\n",
        "- Split: Stratified train/val (e.g., 90/10). Start with 1-fold to get a baseline, then extend to 5-fold if time permits.\n",
        "- Early stopping by val logloss; checkpoint best model.\n",
        "- Inference TTA (e.g., 3-5 flips/resize) to boost robustness.\n",
        "- Ensure submission format matches sample_submission (columns are breeds, rows by test image id, probabilities sum to 1 per row).\n",
        "\n",
        "Milestones:\n",
        "1) Environment setup (install torch/cu121, timm, albumentations, opencv).\n",
        "2) Load labels.csv; build class map and stratified split.\n",
        "3) Dataset/Dataloader with augmentations.\n",
        "4) Baseline model training (frozen backbone head-only warmup 1 epoch, then unfreeze).\n",
        "5) Validate, tune LR/augmentation if needed.\n",
        "6) Full-train best config; TTA inference on test; write submission.csv.\n",
        "\n",
        "Logging/Speed:\n",
        "- Print fold/epoch progress, timings, and interim val logloss.\n",
        "- Use num_workers based on CPU; pin_memory; gradient accumulation if needed.\n",
        "\n",
        "Next: Set up environment and verify GPU, then request expert feedback on model/size and augment/TTAs before long runs."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "9ad67a9c-9bbf-4d6a-9d5c-7cd8f1597dda",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# GPU diagnostic\n",
        "!nvidia-smi || echo 'nvidia-smi failed: GPU not visible to the runtime'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to initialize NVML: Unknown Error\nnvidia-smi failed: GPU not visible to the runtime\n"
          ]
        }
      ]
    },
    {
      "id": "20dad5db-740d-4b96-aae3-cde2ea4f2e1a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment setup and GPU check\n",
        "import sys, subprocess, os, time\n",
        "\n",
        "# Set writable cache dirs BEFORE importing libraries that may download from HF Hub\n",
        "CACHE_ROOT = os.path.join(os.getcwd(), '.model_cache')\n",
        "HF_ROOT = os.path.join(os.getcwd(), 'hf_cache')\n",
        "os.makedirs(CACHE_ROOT, exist_ok=True)\n",
        "os.makedirs(HF_ROOT, exist_ok=True)\n",
        "os.environ['TORCH_HOME'] = CACHE_ROOT\n",
        "os.environ['XDG_CACHE_HOME'] = CACHE_ROOT  # avoid /app/.cache\n",
        "os.environ['HF_HOME'] = HF_ROOT\n",
        "os.environ['HF_HUB_CACHE'] = os.path.join(HF_ROOT, 'hub')\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = os.path.join(HF_ROOT, 'hub')\n",
        "# Reduce CUDA memory fragmentation\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "def pip_install(pkgs):\n",
        "    print(f\"Installing: {' '.join(pkgs)}\", flush=True)\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + pkgs)\n",
        "\n",
        "# Force reinstall PyTorch from official cu121 index\n",
        "print('Reinstalling torch/torchvision from cu121 index (force-reinstall)...', flush=True)\n",
        "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--force-reinstall', '-q',\n",
        "                       'torch==2.4.0', 'torchvision==0.19.0',\n",
        "                       '--index-url', 'https://download.pytorch.org/whl/cu121'])\n",
        "\n",
        "# Ensure timm, albumentations, opencv, sklearn, pandas, numpy\n",
        "pkgs = [\n",
        "    'timm==1.0.9',\n",
        "    'albucore==0.0.11',  # ensure compatibility for albumentations 1.4.x\n",
        "    'albumentations==1.4.8',\n",
        "    'opencv-python-headless==4.10.0.84',\n",
        "    'pandas==2.2.2',\n",
        "    'scikit-learn==1.5.1',\n",
        "    'numpy==1.26.4'\n",
        "]\n",
        "pip_install(pkgs)\n",
        "\n",
        "# Retry import; if albumentations still fails, attempt a fallback pin\n",
        "try:\n",
        "    import torch, torchvision, timm, albumentations as A, cv2, pandas as pd, numpy as np, sklearn\n",
        "except Exception as e:\n",
        "    print('Primary import failed, attempting albumentations fallback pin (1.3.1) ...', e, flush=True)\n",
        "    pip_install(['albumentations==1.3.1'])\n",
        "    import torch, torchvision, timm, albumentations as A, cv2, pandas as pd, numpy as np, sklearn\n",
        "\n",
        "print('Versions:',\n",
        "      f\"torch {torch.__version__}\",\n",
        "      f\"torchvision {torchvision.__version__}\",\n",
        "      f\"timm {timm.__version__}\",\n",
        "      f\"albumentations {A.__version__}\",\n",
        "      f\"cv2 {cv2.__version__}\",\n",
        "      f\"sklearn {sklearn.__version__}\")\n",
        "\n",
        "print('Torch CUDA build:', getattr(torch.version, 'cuda', 'n/a'))\n",
        "print('torch.cuda.is_available():', torch.cuda.is_available())\n",
        "try:\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        for i in range(torch.cuda.device_count()):\n",
        "            print(f'GPU {i}:', torch.cuda.get_device_name(i))\n",
        "    else:\n",
        "        print('No CUDA GPUs detected by PyTorch.')\n",
        "except Exception as e:\n",
        "    print('CUDA query error:', e)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device:', device)\n",
        "if device == 'cuda':\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "else:\n",
        "    print('WARNING: CUDA not available, training will be slow.')\n",
        "\n",
        "# Quick dataset sanity checks\n",
        "import glob\n",
        "train_dir, test_dir = 'train', 'test'\n",
        "train_imgs = glob.glob(os.path.join(train_dir, '*.jpg'))\n",
        "test_imgs = glob.glob(os.path.join(test_dir, '*.jpg'))\n",
        "print(f\"Found {len(train_imgs)} train images, {len(test_imgs)} test images\")\n",
        "labels_path = 'labels.csv'\n",
        "ss_path = 'sample_submission.csv'\n",
        "assert os.path.exists(labels_path), 'labels.csv not found'\n",
        "assert os.path.exists(ss_path), 'sample_submission.csv not found'\n",
        "labels_df = pd.read_csv(labels_path)\n",
        "ss = pd.read_csv(ss_path)\n",
        "print('labels_df shape:', labels_df.shape, 'unique breeds:', labels_df['breed'].nunique())\n",
        "print('sample_submission shape:', ss.shape)\n",
        "print('First 3 breeds in sample_submission:', list(ss.columns[1:4]))\n",
        "print('Setup complete.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinstalling torch/torchvision from cu121 index (force-reinstall)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing: timm==1.0.9 albucore==0.0.11 albumentations==1.4.8 opencv-python-headless==4.10.0.84 pandas==2.2.2 scikit-learn==1.5.1 numpy==1.26.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/timm already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/timm-1.0.9.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/albumentations-1.4.8.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/albumentations already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/albucore-0.0.11.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/albucore already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/huggingface_hub-0.34.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/huggingface_hub already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pandas-2.2.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pandas already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pydantic-2.11.7.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pydantic already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scikit_image-0.25.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/skimage already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scikit_learn.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sklearn already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scikit_learn-1.5.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/imageio-2.37.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/imageio already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/lazy_loader-0.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/lazy_loader already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/cv2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/opencv_python_headless.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/opencv_python_headless-4.10.0.84.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pydantic_core already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pydantic_core-2.33.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/dateutil already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/requests-2.32.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/requests already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy-1.16.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tifffile-2025.8.28.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tifffile already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_inspection-0.4.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_inspection already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/annotated_types-0.7.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/annotated_types already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/certifi-2025.8.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/certifi already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/charset_normalizer-3.4.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/charset_normalizer already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/hf_xet-1.1.9.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/hf_xet already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/idna-3.10.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/idna already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/joblib-1.5.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/joblib already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging-25.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/_yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PyYAML-6.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/safetensors already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/safetensors-0.6.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/six-1.17.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/six.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/threadpoolctl-3.6.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/threadpoolctl.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tomli-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tomli already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/5bae8a57b5ef85818b48__mypyc.cpython-311-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tqdm-4.67.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tqdm already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tzdata-2025.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tzdata already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/urllib3-2.5.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/urllib3 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pytz-2025.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pytz already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:albumentations.check_version:A new version of Albumentations is available: 2.0.8 (you have 1.4.8). Upgrade using: pip install --upgrade albumentations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versions: torch 2.4.0+cu121 torchvision 0.19.0+cu121 timm 1.0.9 albumentations 1.4.8 cv2 4.10.0 sklearn 1.5.1\nTorch CUDA build: 12.1\ntorch.cuda.is_available(): False\nNo CUDA GPUs detected by PyTorch.\nDevice: cpu\nWARNING: CUDA not available, training will be slow.\nFound 9199 train images, 1023 test images\nlabels_df shape: (9199, 2) unique breeds: 120\nsample_submission shape: (1023, 121)\nFirst 3 breeds in sample_submission: ['affenpinscher', 'afghan_hound', 'african_hunting_dog']\nSetup complete.\n"
          ]
        }
      ]
    },
    {
      "id": "23e5ca77-cc2a-4b68-a498-369e4638ea8c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data prep: stratified split, datasets, dataloaders, transforms\n",
        "import os, glob, random, math, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Build class mapping from labels_df and ensure sample_submission order alignment\n",
        "breeds = list(pd.read_csv('sample_submission.csv').columns[1:])\n",
        "breed_to_idx = {b:i for i,b in enumerate(breeds)}\n",
        "num_classes = len(breeds)\n",
        "print('Num classes:', num_classes)\n",
        "\n",
        "# Merge labels with paths and map to indices\n",
        "labels_df = pd.read_csv('labels.csv')\n",
        "labels_df['filepath'] = labels_df['id'].apply(lambda x: os.path.join('train', f'{x}.jpg'))\n",
        "labels_df['label'] = labels_df['breed'].map(breed_to_idx)\n",
        "assert labels_df['label'].notnull().all(), 'Found breeds not in sample_submission columns'\n",
        "\n",
        "# Stratified split 90/10\n",
        "train_df, val_df = train_test_split(labels_df, test_size=0.1, stratify=labels_df['label'], random_state=SEED)\n",
        "print('Train/Val sizes:', len(train_df), len(val_df))\n",
        "\n",
        "# Transforms (CPU\u2011friendly, simple)\n",
        "IMG_SIZE = 224\n",
        "imagenet_mean = (0.485, 0.456, 0.406)\n",
        "imagenet_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "train_tfms = A.Compose([\n",
        "    A.RandomResizedCrop(IMG_SIZE, IMG_SIZE, scale=(0.8, 1.0), ratio=(0.75, 1.33), p=1.0),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_tfms = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.CenterCrop(IMG_SIZE, IMG_SIZE),\n",
        "    A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "class DogDataset(Dataset):\n",
        "    def __init__(self, df, augment, is_train=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.augment = augment\n",
        "        self.is_train = is_train\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = cv2.imread(row.filepath)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(row.filepath)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        aug = self.augment(image=img)\n",
        "        img_t = aug['image']\n",
        "        if self.is_train:\n",
        "            label = int(row.label)\n",
        "            return img_t, label\n",
        "        else:\n",
        "            return img_t, row.id\n",
        "\n",
        "# Datasets\n",
        "ds_train = DogDataset(train_df, train_tfms, is_train=True)\n",
        "ds_val = DogDataset(val_df, val_tfms, is_train=True)\n",
        "\n",
        "# Dataloaders (CPU\u2011safe settings)\n",
        "BATCH_SIZE = 8\n",
        "NUM_WORKERS = 0\n",
        "train_loader = DataLoader(\n",
        "    ds_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=False, drop_last=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    ds_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=False\n",
        ")\n",
        "print('DataLoaders ready:', len(train_loader), 'train batches,', len(val_loader), 'val batches')\n",
        "\n",
        "# Prepare test df and loader\n",
        "test_ids = [os.path.splitext(os.path.basename(p))[0] for p in sorted(glob.glob(os.path.join('test','*.jpg')))]\n",
        "test_df = pd.DataFrame({'id': test_ids})\n",
        "test_df['filepath'] = test_df['id'].apply(lambda x: os.path.join('test', f'{x}.jpg'))\n",
        "ds_test = DogDataset(test_df, val_tfms, is_train=False)\n",
        "test_loader = DataLoader(\n",
        "    ds_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=False\n",
        ")\n",
        "print('Test batches:', len(test_loader))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num classes: 120\nTrain/Val sizes: 8279 920\nDataLoaders ready: 1034 train batches, 115 val batches\nTest batches: 128\n"
          ]
        }
      ]
    },
    {
      "id": "0b5f5354-9fcc-4416-9b76-a0915bfc7530",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Model, training loop with AMP, Mixup, EMA, early stopping\n",
        "import math, time, os, sys, importlib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from timm.utils import ModelEmaV2\n",
        "from timm.data.mixup import Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy, LabelSmoothingCrossEntropy\n",
        "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
        "\n",
        "# Ensure cache dirs are writable for any downloads\n",
        "CACHE_ROOT = os.path.join(os.getcwd(), '.model_cache')\n",
        "os.makedirs(CACHE_ROOT, exist_ok=True)\n",
        "os.environ['TORCH_HOME'] = CACHE_ROOT\n",
        "os.environ['XDG_CACHE_HOME'] = CACHE_ROOT\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Create torchvision model (avoid HF Hub read-only cache issue)\n",
        "weights = EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
        "model = efficientnet_v2_s(weights=weights)\n",
        "in_features = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "model = model.to(device)\n",
        "model = model.to(memory_format=torch.channels_last)\n",
        "\n",
        "# Mixup/CutMix\n",
        "mixup_fn = Mixup(mixup_alpha=0.2, cutmix_alpha=1.0, cutmix_minmax=None, prob=1.0, switch_prob=0.5, mode='batch', label_smoothing=0.0, num_classes=num_classes)\n",
        "use_mixup = True\n",
        "criterion = SoftTargetCrossEntropy() if use_mixup else LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "\n",
        "# Optimizer with weight decay exclusions (by parameter shape/name to avoid tensor comparisons)\n",
        "lr = 5e-4\n",
        "weight_decay = 0.01\n",
        "decay, no_decay = [], []\n",
        "for name, p in model.named_parameters():\n",
        "    if not p.requires_grad:\n",
        "        continue\n",
        "    if p.ndim == 1 or name.endswith('.bias'):\n",
        "        no_decay.append(p)\n",
        "    else:\n",
        "        decay.append(p)\n",
        "param_groups = [\n",
        "    {'params': decay, 'weight_decay': weight_decay},\n",
        "    {'params': no_decay, 'weight_decay': 0.0},\n",
        "]\n",
        "optimizer = torch.optim.AdamW(param_groups, lr=lr, betas=(0.9, 0.999))\n",
        "\n",
        "# Scheduler (cosine after warmup handled manually per-epoch at loop start)\n",
        "epochs = 20\n",
        "warmup_epochs = 2\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs - warmup_epochs, eta_min=1e-6)\n",
        "\n",
        "# EMA (keep EMA on same device as model to avoid dtype/device mismatches)\n",
        "ema_decay = 0.9996\n",
        "model_ema = ModelEmaV2(model, decay=ema_decay)  # no explicit device arg\n",
        "# ensure EMA module is on same device and memory format\n",
        "if getattr(model_ema, 'module', None) is not None:\n",
        "    model_ema.module.to(device)\n",
        "    model_ema.module.to(memory_format=torch.channels_last)\n",
        "\n",
        "# Grad scaler for AMP\n",
        "scaler = GradScaler(enabled=True)\n",
        "\n",
        "# Train utils\n",
        "def train_one_epoch(epoch, freeze_backbone=False, accum_steps=4):\n",
        "    model.train()\n",
        "    if freeze_backbone:\n",
        "        for n,p in model.named_parameters():\n",
        "            if 'classifier' in n:\n",
        "                p.requires_grad = True\n",
        "            else:\n",
        "                p.requires_grad = False\n",
        "    else:\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = True\n",
        "    running_loss = 0.0\n",
        "    n_samples = 0\n",
        "    start = time.time()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    for i, (images, targets) in enumerate(train_loader):\n",
        "        images = images.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "        if use_mixup:\n",
        "            images, targets = mixup_fn(images, targets)\n",
        "        with autocast(enabled=True):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets) / accum_steps\n",
        "        scaler.scale(loss).backward()\n",
        "        if (i + 1) % accum_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            if model_ema is not None:\n",
        "                model_ema.update(model)\n",
        "        running_loss += loss.item() * accum_steps * images.size(0)\n",
        "        n_samples += images.size(0)\n",
        "        if (i+1) % 50 == 0:\n",
        "            elapsed = time.time() - start\n",
        "            print(f\"Epoch {epoch} [{i+1}/{len(train_loader)}] loss={running_loss/max(n_samples,1):.4f} time={elapsed:.1f}s\", flush=True)\n",
        "    return running_loss / max(n_samples,1)\n",
        "\n",
        "def _get_ema_module():\n",
        "    return getattr(model_ema, 'module', None)\n",
        "\n",
        "def evaluate(use_ema=False):\n",
        "    model_to_eval = _get_ema_module() if (use_ema and model_ema is not None) else model\n",
        "    # ensure EMA is on the correct device for eval\n",
        "    if use_ema and model_to_eval is not None and device.type == 'cuda':\n",
        "        model_to_eval.to(device)\n",
        "        model_to_eval.to(memory_format=torch.channels_last)\n",
        "    model_to_eval.eval()\n",
        "    total_loss = 0.0\n",
        "    n_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for images, targets in val_loader:\n",
        "            images = images.to(device, non_blocking=True, memory_format=torch.channels_last).float()\n",
        "            targets = targets.to(device, non_blocking=True)\n",
        "            outputs = model_to_eval(images)\n",
        "            loss = F.cross_entropy(outputs, targets)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            n_samples += images.size(0)\n",
        "    return total_loss / max(n_samples,1)\n",
        "\n",
        "# Training loop with early stopping\n",
        "best_loss = float('inf')\n",
        "best_ema_loss = float('inf')\n",
        "patience = 4\n",
        "no_improve = 0\n",
        "save_dir = 'checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "print('Starting training...', flush=True)\n",
        "t0 = time.time()\n",
        "for epoch in range(epochs):\n",
        "    # Set LR at the BEGINNING of epoch (manual linear warmup across warmup_epochs)\n",
        "    if epoch < warmup_epochs:\n",
        "        warm_factor = (epoch + 1) / max(1, warmup_epochs)\n",
        "        for pg in optimizer.param_groups:\n",
        "            pg['lr'] = lr * warm_factor\n",
        "    else:\n",
        "        # keep scheduler-managed LR for cosine phase\n",
        "        pass\n",
        "\n",
        "    freeze = (epoch == 0)  # head-only warmup for first epoch\n",
        "    train_loss = train_one_epoch(epoch, freeze_backbone=freeze, accum_steps=4)\n",
        "    val_loss = evaluate(use_ema=False)\n",
        "    val_loss_ema = evaluate(use_ema=True)\n",
        "    cur_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f} val_loss={val_loss:.5f} val_loss_ema={val_loss_ema:.5f} lr={cur_lr:.6f} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    improved = False\n",
        "    if val_loss < best_loss - 1e-5:\n",
        "        best_loss = val_loss\n",
        "        torch.save({'model': model.state_dict(), 'epoch': epoch, 'val_loss': best_loss}, os.path.join(save_dir, 'best.pth'))\n",
        "        improved = True\n",
        "    if val_loss_ema < best_ema_loss - 1e-5:\n",
        "        best_ema_loss = val_loss_ema\n",
        "        ema_module = _get_ema_module()\n",
        "        if ema_module is not None:\n",
        "            cpu_state = {k: v.cpu() for k, v in ema_module.state_dict().items()}\n",
        "            torch.save({'model': cpu_state, 'epoch': epoch, 'val_loss': best_ema_loss}, os.path.join(save_dir, 'best_ema.pth'))\n",
        "        improved = True\n",
        "    if not improved:\n",
        "        no_improve += 1\n",
        "    else:\n",
        "        no_improve = 0\n",
        "    # Step cosine scheduler AFTER warmup epochs\n",
        "    if epoch >= warmup_epochs:\n",
        "        scheduler.step()\n",
        "    if no_improve >= patience:\n",
        "        print('Early stopping triggered.', flush=True)\n",
        "        break\n",
        "print('Training complete. Best val loss:', best_loss, 'Best EMA val loss:', best_ema_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "bd711c11-68c9-4ff9-a367-a9b40a1a4297",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference: load best checkpoint from timm convnext_tiny run, TTA (orig + hflip), temperature scaling, create submission.csv\n",
        "import os, numpy as np, pandas as pd, torch, torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_logits_tta(model, loader, device, use_hflip=True):\n",
        "    model.eval()\n",
        "    all_logits, all_ids = [], []\n",
        "    for batch in loader:\n",
        "        if len(batch) == 2 and isinstance(batch[1], torch.Tensor):\n",
        "            images, _ = batch\n",
        "            ids = None\n",
        "        else:\n",
        "            images, ids = batch\n",
        "        images = images.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "        logits = model(images)\n",
        "        if use_hflip:\n",
        "            logits_flip = model(images.flip(-1))\n",
        "            logits = 0.5 * (logits + logits_flip)\n",
        "        all_logits.append(logits.float().cpu())\n",
        "        if ids is not None:\n",
        "            all_ids.extend(list(ids))\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    return all_logits, all_ids\n",
        "\n",
        "def build_model(num_classes):\n",
        "    m = timm.create_model('convnext_tiny', pretrained=False, num_classes=num_classes, drop_path_rate=0.2)\n",
        "    return m\n",
        "\n",
        "def load_ckpt(model, ckpt_path):\n",
        "    ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=True)\n",
        "    state = ckpt.get('model', ckpt)\n",
        "    model.load_state_dict(state, strict=True)\n",
        "    return model\n",
        "\n",
        "def nll_from_logits(logits, targets):\n",
        "    return F.cross_entropy(logits, targets).item()\n",
        "\n",
        "def find_best_temperature(val_logits, val_targets, t_min=0.5, t_max=2.0, steps=31):\n",
        "    ts = np.linspace(t_min, t_max, steps)\n",
        "    best_t, best_loss = 1.0, float('inf')\n",
        "    for t in ts:\n",
        "        loss = nll_from_logits(val_logits / t, val_targets)\n",
        "        if loss < best_loss:\n",
        "            best_loss, best_t = loss, float(t)\n",
        "    return best_t, best_loss\n",
        "\n",
        "def run_inference_and_save(use_ema=False):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = build_model(num_classes)\n",
        "    ckpt_name = 'best_ema.pth' if use_ema else 'best.pth'        \n",
        "    model = load_ckpt(model, os.path.join('checkpoints', ckpt_name))\n",
        "    model = model.to(device)\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "\n",
        "    # Validation logits and temperature scaling\n",
        "    val_targets = []\n",
        "    for _, t in val_loader:\n",
        "        val_targets.append(t)\n",
        "    val_targets = torch.cat(val_targets, dim=0).to('cpu')\n",
        "    val_logits, _ = predict_logits_tta(model, val_loader, device, use_hflip=True)\n",
        "    T_opt, _ = find_best_temperature(val_logits, val_targets, 0.5, 2.0, 31)\n",
        "    print(f'Optimal temperature T={T_opt:.3f}')\n",
        "\n",
        "    # Test logits with same TTA\n",
        "    test_logits, test_ids = predict_logits_tta(model, test_loader, device, use_hflip=True)\n",
        "    probs = F.softmax(test_logits / T_opt, dim=1).numpy()\n",
        "\n",
        "    # Build submission in sample_submission order\n",
        "    sub = pd.DataFrame(probs, columns=breeds)\n",
        "    sub.insert(0, 'id', test_ids)\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv with shape', sub.shape)\n",
        "\n",
        "# To run after training completes: run_inference_and_save(use_ema=True or False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "id": "19cd4231-bd56-4682-bb63-e7cc667358e5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Execute inference with automatic EMA selection based on stored val_loss\n",
        "import os, torch\n",
        "\n",
        "def choose_use_ema():\n",
        "    best_path = os.path.join('checkpoints', 'best.pth')\n",
        "    best_ema_path = os.path.join('checkpoints', 'best_ema.pth')\n",
        "    use_ema = False\n",
        "    if os.path.exists(best_path) and os.path.exists(best_ema_path):\n",
        "        try:\n",
        "            b = torch.load(best_path, map_location='cpu', weights_only=True)\n",
        "            be = torch.load(best_ema_path, map_state_dict=None, map_location='cpu', weights_only=True) if False else torch.load(best_ema_path, map_location='cpu', weights_only=True)\n",
        "            b_loss = float(b.get('val_loss', float('inf')))\n",
        "            be_loss = float(be.get('val_loss', float('inf')))\n",
        "            use_ema = be_loss < b_loss\n",
        "            print(f\"Choosing {'EMA' if use_ema else 'non-EMA'} checkpoint (val_loss: best={b_loss:.5f}, best_ema={be_loss:.5f})\")\n",
        "        except Exception as e:\n",
        "            print('Failed to compare checkpoints, defaulting to non-EMA:', e)\n",
        "            use_ema = False\n",
        "    elif os.path.exists(best_ema_path):\n",
        "        print('Only best_ema.pth found, using EMA.')\n",
        "        use_ema = True\n",
        "    else:\n",
        "        print('Using non-EMA best.pth (either EMA missing or non-EMA better).')\n",
        "        use_ema = False\n",
        "    return use_ema\n",
        "\n",
        "use_ema = choose_use_ema()\n",
        "run_inference_and_save(use_ema=use_ema)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_25410/2588856939.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  b = torch.load(best_path, map_location='cpu')\n/tmp/ipykernel_25410/2588856939.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  be = torch.load(best_ema_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choosing EMA checkpoint (val_loss: best=0.84325, best_ema=0.69830)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_25410/4097048782.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal temperature T=1.200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv with shape (1023, 121)\n"
          ]
        }
      ]
    },
    {
      "id": "febfed0d-3f00-4453-aaf4-e77a876a7ecb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# New strong training run: timm convnext_tiny.in22k_ft_in1k + fixed EMA + per-step warmup + grad clip\n",
        "import os, time, math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler\n",
        "from torch.amp import autocast\n",
        "\n",
        "# Minor perf boost on T4\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "# Writable caches (must set before any hub downloads)\n",
        "os.environ['HF_HOME'] = os.path.join(os.getcwd(), 'hf_cache')\n",
        "os.environ['HF_HUB_CACHE'] = os.path.join(os.getcwd(), 'hf_cache', 'hub')\n",
        "os.environ['TORCH_HOME'] = os.path.join(os.getcwd(), '.model_cache')\n",
        "os.makedirs(os.environ['HF_HOME'], exist_ok=True)\n",
        "os.makedirs(os.environ['TORCH_HOME'], exist_ok=True)\n",
        "\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from timm.data.mixup import Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy, LabelSmoothingCrossEntropy\n",
        "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Try to minimize fragmentation\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Model (memory-efficient backbone) \n",
        "model = timm.create_model(\n",
        "    'convnext_tiny',  # use default IM1K pretrained to avoid invalid tag issues\n",
        "    pretrained=True,\n",
        "    num_classes=num_classes,\n",
        "    drop_path_rate=0.2\n",
        ")\n",
        "if hasattr(model, 'set_grad_checkpointing'):\n",
        "    model.set_grad_checkpointing(True)\n",
        "model = model.to(device)\n",
        "model = model.to(memory_format=torch.channels_last)\n",
        "\n",
        "# MixUp/CutMix setup\n",
        "mixup_fn = Mixup(mixup_alpha=0.2, cutmix_alpha=1.0, prob=1.0, switch_prob=0.5, mode='batch', label_smoothing=0.0, num_classes=num_classes)\n",
        "use_mixup = True\n",
        "criterion_soft = SoftTargetCrossEntropy()\n",
        "criterion_ls = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "\n",
        "# Optimizer with wd exclusions\n",
        "lr = 5e-4\n",
        "weight_decay = 0.01\n",
        "decay, no_decay = [], []\n",
        "for n, p in model.named_parameters():\n",
        "    if not p.requires_grad:\n",
        "        continue\n",
        "    if p.ndim == 1 or n.endswith('.bias'):\n",
        "        no_decay.append(p)\n",
        "    else:\n",
        "        decay.append(p)\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': decay, 'weight_decay': weight_decay},\n",
        "    {'params': no_decay, 'weight_decay': 0.0},\n",
        "], lr=lr, betas=(0.9, 0.999))\n",
        "\n",
        "# EMA (manual BN buffer sync workaround)\n",
        "ema_decay = 0.9996\n",
        "model_ema = ModelEmaV2(model, decay=ema_decay)\n",
        "if getattr(model_ema, 'module', None) is not None:\n",
        "    model_ema.module.to(device)\n",
        "    model_ema.module.to(memory_format=torch.channels_last)\n",
        "\n",
        "def sync_bn_buffers(ema_module: torch.nn.Module, src_module: torch.nn.Module):\n",
        "    ema_state = ema_module.state_dict()\n",
        "    src_state = src_module.state_dict()\n",
        "    for k, v in src_state.items():\n",
        "        if ('running_mean' in k) or ('running_var' in k) or ('num_batches_tracked' in k):\n",
        "            if k in ema_state and ema_state[k].shape == v.shape:\n",
        "                ema_state[k] = v.detach().clone()\n",
        "    ema_module.load_state_dict(ema_state, strict=True)\n",
        "\n",
        "# Scheduler: per-step warmup then cosine\n",
        "epochs = 25\n",
        "accum_steps = 8\n",
        "warmup_steps = 500\n",
        "total_steps = (len(train_loader) // accum_steps) * epochs\n",
        "warmup_lr = LinearLR(optimizer, start_factor=0.1, total_iters=warmup_steps)\n",
        "cosine_lr = CosineAnnealingLR(optimizer, T_max=max(1, total_steps - warmup_steps), eta_min=1e-6)\n",
        "scheduler = SequentialLR(optimizer, schedulers=[warmup_lr, cosine_lr], milestones=[warmup_steps])\n",
        "\n",
        "scaler = GradScaler(enabled=True)\n",
        "\n",
        "def evaluate_model(eval_model):\n",
        "    eval_model.eval()\n",
        "    total_loss, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, targets in val_loader:\n",
        "            images = images.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "            targets = targets.to(device, non_blocking=True)\n",
        "            with autocast('cuda', enabled=True):\n",
        "                outputs = eval_model(images)\n",
        "                loss = F.cross_entropy(outputs, targets)\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            n += images.size(0)\n",
        "    return total_loss / max(n, 1)\n",
        "\n",
        "save_dir = 'checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "best_loss = float('inf')\n",
        "best_ema_loss = float('inf')\n",
        "patience = 6\n",
        "no_improve = 0\n",
        "\n",
        "print('Starting strong run (timm convnext_tiny @320px)...', flush=True)\n",
        "t0 = time.time()\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss, seen = 0.0, 0\n",
        "    start = time.time()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    # Disable MixUp in the final 3 epochs, switch to label smoothing\n",
        "    use_mixup = (epoch < epochs - 3)\n",
        "\n",
        "    for it, (images, targets) in enumerate(train_loader):\n",
        "        images = images.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "        if use_mixup:\n",
        "            images, targets = mixup_fn(images, targets)\n",
        "        with autocast('cuda', enabled=True):\n",
        "            outputs = model(images)\n",
        "            loss = (criterion_soft(outputs, targets) if use_mixup else criterion_ls(outputs, targets))\n",
        "            loss = loss / accum_steps\n",
        "        scaler.scale(loss).backward()\n",
        "        if (it + 1) % accum_steps == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            if model_ema is not None:\n",
        "                model_ema.update(model)\n",
        "                sync_bn_buffers(model_ema.module, model)\n",
        "            scheduler.step()\n",
        "        running_loss += loss.item() * accum_steps * images.size(0)\n",
        "        seen += images.size(0)\n",
        "        if (it + 1) % 50 == 0:\n",
        "            print(f\"Epoch {epoch} [{it+1}/{len(train_loader)}] loss={running_loss/max(seen,1):.4f} time={time.time()-start:.1f}s\", flush=True)\n",
        "\n",
        "    # Validation\n",
        "    val_loss = evaluate_model(model)\n",
        "    ema_module = getattr(model_ema, 'module', None)\n",
        "    if ema_module is not None:\n",
        "        ema_module.to(device)\n",
        "        ema_module.to(memory_format=torch.channels_last)\n",
        "        val_loss_ema = evaluate_model(ema_module)\n",
        "    else:\n",
        "        val_loss_ema = float('inf')\n",
        "\n",
        "    cur_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Epoch {epoch}: train_loss={running_loss/max(seen,1):.4f} val={val_loss:.5f} val_ema={val_loss_ema:.5f} lr={cur_lr:.6f} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "\n",
        "    improved = False\n",
        "    if val_loss < best_loss - 1e-6:\n",
        "        best_loss = val_loss\n",
        "        torch.save({'model': model.state_dict(), 'epoch': epoch, 'val_loss': best_loss}, os.path.join(save_dir, 'best.pth'))\n",
        "        improved = True\n",
        "    if val_loss_ema < best_ema_loss - 1e-6:\n",
        "        best_ema_loss = val_loss_ema\n",
        "        if ema_module is not None:\n",
        "            cpu_state = {k: v.cpu() for k, v in ema_module.state_dict().items()}\n",
        "            torch.save({'model': cpu_state, 'epoch': epoch, 'val_loss': best_ema_loss}, os.path.join(save_dir, 'best_ema.pth'))\n",
        "        improved = True\n",
        "    if not improved:\n",
        "        no_improve += 1\n",
        "    else:\n",
        "        no_improve = 0\n",
        "    if no_improve >= patience:\n",
        "        print('Early stopping.', flush=True)\n",
        "        break\n",
        "\n",
        "print('Strong run complete. Best val:', best_loss, 'Best EMA val:', best_ema_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "4a00d826-992a-4498-97bb-955e8e0a4a54",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 5-Fold CV setup (splits, transforms, dataloaders) for medal push\n",
        "import os, math, random, glob, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Config for strong runs\n",
        "CFG = {\n",
        "    'model_name': 'convnext_small.in12k_ft_in1k',\n",
        "    'img_size': 384,\n",
        "    'epochs': 25,\n",
        "    'patience': 6,\n",
        "    'batch_size': 4,          # physical BS\n",
        "    'accum_steps': 8,         # effective BS ~32\n",
        "    'num_workers': min(8, os.cpu_count() or 4),\n",
        "    'lr': 2e-4,\n",
        "    'weight_decay': 0.05,\n",
        "    'ema_decay': 0.9996,\n",
        "    'mixup_alpha': 0.1,\n",
        "    'cutmix_alpha': 0.5,\n",
        "    'disable_mixup_last': 5,  # epochs\n",
        "}\n",
        "\n",
        "# Reuse global breeds/labels if present\n",
        "breeds = list(pd.read_csv('sample_submission.csv').columns[1:])\n",
        "breed_to_idx = {b:i for i,b in enumerate(breeds)}\n",
        "num_classes = len(breeds)\n",
        "labels_df = pd.read_csv('labels.csv')\n",
        "labels_df['filepath'] = labels_df['id'].apply(lambda x: os.path.join('train', f'{x}.jpg'))\n",
        "labels_df['label'] = labels_df['breed'].map(breed_to_idx)\n",
        "assert labels_df['label'].notnull().all()\n",
        "\n",
        "# Build 5 folds\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "folds = []\n",
        "for fold, (trn_idx, val_idx) in enumerate(skf.split(labels_df['id'].values, labels_df['label'].values)):\n",
        "    trn_df = labels_df.iloc[trn_idx].reset_index(drop=True)\n",
        "    val_df = labels_df.iloc[val_idx].reset_index(drop=True)\n",
        "    folds.append((trn_df, val_df))\n",
        "    os.makedirs('folds', exist_ok=True)\n",
        "    trn_df[['id','breed','filepath','label']].to_csv(f'folds/train_fold{fold}.csv', index=False)\n",
        "    val_df[['id','breed','filepath','label']].to_csv(f'folds/val_fold{fold}.csv', index=False)\n",
        "print('Created 5-fold splits. Fold sizes:')\n",
        "for i,(trn,val) in enumerate(folds):\n",
        "    print(f'  Fold {i}: train={len(trn)} val={len(val)}')\n",
        "\n",
        "# Transforms (robust, albumentations-only due to version quirks)\n",
        "IM = CFG['img_size']\n",
        "imagenet_mean = (0.485, 0.456, 0.406)\n",
        "imagenet_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_train_tfms():\n",
        "    return A.Compose([\n",
        "        A.RandomResizedCrop(IM, IM, scale=(0.8, 1.0), ratio=(0.75, 1.33), p=1.0),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.OneOf([\n",
        "            A.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.15, hue=0.05, p=1.0),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=1.0),\n",
        "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=1.0),\n",
        "            A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=1.0),\n",
        "            A.Blur(blur_limit=3, p=1.0),\n",
        "            A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
        "            A.Sharpen(alpha=(0.1, 0.2), lightness=(0.8, 1.2), p=1.0),\n",
        "        ], p=0.9),\n",
        "        A.CoarseDropout(max_holes=1, max_height=int(0.12*IM), max_width=int(0.12*IM), min_holes=1, fill_value=0, p=0.5),\n",
        "        A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_val_tfms():\n",
        "    return A.Compose([\n",
        "        A.Resize(IM, IM),\n",
        "        A.CenterCrop(IM, IM),\n",
        "        A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "class DogDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, augment, is_train=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.augment = augment\n",
        "        self.is_train = is_train\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = cv2.imread(row.filepath)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(row.filepath)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.augment(image=img)['image']\n",
        "        if self.is_train:\n",
        "            return img, int(row.label)\n",
        "        else:\n",
        "            return img, row.id\n",
        "\n",
        "def make_loaders_for_fold(fold_idx):\n",
        "    trn_df, val_df = folds[fold_idx]\n",
        "    ds_tr = DogDataset(trn_df, get_train_tfms(), is_train=True)\n",
        "    ds_va = DogDataset(val_df, get_val_tfms(), is_train=True)\n",
        "    num_workers = CFG['num_workers']\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        ds_tr, batch_size=CFG['batch_size'], shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=True,\n",
        "        persistent_workers=True if num_workers > 0 else False, prefetch_factor=2 if num_workers > 0 else None\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        ds_va, batch_size=CFG['batch_size'], shuffle=False, num_workers=num_workers, pin_memory=True,\n",
        "        persistent_workers=True if num_workers > 0 else False, prefetch_factor=2 if num_workers > 0 else None\n",
        "    )\n",
        "    return train_loader, val_loader, trn_df, val_df\n",
        "\n",
        "print('CV setup complete. Use make_loaders_for_fold(k) to get loaders for fold k. Next: implement per-fold training loop with EMA and save OOF logits.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "d8a5a7a2-5cff-468d-98d7-f86a6a606da3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 5-fold training loop with EMA, OOF saving, and ensemble inference utilities\n",
        "import os, time, math, gc, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from timm.data.mixup import Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy, LabelSmoothingCrossEntropy\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.set_float32_matmul_precision('high')\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "os.makedirs('checkpoints', exist_ok=True)\n",
        "os.makedirs('oof', exist_ok=True)\n",
        "\n",
        "def build_model(num_classes):\n",
        "    # drop_path_rate tuned to 0.25 as per expert advice\n",
        "    m = timm.create_model(CFG['model_name'], pretrained=True, num_classes=num_classes, drop_path_rate=0.25)\n",
        "    if hasattr(m, 'set_grad_checkpointing'):\n",
        "        m.set_grad_checkpointing(True)\n",
        "    m.to(device)\n",
        "    m.to(memory_format=torch.channels_last)\n",
        "    return m\n",
        "\n",
        "def get_optim(model):\n",
        "    decay, no_decay = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad: continue\n",
        "        if p.ndim == 1 or n.endswith('.bias'): no_decay.append(p)\n",
        "        else: decay.append(p)\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': decay, 'weight_decay': CFG['weight_decay']},\n",
        "        {'params': no_decay, 'weight_decay': 0.0},\n",
        "    ], lr=CFG['lr'], betas=(0.9, 0.999))\n",
        "    return optimizer\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, targets in loader:\n",
        "            images = images.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "            targets = targets.to(device, non_blocking=True)\n",
        "            with autocast(enabled=True):\n",
        "                logits = model(images)\n",
        "                loss = F.cross_entropy(logits, targets)\n",
        "            total += loss.item() * images.size(0)\n",
        "            n += images.size(0)\n",
        "    return total / max(n, 1)\n",
        "\n",
        "def collect_logits(model, loader):\n",
        "    model.eval()\n",
        "    all_logits, all_targets = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, targets in loader:\n",
        "            images = images.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "            with autocast(enabled=True):\n",
        "                logits = model(images)\n",
        "            all_logits.append(logits.float().cpu())\n",
        "            all_targets.append(targets.cpu())\n",
        "    return torch.cat(all_logits, 0), torch.cat(all_targets, 0)\n",
        "\n",
        "def train_one_fold(fold_idx):\n",
        "    print(f'===== Fold {fold_idx} training start =====', flush=True)\n",
        "    train_loader, val_loader, trn_df, val_df = make_loaders_for_fold(fold_idx)\n",
        "    model = build_model(num_classes)\n",
        "    optimizer = get_optim(model)\n",
        "    scaler = GradScaler(enabled=True)\n",
        "    model_ema = ModelEmaV2(model, decay=CFG['ema_decay'])\n",
        "    model_ema.module.to(device); model_ema.module.to(memory_format=torch.channels_last)\n",
        "    # Keep some identity samples via prob=0.8\n",
        "    mixup_fn = Mixup(mixup_alpha=CFG['mixup_alpha'], cutmix_alpha=CFG['cutmix_alpha'], prob=0.8, switch_prob=0.5, mode='batch', label_smoothing=0.0, num_classes=num_classes)\n",
        "    crit_soft = SoftTargetCrossEntropy()\n",
        "    crit_ls = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "\n",
        "    accum = CFG['accum_steps']\n",
        "\n",
        "    # --- Start of refined scheduler/EMA block ---\n",
        "    steps_per_epoch = len(train_loader)\n",
        "    update_steps_per_epoch = max(1, steps_per_epoch // CFG['accum_steps'])\n",
        "    total_updates = update_steps_per_epoch * CFG['epochs']\n",
        "\n",
        "    # LR: guarded linear warmup then cosine to 0.01x base LR\n",
        "    min_lr = CFG['lr'] * 0.01\n",
        "    warmup_updates = min(400, max(update_steps_per_epoch, int(0.3 * total_updates)))\n",
        "    def get_lr_update(u_step):\n",
        "        if u_step < warmup_updates:\n",
        "            return CFG['lr'] * (u_step + 1) / max(1, warmup_updates)\n",
        "        t = (u_step - warmup_updates) / max(1, (total_updates - warmup_updates))\n",
        "        return min_lr + (CFG['lr'] - min_lr) * 0.5 * (1 + math.cos(math.pi * t))\n",
        "\n",
        "    # EMA: adaptive decay warmup\n",
        "    ema_warmup_updates = min(800, int(0.3 * total_updates))\n",
        "    ema_decay_start = 0.99\n",
        "    ema_decay_target = CFG['ema_decay']\n",
        "    def get_ema_decay_update(u_step):\n",
        "        if u_step >= ema_warmup_updates:\n",
        "            return ema_decay_target\n",
        "        frac = u_step / max(1, ema_warmup_updates)\n",
        "        return float(ema_decay_start + (ema_decay_target - ema_decay_start) * frac)\n",
        "    # --- End of refined scheduler/EMA block ---\n",
        "\n",
        "    best, best_ema, no_improve = 1e9, 1e9, 0\n",
        "    global_iter = 0           # counts dataloader iterations\n",
        "    update_step = 0           # counts optimizer updates\n",
        "\n",
        "    for epoch in range(CFG['epochs']):\n",
        "        model.train()\n",
        "        running, seen = 0.0, 0\n",
        "        t0 = time.time()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        use_mix = (epoch < (CFG['epochs'] - CFG['disable_mixup_last']))\n",
        "        for it, (images, targets) in enumerate(train_loader):\n",
        "            images = images.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "            targets = targets.to(device, non_blocking=True)\n",
        "            if use_mix:\n",
        "                images, targets = mixup_fn(images, targets)\n",
        "            with autocast(enabled=True):\n",
        "                logits = model(images)\n",
        "                loss = (crit_soft(logits, targets) if use_mix else crit_ls(logits, targets)) / accum\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (it + 1) % accum == 0:\n",
        "                # Apply LR & EMA based on optimizer update steps\n",
        "                lr_now = get_lr_update(update_step)\n",
        "                for pg in optimizer.param_groups: pg['lr'] = lr_now\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                model_ema.decay = get_ema_decay_update(update_step)\n",
        "                model_ema.update(model)\n",
        "                # CRITICAL: sync BN buffers for EMA to avoid stale statistics\n",
        "                model_ema.update_buffers(model)\n",
        "                update_step += 1\n",
        "\n",
        "            running += loss.item() * accum * images.size(0)\n",
        "            seen += images.size(0)\n",
        "            global_iter += 1\n",
        "            if (it + 1) % 100 == 0:\n",
        "                cur_lr = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Fold {fold_idx} Epoch {epoch} [{it+1}/{len(train_loader)}] loss={running/max(seen,1):.4f} lr={cur_lr:.6f} upd={update_step} time={time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "        val = evaluate(model, val_loader)\n",
        "        model_ema.module.to(device); model_ema.module.to(memory_format=torch.channels_last)\n",
        "        val_ema = evaluate(model_ema.module, val_loader)\n",
        "        cur_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f\"Fold {fold_idx} Epoch {epoch}: train_loss={running/max(seen,1):.4f} val={val:.5f} val_ema={val_ema:.5f} lr={cur_lr:.6f}\", flush=True)\n",
        "\n",
        "        improved = False\n",
        "        ckpt_dir = f'checkpoints/fold{fold_idx}'\n",
        "        os.makedirs(ckpt_dir, exist_ok=True)\n",
        "        if val < best - 1e-6:\n",
        "            best = val; improved = True\n",
        "            torch.save({'model': model.state_dict(), 'val_loss': best, 'epoch': epoch}, os.path.join(ckpt_dir, 'best.pth'))\n",
        "        if val_ema < best_ema - 1e-6:\n",
        "            best_ema = val_ema; improved = True\n",
        "            cpu_state = {k: v.detach().cpu() for k, v in model_ema.module.state_dict().items()}\n",
        "            torch.save({'model': cpu_state, 'val_loss': best_ema, 'epoch': epoch}, os.path.join(ckpt_dir, 'best_ema.pth'))\n",
        "        if not improved:\n",
        "            no_improve += 1\n",
        "        else:\n",
        "            no_improve = 0\n",
        "        if no_improve >= CFG['patience']:\n",
        "            print(f'Fold {fold_idx}: early stopping.', flush=True)\n",
        "            break\n",
        "        gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "    # Save OOF logits (EMA)\n",
        "    print(f'Fold {fold_idx}: generating OOF logits for validation set...', flush=True)\n",
        "    # Build EMA model with pretrained=False to avoid redundant downloads/VRAM spikes\n",
        "    ema_model = timm.create_model(CFG['model_name'], pretrained=False, num_classes=num_classes, drop_path_rate=0.25)\n",
        "    if hasattr(ema_model, 'set_grad_checkpointing'):\n",
        "        ema_model.set_grad_checkpointing(True)\n",
        "    ema_ckpt = torch.load(os.path.join(f'checkpoints/fold{fold_idx}', 'best_ema.pth'), map_location='cpu', weights_only=True)\n",
        "    state = ema_ckpt.get('model', ema_ckpt)\n",
        "    ema_model.load_state_dict(state, strict=True)\n",
        "    ema_model.to(device); ema_model.to(memory_format=torch.channels_last)\n",
        "    val_loader = make_loaders_for_fold(fold_idx)[1]\n",
        "    oof_logits, oof_tgts = collect_logits(ema_model, val_loader)\n",
        "    np.savez_compressed(f'oof/fold{fold_idx}_oof.npz', logits=oof_logits.numpy(), targets=oof_tgts.numpy(), idx=val_df.index.values)\n",
        "    del ema_model; gc.collect(); torch.cuda.empty_cache()\n",
        "    print(f'===== Fold {fold_idx} done. Best val={best:.5f} best_ema={best_ema:.5f} =====', flush=True)\n",
        "\n",
        "def nll_from_logits_np(logits, targets):\n",
        "    logits_t = torch.from_numpy(logits)\n",
        "    targets_t = torch.from_numpy(targets).long()\n",
        "    return F.cross_entropy(logits_t, targets_t).item()\n",
        "\n",
        "def fit_global_temperature_from_oof():\n",
        "    # Load all OOF logits\n",
        "    all_logits, all_targets = [], []\n",
        "    for k in range(5):\n",
        "        path = f'oof/fold{k}_oof.npz'\n",
        "        if not os.path.exists(path):\n",
        "            continue\n",
        "        d = np.load(path)\n",
        "        all_logits.append(d['logits'])\n",
        "        all_targets.append(d['targets'])\n",
        "    if len(all_logits) == 0:\n",
        "        print('WARNING: No OOF files found. Defaulting temperature T=1.0', flush=True)\n",
        "        return 1.0\n",
        "    logits = np.concatenate(all_logits, 0)\n",
        "    targets = np.concatenate(all_targets, 0)\n",
        "    Ts = np.linspace(0.5, 2.5, 41)\n",
        "    best_T, best_loss = 1.0, 1e9\n",
        "    for T in Ts:\n",
        "        loss = nll_from_logits_np(logits / T, targets)\n",
        "        if loss < best_loss:\n",
        "            best_loss, best_T = loss, float(T)\n",
        "    print(f'Fitted global temperature T={best_T:.3f} on OOF (CE={best_loss:.5f})')\n",
        "    return best_T\n",
        "\n",
        "def fit_bias_vector_from_oof(T=1.0):\n",
        "    # Vector scaling: fit per-class bias b on OOF to minimize CE of logits/T + b\n",
        "    all_logits, all_targets = [], []\n",
        "    for k in range(5):\n",
        "        path = f'oof/fold{k}_oof.npz'\n",
        "        if not os.path.exists(path):\n",
        "            continue\n",
        "        d = np.load(path)\n",
        "        all_logits.append(d['logits'])\n",
        "        all_targets.append(d['targets'])\n",
        "    if len(all_logits) == 0:\n",
        "        print('WARNING: No OOF files for bias fit. Using zero bias.', flush=True)\n",
        "        return torch.zeros((num_classes,), dtype=torch.float32)\n",
        "    logits = torch.from_numpy(np.concatenate(all_logits, 0)).float() / float(T)\n",
        "    targets = torch.from_numpy(np.concatenate(all_targets, 0)).long()\n",
        "    b = torch.zeros((num_classes,), dtype=torch.float32, requires_grad=True)\n",
        "    optimizer = torch.optim.LBFGS([b], max_iter=100, tolerance_grad=1e-7, tolerance_change=1e-9, line_search_fn='strong_wolfe')\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "        loss = F.cross_entropy(logits + b.unsqueeze(0), targets)\n",
        "        loss.backward()\n",
        "        return loss\n",
        "    loss0 = F.cross_entropy(logits, targets).item()\n",
        "    optimizer.step(closure)\n",
        "    with torch.no_grad():\n",
        "        loss1 = F.cross_entropy(logits + b.unsqueeze(0), targets).item()\n",
        "    print(f'Bias vector fit on OOF: CE before={loss0:.5f} after={loss1:.5f}')\n",
        "    return b.detach()\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_logits_tta(model, loader, use_hflip=True):\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "    for images, _ in loader:\n",
        "        images = images.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "        with autocast(enabled=True):\n",
        "            logits = model(images)\n",
        "            if use_hflip:\n",
        "                logits = 0.5 * (logits + model(images.flip(-1)))\n",
        "        all_logits.append(logits.float().cpu())\n",
        "    return torch.cat(all_logits, 0)\n",
        "\n",
        "def build_scaled_loader(size):\n",
        "    tfm = A.Compose([\n",
        "        A.Resize(size, size),\n",
        "        A.CenterCrop(size, size),\n",
        "        A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "    import glob as _glob, os as _os, cv2\n",
        "    class TestDS(torch.utils.data.Dataset):\n",
        "        def __init__(self, ids): self.ids = ids\n",
        "        def __len__(self): return len(self.ids)\n",
        "        def __getitem__(self, i):\n",
        "            pid = self.ids[i]\n",
        "            img = cv2.imread(_os.path.join('test', f'{pid}.jpg'))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = tfm(image=img)['image']\n",
        "            return img, pid\n",
        "    test_ids = [os.path.splitext(os.path.basename(p))[0] for p in sorted(_glob.glob(os.path.join('test','*.jpg')))]\n",
        "    ds = TestDS(test_ids)\n",
        "    # Use a larger, fixed batch size for fast inference; set num_workers=0 to prevent hang\n",
        "    loader = torch.utils.data.DataLoader(ds, batch_size=32, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    return loader, test_ids\n",
        "\n",
        "def infer_ensemble_and_save():\n",
        "    sizes = [CFG['img_size'], CFG['img_size'] + 32]\n",
        "    fold_ckpts = [f'checkpoints/fold{k}/best_ema.pth' for k in range(5) if os.path.exists(f'checkpoints/fold{k}/best_ema.pth')]\n",
        "    if len(fold_ckpts) < 2:\n",
        "        print(f'WARNING: Only {len(fold_ckpts)} fold checkpoints found. Proceeding anyway.', flush=True)\n",
        "    if len(fold_ckpts) == 0:\n",
        "        print('ERROR: No fold checkpoints found. Aborting ensemble inference.', flush=True)\n",
        "        return\n",
        "    # Fit temperature on OOF\n",
        "    T = fit_global_temperature_from_oof()\n",
        "    # Also fit per-class bias on OOF (vector scaling) using logits/T\n",
        "    b = fit_bias_vector_from_oof(T=T)\n",
        "    # Prepare loaders per size\n",
        "    loaders = [build_scaled_loader(s)[0] for s in sizes]\n",
        "    # Accumulate logits across folds and TTAs\n",
        "    fold_logits = None\n",
        "    for fi, ck in enumerate(fold_ckpts):\n",
        "        print(f'Loading fold checkpoint: {ck}', flush=True)\n",
        "        model = build_model(num_classes)\n",
        "        ckpt = torch.load(ck, map_location='cpu', weights_only=True)\n",
        "        state = ckpt.get('model', ckpt)\n",
        "        model.load_state_dict(state, strict=True)\n",
        "        model.to(device); model.to(memory_format=torch.channels_last)\n",
        "        logits_sum = None\n",
        "        for ld in loaders:\n",
        "            lg = predict_logits_tta(model, ld, use_hflip=True)\n",
        "            logits_sum = lg if logits_sum is None else logits_sum + lg\n",
        "        logits_avg = logits_sum / len(loaders)\n",
        "        fold_logits = logits_avg if fold_logits is None else fold_logits + logits_avg\n",
        "        del model; gc.collect(); torch.cuda.empty_cache()\n",
        "    fold_logits = fold_logits / len(fold_ckpts)\n",
        "    # Apply temperature and per-class bias before softmax\n",
        "    probs = F.softmax(fold_logits / float(T) + b.unsqueeze(0), dim=1).numpy()\n",
        "    # Build submission\n",
        "    _, test_ids = build_scaled_loader(CFG['img_size'])\n",
        "    sub = pd.DataFrame(probs, columns=breeds)\n",
        "    sub.insert(0, 'id', test_ids)\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (ensemble) with shape', sub.shape)\n",
        "\n",
        "print('Utilities ready: call train_one_fold(k) for k in 0..4, then infer_ensemble_and_save() to create submission.')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilities ready: call train_one_fold(k) for k in 0..4, then infer_ensemble_and_save() to create submission.\n"
          ]
        }
      ]
    },
    {
      "id": "e41e7ff6-fac3-4ab5-bc96-aa16250c0391",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Kick off sanity fold training (reduce epochs for speed) \n",
        "import time\n",
        "start_ts = time.time()\n",
        "CFG['epochs'] = 18\n",
        "CFG['patience'] = 4\n",
        "print('Starting train_one_fold(0) with CFG:', CFG)\n",
        "train_one_fold(0)\n",
        "print(f'Fold 0 training finished in {(time.time()-start_ts)/60:.2f} min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c5ad0e8e-7d0d-4edb-99a4-d89ba100f541",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Override CFG and loaders without re-running cell 7; use saved CSV folds\n",
        "import os, time, math, glob, cv2, torch, pandas as pd, numpy as np, random\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "\n",
        "# Stability: prevent OpenCV thread contention\n",
        "cv2.setNumThreads(0)\n",
        "\n",
        "CFG = {\n",
        "    'model_name': 'convnext_small.in12k_ft_in1k',\n",
        "    'img_size': 384,\n",
        "    'epochs': 25,\n",
        "    'patience': 6,\n",
        "    'batch_size': 4,\n",
        "    'accum_steps': 8,\n",
        "    'num_workers': 4,\n",
        "    'lr': 2e-4,\n",
        "    'weight_decay': 0.05,\n",
        "    'ema_decay': 0.9996,\n",
        "    'mixup_alpha': 0.1,\n",
        "    'cutmix_alpha': 0.5,\n",
        "    'disable_mixup_last': 5,\n",
        "}\n",
        "\n",
        "# Rebuild breeds mapping\n",
        "breeds = list(pd.read_csv('sample_submission.csv').columns[1:])\n",
        "breed_to_idx = {b:i for i,b in enumerate(breeds)}\n",
        "num_classes = len(breeds)\n",
        "\n",
        "# Transforms\n",
        "IM = CFG['img_size']\n",
        "imagenet_mean = (0.485, 0.456, 0.406)\n",
        "imagenet_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_train_tfms():\n",
        "    return A.Compose([\n",
        "        A.RandomResizedCrop(IM, IM, scale=(0.8, 1.0), ratio=(0.75, 1.33), p=1.0),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.OneOf([\n",
        "            A.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.15, hue=0.05, p=1.0),\n",
        "            A.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=1.0),\n",
        "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=1.0),\n",
        "            A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=1.0),\n",
        "            A.Blur(blur_limit=3, p=1.0),\n",
        "            A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
        "            A.Sharpen(alpha=(0.1, 0.2), lightness=(0.8, 1.2), p=1.0),\n",
        "        ], p=0.9),\n",
        "        A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.1, rotate_limit=10, p=0.3),\n",
        "        A.CoarseDropout(max_holes=1, max_height=int(0.12*IM), max_width=int(0.12*IM), min_holes=1, fill_value=0, p=0.5),\n",
        "        A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_val_tfms():\n",
        "    return A.Compose([\n",
        "        A.Resize(IM, IM),\n",
        "        A.CenterCrop(IM, IM),\n",
        "        A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "class DogDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, augment, is_train=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.augment = augment\n",
        "        self.is_train = is_train\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = cv2.imread(row.filepath)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(row.filepath)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.augment(image=img)['image']\n",
        "        if self.is_train:\n",
        "            return img, int(row.label)\n",
        "        else:\n",
        "            return img, row.id\n",
        "\n",
        "def seed_worker(worker_id: int):\n",
        "    base_seed = SEED + worker_id\n",
        "    np.random.seed(base_seed)\n",
        "    random.seed(base_seed)\n",
        "    torch.manual_seed(base_seed)\n",
        "    return None\n",
        "\n",
        "def make_loaders_for_fold(fold_idx):\n",
        "    trn_df = pd.read_csv(f'folds/train_fold{fold_idx}.csv')\n",
        "    val_df = pd.read_csv(f'folds/val_fold{fold_idx}.csv')\n",
        "    ds_tr = DogDataset(trn_df, get_train_tfms(), is_train=True)\n",
        "    ds_va = DogDataset(val_df, get_val_tfms(), is_train=True)\n",
        "    num_workers = CFG['num_workers']\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        ds_tr, batch_size=CFG['batch_size'], shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=True,\n",
        "        persistent_workers=True if num_workers > 0 else False, prefetch_factor=2 if num_workers > 0 else None,\n",
        "        worker_init_fn=seed_worker\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        ds_va, batch_size=CFG['batch_size'], shuffle=False, num_workers=num_workers, pin_memory=True,\n",
        "        persistent_workers=True if num_workers > 0 else False, prefetch_factor=2 if num_workers > 0 else None,\n",
        "        worker_init_fn=seed_worker\n",
        "    )\n",
        "    return train_loader, val_loader, trn_df, val_df\n",
        "\n",
        "print('CFG and loaders set via CSV folds. Ready to call train_one_fold(0).')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CFG and loaders set via CSV folds. Ready to call train_one_fold(0).\n"
          ]
        }
      ]
    },
    {
      "id": "c2c10bc6-91aa-455c-b8fc-477922c8afc5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CPU-only ensemble inference: convnext_tiny (existing ckpts) + convnext_small fold0 (if present), extra scales\n",
        "import os, time, numpy as np, pandas as pd, torch, torch.nn.functional as F\n",
        "import timm\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import albumentations as A\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def build_model(name, num_classes):\n",
        "    return timm.create_model(name, pretrained=False, num_classes=num_classes)\n",
        "\n",
        "def load_ckpt(model, ckpt_path):\n",
        "    ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=True)\n",
        "    state = ckpt.get('model', ckpt)\n",
        "    model.load_state_dict(state, strict=True)\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_logits_tta(model, loader, use_hflip=True):\n",
        "    model.eval()\n",
        "    outs = []\n",
        "    for batch in loader:\n",
        "        if len(batch) == 2 and isinstance(batch[1], torch.Tensor):\n",
        "            images, _ = batch\n",
        "        else:\n",
        "            images, _ids = batch\n",
        "        images = images.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "        logits = model(images)\n",
        "        if use_hflip:\n",
        "            logits = 0.5 * (logits + model(images.flip(-1)))\n",
        "        outs.append(logits.float().cpu())\n",
        "    return torch.cat(outs, 0)\n",
        "\n",
        "def build_scaled_test_loader(size):\n",
        "    tfm = A.Compose([\n",
        "        A.Resize(size, size),\n",
        "        A.CenterCrop(size, size),\n",
        "        A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    import glob, cv2\n",
        "    class TestDS(Dataset):\n",
        "        def __init__(self, ids):\n",
        "            self.ids = ids\n",
        "        def __len__(self):\n",
        "            return len(self.ids)\n",
        "        def __getitem__(self, i):\n",
        "            pid = self.ids[i]\n",
        "            img = cv2.imread(os.path.join('test', f'{pid}.jpg'))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = tfm(image=img)['image']\n",
        "            return img, pid\n",
        "    test_ids = [os.path.splitext(os.path.basename(p))[0] for p in sorted(glob.glob(os.path.join('test','*.jpg')))]\n",
        "    ds = TestDS(test_ids)\n",
        "    ld = torch.utils.data.DataLoader(ds, batch_size=max(2, 8), shuffle=False, num_workers=0, pin_memory=False)\n",
        "    return ld, test_ids\n",
        "\n",
        "def nll_from_logits(logits, targets):\n",
        "    return F.cross_entropy(logits, targets).item()\n",
        "\n",
        "def find_best_temperature(val_logits, val_targets, t_min=0.5, t_max=2.0, steps=31):\n",
        "    ts = np.linspace(t_min, t_max, steps)\n",
        "    best_t, best_loss = 1.0, float('inf')\n",
        "    for t in ts:\n",
        "        loss = nll_from_logits(val_logits / t, val_targets)\n",
        "        if loss < best_loss:\n",
        "            best_loss, best_t = loss, float(t)\n",
        "    return best_t, best_loss\n",
        "\n",
        "print('Starting CPU ensemble inference...', flush=True)\n",
        "# Build models conditionally (include EMA and non-EMA if both exist)\n",
        "models = []\n",
        "names = []\n",
        "\n",
        "# convnext_tiny checkpoints\n",
        "if os.path.exists('checkpoints/best_ema.pth'):\n",
        "    m = build_model('convnext_tiny', num_classes)\n",
        "    m = load_ckpt(m, 'checkpoints/best_ema.pth').to(device).to(memory_format=torch.channels_last)\n",
        "    models.append(m); names.append('tiny_ema'); print('Loaded convnext_tiny EMA')\n",
        "if os.path.exists('checkpoints/best.pth'):\n",
        "    m = build_model('convnext_tiny', num_classes)\n",
        "    m = load_ckpt(m, 'checkpoints/best.pth').to(device).to(memory_format=torch.channels_last)\n",
        "    models.append(m); names.append('tiny'); print('Loaded convnext_tiny non-EMA')\n",
        "\n",
        "# convnext_small fold0 checkpoints\n",
        "if os.path.exists('checkpoints/fold0/best_ema.pth'):\n",
        "    m = build_model('convnext_small.in12k_ft_in1k', num_classes)\n",
        "    m = load_ckpt(m, 'checkpoints/fold0/best_ema.pth').to(device).to(memory_format=torch.channels_last)\n",
        "    models.append(m); names.append('small_f0_ema'); print('Loaded convnext_small fold0 EMA')\n",
        "if os.path.exists('checkpoints/fold0/best.pth'):\n",
        "    m = build_model('convnext_small.in12k_ft_in1k', num_classes)\n",
        "    m = load_ckpt(m, 'checkpoints/fold0/best.pth').to(device).to(memory_format=torch.channels_last)\n",
        "    models.append(m); names.append('small_f0'); print('Loaded convnext_small fold0 non-EMA')\n",
        "\n",
        "assert len(models) > 0, 'No checkpoints found to run ensemble inference.'\n",
        "\n",
        "# Fit temperature on current val split using ensemble of models\n",
        "with torch.no_grad():\n",
        "    val_logits_list = []\n",
        "    for m in models:\n",
        "        lg = predict_logits_tta(m, val_loader, use_hflip=True)\n",
        "        val_logits_list.append(lg)\n",
        "    val_logits_ens = torch.stack(val_logits_list, 0).mean(0)\n",
        "    val_targets = torch.cat([t for _, t in val_loader], 0).long()\n",
        "T_opt, ce = find_best_temperature(val_logits_ens, val_targets, 0.5, 2.0, 41)\n",
        "print(f'Fitted temperature T={T_opt:.3f} (CE={ce:.5f}) on current val split)')\n",
        "\n",
        "# Test inference at multiple scales, then average across models and scales\n",
        "sizes = [224, 256, 288, 320]\n",
        "test_logits_accum = None\n",
        "for sz in sizes:\n",
        "    ld, test_ids = build_scaled_test_loader(sz)\n",
        "    logits_models = []\n",
        "    for m in models:\n",
        "        lg = predict_logits_tta(m, ld, use_hflip=True)\n",
        "        logits_models.append(lg)\n",
        "    logits_scale_avg = torch.stack(logits_models, 0).mean(0)\n",
        "    test_logits_accum = logits_scale_avg if test_logits_accum is None else (test_logits_accum + logits_scale_avg)\n",
        "test_logits_avg = test_logits_accum / len(sizes)\n",
        "probs = F.softmax(test_logits_avg / T_opt, dim=1).numpy()\n",
        "\n",
        "# Build and save submission\n",
        "sub = pd.DataFrame(probs, columns=breeds)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (CPU ensemble) with shape', sub.shape, 'from models:', names, 'scales:', sizes)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "id": "1918a12f-d4d8-4058-a034-ba0a85d2cf9f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CPU-only optimized inference: 2 EMA models (tiny + small_f0), 2 scales, per-model temp + blend weight optimization\n",
        "import os, numpy as np, pandas as pd, torch, torch.nn.functional as F\n",
        "import timm, scipy.optimize as opt\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def build_model(name, num_classes):\n",
        "    return timm.create_model(name, pretrained=False, num_classes=num_classes)\n",
        "\n",
        "def load_ckpt(model, path):\n",
        "    ckpt = torch.load(path, map_location='cpu', weights_only=True)\n",
        "    state = ckpt.get('model', ckpt)\n",
        "    model.load_state_dict(state, strict=True)\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_logits_tta(model, loader, use_hflip=True):\n",
        "    model.eval()\n",
        "    outs = []\n",
        "    for batch in loader:\n",
        "        if len(batch) == 2 and isinstance(batch[1], torch.Tensor):\n",
        "            images, _ = batch\n",
        "        else:\n",
        "            images, _ids = batch\n",
        "        images = images.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "        logits = model(images)\n",
        "        if use_hflip:\n",
        "            logits = 0.5 * (logits + model(images.flip(-1)))\n",
        "        outs.append(logits.float().cpu())\n",
        "    return torch.cat(outs, 0)\n",
        "\n",
        "def build_test_loader(size, batch_size=48):\n",
        "    tfm = A.Compose([A.Resize(size, size), A.CenterCrop(size, size), A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)), ToTensorV2()])\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    import glob, cv2\n",
        "    class TestDS(Dataset):\n",
        "        def __init__(self, ids): self.ids = ids\n",
        "        def __len__(self): return len(self.ids)\n",
        "        def __getitem__(self, i):\n",
        "            pid = self.ids[i]\n",
        "            img = cv2.imread(os.path.join('test', f'{pid}.jpg'))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = tfm(image=img)['image']\n",
        "            return img, pid\n",
        "    test_ids = [os.path.splitext(os.path.basename(p))[0] for p in sorted(glob.glob(os.path.join('test','*.jpg')))]\n",
        "    ds = TestDS(test_ids)\n",
        "    ld = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    return ld, test_ids\n",
        "\n",
        "def ce_from_logits(logits, targets):\n",
        "    return F.cross_entropy(logits, targets).item()\n",
        "\n",
        "def grid_search_temperature(val_logits, val_targets, t_min=0.5, t_max=2.0, steps=41):\n",
        "    ts = np.linspace(t_min, t_max, steps)\n",
        "    best_t, best_loss = 1.0, 1e9\n",
        "    for t in ts:\n",
        "        loss = ce_from_logits(val_logits / t, val_targets)\n",
        "        if loss < best_loss:\n",
        "            best_loss, best_t = loss, float(t)\n",
        "    return best_t, best_loss\n",
        "\n",
        "print('Optimized CPU inference: loading EMA models...', flush=True)\n",
        "paths = {\n",
        "    'tiny_ema': 'checkpoints/best_ema.pth',\n",
        "    'small_f0_ema': 'checkpoints/fold0/best_ema.pth'\n",
        "}\n",
        "avail = {k: os.path.exists(v) for k,v in paths.items()}\n",
        "assert any(avail.values()), 'No EMA checkpoints found'\n",
        "\n",
        "models = []\n",
        "names = []\n",
        "if avail.get('tiny_ema'):\n",
        "    m = build_model('convnext_tiny', num_classes)\n",
        "    m = load_ckpt(m, paths['tiny_ema']).to(device).to(memory_format=torch.channels_last)\n",
        "    models.append(m); names.append('tiny_ema')\n",
        "if avail.get('small_f0_ema'):\n",
        "    m = build_model('convnext_small.in12k_ft_in1k', num_classes)\n",
        "    m = load_ckpt(m, paths['small_f0_ema']).to(device).to(memory_format=torch.channels_last)\n",
        "    models.append(m); names.append('small_f0_ema')\n",
        "print('Loaded:', names)\n",
        "\n",
        "# 1) Compute val logits per model (reuse existing val_loader from Cell 3) and fit per-model temperatures\n",
        "val_targets = torch.cat([t for _, t in val_loader], 0).long()\n",
        "val_logits_list, Ts = [], []\n",
        "for m in models:\n",
        "    lg = predict_logits_tta(m, val_loader, use_hflip=True)\n",
        "    t_opt, _ = grid_search_temperature(lg, val_targets, 0.5, 2.0, 41)\n",
        "    val_logits_list.append(lg); Ts.append(t_opt)\n",
        "print('Per-model temperatures:', dict(zip(names, Ts)))\n",
        "\n",
        "# 2) Optimize blend weight w in [0,1] to minimize CE on val\n",
        "def val_loss_for_w(w):\n",
        "    w = float(w)\n",
        "    blend = w * (val_logits_list[0] / Ts[0])\n",
        "    if len(val_logits_list) > 1:\n",
        "        blend = blend + (1.0 - w) * (val_logits_list[1] / Ts[1])\n",
        "    return ce_from_logits(blend, val_targets)\n",
        "if len(val_logits_list) == 1:\n",
        "    w_opt = 1.0\n",
        "else:\n",
        "    res = opt.minimize_scalar(lambda x: val_loss_for_w(x), bounds=(0.0, 1.0), method='bounded', options={'xatol':1e-3, 'maxiter':100})\n",
        "    w_opt = float(res.x)\n",
        "print('Optimized blend weight w:', w_opt)\n",
        "\n",
        "# 3) Test inference at three scales (224,256,288) with hflip; batch_size=48 for speed\n",
        "sizes = [224, 256, 288]\n",
        "test_logits_accum = None\n",
        "for sz in sizes:\n",
        "    ld, test_ids = build_test_loader(sz, batch_size=48)\n",
        "    # per-model logits with their calibrated temps\n",
        "    per_model = []\n",
        "    for mi, m in enumerate(models):\n",
        "        lg = predict_logits_tta(m, ld, use_hflip=True) / Ts[mi]\n",
        "        per_model.append(lg)\n",
        "    # blend with w_opt\n",
        "    if len(per_model) == 1:\n",
        "        blended = per_model[0]\n",
        "    else:\n",
        "        blended = w_opt * per_model[0] + (1.0 - w_opt) * per_model[1]\n",
        "    test_logits_accum = blended if test_logits_accum is None else (test_logits_accum + blended)\n",
        "test_logits_avg = test_logits_accum / len(sizes)\n",
        "probs = F.softmax(test_logits_avg, dim=1).numpy()\n",
        "\n",
        "sub = pd.DataFrame(probs, columns=breeds)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (CPU optimized blend) with shape', sub.shape, 'models:', names, 'scales:', sizes, 'w:', w_opt)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "id": "93cfc45e-e116-4f2a-9f77-7f788c95330e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CPU feature extraction + logistic regression, then blend with current submission\n",
        "import os, glob, numpy as np, pandas as pd, torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm, cv2, albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "import scipy.optimize as opt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class ImageDS(Dataset):\n",
        "    def __init__(self, df, tfm):\n",
        "        self.df = df.reset_index(drop=True); self.tfm = tfm\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        img = cv2.imread(r.filepath); img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        t = self.tfm(image=img)['image']\n",
        "        return t, int(r.label) if 'label' in r else r.id\n",
        "\n",
        "def build_feature_model(name):\n",
        "    # num_classes=0 returns global pooled features\n",
        "    m = timm.create_model(name, pretrained=True, num_classes=0)\n",
        "    m.eval(); m.to(device); m.to(memory_format=torch.channels_last)\n",
        "    return m\n",
        "\n",
        "def make_tfm(sz):\n",
        "    return A.Compose([A.Resize(sz, sz), A.CenterCrop(sz, sz), A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)), ToTensorV2()])\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_feats(model, loader):\n",
        "    feats, ys_or_ids = [], []\n",
        "    for batch in loader:\n",
        "        imgs, meta = batch\n",
        "        imgs = imgs.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "        f = model(imgs).float().cpu().numpy()\n",
        "        feats.append(f)\n",
        "        if isinstance(meta, torch.Tensor):\n",
        "            ys_or_ids.extend(meta.cpu().numpy().tolist())\n",
        "        else:\n",
        "            ys_or_ids.extend(list(meta))\n",
        "    return np.concatenate(feats, 0), ys_or_ids\n",
        "\n",
        "# Use convnext_tiny features at two sizes for speed\n",
        "model_name = 'convnext_tiny'\n",
        "sizes = [224, 256]\n",
        "BATCH = 32\n",
        "\n",
        "# Full train df for features\n",
        "labels_df_all = pd.read_csv('labels.csv')\n",
        "labels_df_all['filepath'] = labels_df_all['id'].apply(lambda x: os.path.join('train', f'{x}.jpg'))\n",
        "labels_df_all['label'] = labels_df_all['breed'].map(breed_to_idx)\n",
        "\n",
        "# Validation split from Cell 3 already exists: val_df\n",
        "train_only_df = labels_df_all[~labels_df_all['id'].isin(val_df['id'])].reset_index(drop=True)\n",
        "\n",
        "feat_list_tr, y_list_tr = [], []\n",
        "feat_list_va, y_list_va = [], []\n",
        "for sz in sizes:\n",
        "    tfm = make_tfm(sz)\n",
        "    ds_tr = ImageDS(train_only_df, tfm); ld_tr = DataLoader(ds_tr, batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    ds_va = ImageDS(val_df, tfm); ld_va = DataLoader(ds_va, batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    m = build_feature_model(model_name)\n",
        "    f_tr, y_tr = extract_feats(m, ld_tr); f_va, y_va = extract_feats(m, ld_va)\n",
        "    feat_list_tr.append(f_tr); feat_list_va.append(f_va)\n",
        "    y_list_tr = y_tr; y_list_va = y_va\n",
        "    del m; torch.cuda.empty_cache()\n",
        "\n",
        "X_tr = np.concatenate(feat_list_tr, axis=1)\n",
        "X_va = np.concatenate(feat_list_va, axis=1)\n",
        "y_tr = np.array(y_list_tr, dtype=int)\n",
        "y_va = np.array(y_list_va, dtype=int)\n",
        "print('Feature shapes:', X_tr.shape, X_va.shape)\n",
        "\n",
        "# Train multinomial logistic regression\n",
        "lr_clf = LogisticRegression(max_iter=200, n_jobs=-1, verbose=0, penalty='l2', solver='saga', multi_class='multinomial', C=1.0)\n",
        "lr_clf.fit(X_tr, y_tr)\n",
        "probs_va_lr = lr_clf.predict_proba(X_va)\n",
        "print('Val CE (LR only):', log_loss(y_va, probs_va_lr, labels=list(range(num_classes))))\n",
        "\n",
        "# Build test features\n",
        "test_ids = [os.path.splitext(os.path.basename(p))[0] for p in sorted(glob.glob(os.path.join('test','*.jpg')))]\n",
        "test_df_all = pd.DataFrame({'id': test_ids})\n",
        "test_df_all['filepath'] = test_df_all['id'].apply(lambda x: os.path.join('test', f'{x}.jpg'))\n",
        "\n",
        "feat_list_te = []\n",
        "for sz in sizes:\n",
        "    tfm = make_tfm(sz)\n",
        "    class TestDS(Dataset):\n",
        "        def __init__(self, df, tfm): self.df=df.reset_index(drop=True); self.tfm=tfm\n",
        "        def __len__(self): return len(self.df)\n",
        "        def __getitem__(self, i):\n",
        "            r = self.df.iloc[i]\n",
        "            img = cv2.imread(r.filepath); img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            t = self.tfm(image=img)['image']\n",
        "            return t, r.id\n",
        "    ld_te = DataLoader(TestDS(test_df_all, tfm), batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    m = build_feature_model(model_name)\n",
        "    f_te, _ids = extract_feats(m, ld_te)\n",
        "    feat_list_te.append(f_te)\n",
        "    del m; torch.cuda.empty_cache()\n",
        "X_te = np.concatenate(feat_list_te, axis=1)\n",
        "probs_te_lr = lr_clf.predict_proba(X_te)\n",
        "\n",
        "# Load current submission (from optimized blend) and corresponding val probs to optimize blend\n",
        "base_sub = pd.read_csv('submission.csv')\n",
        "assert base_sub.shape[1] == 121, 'submission.csv format mismatch'\n",
        "base_cols = list(base_sub.columns[1:])\n",
        "assert base_cols == breeds, 'breed columns mismatch'\n",
        "\n",
        "# Recompute base model val probs using Cell 13 models for a fair blend on validation\n",
        "from copy import deepcopy\n",
        "paths = {\n",
        "    'tiny_ema': 'checkpoints/best_ema.pth',\n",
        "    'small_f0_ema': 'checkpoints/fold0/best_ema.pth'\n",
        "}\n",
        "models_blend = []\n",
        "names_blend = []\n",
        "for name, pth in paths.items():\n",
        "    if os.path.exists(pth):\n",
        "        nm = 'convnext_tiny' if 'tiny' in name else 'convnext_small.in12k_ft_in1k'\n",
        "        m = timm.create_model(nm, pretrained=False, num_classes=num_classes)\n",
        "        ck = torch.load(pth, map_location='cpu', weights_only=True); st = ck.get('model', ck)\n",
        "        m.load_state_dict(st, strict=True); m.to(device); m.to(memory_format=torch.channels_last)\n",
        "        models_blend.append(m); names_blend.append(name)\n",
        "\n",
        "@torch.no_grad()\n",
        "def val_logits_for_models(models):\n",
        "    outs = []\n",
        "    for m in models:\n",
        "        m.eval()\n",
        "        logits = []\n",
        "        for imgs, tgts in val_loader:\n",
        "            imgs = imgs.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "            lg = m(imgs)\n",
        "            lg = 0.5*(lg + m(imgs.flip(-1)))\n",
        "            logits.append(lg.float().cpu())\n",
        "        outs.append(torch.cat(logits, 0))\n",
        "    return outs\n",
        "\n",
        "val_logits_models = val_logits_for_models(models_blend) if len(models_blend)>0 else []\n",
        "val_targets = torch.cat([t for _, t in val_loader], 0).long().numpy()\n",
        "\n",
        "# Optimize blend: base (models_blend averaged) vs LR features\n",
        "if len(val_logits_models) > 0:\n",
        "    val_logits_base = torch.stack(val_logits_models, 0).mean(0).numpy()\n",
        "    val_probs_base = torch.softmax(torch.from_numpy(val_logits_base), dim=1).numpy()\n",
        "else:\n",
        "    val_probs_base = np.zeros((len(val_targets), num_classes), dtype=np.float32) + (1.0/num_classes)\n",
        "\n",
        "def val_blend_loss(w):\n",
        "    w = float(w)\n",
        "    probs = w*val_probs_base + (1.0-w)*probs_va_lr\n",
        "    return log_loss(val_targets, probs, labels=list(range(num_classes)))\n",
        "res = opt.minimize_scalar(lambda x: val_blend_loss(x), bounds=(0.0,1.0), method='bounded', options={'xatol':1e-3,'maxiter':100})\n",
        "w_opt = float(res.x) if res.success else 0.5\n",
        "print('Optimized blend w (base vs LR):', w_opt)\n",
        "\n",
        "# Build final probs for test\n",
        "if len(models_blend) > 0:\n",
        "    # reuse base_sub as base probs\n",
        "    probs_base_te = base_sub[breeds].values.astype(np.float32)\n",
        "else:\n",
        "    probs_base_te = np.zeros_like(probs_te_lr) + (1.0/num_classes)\n",
        "probs_final = w_opt*probs_base_te + (1.0-w_opt)*probs_te_lr\n",
        "\n",
        "sub = pd.DataFrame(probs_final, columns=breeds)\n",
        "sub.insert(0, 'id', base_sub['id'].values)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (blend base + LR features) with shape', sub.shape, 'w=', w_opt)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "id": "551f2156-7d45-4909-beb0-8938bae2c05d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CPU-only: calibration with per-class bias on blended logits (2 EMA models, 2 scales) to reduce logloss\n",
        "import os, numpy as np, pandas as pd, torch, torch.nn.functional as F\n",
        "import timm, albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def build_model(name, num_classes):\n",
        "    return timm.create_model(name, pretrained=False, num_classes=num_classes)\n",
        "\n",
        "def load_ckpt(model, path):\n",
        "    ckpt = torch.load(path, map_location='cpu', weights_only=True)\n",
        "    state = ckpt.get('model', ckpt)\n",
        "    model.load_state_dict(state, strict=True)\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_logits_tta(model, loader, use_hflip=True):\n",
        "    model.eval()\n",
        "    outs = []\n",
        "    for batch in loader:\n",
        "        if len(batch) == 2 and isinstance(batch[1], torch.Tensor):\n",
        "            images, _ = batch\n",
        "        else:\n",
        "            images, _ids = batch\n",
        "        images = images.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "        logits = model(images)\n",
        "        if use_hflip:\n",
        "            logits = 0.5 * (logits + model(images.flip(-1)))\n",
        "        outs.append(logits.float().cpu())\n",
        "    return torch.cat(outs, 0)\n",
        "\n",
        "def build_loader(size, df, is_test=False, batch_size=48):\n",
        "    tfm = A.Compose([A.Resize(size, size), A.CenterCrop(size, size), A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)), ToTensorV2()])\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    import cv2\n",
        "    class DS(Dataset):\n",
        "        def __init__(self, df): self.df=df.reset_index(drop=True)\n",
        "        def __len__(self): return len(self.df)\n",
        "        def __getitem__(self, i):\n",
        "            r = self.df.iloc[i]\n",
        "            img = cv2.imread(r.filepath); img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = tfm(image=img)['image']\n",
        "            return (img, r.label) if not is_test else (img, r.id)\n",
        "    ds = DS(df)\n",
        "    ld = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    return ld\n",
        "\n",
        "# Load EMA checkpoints (tiny + small fold0). If not found, fallback to available ones.\n",
        "paths = {\n",
        "    'tiny_ema': 'checkpoints/best_ema.pth',\n",
        "    'small_f0_ema': 'checkpoints/fold0/best_ema.pth'\n",
        "}\n",
        "models = []\n",
        "names = []\n",
        "if os.path.exists(paths['tiny_ema']):\n",
        "    m = build_model('convnext_tiny', num_classes); m = load_ckpt(m, paths['tiny_ema']).to(device).to(memory_format=torch.channels_last)\n",
        "    models.append(m); names.append('tiny_ema')\n",
        "if os.path.exists(paths['small_f0_ema']):\n",
        "    m = build_model('convnext_small.in12k_ft_in1k', num_classes); m = load_ckpt(m, paths['small_f0_ema']).to(device).to(memory_format=torch.channels_last)\n",
        "    models.append(m); names.append('small_f0_ema')\n",
        "assert len(models) > 0, 'No EMA checkpoints found'\n",
        "print('Calib using models:', names)\n",
        "\n",
        "# Build val/test DataFrames compatible with loaders\n",
        "val_df_ = val_df[['id','filepath','label']].copy()\n",
        "test_ids = [os.path.splitext(os.path.basename(p))[0] for p in sorted(__import__('glob').glob(os.path.join('test','*.jpg')))]\n",
        "test_df_ = pd.DataFrame({'id': test_ids}); test_df_['filepath'] = test_df_['id'].apply(lambda x: os.path.join('test', f'{x}.jpg'))\n",
        "\n",
        "# Sizes and per-model temperature via grid on validation\n",
        "sizes = [224, 256]\n",
        "val_targets = torch.tensor(val_df_['label'].values, dtype=torch.long)\n",
        "val_logits_models = []  # list of tensors (N,C)\n",
        "Ts = []\n",
        "for m in models:\n",
        "    # average logits over sizes\n",
        "    logits_sum = None\n",
        "    for sz in sizes:\n",
        "        ld_va = build_loader(sz, val_df_, is_test=False, batch_size=32)\n",
        "        lg = predict_logits_tta(m, ld_va, use_hflip=True)\n",
        "        logits_sum = lg if logits_sum is None else (logits_sum + lg)\n",
        "    lg_avg = logits_sum / len(sizes)\n",
        "    # temperature grid search\n",
        "    ts = np.linspace(0.5, 2.0, 41); best_t, best_ce = 1.0, 1e9\n",
        "    for t in ts:\n",
        "        ce = F.cross_entropy(lg_avg/float(t), val_targets).item()\n",
        "        if ce < best_ce: best_ce, best_t = ce, float(t)\n",
        "    Ts.append(best_t); val_logits_models.append(lg_avg)\n",
        "print('Per-model T:', Ts)\n",
        "\n",
        "# Optimize blend weight w on validation\n",
        "def ce_w(w):\n",
        "    w = float(w)\n",
        "    blend = (val_logits_models[0]/Ts[0])\n",
        "    if len(val_logits_models) > 1:\n",
        "        blend = w*(val_logits_models[0]/Ts[0]) + (1.0-w)*(val_logits_models[1]/Ts[1])\n",
        "    return F.cross_entropy(blend, val_targets).item()\n",
        "if len(val_logits_models) == 1:\n",
        "    w_opt = 1.0\n",
        "else:\n",
        "    from scipy.optimize import minimize_scalar\n",
        "    res = minimize_scalar(lambda x: ce_w(x), bounds=(0.0,1.0), method='bounded', options={'xatol':1e-3,'maxiter':100})\n",
        "    w_opt = float(res.x)\n",
        "print('w_opt:', w_opt)\n",
        "\n",
        "# Build blended validation logits\n",
        "val_blend = (val_logits_models[0]/Ts[0]) if len(val_logits_models)==1 else (w_opt*(val_logits_models[0]/Ts[0]) + (1.0-w_opt)*(val_logits_models[1]/Ts[1]))\n",
        "\n",
        "# Fit per-class bias vector b to minimize CE on validation: minimize CE(softmax(val_blend + b), y)\n",
        "b = torch.zeros((num_classes,), dtype=torch.float32, requires_grad=True)\n",
        "optim = torch.optim.LBFGS([b], max_iter=100, tolerance_grad=1e-7, tolerance_change=1e-9, line_search_fn='strong_wolfe')\n",
        "def closure():\n",
        "    optim.zero_grad()\n",
        "    logits = val_blend + b.unsqueeze(0)\n",
        "    loss = F.cross_entropy(logits, val_targets)\n",
        "    loss.backward()\n",
        "    return loss\n",
        "loss0 = F.cross_entropy(val_blend, val_targets).item()\n",
        "optim.step(closure)\n",
        "with torch.no_grad():\n",
        "    loss1 = F.cross_entropy(val_blend + b.unsqueeze(0), val_targets).item()\n",
        "print(f'Bias calib CE: before={loss0:.5f} after={loss1:.5f}')\n",
        "\n",
        "# Detach bias for test-time inference to avoid grads in numpy conversion\n",
        "b = b.detach()\n",
        "\n",
        "# Inference on test with sizes, blend, and bias\n",
        "test_logits_accum = None\n",
        "for sz in sizes:\n",
        "    ld_te = build_loader(sz, test_df_[['id','filepath']].copy(), is_test=True, batch_size=48)\n",
        "    # collect per-model logits\n",
        "    per_model = []\n",
        "    for mi, m in enumerate(models):\n",
        "        lg = predict_logits_tta(m, ld_te, use_hflip=True) / Ts[mi]\n",
        "        per_model.append(lg)\n",
        "    # blend\n",
        "    if len(per_model) == 1:\n",
        "        blended = per_model[0]\n",
        "    else:\n",
        "        blended = w_opt*per_model[0] + (1.0 - w_opt)*per_model[1]\n",
        "    test_logits_accum = blended if test_logits_accum is None else (test_logits_accum + blended)\n",
        "test_logits_avg = test_logits_accum / len(sizes)\n",
        "probs = F.softmax(test_logits_avg + b.unsqueeze(0), dim=1).detach().numpy()\n",
        "\n",
        "sub = pd.DataFrame(probs, columns=breeds)\n",
        "sub.insert(0, 'id', test_df_['id'].values)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with per-class bias calibration. Shape:', sub.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_25410/1440994589.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calib using models: ['tiny_ema', 'small_f0_ema']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per-model T: [1.1, 0.65]\nw_opt: 0.07063204494756387\nBias calib CE: before=0.52495 after=0.42436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv with per-class bias calibration. Shape: (1023, 121)\n"
          ]
        }
      ]
    },
    {
      "id": "a0efe973-edf6-46ae-9407-941ced0ca43d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# === GPU Driver: 5-fold ConvNeXt-Small medal run ===\n",
        "import torch, time, gc\n",
        "try:\n",
        "    CFG\n",
        "    train_one_fold\n",
        "    infer_ensemble_and_save\n",
        "except NameError as e:\n",
        "    print('ERROR: Missing definitions. Run Cells 11 (CFG/loaders) and 9 (training/utils) first, then re-run this cell.')\n",
        "    raise\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print('CUDA not available. Relaunch environment to obtain a working GPU (nvidia-smi must succeed), then run:')\n",
        "    print('  1) Run Cell 11 (CFG/loaders)')\n",
        "    print('  2) Run Cell 9 (training/utils)')\n",
        "    print('  3) Run this driver cell to train all folds and infer submission')\n",
        "else:\n",
        "    print('GPU detected. Starting 5-fold training...')\n",
        "    # Runtime-safe medal plan per expert synthesis\n",
        "    CFG['epochs'] = 8\n",
        "    CFG['patience'] = 2\n",
        "    t0 = time.time()\n",
        "    for fold_idx in range(5):\n",
        "        fold_t0 = time.time()\n",
        "        print(f'>>> Launching fold {fold_idx} / 5', flush=True)\n",
        "        train_one_fold(fold_idx)\n",
        "        torch.cuda.synchronize()\n",
        "        elapsed_h = (time.time() - fold_t0) / 3600.0\n",
        "        print(f'>>> Fold {fold_idx} finished in {elapsed_h:.2f} h', flush=True)\n",
        "        # Free VRAM/host RAM between folds\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "    total_h = (time.time()-t0)/3600.0\n",
        "    print(f'All folds completed in {total_h:.2f} h. Starting ensemble inference...', flush=True)\n",
        "    infer_ensemble_and_save()\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "    print('Done. submission.csv saved.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA not available. Relaunch environment to obtain a working GPU (nvidia-smi must succeed), then run:\n  1) Run Cell 11 (CFG/loaders)\n  2) Run Cell 9 (training/utils)\n  3) Run this driver cell to train all folds and infer submission\n"
          ]
        }
      ]
    },
    {
      "id": "2bb0eb7f-b362-4ac2-9a32-ef8f2cad27b8",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Medal Run Checklist (GPU required)\n",
        "\n",
        "Follow these exact steps after relaunching with a working GPU:\n",
        "\n",
        "1) Verify GPU works:\n",
        "   - Run Cell 1 (nvidia-smi). Ensure torch.cuda.is_available() == True (Cell 2 prints device).\n",
        "   - If not available, relaunch/copy-and-edit to a new host. Optional: add a lightweight retry loop to re-check CUDA every 60\u201390s.\n",
        "\n",
        "2) Prepare definitions:\n",
        "   - Run Cell 11 (CFG/loaders via CSV folds).\n",
        "   - Run Cell 9 (training + inference utilities).\n",
        "\n",
        "3) Train all folds + infer:\n",
        "   - Run Cell 16 (GPU driver).\n",
        "   - It sets epochs=8, patience=2 (runtime-safe) and loops folds 0..4 with EMA warmup, then runs ensemble TTA (sizes: 384, 416) and global temperature from OOF, saving submission.csv.\n",
        "\n",
        "Notes:\n",
        "- Keep CFG as-is: convnext_small.in12k_ft_in1k @384, batch_size=4, accum_steps=8, lr=2e-4, ema_decay warmup ~0.99\u21920.9996 (adaptive), mixup_alpha=0.1, cutmix_alpha=0.5, num_workers=4, drop_path_rate=0.25.\n",
        "- LR/EMA schedules are tied to optimizer update steps (respecting grad accumulation).\n",
        "- Dataloaders use pin_memory and persistent_workers for speed; inference uses batch_size=32 and num_workers=0 to avoid hangs.\n",
        "- If OOM: set CFG['accum_steps']=6 in Cell 11, then re-run Cell 9 and Cell 16.\n",
        "- Do not change hyperparameters mid-run.\n",
        "- Stability tip: add `cv2.setNumThreads(0)` near imports to avoid OpenCV thread contention.\n",
        "\n",
        "Outcome:\n",
        "- After \u22652 folds (preferably all 5), submission.csv will be saved in CWD, ready to score."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "8e729dc0-9a1b-4865-ac07-853de56b4ac3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lightweight CUDA retry loop (run this to periodically check for GPU availability)\n",
        "import time, torch, datetime\n",
        "max_checks = 8  # ~10 minutes if interval=75s\n",
        "interval_s = 75\n",
        "print(f\"[{datetime.datetime.now().strftime('%H:%M:%S')}] Starting CUDA retry loop: {max_checks} checks, {interval_s}s interval\", flush=True)\n",
        "for i in range(max_checks):\n",
        "    ok = torch.cuda.is_available()\n",
        "    ts = datetime.datetime.now().strftime('%H:%M:%S')\n",
        "    print(f\"[{ts}] Check {i+1}/{max_checks}: torch.cuda.is_available() = {ok}\", flush=True)\n",
        "    if ok:\n",
        "        print('GPU is now available. Next steps: run Cell 11 -> Cell 9 -> Cell 16.', flush=True)\n",
        "        break\n",
        "    if i < max_checks - 1:\n",
        "        time.sleep(interval_s)\n",
        "else:\n",
        "    print('GPU still unavailable after retries. Recommended: Restart session or Copy & Edit to force new host, then run Cells 11 -> 9 -> 16.', flush=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:17:08] Starting CUDA retry loop: 8 checks, 75s interval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:17:08] Check 1/8: torch.cuda.is_available() = False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:18:23] Check 2/8: torch.cuda.is_available() = False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:19:38] Check 3/8: torch.cuda.is_available() = False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:20:53] Check 4/8: torch.cuda.is_available() = False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:22:08] Check 5/8: torch.cuda.is_available() = False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:23:23] Check 6/8: torch.cuda.is_available() = False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:24:38] Check 7/8: torch.cuda.is_available() = False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:25:53] Check 8/8: torch.cuda.is_available() = False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU still unavailable after retries. Recommended: Restart session or Copy & Edit to force new host, then run Cells 11 -> 9 -> 16.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}