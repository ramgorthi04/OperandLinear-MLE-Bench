{
  "cells": [
    {
      "id": "a7c2a7d8-f51e-4379-8808-bad660a42801",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tabular Playground Series - Dec 2021: Plan & Experiment Log\n",
        "\n",
        "## Problem framing\n",
        "- Task: Multiclass classification (7 classes) predicting Cover_Type\n",
        "- Metric: Accuracy\n",
        "- Data: Synthetic Forest Cover inspired (all numeric/binary)\n",
        "\n",
        "## Success targets\n",
        "- Ship a working baseline ASAP and submit\n",
        "- Above median: >= 0.953\n",
        "- Medal target: >= 0.9566 LB via robust CV and ensembling/tuning\n",
        "\n",
        "## Validation protocol\n",
        "- Stratified KFold (n_splits=5, shuffle=True, fixed seed)\n",
        "- Single fold set reused for all experiments; save OOF predictions\n",
        "- Track CV mean/std, compare to LB with early submissions\n",
        "\n",
        "## Modeling plan (iterative)\n",
        "1) Baseline: XGBoost (GPU) with modest depth/regularization\n",
        "2) Tune key params (max_depth, eta, min_child_weight, subsamples) using CV\n",
        "3) Try CatBoost (GPU) as alternative; blend XGB+Cat\n",
        "4) Feature engineering:\n",
        "   - Basic interactions: distances, hillshade stats, slope/aspect trigs\n",
        "   - Row-wise aggregates over Soil_Type and Wilderness_Area binaries\n",
        "5) Error analysis on OOF by class; adjust class-wise calibration if needed\n",
        "\n",
        "## Guardrails\n",
        "- Use GPU: tree_method=gpu_hist, predictor=gpu_predictor\n",
        "- Early stopping with validation folds\n",
        "- Start with smoke runs (subset rows, fewer rounds) to validate code\n",
        "- Deterministic seeds, single CV splitter\n",
        "\n",
        "## Experiment Log\n",
        "| Exp | Date/Time | Features | Model | Params | Folds | OOF Acc | LB Acc | Notes |\n",
        "|-----|-----------|----------|-------|--------|-------|---------|--------|-------|\n",
        "\n",
        "## Next actions\n",
        "1) Environment check (GPU available) and install xgboost/catboost if needed\n",
        "2) Load data, target distribution, basic checks\n",
        "3) Implement 5-fold stratified CV XGBoost baseline, generate OOF/test, submit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "4e1e46df-1f67-4923-a40d-6b24330307bf",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment check: GPU + packages\n",
        "import sys, subprocess, importlib, os\n",
        "print(sys.version)\n",
        "print('CUDA libraries present:', os.path.exists('/usr/lib/x86_64-linux-gnu/libcuda.so.1'))\n",
        "\n",
        "def ensure(pkg, import_name=None, extras=None):\n",
        "    import_name = import_name or pkg\n",
        "    try:\n",
        "        importlib.import_module(import_name)\n",
        "        print(f'{pkg} already installed')\n",
        "    except ImportError:\n",
        "        to_install = pkg if extras is None else f\"{pkg}{extras}\"\n",
        "        print(f'Installing {to_install} ...')\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', to_install], check=True)\n",
        "        importlib.import_module(import_name)\n",
        "        print(f'{pkg} installed')\n",
        "\n",
        "# Prefer GPU-ready libs: XGBoost and CatBoost\n",
        "ensure('xgboost')\n",
        "ensure('catboost')\n",
        "ensure('pandas')\n",
        "ensure('numpy')\n",
        "ensure('scikit-learn', 'sklearn')\n",
        "\n",
        "# GPU sanity (PyTorch just for check if not present, skip heavy install)\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch GPU Available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU Name:', torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    print('Torch not available for GPU check; skipping. Error:', str(e))\n",
        "\n",
        "import xgboost as xgb\n",
        "print('XGBoost version:', xgb.__version__)\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "print('CatBoost ready')\n",
        "\n",
        "import pandas as pd, numpy as np\n",
        "pd.set_option('display.max_columns', 200)\n",
        "print('Env ready.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]\nCUDA libraries present: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgboost already installed\ncatboost already installed\npandas already installed\nnumpy already installed\nscikit-learn already installed\nTorch not available for GPU check; skipping. Error: No module named 'torch'\nXGBoost version: 2.1.4\nCatBoost ready\nEnv ready.\n"
          ]
        }
      ]
    },
    {
      "id": "aa2b2700-0f3e-4058-a65a-0934460709e2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Baseline: Load data, 5-fold Stratified CV XGBoost (raw features), OOF acc, test preds, submission\n",
        "import pandas as pd, numpy as np, os, time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "\n",
        "t0 = time.time()\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "print('Train shape:', train.shape, 'Test shape:', test.shape)\n",
        "\n",
        "id_col = 'Id' if 'Id' in train.columns else None\n",
        "target_col = 'Cover_Type'\n",
        "\n",
        "# Prepare features\n",
        "feature_cols = [c for c in train.columns if c not in ([id_col] if id_col else []) + [target_col]]\n",
        "X = train[feature_cols].astype(np.float32).values\n",
        "y = train[target_col].astype(int).values - 1  # convert to 0..6\n",
        "X_test = test[feature_cols].astype(np.float32).values\n",
        "\n",
        "n_classes = len(np.unique(y))\n",
        "print('Features:', len(feature_cols), 'Classes:', n_classes)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_proba = np.zeros((len(train), n_classes), dtype=np.float32)\n",
        "test_proba = np.zeros((len(test), n_classes), dtype=np.float32)\n",
        "\n",
        "# XGBoost native params (use xgb.train for early stopping in xgb 2.x)\n",
        "params_native = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': n_classes,\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'predictor': 'gpu_predictor',\n",
        "    'max_depth': 10,\n",
        "    'eta': 0.03,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'reg_lambda': 5.0,\n",
        "    'min_child_weight': 1.0,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'max_bin': 256,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "num_boost_round = 2000\n",
        "early_stopping_rounds = 200\n",
        "\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "\n",
        "fold_accs = []\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "    X_tr, y_tr = X[tr_idx], y[tr_idx]\n",
        "    X_va, y_va = X[va_idx], y[va_idx]\n",
        "    dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
        "    dvalid = xgb.DMatrix(X_va, label=y_va)\n",
        "    bst = xgb.train(\n",
        "        params_native,\n",
        "        dtrain,\n",
        "        num_boost_round=num_boost_round,\n",
        "        evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
        "        early_stopping_rounds=early_stopping_rounds,\n",
        "        verbose_eval=False\n",
        "    )\n",
        "    proba_va = bst.predict(dvalid)\n",
        "    oof_proba[va_idx] = proba_va.astype(np.float32)\n",
        "    preds_va = np.argmax(proba_va, axis=1)\n",
        "    acc = accuracy_score(y_va, preds_va)\n",
        "    fold_accs.append(acc)\n",
        "    best_it = getattr(bst, 'best_iteration', None)\n",
        "    print(f'Fold {fold} acc: {acc:.6f}, best_iter: {best_it}')\n",
        "    # predict test using best_iteration\n",
        "    if best_it is not None:\n",
        "        test_proba += bst.predict(dtest, iteration_range=(0, best_it + 1)) / skf.n_splits\n",
        "    else:\n",
        "        test_proba += bst.predict(dtest) / skf.n_splits\n",
        "\n",
        "oof_pred = np.argmax(oof_proba, axis=1)\n",
        "oof_acc = accuracy_score(y, oof_pred)\n",
        "print('Fold accs:', [round(a,6) for a in fold_accs])\n",
        "print(f'OOF accuracy: {oof_acc:.6f}')\n",
        "\n",
        "# Save submission\n",
        "pred_labels = np.argmax(test_proba, axis=1) + 1  # back to 1..7\n",
        "sub = pd.DataFrame({\n",
        "    ('Id' if 'Id' in test.columns else 'id'): test[id_col].values if id_col else np.arange(len(test)),\n",
        "    'Cover_Type': pred_labels.astype(int)\n",
        "})\n",
        "sub.rename(columns={'id': 'Id'}, inplace=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with shape:', sub.shape)\n",
        "print('Done in %.1fs' % (time.time() - t0))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (3600000, 56) Test shape: (400000, 55)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: 54 Classes: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:45:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:45:17] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"predictor\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:56:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 acc: 0.961167, best_iter: 1936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:56:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [20:56:47] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"predictor\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:08:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 acc: 0.961110, best_iter: 1892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:08:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:08:18] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"predictor\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:19:31] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 acc: 0.961290, best_iter: 1947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:19:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:19:41] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"predictor\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:28:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 acc: 0.961810, best_iter: 1902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:28:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:28:18] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"predictor\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:31:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 acc: 0.961633, best_iter: 1906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold accs: [0.961167, 0.96111, 0.96129, 0.96181, 0.961633]\nOOF accuracy: 0.961402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv with shape: (400000, 2)\nDone in 2809.7s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}