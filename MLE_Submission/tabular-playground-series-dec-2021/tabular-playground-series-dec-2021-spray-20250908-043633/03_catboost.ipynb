{
  "cells": [
    {
      "id": "a3e5d96c-64d8-4a8d-bb55-23f377f3223f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CatBoost full-data training with categorical indices and robust validation\n",
        "import os, sys, time, json, logging, importlib, subprocess, gc, traceback\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "t0_total = time.time()\n",
        "os.environ['PYTHONUNBUFFERED'] = '1'\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                    format='%(asctime)s [%(levelname)s] %(message)s',\n",
        "                    handlers=[\n",
        "                        logging.FileHandler('run_catboost.log', mode='w'),\n",
        "                        logging.StreamHandler(sys.stdout)\n",
        "                    ],\n",
        "                    force=True)\n",
        "\n",
        "def ensure_package(pkg: str, import_name: str = None):\n",
        "    name = import_name or pkg\n",
        "    try:\n",
        "        return importlib.import_module(name)\n",
        "    except ImportError:\n",
        "        logging.info(f'Installing {pkg}...')\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
        "        return importlib.import_module(name)\n",
        "\n",
        "try:\n",
        "    logging.info('Importing CatBoost...')\n",
        "    cb = ensure_package('catboost', 'catboost')\n",
        "    from catboost import CatBoostClassifier, Pool\n",
        "    logging.info('CatBoost imported.')\n",
        "\n",
        "    # Load processed features and target\n",
        "    logging.info('Loading cached Feather/NumPy artifacts...')\n",
        "    X = pd.read_feather('X.feather')\n",
        "    X_test = pd.read_feather('X_test.feather')\n",
        "    y = np.load('y.npy')  # 0..6\n",
        "    with open('features.json','r') as f:\n",
        "        features = json.load(f)\n",
        "    # Enforce same base feature order\n",
        "    X = X[features].copy()\n",
        "    X_test = X_test[features].copy()\n",
        "    logging.info(f'Data shapes: X={X.shape}, X_test={X_test.shape}, y={y.shape}')\n",
        "\n",
        "    # Reconstruct categorical indices from one-hot columns; if missing in X, read minimal columns from raw CSVs\n",
        "    wild_cols = [c for c in X.columns if c.startswith('Wilderness_Area')]\n",
        "    soil_cols = [c for c in X.columns if c.startswith('Soil_Type')]\n",
        "    if not wild_cols or not soil_cols:\n",
        "        logging.info('One-hot Wilderness/Soil columns not found in X; reconstructing from raw CSV...')\n",
        "        # Determine column names from train.csv header (support names with/without underscore before number)\n",
        "        header = pd.read_csv('train.csv', nrows=0).columns.tolist()\n",
        "        wild_cols_all = [c for c in header if c.startswith('Wilderness_Area')]\n",
        "        soil_cols_all = [c for c in header if c.startswith('Soil_Type')]\n",
        "        if not wild_cols_all or not soil_cols_all:\n",
        "            raise RuntimeError('Could not find Wilderness_Area* or Soil_Type* in raw CSV header.')\n",
        "        usecols_train = wild_cols_all + soil_cols_all\n",
        "        usecols_test = usecols_train.copy()\n",
        "        logging.info('Reading minimal one-hot columns from train/test CSVs to build indices...')\n",
        "        tr_onehot = pd.read_csv('train.csv', usecols=usecols_train)\n",
        "        te_onehot = pd.read_csv('test.csv', usecols=usecols_test)\n",
        "        # Sort by numeric suffix for stable argmax order\n",
        "        def numeric_suffix(col):\n",
        "            digits = ''.join(ch for ch in col if ch.isdigit())\n",
        "            return int(digits) if digits else 0\n",
        "        wild_cols_sorted = sorted(wild_cols_all, key=numeric_suffix)\n",
        "        soil_cols_sorted = sorted(soil_cols_all, key=numeric_suffix)\n",
        "        X['Wilderness_Area_Index'] = tr_onehot[wild_cols_sorted].to_numpy().argmax(axis=1).astype(np.int16)\n",
        "        X_test['Wilderness_Area_Index'] = te_onehot[wild_cols_sorted].to_numpy().argmax(axis=1).astype(np.int16)\n",
        "        X['Soil_Type_Index'] = tr_onehot[soil_cols_sorted].to_numpy().argmax(axis=1).astype(np.int16)\n",
        "        X_test['Soil_Type_Index'] = te_onehot[soil_cols_sorted].to_numpy().argmax(axis=1).astype(np.int16)\n",
        "        del tr_onehot, te_onehot\n",
        "        gc.collect()\n",
        "    else:\n",
        "        def numeric_suffix(col):\n",
        "            digits = ''.join(ch for ch in col if ch.isdigit())\n",
        "            return int(digits) if digits else 0\n",
        "        wild_cols_sorted = sorted(wild_cols, key=numeric_suffix)\n",
        "        soil_cols_sorted = sorted(soil_cols, key=numeric_suffix)\n",
        "        # Argmax over one-hot to get integer category indices (0-based)\n",
        "        X['Wilderness_Area_Index'] = X[wild_cols_sorted].to_numpy().argmax(axis=1).astype(np.int16)\n",
        "        X_test['Wilderness_Area_Index'] = X_test[wild_cols_sorted].to_numpy().argmax(axis=1).astype(np.int16)\n",
        "        X['Soil_Type_Index'] = X[soil_cols_sorted].to_numpy().argmax(axis=1).astype(np.int16)\n",
        "        X_test['Soil_Type_Index'] = X_test[soil_cols_sorted].to_numpy().argmax(axis=1).astype(np.int16)\n",
        "\n",
        "    # Elevation band (categorical integer bins)\n",
        "    elev_bins = [0, 2400, 2800, 3200, 10000]\n",
        "    X['ElevationBand'] = pd.cut(X['Elevation'], bins=elev_bins, labels=False, include_lowest=True).astype('Int8').fillna(0).astype(np.int16)\n",
        "    X_test['ElevationBand'] = pd.cut(X_test['Elevation'], bins=elev_bins, labels=False, include_lowest=True).astype('Int8').fillna(0).astype(np.int16)\n",
        "\n",
        "    # Build CatBoost feature lists\n",
        "    cat_feature_names = ['Wilderness_Area_Index', 'Soil_Type_Index', 'ElevationBand']\n",
        "    for c in cat_feature_names:\n",
        "        if c not in X.columns:\n",
        "            raise RuntimeError(f'Missing categorical feature {c}')\n",
        "    all_features = X.columns.tolist()\n",
        "    cat_features_idx = [all_features.index(c) for c in cat_feature_names]\n",
        "    logging.info(f'Categorical features indices: {cat_features_idx}')\n",
        "\n",
        "    # Validation split: ensure singleton class (index 4) stays in training\n",
        "    singleton_class = 4\n",
        "    singleton_mask = (y == singleton_class)\n",
        "    singleton_idx = np.where(singleton_mask)[0]\n",
        "    excl_mask = ~singleton_mask\n",
        "    X_excl = X.loc[excl_mask].reset_index(drop=True)\n",
        "    y_excl = y[excl_mask]\n",
        "    # Use stratify if possible (all classes except singleton present)\n",
        "    do_strat = True\n",
        "    try:\n",
        "        _, strat_counts = np.unique(y_excl, return_counts=True)\n",
        "        do_strat = (strat_counts.min() >= 2)\n",
        "    except Exception:\n",
        "        do_strat = False\n",
        "    logging.info(f'Splitting hold-out (stratify={do_strat})...')\n",
        "    X_trn_ex, X_val, y_trn_ex, y_val = train_test_split(\n",
        "        X_excl, y_excl, test_size=0.10, random_state=42, shuffle=True, stratify=(y_excl if do_strat else None)\n",
        "    )\n",
        "    # Concatenate singleton back into training set\n",
        "    if singleton_idx.size == 1:\n",
        "        X_trn = pd.concat([X_trn_ex, X.iloc[singleton_idx]], axis=0, ignore_index=True)\n",
        "        y_trn = np.concatenate([y_trn_ex, y[singleton_idx]], axis=0)\n",
        "    else:\n",
        "        X_trn, y_trn = X_trn_ex, y_trn_ex\n",
        "    logging.info(f'Train/Valid shapes: {X_trn.shape}/{X_val.shape}')\n",
        "\n",
        "    # Pools for CatBoost\n",
        "    train_pool = Pool(data=X_trn, label=y_trn, cat_features=cat_features_idx)\n",
        "    valid_pool = Pool(data=X_val, label=y_val, cat_features=cat_features_idx)\n",
        "\n",
        "    # CatBoost parameters (CPU)\n",
        "    params = {\n",
        "        'loss_function': 'MultiClass',\n",
        "        'iterations': 3000,\n",
        "        'depth': 10,\n",
        "        'learning_rate': 0.03,\n",
        "        'l2_leaf_reg': 3.0,\n",
        "        'random_strength': 1.0,\n",
        "        'bootstrap_type': 'Bayesian',\n",
        "        'bagging_temperature': 1.0,\n",
        "        'eval_metric': 'Accuracy',\n",
        "        'od_type': 'Iter',\n",
        "        'od_wait': 200,\n",
        "        'random_seed': 42,\n",
        "        'task_type': 'CPU',\n",
        "        'thread_count': min(24, os.cpu_count() or 24),\n",
        "        'verbose': 100\n",
        "    }\n",
        "\n",
        "    logging.info('Training CatBoost (full data, early stopping)...')\n",
        "    t0 = time.time()\n",
        "    model = CatBoostClassifier(**params)\n",
        "    model.fit(train_pool, eval_set=valid_pool, use_best_model=True)\n",
        "    logging.info(f'Training complete in {time.time()-t0:.1f}s. Best iters: {model.tree_count_}')\n",
        "\n",
        "    # Predict test\n",
        "    logging.info('Predicting on test...')\n",
        "    test_pool = Pool(data=X_test, cat_features=cat_features_idx)\n",
        "    test_proba = model.predict_proba(test_pool)\n",
        "    test_pred = np.argmax(test_proba, axis=1).astype(np.int32)  # 0..6\n",
        "\n",
        "    # Post-processing override for class 5 (index 4): Wilderness_Area == 4th and Elevation > 3300\n",
        "    try:\n",
        "        wild_idx_test = X_test['Wilderness_Area_Index'].to_numpy()\n",
        "        elev_test = X_test['Elevation'].to_numpy()\n",
        "        override_mask = (wild_idx_test == 3) & (elev_test > 3300)\n",
        "        num_over = int(override_mask.sum())\n",
        "        if num_over > 0:\n",
        "            test_pred[override_mask] = 4  # zero-based index for class 5\n",
        "        logging.info(f'Post-processing overrides applied: {num_over}')\n",
        "    except Exception as e:\n",
        "        logging.warning(f'Post-processing step skipped due to error: {e}')\n",
        "\n",
        "    # Save submission\n",
        "    test_ids = np.load('test_ids.npy')\n",
        "    sub = pd.DataFrame({'Id': test_ids, 'Cover_Type': test_pred + 1})\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    logging.info('Saved submission.csv')\n",
        "    logging.info(f'Done. Total elapsed: {time.time()-t0_total:.1f}s')\n",
        "\n",
        "except Exception as e:\n",
        "    logging.error('Exception in CatBoost pipeline: ' + str(e))\n",
        "    with open('catboost_error.log','w') as f:\n",
        "        f.write(traceback.format_exc())\n",
        "    raise"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-08 17:12:37,234 [INFO] Importing CatBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-08 17:12:37,238 [INFO] CatBoost imported.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-08 17:12:37,238 [INFO] Loading cached Feather/NumPy artifacts...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-08 17:12:39,215 [INFO] Data shapes: X=(3600000, 70), X_test=(400000, 70), y=(3600000,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-08 17:12:40,405 [INFO] Categorical features indices: [70, 71, 72]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-08 17:12:41,465 [INFO] Splitting hold-out (stratify=True)...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}