{
  "cells": [
    {
      "id": "587a1daa-5ed0-4e55-ab2b-87c8f358df7c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Stage 1: Preprocess CSV -> Feather/Parquet with logging\n",
        "import os, sys, time, json, logging, importlib, subprocess, gc\n",
        "from typing import Dict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- Logging setup ---\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                    format='%(asctime)s [%(levelname)s] %(message)s',\n",
        "                    handlers=[\n",
        "                        logging.FileHandler('run_preprocess.log', mode='w'),\n",
        "                        logging.StreamHandler(sys.stdout)\n",
        "                    ])\n",
        "os.environ['PYTHONUNBUFFERED'] = '1'\n",
        "\n",
        "def ensure_package(pkg: str):\n",
        "    try:\n",
        "        return importlib.import_module(pkg)\n",
        "    except ImportError:\n",
        "        logging.info(f'Installing {pkg}...')\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
        "        return importlib.import_module(pkg)\n",
        "\n",
        "# Feather requires pyarrow\n",
        "ensure_package('pyarrow')\n",
        "\n",
        "t0 = time.time()\n",
        "logging.info('Reading small head to infer columns...')\n",
        "head = pd.read_csv('train.csv', nrows=5)\n",
        "cols = head.columns.tolist()\n",
        "assert 'Cover_Type' in cols, 'Cover_Type not found in train.csv'\n",
        "has_id = 'Id' in cols\n",
        "\n",
        "# --- Build dtype map ---\n",
        "dtypes: Dict[str, str] = {}\n",
        "for c in cols:\n",
        "    if c == 'Cover_Type':\n",
        "        dtypes[c] = 'int8'\n",
        "    elif c == 'Id':\n",
        "        dtypes[c] = 'int32'\n",
        "    elif c.startswith('Wilderness_Area_') or c.startswith('Soil_Type_'):\n",
        "        dtypes[c] = 'uint8'\n",
        "    elif c in ['Hillshade_9am','Hillshade_Noon','Hillshade_3pm']:\n",
        "        dtypes[c] = 'uint16'  # safe; will downcast later if needed\n",
        "    elif c in ['Elevation','Aspect','Slope',\n",
        "               'Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology',\n",
        "               'Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points']:\n",
        "        dtypes[c] = 'int32'  # will downcast post-read\n",
        "    else:\n",
        "        # default safe int32\n",
        "        dtypes[c] = 'int32'\n",
        "\n",
        "logging.info('Reading full train with dtypes...')\n",
        "train = pd.read_csv('train.csv', dtype=dtypes)\n",
        "logging.info(f'train shape: {train.shape}')\n",
        "\n",
        "logging.info('Reading full test with dtypes...')\n",
        "test = pd.read_csv('test.csv', dtype={k: v for k, v in dtypes.items() if k != 'Cover_Type'})\n",
        "logging.info(f'test shape: {test.shape}')\n",
        "\n",
        "# Downcast numerics to reduce memory\n",
        "def downcast_df(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    for c in df.columns:\n",
        "        if pd.api.types.is_integer_dtype(df[c]):\n",
        "            df[c] = pd.to_numeric(df[c], downcast='integer')\n",
        "        elif pd.api.types.is_float_dtype(df[c]):\n",
        "            df[c] = pd.to_numeric(df[c], downcast='float')\n",
        "    return df\n",
        "\n",
        "train = downcast_df(train)\n",
        "test = downcast_df(test)\n",
        "logging.info('Downcast complete')\n",
        "\n",
        "# --- Target and base features ---\n",
        "y = (train['Cover_Type'].values.astype(np.int8) - 1)  # 0..6\n",
        "feature_cols = [c for c in train.columns if c not in ['Cover_Type']]\n",
        "if 'Id' in feature_cols:\n",
        "    feature_cols.remove('Id')\n",
        "X = train[feature_cols].copy()\n",
        "X_test = test[[c for c in test.columns if c != 'Id']].copy()\n",
        "test_ids = test['Id'].values if 'Id' in test.columns else np.arange(len(test), dtype=np.int64)\n",
        "\n",
        "# --- Feature Engineering (exactly as in main notebook) ---\n",
        "logging.info('Feature engineering...')\n",
        "# 1) Distribution shift feature on Elevation (threshold from test)\n",
        "elev_threshold = X_test['Elevation'].median()\n",
        "X['is_high_elevation'] = (X['Elevation'] > elev_threshold).astype(np.int8)\n",
        "X_test['is_high_elevation'] = (X_test['Elevation'] > elev_threshold).astype(np.int8)\n",
        "\n",
        "# 2) Hydrology features\n",
        "if set(['Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology']).issubset(X.columns):\n",
        "    X['Hydrology_Euclid'] = np.sqrt((X['Horizontal_Distance_To_Hydrology'].astype(np.float32))**2 + (X['Vertical_Distance_To_Hydrology'].astype(np.float32))**2).astype(np.float32)\n",
        "    X_test['Hydrology_Euclid'] = np.sqrt((X_test['Horizontal_Distance_To_Hydrology'].astype(np.float32))**2 + (X_test['Vertical_Distance_To_Hydrology'].astype(np.float32))**2).astype(np.float32)\n",
        "    X['Elev_minus_VertHydro'] = (X['Elevation'].astype(np.float32) - X['Vertical_Distance_To_Hydrology'].astype(np.float32)).astype(np.float32)\n",
        "    X_test['Elev_minus_VertHydro'] = (X_test['Elevation'].astype(np.float32) - X_test['Vertical_Distance_To_Hydrology'].astype(np.float32)).astype(np.float32)\n",
        "\n",
        "# 3) Hillshade features\n",
        "hill_cols = [c for c in ['Hillshade_9am','Hillshade_Noon','Hillshade_3pm'] if c in X.columns]\n",
        "if len(hill_cols) == 3:\n",
        "    X['Hillshade_Mean'] = X[hill_cols].mean(axis=1).astype(np.float32)\n",
        "    X_test['Hillshade_Mean'] = X_test[hill_cols].mean(axis=1).astype(np.float32)\n",
        "    X['Hillshade_Min'] = X[hill_cols].min(axis=1).astype(np.float32)\n",
        "    X_test['Hillshade_Min'] = X_test[hill_cols].min(axis=1).astype(np.float32)\n",
        "    X['Hillshade_Max'] = X[hill_cols].max(axis=1).astype(np.float32)\n",
        "    X_test['Hillshade_Max'] = X_test[hill_cols].max(axis=1).astype(np.float32)\n",
        "    X['Hillshade_Range'] = (X['Hillshade_Max'] - X['Hillshade_Min']).astype(np.float32)\n",
        "    X_test['Hillshade_Range'] = (X_test['Hillshade_Max'] - X_test['Hillshade_Min']).astype(np.float32)\n",
        "\n",
        "# 4) Distance interactions\n",
        "dist_cols = ['Horizontal_Distance_To_Fire_Points','Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Hydrology']\n",
        "if set(dist_cols).issubset(X.columns):\n",
        "    hf, rr, hh = dist_cols\n",
        "    X['DistDiff_Fire_Road'] = (X[hf] - X[rr]).abs().astype(np.int32)\n",
        "    X_test['DistDiff_Fire_Road'] = (X_test[hf] - X_test[rr]).abs().astype(np.int32)\n",
        "    X['DistDiff_Fire_Hydro'] = (X[hf] - X[hh]).abs().astype(np.int32)\n",
        "    X_test['DistDiff_Fire_Hydro'] = (X_test[hf] - X_test[hh]).abs().astype(np.int32)\n",
        "    X['DistDiff_Road_Hydro'] = (X[rr] - X[hh]).abs().astype(np.int32)\n",
        "    X_test['DistDiff_Road_Hydro'] = (X_test[rr] - X_test[hh]).abs().astype(np.int32)\n",
        "    X['DistMean_FRH'] = ((X[hf].astype(np.float32) + X[rr].astype(np.float32) + X[hh].astype(np.float32)) / 3.0).astype(np.float32)\n",
        "    X_test['DistMean_FRH'] = ((X_test[hf].astype(np.float32) + X_test[rr].astype(np.float32) + X_test[hh].astype(np.float32)) / 3.0).astype(np.float32)\n",
        "    X['DistSum_FRH'] = (X[hf] + X[rr] + X[hh]).astype(np.int32)\n",
        "    X_test['DistSum_FRH'] = (X_test[hf] + X_test[rr] + X_test[hh]).astype(np.int32)\n",
        "    X['DistMin_FRH'] = X[[hf, rr, hh]].min(axis=1).astype(np.int32)\n",
        "    X_test['DistMin_FRH'] = X_test[[hf, rr, hh]].min(axis=1).astype(np.int32)\n",
        "    X['DistMax_FRH'] = X[[hf, rr, hh]].max(axis=1).astype(np.int32)\n",
        "    X_test['DistMax_FRH'] = X_test[[hf, rr, hh]].max(axis=1).astype(np.int32)\n",
        "\n",
        "# 5) One-hot counts\n",
        "soil_cols = [c for c in X.columns if c.startswith('Soil_Type_')]\n",
        "wild_cols = [c for c in X.columns if c.startswith('Wilderness_Area_')]\n",
        "if soil_cols:\n",
        "    X['Soil_Type_Count'] = X[soil_cols].sum(axis=1).astype(np.int16)\n",
        "    X_test['Soil_Type_Count'] = X_test[soil_cols].sum(axis=1).astype(np.int16)\n",
        "if wild_cols:\n",
        "    X['Wilderness_Area_Count'] = X[wild_cols].sum(axis=1).astype(np.int16)\n",
        "    X_test['Wilderness_Area_Count'] = X_test[wild_cols].sum(axis=1).astype(np.int16)\n",
        "\n",
        "# 6) Aspect sin/cos\n",
        "if 'Aspect' in X.columns:\n",
        "    X['Aspect_sin'] = np.sin(np.deg2rad(X['Aspect'].astype(np.float32))).astype(np.float32)\n",
        "    X_test['Aspect_sin'] = np.sin(np.deg2rad(X_test['Aspect'].astype(np.float32))).astype(np.float32)\n",
        "    X['Aspect_cos'] = np.cos(np.deg2rad(X['Aspect'].astype(np.float32))).astype(np.float32)\n",
        "    X_test['Aspect_cos'] = np.cos(np.deg2rad(X_test['Aspect'].astype(np.float32))).astype(np.float32)\n",
        "\n",
        "features = X.columns.tolist()\n",
        "logging.info(f'Final feature count: {len(features)}')\n",
        "\n",
        "# Save outputs\n",
        "logging.info('Saving processed datasets to Feather/NumPy...')\n",
        "X.reset_index(drop=True).to_feather('X.feather')\n",
        "X_test.reset_index(drop=True).to_feather('X_test.feather')\n",
        "np.save('y.npy', y)\n",
        "np.save('test_ids.npy', test_ids)\n",
        "with open('features.json', 'w') as f:\n",
        "    json.dump(features, f)\n",
        "with open('preprocess_meta.json', 'w') as f:\n",
        "    json.dump({'elev_threshold': float(elev_threshold)}, f)\n",
        "\n",
        "logging.info(f'Done. Elapsed: {time.time()-t0:.1f}s')\n",
        "gc.collect()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-08 06:19:50,094 [INFO] Reading small head to infer columns...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-08 06:19:50,102 [INFO] Reading full train with dtypes...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}