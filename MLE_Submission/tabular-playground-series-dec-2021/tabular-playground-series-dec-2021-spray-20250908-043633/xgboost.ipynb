{
  "cells": [
    {
      "id": "fefd8c64-7fec-4ea5-bce5-9b6ea1719ae6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, time, gc, warnings, subprocess, importlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "np.set_printoptions(suppress=True)\n",
        "pd.set_option('display.max_columns', 200)\n",
        "\n",
        "SEED = 42\n",
        "N_SPLITS = 5\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "def ensure_package(pkg_name: str, import_name: str = None):\n",
        "    name = import_name or pkg_name\n",
        "    try:\n",
        "        return importlib.import_module(name)\n",
        "    except ImportError:\n",
        "        print(f\"[INFO] Installing {pkg_name}...\")\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg_name])\n",
        "        return importlib.import_module(name)\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "xgb = ensure_package('xgboost', 'xgboost')\n",
        "from xgboost import DMatrix, train as xgb_train\n",
        "\n",
        "t0 = time.time()\n",
        "print('[INFO] Loading data...')\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "print(f\"[INFO] train shape: {train.shape}, test shape: {test.shape}\")\n",
        "assert 'Cover_Type' in train.columns\n",
        "\n",
        "# Target and base features\n",
        "y = train['Cover_Type'].values - 1\n",
        "feature_cols = [c for c in train.columns if c not in ['Cover_Type', 'Id']]\n",
        "X = train[feature_cols].copy()\n",
        "X_test = test[[c for c in test.columns if c != 'Id']].copy()\n",
        "\n",
        "# --- Feature Engineering (match main/catboost) ---\n",
        "print('[INFO] Feature engineering...')\n",
        "elev_threshold = X_test['Elevation'].median()\n",
        "X['is_high_elevation'] = (X['Elevation'] > elev_threshold).astype(np.int8)\n",
        "X_test['is_high_elevation'] = (X_test['Elevation'] > elev_threshold).astype(np.int8)\n",
        "\n",
        "if set(['Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology']).issubset(X.columns):\n",
        "    X['Hydrology_Euclid'] = np.sqrt(X['Horizontal_Distance_To_Hydrology']**2 + X['Vertical_Distance_To_Hydrology']**2)\n",
        "    X_test['Hydrology_Euclid'] = np.sqrt(X_test['Horizontal_Distance_To_Hydrology']**2 + X_test['Vertical_Distance_To_Hydrology']**2)\n",
        "    X['Elev_minus_VertHydro'] = X['Elevation'] - X['Vertical_Distance_To_Hydrology']\n",
        "    X_test['Elev_minus_VertHydro'] = X_test['Elevation'] - X_test['Vertical_Distance_To_Hydrology']\n",
        "\n",
        "hill_cols = [c for c in ['Hillshade_9am','Hillshade_Noon','Hillshade_3pm'] if c in X.columns]\n",
        "if len(hill_cols) == 3:\n",
        "    X['Hillshade_Mean'] = X[hill_cols].mean(axis=1)\n",
        "    X_test['Hillshade_Mean'] = X_test[hill_cols].mean(axis=1)\n",
        "    X['Hillshade_Min'] = X[hill_cols].min(axis=1)\n",
        "    X_test['Hillshade_Min'] = X_test[hill_cols].min(axis=1)\n",
        "    X['Hillshade_Max'] = X[hill_cols].max(axis=1)\n",
        "    X_test['Hillshade_Max'] = X_test[hill_cols].max(axis=1)\n",
        "    X['Hillshade_Range'] = X['Hillshade_Max'] - X['Hillshade_Min']\n",
        "    X_test['Hillshade_Range'] = X_test['Hillshade_Max'] - X_test['Hillshade_Min']\n",
        "\n",
        "dist_cols = ['Horizontal_Distance_To_Fire_Points','Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Hydrology']\n",
        "if set(dist_cols).issubset(X.columns):\n",
        "    hf, rr, hh = dist_cols\n",
        "    X['DistDiff_Fire_Road'] = (X[hf] - X[rr]).abs()\n",
        "    X_test['DistDiff_Fire_Road'] = (X_test[hf] - X_test[rr]).abs()\n",
        "    X['DistDiff_Fire_Hydro'] = (X[hf] - X[hh]).abs()\n",
        "    X_test['DistDiff_Fire_Hydro'] = (X_test[hf] - X_test[hh]).abs()\n",
        "    X['DistDiff_Road_Hydro'] = (X[rr] - X[hh]).abs()\n",
        "    X_test['DistDiff_Road_Hydro'] = (X_test[rr] - X_test[hh]).abs()\n",
        "    X['DistMean_FRH'] = (X[hf] + X[rr] + X[hh]) / 3.0\n",
        "    X_test['DistMean_FRH'] = (X_test[hf] + X_test[rr] + X_test[hh]) / 3.0\n",
        "    X['DistSum_FRH'] = (X[hf] + X[rr] + X[hh])\n",
        "    X_test['DistSum_FRH'] = (X_test[hf] + X_test[rr] + X_test[hh])\n",
        "    X['DistMin_FRH'] = X[[hf, rr, hh]].min(axis=1)\n",
        "    X_test['DistMin_FRH'] = X_test[[hf, rr, hh]].min(axis=1)\n",
        "    X['DistMax_FRH'] = X[[hf, rr, hh]].max(axis=1)\n",
        "    X_test['DistMax_FRH'] = X_test[[hf, rr, hh]].max(axis=1)\n",
        "\n",
        "soil_cols = [c for c in X.columns if c.startswith('Soil_Type_')]\n",
        "wild_cols = [c for c in X.columns if c.startswith('Wilderness_Area_')]\n",
        "if soil_cols:\n",
        "    X['Soil_Type_Count'] = X[soil_cols].sum(axis=1)\n",
        "    X_test['Soil_Type_Count'] = X_test[soil_cols].sum(axis=1)\n",
        "if wild_cols:\n",
        "    X['Wilderness_Area_Count'] = X[wild_cols].sum(axis=1)\n",
        "    X_test['Wilderness_Area_Count'] = X_test[wild_cols].sum(axis=1)\n",
        "\n",
        "if 'Aspect' in X.columns:\n",
        "    X['Aspect_sin'] = np.sin(np.deg2rad(X['Aspect']))\n",
        "    X_test['Aspect_sin'] = np.sin(np.deg2rad(X_test['Aspect']))\n",
        "    X['Aspect_cos'] = np.cos(np.deg2rad(X['Aspect']))\n",
        "    X_test['Aspect_cos'] = np.cos(np.deg2rad(X_test['Aspect']))\n",
        "\n",
        "features = X.columns.tolist()\n",
        "print(f\"[INFO] Final feature count: {len(features)}\")\n",
        "\n",
        "# Load consistent folds\n",
        "fold_file = 'fold_indices.npy'\n",
        "if os.path.exists(fold_file):\n",
        "    folds = np.load(fold_file, allow_pickle=True).tolist()\n",
        "else:\n",
        "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
        "    folds = list(skf.split(X, y))\n",
        "    np.save(fold_file, np.array(folds, dtype=object))\n",
        "    print(f\"[INFO] Saved fold indices to {fold_file}\")\n",
        "\n",
        "# XGBoost params with GPU fallback\n",
        "tree_method = 'gpu_hist'\n",
        "use_gpu = True\n",
        "try:\n",
        "    # quick test if GPU context works by constructing a tiny DMatrix (will still fall back in except)\n",
        "    _ = xgb.__version__  # silence linter\n",
        "except Exception:\n",
        "    use_gpu = False\n",
        "if not use_gpu:\n",
        "    tree_method = 'hist'\n",
        "\n",
        "base_params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': 7,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'eta': 0.03,\n",
        "    'max_depth': 8,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'lambda': 2.0,\n",
        "    'alpha': 0.1,\n",
        "    'tree_method': tree_method,\n",
        "    'nthread': 8,\n",
        "    'verbosity': 1,\n",
        "    'seed': SEED\n",
        "}\n",
        "\n",
        "oof_preds = np.zeros((X.shape[0], 7), dtype=np.float32)\n",
        "test_preds = np.zeros((X_test.shape[0], 7), dtype=np.float32)\n",
        "fold_acc = []\n",
        "\n",
        "print(f\"[INFO] Starting XGBoost 5-fold CV... (tree_method={tree_method})\")\n",
        "for fold, (trn_idx, val_idx) in enumerate(folds, 1):\n",
        "    f_t = time.time()\n",
        "    print(f\"[FOLD {fold}/{N_SPLITS}] Train: {len(trn_idx)}, Valid: {len(val_idx)}\")\n",
        "    X_trn = X.iloc[trn_idx]\n",
        "    y_trn = y[trn_idx]\n",
        "    X_val = X.iloc[val_idx]\n",
        "    y_val = y[val_idx]\n",
        "\n",
        "    dtrain = DMatrix(X_trn, label=y_trn)\n",
        "    dvalid = DMatrix(X_val, label=y_val)\n",
        "    dtest = DMatrix(X_test)\n",
        "\n",
        "    model = xgb_train(\n",
        "        params=base_params,\n",
        "        dtrain=dtrain,\n",
        "        num_boost_round=5000,\n",
        "        evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
        "        early_stopping_rounds=200,\n",
        "        verbose_eval=100\n",
        "    )\n",
        "\n",
        "    val_pred_proba = model.predict(dvalid, iteration_range=(0, model.best_iteration+1))\n",
        "    oof_preds[val_idx] = val_pred_proba\n",
        "    val_pred = np.argmax(val_pred_proba, axis=1)\n",
        "    acc = accuracy_score(y_val, val_pred)\n",
        "    fold_acc.append(acc)\n",
        "    print(f\"[FOLD {fold}] ACC={acc:.6f} | best_iter={model.best_iteration} | elapsed={time.time()-f_t:.1f}s\")\n",
        "\n",
        "    test_fold_pred = model.predict(dtest, iteration_range=(0, model.best_iteration+1))\n",
        "    test_preds += test_fold_pred / N_SPLITS\n",
        "\n",
        "    del X_trn, X_val, y_trn, y_val, dtrain, dvalid, dtest, model, val_pred_proba, test_fold_pred\n",
        "    gc.collect()\n",
        "\n",
        "oof_pred_labels = np.argmax(oof_preds, axis=1)\n",
        "cv_acc = accuracy_score(y, oof_pred_labels)\n",
        "print(f\"[CV] XGBoost Mean ACC: {np.mean(fold_acc):.6f}; OOF ACC: {cv_acc:.6f}\")\n",
        "\n",
        "np.save('xgb_oof_preds.npy', oof_preds)\n",
        "np.save('xgb_test_preds.npy', test_preds)\n",
        "print('[INFO] Saved xgb_oof_preds.npy and xgb_test_preds.npy')\n",
        "\n",
        "sub = pd.DataFrame({\n",
        "    'Id': test['Id'].values if 'Id' in test.columns else np.arange(len(test)),\n",
        "    'Cover_Type': np.argmax(test_preds, axis=1) + 1\n",
        "})\n",
        "sub.to_csv('submission_xgb.csv', index=False)\n",
        "print('[INFO] Saved submission_xgb.csv')\n",
        "print(f\"[DONE] Total elapsed: {time.time()-t0:.1f}s\")"
      ],
      "execution_count": 2,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}