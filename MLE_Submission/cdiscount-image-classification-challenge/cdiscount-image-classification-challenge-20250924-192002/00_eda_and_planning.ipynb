{
  "cells": [
    {
      "id": "c54753fe-1639-4fb0-8350-012e3ea1c712",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan to WIN A MEDAL \u2013 Cdiscount Image Classification\n",
        "\n",
        "Objectives:\n",
        "- Build a robust, GPU-accelerated image classification pipeline for 5k+ classes\n",
        "- Establish trustworthy CV and fast baselines; iterate to strong accuracy\n",
        "- Produce a valid submission.csv ASAP, then improve\n",
        "\n",
        "Workflow:\n",
        "1) Environment & GPU\n",
        "- Verify GPU availability (nvidia-smi), install PyTorch CUDA 12.1 stack if needed\n",
        "- Create constraints to lock torch versions; avoid drift\n",
        "\n",
        "2) Data understanding\n",
        "- Inspect files: train.bson, test.bson, train_example.bson, category_names.csv, sample_submission.csv\n",
        "- Determine schema: BSON contains products, each with multiple images and category_id (train only)\n",
        "- Map category_id <-> class index; confirm number of classes\n",
        "\n",
        "3) Reader & Dataset\n",
        "- Implement BSON streaming reader (avoid loading entire file in memory)\n",
        "- For train: expand to (product_id, image_index) samples with label; for test: (product_id, image_index)\n",
        "- Use JPEG decode from bytes (PIL) and standard transforms; cache occasional decoded bytes if RAM allows\n",
        "\n",
        "4) CV Protocol\n",
        "- StratifiedGroupKFold by product_id grouped, stratified on category_id\n",
        "- Single deterministic split first (e.g., 90/10) to iterate fast; later move to 5-fold if time\n",
        "- Aggregate per-product predictions by mean of image logits\n",
        "\n",
        "5) Baseline Model (fast)\n",
        "- Use torchvision/timm pretrained backbone at 180x180: e.g., efficientnet_b0, convnext_tiny, or resnet50\n",
        "- Replace head with num_classes; use label-smoothing CE\n",
        "- Optim: AdamW, cosine schedule, warmup; amp autocast; EMA head optional\n",
        "- Data aug: RandomResizedCrop(180), HFlip; test-time: center-crop only\n",
        "\n",
        "6) Training Loop\n",
        "- Mixed precision, gradient accumulation if needed; log every N steps with elapsed time\n",
        "- Early stopping by val accuracy; save best weights per fold\n",
        "\n",
        "7) Inference\n",
        "- Predict per-image, aggregate per-product (mean logits), argmax category_id\n",
        "- Write submission.csv with correct columns\n",
        "\n",
        "8) Iterations to Medal\n",
        "- Resolution sweep: 224, 256 short runs\n",
        "- Stronger backbones: convnext_tiny/base, efficientnet_b3, vit_tiny/base (if time)\n",
        "- Class-balanced sampling / reweighting; focal loss trial\n",
        "- Ensembling: average logits from 2\u20133 diverse seeds/backbones\n",
        "\n",
        "9) Validation Rigor\n",
        "- Save folds, OOF logits; compute accuracy by product and by image\n",
        "- Inspect per-class accuracy and top-k errors; adjust sampling/augmentations\n",
        "\n",
        "10) Time Management\n",
        "- Start with train_example.bson to validate pipeline and submission\n",
        "- Scale to a subset of train (e.g., 200k products) for fast baseline\n",
        "- Only then run full training; keep logs; consider interrupting long runs based on expert advice"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0ca82902-e859-4d8d-8a70-656b72df213d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install BSON dependency (provided by pymongo)\n",
        "import sys, subprocess\n",
        "def pip(*args):\n",
        "    print('> pip', *args, flush=True)\n",
        "    return subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "pip('install', 'pymongo')\n",
        "print('pymongo installed for bson import')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c43cfe0d-4bb5-47c5-99ed-58b0c64abfec",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & GPU check + Torch cu121 install, quick data peek\n",
        "import os, sys, shutil, subprocess, time, json, bson, struct, io\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "def run(cmd):\n",
        "    print('>',' '.join(cmd), flush=True)\n",
        "    return subprocess.run(cmd, check=False, text=True, capture_output=True)\n",
        "\n",
        "print('=== NVIDIA SMI ===', flush=True)\n",
        "print(run(['bash','-lc','nvidia-smi || true']).stdout)\n",
        "\n",
        "# Clean any preinstalled torch stacks to avoid CUDA mismatch\n",
        "for pkg in (\"torch\",\"torchvision\",\"torchaudio\"):\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg], check=False)\n",
        "\n",
        "# Remove possible shadow dirs\n",
        "for d in (\n",
        "    \"/app/.pip-target/torch\",\n",
        "    \"/app/.pip-target/torchvision\",\n",
        "    \"/app/.pip-target/torchaudio\",\n",
        "    \"/app/.pip-target/torch-2.4.1.dist-info\",\n",
        "    \"/app/.pip-target/torchvision-0.19.1.dist-info\",\n",
        "    \"/app/.pip-target/torchaudio-2.4.1.dist-info\",\n",
        "    \"/app/.pip-target/torchgen\",\n",
        "    \"/app/.pip-target/functorch\",\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d, flush=True)\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "def pip(*args):\n",
        "    print('> pip', *args, flush=True)\n",
        "    return subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Install exact cu121 torch stack\n",
        "pip('install',\n",
        "    '--index-url','https://download.pytorch.org/whl/cu121',\n",
        "    '--extra-index-url','https://pypi.org/simple',\n",
        "    'torch==2.4.1','torchvision==0.19.1','torchaudio==2.4.1')\n",
        "\n",
        "# Freeze torch versions for later installs\n",
        "Path('constraints.txt').write_text('torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n')\n",
        "\n",
        "import torch\n",
        "print('torch:', torch.__version__, 'CUDA build:', getattr(torch.version,'cuda',None))\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f\"Wrong CUDA build: {torch.version.cuda}\"\n",
        "assert torch.cuda.is_available(), 'CUDA not available'\n",
        "\n",
        "print('\\n=== Repo contents ===')\n",
        "for p in sorted(Path('.').glob('*')):\n",
        "    try:\n",
        "        sz = p.stat().st_size\n",
        "    except Exception:\n",
        "        sz = -1\n",
        "    print(f\"{p.name}\\t{sz/1e6:.1f} MB\")\n",
        "\n",
        "# Quick CSV peeks\n",
        "if Path('sample_submission.csv').exists():\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    print('\\nSample submission shape:', ss.shape)\n",
        "    print(ss.head())\n",
        "if Path('category_names.csv').exists():\n",
        "    cat = pd.read_csv('category_names.csv')\n",
        "    print('\\nCategory names shape:', cat.shape)\n",
        "    print(cat.head())\n",
        "\n",
        "# Peek a few BSON docs from train_example to confirm schema\n",
        "def peek_bson(path, n=3):\n",
        "    print(f'\\nPeeking {n} docs from {path}...')\n",
        "    c = 0\n",
        "    with open(path, 'rb') as f:\n",
        "        while c < n:\n",
        "            len_bytes = f.read(4)\n",
        "            if not len_bytes or len(len_bytes) < 4:\n",
        "                break\n",
        "            (doc_len,) = struct.unpack('<i', len_bytes)\n",
        "            rest = f.read(doc_len - 4)\n",
        "            if len(rest) < doc_len - 4:\n",
        "                break\n",
        "            try:\n",
        "                d = bson.BSON(len_bytes + rest).decode()\n",
        "            except Exception as e:\n",
        "                print('Decode error:', e)\n",
        "                continue\n",
        "            keys = list(d.keys())\n",
        "            print('Doc keys:', keys)\n",
        "            print({k: type(d[k]).__name__ for k in keys})\n",
        "            if '_id' in d:\n",
        "                print('product_id:', d['_id'])\n",
        "            if 'category_id' in d:\n",
        "                print('category_id:', d['category_id'])\n",
        "            if 'imgs' in d:\n",
        "                print('n_imgs:', len(d['imgs']))\n",
        "            c += 1\n",
        "\n",
        "if Path('train_example.bson').exists():\n",
        "    peek_bson('train_example.bson', n=3)\n",
        "elif Path('train.bson').exists():\n",
        "    # Fallback to full train if example is absent (will be slow, we only read 1-3 docs)\n",
        "    peek_bson('train.bson', n=3)\n",
        "\n",
        "print('\\nSETUP COMPLETE', flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "4c035882-7926-437e-97b4-ee09b524882e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# BSON indexing utilities: build product-level index and category mappings\n",
        "import os, struct, json, io\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "def build_bson_index(bson_path, out_index_csv, is_train=True, max_docs=None, log_every=100000):\n",
        "    rows = []\n",
        "    bson_path = Path(bson_path)\n",
        "    total = bson_path.stat().st_size\n",
        "    with open(bson_path, 'rb') as f:\n",
        "        ofs = 0\n",
        "        i = 0\n",
        "        while True:\n",
        "            len_bytes = f.read(4)\n",
        "            if not len_bytes or len(len_bytes) < 4:\n",
        "                break\n",
        "            (doc_len,) = struct.unpack('<i', len_bytes)\n",
        "            rest = f.read(doc_len - 4)\n",
        "            if len(rest) < doc_len - 4:\n",
        "                break\n",
        "            try:\n",
        "                import bson as _bson\n",
        "                d = _bson.BSON(len_bytes + rest).decode()\n",
        "            except Exception:\n",
        "                # skip corrupted doc; advance offset anyway\n",
        "                ofs += doc_len\n",
        "                i += 1\n",
        "                continue\n",
        "            prod_id = d.get('_id')\n",
        "            imgs = d.get('imgs', [])\n",
        "            n_imgs = len(imgs) if isinstance(imgs, list) else 0\n",
        "            cat_id = d.get('category_id') if is_train else None\n",
        "            rows.append({\n",
        "                'offset': ofs,\n",
        "                '_id': prod_id,\n",
        "                'n_imgs': n_imgs,\n",
        "                'category_id': cat_id if is_train else pd.NA,\n",
        "                'doc_len': doc_len,\n",
        "            })\n",
        "            ofs += doc_len\n",
        "            i += 1\n",
        "            if log_every and (i % log_every == 0):\n",
        "                print(f\"Indexed {i:,} docs, pos {ofs/1e9:.3f} GB / {total/1e9:.3f} GB\", flush=True)\n",
        "            if max_docs is not None and i >= max_docs:\n",
        "                break\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv(out_index_csv, index=False)\n",
        "    print(f\"Saved index: {out_index_csv} with {len(df):,} rows\", flush=True)\n",
        "    return df\n",
        "\n",
        "def build_category_mapping_from_index(train_index_csv, out_map_json):\n",
        "    df = pd.read_csv(train_index_csv)\n",
        "    cats = sorted(df['category_id'].dropna().astype(int).unique().tolist())\n",
        "    cat2idx = {int(c): i for i, c in enumerate(cats)}\n",
        "    idx2cat = {i: int(c) for i, c in enumerate(cats)}\n",
        "    payload = {'cat2idx': cat2idx, 'idx2cat': idx2cat, 'num_classes': len(cats)}\n",
        "    Path(out_map_json).write_text(json.dumps(payload))\n",
        "    print(f\"Saved category mapping to {out_map_json} (num_classes={len(cats)})\", flush=True)\n",
        "    return payload\n",
        "\n",
        "# Dry-run helpers (won't execute automatically):\n",
        "print('Indexing utilities ready. Example usage:', flush=True)\n",
        "print(\"- build_bson_index('train_example.bson', 'train_example_index.csv', is_train=True)\", flush=True)\n",
        "print(\"- build_bson_index('test.bson', 'test_index.csv', is_train=False, max_docs=50000)  # for smoke\", flush=True)\n",
        "print(\"- build_bson_index('train.bson', 'train_index.csv', is_train=True, log_every=200000)\", flush=True)\n",
        "print(\"- build_category_mapping_from_index('train_index.csv', 'category_mapping.json')\", flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "078c9f08-8053-4f3c-a33e-d35d8ad11b73",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build tiny indices/mapping on train_example to validate pipeline\n",
        "from pathlib import Path\n",
        "import pandas as pd, json\n",
        "\n",
        "if Path('train_example.bson').exists():\n",
        "    df_idx = build_bson_index('train_example.bson', 'train_example_index.csv', is_train=True)\n",
        "    print(df_idx.head())\n",
        "    mapping = build_category_mapping_from_index('train_example_index.csv', 'category_mapping_example.json')\n",
        "    print('Mapping keys:', list(mapping.keys()), 'num_classes:', mapping['num_classes'])\n",
        "else:\n",
        "    print('train_example.bson not found; skipping example index build')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c808f5d0-7997-424f-af13-5b1bb2753f17",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build full train/test indices with explicit dtypes and save as parquet (optionally smoke-limit)\n",
        "import pandas as pd, pyarrow as pa, pyarrow.parquet as pq, struct, os, json, time\n",
        "from pathlib import Path\n",
        "import bson as _bson\n",
        "\n",
        "def build_index_parquet(bson_path: str, out_parquet: str, is_train: bool, max_docs=None, log_every=200000):\n",
        "    t0 = time.time()\n",
        "    rows = []\n",
        "    p = Path(bson_path)\n",
        "    total = p.stat().st_size\n",
        "    with open(p, 'rb') as f:\n",
        "        ofs = 0\n",
        "        i = 0\n",
        "        while True:\n",
        "            len_bytes = f.read(4)\n",
        "            if not len_bytes or len(len_bytes) < 4:\n",
        "                break\n",
        "            (doc_len,) = struct.unpack('<i', len_bytes)\n",
        "            rest = f.read(doc_len - 4)\n",
        "            if len(rest) < doc_len - 4:\n",
        "                break\n",
        "            try:\n",
        "                d = _bson.BSON(len_bytes + rest).decode()\n",
        "            except Exception:\n",
        "                ofs += doc_len; i += 1\n",
        "                continue\n",
        "            prod_id = int(d.get('_id'))\n",
        "            imgs = d.get('imgs', [])\n",
        "            n_imgs = len(imgs) if isinstance(imgs, list) else 0\n",
        "            if n_imgs <= 0:\n",
        "                ofs += doc_len; i += 1\n",
        "                continue\n",
        "            cat_id = int(d['category_id']) if is_train else None\n",
        "            rows.append((ofs, prod_id, n_imgs, cat_id if is_train else None, doc_len))\n",
        "            ofs += doc_len\n",
        "            i += 1\n",
        "            if log_every and (i % log_every == 0):\n",
        "                print(f\"Indexed {i:,} docs, pos {ofs/1e9:.3f} GB / {total/1e9:.3f} GB, elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "            if max_docs is not None and i >= max_docs:\n",
        "                break\n",
        "    if not rows:\n",
        "        print('No rows parsed; nothing to write.')\n",
        "        return None\n",
        "    # Build DataFrame with explicit dtypes\n",
        "    df = pd.DataFrame(rows, columns=['offset','_id','n_imgs','category_id','doc_len'])\n",
        "    dtypes = {\n",
        "        'offset': 'int64',\n",
        "        '_id': 'int64',\n",
        "        'n_imgs': 'int16',\n",
        "        'doc_len': 'int32'\n",
        "    }\n",
        "    if is_train:\n",
        "        dtypes['category_id'] = 'Int64'\n",
        "    else:\n",
        "        dtypes['category_id'] = 'Int64'\n",
        "        df['category_id'] = pd.NA\n",
        "    df = df.astype(dtypes)\n",
        "    table = pa.Table.from_pandas(df, preserve_index=False)\n",
        "    pq.write_table(table, out_parquet, compression='zstd')\n",
        "    print(f\"Saved {len(df):,} rows to {out_parquet} in {time.time()-t0:.1f}s\", flush=True)\n",
        "    return out_parquet\n",
        "\n",
        "def ensure_full_indices(smoke=False):\n",
        "    # If smoke=True, limit docs for quick run\n",
        "    train_out = 'train_index.parquet'\n",
        "    test_out = 'test_index.parquet'\n",
        "    if not Path(train_out).exists():\n",
        "        build_index_parquet('train.bson', train_out, is_train=True, max_docs=(50000 if smoke else None))\n",
        "    else:\n",
        "        print(f'{train_out} exists, skipping.')\n",
        "    if not Path(test_out).exists():\n",
        "        build_index_parquet('test.bson', test_out, is_train=False, max_docs=(50000 if smoke else None))\n",
        "    else:\n",
        "        print(f'{test_out} exists, skipping.')\n",
        "    # Build mapping if train index created\n",
        "    if Path(train_out).exists():\n",
        "        df_tr = pd.read_parquet(train_out, columns=['category_id'])\n",
        "        cats = sorted(df_tr['category_id'].dropna().astype(int).unique().tolist())\n",
        "        cat2idx = {int(c): i for i, c in enumerate(cats)}\n",
        "        idx2cat = {i: int(c) for i, c in enumerate(cats)}\n",
        "        payload = {'cat2idx': cat2idx, 'idx2cat': idx2cat, 'num_classes': len(cats)}\n",
        "        Path('category_mapping.json').write_text(json.dumps(payload))\n",
        "        print(f\"Saved category_mapping.json (num_classes={len(cats)})\", flush=True)\n",
        "\n",
        "print('Full-index builder ready. Call ensure_full_indices(smoke=True) for a quick pass, or smoke=False for full run.', flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "43444f79-b6c6-490a-bbf2-a052fdd2fc5c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Smoke-build indices (50k docs) for train/test to validate performance before full pass\n",
        "import time\n",
        "t0 = time.time()\n",
        "print('Starting ensure_full_indices(smoke=True)...')\n",
        "ensure_full_indices(smoke=True)\n",
        "print(f'Done smoke indexing in {time.time()-t0:.1f}s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "52d96107-000f-46e5-995e-9614e56f4f35",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dataset and DataLoader utilities for BSON with per-worker file handles\n",
        "import os, io, random, struct\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFile\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torchvision.transforms as T\n",
        "import bson as _bson\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def load_mapping(path='category_mapping.json'):\n",
        "    import json\n",
        "    m = json.loads(Path(path).read_text())\n",
        "    cat2idx = {int(k): int(v) for k,v in m['cat2idx'].items()}\n",
        "    idx2cat = {int(k): int(v) for k,v in m['idx2cat'].items()}\n",
        "    num_classes = int(m['num_classes'])\n",
        "    return cat2idx, idx2cat, num_classes\n",
        "\n",
        "def read_bson_doc_at(fh, offset):\n",
        "    # fh is a file handle opened in 'rb'\n",
        "    fh.seek(offset)\n",
        "    len_bytes = fh.read(4)\n",
        "    if not len_bytes or len(len_bytes) < 4:\n",
        "        return None\n",
        "    (doc_len,) = struct.unpack('<i', len_bytes)\n",
        "    rest = fh.read(doc_len - 4)\n",
        "    if len(rest) < doc_len - 4:\n",
        "        return None\n",
        "    try:\n",
        "        d = _bson.BSON(len_bytes + rest).decode()\n",
        "        return d\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "class BSONProductTrain(Dataset):\n",
        "    def __init__(self, index_df: pd.DataFrame, bson_path: str, cat2idx: dict, image_size=224):\n",
        "        self.df = index_df.reset_index(drop=True)\n",
        "        self.bson_path = str(bson_path)\n",
        "        self.cat2idx = cat2idx\n",
        "        self._fh = None  # per-worker handle, opened lazily\n",
        "        # Strong but stable aug pipeline\n",
        "        self.transform = T.Compose([\n",
        "            T.RandomResizedCrop(image_size, scale=(0.5, 1.0), ratio=(0.75, 1.33)),\n",
        "            T.RandomHorizontalFlip(0.5),\n",
        "            T.ColorJitter(0.2, 0.2, 0.2, 0.05),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "            T.RandomErasing(p=0.18, scale=(0.02, 0.2), ratio=(0.3, 3.3)),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _ensure_fh(self):\n",
        "        if self._fh is None:\n",
        "            self._fh = open(self.bson_path, 'rb', buffering=0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        self._ensure_fh()\n",
        "        d = read_bson_doc_at(self._fh, int(row['offset']))\n",
        "        # Always set label from index row's category_id mapping (do NOT force class 0 on failures)\n",
        "        cat_id_row = int(row['category_id']) if pd.notna(row['category_id']) else None\n",
        "        y = self.cat2idx.get(cat_id_row, 0) if cat_id_row is not None else 0\n",
        "        if d is None:\n",
        "            # return a dummy image but keep correct label\n",
        "            img = Image.new('RGB', (256,256), color=(128,128,128))\n",
        "            return self.transform(img), y\n",
        "        imgs = d.get('imgs', [])\n",
        "        # pick one random image\n",
        "        choice = random.randrange(len(imgs)) if imgs else 0\n",
        "        pic_bytes = imgs[choice]['picture'] if imgs else None\n",
        "        try:\n",
        "            img = Image.open(io.BytesIO(pic_bytes)).convert('RGB') if pic_bytes is not None else Image.new('RGB',(256,256))\n",
        "        except Exception:\n",
        "            img = Image.new('RGB',(256,256), color=(128,128,128))\n",
        "        x = self.transform(img)\n",
        "        return x, y\n",
        "\n",
        "class BSONImageEval(Dataset):\n",
        "    # Yields one image per item for val/test; aggregate per-product outside\n",
        "    def __init__(self, index_df: pd.DataFrame, bson_path: str, include_label: bool, cat2idx: dict | None, image_size=224):\n",
        "        # expand to per-image rows\n",
        "        rows = []\n",
        "        for _, r in index_df.iterrows():\n",
        "            for k in range(int(r['n_imgs'])):\n",
        "                rows.append((int(r['offset']), int(r['_id']), k, int(r['category_id']) if include_label and pd.notna(r['category_id']) else None))\n",
        "        self.df = pd.DataFrame(rows, columns=['offset','_id','img_idx','category_id'])\n",
        "        # Cheap IO win: process in offset order to improve locality\n",
        "        self.df.sort_values('offset', inplace=True)\n",
        "        self.bson_path = str(bson_path)\n",
        "        self.include_label = include_label\n",
        "        self.cat2idx = cat2idx\n",
        "        self._fh = None\n",
        "        self.transform = T.Compose([\n",
        "            T.Resize(256),\n",
        "            T.CenterCrop(image_size),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _ensure_fh(self):\n",
        "        if self._fh is None:\n",
        "            self._fh = open(self.bson_path, 'rb', buffering=0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]\n",
        "        self._ensure_fh()\n",
        "        d = read_bson_doc_at(self._fh, int(r['offset']))\n",
        "        imgs = d.get('imgs', []) if d is not None else []\n",
        "        pic_bytes = imgs[int(r['img_idx'])]['picture'] if d is not None and imgs else None\n",
        "        try:\n",
        "            img = Image.open(io.BytesIO(pic_bytes)).convert('RGB') if pic_bytes is not None else Image.new('RGB',(256,256))\n",
        "        except Exception:\n",
        "            img = Image.new('RGB',(256,256), color=(128,128,128))\n",
        "        x = self.transform(img)\n",
        "        if self.include_label:\n",
        "            cat_id = int(r['category_id']) if r['category_id'] is not None and pd.notna(r['category_id']) else None\n",
        "            y = self.cat2idx.get(cat_id, 0) if (self.cat2idx is not None and cat_id is not None) else -1\n",
        "            return x, int(r['_id']), int(r['img_idx']), y\n",
        "        else:\n",
        "            return x, int(r['_id']), int(r['img_idx'])\n",
        "\n",
        "def make_dataloaders_for_smoke(train_index_path='train_index.parquet', batch_size=64, num_workers=8):\n",
        "    cat2idx, idx2cat, num_classes = load_mapping('category_mapping.json')\n",
        "    dft = pd.read_parquet(train_index_path)\n",
        "    # small subset for smoke: 2k products\n",
        "    dft = dft.sample(n=min(2000, len(dft)), random_state=42).reset_index(drop=True)\n",
        "    # split 90/10 stratified by category at product level\n",
        "    from sklearn.model_selection import StratifiedGroupKFold\n",
        "    y = dft['category_id'].astype(int)\n",
        "    g = dft['_id'].astype(int)\n",
        "    skf = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    tr_idx, va_idx = next(skf.split(dft, y, g))\n",
        "    df_tr = dft.iloc[tr_idx].reset_index(drop=True)\n",
        "    df_va = dft.iloc[va_idx].reset_index(drop=True)\n",
        "    ds_tr = BSONProductTrain(df_tr, 'train.bson', cat2idx, image_size=192)\n",
        "    ds_va = BSONImageEval(df_va, 'train.bson', include_label=True, cat2idx=cat2idx, image_size=192)\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True, prefetch_factor=4, drop_last=True)\n",
        "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True, prefetch_factor=4)\n",
        "    return dl_tr, dl_va, num_classes, (df_tr, df_va)\n",
        "\n",
        "print('Dataset classes ready. Next: create loaders with make_dataloaders_for_smoke() and wire a minimal ConvNeXt-Tiny training loop.', flush=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset classes ready. Next: create loaders with make_dataloaders_for_smoke() and wire a minimal ConvNeXt-Tiny training loop.\n"
          ]
        }
      ]
    },
    {
      "id": "1b5ff29a-6e95-496f-807e-d99daf87108a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install timm, create smoke loaders, and sanity-check a couple batches\n",
        "import sys, subprocess, time, torch\n",
        "from pathlib import Path\n",
        "\n",
        "def pip(*args):\n",
        "    print('> pip', *args, flush=True)\n",
        "    return subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Install timm honoring torch constraints but without touching torch stack\n",
        "if not Path('installed_timm.flag').exists():\n",
        "    pip('install', '-c', 'constraints.txt', 'timm==1.0.9', '--upgrade-strategy', 'only-if-needed', '--no-deps')\n",
        "    Path('installed_timm.flag').write_text('ok')\n",
        "    print('timm installed')\n",
        "else:\n",
        "    print('timm already installed')\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "dl_tr, dl_va, num_classes, (df_tr, df_va) = make_dataloaders_for_smoke(batch_size=128, num_workers=12)\n",
        "print('num_classes:', num_classes, 'train products:', len(df_tr), 'val products:', len(df_va))\n",
        "\n",
        "# Fetch a couple of train batches and move to GPU to validate shapes and throughput\n",
        "t0 = time.time()\n",
        "for bi, (x, y) in enumerate(dl_tr):\n",
        "    x = x.cuda(non_blocking=True)\n",
        "    y = y.cuda(non_blocking=True)\n",
        "    if bi == 0:\n",
        "        print('Train batch 0:', x.shape, y.shape, 'GPU mem (MB):', torch.cuda.memory_allocated()/1e6)\n",
        "    if bi >= 2:\n",
        "        break\n",
        "print('Train fetch elapsed:', time.time()-t0, 's')\n",
        "\n",
        "# Fetch a couple of val batches\n",
        "t1 = time.time()\n",
        "for bi, batch in enumerate(dl_va):\n",
        "    # dl_va yields (x, _id, img_idx, y)\n",
        "    x = batch[0].cuda(non_blocking=True)\n",
        "    if bi == 0:\n",
        "        print('Val batch 0 x-shape:', x.shape)\n",
        "    if bi >= 2:\n",
        "        break\n",
        "print('Val fetch elapsed:', time.time()-t1, 's')\n",
        "\n",
        "print('Smoke loaders OK')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f3e3e580-2d27-4a35-90c5-afb20661e64c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Minimal ConvNeXt-Tiny training loop (smoke) with product-level validation\n",
        "import time, math, collections\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import timm\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, scaler, device, log_every=20):\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1).to(device)\n",
        "    total, correct, running_loss = 0, 0, 0.0\n",
        "    t0 = time.time()\n",
        "    for i, (x, y) in enumerate(loader):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast():\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item() * x.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total += y.size(0)\n",
        "        correct += (preds == y).sum().item()\n",
        "        if (i+1) % log_every == 0:\n",
        "            elapsed = time.time() - t0\n",
        "            print(f\"  iter {i+1}/{len(loader)}  loss={(running_loss/total):.4f}  acc={(correct/total):.4f}  elapsed={elapsed:.1f}s\", flush=True)\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "def validate_product_level(model, loader, df_va, cat2idx, device):\n",
        "    model.eval()\n",
        "    # True label per product_id\n",
        "    id2y = {int(r['_id']): cat2idx[int(r['category_id'])] for _, r in df_va.iterrows()}\n",
        "    agg_logits = {}  # _id -> sum logits\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            # batch: (x, _id, img_idx, y)\n",
        "            x = batch[0].to(device, non_blocking=True)\n",
        "            ids = batch[1].tolist()\n",
        "            with autocast():\n",
        "                logits = model(x).float().cpu()  # [B, C]\n",
        "            for pid, logit in zip(ids, logits):\n",
        "                if pid not in agg_logits:\n",
        "                    agg_logits[pid] = logit.clone()\n",
        "                else:\n",
        "                    agg_logits[pid] += logit\n",
        "    # Compute product-level accuracy\n",
        "    correct = 0\n",
        "    for pid, logit in agg_logits.items():\n",
        "        pred = int(logit.argmax().item())\n",
        "        if pid in id2y and pred == id2y[pid]:\n",
        "            correct += 1\n",
        "    total = len(id2y)\n",
        "    acc = correct / max(1, total)\n",
        "    return acc\n",
        "\n",
        "def run_smoke_training(epochs=1, lr=1e-3, wd=0.05):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    dl_tr, dl_va, num_classes, (df_tr, df_va) = make_dataloaders_for_smoke(batch_size=128, num_workers=12)\n",
        "    cat2idx, idx2cat, _ = load_mapping('category_mapping.json')\n",
        "    model = timm.create_model('convnext_tiny', pretrained=True, num_classes=num_classes)\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scaler = GradScaler()\n",
        "    best_acc = -1.0\n",
        "    for ep in range(1, epochs+1):\n",
        "        print(f\"Epoch {ep}/{epochs}\")\n",
        "        tr_loss, tr_acc = train_one_epoch(model, dl_tr, optimizer, scaler, device, log_every=10)\n",
        "        va_acc = validate_product_level(model, dl_va, df_va, cat2idx, device)\n",
        "        print(f\"  Train loss={tr_loss:.4f} acc={tr_acc:.4f} | Val product-acc={va_acc:.4f}\", flush=True)\n",
        "        if va_acc > best_acc:\n",
        "            best_acc = va_acc\n",
        "            torch.save({'model': model.state_dict(), 'val_acc': va_acc}, 'model_smoke_convnext_tiny.pt')\n",
        "            print(f\"  Saved checkpoint with val_acc={va_acc:.4f}\")\n",
        "    print(f\"Best val product-acc: {best_acc:.4f}\")\n",
        "    return best_acc\n",
        "\n",
        "print('Smoke training utilities ready. Call run_smoke_training(epochs=1) to validate end-to-end.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "5f3d9295-7bf8-4653-9464-056ef97dd429",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install missing dependency and run smoke training for 1 epoch\n",
        "import sys, subprocess, time, os\n",
        "from pathlib import Path\n",
        "\n",
        "def pip(*args):\n",
        "    print('> pip', *args, flush=True)\n",
        "    return subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Ensure huggingface_hub is available for timm pretrained weights without touching torch stack\n",
        "if not Path('installed_hfhub.flag').exists():\n",
        "    pip('install', '-c', 'constraints.txt', 'huggingface_hub==0.35.1', '--upgrade-strategy', 'only-if-needed', '--no-deps')\n",
        "    Path('installed_hfhub.flag').write_text('ok')\n",
        "    print('huggingface_hub installed')\n",
        "else:\n",
        "    print('huggingface_hub already installed')\n",
        "\n",
        "t0 = time.time()\n",
        "acc = run_smoke_training(epochs=1, lr=1e-3, wd=0.05)\n",
        "print(f'Smoke training done in {time.time()-t0:.1f}s, val product-acc={acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a044cc60-45b0-438f-bc3b-a08a91684a46",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reload timm hub to pick up newly installed huggingface_hub, then run smoke training\n",
        "import importlib, timm, time\n",
        "import timm.models._hub as timm_hub\n",
        "importlib.reload(timm_hub)\n",
        "print('Reloaded timm.models._hub; has_hf_hub should be True now.')\n",
        "t0 = time.time()\n",
        "acc = run_smoke_training(epochs=1, lr=1e-3, wd=0.05)\n",
        "print(f'Smoke training done in {time.time()-t0:.1f}s, val product-acc={acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "fa14a274-60a4-4c98-8f9e-43a95e4b07f6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build full indices (train/test) and full mapping\n",
        "import time\n",
        "t0 = time.time()\n",
        "print('Starting ensure_full_indices(smoke=False)...')\n",
        "ensure_full_indices(smoke=False)\n",
        "print(f'Done full indexing in {time.time()-t0:.1f}s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0b6544e9-ee26-4084-8983-ea3196fb9f5a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# FORCE full reindex (overwrite smoke parquet) to get full class mapping (~5270)\n",
        "from pathlib import Path\n",
        "import pandas as pd, json\n",
        "print('Removing existing parquets if present...')\n",
        "for p in ['train_index.parquet','test_index.parquet']:\n",
        "    if Path(p).exists():\n",
        "        Path(p).unlink()\n",
        "        print('Deleted', p)\n",
        "print('Building full train index...')\n",
        "build_index_parquet('train.bson', 'train_index.parquet', is_train=True, max_docs=None, log_every=200000)\n",
        "print('Building full test index...')\n",
        "build_index_parquet('test.bson', 'test_index.parquet', is_train=False, max_docs=None, log_every=200000)\n",
        "print('Rebuilding full category mapping...')\n",
        "df_tr = pd.read_parquet('train_index.parquet', columns=['category_id'])\n",
        "cats = sorted(df_tr['category_id'].dropna().astype(int).unique().tolist())\n",
        "cat2idx = {int(c): i for i, c in enumerate(cats)}\n",
        "idx2cat = {i: int(c) for i, c in enumerate(cats)}\n",
        "payload = {'cat2idx': cat2idx, 'idx2cat': idx2cat, 'num_classes': len(cats)}\n",
        "Path('category_mapping.json').write_text(json.dumps(payload))\n",
        "print('Full mapping saved. num_classes =', len(cats))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "db039c37-68d0-4883-a7d5-b4b4ad097d9f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build 200k balanced subset (q-cap + 1/sqrt(freq) top-up) and persist SGKF 90/10 split\n",
        "import math, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "\n",
        "train_idx_path = 'train_index.parquet'\n",
        "assert Path(train_idx_path).exists(), 'train_index.parquet not found'\n",
        "df = pd.read_parquet(train_idx_path, columns=['_id','category_id','offset','n_imgs'])\n",
        "df = df.dropna(subset=['category_id']).copy()\n",
        "df['category_id'] = df['category_id'].astype(np.int64)\n",
        "\n",
        "# Compute class freq\n",
        "freq = df['category_id'].value_counts().rename_axis('category_id').reset_index(name='freq')\n",
        "n_classes = freq.shape[0]\n",
        "target_n = 200_000\n",
        "q = int(math.ceil(target_n / n_classes))\n",
        "print('Classes:', n_classes, 'target subset size:', target_n, 'q per class:', q)\n",
        "\n",
        "# Per-class cap sample\n",
        "df_grouped = df.groupby('category_id', group_keys=False)\n",
        "def take_q(g):\n",
        "    n = len(g)\n",
        "    k = min(q, n) if n > 0 else 0\n",
        "    if k == 0:\n",
        "        return g.iloc[:0]\n",
        "    return g.sample(n=k, random_state=42, replace=False)\n",
        "cap_df = df_grouped.apply(take_q).reset_index(drop=True)\n",
        "print('After cap sample:', len(cap_df))\n",
        "\n",
        "# Top-up if needed with p(c) \u221d 1/sqrt(f_c) from remaining products\n",
        "remaining = df.merge(cap_df[['_id']], on='_id', how='left', indicator=True)\n",
        "remaining = remaining[remaining['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
        "if len(cap_df) < target_n and len(remaining) > 0:\n",
        "    freq_map = freq.set_index('category_id')['freq'].to_dict()\n",
        "    w = remaining['category_id'].map(lambda c: 1.0 / math.sqrt(freq_map.get(int(c), 1)))\n",
        "    w = w / w.sum()\n",
        "    need = target_n - len(cap_df)\n",
        "    need = min(need, len(remaining))\n",
        "    top_idx = remaining.sample(n=need, weights=w, random_state=42).index\n",
        "    top_df = remaining.loc[top_idx]\n",
        "    sub_df = pd.concat([cap_df, top_df], axis=0, ignore_index=True)\n",
        "else:\n",
        "    sub_df = cap_df\n",
        "sub_df = sub_df.drop_duplicates('_id')\n",
        "print('Final subset size:', len(sub_df))\n",
        "\n",
        "# Persist subset product_ids\n",
        "sub_ids = sub_df['_id'].astype(np.int64).tolist()\n",
        "pd.Series(sub_ids, name='_id').to_csv('subset_200k_ids.csv', index=False)\n",
        "print('Saved subset_200k_ids.csv')\n",
        "\n",
        "# SGKF 90/10 split within subset\n",
        "y = sub_df['category_id'].astype(np.int64).values\n",
        "g = sub_df['_id'].astype(np.int64).values\n",
        "skf = StratifiedGroupKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "tr_idx, va_idx = next(skf.split(sub_df, y, g))\n",
        "train_ids = sub_df.iloc[tr_idx]['_id'].astype(np.int64).tolist()\n",
        "val_ids = sub_df.iloc[va_idx]['_id'].astype(np.int64).tolist()\n",
        "pd.Series(train_ids, name='_id').to_csv('train_ids.csv', index=False)\n",
        "pd.Series(val_ids, name='_id').to_csv('val_ids.csv', index=False)\n",
        "print('Saved train_ids.csv:', len(train_ids), 'val_ids.csv:', len(val_ids))\n",
        "\n",
        "# Quick coverage check\n",
        "print('Covered classes in subset:', sub_df['category_id'].nunique())\n",
        "print('Covered classes in train split:', sub_df.iloc[tr_idx]['category_id'].nunique())\n",
        "print('Covered classes in val split:', sub_df.iloc[va_idx]['category_id'].nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7ce014c4-96e5-4bf6-8619-07b2727d6033",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train ConvNeXt-Tiny@192 on 200k subset (2-3 epochs) for quick LB check; then prepare inference util\n",
        "import time, math, collections, io, numpy as np, pandas as pd, torch, torch.nn as nn, torch.optim as optim\n",
        "from torch import amp\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "def make_subset_loaders(batch_size=128, num_workers=16, image_size=192):\n",
        "    # Load full mapping and index\n",
        "    cat2idx, idx2cat, num_classes = load_mapping('category_mapping.json')\n",
        "    dfi = pd.read_parquet('train_index.parquet')\n",
        "    train_ids = pd.read_csv('train_ids.csv')['_id'].astype(np.int64).tolist()\n",
        "    val_ids = pd.read_csv('val_ids.csv')['_id'].astype(np.int64).tolist()\n",
        "    df_tr = dfi[dfi['_id'].isin(train_ids)].reset_index(drop=True)\n",
        "    df_va = dfi[dfi['_id'].isin(val_ids)].reset_index(drop=True)\n",
        "    ds_tr = BSONProductTrain(df_tr, 'train.bson', cat2idx, image_size=image_size)\n",
        "    ds_va = BSONImageEval(df_va, 'train.bson', include_label=True, cat2idx=cat2idx, image_size=image_size)\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True,\n",
        "                       persistent_workers=True, prefetch_factor=8, drop_last=True)\n",
        "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True,\n",
        "                       persistent_workers=True, prefetch_factor=12)\n",
        "    return dl_tr, dl_va, df_tr, df_va, num_classes, cat2idx, idx2cat\n",
        "\n",
        "def compute_class_weights(df_tr, cat2idx):\n",
        "    # w_c \u221d 1/sqrt(freq_c), normalized to mean=1\n",
        "    freq = df_tr['category_id'].value_counts().to_dict()\n",
        "    num_classes = len(cat2idx)\n",
        "    w = np.ones(num_classes, dtype=np.float32)\n",
        "    for cat, idx in cat2idx.items():\n",
        "        f = freq.get(int(cat), 1)\n",
        "        w[idx] = 1.0 / math.sqrt(float(f))\n",
        "    w = w / (w.mean() + 1e-9)\n",
        "    return torch.tensor(w, dtype=torch.float32)\n",
        "\n",
        "def train_epoch(model, loader, optimizer, scaler, device, criterion, sched=None, accum_steps=2, log_every=200, ep_offset=0, model_ema=None, ep_offset_updates=0):\n",
        "    model.train()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    t0 = time.time()\n",
        "    upd_idx = 0\n",
        "    for it, (x, y) in enumerate(loader):\n",
        "        x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        with amp.autocast('cuda'):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y) / accum_steps\n",
        "        scaler.scale(loss).backward()\n",
        "        if (it + 1) % accum_steps == 0:\n",
        "            # grad clip\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            if model_ema is not None:\n",
        "                model_ema.update(model)\n",
        "            # step scheduler per optimizer update (not per micro-iter)\n",
        "            if sched is not None:\n",
        "                upd_idx += 1\n",
        "                sched.step_update(ep_offset_updates + upd_idx)\n",
        "        preds = logits.detach().argmax(1)\n",
        "        total += y.size(0)\n",
        "        correct += (preds == y).sum().item()\n",
        "        loss_sum += loss.item() * accum_steps * x.size(0)\n",
        "        if (it + 1) % log_every == 0:\n",
        "            print(f\"  it {it+1}/{len(loader)} loss={loss_sum/total:.4f} acc={correct/total:.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "    return loss_sum/total, correct/total\n",
        "\n",
        "def validate_products(model, loader, df_va, cat2idx, device):\n",
        "    model.eval()\n",
        "    id2y = {int(r['_id']): cat2idx[int(r['category_id'])] for _, r in df_va.iterrows()}\n",
        "    agg = {}\n",
        "    cnt = {}\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            x = batch[0].to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            ids = batch[1].tolist()\n",
        "            with amp.autocast('cuda'):\n",
        "                logits = model(x).float().cpu()\n",
        "            for pid, logit in zip(ids, logits):\n",
        "                if pid not in agg:\n",
        "                    agg[pid] = torch.zeros_like(logit)\n",
        "                    cnt[pid] = 0\n",
        "                agg[pid] += logit\n",
        "                cnt[pid] += 1\n",
        "    correct = 0\n",
        "    for pid, logit in agg.items():\n",
        "        m = logit / max(1, cnt.get(pid, 1))\n",
        "        if int(pid) in id2y and int(m.argmax().item()) == id2y[int(pid)]:\n",
        "            correct += 1\n",
        "    return correct / max(1, len(id2y))\n",
        "\n",
        "def train_convnext_tiny_subset(epochs=2, lr=1e-3, wd=0.05, image_size=192, batch_size=128, accum_steps=2):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    dl_tr, dl_va, df_tr, df_va, num_classes, cat2idx, idx2cat = make_subset_loaders(batch_size=batch_size, num_workers=16, image_size=image_size)\n",
        "    model = timm.create_model('convnext_tiny', pretrained=True, num_classes=num_classes).to(device)\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    # EMA\n",
        "    model_ema = ModelEmaV2(model, decay=0.9997)\n",
        "    # Class-weighted CE with smoothing\n",
        "    cls_w = compute_class_weights(df_tr, cat2idx).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1, weight=cls_w)\n",
        "    scaler = amp.GradScaler('cuda')\n",
        "    # Scheduler: 1 epoch warmup + cosine to 1e-6, step per optimizer update\n",
        "    steps_per_epoch = len(dl_tr)\n",
        "    updates_per_epoch = int(math.ceil(steps_per_epoch / max(1, accum_steps)))\n",
        "    total_updates = updates_per_epoch * epochs\n",
        "    warmup_updates = updates_per_epoch  # 1 epoch warmup\n",
        "    sched = CosineLRScheduler(\n",
        "        optimizer, t_initial=max(1, total_updates - warmup_updates), lr_min=1e-6,\n",
        "        warmup_t=warmup_updates, warmup_lr_init=1e-5, t_in_epochs=False\n",
        "    )\n",
        "    best_acc = -1.0\n",
        "    for ep in range(1, epochs+1):\n",
        "        print(f\"Epoch {ep}/{epochs}\")\n",
        "        ep_offset = (ep - 1) * steps_per_epoch\n",
        "        ep_offset_updates = (ep - 1) * updates_per_epoch\n",
        "        tr_loss, tr_acc = train_epoch(model, dl_tr, optimizer, scaler, device, criterion, sched=sched, accum_steps=accum_steps, log_every=200, ep_offset=ep_offset, model_ema=model_ema, ep_offset_updates=ep_offset_updates)\n",
        "        va_acc = validate_products(model_ema.module, dl_va, df_va, cat2idx, device)\n",
        "        print(f\"  train loss={tr_loss:.4f} acc={tr_acc:.4f} | val product-acc={va_acc:.4f}\", flush=True)\n",
        "        if va_acc > best_acc:\n",
        "            best_acc = va_acc\n",
        "            torch.save({'model': model_ema.module.state_dict(), 'val_acc': va_acc}, 'ckpt_tiny_subset.pt')\n",
        "            print(f\"  Saved ckpt_tiny_subset.pt (EMA, val_acc={va_acc:.4f})\")\n",
        "    return best_acc\n",
        "\n",
        "print('Subset training utilities ready. Next: run acc = train_convnext_tiny_subset(epochs=2) and then implement test inference & submission.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset training utilities ready. Next: run acc = train_convnext_tiny_subset(epochs=2) and then implement test inference & submission.\n"
          ]
        }
      ]
    },
    {
      "id": "ae9b5199-cf64-4901-a288-2f7fb4653496",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Launch 2-epoch training on 200k subset (ConvNeXt-Tiny@192) with EMA + cosine schedule\n",
        "import time\n",
        "t0 = time.time()\n",
        "acc = train_convnext_tiny_subset(epochs=2, lr=1e-3, wd=0.05, image_size=192, batch_size=128, accum_steps=2)\n",
        "print(f'Training finished in {time.time()-t0:.1f}s, best val product-acc={acc:.5f}', flush=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 200/1406 loss=8.6756 acc=0.0003 elapsed=36.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 400/1406 loss=8.5689 acc=0.0018 elapsed=71.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 600/1406 loss=8.3278 acc=0.0081 elapsed=105.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 800/1406 loss=8.0837 acc=0.0171 elapsed=140.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 1000/1406 loss=7.8805 acc=0.0257 elapsed=175.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 1200/1406 loss=7.7187 acc=0.0329 elapsed=210.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 1400/1406 loss=7.5911 acc=0.0393 elapsed=245.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train loss=7.5874 acc=0.0396 | val product-acc=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_tiny_subset.pt (EMA, val_acc=0.0020)\nEpoch 2/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 200/1406 loss=6.3735 acc=0.1112 elapsed=35.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 400/1406 loss=6.3342 acc=0.1159 elapsed=70.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 600/1406 loss=6.3104 acc=0.1176 elapsed=106.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 800/1406 loss=6.2916 acc=0.1198 elapsed=141.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 1000/1406 loss=6.2759 acc=0.1209 elapsed=176.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 1200/1406 loss=6.2602 acc=0.1232 elapsed=211.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  it 1400/1406 loss=6.2481 acc=0.1248 elapsed=247.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train loss=6.2467 acc=0.1249 | val product-acc=0.0573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_tiny_subset.pt (EMA, val_acc=0.0573)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training finished in 539.5s, best val product-acc=0.05735\n"
          ]
        }
      ]
    },
    {
      "id": "c9d88343-af6b-45cd-b32f-de566080579f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity checks: unseen val classes, label mismatches, class-weight extremes, quick val image-acc probe\n",
        "import numpy as np, pandas as pd, torch\n",
        "\n",
        "cat2idx, idx2cat, num_classes = load_mapping('category_mapping.json')\n",
        "dfi = pd.read_parquet('train_index.parquet')\n",
        "train_ids = pd.read_csv('train_ids.csv')['_id'].astype(np.int64).tolist()\n",
        "val_ids = pd.read_csv('val_ids.csv')['_id'].astype(np.int64).tolist()\n",
        "df_tr = dfi[dfi['_id'].isin(train_ids)].reset_index(drop=True)\n",
        "df_va = dfi[dfi['_id'].isin(val_ids)].reset_index(drop=True)\n",
        "\n",
        "# 1) Unseen-in-train classes check\n",
        "seen_tr = set(df_tr['category_id'].dropna().astype(int).unique().tolist())\n",
        "seen_va = set(df_va['category_id'].dropna().astype(int).unique().tolist())\n",
        "unseen = seen_va - seen_tr\n",
        "print('Unseen val classes count:', len(unseen))\n",
        "print('Val products affected:', df_va[df_va['category_id'].isin(list(unseen))].shape[0])\n",
        "\n",
        "# 2) Build val loader and check label consistency on a few batches\n",
        "ds_va = BSONImageEval(df_va, 'train.bson', include_label=True, cat2idx=cat2idx, image_size=192)\n",
        "from torch.utils.data import DataLoader\n",
        "dl_va = DataLoader(ds_va, batch_size=128, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=False, prefetch_factor=8)\n",
        "id2y = {int(r['_id']): cat2idx[int(r['category_id'])] for _, r in df_va.iterrows()}\n",
        "mism = 0; checked = 0\n",
        "for bi, batch in enumerate(dl_va):\n",
        "    _, pids, _, ys = batch\n",
        "    pids = pids.tolist(); ys = ys.tolist()\n",
        "    for pid, y in zip(pids, ys):\n",
        "        if id2y.get(int(pid), -999) != int(y):\n",
        "            mism += 1\n",
        "    checked += len(pids)\n",
        "    if checked >= 6400:\n",
        "        break\n",
        "print('Val label mismatches (first ~5k items):', mism)\n",
        "\n",
        "# 3) Class-weight extremes\n",
        "from math import sqrt\n",
        "freq = df_tr['category_id'].value_counts().to_dict()\n",
        "w = np.ones(len(cat2idx), dtype=np.float32)\n",
        "for cat, idx in cat2idx.items():\n",
        "    w[idx] = 1.0 / sqrt(float(freq.get(int(cat), 1)))\n",
        "w = w / (w.mean() + 1e-9)\n",
        "print('Class weight stats: min/median/max =', float(w.min()), float(np.median(w)), float(w.max()))\n",
        "\n",
        "# 4) Quick image-level val probe on EMA checkpoint (first ~100 batches)\n",
        "ckpt = torch.load('ckpt_tiny_subset.pt', map_location='cpu') if Path('ckpt_tiny_subset.pt').exists() else None\n",
        "img_acc = None\n",
        "if ckpt is not None:\n",
        "    import timm\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = timm.create_model('convnext_tiny', pretrained=False, num_classes=num_classes).to(device).to(memory_format=torch.channels_last)\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    correct = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for bi, batch in enumerate(dl_va):\n",
        "            x = batch[0].to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            y = [id2y[int(pid)] for pid in batch[1].tolist()]\n",
        "            y = torch.tensor(y, device=device, dtype=torch.long)\n",
        "            with torch.amp.autocast('cuda') if device.type=='cuda' else torch.no_grad():\n",
        "                logits = model(x)\n",
        "            pred = logits.argmax(1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "            if bi >= 100:\n",
        "                break\n",
        "    img_acc = correct / max(1, total)\n",
        "print('Quick image-level val acc (~100 batches):', img_acc)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unseen val classes count: 0\nVal products affected: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val label mismatches (first ~5k items): 0\nClass weight stats: min/median/max = 0.6879196763038635 0.958866536617279 2.5369224548339844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_327/1928096031.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load('ckpt_tiny_subset.pt', map_location='cpu') if Path('ckpt_tiny_subset.pt').exists() else None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quick image-level val acc (~100 batches): 0.04447710396039604\n"
          ]
        }
      ]
    },
    {
      "id": "143915ba-0f8c-4c72-8404-58289426f1d8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test inference with HFlip TTA, product-level aggregation, and submission.csv generation\n",
        "import pandas as pd, numpy as np, torch\n",
        "from pathlib import Path\n",
        "import torch.multiprocessing as mp\n",
        "mp.set_sharing_strategy('file_system')  # avoid /dev/shm exhaustion\n",
        "\n",
        "def build_test_loader(image_size=192, batch_size=128, num_workers=0):\n",
        "    dft = pd.read_parquet('test_index.parquet')\n",
        "    ds_te = BSONImageEval(dft, 'test.bson', include_label=False, cat2idx=None, image_size=image_size)\n",
        "    if num_workers <= 0:\n",
        "        dl_te = DataLoader(ds_te, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    else:\n",
        "        dl_te = DataLoader(ds_te, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=False,\n",
        "                           persistent_workers=False, prefetch_factor=2)\n",
        "    return dl_te, dft\n",
        "\n",
        "def infer_and_submit(ckpt_path='ckpt_tiny_subset.pt', model_name='convnext_tiny', image_size=192, out_path='submission.csv'):\n",
        "    assert Path(ckpt_path).exists(), f'Checkpoint not found: {ckpt_path}'\n",
        "    cat2idx, idx2cat, num_classes = load_mapping('category_mapping.json')\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    import timm\n",
        "    model = timm.create_model(model_name, pretrained=False, num_classes=num_classes).to(device).to(memory_format=torch.channels_last)\n",
        "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    dl_te, dft = build_test_loader(image_size=image_size, batch_size=128, num_workers=0)\n",
        "    agg = {}  # pid -> summed logits (torch tensor on CPU)\n",
        "    cnt = {}  # pid -> count\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(dl_te):\n",
        "            x = batch[0].to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            pids = batch[1].tolist()\n",
        "            with amp.autocast('cuda') if device.type=='cuda' else torch.no_grad():\n",
        "                logits = model(x)\n",
        "                logits_fl = model(x.flip(-1))\n",
        "            out = (logits + logits_fl) * 0.5\n",
        "            out = out.float().cpu()\n",
        "            for pid, logit in zip(pids, out):\n",
        "                if pid not in agg:\n",
        "                    agg[pid] = logit.clone()\n",
        "                    cnt[pid] = 1\n",
        "                else:\n",
        "                    agg[pid] += logit\n",
        "                    cnt[pid] += 1\n",
        "            if (i+1) % 200 == 0:\n",
        "                print(f'  infer {i+1}/{len(dl_te)} batches', flush=True)\n",
        "    # Build submission following sample_submission order\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    preds = []\n",
        "    missing = 0\n",
        "    for pid in ss['_id'].astype(np.int64).tolist():\n",
        "        if pid in agg:\n",
        "            logit = agg[pid] / max(1, cnt[pid])\n",
        "            cls = int(logit.argmax().item())\n",
        "            cat = int(idx2cat[cls])\n",
        "        else:\n",
        "            missing += 1\n",
        "            cat = int(idx2cat[0])\n",
        "        preds.append(cat)\n",
        "    if missing:\n",
        "        print('Warning: missing products in aggregation:', missing)\n",
        "    sub = pd.DataFrame({'_id': ss['_id'].astype(np.int64), 'category_id': preds})\n",
        "    sub.to_csv(out_path, index=False)\n",
        "    print('Wrote', out_path, 'rows:', len(sub))\n",
        "    return out_path\n",
        "\n",
        "# FAST path: one image per product (first image) to speed up inference for initial LB check\n",
        "class BSONProductEvalOneImage(Dataset):\n",
        "    def __init__(self, index_df: pd.DataFrame, bson_path: str, image_size=192):\n",
        "        self.df = index_df[['offset','_id']].reset_index(drop=True).copy()\n",
        "        self.bson_path = str(bson_path)\n",
        "        self._fh = None\n",
        "        self.transform = T.Compose([\n",
        "            T.Resize(int(image_size*1.15)),\n",
        "            T.CenterCrop(image_size),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def _ensure_fh(self):\n",
        "        if self._fh is None:\n",
        "            self._fh = open(self.bson_path, 'rb', buffering=0)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]\n",
        "        self._ensure_fh()\n",
        "        d = read_bson_doc_at(self._fh, int(r['offset']))\n",
        "        imgs = d.get('imgs', []) if d is not None else []\n",
        "        pic_bytes = imgs[0]['picture'] if d is not None and imgs else None\n",
        "        try:\n",
        "            img = Image.open(io.BytesIO(pic_bytes)).convert('RGB') if pic_bytes is not None else Image.new('RGB',(256,256))\n",
        "        except Exception:\n",
        "            img = Image.new('RGB',(256,256), color=(128,128,128))\n",
        "        x = self.transform(img)\n",
        "        return x, int(r['_id'])\n",
        "\n",
        "def build_test_loader_fast_products(image_size=192, batch_size=256, num_workers=0):\n",
        "    dft = pd.read_parquet('test_index.parquet')\n",
        "    ds = BSONProductEvalOneImage(dft, 'test.bson', image_size=image_size)\n",
        "    if num_workers <= 0:\n",
        "        dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    else:\n",
        "        dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=False,\n",
        "                        persistent_workers=False, prefetch_factor=2)\n",
        "    return dl, dft\n",
        "\n",
        "def infer_and_submit_fast(ckpt_path='ckpt_tiny_subset.pt', model_name='convnext_tiny', image_size=192, out_path='submission.csv'):\n",
        "    assert Path(ckpt_path).exists(), f'Checkpoint not found: {ckpt_path}'\n",
        "    _, idx2cat, num_classes = load_mapping('category_mapping.json')\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    import timm\n",
        "    model = timm.create_model(model_name, pretrained=False, num_classes=num_classes).to(device).to(memory_format=torch.channels_last)\n",
        "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    dl, dft = build_test_loader_fast_products(image_size=image_size, batch_size=256, num_workers=0)\n",
        "    preds_map = {}  # pid -> cls\n",
        "    with torch.no_grad():\n",
        "        for i, (x, pids) in enumerate(dl):\n",
        "            x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            with amp.autocast('cuda') if device.type=='cuda' else torch.no_grad():\n",
        "                logits = model(x)\n",
        "                logits_fl = model(x.flip(-1))\n",
        "            out = (logits + logits_fl) * 0.5\n",
        "            cls = out.argmax(1).detach().cpu().tolist()\n",
        "            for pid, c in zip(pids.tolist(), cls):\n",
        "                preds_map[int(pid)] = int(c)\n",
        "            if (i+1) % 200 == 0:\n",
        "                print(f'  fast infer {i+1}/{len(dl)} batches', flush=True)\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    preds = []\n",
        "    missing = 0\n",
        "    for pid in ss['_id'].astype(np.int64).tolist():\n",
        "        if int(pid) in preds_map:\n",
        "            cat = int(idx2cat[preds_map[int(pid)]])\n",
        "        else:\n",
        "            missing += 1\n",
        "            cat = int(idx2cat[0])\n",
        "        preds.append(cat)\n",
        "    if missing:\n",
        "        print('Warning: missing products in fast inference:', missing)\n",
        "    sub = pd.DataFrame({'_id': ss['_id'].astype(np.int64), 'category_id': preds})\n",
        "    sub.to_csv(out_path, index=False)\n",
        "    print('Wrote', out_path, 'rows:', len(sub))\n",
        "    return out_path\n",
        "\n",
        "print('Inference utilities ready. Call infer_and_submit(...) for full per-image agg, or infer_and_submit_fast(...) for one-image-per-product baseline.')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference utilities ready. Call infer_and_submit(...) for full per-image agg, or infer_and_submit_fast(...) for one-image-per-product baseline.\n"
          ]
        }
      ]
    },
    {
      "id": "a9f7912a-ea47-4d1a-98be-8748068edaf5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate submission quickly using fast one-image-per-product inference (HFlip TTA)\n",
        "out_path = infer_and_submit_fast(ckpt_path='ckpt_tiny_subset.pt', model_name='convnext_tiny', image_size=192, out_path='submission.csv')\n",
        "import pandas as pd\n",
        "sub = pd.read_csv(out_path)\n",
        "print('submission shape:', sub.shape)\n",
        "print(sub.head())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_327/2226608465.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 200/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 400/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 600/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 800/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 1000/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 1200/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 1400/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 1600/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 1800/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 2000/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 2200/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 2400/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fast infer 2600/2762 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv rows: 706990\nsubmission shape: (706990, 2)\n   _id  category_id\n0    6   1000012546\n1    7   1000012546\n2   12   1000001844\n3   59   1000019193\n4   61   1000010633\n"
          ]
        }
      ]
    },
    {
      "id": "fd6d4b79-77b8-43ac-bb6e-50607e3923ef",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ConvNeXt-Base@224 training on 200k subset with EMA, cosine, early stopping\n",
        "import math, time, numpy as np, pandas as pd, torch, torch.nn as nn, torch.optim as optim\n",
        "from torch import amp\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
        "\n",
        "def make_subset_loaders_base(batch_size=64, num_workers=16, image_size=224):\n",
        "    cat2idx, idx2cat, num_classes = load_mapping('category_mapping.json')\n",
        "    dfi = pd.read_parquet('train_index.parquet')\n",
        "    train_ids = pd.read_csv('train_ids.csv')['_id'].astype(np.int64).tolist()\n",
        "    val_ids = pd.read_csv('val_ids.csv')['_id'].astype(np.int64).tolist()\n",
        "    df_tr = dfi[dfi['_id'].isin(train_ids)].reset_index(drop=True)\n",
        "    df_va = dfi[dfi['_id'].isin(val_ids)].reset_index(drop=True)\n",
        "    ds_tr = BSONProductTrain(df_tr, 'train.bson', cat2idx, image_size=image_size)\n",
        "    ds_va = BSONImageEval(df_va, 'train.bson', include_label=True, cat2idx=cat2idx, image_size=image_size)\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True,\n",
        "                       persistent_workers=True, prefetch_factor=8, drop_last=True)\n",
        "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True,\n",
        "                       persistent_workers=True, prefetch_factor=12)\n",
        "    return dl_tr, dl_va, df_tr, df_va, num_classes, cat2idx, idx2cat\n",
        "\n",
        "def compute_class_weights_from_df(df_tr, cat2idx):\n",
        "    import numpy as np, math as _m\n",
        "    freq = df_tr['category_id'].value_counts().to_dict()\n",
        "    w = np.ones(len(cat2idx), dtype=np.float32)\n",
        "    for cat, idx in cat2idx.items():\n",
        "        f = float(freq.get(int(cat), 1))\n",
        "        w[idx] = 1.0 / _m.sqrt(max(f, 1.0))\n",
        "    w = w / (w.mean() + 1e-9)\n",
        "    return torch.tensor(w, dtype=torch.float32)\n",
        "\n",
        "def validate_products_base(model, loader, df_va, cat2idx, device):\n",
        "    model.eval()\n",
        "    id2y = {int(r['_id']): cat2idx[int(r['category_id'])] for _, r in df_va.iterrows()}\n",
        "    agg, cnt = {}, {}\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            x = batch[0].to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            ids = batch[1].tolist()\n",
        "            with amp.autocast('cuda') if device.type == 'cuda' else torch.no_grad():\n",
        "                logits = model(x).float().cpu()\n",
        "            for pid, logit in zip(ids, logits):\n",
        "                if pid not in agg:\n",
        "                    agg[pid] = logit.clone(); cnt[pid] = 1\n",
        "                else:\n",
        "                    agg[pid] += logit; cnt[pid] += 1\n",
        "    correct = 0\n",
        "    for pid, logit in agg.items():\n",
        "        m = logit / max(1, cnt.get(pid, 1))\n",
        "        if int(pid) in id2y and int(m.argmax().item()) == id2y[int(pid)]:\n",
        "            correct += 1\n",
        "    total = len(id2y)\n",
        "    return correct / max(1, total)\n",
        "\n",
        "def train_convnext_base_subset(epochs=10, lr=8e-4, wd=0.05, image_size=224, batch_size=64, accum_steps=4, patience=2, drop_path=0.2, ckpt_path='ckpt_convnextb_subset.pt'):\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    dl_tr, dl_va, df_tr, df_va, num_classes, cat2idx, idx2cat = make_subset_loaders_base(batch_size=batch_size, num_workers=16, image_size=image_size)\n",
        "    model = timm.create_model('convnext_base', pretrained=True, num_classes=num_classes, drop_path_rate=drop_path).to(device).to(memory_format=torch.channels_last)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=(0.9,0.999))\n",
        "    model_ema = ModelEmaV2(model, decay=0.9997)\n",
        "    cls_w = compute_class_weights_from_df(df_tr, cat2idx).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1, weight=cls_w)\n",
        "    scaler = amp.GradScaler('cuda') if device.type == 'cuda' else None\n",
        "    steps_per_epoch = len(dl_tr)\n",
        "    updates_per_epoch = int(math.ceil(steps_per_epoch / max(1, accum_steps)))\n",
        "    total_updates = updates_per_epoch * epochs\n",
        "    warmup_updates = updates_per_epoch  # 1 epoch warmup\n",
        "    sched = CosineLRScheduler(\n",
        "        optimizer, t_initial=max(1, total_updates - warmup_updates), lr_min=1e-6,\n",
        "        warmup_t=warmup_updates, warmup_lr_init=1e-5, t_in_epochs=False\n",
        "    )\n",
        "    best_acc = -1.0\n",
        "    no_improve = 0\n",
        "    print(f'Start training: epochs={epochs}, eff_batch~={batch_size*accum_steps}, lr={lr}, wd={wd}, img={image_size}', flush=True)\n",
        "    for ep in range(1, epochs + 1):\n",
        "        t0 = time.time()\n",
        "        model.train()\n",
        "        total, correct, loss_sum = 0, 0, 0.0\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        upd_idx = 0\n",
        "        for it, (x, y) in enumerate(dl_tr):\n",
        "            x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            if scaler is not None:\n",
        "                with amp.autocast('cuda'):\n",
        "                    logits = model(x)\n",
        "                    loss = criterion(logits, y) / accum_steps\n",
        "                scaler.scale(loss).backward()\n",
        "            else:\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y) / accum_steps\n",
        "                loss.backward()\n",
        "            if (it + 1) % accum_steps == 0:\n",
        "                if scaler is not None:\n",
        "                    scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                if scaler is not None:\n",
        "                    scaler.step(optimizer); scaler.update()\n",
        "                else:\n",
        "                    optimizer.step()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                model_ema.update(model)\n",
        "                upd_idx += 1\n",
        "                sched.step_update((ep - 1) * updates_per_epoch + upd_idx)\n",
        "            preds = logits.detach().argmax(1)\n",
        "            total += y.size(0)\n",
        "            correct += (preds == y).sum().item()\n",
        "            loss_sum += loss.item() * accum_steps * x.size(0)\n",
        "            if (it + 1) % 100 == 0:\n",
        "                print(f'E{ep} it {it+1}/{len(dl_tr)} loss={loss_sum/max(1,total):.4f} acc={correct/max(1,total):.4f} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "        tr_loss = loss_sum / max(1, total)\n",
        "        tr_acc = correct / max(1, total)\n",
        "        va_acc = validate_products_base(model_ema.module, dl_va, df_va, cat2idx, device)\n",
        "        print(f'Epoch {ep}: train loss={tr_loss:.4f} acc={tr_acc:.4f} | val product-acc={va_acc:.4f} | took {time.time()-t0:.1f}s', flush=True)\n",
        "        if va_acc > best_acc:\n",
        "            best_acc = va_acc; no_improve = 0\n",
        "            torch.save({'model': model_ema.module.state_dict(), 'val_acc': va_acc}, ckpt_path)\n",
        "            print(f'  Saved {ckpt_path} (EMA) with val_acc={va_acc:.4f}', flush=True)\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= patience:\n",
        "                print(f'Early stopping at epoch {ep} (no improvement {no_improve}/{patience})', flush=True)\n",
        "                break\n",
        "    print('Best val product-acc:', f'{best_acc:.4f}')\n",
        "    return best_acc\n",
        "\n",
        "print('ConvNeXt-Base training function ready. Next: execute train_convnext_base_subset(...) to launch the strong run.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNeXt-Base training function ready. Next: execute train_convnext_base_subset(...) to launch the strong run.\n"
          ]
        }
      ]
    },
    {
      "id": "35422ed3-3f4d-4b88-95d4-bc575ddb1e3b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Launch ConvNeXt-Base@224 strong run on 200k subset\n",
        "import os, time, torch\n",
        "os.environ.setdefault('OMP_NUM_THREADS', '1')\n",
        "os.environ.setdefault('MKL_NUM_THREADS', '1')\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "t0 = time.time()\n",
        "best_acc = train_convnext_base_subset(\n",
        "    epochs=10, lr=8e-4, wd=0.05, image_size=224,\n",
        "    batch_size=64, accum_steps=4, patience=2, drop_path=0.2,\n",
        "    ckpt_path='ckpt_convnextb_subset.pt'\n",
        ")\n",
        "print(f'Total training time: {time.time()-t0:.1f}s | best val product-acc={best_acc:.4f}', flush=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\nGPU: NVIDIA A10-24Q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training: epochs=10, eff_batch~=256, lr=0.0008, wd=0.05, img=224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 100/2812 loss=8.7830 acc=0.0006 elapsed=35.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 200/2812 loss=8.7411 acc=0.0004 elapsed=63.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 300/2812 loss=8.6976 acc=0.0005 elapsed=91.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 400/2812 loss=8.6684 acc=0.0004 elapsed=119.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 500/2812 loss=8.6341 acc=0.0015 elapsed=147.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 600/2812 loss=8.5816 acc=0.0039 elapsed=175.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 700/2812 loss=8.5054 acc=0.0082 elapsed=203.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 800/2812 loss=8.4161 acc=0.0124 elapsed=231.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 900/2812 loss=8.3145 acc=0.0175 elapsed=259.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 1000/2812 loss=8.2018 acc=0.0224 elapsed=287.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 1100/2812 loss=8.0858 acc=0.0277 elapsed=315.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 1200/2812 loss=7.9727 acc=0.0331 elapsed=343.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 1300/2812 loss=7.8628 acc=0.0388 elapsed=371.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 1400/2812 loss=7.7570 acc=0.0446 elapsed=400.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 1500/2812 loss=7.6558 acc=0.0497 elapsed=428.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 1600/2812 loss=7.5604 acc=0.0552 elapsed=456.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 1700/2812 loss=7.4692 acc=0.0609 elapsed=484.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 1800/2812 loss=7.3824 acc=0.0668 elapsed=513.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 1900/2812 loss=7.3012 acc=0.0717 elapsed=541.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 2000/2812 loss=7.2259 acc=0.0768 elapsed=569.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 2100/2812 loss=7.1554 acc=0.0816 elapsed=597.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 2200/2812 loss=7.0909 acc=0.0858 elapsed=626.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 2300/2812 loss=7.0300 acc=0.0899 elapsed=654.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 2400/2812 loss=6.9737 acc=0.0939 elapsed=682.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 2500/2812 loss=6.9196 acc=0.0977 elapsed=710.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 2600/2812 loss=6.8703 acc=0.1012 elapsed=739.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 2700/2812 loss=6.8238 acc=0.1046 elapsed=767.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 it 2800/2812 loss=6.7806 acc=0.1077 elapsed=795.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train loss=6.7758 acc=0.1080 | val product-acc=0.0076 | took 854.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_convnextb_subset.pt (EMA) with val_acc=0.0076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 100/2812 loss=4.9407 acc=0.2725 elapsed=28.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 200/2812 loss=4.9086 acc=0.2767 elapsed=56.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 300/2812 loss=4.9302 acc=0.2724 elapsed=84.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 400/2812 loss=4.9416 acc=0.2710 elapsed=112.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 500/2812 loss=4.9546 acc=0.2703 elapsed=141.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 600/2812 loss=4.9593 acc=0.2699 elapsed=169.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 700/2812 loss=4.9531 acc=0.2699 elapsed=197.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 800/2812 loss=4.9523 acc=0.2701 elapsed=226.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 900/2812 loss=4.9516 acc=0.2698 elapsed=254.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 1000/2812 loss=4.9585 acc=0.2691 elapsed=282.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 1100/2812 loss=4.9548 acc=0.2697 elapsed=310.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 1200/2812 loss=4.9546 acc=0.2694 elapsed=339.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 1300/2812 loss=4.9522 acc=0.2696 elapsed=367.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 1400/2812 loss=4.9462 acc=0.2705 elapsed=395.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 1500/2812 loss=4.9453 acc=0.2709 elapsed=423.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 1600/2812 loss=4.9450 acc=0.2711 elapsed=451.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 1700/2812 loss=4.9458 acc=0.2713 elapsed=480.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 1800/2812 loss=4.9418 acc=0.2723 elapsed=508.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 1900/2812 loss=4.9383 acc=0.2729 elapsed=536.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 2000/2812 loss=4.9349 acc=0.2737 elapsed=564.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 2100/2812 loss=4.9300 acc=0.2747 elapsed=593.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 2200/2812 loss=4.9268 acc=0.2754 elapsed=621.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 2300/2812 loss=4.9209 acc=0.2764 elapsed=649.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 2400/2812 loss=4.9147 acc=0.2773 elapsed=678.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 2500/2812 loss=4.9117 acc=0.2775 elapsed=706.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 2600/2812 loss=4.9066 acc=0.2784 elapsed=734.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 2700/2812 loss=4.9005 acc=0.2794 elapsed=762.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2 it 2800/2812 loss=4.8940 acc=0.2805 elapsed=791.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: train loss=4.8928 acc=0.2806 | val product-acc=0.1933 | took 848.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_convnextb_subset.pt (EMA) with val_acc=0.1933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 100/2812 loss=3.8330 acc=0.4400 elapsed=28.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 200/2812 loss=3.8521 acc=0.4359 elapsed=56.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 300/2812 loss=3.8633 acc=0.4339 elapsed=84.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 400/2812 loss=3.8655 acc=0.4326 elapsed=113.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 500/2812 loss=3.8590 acc=0.4339 elapsed=141.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 600/2812 loss=3.8626 acc=0.4325 elapsed=169.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 700/2812 loss=3.8730 acc=0.4317 elapsed=198.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 800/2812 loss=3.8781 acc=0.4314 elapsed=226.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 900/2812 loss=3.8842 acc=0.4293 elapsed=254.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 1000/2812 loss=3.8905 acc=0.4288 elapsed=283.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 1100/2812 loss=3.8938 acc=0.4285 elapsed=311.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 1200/2812 loss=3.9038 acc=0.4269 elapsed=339.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 1300/2812 loss=3.9141 acc=0.4253 elapsed=367.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 1400/2812 loss=3.9187 acc=0.4247 elapsed=396.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 1500/2812 loss=3.9205 acc=0.4244 elapsed=424.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 1600/2812 loss=3.9248 acc=0.4244 elapsed=452.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 1700/2812 loss=3.9283 acc=0.4239 elapsed=480.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 1800/2812 loss=3.9334 acc=0.4226 elapsed=508.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 1900/2812 loss=3.9358 acc=0.4224 elapsed=537.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 2000/2812 loss=3.9363 acc=0.4226 elapsed=565.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 2100/2812 loss=3.9383 acc=0.4220 elapsed=593.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 2200/2812 loss=3.9414 acc=0.4217 elapsed=622.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 2300/2812 loss=3.9442 acc=0.4215 elapsed=650.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 2400/2812 loss=3.9465 acc=0.4211 elapsed=678.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 2500/2812 loss=3.9465 acc=0.4213 elapsed=707.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 2600/2812 loss=3.9470 acc=0.4213 elapsed=735.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 2700/2812 loss=3.9476 acc=0.4216 elapsed=763.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E3 it 2800/2812 loss=3.9485 acc=0.4213 elapsed=791.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: train loss=3.9493 acc=0.4211 | val product-acc=0.3276 | took 849.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_convnextb_subset.pt (EMA) with val_acc=0.3276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 100/2812 loss=3.0468 acc=0.6081 elapsed=28.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 200/2812 loss=3.0681 acc=0.5988 elapsed=56.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 300/2812 loss=3.0794 acc=0.5969 elapsed=84.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 400/2812 loss=3.0893 acc=0.5923 elapsed=113.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 500/2812 loss=3.0948 acc=0.5917 elapsed=141.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 600/2812 loss=3.0974 acc=0.5903 elapsed=169.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 700/2812 loss=3.1087 acc=0.5877 elapsed=198.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 800/2812 loss=3.1125 acc=0.5858 elapsed=226.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 900/2812 loss=3.1182 acc=0.5846 elapsed=254.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 1000/2812 loss=3.1234 acc=0.5836 elapsed=282.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 1100/2812 loss=3.1309 acc=0.5819 elapsed=311.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 1200/2812 loss=3.1311 acc=0.5814 elapsed=339.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 1300/2812 loss=3.1371 acc=0.5802 elapsed=367.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 1400/2812 loss=3.1473 acc=0.5784 elapsed=395.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 1500/2812 loss=3.1515 acc=0.5767 elapsed=424.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 1600/2812 loss=3.1578 acc=0.5753 elapsed=452.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 1700/2812 loss=3.1644 acc=0.5739 elapsed=480.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 1800/2812 loss=3.1698 acc=0.5729 elapsed=508.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 1900/2812 loss=3.1762 acc=0.5713 elapsed=536.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 2000/2812 loss=3.1806 acc=0.5704 elapsed=565.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 2100/2812 loss=3.1851 acc=0.5693 elapsed=593.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 2200/2812 loss=3.1885 acc=0.5683 elapsed=621.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 2300/2812 loss=3.1912 acc=0.5676 elapsed=649.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 2400/2812 loss=3.1960 acc=0.5663 elapsed=678.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 2500/2812 loss=3.1994 acc=0.5660 elapsed=706.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 2600/2812 loss=3.2023 acc=0.5653 elapsed=735.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 2700/2812 loss=3.2068 acc=0.5643 elapsed=763.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E4 it 2800/2812 loss=3.2110 acc=0.5632 elapsed=791.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: train loss=3.2108 acc=0.5633 | val product-acc=0.3901 | took 849.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_convnextb_subset.pt (EMA) with val_acc=0.3901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 100/2812 loss=2.4867 acc=0.7430 elapsed=28.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 200/2812 loss=2.5181 acc=0.7367 elapsed=56.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 300/2812 loss=2.5363 acc=0.7327 elapsed=84.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 400/2812 loss=2.5454 acc=0.7290 elapsed=112.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 500/2812 loss=2.5562 acc=0.7257 elapsed=141.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 600/2812 loss=2.5618 acc=0.7241 elapsed=169.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 700/2812 loss=2.5695 acc=0.7222 elapsed=197.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 800/2812 loss=2.5778 acc=0.7206 elapsed=225.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 900/2812 loss=2.5834 acc=0.7192 elapsed=254.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 1000/2812 loss=2.5901 acc=0.7181 elapsed=282.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 1100/2812 loss=2.5923 acc=0.7169 elapsed=310.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 1200/2812 loss=2.5956 acc=0.7158 elapsed=339.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 1300/2812 loss=2.5991 acc=0.7144 elapsed=367.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 1400/2812 loss=2.6025 acc=0.7135 elapsed=395.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 1500/2812 loss=2.6048 acc=0.7129 elapsed=423.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 1600/2812 loss=2.6082 acc=0.7115 elapsed=451.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 1700/2812 loss=2.6123 acc=0.7100 elapsed=480.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 1800/2812 loss=2.6165 acc=0.7089 elapsed=508.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 1900/2812 loss=2.6189 acc=0.7081 elapsed=536.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 2000/2812 loss=2.6203 acc=0.7077 elapsed=564.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 2100/2812 loss=2.6226 acc=0.7070 elapsed=592.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 2200/2812 loss=2.6266 acc=0.7059 elapsed=621.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 2300/2812 loss=2.6281 acc=0.7053 elapsed=649.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 2400/2812 loss=2.6299 acc=0.7047 elapsed=677.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 2500/2812 loss=2.6311 acc=0.7046 elapsed=705.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 2600/2812 loss=2.6314 acc=0.7045 elapsed=734.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 2700/2812 loss=2.6319 acc=0.7039 elapsed=762.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E5 it 2800/2812 loss=2.6328 acc=0.7038 elapsed=790.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: train loss=2.6323 acc=0.7040 | val product-acc=0.4237 | took 848.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_convnextb_subset.pt (EMA) with val_acc=0.4237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 100/2812 loss=2.2155 acc=0.8161 elapsed=28.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 200/2812 loss=2.2080 acc=0.8188 elapsed=56.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 300/2812 loss=2.2047 acc=0.8189 elapsed=85.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 400/2812 loss=2.2122 acc=0.8174 elapsed=113.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 500/2812 loss=2.2117 acc=0.8179 elapsed=141.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 600/2812 loss=2.2156 acc=0.8157 elapsed=169.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 700/2812 loss=2.2210 acc=0.8155 elapsed=198.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 800/2812 loss=2.2193 acc=0.8154 elapsed=226.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 900/2812 loss=2.2258 acc=0.8132 elapsed=254.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 1000/2812 loss=2.2236 acc=0.8137 elapsed=282.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 1100/2812 loss=2.2256 acc=0.8130 elapsed=311.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 1200/2812 loss=2.2287 acc=0.8120 elapsed=339.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 1300/2812 loss=2.2327 acc=0.8108 elapsed=367.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 1400/2812 loss=2.2329 acc=0.8103 elapsed=395.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 1500/2812 loss=2.2341 acc=0.8101 elapsed=424.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 1600/2812 loss=2.2339 acc=0.8102 elapsed=452.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 1700/2812 loss=2.2373 acc=0.8095 elapsed=480.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 1800/2812 loss=2.2372 acc=0.8092 elapsed=508.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 1900/2812 loss=2.2386 acc=0.8088 elapsed=536.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 2000/2812 loss=2.2385 acc=0.8087 elapsed=565.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 2100/2812 loss=2.2390 acc=0.8085 elapsed=593.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 2200/2812 loss=2.2406 acc=0.8081 elapsed=621.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 2300/2812 loss=2.2418 acc=0.8076 elapsed=649.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 2400/2812 loss=2.2437 acc=0.8073 elapsed=677.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 2500/2812 loss=2.2449 acc=0.8070 elapsed=706.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 2600/2812 loss=2.2462 acc=0.8066 elapsed=734.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 2700/2812 loss=2.2462 acc=0.8065 elapsed=762.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E6 it 2800/2812 loss=2.2477 acc=0.8062 elapsed=791.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: train loss=2.2480 acc=0.8062 | val product-acc=0.4420 | took 849.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_convnextb_subset.pt (EMA) with val_acc=0.4420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 100/2812 loss=1.9902 acc=0.8719 elapsed=28.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 200/2812 loss=1.9898 acc=0.8714 elapsed=56.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 300/2812 loss=1.9938 acc=0.8710 elapsed=84.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 400/2812 loss=1.9934 acc=0.8704 elapsed=112.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 500/2812 loss=1.9894 acc=0.8710 elapsed=141.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 600/2812 loss=1.9905 acc=0.8711 elapsed=169.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 700/2812 loss=1.9955 acc=0.8699 elapsed=197.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 800/2812 loss=1.9968 acc=0.8691 elapsed=225.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 900/2812 loss=1.9980 acc=0.8685 elapsed=253.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 1000/2812 loss=1.9953 acc=0.8693 elapsed=282.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 1100/2812 loss=1.9970 acc=0.8682 elapsed=310.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 1200/2812 loss=2.0001 acc=0.8672 elapsed=338.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 1300/2812 loss=1.9991 acc=0.8674 elapsed=367.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 1400/2812 loss=2.0006 acc=0.8667 elapsed=395.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 1500/2812 loss=2.0001 acc=0.8670 elapsed=424.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 1600/2812 loss=2.0011 acc=0.8669 elapsed=452.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 1700/2812 loss=2.0015 acc=0.8663 elapsed=480.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 1800/2812 loss=2.0026 acc=0.8661 elapsed=508.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 1900/2812 loss=2.0031 acc=0.8659 elapsed=536.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 2000/2812 loss=2.0035 acc=0.8657 elapsed=565.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 2100/2812 loss=2.0037 acc=0.8659 elapsed=593.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 2200/2812 loss=2.0037 acc=0.8660 elapsed=621.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 2300/2812 loss=2.0035 acc=0.8661 elapsed=649.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 2400/2812 loss=2.0036 acc=0.8660 elapsed=677.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 2500/2812 loss=2.0039 acc=0.8660 elapsed=705.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 2600/2812 loss=2.0045 acc=0.8658 elapsed=734.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 2700/2812 loss=2.0050 acc=0.8656 elapsed=762.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E7 it 2800/2812 loss=2.0042 acc=0.8657 elapsed=790.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: train loss=2.0040 acc=0.8657 | val product-acc=0.4548 | took 848.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_convnextb_subset.pt (EMA) with val_acc=0.4548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 100/2812 loss=1.8346 acc=0.9047 elapsed=28.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 200/2812 loss=1.8543 acc=0.9000 elapsed=56.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 300/2812 loss=1.8501 acc=0.9028 elapsed=85.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 400/2812 loss=1.8566 acc=0.9013 elapsed=113.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 500/2812 loss=1.8585 acc=0.9005 elapsed=141.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 600/2812 loss=1.8586 acc=0.9005 elapsed=170.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 700/2812 loss=1.8570 acc=0.9007 elapsed=198.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 800/2812 loss=1.8612 acc=0.9002 elapsed=226.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 900/2812 loss=1.8603 acc=0.9004 elapsed=255.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 1000/2812 loss=1.8602 acc=0.8999 elapsed=283.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 1100/2812 loss=1.8596 acc=0.9003 elapsed=311.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 1200/2812 loss=1.8589 acc=0.9001 elapsed=340.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 1300/2812 loss=1.8573 acc=0.9002 elapsed=368.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 1400/2812 loss=1.8565 acc=0.9006 elapsed=396.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 1500/2812 loss=1.8575 acc=0.9006 elapsed=424.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 1600/2812 loss=1.8594 acc=0.9000 elapsed=453.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 1700/2812 loss=1.8602 acc=0.8998 elapsed=481.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 1800/2812 loss=1.8593 acc=0.9000 elapsed=509.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 1900/2812 loss=1.8590 acc=0.9000 elapsed=537.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 2000/2812 loss=1.8590 acc=0.9000 elapsed=565.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 2100/2812 loss=1.8587 acc=0.8999 elapsed=594.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 2200/2812 loss=1.8582 acc=0.9000 elapsed=622.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 2300/2812 loss=1.8588 acc=0.8998 elapsed=650.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 2400/2812 loss=1.8586 acc=0.8998 elapsed=678.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 2500/2812 loss=1.8587 acc=0.8998 elapsed=706.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 2600/2812 loss=1.8582 acc=0.8998 elapsed=734.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 2700/2812 loss=1.8584 acc=0.8998 elapsed=763.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E8 it 2800/2812 loss=1.8583 acc=0.8998 elapsed=791.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: train loss=1.8584 acc=0.8998 | val product-acc=0.4607 | took 849.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_convnextb_subset.pt (EMA) with val_acc=0.4607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 100/2812 loss=1.8052 acc=0.9145 elapsed=28.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 200/2812 loss=1.7968 acc=0.9170 elapsed=56.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 300/2812 loss=1.7976 acc=0.9166 elapsed=85.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 400/2812 loss=1.7992 acc=0.9150 elapsed=113.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 500/2812 loss=1.7982 acc=0.9154 elapsed=141.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 600/2812 loss=1.7999 acc=0.9146 elapsed=170.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 700/2812 loss=1.7979 acc=0.9152 elapsed=198.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 800/2812 loss=1.7992 acc=0.9150 elapsed=226.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 900/2812 loss=1.8007 acc=0.9152 elapsed=254.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 1000/2812 loss=1.7992 acc=0.9157 elapsed=283.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 1100/2812 loss=1.7966 acc=0.9161 elapsed=311.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 1200/2812 loss=1.7958 acc=0.9163 elapsed=339.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 1300/2812 loss=1.7973 acc=0.9158 elapsed=368.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 1400/2812 loss=1.7979 acc=0.9154 elapsed=396.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 1500/2812 loss=1.7971 acc=0.9154 elapsed=424.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 1600/2812 loss=1.7962 acc=0.9153 elapsed=453.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 1700/2812 loss=1.7967 acc=0.9152 elapsed=481.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 1800/2812 loss=1.7971 acc=0.9149 elapsed=509.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 1900/2812 loss=1.7963 acc=0.9148 elapsed=538.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 2000/2812 loss=1.7972 acc=0.9146 elapsed=566.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 2100/2812 loss=1.7964 acc=0.9147 elapsed=594.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 2200/2812 loss=1.7953 acc=0.9149 elapsed=622.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 2300/2812 loss=1.7950 acc=0.9151 elapsed=651.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 2400/2812 loss=1.7956 acc=0.9150 elapsed=679.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 2500/2812 loss=1.7956 acc=0.9150 elapsed=707.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 2600/2812 loss=1.7954 acc=0.9150 elapsed=735.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 2700/2812 loss=1.7955 acc=0.9150 elapsed=764.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E9 it 2800/2812 loss=1.7949 acc=0.9151 elapsed=792.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: train loss=1.7949 acc=0.9151 | val product-acc=0.4648 | took 850.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_convnextb_subset.pt (EMA) with val_acc=0.4648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 100/2812 loss=1.8066 acc=0.9133 elapsed=28.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 200/2812 loss=1.7813 acc=0.9176 elapsed=56.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 300/2812 loss=1.7925 acc=0.9142 elapsed=85.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 400/2812 loss=1.7952 acc=0.9134 elapsed=113.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 500/2812 loss=1.7932 acc=0.9141 elapsed=141.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 600/2812 loss=1.7953 acc=0.9139 elapsed=169.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 700/2812 loss=1.7957 acc=0.9138 elapsed=197.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 800/2812 loss=1.7913 acc=0.9151 elapsed=226.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 900/2812 loss=1.7901 acc=0.9151 elapsed=254.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 1000/2812 loss=1.7922 acc=0.9147 elapsed=282.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 1100/2812 loss=1.7901 acc=0.9154 elapsed=310.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 1200/2812 loss=1.7890 acc=0.9157 elapsed=339.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 1300/2812 loss=1.7879 acc=0.9159 elapsed=367.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 1400/2812 loss=1.7874 acc=0.9160 elapsed=395.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 1500/2812 loss=1.7874 acc=0.9160 elapsed=424.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 1600/2812 loss=1.7881 acc=0.9160 elapsed=452.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 1700/2812 loss=1.7891 acc=0.9159 elapsed=480.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 1800/2812 loss=1.7894 acc=0.9160 elapsed=508.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 1900/2812 loss=1.7892 acc=0.9160 elapsed=537.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 2000/2812 loss=1.7893 acc=0.9161 elapsed=565.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 2100/2812 loss=1.7902 acc=0.9159 elapsed=593.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 2200/2812 loss=1.7908 acc=0.9155 elapsed=621.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 2300/2812 loss=1.7896 acc=0.9159 elapsed=649.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 2400/2812 loss=1.7888 acc=0.9160 elapsed=678.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 2500/2812 loss=1.7887 acc=0.9159 elapsed=706.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 2600/2812 loss=1.7892 acc=0.9158 elapsed=734.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 2700/2812 loss=1.7890 acc=0.9158 elapsed=762.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E10 it 2800/2812 loss=1.7883 acc=0.9160 elapsed=791.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: train loss=1.7882 acc=0.9160 | val product-acc=0.4663 | took 849.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved ckpt_convnextb_subset.pt (EMA) with val_acc=0.4663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best val product-acc: 0.4663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training time: 8509.6s | best val product-acc=0.4663\n"
          ]
        }
      ]
    },
    {
      "id": "97e8d38a-d3dc-4b51-9b2a-ce241e7f3ccc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference with ConvNeXt-Base EMA checkpoint: full per-image aggregation + HFlip TTA\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "ckpt_path = 'ckpt_convnextb_subset.pt'\n",
        "assert Path(ckpt_path).exists(), 'ConvNeXt-Base checkpoint not found. Train run must complete first.'\n",
        "out_path = infer_and_submit(ckpt_path=ckpt_path, model_name='convnext_base', image_size=224, out_path='submission_base.csv')\n",
        "sub = pd.read_csv(out_path)\n",
        "print('submission_base shape:', sub.shape)\n",
        "print(sub.head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_327/2226608465.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 200/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 400/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 600/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 800/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 1000/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 1200/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 1400/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 1600/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 1800/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 2000/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 2200/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 2400/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 2600/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 2800/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 3000/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 3200/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 3400/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 3600/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 3800/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 4000/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 4200/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 4400/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 4600/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 4800/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 5000/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 5200/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 5400/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 5600/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 5800/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 6000/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 6200/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 6400/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 6600/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 6800/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 7000/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 7200/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 7400/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 7600/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 7800/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 8000/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 8200/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 8400/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 8600/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 8800/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 9000/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 9200/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 9400/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  infer 9600/9671 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_base.csv rows: 706990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission_base shape: (706990, 2)\n   _id  category_id\n0    6   1000005744\n1    7   1000004079\n2   12   1000018286\n3   59   1000007138\n4   61   1000010653\n"
          ]
        }
      ]
    },
    {
      "id": "3fab67c4-f863-4bbd-ae40-6d5909af044f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Copy best submission to official filename and quick sanity check\n",
        "import pandas as pd, shutil, os\n",
        "assert os.path.exists('submission_base.csv'), 'submission_base.csv not found'\n",
        "shutil.copyfile('submission_base.csv', 'submission.csv')\n",
        "sub = pd.read_csv('submission.csv')\n",
        "print('submission.csv shape:', sub.shape)\n",
        "print(sub.head())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv shape: (706990, 2)\n   _id  category_id\n0    6   1000005744\n1    7   1000004079\n2   12   1000018286\n3   59   1000007138\n4   61   1000010653\n"
          ]
        }
      ]
    },
    {
      "id": "0b22dded-b904-463d-8915-656730b0d6cf",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Multi-scale TTA inference: add Resize 240 -> CenterCrop 224 alongside 256->224 + HFlip\n",
        "import pandas as pd, numpy as np, torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "class BSONImageEvalScaled(Dataset):\n",
        "    def __init__(self, index_df: pd.DataFrame, bson_path: str, include_label: bool, cat2idx: dict | None, resize_size: int, crop_size: int):\n",
        "        rows = []\n",
        "        for _, r in index_df.iterrows():\n",
        "            for k in range(int(r['n_imgs'])):\n",
        "                rows.append((int(r['offset']), int(r['_id']), k, int(r['category_id']) if include_label and pd.notna(r['category_id']) else None))\n",
        "        self.df = pd.DataFrame(rows, columns=['offset','_id','img_idx','category_id'])\n",
        "        self.df.sort_values('offset', inplace=True)\n",
        "        self.bson_path = str(bson_path)\n",
        "        self.include_label = include_label\n",
        "        self.cat2idx = cat2idx\n",
        "        self._fh = None\n",
        "        self.transform = T.Compose([\n",
        "            T.Resize(resize_size),\n",
        "            T.CenterCrop(crop_size),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def _ensure_fh(self):\n",
        "        if self._fh is None:\n",
        "            self._fh = open(self.bson_path, 'rb', buffering=0)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]\n",
        "        self._ensure_fh()\n",
        "        d = read_bson_doc_at(self._fh, int(r['offset']))\n",
        "        imgs = d.get('imgs', []) if d is not None else []\n",
        "        pic_bytes = imgs[int(r['img_idx'])]['picture'] if d is not None and imgs else None\n",
        "        try:\n",
        "            img = Image.open(io.BytesIO(pic_bytes)).convert('RGB') if pic_bytes is not None else Image.new('RGB',(256,256))\n",
        "        except Exception:\n",
        "            img = Image.new('RGB',(256,256), color=(128,128,128))\n",
        "        x = self.transform(img)\n",
        "        if self.include_label:\n",
        "            cat_id = int(r['category_id']) if r['category_id'] is not None and pd.notna(r['category_id']) else None\n",
        "            y = self.cat2idx.get(cat_id, 0) if (self.cat2idx is not None and cat_id is not None) else -1\n",
        "            return x, int(r['_id']), int(r['img_idx']), y\n",
        "        else:\n",
        "            return x, int(r['_id']), int(r['img_idx'])\n",
        "\n",
        "def infer_and_submit_multiscale(ckpt_path: str, model_name: str, crop_size=224, scales=(256, 240), out_path='submission_ms.csv'):\n",
        "    assert Path(ckpt_path).exists(), f'Checkpoint not found: {ckpt_path}'\n",
        "    cat2idx, idx2cat, num_classes = load_mapping('category_mapping.json')\n",
        "    import timm\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = timm.create_model(model_name, pretrained=False, num_classes=num_classes).to(device).to(memory_format=torch.channels_last)\n",
        "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
        "    model.load_state_dict(ckpt['model'], strict=False)\n",
        "    model.eval()\n",
        "    dft = pd.read_parquet('test_index.parquet')\n",
        "    agg, cnt = {}, {}  # pid -> logits sum, count\n",
        "    with torch.no_grad():\n",
        "        for s in scales:\n",
        "            ds = BSONImageEvalScaled(dft, 'test.bson', include_label=False, cat2idx=None, resize_size=s, crop_size=crop_size)\n",
        "            dl = DataLoader(ds, batch_size=128, shuffle=False, num_workers=0, pin_memory=False)\n",
        "            for i, batch in enumerate(dl):\n",
        "                x = batch[0].to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                pids = batch[1].tolist()\n",
        "                with amp.autocast('cuda') if device.type=='cuda' else torch.no_grad():\n",
        "                    logits = model(x)\n",
        "                    logits_fl = model(x.flip(-1))\n",
        "                out = (logits + logits_fl) * 0.5\n",
        "                out = out.float().cpu()\n",
        "                for pid, logit in zip(pids, out):\n",
        "                    if pid not in agg:\n",
        "                        agg[pid] = logit.clone(); cnt[pid] = 1\n",
        "                    else:\n",
        "                        agg[pid] += logit; cnt[pid] += 1\n",
        "                if (i+1) % 200 == 0:\n",
        "                    print(f'scale {s}: infer {i+1}/{len(dl)} batches', flush=True)\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    preds = []\n",
        "    missing = 0\n",
        "    for pid in ss['_id'].astype(np.int64).tolist():\n",
        "        if pid in agg:\n",
        "            logit = agg[pid] / max(1, cnt[pid])\n",
        "            cls = int(logit.argmax().item())\n",
        "            cat = int(idx2cat[cls])\n",
        "        else:\n",
        "            missing += 1\n",
        "            cat = int(idx2cat[0])\n",
        "        preds.append(cat)\n",
        "    if missing:\n",
        "        print('Warning: missing products in aggregation:', missing)\n",
        "    sub = pd.DataFrame({'_id': ss['_id'].astype(np.int64), 'category_id': preds})\n",
        "    sub.to_csv(out_path, index=False)\n",
        "    print('Wrote', out_path, 'rows:', len(sub))\n",
        "    return out_path\n",
        "\n",
        "# Run multi-scale TTA on ConvNeXt-Base EMA checkpoint and prepare submission.csv\n",
        "ms_out = infer_and_submit_multiscale(ckpt_path='ckpt_convnextb_subset.pt', model_name='convnext_base', crop_size=224, scales=(256,240), out_path='submission_ms.csv')\n",
        "import shutil\n",
        "shutil.copyfile(ms_out, 'submission.csv')\n",
        "print('submission.csv updated from multi-scale TTA:', ms_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_327/2072974973.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}