{
  "cells": [
    {
      "id": "c4bf7f0f-4821-4176-a609-5d3022625ee6",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Random Acts of Pizza \u2013 Plan\n",
        "\n",
        "Objectives:\n",
        "- Win a medal (AUC-ROC target \u2265 0.692 for bronze; aim much higher with strong text models).\n",
        "- Build fast, reliable CV and iterate quickly with cached text features.\n",
        "\n",
        "Data:\n",
        "- train.json, test.json; labels likely binary (requester_received_pizza / success).\n",
        "- Text fields: request_text, title, possibly combined; meta-features available (karma, account age, etc.).\n",
        "\n",
        "Validation:\n",
        "- Stratified KFold (e.g., 5 folds) with deterministic seed.\n",
        "- Fit transforms inside folds; cache TF-IDF matrices once and slice for folds.\n",
        "\n",
        "Baseline v1:\n",
        "- Text-only: TF-IDF (word + char n-grams) \u2192 LogisticRegression (liblinear/saga) or LinearSVC with calibrated probs.\n",
        "- Fast OOF to establish reference AUC.\n",
        "\n",
        "Feature Engineering v2:\n",
        "- Combine title + request_text; clean URLs/emojis; length stats (chars, words, sentences).\n",
        "- Handcrafted features from paper: gratitude, politeness cues, reciprocity, evidence (imgur links), need, urgency, narrative, user-reputation proxies (karma, account age), subreddit activity.\n",
        "- Binary flags: has_image, has_url, mentions_pizza, mentions_money, day-of-week/hour.\n",
        "\n",
        "Models:\n",
        "- Linear models on sparse TF-IDF: LogisticRegression, LinearSVC (calibrated).\n",
        "- Tree models on dense/meta features: XGBoost/LightGBM (CPU ok; GPU optional).\n",
        "- Optionally Naive Bayes\u2013SVM (NB-SVM) style log-count ratio features.\n",
        "\n",
        "Ensembling:\n",
        "- Blend linear text model with boosted trees on meta features.\n",
        "- Optionally stack: meta-model on OOF predictions.\n",
        "\n",
        "Efficiency:\n",
        "- Cache: TF-IDF matrices (train/test), OOF preds, test preds, feature frames.\n",
        "- Log per-fold progress and elapsed time.\n",
        "- Subsample quick checks (1k rows, 2 folds) before full runs.\n",
        "\n",
        "Milestones (expert review at each):\n",
        "1) Baseline plan + data loading/EDA\n",
        "2) CV established + TF-IDF/logreg baseline OOF/LB\n",
        "3) Add meta + text-engineered features; evaluate\n",
        "4) NB-SVM/Calibrated SVC; evaluate\n",
        "5) Gradient boosting on meta features; evaluate\n",
        "6) Blending; finalize and generate submission\n",
        "\n",
        "Next Steps:\n",
        "- Load and inspect train.json/test.json schema; identify label and text/meta fields.\n",
        "- Implement deterministic CV and text preprocessing pipeline; produce baseline OOF and submission."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "1d08c561-9674-479a-98fa-f910021673f5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data loading and quick EDA\n",
        "import os, json, re, time, gc, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "def read_json_file(path):\n",
        "    # Try reading as a JSON array; fallback to lines\n",
        "    try:\n",
        "        df = pd.read_json(path)\n",
        "    except ValueError:\n",
        "        df = pd.read_json(path, lines=True)\n",
        "    return df\n",
        "\n",
        "train_path = 'train.json'\n",
        "test_path = 'test.json'\n",
        "\n",
        "train = read_json_file(train_path)\n",
        "test = read_json_file(test_path)\n",
        "\n",
        "print('Train shape:', train.shape)\n",
        "print('Test shape:', test.shape)\n",
        "print('Train columns:', list(train.columns))\n",
        "print('Test columns:', list(test.columns))\n",
        "\n",
        "# Peek at sample submission to identify ID/target column names\n",
        "sample = pd.read_csv('sampleSubmission.csv')\n",
        "print('SampleSubmission head:')\n",
        "print(sample.head())\n",
        "\n",
        "# Identify id and target names from sample submission\n",
        "id_col = sample.columns[0]\n",
        "target_col = sample.columns[1]\n",
        "print('ID column in sample:', id_col, '| Target column:', target_col)\n",
        "\n",
        "# Basic label check\n",
        "if target_col in train.columns:\n",
        "    y = train[target_col].astype(int)\n",
        "    print('Label distribution:', y.value_counts(normalize=True).to_dict())\n",
        "else:\n",
        "    # Common label name in RAOP is requester_received_pizza\n",
        "    if 'requester_received_pizza' in train.columns:\n",
        "        target_col = 'requester_received_pizza'\n",
        "        y = train[target_col].astype(int)\n",
        "        print('Label distribution (requester_received_pizza):', y.value_counts(normalize=True).to_dict())\n",
        "    else:\n",
        "        raise RuntimeError('Could not locate target column in train.json')\n",
        "\n",
        "# Identify text fields; typical: request_title, request_text or request_text_edit_aware\n",
        "text_cols_candidates = [c for c in ['request_title','request_text_edit_aware','request_text'] if c in train.columns]\n",
        "print('Text columns found:', text_cols_candidates)\n",
        "if not text_cols_candidates:\n",
        "    raise RuntimeError('No text columns found in dataset')\n",
        "\n",
        "def preprocess_text_df(df):\n",
        "    title = df[text_cols_candidates[0]].fillna('') if 'request_title' in text_cols_candidates[0] or 'request_title' in df.columns else ''\n",
        "    # Prefer edit-aware if present, else request_text\n",
        "    body_col = 'request_text_edit_aware' if 'request_text_edit_aware' in df.columns else ('request_text' if 'request_text' in df.columns else None)\n",
        "    body = df[body_col].fillna('') if body_col else ''\n",
        "    # Simple URL replacement\n",
        "    def replace_urls(s):\n",
        "        return re.sub(r'http\\S+|www\\.[^\\s]+', ' [URL] ', s, flags=re.IGNORECASE)\n",
        "    joined = (title.astype(str) + ' [SEP] ' + body.astype(str)).str.lower().map(replace_urls)\n",
        "    return joined\n",
        "\n",
        "train_text = preprocess_text_df(train)\n",
        "test_text = preprocess_text_df(test)\n",
        "print('Example combined text (train):')\n",
        "print(train_text.iloc[0][:300] if len(train_text) else 'N/A')\n",
        "\n",
        "# Ensure ID column exists in both train/test\n",
        "if id_col not in train.columns:\n",
        "    # Common RAOP id is 'request_id'\n",
        "    if 'request_id' in train.columns:\n",
        "        id_col = 'request_id'\n",
        "    else:\n",
        "        # Fallback: try to infer\n",
        "        raise RuntimeError(f'ID column {id_col} from sample not found; available: {list(train.columns)}')\n",
        "if id_col not in test.columns:\n",
        "    if 'request_id' in test.columns:\n",
        "        id_col = 'request_id'\n",
        "    else:\n",
        "        raise RuntimeError(f'ID column {id_col} not in test; available: {list(test.columns)}')\n",
        "\n",
        "print('Using ID column:', id_col, 'and target column:', target_col)\n",
        "\n",
        "# Save quick schema snapshot for reference\n",
        "schema_info = {\n",
        "    'train_shape': train.shape,\n",
        "    'test_shape': test.shape,\n",
        "    'id_col': id_col,\n",
        "    'target_col': target_col,\n",
        "    'text_cols': text_cols_candidates,\n",
        "}\n",
        "print('Schema summary:', schema_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (2878, 32)\nTest shape: (1162, 17)\nTrain columns: ['giver_username_if_known', 'number_of_downvotes_of_request_at_retrieval', 'number_of_upvotes_of_request_at_retrieval', 'post_was_edited', 'request_id', 'request_number_of_comments_at_retrieval', 'request_text', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_account_age_in_days_at_retrieval', 'requester_days_since_first_post_on_raop_at_request', 'requester_days_since_first_post_on_raop_at_retrieval', 'requester_number_of_comments_at_request', 'requester_number_of_comments_at_retrieval', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_comments_in_raop_at_retrieval', 'requester_number_of_posts_at_request', 'requester_number_of_posts_at_retrieval', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_posts_on_raop_at_retrieval', 'requester_number_of_subreddits_at_request', 'requester_received_pizza', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_minus_downvotes_at_retrieval', 'requester_upvotes_plus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_retrieval', 'requester_user_flair', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\nTest columns: ['giver_username_if_known', 'request_id', 'request_text_edit_aware', 'request_title', 'requester_account_age_in_days_at_request', 'requester_days_since_first_post_on_raop_at_request', 'requester_number_of_comments_at_request', 'requester_number_of_comments_in_raop_at_request', 'requester_number_of_posts_at_request', 'requester_number_of_posts_on_raop_at_request', 'requester_number_of_subreddits_at_request', 'requester_subreddits_at_request', 'requester_upvotes_minus_downvotes_at_request', 'requester_upvotes_plus_downvotes_at_request', 'requester_username', 'unix_timestamp_of_request', 'unix_timestamp_of_request_utc']\nSampleSubmission head:\n  request_id  requester_received_pizza\n0  t3_1aw5zf                         0\n1   t3_roiuw                         0\n2   t3_mjnbq                         0\n3   t3_t8wd1                         0\n4  t3_1m4zxu                         0\nID column in sample: request_id | Target column: requester_received_pizza\nLabel distribution: {0: 0.7515635858234886, 1: 0.24843641417651147}\nText columns found: ['request_title', 'request_text_edit_aware', 'request_text']\nExample combined text (train):\n[request] oceanside, ca. usa-  us marine getting ready to deploy. [sep] i will soon be going on a long deployment which i'm not aloud to discuss but willing to give some info if you ask. just wanna eat some of the stuff america has to offer before i leave for a long time to afganistan.\nUsing ID column: request_id and target column: requester_received_pizza\nSchema summary: {'train_shape': (2878, 32), 'test_shape': (1162, 17), 'id_col': 'request_id', 'target_col': 'requester_received_pizza', 'text_cols': ['request_title', 'request_text_edit_aware', 'request_text']}\n"
          ]
        }
      ]
    },
    {
      "id": "829e20d5-49a9-48f5-afb6-092c49edfb28",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Baseline: TF-IDF (word 1-2) + LogisticRegression with 5-fold Stratified CV\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "X_text = train_text.values.astype(str)\n",
        "y = train[target_col].astype(int).values\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "oof = np.zeros(len(train))\n",
        "test_pred_folds = []\n",
        "\n",
        "start = time.time()\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_text, y), 1):\n",
        "    t0 = time.time()\n",
        "    X_tr_text = X_text[tr_idx]\n",
        "    X_va_text = X_text[va_idx]\n",
        "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "    # Vectorizer fit inside fold (no leakage)\n",
        "    vec = TfidfVectorizer(lowercase=True, strip_accents='unicode',\n",
        "                          ngram_range=(1,2), min_df=2, max_features=300000,\n",
        "                          sublinear_tf=True)\n",
        "    X_tr = vec.fit_transform(X_tr_text)\n",
        "    X_va = vec.transform(X_va_text)\n",
        "    X_te = vec.transform(test_text.values.astype(str))\n",
        "\n",
        "    clf = LogisticRegression(solver='saga', C=2.0, penalty='l2',\n",
        "                             max_iter=2000, n_jobs=-1, class_weight='balanced',\n",
        "                             random_state=SEED + fold)\n",
        "    clf.fit(X_tr, y_tr)\n",
        "    oof[va_idx] = clf.predict_proba(X_va)[:,1]\n",
        "    fold_auc = roc_auc_score(y_va, oof[va_idx])\n",
        "    test_pred_folds.append(clf.predict_proba(X_te)[:,1])\n",
        "    elapsed = time.time() - t0\n",
        "    print(f'Fold {fold} AUC: {fold_auc:.5f} | time: {elapsed:.2f}s', flush=True)\n",
        "\n",
        "oof_auc = roc_auc_score(y, oof)\n",
        "print(f'OOF AUC: {oof_auc:.5f} | total time: {time.time()-start:.2f}s', flush=True)\n",
        "\n",
        "# Blend test predictions across folds\n",
        "test_pred = np.mean(np.vstack(test_pred_folds), axis=0)\n",
        "\n",
        "# Save OOF and test predictions for reuse\n",
        "np.save('oof_lr_tfidf.npy', oof)\n",
        "np.save('test_lr_tfidf.npy', test_pred)\n",
        "\n",
        "# Build submission\n",
        "sub = pd.DataFrame({id_col: test[id_col].values, target_col: test_pred})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with shape', sub.shape, 'and columns', list(sub.columns))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 AUC: 0.62931 | time: 0.99s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 AUC: 0.63082 | time: 0.94s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 AUC: 0.64105 | time: 0.92s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 AUC: 0.58332 | time: 0.94s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 AUC: 0.64344 | time: 0.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF AUC: 0.62528 | total time: 4.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv with shape (1162, 2) and columns ['request_id', 'requester_received_pizza']\n"
          ]
        }
      ]
    },
    {
      "id": "d3cf295d-7f58-481f-8289-2a591d3423ac",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Improved baseline: word (1-2) + char_wb (3-5) TF-IDF, LogisticRegression (C=4), 5-fold CV\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "X_text = train_text.values.astype(str)\n",
        "y = train[target_col].astype(int).values\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "oof2 = np.zeros(len(train))\n",
        "test_pred_folds2 = []\n",
        "\n",
        "start = time.time()\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_text, y), 1):\n",
        "    t0 = time.time()\n",
        "    X_tr_text = X_text[tr_idx]\n",
        "    X_va_text = X_text[va_idx]\n",
        "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "    # Fit vectorizers inside fold\n",
        "    vec_w = TfidfVectorizer(lowercase=True, strip_accents='unicode',\n",
        "                            analyzer='word', ngram_range=(1,2), min_df=2,\n",
        "                            max_features=60000, sublinear_tf=True)\n",
        "    vec_c = TfidfVectorizer(lowercase=True, strip_accents='unicode',\n",
        "                            analyzer='char_wb', ngram_range=(3,5), min_df=2,\n",
        "                            max_features=200000, sublinear_tf=True)\n",
        "\n",
        "    X_tr_w = vec_w.fit_transform(X_tr_text)\n",
        "    X_va_w = vec_w.transform(X_va_text)\n",
        "    X_te_w = vec_w.transform(test_text.values.astype(str))\n",
        "\n",
        "    X_tr_c = vec_c.fit_transform(X_tr_text)\n",
        "    X_va_c = vec_c.transform(X_va_text)\n",
        "    X_te_c = vec_c.transform(test_text.values.astype(str))\n",
        "\n",
        "    X_tr = hstack([X_tr_w, X_tr_c]).tocsr()\n",
        "    X_va = hstack([X_va_w, X_va_c]).tocsr()\n",
        "    X_te = hstack([X_te_w, X_te_c]).tocsr()\n",
        "\n",
        "    clf = LogisticRegression(solver='saga', C=4.0, penalty='l2',\n",
        "                             max_iter=3000, n_jobs=-1, class_weight='balanced',\n",
        "                             random_state=SEED + 1337 + fold)\n",
        "    clf.fit(X_tr, y_tr)\n",
        "    oof2[va_idx] = clf.predict_proba(X_va)[:,1]\n",
        "    fold_auc = roc_auc_score(y_va, oof2[va_idx])\n",
        "    test_pred_folds2.append(clf.predict_proba(X_te)[:,1])\n",
        "    elapsed = time.time() - t0\n",
        "    print(f'[word+char] Fold {fold} AUC: {fold_auc:.5f} | time: {elapsed:.2f}s', flush=True)\n",
        "\n",
        "oof_auc2 = roc_auc_score(y, oof2)\n",
        "print(f'[word+char] OOF AUC: {oof_auc2:.5f} | total time: {time.time()-start:.2f}s', flush=True)\n",
        "\n",
        "test_pred2 = np.mean(np.vstack(test_pred_folds2), axis=0)\n",
        "np.save('oof_lr_tfidf_wordchar.npy', oof2)\n",
        "np.save('test_lr_tfidf_wordchar.npy', test_pred2)\n",
        "\n",
        "# Save improved submission variant\n",
        "sub2 = pd.DataFrame({id_col: test[id_col].values, target_col: test_pred2})\n",
        "sub2.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (word+char) with shape', sub2.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word+char] Fold 1 AUC: 0.61288 | time: 9.43s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word+char] Fold 2 AUC: 0.63908 | time: 9.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word+char] Fold 3 AUC: 0.62343 | time: 9.11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word+char] Fold 4 AUC: 0.58649 | time: 9.56s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word+char] Fold 5 AUC: 0.61231 | time: 8.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word+char] OOF AUC: 0.61491 | total time: 46.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (word+char) with shape (1162, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "f2a9c7cd-710c-48eb-9c99-6783eea13824",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fix preprocessing (keep URLs/domains) and tighten TF-IDF; tune LR C on word-only\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Redefine text preprocessing: keep raw text (no URL replacement); prefer edit-aware to match test\n",
        "def preprocess_text_df_keep_urls(df):\n",
        "    title = df['request_title'].fillna('') if 'request_title' in df.columns else ''\n",
        "    body_col = 'request_text_edit_aware' if 'request_text_edit_aware' in df.columns else ('request_text' if 'request_text' in df.columns else None)\n",
        "    body = df[body_col].fillna('') if body_col else ''\n",
        "    joined = (title.astype(str) + ' [SEP] ' + body.astype(str)).str.lower()\n",
        "    return joined\n",
        "\n",
        "train_text = preprocess_text_df_keep_urls(train)\n",
        "test_text = preprocess_text_df_keep_urls(test)\n",
        "print('Rebuilt text with URLs kept. Example:', train_text.iloc[0][:200])\n",
        "\n",
        "X_text = train_text.values.astype(str)\n",
        "y = train[target_col].astype(int).values\n",
        "\n",
        "Cs = [0.5, 1.0, 2.0]\n",
        "best_auc = -1.0\n",
        "best_C = None\n",
        "best_oof = None\n",
        "best_test_pred = None\n",
        "\n",
        "for C in Cs:\n",
        "    print(f'\\n=== Training word-only TF-IDF + LR with C={C} ===')\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    oof_c = np.zeros(len(train))\n",
        "    test_pred_folds_c = []\n",
        "    start = time.time()\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_text, y), 1):\n",
        "        t0 = time.time()\n",
        "        X_tr_text = X_text[tr_idx]\n",
        "        X_va_text = X_text[va_idx]\n",
        "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "        vec = TfidfVectorizer(lowercase=True, strip_accents='unicode',\n",
        "                              analyzer='word', ngram_range=(1,2),\n",
        "                              min_df=5, max_features=60000, sublinear_tf=True)\n",
        "        X_tr = vec.fit_transform(X_tr_text)\n",
        "        X_va = vec.transform(X_va_text)\n",
        "        X_te = vec.transform(test_text.values.astype(str))\n",
        "\n",
        "        clf = LogisticRegression(solver='saga', C=C, penalty='l2',\n",
        "                                 max_iter=2000, n_jobs=-1, random_state=SEED+fold)\n",
        "        clf.fit(X_tr, y_tr)\n",
        "        oof_c[va_idx] = clf.predict_proba(X_va)[:,1]\n",
        "        fold_auc = roc_auc_score(y_va, oof_c[va_idx])\n",
        "        test_pred_folds_c.append(clf.predict_proba(X_te)[:,1])\n",
        "        print(f'[word-only C={C}] Fold {fold} AUC: {fold_auc:.5f} | time: {time.time()-t0:.2f}s', flush=True)\n",
        "\n",
        "    oof_auc_c = roc_auc_score(y, oof_c)\n",
        "    test_pred_c = np.mean(np.vstack(test_pred_folds_c), axis=0)\n",
        "    print(f'[word-only C={C}] OOF AUC: {oof_auc_c:.5f} | total time: {time.time()-start:.2f}s', flush=True)\n",
        "\n",
        "    if oof_auc_c > best_auc:\n",
        "        best_auc = oof_auc_c\n",
        "        best_C = C\n",
        "        best_oof = oof_c.copy()\n",
        "        best_test_pred = test_pred_c.copy()\n",
        "\n",
        "print(f'Best C: {best_C} with OOF AUC: {best_auc:.5f}')\n",
        "\n",
        "# Save best predictions and submission\n",
        "np.save('oof_lr_tfidf_word_only.npy', best_oof)\n",
        "np.save('test_lr_tfidf_word_only.npy', best_test_pred)\n",
        "sub_best = pd.DataFrame({id_col: test[id_col].values, target_col: best_test_pred})\n",
        "sub_best.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (word-only tuned) with shape', sub_best.shape, 'best C:', best_C)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rebuilt text with URLs kept. Example: [request] oceanside, ca. usa-  us marine getting ready to deploy. [sep] i will soon be going on a long deployment which i'm not aloud to discuss but willing to give some info if you ask. just wanna ea\n\n=== Training word-only TF-IDF + LR with C=0.5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=0.5] Fold 1 AUC: 0.64491 | time: 0.80s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=0.5] Fold 2 AUC: 0.64580 | time: 0.80s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=0.5] Fold 3 AUC: 0.64008 | time: 0.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=0.5] Fold 4 AUC: 0.59855 | time: 0.80s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=0.5] Fold 5 AUC: 0.65375 | time: 0.71s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=0.5] OOF AUC: 0.63614 | total time: 3.94s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n=== Training word-only TF-IDF + LR with C=1.0 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=1.0] Fold 1 AUC: 0.63859 | time: 0.88s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=1.0] Fold 2 AUC: 0.64542 | time: 0.88s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=1.0] Fold 3 AUC: 0.64169 | time: 0.91s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=1.0] Fold 4 AUC: 0.59489 | time: 0.89s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=1.0] Fold 5 AUC: 0.64655 | time: 0.80s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=1.0] OOF AUC: 0.63296 | total time: 4.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n=== Training word-only TF-IDF + LR with C=2.0 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=2.0] Fold 1 AUC: 0.63008 | time: 1.00s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=2.0] Fold 2 AUC: 0.64533 | time: 1.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=2.0] Fold 3 AUC: 0.64105 | time: 1.02s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=2.0] Fold 4 AUC: 0.58709 | time: 0.99s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=2.0] Fold 5 AUC: 0.63672 | time: 0.91s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[word-only C=2.0] OOF AUC: 0.62754 | total time: 4.92s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C: 0.5 with OOF AUC: 0.63614\nSaved submission.csv (word-only tuned) with shape (1162, 2) best C: 0.5\n"
          ]
        }
      ]
    },
    {
      "id": "8b90a3c7-e6a1-4a79-9a17-5c2fdfa036fa",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# NB-SVM (log-count ratio) with word counts (1,2), min_df=3, max_features=50k\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def compute_log_count_ratio(X, y, alpha=1.0):\n",
        "    # X is csr, y is binary array (0/1)\n",
        "    pos_mask = (y == 1)\n",
        "    neg_mask = (y == 0)\n",
        "    # Sum counts per feature for each class\n",
        "    pos_counts = X[pos_mask].sum(axis=0) + alpha\n",
        "    neg_counts = X[neg_mask].sum(axis=0) + alpha\n",
        "    # Normalize to probabilities\n",
        "    pos_total = np.asarray(pos_counts).sum()\n",
        "    neg_total = np.asarray(neg_counts).sum()\n",
        "    p_pos = np.asarray(pos_counts / pos_total).ravel()\n",
        "    p_neg = np.asarray(neg_counts / neg_total).ravel()\n",
        "    r = np.log(p_pos / p_neg)\n",
        "    return r\n",
        "\n",
        "X_text = train_text.values.astype(str)\n",
        "y = train[target_col].astype(int).values\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "oof_nbsvm = np.zeros(len(train))\n",
        "test_pred_folds_nbsvm = []\n",
        "\n",
        "start = time.time()\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_text, y), 1):\n",
        "    t0 = time.time()\n",
        "    X_tr_text = X_text[tr_idx]\n",
        "    X_va_text = X_text[va_idx]\n",
        "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "    vec = CountVectorizer(lowercase=True, strip_accents='unicode',\n",
        "                          analyzer='word', ngram_range=(1,2),\n",
        "                          min_df=3, max_features=50000)\n",
        "    X_tr = vec.fit_transform(X_tr_text)\n",
        "    X_va = vec.transform(X_va_text)\n",
        "    X_te = vec.transform(test_text.values.astype(str))\n",
        "\n",
        "    r = compute_log_count_ratio(X_tr, y_tr, alpha=1.0)\n",
        "    # Reweight by log-count ratio\n",
        "    X_tr_lr = X_tr.multiply(r)\n",
        "    X_va_lr = X_va.multiply(r)\n",
        "    X_te_lr = X_te.multiply(r)\n",
        "\n",
        "    clf = LogisticRegression(solver='saga', C=2.0, penalty='l2',\n",
        "                             max_iter=2000, n_jobs=-1, random_state=SEED+fold)\n",
        "    clf.fit(X_tr_lr, y_tr)\n",
        "    oof_nbsvm[va_idx] = clf.predict_proba(X_va_lr)[:,1]\n",
        "    fold_auc = roc_auc_score(y_va, oof_nbsvm[va_idx])\n",
        "    test_pred_folds_nbsvm.append(clf.predict_proba(X_te_lr)[:,1])\n",
        "    print(f'[NB-SVM] Fold {fold} AUC: {fold_auc:.5f} | time: {time.time()-t0:.2f}s', flush=True)\n",
        "\n",
        "oof_auc_nbsvm = roc_auc_score(y, oof_nbsvm)\n",
        "print(f'[NB-SVM] OOF AUC: {oof_auc_nbsvm:.5f} | total time: {time.time()-start:.2f}s', flush=True)\n",
        "\n",
        "test_pred_nbsvm = np.mean(np.vstack(test_pred_folds_nbsvm), axis=0)\n",
        "np.save('oof_nbsvm.npy', oof_nbsvm)\n",
        "np.save('test_nbsvm.npy', test_pred_nbsvm)\n",
        "\n",
        "# Save submission from NB-SVM\n",
        "sub_nbsvm = pd.DataFrame({id_col: test[id_col].values, target_col: test_pred_nbsvm})\n",
        "sub_nbsvm.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (NB-SVM) with shape', sub_nbsvm.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NB-SVM] Fold 1 AUC: 0.56177 | time: 1.89s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NB-SVM] Fold 2 AUC: 0.58880 | time: 5.55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NB-SVM] Fold 3 AUC: 0.59479 | time: 5.55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NB-SVM] Fold 4 AUC: 0.52723 | time: 5.54s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NB-SVM] Fold 5 AUC: 0.55031 | time: 1.97s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NB-SVM] OOF AUC: 0.56467 | total time: 20.51s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (NB-SVM) with shape (1162, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "c91dc69d-baee-4d20-947a-bd505ef35127",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Meta/features model: XGBoost on *_at_request + timing + rich text/domain flags; 5-fold CV and blend\n",
        "import time, re, math, ast, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "def build_meta_features(df):\n",
        "    feats = pd.DataFrame(index=df.index)\n",
        "    # Numeric *_at_request columns present in both train/test\n",
        "    cols_req = [\n",
        "        'requester_account_age_in_days_at_request',\n",
        "        'requester_days_since_first_post_on_raop_at_request',\n",
        "        'requester_number_of_comments_at_request',\n",
        "        'requester_number_of_comments_in_raop_at_request',\n",
        "        'requester_number_of_posts_at_request',\n",
        "        'requester_number_of_posts_on_raop_at_request',\n",
        "        'requester_number_of_subreddits_at_request',\n",
        "        'requester_upvotes_minus_downvotes_at_request',\n",
        "        'requester_upvotes_plus_downvotes_at_request',\n",
        "        'unix_timestamp_of_request'\n",
        "    ]\n",
        "    for c in cols_req:\n",
        "        feats[c] = pd.to_numeric(df[c], errors='coerce') if c in df.columns else 0.0\n",
        "    # Time features\n",
        "    ts = feats['unix_timestamp_of_request'].fillna(0).astype(float)\n",
        "    feats['hour'] = ((ts // 3600) % 24).astype(int)\n",
        "    feats['dow'] = ((ts // 86400) + 4).astype(int) % 7  # epoch 1970-01-01 was Thursday\n",
        "    feats['is_weekend'] = feats['dow'].isin([5,6]).astype(int)\n",
        "    feats['month'] = pd.to_datetime(ts, unit='s', errors='coerce').dt.month.fillna(0).astype(int)\n",
        "    # Rates (per day), avoid div by zero\n",
        "    acc_age = feats['requester_account_age_in_days_at_request'].fillna(0).astype(float) + 1.0\n",
        "    feats['comments_per_day'] = feats['requester_number_of_comments_at_request'].fillna(0).astype(float) / acc_age\n",
        "    feats['posts_per_day'] = feats['requester_number_of_posts_at_request'].fillna(0).astype(float) / acc_age\n",
        "    feats['karma_plus_per_day'] = feats['requester_upvotes_plus_downvotes_at_request'].fillna(0).astype(float) / acc_age\n",
        "    feats['karma_minus_per_day'] = feats['requester_upvotes_minus_downvotes_at_request'].fillna(0).astype(float) / acc_age\n",
        "    # RAOP ratios\n",
        "    denom_comments = feats['requester_number_of_comments_at_request'].fillna(0).astype(float) + 1.0\n",
        "    denom_posts = feats['requester_number_of_posts_at_request'].fillna(0).astype(float) + 1.0\n",
        "    feats['raop_comments_share'] = feats['requester_number_of_comments_in_raop_at_request'].fillna(0).astype(float) / denom_comments\n",
        "    feats['raop_posts_share'] = feats['requester_number_of_posts_on_raop_at_request'].fillna(0).astype(float) / denom_posts\n",
        "    feats['prior_raop_flag'] = (feats['requester_number_of_posts_on_raop_at_request'].fillna(0) > 0).astype(int)\n",
        "    feats['newbie_flag'] = (feats['requester_account_age_in_days_at_request'].fillna(0) < 30).astype(int)\n",
        "    # requester_subreddits_at_request: count\n",
        "    if 'requester_subreddits_at_request' in df.columns:\n",
        "        def sub_count(x):\n",
        "            if isinstance(x, list):\n",
        "                return len(x)\n",
        "            try:\n",
        "                if isinstance(x, str):\n",
        "                    val = ast.literal_eval(x)\n",
        "                    return len(val) if isinstance(val, list) else 0\n",
        "            except Exception:\n",
        "                return 0\n",
        "            return 0\n",
        "        feats['subreddits_count'] = df['requester_subreddits_at_request'].apply(sub_count)\n",
        "    else:\n",
        "        feats['subreddits_count'] = 0\n",
        "    # Build text locally from df (title + edit_aware or text), keep URLs\n",
        "    title = df['request_title'].fillna('') if 'request_title' in df.columns else ''\n",
        "    body_col = 'request_text_edit_aware' if 'request_text_edit_aware' in df.columns else ('request_text' if 'request_text' in df.columns else None)\n",
        "    body = df[body_col].fillna('') if body_col else ''\n",
        "    title_l = title.astype(str).str.lower() if isinstance(title, pd.Series) else pd.Series(['']*len(df))\n",
        "    body_l = body.astype(str).str.lower() if isinstance(body, pd.Series) else pd.Series(['']*len(df))\n",
        "    text_series = (title_l + ' ' + body_l).fillna('')\n",
        "    feats['n_chars'] = text_series.str.len().astype(int)\n",
        "    feats['n_words'] = text_series.str.split().str.len().astype(int)\n",
        "    feats['title_len'] = title_l.str.len().astype(int) if isinstance(title_l, pd.Series) else 0\n",
        "    # URL/image/domain flags\n",
        "    def count_pattern(s, pat):\n",
        "        return len(re.findall(pat, s)) if isinstance(s, str) else 0\n",
        "    feats['has_url'] = text_series.apply(lambda s: int(bool(re.search(r'http[s]?://|www\\.', s))))\n",
        "    feats['num_urls'] = text_series.apply(lambda s: count_pattern(s, r'http[s]?://|www\\.'))\n",
        "    feats['has_imgur'] = text_series.apply(lambda s: int(isinstance(s, str) and ('imgur' in s)))\n",
        "    feats['num_imgur'] = text_series.apply(lambda s: s.count('imgur') if isinstance(s, str) else 0)\n",
        "    feats['imgur_in_title'] = title_l.apply(lambda s: int('imgur' in s) if isinstance(s, str) else 0)\n",
        "    feats['imgur_in_body'] = body_l.apply(lambda s: int('imgur' in s) if isinstance(s, str) else 0)\n",
        "    feats['has_image_ext'] = text_series.apply(lambda s: int(bool(re.search(r'\\.(jpg|jpeg|png|gif)(\\b|$)', s))))\n",
        "    # Domain buckets\n",
        "    domains = ['reddit','youtube','gyazo','tinypic','dropbox','google','blogspot']\n",
        "    for d in domains:\n",
        "        feats[f'domain_{d}'] = text_series.apply(lambda s: int(d in s))\n",
        "    # Politeness/reciprocity/urgency keywords\n",
        "    kw_money = ['$', 'usd', 'dollar', 'rent', 'bill', 'bills', 'paycheck', 'broke', 'unemployed', 'laid off', 'jobless', 'homeless']\n",
        "    kw_urgency = ['hungry', 'starving', 'emergency', 'asap', 'today', 'tonight', 'now']\n",
        "    kw_roles = ['student', 'college', 'finals', 'exam', 'interview', 'job', 'veteran', 'military', 'marine', 'kids', 'children', 'family', 'pregnant', 'wife', 'husband', 'roommate']\n",
        "    kw_evidence = ['picture', 'photo', 'album', 'proof', 'receipt', 'screenshot', 'link']\n",
        "    def kw_count(s, kws):\n",
        "        if not isinstance(s, str): return 0\n",
        "        return sum(s.count(k) for k in kws)\n",
        "    feats['please_cnt'] = text_series.apply(lambda s: s.count('please') if isinstance(s, str) else 0)\n",
        "    feats['thanks_cnt'] = text_series.apply(lambda s: s.count('thank') if isinstance(s, str) else 0)\n",
        "    feats['payitforward_cnt'] = text_series.apply(lambda s: sum(s.count(k) for k in ['pay it forward','return the favor','pay-it-forward']) if isinstance(s, str) else 0)\n",
        "    feats['money_kw_cnt'] = text_series.apply(lambda s: kw_count(s, kw_money))\n",
        "    feats['urgency_kw_cnt'] = text_series.apply(lambda s: kw_count(s, kw_urgency))\n",
        "    feats['roles_kw_cnt'] = text_series.apply(lambda s: kw_count(s, kw_roles))\n",
        "    feats['evidence_kw_cnt'] = text_series.apply(lambda s: kw_count(s, kw_evidence))\n",
        "    # Structure/tone\n",
        "    feats['qmark_cnt'] = text_series.str.count('\\?').fillna(0).astype(int)\n",
        "    feats['excl_cnt'] = text_series.str.count('!').fillna(0).astype(int)\n",
        "    feats['dots_cnt'] = text_series.str.count('\\.\\.\\.').fillna(0).astype(int)\n",
        "    feats['digit_cnt'] = text_series.str.count('[0-9]').fillna(0).astype(int)\n",
        "    feats['uppercase_ratio'] = text_series.apply(lambda s: (sum(ch.isupper() for ch in s) / max(1,len(s))) if isinstance(s, str) else 0.0)\n",
        "    pronouns = re.compile(r'\\b(i|me|my|we|our)\\b')\n",
        "    feats['pronoun_density'] = text_series.apply(lambda s: (len(pronouns.findall(s))/max(1, len(s.split()))) if isinstance(s, str) else 0.0)\n",
        "    # Cyclical hour encoding\n",
        "    feats['hour_sin'] = np.sin(2*np.pi*feats['hour']/24.0)\n",
        "    feats['hour_cos'] = np.cos(2*np.pi*feats['hour']/24.0)\n",
        "    # Final cleanup: ensure numeric, finite, float32\n",
        "    for col in feats.columns:\n",
        "        feats[col] = pd.to_numeric(feats[col], errors='coerce')\n",
        "    feats = feats.replace([np.inf, -np.inf], 0).fillna(0).astype(np.float32)\n",
        "    return feats\n",
        "\n",
        "X_train_meta = build_meta_features(train)\n",
        "X_test_meta = build_meta_features(test)\n",
        "y = train[target_col].astype(int).values\n",
        "print('Meta features shape:', X_train_meta.shape, X_test_meta.shape, flush=True)\n",
        "\n",
        "# XGBoost model (hist, no early stopping due to API limits)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "oof_meta = np.zeros(len(train), dtype=np.float32)\n",
        "test_meta_folds = []\n",
        "start = time.time()\n",
        "pos = float(y.sum())\n",
        "neg = float(len(y) - pos)\n",
        "scale_pos_weight = max(1.0, neg / max(1.0, pos))\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_train_meta, y), 1):\n",
        "    t0 = time.time()\n",
        "    X_tr = X_train_meta.iloc[tr_idx]\n",
        "    X_va = X_train_meta.iloc[va_idx]\n",
        "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "    clf = XGBClassifier(\n",
        "        n_estimators=800,\n",
        "        learning_rate=0.06,\n",
        "        max_depth=4,\n",
        "        subsample=0.85,\n",
        "        colsample_bytree=0.75,\n",
        "        min_child_weight=3.0,\n",
        "        reg_lambda=1.5,\n",
        "        objective='binary:logistic',\n",
        "        eval_metric='auc',\n",
        "        tree_method='hist',\n",
        "        random_state=SEED+fold,\n",
        "        scale_pos_weight=scale_pos_weight\n",
        "    )\n",
        "    clf.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
        "    oof_meta[va_idx] = clf.predict_proba(X_va)[:,1]\n",
        "    fold_auc = roc_auc_score(y_va, oof_meta[va_idx])\n",
        "    test_meta_folds.append(clf.predict_proba(X_test_meta)[:,1])\n",
        "    print(f'[META-XGB] Fold {fold} AUC: {fold_auc:.5f} | time: {time.time()-t0:.2f}s', flush=True)\n",
        "\n",
        "print('[META-XGB] Finished all folds, computing OOF/test/blend...', flush=True)\n",
        "oof_auc_meta = roc_auc_score(y, oof_meta)\n",
        "print(f'[META-XGB] OOF AUC: {oof_auc_meta:.5f} | total time: {time.time()-start:.2f}s', flush=True)\n",
        "test_meta = np.mean(np.vstack(test_meta_folds), axis=0)\n",
        "np.save('oof_meta_xgb.npy', oof_meta)\n",
        "np.save('test_meta_xgb.npy', test_meta)\n",
        "\n",
        "# Blend with best text model available (prefer word-only tuned from cell 4)\n",
        "oof_text, test_text_pred = None, None\n",
        "if os.path.exists('oof_lr_tfidf_word_only.npy') and os.path.exists('test_lr_tfidf_word_only.npy'):\n",
        "    oof_text = np.load('oof_lr_tfidf_word_only.npy')\n",
        "    test_text_pred = np.load('test_lr_tfidf_word_only.npy')\n",
        "elif os.path.exists('oof_lr_tfidf.npy') and os.path.exists('test_lr_tfidf.npy'):\n",
        "    oof_text = np.load('oof_lr_tfidf.npy')\n",
        "    test_text_pred = np.load('test_lr_tfidf.npy')\n",
        "else:\n",
        "    print('[BLEND] No text OOF found; skipping blend and saving meta-only submission.', flush=True)\n",
        "    sub_meta_only = pd.DataFrame({id_col: test[id_col].values, target_col: test_meta})\n",
        "    sub_meta_only.to_csv('submission_meta.csv', index=False)\n",
        "    sub_meta_only.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv and submission_meta.csv (META only)', flush=True)\n",
        "    raise SystemExit()\n",
        "\n",
        "def tune_blend_weight(oof_a, oof_b, y_true):\n",
        "    best_w, best_auc = 0.5, -1.0\n",
        "    for w in [i/20 for i in range(0,21)]:\n",
        "        pred = w*oof_a + (1-w)*oof_b\n",
        "        auc = roc_auc_score(y_true, pred)\n",
        "        if auc > best_auc:\n",
        "            best_auc, best_w = auc, w\n",
        "    return best_w, best_auc\n",
        "\n",
        "w_text, best_blend_auc = tune_blend_weight(oof_text, oof_meta, y)\n",
        "print(f'[BLEND] Best weight on text: {w_text:.2f} | OOF AUC: {best_blend_auc:.5f}', flush=True)\n",
        "test_blend = w_text*test_text_pred + (1-w_text)*test_meta\n",
        "np.save('test_blend.npy', test_blend)\n",
        "\n",
        "# Save submissions\n",
        "sub_blend = pd.DataFrame({id_col: test[id_col].values, target_col: test_blend})\n",
        "sub_blend.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (BLEND) with shape', sub_blend.shape, '| w_text=', w_text, flush=True)\n",
        "pd.DataFrame({id_col: test[id_col].values, target_col: test_meta}).to_csv('submission_meta.csv', index=False)\n",
        "print('Saved submission_meta.csv (META only)', flush=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta features shape: (2878, 55) (1162, 55)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB] Fold 1 AUC: 0.64911 | time: 0.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB] Fold 2 AUC: 0.64476 | time: 0.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB] Fold 3 AUC: 0.69735 | time: 0.81s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB] Fold 4 AUC: 0.58628 | time: 0.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB] Fold 5 AUC: 0.66317 | time: 0.81s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB] Finished all folds, computing OOF/test/blend...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB] OOF AUC: 0.64700 | total time: 4.09s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BLEND] Best weight on text: 0.80 | OOF AUC: 0.67328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (BLEND) with shape (1162, 2) | w_text= 0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_meta.csv (META only)\n"
          ]
        }
      ]
    },
    {
      "id": "8b8226da-cf57-484e-bdd3-643b7773cab7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Improved text baseline v2: word(1,2) TF-IDF with better tokenization (keep URLs), no [SEP], LR lbfgs; blend with meta OOF\n",
        "import time, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def preprocess_text_urls_no_sep(df):\n",
        "    title = df['request_title'].fillna('') if 'request_title' in df.columns else ''\n",
        "    body_col = 'request_text_edit_aware' if 'request_text_edit_aware' in df.columns else ('request_text' if 'request_text' in df.columns else None)\n",
        "    body = df[body_col].fillna('') if body_col else ''\n",
        "    # Simple concat with space; keep URLs/domains; lowercase\n",
        "    return (title.astype(str) + ' ' + body.astype(str)).str.lower()\n",
        "\n",
        "train_text_v2 = preprocess_text_urls_no_sep(train)\n",
        "test_text_v2 = preprocess_text_urls_no_sep(test)\n",
        "X_text = train_text_v2.values.astype(str)\n",
        "y = train[target_col].astype(int).values\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "oof_t = np.zeros(len(train))\n",
        "test_pred_folds_t = []\n",
        "start = time.time()\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_text, y), 1):\n",
        "    t0 = time.time()\n",
        "    X_tr_text = X_text[tr_idx]\n",
        "    X_va_text = X_text[va_idx]\n",
        "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "    vec = TfidfVectorizer(\n",
        "        lowercase=True, strip_accents='unicode',\n",
        "        analyzer='word', ngram_range=(1,2),\n",
        "        min_df=3, max_features=60000, sublinear_tf=True,\n",
        "        token_pattern=r'(?u)\\b\\w+\\b'\n",
        "    )\n",
        "    X_tr = vec.fit_transform(X_tr_text)\n",
        "    X_va = vec.transform(X_va_text)\n",
        "    X_te = vec.transform(test_text_v2.values.astype(str))\n",
        "    clf = LogisticRegression(solver='lbfgs', C=1.0, max_iter=2000, random_state=SEED+fold)\n",
        "    clf.fit(X_tr, y_tr)\n",
        "    oof_t[va_idx] = clf.predict_proba(X_va)[:,1]\n",
        "    fold_auc = roc_auc_score(y_va, oof_t[va_idx])\n",
        "    test_pred_folds_t.append(clf.predict_proba(X_te)[:,1])\n",
        "    print(f'[text-v2] Fold {fold} AUC: {fold_auc:.5f} | time: {time.time()-t0:.2f}s', flush=True)\n",
        "\n",
        "oof_auc_t = roc_auc_score(y, oof_t)\n",
        "test_pred_t = np.mean(np.vstack(test_pred_folds_t), axis=0)\n",
        "print(f'[text-v2] OOF AUC: {oof_auc_t:.5f} | total time: {time.time()-start:.2f}s', flush=True)\n",
        "\n",
        "# Save replacing previous word-only to be picked by other cells\n",
        "np.save('oof_lr_tfidf_word_only.npy', oof_t)\n",
        "np.save('test_lr_tfidf_word_only.npy', test_pred_t)\n",
        "\n",
        "# If meta OOF exists, compute tuned blend and save submission\n",
        "if os.path.exists('oof_meta_xgb.npy') and os.path.exists('test_meta_xgb.npy'):\n",
        "    oof_meta = np.load('oof_meta_xgb.npy')\n",
        "    test_meta = np.load('test_meta_xgb.npy')\n",
        "    best_w, best_auc = 0.5, -1.0\n",
        "    for w in [i/20 for i in range(0,21)]:\n",
        "        pred = w*oof_t + (1-w)*oof_meta\n",
        "        auc = roc_auc_score(y, pred)\n",
        "        if auc > best_auc:\n",
        "            best_auc, best_w = auc, w\n",
        "    print(f'[text+meta BLEND] Best weight on text: {best_w:.2f} | OOF AUC: {best_auc:.5f}', flush=True)\n",
        "    test_blend = best_w*test_pred_t + (1-best_w)*test_meta\n",
        "    pd.DataFrame({id_col: test[id_col].values, target_col: test_blend}).to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (blend via v2) with shape', (len(test_blend), 2))\n",
        "else:\n",
        "    pd.DataFrame({id_col: test[id_col].values, target_col: test_pred_t}).to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (text-v2 only); meta OOF not found')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v2] Fold 1 AUC: 0.64069 | time: 0.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v2] Fold 2 AUC: 0.64050 | time: 0.48s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v2] Fold 3 AUC: 0.63523 | time: 0.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v2] Fold 4 AUC: 0.59834 | time: 0.54s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v2] Fold 5 AUC: 0.64703 | time: 0.48s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v2] OOF AUC: 0.63231 | total time: 2.42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text+meta BLEND] Best weight on text: 0.75 | OOF AUC: 0.67137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (blend via v2) with shape (1162, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "745dd843-e689-4456-a66a-db8651fa45c4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Text baseline v3: word(1,2) TF-IDF grid over C and larger vocab; blend with meta\n",
        "import time, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def build_text_v3(df):\n",
        "    title = df['request_title'].fillna('') if 'request_title' in df.columns else ''\n",
        "    body_col = 'request_text_edit_aware' if 'request_text_edit_aware' in df.columns else ('request_text' if 'request_text' in df.columns else None)\n",
        "    body = df[body_col].fillna('') if body_col else ''\n",
        "    return (title.astype(str) + ' ' + body.astype(str)).str.lower()\n",
        "\n",
        "train_text_v3 = build_text_v3(train)\n",
        "test_text_v3 = build_text_v3(test)\n",
        "X_text = train_text_v3.values.astype(str)\n",
        "y = train[target_col].astype(int).values\n",
        "\n",
        "Cs = [0.5, 1.0, 2.0]\n",
        "best_auc, best_C = -1.0, None\n",
        "best_oof, best_test_pred = None, None\n",
        "\n",
        "for C in Cs:\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    oof_t = np.zeros(len(train))\n",
        "    test_pred_folds_t = []\n",
        "    start = time.time()\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_text, y), 1):\n",
        "        t0 = time.time()\n",
        "        X_tr_text = X_text[tr_idx]\n",
        "        X_va_text = X_text[va_idx]\n",
        "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "        vec = TfidfVectorizer(\n",
        "            lowercase=True, strip_accents='unicode',\n",
        "            analyzer='word', ngram_range=(1,2),\n",
        "            min_df=3, max_features=100000, sublinear_tf=True,\n",
        "            token_pattern=r'(?u)\\b\\w+\\b'\n",
        "        )\n",
        "        X_tr = vec.fit_transform(X_tr_text)\n",
        "        X_va = vec.transform(X_va_text)\n",
        "        X_te = vec.transform(test_text_v3.values.astype(str))\n",
        "        clf = LogisticRegression(solver='lbfgs', C=C, max_iter=3000, random_state=SEED+fold)\n",
        "        clf.fit(X_tr, y_tr)\n",
        "        oof_t[va_idx] = clf.predict_proba(X_va)[:,1]\n",
        "        test_pred_folds_t.append(clf.predict_proba(X_te)[:,1])\n",
        "        print(f'[text-v3 C={C}] Fold {fold} AUC: {roc_auc_score(y_va, oof_t[va_idx]):.5f} | time: {time.time()-t0:.2f}s', flush=True)\n",
        "    oof_auc_t = roc_auc_score(y, oof_t)\n",
        "    test_pred_t = np.mean(np.vstack(test_pred_folds_t), axis=0)\n",
        "    print(f'[text-v3 C={C}] OOF AUC: {oof_auc_t:.5f} | total time: {time.time()-start:.2f}s', flush=True)\n",
        "    if oof_auc_t > best_auc:\n",
        "        best_auc, best_C = oof_auc_t, C\n",
        "        best_oof, best_test_pred = oof_t.copy(), test_pred_t.copy()\n",
        "\n",
        "print(f'[text-v3] Best C: {best_C} with OOF AUC: {best_auc:.5f}', flush=True)\n",
        "np.save('oof_lr_tfidf_word_only.npy', best_oof)\n",
        "np.save('test_lr_tfidf_word_only.npy', best_test_pred)\n",
        "\n",
        "# Blend with meta if available\n",
        "if os.path.exists('oof_meta_xgb.npy') and os.path.exists('test_meta_xgb.npy'):\n",
        "    oof_meta = np.load('oof_meta_xgb.npy')\n",
        "    test_meta = np.load('test_meta_xgb.npy')\n",
        "    best_w, best_blend_auc = 0.5, -1.0\n",
        "    for w in [i/20 for i in range(0,21)]:\n",
        "        auc = roc_auc_score(y, w*best_oof + (1-w)*oof_meta)\n",
        "        if auc > best_blend_auc:\n",
        "            best_blend_auc, best_w = auc, w\n",
        "    print(f'[text-v3+meta] Best weight on text: {best_w:.2f} | OOF AUC: {best_blend_auc:.5f}', flush=True)\n",
        "    test_blend = best_w*best_test_pred + (1-best_w)*test_meta\n",
        "    pd.DataFrame({id_col: test[id_col].values, target_col: test_blend}).to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (text-v3 blend) with shape', (len(test_blend), 2))\n",
        "else:\n",
        "    pd.DataFrame({id_col: test[id_col].values, target_col: best_test_pred}).to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (text-v3 only)')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=0.5] Fold 1 AUC: 0.64378 | time: 0.42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=0.5] Fold 2 AUC: 0.64098 | time: 0.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=0.5] Fold 3 AUC: 0.63422 | time: 0.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=0.5] Fold 4 AUC: 0.60297 | time: 0.45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=0.5] Fold 5 AUC: 0.65364 | time: 0.45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=0.5] OOF AUC: 0.63475 | total time: 2.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=1.0] Fold 1 AUC: 0.64069 | time: 0.53s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=1.0] Fold 2 AUC: 0.64050 | time: 0.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=1.0] Fold 3 AUC: 0.63523 | time: 0.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=1.0] Fold 4 AUC: 0.59834 | time: 0.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=1.0] Fold 5 AUC: 0.64703 | time: 0.45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=1.0] OOF AUC: 0.63231 | total time: 2.40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=2.0] Fold 1 AUC: 0.63373 | time: 0.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=2.0] Fold 2 AUC: 0.63892 | time: 0.53s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=2.0] Fold 3 AUC: 0.63249 | time: 0.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=2.0] Fold 4 AUC: 0.59282 | time: 0.48s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=2.0] Fold 5 AUC: 0.63708 | time: 0.48s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3 C=2.0] OOF AUC: 0.62720 | total time: 2.43s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3] Best C: 0.5 with OOF AUC: 0.63475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[text-v3+meta] Best weight on text: 0.85 | OOF AUC: 0.67124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (text-v3 blend) with shape (1162, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "011d46e3-fe17-434f-b96b-7f6ba44e5bc3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Meta XGB param sweep (fast): try few combos to push OOF > 0.69; update blend\n",
        "import numpy as np, time, os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Reuse prebuilt features from cell 6\n",
        "X_trm = X_train_meta\n",
        "X_tem = X_test_meta\n",
        "y_bin = train[target_col].astype(int).values\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "pos = float(y_bin.sum()); neg = float(len(y_bin)-pos)\n",
        "spw = max(1.0, neg/max(1.0,pos))\n",
        "\n",
        "param_grid = [\n",
        "    {'max_depth':3, 'min_child_weight':3, 'subsample':0.90, 'colsample_bytree':0.70, 'learning_rate':0.06, 'n_estimators':900},\n",
        "    {'max_depth':3, 'min_child_weight':5, 'subsample':0.90, 'colsample_bytree':0.70, 'learning_rate':0.06, 'n_estimators':900},\n",
        "    {'max_depth':4, 'min_child_weight':5, 'subsample':0.85, 'colsample_bytree':0.70, 'learning_rate':0.05, 'n_estimators':900},\n",
        "    {'max_depth':4, 'min_child_weight':4, 'subsample':0.80, 'colsample_bytree':0.80, 'learning_rate':0.05, 'n_estimators':800},\n",
        "    {'max_depth':3, 'min_child_weight':4, 'subsample':0.85, 'colsample_bytree':0.80, 'learning_rate':0.05, 'n_estimators':1000},\n",
        "]\n",
        "\n",
        "best_auc, best_params = -1.0, None\n",
        "best_oof, best_test = None, None\n",
        "\n",
        "for i, p in enumerate(param_grid, 1):\n",
        "    oof = np.zeros(len(X_trm), dtype=np.float32)\n",
        "    test_folds = []\n",
        "    t0 = time.time()\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_trm, y_bin), 1):\n",
        "        X_tr, X_va = X_trm.iloc[tr_idx], X_trm.iloc[va_idx]\n",
        "        y_tr, y_va = y_bin[tr_idx], y_bin[va_idx]\n",
        "        clf = XGBClassifier(\n",
        "            n_estimators=p['n_estimators'],\n",
        "            learning_rate=p['learning_rate'],\n",
        "            max_depth=p['max_depth'],\n",
        "            subsample=p['subsample'],\n",
        "            colsample_bytree=p['colsample_bytree'],\n",
        "            min_child_weight=p['min_child_weight'],\n",
        "            reg_lambda=1.8,\n",
        "            objective='binary:logistic',\n",
        "            eval_metric='auc',\n",
        "            tree_method='hist',\n",
        "            random_state=SEED+fold,\n",
        "            scale_pos_weight=spw\n",
        "        )\n",
        "        clf.fit(X_tr, y_tr, eval_set=[(X_va, y_va)], verbose=False)\n",
        "        oof[va_idx] = clf.predict_proba(X_va)[:,1]\n",
        "        test_folds.append(clf.predict_proba(X_tem)[:,1])\n",
        "    auc = roc_auc_score(y_bin, oof)\n",
        "    print(f'[META-XGB SWEEP {i}] params={p} | OOF AUC: {auc:.5f} | time: {time.time()-t0:.2f}s', flush=True)\n",
        "    if auc > best_auc:\n",
        "        best_auc, best_params = auc, p\n",
        "        best_oof = oof.copy()\n",
        "        best_test = np.mean(np.vstack(test_folds), axis=0)\n",
        "\n",
        "print(f'[META-XGB SWEEP] Best params: {best_params} | OOF AUC: {best_auc:.5f}', flush=True)\n",
        "np.save('oof_meta_xgb.npy', best_oof)\n",
        "np.save('test_meta_xgb.npy', best_test)\n",
        "\n",
        "# Re-blend with current best text OOF if available\n",
        "if os.path.exists('oof_lr_tfidf_word_only.npy') and os.path.exists('test_lr_tfidf_word_only.npy'):\n",
        "    oof_text = np.load('oof_lr_tfidf_word_only.npy')\n",
        "    test_text = np.load('test_lr_tfidf_word_only.npy')\n",
        "    best_w, best_blend_auc = 0.5, -1.0\n",
        "    for w in [i/20 for i in range(0,21)]:\n",
        "        auc_b = roc_auc_score(y_bin, w*oof_text + (1-w)*best_oof)\n",
        "        if auc_b > best_blend_auc:\n",
        "            best_blend_auc, best_w = auc_b, w\n",
        "    print(f'[BLEND after SWEEP] Best weight on text: {best_w:.2f} | OOF AUC: {best_blend_auc:.5f}', flush=True)\n",
        "    test_blend = best_w*test_text + (1-best_w)*best_test\n",
        "    pd.DataFrame({id_col: test[id_col].values, target_col: test_blend}).to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (post-sweep blend) with shape', (len(test_blend), 2))\n",
        "else:\n",
        "    pd.DataFrame({id_col: test[id_col].values, target_col: best_test}).to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (meta-only, post-sweep)')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB SWEEP 1] params={'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.9, 'colsample_bytree': 0.7, 'learning_rate': 0.06, 'n_estimators': 900} | OOF AUC: 0.64731 | time: 4.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB SWEEP 2] params={'max_depth': 3, 'min_child_weight': 5, 'subsample': 0.9, 'colsample_bytree': 0.7, 'learning_rate': 0.06, 'n_estimators': 900} | OOF AUC: 0.64837 | time: 3.94s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB SWEEP 3] params={'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.85, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'n_estimators': 900} | OOF AUC: 0.65052 | time: 4.64s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB SWEEP 4] params={'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.8, 'learning_rate': 0.05, 'n_estimators': 800} | OOF AUC: 0.64986 | time: 4.12s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB SWEEP 5] params={'max_depth': 3, 'min_child_weight': 4, 'subsample': 0.85, 'colsample_bytree': 0.8, 'learning_rate': 0.05, 'n_estimators': 1000} | OOF AUC: 0.64878 | time: 4.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[META-XGB SWEEP] Best params: {'max_depth': 4, 'min_child_weight': 5, 'subsample': 0.85, 'colsample_bytree': 0.7, 'learning_rate': 0.05, 'n_estimators': 900} | OOF AUC: 0.65052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BLEND after SWEEP] Best weight on text: 0.80 | OOF AUC: 0.67310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (post-sweep blend) with shape (1162, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "c69bf0d6-e54c-4b10-84c8-cb5478ba816c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Text+Meta in one LR: hstack TF-IDF(word 1-2) with standardized meta features; 5-fold OOF and blend\n",
        "import time, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "# Text inputs (same as v3)\n",
        "def build_text_for_lr(df):\n",
        "    title = df['request_title'].fillna('') if 'request_title' in df.columns else ''\n",
        "    body_col = 'request_text_edit_aware' if 'request_text_edit_aware' in df.columns else ('request_text' if 'request_text' in df.columns else None)\n",
        "    body = df[body_col].fillna('') if body_col else ''\n",
        "    return (title.astype(str) + ' ' + body.astype(str)).str.lower()\n",
        "\n",
        "train_text_lr = build_text_for_lr(train)\n",
        "test_text_lr = build_text_for_lr(test)\n",
        "X_text_arr = train_text_lr.values.astype(str)\n",
        "y_bin = train[target_col].astype(int).values\n",
        "\n",
        "# Meta features from cell 6 (use all built columns)\n",
        "meta_cols = list(X_train_meta.columns)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "oof_lrm = np.zeros(len(train), dtype=np.float32)\n",
        "test_pred_folds_lrm = []\n",
        "start = time.time()\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_text_arr, y_bin), 1):\n",
        "    t0 = time.time()\n",
        "    # Text vectorizer\n",
        "    vec = TfidfVectorizer(lowercase=True, strip_accents='unicode',\n",
        "                          analyzer='word', ngram_range=(1,2),\n",
        "                          min_df=3, max_features=120000, sublinear_tf=True,\n",
        "                          token_pattern=r'(?u)\\b\\w+\\b')\n",
        "    X_tr_text = vec.fit_transform(X_text_arr[tr_idx])\n",
        "    X_va_text = vec.transform(X_text_arr[va_idx])\n",
        "    X_te_text = vec.transform(test_text_lr.values.astype(str))\n",
        "\n",
        "    # Meta scaler per fold\n",
        "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
        "    X_tr_meta = scaler.fit_transform(X_train_meta.iloc[tr_idx][meta_cols].values)\n",
        "    X_va_meta = scaler.transform(X_train_meta.iloc[va_idx][meta_cols].values)\n",
        "    X_te_meta = scaler.transform(X_test_meta[meta_cols].values)\n",
        "\n",
        "    # To sparse\n",
        "    X_tr_meta_sp = csr_matrix(X_tr_meta)\n",
        "    X_va_meta_sp = csr_matrix(X_va_meta)\n",
        "    X_te_meta_sp = csr_matrix(X_te_meta)\n",
        "\n",
        "    # Stack\n",
        "    X_tr = hstack([X_tr_text, X_tr_meta_sp], format='csr')\n",
        "    X_va = hstack([X_va_text, X_va_meta_sp], format='csr')\n",
        "    X_te = hstack([X_te_text, X_te_meta_sp], format='csr')\n",
        "\n",
        "    clf = LogisticRegression(solver='lbfgs', C=1.0, max_iter=3000, random_state=SEED+fold)\n",
        "    clf.fit(X_tr, y_bin[tr_idx])\n",
        "    oof_lrm[va_idx] = clf.predict_proba(X_va)[:,1]\n",
        "    test_pred_folds_lrm.append(clf.predict_proba(X_te)[:,1])\n",
        "    print(f'[LR text+meta] Fold {fold} AUC: {roc_auc_score(y_bin[va_idx], oof_lrm[va_idx]):.5f} | time: {time.time()-t0:.2f}s', flush=True)\n",
        "\n",
        "oof_auc_lrm = roc_auc_score(y_bin, oof_lrm)\n",
        "test_pred_lrm = np.mean(np.vstack(test_pred_folds_lrm), axis=0)\n",
        "print(f'[LR text+meta] OOF AUC: {oof_auc_lrm:.5f} | total time: {time.time()-start:.2f}s', flush=True)\n",
        "\n",
        "np.save('oof_lr_text_meta.npy', oof_lrm)\n",
        "np.save('test_lr_text_meta.npy', test_pred_lrm)\n",
        "\n",
        "# Blend this with meta-XGB if beneficial\n",
        "if os.path.exists('oof_meta_xgb.npy') and os.path.exists('test_meta_xgb.npy'):\n",
        "    oof_meta = np.load('oof_meta_xgb.npy')\n",
        "    test_meta = np.load('test_meta_xgb.npy')\n",
        "    best_w, best_blend_auc = 0.5, -1.0\n",
        "    for w in [i/20 for i in range(0,21)]:\n",
        "        auc_b = roc_auc_score(y_bin, w*oof_lrm + (1-w)*oof_meta)\n",
        "        if auc_b > best_blend_auc:\n",
        "            best_blend_auc, best_w = auc_b, w\n",
        "    print(f'[BLEND LR(text+meta)+XGB] Best weight on LR: {best_w:.2f} | OOF AUC: {best_blend_auc:.5f}', flush=True)\n",
        "    test_blend = best_w*test_pred_lrm + (1-best_w)*test_meta\n",
        "    pd.DataFrame({id_col: test[id_col].values, target_col: test_blend}).to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (blend LR(text+meta)+XGB) with shape', (len(test_blend), 2))\n",
        "else:\n",
        "    pd.DataFrame({id_col: test[id_col].values, target_col: test_pred_lrm}).to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (LR text+meta only)')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR text+meta] Fold 1 AUC: 0.70851 | time: 0.60s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR text+meta] Fold 2 AUC: 0.67369 | time: 0.68s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR text+meta] Fold 3 AUC: 0.69034 | time: 0.67s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR text+meta] Fold 4 AUC: 0.63186 | time: 0.71s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR text+meta] Fold 5 AUC: 0.65692 | time: 0.65s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR text+meta] OOF AUC: 0.67149 | total time: 3.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BLEND LR(text+meta)+XGB] Best weight on LR: 0.75 | OOF AUC: 0.68211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (blend LR(text+meta)+XGB) with shape (1162, 2)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}