{
  "cells": [
    {
      "id": "ffe6fd7d-96d2-41d0-a334-a4196a63b429",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, time\n",
        "from pathlib import Path\n",
        "print('Smoke check: cell executed at', time.strftime('%Y-%m-%d %H:%M:%S'))\n",
        "print('CWD:', Path.cwd())\n",
        "print('Files in CWD:', sorted(os.listdir('.')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "d37767ca-472b-4e43-a0e7-fafb5abdea3d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment and Data Audit\n",
        "import os, sys, platform, time, subprocess, random\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "start_time = time.time()\n",
        "CWD = Path.cwd()\n",
        "print(f\"CWD: {CWD}\")\n",
        "print(f\"Python: {sys.version.split()[0]} | Platform: {platform.platform()}\")\n",
        "\n",
        "def run(cmd):\n",
        "    print(f\"$ {' '.join(cmd)}\")\n",
        "    try:\n",
        "        out = subprocess.check_output(cmd, stderr=subprocess.STDOUT, text=True)\n",
        "        print(out)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(e.output)\n",
        "\n",
        "# Try Torch and GPU\n",
        "def ensure_torch():\n",
        "    try:\n",
        "        import torch  # noqa: F401\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Torch import failed: {e}\\nInstalling torch (CUDA 12.1) ...\")\n",
        "        run([sys.executable, '-m', 'pip', 'install', '--quiet', '--upgrade', 'pip'])\n",
        "        rc = subprocess.call([sys.executable, '-m', 'pip', 'install', '--quiet', '--index-url', 'https://download.pytorch.org/whl/cu121', 'torch'])\n",
        "        if rc != 0:\n",
        "            print(\"CUDA wheel install failed, trying CPU wheel ...\")\n",
        "            run([sys.executable, '-m', 'pip', 'install', '--quiet', 'torch'])\n",
        "        import importlib; importlib.invalidate_caches()\n",
        "        import torch  # noqa: F401\n",
        "\n",
        "ensure_torch()\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    props = torch.cuda.get_device_properties(0)\n",
        "    print(f\"GPU Memory: {props.total_memory/1024**3:.1f} GB\")\n",
        "    run(['nvidia-smi'])\n",
        "\n",
        "# CSV existence and basic stats\n",
        "csv_files = ['train.csv', 'depths.csv', 'sample_submission.csv']\n",
        "for f in csv_files:\n",
        "    p = CWD / f\n",
        "    print(f\"{f}: exists={p.exists()} size={p.stat().st_size if p.exists() else 'NA'}\")\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "depths_df = pd.read_csv('depths.csv')\n",
        "sub_df = pd.read_csv('sample_submission.csv')\n",
        "print('train.csv shape:', train_df.shape)\n",
        "print(train_df.head(5))\n",
        "print('depths.csv shape:', depths_df.shape)\n",
        "print(depths_df.head(5))\n",
        "print('sample_submission.csv shape:', sub_df.shape)\n",
        "print(sub_df.head(5))\n",
        "\n",
        "# Empty mask stats\n",
        "is_empty = train_df['rle_mask'].isna() | (train_df['rle_mask'].astype(str).str.len() == 0) | (train_df['rle_mask'].astype(str) == 'nan')\n",
        "empty_pct = is_empty.mean()*100\n",
        "print(f\"Empty masks: {is_empty.sum()}/{len(train_df)} = {empty_pct:.2f}%\")\n",
        "\n",
        "# Depth coverage for train ids\n",
        "has_depth = train_df['id'].isin(depths_df['id'])\n",
        "print(f\"Train ids with depth: {has_depth.mean()*100:.2f}%\")\n",
        "\n",
        "# Image directories audit\n",
        "paths = {'train_images': CWD/'train'/'images', 'test_images': CWD/'test'/'images', 'train_masks_dir': CWD/'train'/'masks'}\n",
        "for k, p in paths.items():\n",
        "    print(f\"{k}: exists={p.exists()} path={p}\")\n",
        "    if p.exists():\n",
        "        cnt = len(list(p.rglob('*.png')))\n",
        "        print(f\"  *.png count: {cnt}\")\n",
        "\n",
        "# Inspect one sample image (if available)\n",
        "sample_id = None\n",
        "img_path = None\n",
        "if (CWD/'train'/'images').exists():\n",
        "    ids = train_df['id'].tolist()\n",
        "    random.shuffle(ids)\n",
        "    for _id in ids[:50]:\n",
        "        ipath = CWD/'train'/'images'/f\"{_id}.png\"\n",
        "        if ipath.exists():\n",
        "            sample_id = _id\n",
        "            img_path = ipath\n",
        "            break\n",
        "    if img_path is None:\n",
        "        pngs = list((CWD/'train'/'images').glob('*.png'))\n",
        "        if pngs:\n",
        "            img_path = pngs[0]\n",
        "            sample_id = img_path.stem\n",
        "\n",
        "if img_path and Path(img_path).exists():\n",
        "    with Image.open(img_path) as im:\n",
        "        print(f\"Sample image: {img_path.name} | size={im.size} | mode={im.mode}\")\n",
        "else:\n",
        "    print(\"No sample image found under train/images\")\n",
        "\n",
        "print(f\"Audit done in {time.time()-start_time:.1f}s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f818b542-9e2b-4774-bd2f-9016753ee805",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment and Data Audit\n",
        "import os, sys, platform, time, subprocess, textwrap, random\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "start_time = time.time()\n",
        "CWD = Path.cwd()\n",
        "print(f\"CWD: {CWD}\")\n",
        "print(f\"Python: {sys.version.split()[0]} | Platform: {platform.platform()}\")\n",
        "\n",
        "def run(cmd):\n",
        "    print(f\"$ {' '.join(cmd)}\")\n",
        "    try:\n",
        "        out = subprocess.check_output(cmd, stderr=subprocess.STDOUT, text=True)\n",
        "        print(out)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(e.output)\n",
        "\n",
        "# Try Torch and GPU\n",
        "def ensure_torch():\n",
        "    try:\n",
        "        import torch  # noqa: F401\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Torch import failed: {e}\\nInstalling torch (CUDA 12.1) ...\")\n",
        "        run([sys.executable, '-m', 'pip', 'install', '--quiet', '--upgrade', 'pip'])\n",
        "        # Prefer CUDA wheels; fallback to CPU if needed\n",
        "        rc = subprocess.call([sys.executable, '-m', 'pip', 'install', '--quiet', '--index-url', 'https://download.pytorch.org/whl/cu121', 'torch'])\n",
        "        if rc != 0:\n",
        "            print(\"CUDA wheel install failed, trying CPU wheel ...\")\n",
        "            run([sys.executable, '-m', 'pip', 'install', '--quiet', 'torch'])\n",
        "        import importlib; importlib.invalidate_caches()\n",
        "        import torch  # noqa: F401\n",
        "\n",
        "ensure_torch()\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    props = torch.cuda.get_device_properties(0)\n",
        "    print(f\"GPU Memory: {props.total_memory/1024**3:.1f} GB\")\n",
        "    run(['nvidia-smi'])\n",
        "\n",
        "# CSV existence and basic stats\n",
        "csv_files = ['train.csv', 'depths.csv', 'sample_submission.csv']\n",
        "for f in csv_files:\n",
        "    p = CWD / f\n",
        "    print(f\"{f}: exists={p.exists()} size={p.stat().st_size if p.exists() else 'NA'}\")\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "depths_df = pd.read_csv('depths.csv')\n",
        "sub_df = pd.read_csv('sample_submission.csv')\n",
        "print('train.csv shape:', train_df.shape)\n",
        "print(train_df.head(5))\n",
        "print('depths.csv shape:', depths_df.shape)\n",
        "print(depths_df.head(5))\n",
        "print('sample_submission.csv shape:', sub_df.shape)\n",
        "print(sub_df.head(5))\n",
        "\n",
        "# Empty mask stats\n",
        "is_empty = train_df['rle_mask'].isna() | (train_df['rle_mask'].astype(str).str.len() == 0) | (train_df['rle_mask'].astype(str) == 'nan')\n",
        "empty_pct = is_empty.mean()*100\n",
        "print(f\"Empty masks: {is_empty.sum()}/{len(train_df)} = {empty_pct:.2f}%\")\n",
        "\n",
        "# Depth coverage for train ids\n",
        "has_depth = train_df['id'].isin(depths_df['id'])\n",
        "print(f\"Train ids with depth: {has_depth.mean()*100:.2f}%\")\n",
        "\n",
        "# Image directories audit\n",
        "paths = {'train_images': CWD/'train'/'images', 'test_images': CWD/'test'/'images', 'train_masks_dir': CWD/'train'/'masks'}\n",
        "for k, p in paths.items():\n",
        "    print(f\"{k}: exists={p.exists()} path={p}\")\n",
        "    if p.exists():\n",
        "        cnt = len(list(p.rglob('*.png')))\n",
        "        print(f\"  *.png count: {cnt}\")\n",
        "\n",
        "# Inspect one sample image (if available)\n",
        "sample_id = None\n",
        "if (CWD/'train'/'images').exists():\n",
        "    # Prefer an id that exists as a file\n",
        "    ids = train_df['id'].tolist()\n",
        "    random.shuffle(ids)\n",
        "    for _id in ids[:50]:\n",
        "        ipath = CWD/'train'/'images'/f\"{_id}.png\"\n",
        "        if ipath.exists():\n",
        "            sample_id = _id\n",
        "            img_path = ipath\n",
        "            break\n",
        "    if sample_id is None:\n",
        "        # fallback: pick any png\n",
        "        pngs = list((CWD/'train'/'images').glob('*.png'))\n",
        "        if pngs:\n",
        "            img_path = pngs[0]\n",
        "            sample_id = img_path.stem\n",
        "else:\n",
        "    img_path = None\n",
        "\n",
        "if img_path and Path(img_path).exists():\n",
        "    with Image.open(img_path) as im:\n",
        "        print(f\"Sample image: {img_path.name} | size={im.size} | mode={im.mode}\")\n",
        "else:\n",
        "    print(\"No sample image found under train/images\")\n",
        "\n",
        "print(f\"Audit done in {time.time()-start_time:.1f}s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "2eb60909-5b4c-45c3-990d-edb0d10d02e7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit (minimal baseline)\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "root = Path('.')\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    empty_pct = train_df['rle_mask'].isna().mean()*100\n",
        "    print(f'Empty-mask %: {empty_pct:.2f}')\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()*100\n",
        "    print(f'Depths coverage on train ids: {cov:.2f}%')\n",
        "\n",
        "# Quick file counts for images (if present)\n",
        "img_dir = Path('train/images'); mask_dir = Path('train/masks'); test_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': img_dir.exists(), 'train/masks': mask_dir.exists(), 'test/images': test_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(img_dir), 'train_masks': count_png(mask_dir), 'test_images': count_png(test_dir)})\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "2ce60669-0a73-4640-97c4-200fb195073d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Empty-mask %:', round(train_df['rle_mask'].isna().mean()*100, 2))\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()*100\n",
        "    print(f'Depths coverage on train ids: {cov:.2f}%')\n",
        "\n",
        "img_dir = Path('train/images'); mask_dir = Path('train/masks'); test_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': img_dir.exists(), 'train/masks': mask_dir.exists(), 'test/images': test_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(img_dir), 'train_masks': count_png(mask_dir), 'test_images': count_png(test_dir)})\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "dce14225-dc0a-47f3-8e4c-e44ea5e749d4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=3):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 3)\n",
        "depths_df = head_csv('depths.csv', 3)\n",
        "sub_df = head_csv('sample_submission.csv', 3)\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Empty-mask %:', round(train_df['rle_mask'].isna().mean()*100, 2))\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()*100\n",
        "    print(f'Depths coverage on train ids: {cov:.2f}%')\n",
        "\n",
        "img_dir = Path('train/images'); mask_dir = Path('train/masks'); test_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': img_dir.exists(), 'train/masks': mask_dir.exists(), 'test/images': test_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(img_dir), 'train_masks': count_png(mask_dir), 'test_images': count_png(test_dir)})\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7fd15704-4347-4dda-bdec-0458d4de7570",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "# GPU check (non-fatal)\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "img_dir = Path('train/images'); mask_dir = Path('train/masks'); test_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': img_dir.exists(), 'train/masks': mask_dir.exists(), 'test/images': test_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(img_dir), 'train_masks': count_png(mask_dir), 'test_images': count_png(test_dir)})\n",
        "\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Empty-mask %:', round(train_df['rle_mask'].isna().mean()*100, 2))\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()*100\n",
        "    print(f'Depths coverage on train ids: {cov:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f4f5164d-1ce4-4232-a9f6-48e1b2650326",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "img_dir = Path('train/images'); mask_dir = Path('train/masks'); test_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': img_dir.exists(), 'train/masks': mask_dir.exists(), 'test/images': test_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(img_dir), 'train_masks': count_png(mask_dir), 'test_images': count_png(test_dir)})\n",
        "\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Empty-mask %:', round(train_df['rle_mask'].isna().mean()*100, 2))\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()*100\n",
        "    print(f'Depths coverage on train ids: {cov:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "3730b97b-67fa-4672-b296-c51516f46c46",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "img_dir = Path('train/images'); mask_dir = Path('train/masks'); test_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': img_dir.exists(), 'train/masks': mask_dir.exists(), 'test/images': test_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(img_dir), 'train_masks': count_png(mask_dir), 'test_images': count_png(test_dir)})\n",
        "\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Empty-mask %:', round(train_df['rle_mask'].isna().mean()*100, 2))\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()*100\n",
        "    print(f'Depths coverage on train ids: {cov:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "300757e9-9b83-41f0-a48b-cca9e2a9884c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit (minimal)\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Empty-mask %:', round(train_df['rle_mask'].isna().mean()*100, 2))\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()*100\n",
        "    print(f'Depths coverage on train ids: {cov:.2f}%')\n",
        "\n",
        "img_dir = Path('train/images'); mask_dir = Path('train/masks'); test_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': img_dir.exists(), 'train/masks': mask_dir.exists(), 'test/images': test_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(img_dir), 'train_masks': count_png(mask_dir), 'test_images': count_png(test_dir)})\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b723786f-de9a-4a8c-9480-dcbb1bfa418d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Train empty-mask %:', train_df['rle_mask'].isna().mean()*100)\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()*100\n",
        "    print(f'Depths coverage on train ids: {cov:.2f}%')\n",
        "\n",
        "print('Audit done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "fd4e083b-61be-468b-adc6-337693a3ade1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "# GPU check (non-fatal)\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': train_img_dir.exists(), 'train/masks': train_mask_dir.exists(), 'test/images': test_img_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(train_img_dir), 'train_masks': count_png(train_mask_dir), 'test_images': count_png(test_img_dir)})\n",
        "\n",
        "# Sample image info\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Train null rle %:', train_df['rle_mask'].isna().mean())\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {cov*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "98b36e8b-21a9-4125-bb66-e18ca5d31713",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit (minimal)\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Train null rle %:', train_df['rle_mask'].isna().mean())\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {cov*100:.2f}%')\n",
        "\n",
        "print('Audit done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "65fd7cf5-792e-4c0e-b92f-b90009728d23",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "# GPU check (non-fatal)\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "# CSV presence and heads\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "# Image dirs and counts\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': train_img_dir.exists(), 'train/masks': train_mask_dir.exists(), 'test/images': test_img_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(train_img_dir), 'train_masks': count_png(train_mask_dir), 'test_images': count_png(test_img_dir)})\n",
        "\n",
        "# Sample image info\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "# Depth coverage\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {cov*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f5114344-1a3d-412c-b37a-27b51fde5f69",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Train null rle %:', train_df['rle_mask'].isna().mean())\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {cov*100:.2f}%')\n",
        "\n",
        "print('Audit done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "63d8b2fa-8106-4d52-ac46-edb9aca8b549",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Train null rle %:', train_df['rle_mask'].isna().mean())\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {cov*100:.2f}%')\n",
        "\n",
        "print('Audit done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "44f99608-0740-41ac-a44d-7ddd1e1aecf3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "# GPU check (non-fatal)\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "# CSVs\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "# Image dirs\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': train_img_dir.exists(), 'train/masks': train_mask_dir.exists(), 'test/images': test_img_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(train_img_dir), 'train_masks': count_png(train_mask_dir), 'test_images': count_png(test_img_dir)})\n",
        "\n",
        "# Sample image info\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "# Depth coverage\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {cov*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "4ce97461-c3af-4edc-8010-00b0aa160991",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Train null rle %:', train_df['rle_mask'].isna().mean())\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {cov*100:.2f}%')\n",
        "\n",
        "print('Audit done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c7870e7d-4ceb-4d56-82db-52dae4481979",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "# GPU check (non-fatal)\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "# CSVs\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "# Image dirs\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': train_img_dir.exists(), 'train/masks': train_mask_dir.exists(), 'test/images': test_img_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(train_img_dir), 'train_masks': count_png(train_mask_dir), 'test_images': count_png(test_img_dir)})\n",
        "\n",
        "# Sample image info\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "# Depth coverage\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {cov*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a220c62c-9814-4368-b4db-a0b2d4bb8b00",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': train_img_dir.exists(), 'train/masks': train_mask_dir.exists(), 'test/images': test_img_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(train_img_dir), 'train_masks': count_png(train_mask_dir), 'test_images': count_png(test_img_dir)})\n",
        "\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {cov*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0a64a9e1-ec5d-4545-b40d-bb375c192367",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick Environment & Data Audit\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "root = Path('.')\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "if train_df is not None and 'rle_mask' in train_df.columns:\n",
        "    print('Train null rle %:', train_df['rle_mask'].isna().mean())\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {cov*100:.2f}%')\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "def count_png(d):\n",
        "    d = Path(d); return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('Dirs exist:', {'train/images': train_img_dir.exists(), 'train/masks': train_mask_dir.exists(), 'test/images': test_img_dir.exists()})\n",
        "print('PNG counts:', {'train_images': count_png(train_img_dir), 'train_masks': count_png(train_mask_dir), 'test_images': count_png(test_img_dir)})\n",
        "\n",
        "print('Audit done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0ac8b56a-2ad0-4a65-a149-b6f05c8119e3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "# GPU check (non-fatal)\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch import failed or CUDA not available:', e)\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "# CSVs present?\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def read_head(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = read_head('train.csv', 5)\n",
        "depths_df = read_head('depths.csv', 5)\n",
        "sub_df = read_head('sample_submission.csv', 5)\n",
        "\n",
        "# Image dirs\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_png(d):\n",
        "    d = Path(d)\n",
        "    return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('PNG counts:', {\n",
        "    'train_images': count_png(train_img_dir),\n",
        "    'train_masks': count_png(train_mask_dir),\n",
        "    'test_images': count_png(test_img_dir),\n",
        "})\n",
        "\n",
        "# Peek one image if available\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "# Depth coverage sanity\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    coverage = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {coverage*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "ed54f512-5686-43b0-9c7c-ee26d9ff6c61",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "# GPU check\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch import failed:', e)\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "# CSVs\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def read_head(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = read_head('train.csv', 5)\n",
        "depths_df = read_head('depths.csv', 5)\n",
        "sub_df = read_head('sample_submission.csv', 5)\n",
        "\n",
        "# Dirs\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_png(d):\n",
        "    d = Path(d)\n",
        "    return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('PNG counts:', {\n",
        "    'train_images': count_png(train_img_dir),\n",
        "    'train_masks': count_png(train_mask_dir),\n",
        "    'test_images': count_png(test_img_dir),\n",
        "})\n",
        "\n",
        "# Sample image\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "# Depth coverage\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    coverage = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {coverage*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "e07f6b2b-e193-411e-ad3b-e2b0b4aac9c8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick Environment & Data Audit\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def head_csv(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape); print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = head_csv('train.csv', 5)\n",
        "depths_df = head_csv('depths.csv', 5)\n",
        "sub_df = head_csv('sample_submission.csv', 5)\n",
        "\n",
        "if train_df is not None:\n",
        "    print('Train null rle %:', train_df['rle_mask'].isna().mean())\n",
        "if train_df is not None and depths_df is not None:\n",
        "    cov = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {cov*100:.2f}%')\n",
        "\n",
        "print('Audit done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "2783d754-fcee-4a8d-ac8c-1ae288ec7488",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def read_head(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = read_head('train.csv', 5)\n",
        "depths_df = read_head('depths.csv', 5)\n",
        "sub_df = read_head('sample_submission.csv', 5)\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_png(d):\n",
        "    d = Path(d)\n",
        "    return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('PNG counts:', {\n",
        "    'train_images': count_png(train_img_dir),\n",
        "    'train_masks': count_png(train_mask_dir),\n",
        "    'test_images': count_png(test_img_dir),\n",
        "})\n",
        "\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    coverage = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {coverage*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "2dbb6105-f518-48eb-906c-0ffdbdfa9870",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "try:\n",
        "    out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "    print('nvidia-smi -L:\\n', out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def read_head(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = read_head('train.csv', 5)\n",
        "depths_df = read_head('depths.csv', 5)\n",
        "sub_df = read_head('sample_submission.csv', 5)\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_png(d):\n",
        "    d = Path(d)\n",
        "    return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('PNG counts:', {\n",
        "    'train_images': count_png(train_img_dir),\n",
        "    'train_masks': count_png(train_mask_dir),\n",
        "    'test_images': count_png(test_img_dir),\n",
        "})\n",
        "\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    coverage = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {coverage*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "77eab438-ea9e-44d7-bcb7-3f1273829be3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3, 2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv', 'depths.csv', 'sample_submission.csv']:\n",
        "    p = root / f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def read_head(p, n=5):\n",
        "    p = Path(p)\n",
        "    if not p.exists():\n",
        "        print('Missing', p); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = read_head('train.csv', 5)\n",
        "depths_df = read_head('depths.csv', 5)\n",
        "sub_df = read_head('sample_submission.csv', 5)\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_png(d):\n",
        "    d = Path(d)\n",
        "    return len(list(d.glob('*.png'))) if d.exists() else 0\n",
        "print('PNG counts:', {\n",
        "    'train_images': count_png(train_img_dir),\n",
        "    'train_masks': count_png(train_mask_dir),\n",
        "    'test_images': count_png(test_img_dir),\n",
        "})\n",
        "\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir / f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    coverage = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {coverage*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "4d38e2db-f6bd-45f1-9b65-e526ae857164",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3,2))\n",
        "except Exception as e:\n",
        "    print('Torch import failed:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def read_csv_head(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'Missing {p}'); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p}: shape {df.shape}')\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = read_csv_head('train.csv', 5)\n",
        "depths_df = read_csv_head('depths.csv', 5)\n",
        "sub_df = read_csv_head('sample_submission.csv', 5)\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_png(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('PNG counts:', {\n",
        "    'train_images': count_png(train_img_dir),\n",
        "    'train_masks': count_png(train_mask_dir),\n",
        "    'test_images': count_png(test_img_dir),\n",
        "})\n",
        "\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    coverage = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {coverage*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "e122054b-e093-4d3f-9ef9-19ea34f03f90",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3,2))\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def read_csv_head(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'Missing {p}'); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p}: shape {df.shape}')\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = read_csv_head('train.csv', 5)\n",
        "depths_df = read_csv_head('depths.csv', 5)\n",
        "sub_df = read_csv_head('sample_submission.csv', 5)\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_png(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('PNG counts:', {\n",
        "    'train_images': count_png(train_img_dir),\n",
        "    'train_masks': count_png(train_mask_dir),\n",
        "    'test_images': count_png(test_img_dir),\n",
        "})\n",
        "\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    coverage = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {coverage*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "fc35b7f9-c441-44b7-867f-b8d69433f54b",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TGS Salt Identification Challenge \u2014 Medal Plan\n",
        "\n",
        "Objectives:\n",
        "- Ship a strong baseline fast; iterate to medal via CV-driven improvements.\n",
        "\n",
        "Data & Files:\n",
        "- train.csv: id,rle_mask (RLE may be empty \u2014 negative examples).\n",
        "- depths.csv: id,depth; joinable feature.\n",
        "- Images: 101x101 PNGs at train/images and masks in train/masks (or RLE). Test at test/images.\n",
        "- sample_submission.csv: required schema (id,rle_mask).\n",
        "\n",
        "Validation:\n",
        "- 5-fold KFold with stratification on empty vs non-empty mask; optionally depth bin strat.\n",
        "- Fixed seed; reuse same folds for all runs.\n",
        "- CV metric: mean precision IoU at thresholds 0.5..0.95.\n",
        "\n",
        "Baseline Model:\n",
        "- U-Net (ResNet18/EfficientNet-B0 encoder via segmentation_models_pytorch).\n",
        "- Input 128x128 (pad from 101x101); channels: image + depth + coord (y, dist2center).\n",
        "- Augs: flips, slight shifts/rotations; keep light initially.\n",
        "- Loss: BCEWithLogits + Lovasz hinge (or Soft Dice).\n",
        "- Optim: AdamW, cosine schedule, AMP; early stopping on CV.\n",
        "\n",
        "Inference:\n",
        "- Flip TTA; average logits; per-fold threshold tuning on OOF.\n",
        "- Post-process: small-object removal.\n",
        "- Encode to RLE; create submission.csv.\n",
        "\n",
        "Iteration Path:\n",
        "1) Environment/Data audit \u2192 implement loader, CV, metric.\n",
        "2) Train baseline 5-fold; get OOF and LB.\n",
        "3) Improve: encoder, resolution (256), augs, seeds; simple blends.\n",
        "\n",
        "Expert Review Checkpoints:\n",
        "- After env/data audit + CV implementation.\n",
        "- After baseline OOF + first submission.\n",
        "- After major improvements (res/encoder/augs/blends)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a75d07ab-ae00-4abd-b373-93641bf1fa02",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version.split('\\n')[0])\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__, '| CUDA:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "        print('GPU Mem (GB):', round(torch.cuda.get_device_properties(0).total_memory/1024**3,2))\n",
        "except Exception as e:\n",
        "    print('Torch import failed:', e)\n",
        "\n",
        "root = Path('.')\n",
        "for f in ['train.csv','depths.csv','sample_submission.csv']:\n",
        "    p = root/f\n",
        "    print(f'{f}:', 'OK' if p.exists() else 'MISSING', '| size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def read_csv_head(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'Missing {p}'); return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p}: shape {df.shape}')\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = read_csv_head('train.csv', 5)\n",
        "depths_df = read_csv_head('depths.csv', 5)\n",
        "sub_df = read_csv_head('sample_submission.csv', 5)\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_png(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('PNG counts:', {\n",
        "    'train_images': count_png(train_img_dir),\n",
        "    'train_masks': count_png(train_mask_dir),\n",
        "    'test_images': count_png(test_img_dir),\n",
        "})\n",
        "\n",
        "sample = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20):\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample = p; break\n",
        "if sample is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample = imgs[0] if imgs else None\n",
        "if sample:\n",
        "    with Image.open(sample) as im:\n",
        "        print('Sample image:', sample.name, '| mode:', im.mode, '| size:', im.size)\n",
        "else:\n",
        "    print('No sample image found.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    coverage = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'Depths coverage on train ids: {coverage*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "ba5c5735-8c85-45fb-9003-4a95e4d8e68f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "def check_nvidia():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "        print('nvidia-smi -L:\\n', out)\n",
        "    except Exception as e:\n",
        "        print('nvidia-smi not available or failed:', e)\n",
        "check_nvidia()\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        print('GPU name:', torch.cuda.get_device_name(0))\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        print(f'GPU Memory: {props.total_memory/1024**3:.2f} GB')\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "repo = Path('.')\n",
        "for f in ['train.csv', 'depths.csv', 'sample_submission.csv']:\n",
        "    p = repo/f\n",
        "    print(f'{f}:', 'exists' if p.exists() else 'MISSING', 'size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def safe_read_csv(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'CSV missing: {p}')\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = safe_read_csv('train.csv')\n",
        "depths_df = safe_read_csv('depths.csv')\n",
        "sub_df = safe_read_csv('sample_submission.csv')\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_pngs(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('Counts:', {\n",
        "    'train_images_png': count_pngs(train_img_dir),\n",
        "    'train_masks_png': count_pngs(train_mask_dir),\n",
        "    'test_images_png': count_pngs(test_img_dir),\n",
        "})\n",
        "\n",
        "sample_img_path = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20).tolist():\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample_img_path = p; break\n",
        "if sample_img_path is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample_img_path = imgs[0] if imgs else None\n",
        "if sample_img_path is not None:\n",
        "    with Image.open(sample_img_path) as im:\n",
        "        print('Sample image:', sample_img_path, 'mode:', im.mode, 'size:', im.size)\n",
        "else:\n",
        "    print('No sample image found to inspect.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    has_depths = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'% train ids with depth info: {has_depths*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a2916405-bc9b-40c7-85c1-a650450ba58e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "def check_nvidia():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "        print('nvidia-smi -L:\\n', out)\n",
        "    except Exception as e:\n",
        "        print('nvidia-smi not available or failed:', e)\n",
        "check_nvidia()\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        print('GPU name:', torch.cuda.get_device_name(0))\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        print(f'GPU Memory: {props.total_memory/1024**3:.2f} GB')\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "repo = Path('.')\n",
        "for f in ['train.csv', 'depths.csv', 'sample_submission.csv']:\n",
        "    p = repo/f\n",
        "    print(f'{f}:', 'exists' if p.exists() else 'MISSING', 'size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def safe_read_csv(p, n=3):\n",
        "    if not Path(p).exists():\n",
        "        print(f'CSV missing: {p}')\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = safe_read_csv('train.csv')\n",
        "depths_df = safe_read_csv('depths.csv')\n",
        "sub_df = safe_read_csv('sample_submission.csv')\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_pngs(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('Counts:', {\n",
        "    'train_images_png': count_pngs(train_img_dir),\n",
        "    'train_masks_png': count_pngs(train_mask_dir),\n",
        "    'test_images_png': count_pngs(test_img_dir),\n",
        "})\n",
        "\n",
        "sample_img_path = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20).tolist():\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample_img_path = p; break\n",
        "if sample_img_path is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample_img_path = imgs[0] if imgs else None\n",
        "if sample_img_path is not None:\n",
        "    with Image.open(sample_img_path) as im:\n",
        "        print('Sample image:', sample_img_path, 'mode:', im.mode, 'size:', im.size)\n",
        "else:\n",
        "    print('No sample image found to inspect.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    has_depths = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'% train ids with depth info: {has_depths*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "428c4c47-ca9c-4991-8926-9518bd459adc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "def check_nvidia():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "        print('nvidia-smi -L:\\n', out)\n",
        "    except Exception as e:\n",
        "        print('nvidia-smi not available or failed:', e)\n",
        "check_nvidia()\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        print('GPU name:', torch.cuda.get_device_name(0))\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        print(f'GPU Memory: {props.total_memory/1024**3:.2f} GB')\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "# CSVs\n",
        "repo = Path('.')\n",
        "files = ['train.csv', 'depths.csv', 'sample_submission.csv']\n",
        "for f in files:\n",
        "    p = repo/f\n",
        "    print(f'{f}:', 'exists' if p.exists() else 'MISSING', 'size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def safe_read_csv(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'CSV missing: {p}')\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = safe_read_csv('train.csv')\n",
        "depths_df = safe_read_csv('depths.csv')\n",
        "sub_df = safe_read_csv('sample_submission.csv')\n",
        "\n",
        "# Dirs\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_pngs(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('Counts:', {\n",
        "    'train_images_png': count_pngs(train_img_dir),\n",
        "    'train_masks_png': count_pngs(train_mask_dir),\n",
        "    'test_images_png': count_pngs(test_img_dir),\n",
        "})\n",
        "\n",
        "# Peek one image\n",
        "sample_img_path = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20).tolist():\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample_img_path = p; break\n",
        "if sample_img_path is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample_img_path = imgs[0] if imgs else None\n",
        "if sample_img_path is not None:\n",
        "    with Image.open(sample_img_path) as im:\n",
        "        print('Sample image:', sample_img_path, 'mode:', im.mode, 'size:', im.size)\n",
        "else:\n",
        "    print('No sample image found to inspect.')\n",
        "\n",
        "# Depth join sanity\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    has_depths = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'% train ids with depth info: {has_depths*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "1438a195-efa5-46e5-9d2b-d087dca89300",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "def check_nvidia():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "        print('nvidia-smi -L:\\n', out)\n",
        "    except Exception as e:\n",
        "        print('nvidia-smi not available or failed:', e)\n",
        "check_nvidia()\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        print('GPU name:', torch.cuda.get_device_name(0))\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        print(f'GPU Memory: {props.total_memory/1024**3:.2f} GB')\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "repo = Path('.')\n",
        "files = ['train.csv', 'depths.csv', 'sample_submission.csv']\n",
        "for f in files:\n",
        "    p = repo/f\n",
        "    print(f'{f}:', 'exists' if p.exists() else 'MISSING', 'size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def safe_read_csv(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'CSV missing: {p}')\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = safe_read_csv('train.csv')\n",
        "depths_df = safe_read_csv('depths.csv')\n",
        "sub_df = safe_read_csv('sample_submission.csv')\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_pngs(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('Counts:', {\n",
        "    'train_images_png': count_pngs(train_img_dir),\n",
        "    'train_masks_png': count_pngs(train_mask_dir),\n",
        "    'test_images_png': count_pngs(test_img_dir),\n",
        "})\n",
        "\n",
        "sample_img_path = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20).tolist():\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample_img_path = p\n",
        "            break\n",
        "if sample_img_path is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample_img_path = imgs[0] if imgs else None\n",
        "if sample_img_path is not None:\n",
        "    with Image.open(sample_img_path) as im:\n",
        "        print('Sample image:', sample_img_path, 'mode:', im.mode, 'size:', im.size)\n",
        "else:\n",
        "    print('No sample image found to inspect.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    has_depths = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'% train ids with depth info: {has_depths*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "5c8b93e8-f255-49e4-b98f-157f6b513925",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "def check_nvidia():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "        print('nvidia-smi -L:\\n', out)\n",
        "    except Exception as e:\n",
        "        print('nvidia-smi not available or failed:', e)\n",
        "check_nvidia()\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        print('GPU name:', torch.cuda.get_device_name(0))\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        print(f'GPU Memory: {props.total_memory/1024**3:.2f} GB')\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "repo = Path('.')\n",
        "files = ['train.csv', 'depths.csv', 'sample_submission.csv']\n",
        "for f in files:\n",
        "    p = repo/f\n",
        "    print(f'{f}:', 'exists' if p.exists() else 'MISSING', 'size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def safe_read_csv(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'CSV missing: {p}')\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = safe_read_csv('train.csv')\n",
        "depths_df = safe_read_csv('depths.csv')\n",
        "sub_df = safe_read_csv('sample_submission.csv')\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_pngs(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('Counts:', {\n",
        "    'train_images_png': count_pngs(train_img_dir),\n",
        "    'train_masks_png': count_pngs(train_mask_dir),\n",
        "    'test_images_png': count_pngs(test_img_dir),\n",
        "})\n",
        "\n",
        "sample_img_path = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20).tolist():\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample_img_path = p\n",
        "            break\n",
        "if sample_img_path is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample_img_path = imgs[0] if imgs else None\n",
        "if sample_img_path is not None:\n",
        "    with Image.open(sample_img_path) as im:\n",
        "        print('Sample image:', sample_img_path, 'mode:', im.mode, 'size:', im.size)\n",
        "else:\n",
        "    print('No sample image found to inspect.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    has_depths = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'% train ids with depth info: {has_depths*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "aa9bf13f-08ab-4483-8645-159a6990d7ec",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "def check_nvidia():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "        print('nvidia-smi -L:\\n', out)\n",
        "    except Exception as e:\n",
        "        print('nvidia-smi not available or failed:', e)\n",
        "check_nvidia()\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        print('GPU name:', torch.cuda.get_device_name(0))\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        print(f'GPU Memory: {props.total_memory/1024**3:.2f} GB')\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "repo = Path('.')\n",
        "files = ['train.csv', 'depths.csv', 'sample_submission.csv']\n",
        "for f in files:\n",
        "    p = repo/f\n",
        "    print(f'{f}:', 'exists' if p.exists() else 'MISSING', 'size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def safe_read_csv(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'CSV missing: {p}')\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = safe_read_csv('train.csv')\n",
        "depths_df = safe_read_csv('depths.csv')\n",
        "sub_df = safe_read_csv('sample_submission.csv')\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_pngs(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('Counts:', {\n",
        "    'train_images_png': count_pngs(train_img_dir),\n",
        "    'train_masks_png': count_pngs(train_mask_dir),\n",
        "    'test_images_png': count_pngs(test_img_dir),\n",
        "})\n",
        "\n",
        "sample_img_path = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20).tolist():\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample_img_path = p\n",
        "            break\n",
        "if sample_img_path is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample_img_path = imgs[0] if imgs else None\n",
        "if sample_img_path is not None:\n",
        "    with Image.open(sample_img_path) as im:\n",
        "        print('Sample image:', sample_img_path, 'mode:', im.mode, 'size:', im.size)\n",
        "else:\n",
        "    print('No sample image found to inspect.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    has_depths = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'% train ids with depth info: {has_depths*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "dee46e4e-469f-4d9e-a880-e0a0889a2f9c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "def check_nvidia():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "        print('nvidia-smi -L:\\n', out)\n",
        "    except Exception as e:\n",
        "        print('nvidia-smi not available or failed:', e)\n",
        "check_nvidia()\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        print('GPU name:', torch.cuda.get_device_name(0))\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        print(f'GPU Memory: {props.total_memory/1024**3:.2f} GB')\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "repo = Path('.')\n",
        "files = ['train.csv', 'depths.csv', 'sample_submission.csv']\n",
        "for f in files:\n",
        "    p = repo/f\n",
        "    print(f'{f}:', 'exists' if p.exists() else 'MISSING', 'size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def safe_read_csv(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'CSV missing: {p}')\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = safe_read_csv('train.csv')\n",
        "depths_df = safe_read_csv('depths.csv')\n",
        "sub_df = safe_read_csv('sample_submission.csv')\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_pngs(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('Counts:', {\n",
        "    'train_images_png': count_pngs(train_img_dir),\n",
        "    'train_masks_png': count_pngs(train_mask_dir),\n",
        "    'test_images_png': count_pngs(test_img_dir),\n",
        "})\n",
        "\n",
        "sample_img_path = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20).tolist():\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample_img_path = p\n",
        "            break\n",
        "if sample_img_path is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample_img_path = imgs[0] if imgs else None\n",
        "if sample_img_path is not None:\n",
        "    with Image.open(sample_img_path) as im:\n",
        "        print('Sample image:', sample_img_path, 'mode:', im.mode, 'size:', im.size)\n",
        "else:\n",
        "    print('No sample image found to inspect.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    has_depths = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'% train ids with depth info: {has_depths*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c4ad58d2-87cc-4a02-b12b-631a8461234a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess, glob\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "def check_nvidia():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "        print('nvidia-smi -L:\\n', out)\n",
        "    except Exception as e:\n",
        "        print('nvidia-smi not available or failed:', e)\n",
        "check_nvidia()\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        print('GPU name:', torch.cuda.get_device_name(0))\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        print(f'GPU Memory: {props.total_memory/1024**3:.2f} GB')\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "repo = Path('.')\n",
        "files = ['train.csv', 'depths.csv', 'sample_submission.csv']\n",
        "for f in files:\n",
        "    p = repo/f\n",
        "    print(f'{f}:', 'exists' if p.exists() else 'MISSING', 'size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def safe_read_csv(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'CSV missing: {p}')\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = safe_read_csv('train.csv')\n",
        "depths_df = safe_read_csv('depths.csv')\n",
        "sub_df = safe_read_csv('sample_submission.csv')\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_pngs(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('Counts:', {\n",
        "    'train_images_png': count_pngs(train_img_dir),\n",
        "    'train_masks_png': count_pngs(train_mask_dir),\n",
        "    'test_images_png': count_pngs(test_img_dir),\n",
        "})\n",
        "\n",
        "sample_img_path = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20).tolist():\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample_img_path = p\n",
        "            break\n",
        "if sample_img_path is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample_img_path = imgs[0] if imgs else None\n",
        "if sample_img_path is not None:\n",
        "    with Image.open(sample_img_path) as im:\n",
        "        print('Sample image:', sample_img_path, 'mode:', im.mode, 'size:', im.size)\n",
        "else:\n",
        "    print('No sample image found to inspect.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    has_depths = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'% train ids with depth info: {has_depths*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "18af4e04-f8d0-4a7b-a59c-6604ba0bdae5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "def check_nvidia():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "        print('nvidia-smi -L:\\n', out)\n",
        "    except Exception as e:\n",
        "        print('nvidia-smi not available or failed:', e)\n",
        "check_nvidia()\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        print('GPU name:', torch.cuda.get_device_name(0))\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        print(f'GPU Memory: {props.total_memory/1024**3:.2f} GB')\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "repo = Path('.')\n",
        "files = ['train.csv', 'depths.csv', 'sample_submission.csv']\n",
        "for f in files:\n",
        "    p = repo/f\n",
        "    print(f'{f}:', 'exists' if p.exists() else 'MISSING', 'size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def safe_read_csv(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'CSV missing: {p}')\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = safe_read_csv('train.csv')\n",
        "depths_df = safe_read_csv('depths.csv')\n",
        "sub_df = safe_read_csv('sample_submission.csv')\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_pngs(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('Counts:', {\n",
        "    'train_images_png': count_pngs(train_img_dir),\n",
        "    'train_masks_png': count_pngs(train_mask_dir),\n",
        "    'test_images_png': count_pngs(test_img_dir),\n",
        "})\n",
        "\n",
        "sample_img_path = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(20).tolist():\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample_img_path = p\n",
        "            break\n",
        "if sample_img_path is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample_img_path = imgs[0] if imgs else None\n",
        "if sample_img_path is not None:\n",
        "    with Image.open(sample_img_path) as im:\n",
        "        print('Sample image:', sample_img_path, 'mode:', im.mode, 'size:', im.size)\n",
        "else:\n",
        "    print('No sample image found to inspect.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    has_depths = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'% train ids with depth info: {has_depths*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "eb601e13-e6ab-43c3-a056-f78386e3b593",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TGS Salt Identification Challenge \u2014 Medal Plan\n",
        "\n",
        "Objectives:\n",
        "- Establish reliable CV and a fast baseline segmentation model.\n",
        "- Iterate with targeted improvements; ensemble if time allows.\n",
        "\n",
        "Pipeline:\n",
        "1) Environment check (GPU) and data audit (CSV schema, image counts/sizes).\n",
        "2) CV: 5-fold KFold, stratify by empty vs non-empty mask and depth bins.\n",
        "3) Model: U-Net/FPN with ResNet18/EfficientNet-B0 (SMP), 128x128 (pad 101x101).\n",
        "   - Inputs: image + depth channel + coord channels.\n",
        "   - Loss: BCEWithLogits + Lovasz; AMP; AdamW + cosine; early stopping.\n",
        "   - Aug: flips, light intensity/shift.\n",
        "4) Inference: flip TTA; threshold tuning on OOF; minor postprocess; RLE encode.\n",
        "5) Iterate: higher res/encoder, seeds, blend diverse models if CV supports.\n",
        "\n",
        "Expert review checkpoints:\n",
        "- After env/data audit + CV definition.\n",
        "- After baseline OOF + first leaderboard submission.\n",
        "- After each major improvement (res/encoder/augs/ensemble)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "2f825ba8-63d6-4d73-bf89-3d64ee9c467c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, platform, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "def check_nvidia():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "        print('nvidia-smi -L:\\n', out)\n",
        "    except Exception as e:\n",
        "        print('nvidia-smi not available or failed:', e)\n",
        "check_nvidia()\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        print('GPU name:', torch.cuda.get_device_name(0))\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        print(f'GPU Memory: {props.total_memory/1024**3:.2f} GB')\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "repo = Path('.')\n",
        "files = ['train.csv', 'depths.csv', 'sample_submission.csv']\n",
        "for f in files:\n",
        "    p = repo/f\n",
        "    print(f'{f}:', 'exists' if p.exists() else 'MISSING', 'size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def safe_read_csv(p, n=3):\n",
        "    if not Path(p).exists():\n",
        "        print(f'CSV missing: {p}')\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = safe_read_csv('train.csv')\n",
        "depths_df = safe_read_csv('depths.csv')\n",
        "sub_df = safe_read_csv('sample_submission.csv')\n",
        "\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_pngs(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('Counts:', {\n",
        "    'train_images_png': count_pngs(train_img_dir),\n",
        "    'train_masks_png': count_pngs(train_mask_dir),\n",
        "    'test_images_png': count_pngs(test_img_dir),\n",
        "})\n",
        "\n",
        "sample_img_path = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    for cid in train_df['id'].astype(str).head(10).tolist():\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample_img_path = p\n",
        "            break\n",
        "if sample_img_path is None:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample_img_path = imgs[0] if imgs else None\n",
        "if sample_img_path is not None:\n",
        "    with Image.open(sample_img_path) as im:\n",
        "        print('Sample image:', sample_img_path, 'mode:', im.mode, 'size:', im.size)\n",
        "else:\n",
        "    print('No sample image found to inspect.')\n",
        "\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    has_depths = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'% train ids with depth info: {has_depths*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "2549acbe-7d9e-4a03-b0c2-23647eb291d5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & Data Audit\n",
        "import os, sys, time, json, glob, shutil, platform, subprocess, textwrap\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "# Try GPU info via nvidia-smi\n",
        "def check_nvidia():\n",
        "    try:\n",
        "        out = subprocess.check_output(['nvidia-smi', '-L'], stderr=subprocess.STDOUT).decode()\n",
        "        print('nvidia-smi -L:\\n', out)\n",
        "    except Exception as e:\n",
        "        print('nvidia-smi not available or failed:', e)\n",
        "\n",
        "check_nvidia()\n",
        "\n",
        "# Try torch if available\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU count:', torch.cuda.device_count())\n",
        "        print('GPU name:', torch.cuda.get_device_name(0))\n",
        "        props = torch.cuda.get_device_properties(0)\n",
        "        print(f'GPU Memory: {props.total_memory/1024**3:.2f} GB')\n",
        "except Exception as e:\n",
        "    print('Torch not available:', e)\n",
        "\n",
        "repo = Path('.')\n",
        "files = ['train.csv', 'depths.csv', 'sample_submission.csv']\n",
        "for f in files:\n",
        "    p = repo/f\n",
        "    print(f'{f}:', 'exists' if p.exists() else 'MISSING', 'size:', p.stat().st_size if p.exists() else '-')\n",
        "\n",
        "def safe_read_csv(p, n=5):\n",
        "    if not Path(p).exists():\n",
        "        print(f'CSV missing: {p}')\n",
        "        return None\n",
        "    df = pd.read_csv(p)\n",
        "    print(f'{p} shape:', df.shape)\n",
        "    print(df.head(n))\n",
        "    return df\n",
        "\n",
        "train_df = safe_read_csv('train.csv', 5)\n",
        "depths_df = safe_read_csv('depths.csv', 5)\n",
        "sub_df = safe_read_csv('sample_submission.csv', 5)\n",
        "\n",
        "# Inspect image directories\n",
        "train_img_dir = Path('train/images')\n",
        "train_mask_dir = Path('train/masks')\n",
        "test_img_dir = Path('test/images')\n",
        "print('Dirs exist:', {\n",
        "    'train/images': train_img_dir.exists(),\n",
        "    'train/masks': train_mask_dir.exists(),\n",
        "    'test/images': test_img_dir.exists(),\n",
        "})\n",
        "def count_pngs(d):\n",
        "    return len(list(Path(d).glob('*.png'))) if Path(d).exists() else 0\n",
        "print('Counts:', {\n",
        "    'train_images_png': count_pngs(train_img_dir),\n",
        "    'train_masks_png': count_pngs(train_mask_dir),\n",
        "    'test_images_png': count_pngs(test_img_dir),\n",
        "})\n",
        "\n",
        "# Peek one image\n",
        "sample_img_path = None\n",
        "if train_df is not None and 'id' in train_df.columns:\n",
        "    cid = train_df['id'].dropna().astype(str).iloc[0] if len(train_df) else None\n",
        "    if cid:\n",
        "        p = train_img_dir/f'{cid}.png'\n",
        "        if p.exists():\n",
        "            sample_img_path = p\n",
        "        else:\n",
        "            # fallback: first png in dir\n",
        "            imgs = list(train_img_dir.glob('*.png'))\n",
        "            sample_img_path = imgs[0] if imgs else None\n",
        "else:\n",
        "    imgs = list(train_img_dir.glob('*.png'))\n",
        "    sample_img_path = imgs[0] if imgs else None\n",
        "\n",
        "if sample_img_path is not None:\n",
        "    with Image.open(sample_img_path) as im:\n",
        "        print('Sample image:', sample_img_path, 'mode:', im.mode, 'size:', im.size)\n",
        "else:\n",
        "    print('No sample image found to inspect.')\n",
        "\n",
        "# Basic sanity: merge depths with train ids if applicable\n",
        "if train_df is not None and depths_df is not None and 'id' in train_df.columns and 'id' in depths_df.columns:\n",
        "    has_depths = train_df['id'].isin(depths_df['id']).mean()\n",
        "    print(f'% train ids with depth info: {has_depths*100:.2f}%')\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "64754ba5-1c3e-47b2-aed1-b1479cfd6dca",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TGS Salt Identification Challenge - Plan\n",
        "\n",
        "Goal: WIN A MEDAL. Build a strong, fast baseline and iterate using reliable CV.\n",
        "\n",
        "Plan:\n",
        "- Environment: verify GPU availability and stability (PyTorch CUDA).\n",
        "- Data audit:\n",
        "  - Files: train.csv (id,rle_mask), depths.csv (id,depth), sample_submission.csv.\n",
        "  - Images: expect 101x101 grayscale PNGs in train/images and masks in train/masks (or masks via RLE in train.csv). Test images in test/images.\n",
        "  - Confirm paths, counts, sizes.\n",
        "- Validation:\n",
        "  - 5-fold KFold with stratification on salt presence (mask empty vs non-empty) and depth bins, fixed seed.\n",
        "  - CV metric: mean precision IoU at thresholds (compute via official AP-IoU).\n",
        "- Baseline model:\n",
        "  - U-Net/FPN with lightweight encoder (ResNet18/EfficientNet-B0) via segmentation_models_pytorch.\n",
        "  - Input: pad 101x101 to 128x128; add depth channel and coordinate channels.\n",
        "  - Aug: flips, light color/shift; keep simple initially.\n",
        "  - Loss: BCEWithLogits + Lovasz hinge.\n",
        "  - Optim: AdamW, cosine schedule, early stopping; AMP on GPU.\n",
        "- Inference:\n",
        "  - TTA (flips), average logits, threshold tuning per fold on OOF.\n",
        "  - Post-process: small-object removal.\n",
        "  - Encode masks as RLE for submission.csv.\n",
        "- Iteration loop:\n",
        "  1) Ship working baseline quickly.\n",
        "  2) Error analysis on OOF and threshold tuning.\n",
        "  3) Improve with higher-res/encoder and simple ensembling if time remains.\n",
        "\n",
        "Checkpoints for Expert Review:\n",
        "- After this plan + environment check.\n",
        "- After data audit and CV split implementation.\n",
        "- After baseline training (OOF) and first submission.\n",
        "- After each major improvement (resolution/encoder/augment/ensemble)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "75077e91-dae9-460b-9237-9fca0789524c",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TGS Salt Identification Challenge - Plan\n",
        "\n",
        "Goal: WIN A MEDAL. Build a strong, fast baseline and iterate using reliable CV.\n",
        "\n",
        "Plan:\n",
        "- Environment: verify GPU availability and stability (PyTorch CUDA).\n",
        "- Data audit:\n",
        "  - Files: train.csv (id,rle_mask), depths.csv (id,depth), sample_submission.csv.\n",
        "  - Images: expect 101x101 grayscale PNGs in train/images and masks in train/masks (or masks via RLE in train.csv). Test images in test/images.\n",
        "  - Confirm paths, counts, sizes.\n",
        "- Validation:\n",
        "  - 5-fold KFold with stratification on salt presence (mask empty vs non-empty) and depth bins, fixed seed.\n",
        "  - CV metric: mean precision IoU at thresholds (compute via fast AP-IoU implementation).\n",
        "- Baseline model:\n",
        "  - U-Net (or FPN) with lightweight encoder (e.g., EfficientNet-B0/ResNet18) via segmentation_models_pytorch.\n",
        "  - Input: pad 101x101 to 128x128; add depth channel and coordinate channels (relative y and distance transform).\n",
        "  - Aug: horizontal/vertical flips, light shifts; keep simple initially.\n",
        "  - Loss: BCEWithLogits + Lovasz hinge (per-pixel BCE + IoU surrogate).\n",
        "  - Optim: AdamW, cosine schedule, early stopping on CV.\n",
        "  - Mixed precision (amp) on GPU.\n",
        "- Inference:\n",
        "  - TTA (flips), average logits, threshold tuning per fold on OOF.\n",
        "  - Post-process: small-object removal; optional contour smoothing.\n",
        "  - Encode masks as RLE for submission.csv.\n",
        "- Iteration loop:\n",
        "  1) Ship working baseline quickly (1-2 hours max).\n",
        "  2) Error analysis on OOF: optimize thresholds, check empty-mask handling.\n",
        "  3) Improve with higher-res (256), better encoder, and ensembling if time remains.\n",
        "\n",
        "Checkpoints for Expert Review:\n",
        "- After this plan + environment check.\n",
        "- After data audit and CV split implementation.\n",
        "- After baseline training (OOF) and first submission.\n",
        "- After each major improvement (resolution/encoder/augment/ensemble)."
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}