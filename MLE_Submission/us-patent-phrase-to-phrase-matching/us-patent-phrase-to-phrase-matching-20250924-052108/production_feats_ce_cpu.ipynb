{
  "cells": [
    {
      "id": "bfb5799f-2fa7-4ab3-9966-c5a92a12fbf8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CE CPU smoke test: cross-encoder/ms-marco-MiniLM-L-6-v2 with CPC-prepended inputs\n",
        "import os, sys, time, math, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# 1) Install compatible deps (pin transformers/tokenizers; honor torch constraints to avoid drift)\n",
        "import subprocess\n",
        "pip_args = [sys.executable, '-m', 'pip', 'install', '-q', '-c', 'constraints.txt',\n",
        "            'transformers==4.44.2', 'tokenizers==0.19.1', 'sentence-transformers==2.7.0',\n",
        "            '--upgrade', '--upgrade-strategy', 'only-if-needed']\n",
        "subprocess.run(pip_args, check=True)\n",
        "from sentence_transformers import CrossEncoder\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# 2) Load data and folds\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "folds = pd.read_csv('folds_by_id.csv')  # id, fold (StratifiedGroupKFold on original train.csv, group=anchor)\n",
        "train = train.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "assert train['fold'].notna().all(), 'Fold merge by id failed'\n",
        "train['fold'] = train['fold'].astype(int)\n",
        "\n",
        "# 3) Build CPC-prepended input pairs\n",
        "def pairify(df: pd.DataFrame):\n",
        "    ctx = df['context'].astype(str).tolist()\n",
        "    a = df['anchor'].astype(str).tolist()\n",
        "    b = df['target'].astype(str).tolist()\n",
        "    s1 = [f\"[CPC {c}] {aa}\" for c, aa in zip(ctx, a)]\n",
        "    s2 = [f\"[CPC {c}] {bb}\" for c, bb in zip(ctx, b)]\n",
        "    return list(zip(s1, s2))\n",
        "\n",
        "# 4) 2k/2-fold smoke OOF using existing folds parity (even vs odd) to define 2 splits\n",
        "# Choose up to 2000 rows (stratified by fold parity) for a quick diagnostic\n",
        "train = train.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
        "parity = (train['fold'] % 2).values  # 0 or 1\n",
        "idx0 = np.where(parity == 0)[0]\n",
        "idx1 = np.where(parity == 1)[0]\n",
        "n0 = min(1000, len(idx0))\n",
        "n1 = min(1000, len(idx1))\n",
        "sel_idx0 = idx0[:n0]\n",
        "sel_idx1 = idx1[:n1]\n",
        "sel_idx = np.concatenate([sel_idx0, sel_idx1])\n",
        "sel = train.iloc[sel_idx].reset_index(drop=True)\n",
        "sel_parity = (sel['fold'] % 2).values\n",
        "\n",
        "# 5) Load CE model on CPU\n",
        "model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
        "print('Loading CE model:', model_name, 'on CPU ...', flush=True)\n",
        "t0 = time.time()\n",
        "ce = CrossEncoder(model_name, max_length=128, device='cpu')\n",
        "print('Loaded in', round(time.time()-t0, 2), 's', flush=True)\n",
        "\n",
        "APPLY_SIGMOID = True  # ms-marco models are often trained with BCE; sigmoid can improve correlation\n",
        "def _sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def predict_pairs(pairs, batch_size=32):\n",
        "    # CrossEncoder returns float scores; optionally pass through sigmoid\n",
        "    p = ce.predict(pairs, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "    if APPLY_SIGMOID:\n",
        "        p = _sigmoid(p).astype(np.float32)\n",
        "    return p\n",
        "\n",
        "# 6) 2-fold OOF on the selected subset\n",
        "y = sel['score'].astype(np.float32).values\n",
        "oof = np.zeros(len(sel), dtype=np.float32)\n",
        "for f in [0, 1]:\n",
        "    va_idx = np.where(sel_parity == f)[0]\n",
        "    if len(va_idx) == 0:\n",
        "        continue\n",
        "    pairs_va = pairify(sel.iloc[va_idx])\n",
        "    t1 = time.time()\n",
        "    preds_va = predict_pairs(pairs_va, batch_size=32)\n",
        "    oof[va_idx] = preds_va\n",
        "    r = pearsonr(preds_va, y[va_idx])[0]\n",
        "    print(f'[Smoke CE FoldParity={f}] val_n={len(va_idx)} raw r={r:.6f}; elapsed {time.time()-t1:.1f}s', flush=True)\n",
        "\n",
        "r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "print('Smoke CE OOF Pearson (2k/2-fold parity subset):', round(float(r_all), 6))\n",
        "print('Pred stats: min', float(oof.min()), 'max', float(oof.max()), 'mean', float(oof.mean()))\n",
        "\n",
        "# 7) Sanity orientation: if negative correlation but decent magnitude, flip sign (diagnostic only)\n",
        "if np.isfinite(r_all) and r_all < 0 and abs(r_all) > 0.3:\n",
        "    oof = -oof\n",
        "    r_all = pearsonr(oof, y)[0]\n",
        "    print('Flipped sign. New r:', round(float(r_all), 6))\n",
        "\n",
        "print('DONE smoke test. If r >= 0.65, proceed to full 5-fold OOF+test generation in next cell.', flush=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 2.21.0 requires fsspec[http]<=2024.6.1,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CE model: cross-encoder/ms-marco-MiniLM-L-6-v2 on CPU ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.36 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Smoke CE FoldParity=0] val_n=1000 raw r=0.188156; elapsed 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Smoke CE FoldParity=1] val_n=1000 raw r=0.222761; elapsed 1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoke CE OOF Pearson (2k/2-fold parity subset): 0.206057\nPred stats: min 0.08257093280553818 max 0.9999490976333618 mean 0.9687997698783875\nDONE smoke test. If r >= 0.65, proceed to full 5-fold OOF+test generation in next cell.\n"
          ]
        }
      ]
    },
    {
      "id": "3dce2973-700e-498b-a56b-9f527ab38df9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Full 5-fold CE OOF + test generation (strict [id,pred] schema) using BAAI/bge-reranker-base (CPU), no CPC, sigmoid\n",
        "import sys, time, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from scipy.stats import pearsonr\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Load data and folds\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "folds = pd.read_csv('folds_by_id.csv')\n",
        "train = train.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "assert train['fold'].notna().all(), 'Fold merge by id failed'\n",
        "train['fold'] = train['fold'].astype(int)\n",
        "NUM_FOLDS = int(train['fold'].max()) + 1\n",
        "\n",
        "def pairify_no_cpc(df: pd.DataFrame):\n",
        "    a = df['anchor'].astype(str).tolist()\n",
        "    b = df['target'].astype(str).tolist()\n",
        "    return list(zip(a, b))\n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "model_name = 'BAAI/bge-reranker-base'  # best from smoke test on CPU\n",
        "print('Loading CE model:', model_name, 'on CPU ...', flush=True)\n",
        "t0 = time.time()\n",
        "ce = CrossEncoder(model_name, max_length=128, device='cpu')\n",
        "print('Loaded in', round(time.time()-t0, 2), 's', flush=True)\n",
        "\n",
        "y = train['score'].astype(np.float32).values\n",
        "oof = np.zeros(len(train), dtype=np.float32)\n",
        "te_acc = np.zeros(len(test), dtype=np.float64)\n",
        "\n",
        "for f in range(NUM_FOLDS):\n",
        "    f0 = time.time()\n",
        "    va_idx = np.where(train['fold'].values == f)[0]\n",
        "    va_df = train.iloc[va_idx]\n",
        "    pairs_va = pairify_no_cpc(va_df)\n",
        "    logits_va = ce.predict(pairs_va, batch_size=32, show_progress_bar=False).astype(np.float32)\n",
        "    preds_va = _sigmoid(logits_va).astype(np.float32)\n",
        "    oof[va_idx] = preds_va\n",
        "    r = pearsonr(preds_va, y[va_idx])[0]\n",
        "    print(f'[CE Fold {f}] n={len(va_idx)} raw(sigmoid) r={r:.6f}; elapsed {time.time()-f0:.1f}s', flush=True)\n",
        "    # test predictions for this fold\n",
        "    te_pairs = pairify_no_cpc(test)\n",
        "    logits_te = ce.predict(te_pairs, batch_size=32, show_progress_bar=False).astype(np.float32)\n",
        "    te_acc += _sigmoid(logits_te).astype(np.float64)\n",
        "\n",
        "# Global OOF r\n",
        "r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "print('CE OOF Pearson (sigmoid):', round(float(r_all), 6))\n",
        "\n",
        "te_pred_mean = (te_acc / NUM_FOLDS).astype(np.float32)\n",
        "\n",
        "# Save artifacts with strict schema [id, pred]\n",
        "oof_df = pd.DataFrame({'id': train['id'], 'pred': oof.astype(np.float32)})\n",
        "sub_df = pd.DataFrame({'id': test['id'], 'pred': np.clip(te_pred_mean, 0.0, 1.0)})\n",
        "oof_path = 'oof_ce_minilm.csv'; sub_path = 'submission_ce_minilm.csv'\n",
        "oof_df.to_csv(oof_path, index=False)\n",
        "sub_df.to_csv(sub_path, index=False)\n",
        "\n",
        "# Sanity checks\n",
        "chk_oof = pd.read_csv(oof_path); chk_sub = pd.read_csv(sub_path)\n",
        "assert list(chk_oof.columns) == ['id','pred'] and list(chk_sub.columns) == ['id','pred']\n",
        "assert chk_oof['id'].nunique() == len(train) and chk_sub['id'].nunique() == len(test)\n",
        "assert not chk_oof['pred'].isna().any() and not chk_sub['pred'].isna().any()\n",
        "print('Saved', oof_path, 'and', sub_path, 'OK.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CE model: BAAI/bge-reranker-base on CPU ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.84 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CE Fold 0] n=6086 raw(sigmoid) r=0.444495; elapsed 18.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CE Fold 1] n=6515 raw(sigmoid) r=0.449640; elapsed 19.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CE Fold 2] n=6630 raw(sigmoid) r=0.436400; elapsed 20.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CE Fold 3] n=6941 raw(sigmoid) r=0.454112; elapsed 19.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CE Fold 4] n=6653 raw(sigmoid) r=0.440996; elapsed 18.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CE OOF Pearson (sigmoid): 0.445097\nSaved oof_ce_minilm.csv and submission_ce_minilm.csv OK.\n"
          ]
        }
      ]
    },
    {
      "id": "5af3a237-9fce-4c80-90bd-6abb963bdce9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Smoke test several alternative cross-encoders (CPU) and formats on the same 2k subset\n",
        "import time\n",
        "from sentence_transformers import CrossEncoder\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "assert 'sel' in globals() and 'sel_parity' in globals(), 'Run cell 0 first to define sel subset'\n",
        "\n",
        "def make_pairs(df, use_cpc: bool):\n",
        "    if use_cpc:\n",
        "        ctx = df['context'].astype(str).tolist()\n",
        "        a = df['anchor'].astype(str).tolist()\n",
        "        b = df['target'].astype(str).tolist()\n",
        "        s1 = [f\"[CPC {c}] {aa}\" for c, aa in zip(ctx, a)]\n",
        "        s2 = [f\"[CPC {c}] {bb}\" for c, bb in zip(ctx, b)]\n",
        "        return list(zip(s1, s2))\n",
        "    else:\n",
        "        return list(zip(df['anchor'].astype(str).tolist(), df['target'].astype(str).tolist()))\n",
        "\n",
        "def _sigmoid(x):\n",
        "    import numpy as np\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def eval_model(model_name: str, use_sigmoid: bool, use_cpc: bool, max_length: int = 128, batch_size: int = 32):\n",
        "    print(f'\\nModel={model_name} sigmoid={use_sigmoid} use_cpc={use_cpc}', flush=True)\n",
        "    t0 = time.time()\n",
        "    ce = CrossEncoder(model_name, max_length=max_length, device='cpu')\n",
        "    print('Loaded in', round(time.time()-t0, 2), 's', flush=True)\n",
        "    y = sel['score'].astype('float32').values\n",
        "    oof = np.zeros(len(sel), dtype=np.float32)\n",
        "    for f in [0,1]:\n",
        "        va_idx = np.where(sel_parity == f)[0]\n",
        "        if len(va_idx) == 0:\n",
        "            continue\n",
        "        pairs = make_pairs(sel.iloc[va_idx], use_cpc=use_cpc)\n",
        "        t1 = time.time()\n",
        "        preds = ce.predict(pairs, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "        if use_sigmoid:\n",
        "            preds = _sigmoid(preds).astype(np.float32)\n",
        "        oof[va_idx] = preds\n",
        "        r = pearsonr(preds, y[va_idx])[0]\n",
        "        print(f'  FoldParity={f} r={r:.6f} elapsed={time.time()-t1:.1f}s', flush=True)\n",
        "    r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "    print('  OOF r=', round(float(r_all), 6), 'min/max/mean=', float(oof.min()), float(oof.max()), float(oof.mean()), flush=True)\n",
        "    return r_all\n",
        "\n",
        "candidates = [\n",
        "    ('cross-encoder/stsb-roberta-base', False),  # usually regression 0..1\n",
        "    ('BAAI/bge-reranker-base', True),           # logits -> sigmoid\n",
        "    ('jinaai/jina-reranker-v2-base-en', True),  # logits -> sigmoid\n",
        "]\n",
        "\n",
        "results = []\n",
        "for name, use_sig in candidates:\n",
        "    for use_cpc in (True, False):\n",
        "        try:\n",
        "            r = eval_model(name, use_sigmoid=use_sig, use_cpc=use_cpc, max_length=128, batch_size=32)\n",
        "            results.append((name, use_sig, use_cpc, float(r)))\n",
        "        except Exception as e:\n",
        "            print('  ERROR for', name, 'use_cpc', use_cpc, ':', e, flush=True)\n",
        "\n",
        "print('\\nSummary:', results, flush=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nModel=cross-encoder/stsb-roberta-base sigmoid=False use_cpc=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ERROR for cross-encoder/stsb-roberta-base use_cpc True : data did not match any variant of untagged enum ModelWrapper at line 250356 column 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nModel=cross-encoder/stsb-roberta-base sigmoid=False use_cpc=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ERROR for cross-encoder/stsb-roberta-base use_cpc False : data did not match any variant of untagged enum ModelWrapper at line 250356 column 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nModel=BAAI/bge-reranker-base sigmoid=True use_cpc=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 3.87 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.309318 elapsed=5.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.268846 elapsed=4.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.289362 min/max/mean= 0.5024835467338562 0.7310519814491272 0.6799047589302063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nModel=BAAI/bge-reranker-base sigmoid=True use_cpc=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 1.05 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.496222 elapsed=3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.433706 elapsed=3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.464706 min/max/mean= 0.5000093579292297 0.7310519814491272 0.6260038614273071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nModel=jinaai/jina-reranker-v2-base-en sigmoid=True use_cpc=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ERROR for jinaai/jina-reranker-v2-base-en use_cpc True : jinaai/jina-reranker-v2-base-en is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nModel=jinaai/jina-reranker-v2-base-en sigmoid=True use_cpc=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ERROR for jinaai/jina-reranker-v2-base-en use_cpc False : jinaai/jina-reranker-v2-base-en is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nSummary: [('BAAI/bge-reranker-base', True, True, 0.28936243057250977), ('BAAI/bge-reranker-base', True, False, 0.46470585465431213)]\n"
          ]
        }
      ]
    },
    {
      "id": "c6791bee-5498-4467-a9c2-fbcac8d1828f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Correct CE (MiniLM-L-6) smoke test: raw logits, CPC prefix3 on both sides, CrossEncoder pairs\n",
        "import time, numpy as np, pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Load data + folds deterministically (no shuffle); use existing folds_by_id.csv\n",
        "train_df = pd.read_csv('train.csv')\n",
        "folds = pd.read_csv('folds_by_id.csv')\n",
        "train_df = train_df.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "train_df['fold'] = train_df['fold'].astype(int)\n",
        "\n",
        "def make_pairs_cpc_prefix3(df: pd.DataFrame):\n",
        "    ctx3 = df['context'].astype(str).str[:3].tolist()\n",
        "    a = df['anchor'].astype(str).tolist()\n",
        "    b = df['target'].astype(str).tolist()\n",
        "    s1 = [f\"[CPC {c}] {aa}\" for c, aa in zip(ctx3, a)]\n",
        "    s2 = [f\"[CPC {c}] {bb}\" for c, bb in zip(ctx3, b)]\n",
        "    return list(zip(s1, s2))\n",
        "\n",
        "# Build a 2k subset: first 1000 rows from even folds and first 1000 from odd folds (stable order)\n",
        "parity = (train_df['fold'].values % 2)\n",
        "idx_even = np.where(parity == 0)[0][:1000]\n",
        "idx_odd  = np.where(parity == 1)[0][:1000]\n",
        "sel_idx = np.concatenate([idx_even, idx_odd])\n",
        "sel = train_df.iloc[sel_idx].reset_index(drop=True)\n",
        "sel_parity = (sel['fold'].values % 2)\n",
        "\n",
        "model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
        "print('Loading CE model:', model_name, 'on CPU ...', flush=True)\n",
        "t0 = time.time()\n",
        "ce = CrossEncoder(model_name, device='cpu', max_length=128)  # raw logits\n",
        "print('Loaded in', round(time.time()-t0,2), 's', flush=True)\n",
        "\n",
        "y = sel['score'].astype(np.float32).values\n",
        "oof = np.zeros(len(sel), dtype=np.float32)\n",
        "for f in [0,1]:\n",
        "    va_idx = np.where(sel_parity == f)[0]\n",
        "    if len(va_idx) == 0:\n",
        "        continue\n",
        "    pairs_va = make_pairs_cpc_prefix3(sel.iloc[va_idx])\n",
        "    t1 = time.time()\n",
        "    logits = ce.predict(pairs_va, batch_size=32, show_progress_bar=False).astype(np.float32)\n",
        "    oof[va_idx] = logits  # no sigmoid\n",
        "    r = pearsonr(logits, y[va_idx])[0]\n",
        "    print(f'[MiniLM-L6 smoke FoldParity={f}] n={len(va_idx)} raw r={r:.6f}; elapsed {time.time()-t1:.1f}s', flush=True)\n",
        "\n",
        "r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "print('Smoke OOF r (expected >=0.65):', round(float(r_all), 6))\n",
        "print('Logit stats min/max/mean:', float(oof.min()), float(oof.max()), float(oof.mean()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CE model: cross-encoder/ms-marco-MiniLM-L-6-v2 on CPU ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.54 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MiniLM-L6 smoke FoldParity=0] n=1000 raw r=0.491884; elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MiniLM-L6 smoke FoldParity=1] n=1000 raw r=0.491177; elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoke OOF r (expected >=0.65): 0.49172\nLogit stats min/max/mean: -2.258300542831421 9.818795204162598 5.268746376037598\n"
          ]
        }
      ]
    },
    {
      "id": "28e85025-7bc7-48f9-8d44-e566922ada15",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# MiniLM CE smoke: test formatting/symmetry/model variants to reach r>=0.65\n",
        "import time, numpy as np, pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "assert 'sel' in globals() and 'sel_parity' in globals(), 'Run cell 3 to define sel subset'\n",
        "\n",
        "def make_pairs(df: pd.DataFrame, use_cpc_prefix3: bool, reverse: bool = False):\n",
        "    a = df['anchor'].astype(str).tolist()\n",
        "    b = df['target'].astype(str).tolist()\n",
        "    if use_cpc_prefix3:\n",
        "        c3 = df['context'].astype(str).str[:3].tolist()\n",
        "        if not reverse:\n",
        "            s1 = [f\"[CPC {c}] {aa}\" for c, aa in zip(c3, a)]\n",
        "            s2 = [f\"[CPC {c}] {bb}\" for c, bb in zip(c3, b)]\n",
        "        else:\n",
        "            s1 = [f\"[CPC {c}] {bb}\" for c, bb in zip(c3, b)]\n",
        "            s2 = [f\"[CPC {c}] {aa}\" for c, aa in zip(c3, a)]\n",
        "    else:\n",
        "        if not reverse:\n",
        "            s1, s2 = a, b\n",
        "        else:\n",
        "            s1, s2 = b, a\n",
        "    return list(zip(s1, s2))\n",
        "\n",
        "def eval_ce(model_name: str, max_len: int, use_cpc_prefix3: bool, symmetry: bool, batch_size: int = 32):\n",
        "    print(f'CE smoke model={model_name} max_len={max_len} cpc3={use_cpc_prefix3} sym={symmetry}', flush=True)\n",
        "    t0 = time.time()\n",
        "    ce = CrossEncoder(model_name, device='cpu', max_length=max_len)\n",
        "    print('Loaded in', round(time.time()-t0,2), 's')\n",
        "    y = sel['score'].astype(np.float32).values\n",
        "    oof = np.zeros(len(sel), dtype=np.float32)\n",
        "    for fp in [0,1]:\n",
        "        va_idx = np.where(sel_parity == fp)[0]\n",
        "        if len(va_idx) == 0: continue\n",
        "        va_df = sel.iloc[va_idx]\n",
        "        p_main = make_pairs(va_df, use_cpc_prefix3=use_cpc_prefix3, reverse=False)\n",
        "        t1 = time.time()\n",
        "        s_main = ce.predict(p_main, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "        if symmetry:\n",
        "            p_rev = make_pairs(va_df, use_cpc_prefix3=use_cpc_prefix3, reverse=True)\n",
        "            s_rev = ce.predict(p_rev, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "            s = (s_main + s_rev) / 2.0\n",
        "        else:\n",
        "            s = s_main\n",
        "        oof[va_idx] = s\n",
        "        r = pearsonr(s, y[va_idx])[0]\n",
        "        print(f'  FoldParity={fp} r={r:.6f}; elapsed {time.time()-t1:.1f}s', flush=True)\n",
        "    r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "    print('  OOF r=', round(float(r_all),6), 'min/max/mean=', float(oof.min()), float(oof.max()), float(oof.mean()), flush=True)\n",
        "    return float(r_all)\n",
        "\n",
        "# Candidates: L-6 and L-12, with/without CPC prefix3, with symmetry averaging\n",
        "cands = [\n",
        "    ('cross-encoder/ms-marco-MiniLM-L-6-v2', 128, True, True),\n",
        "    ('cross-encoder/ms-marco-MiniLM-L-6-v2', 128, False, True),\n",
        "    ('cross-encoder/ms-marco-MiniLM-L-12-v2', 192, True, True),\n",
        "    ('cross-encoder/ms-marco-MiniLM-L-12-v2', 192, False, True),\n",
        "]\n",
        "results = []\n",
        "for m, ml, cpc3, sym in cands:\n",
        "    try:\n",
        "        r = eval_ce(m, ml, cpc3, sym)\n",
        "        results.append((m, ml, cpc3, sym, r))\n",
        "    except Exception as e:\n",
        "        print('  ERROR', m, ml, cpc3, sym, ':', e, flush=True)\n",
        "\n",
        "print('Summary:', results, flush=True)\n",
        "best = None\n",
        "for row in results:\n",
        "    if best is None or (row[-1] is not None and row[-1] > best[-1]):\n",
        "        best = row\n",
        "print('Best:', best, flush=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CE smoke model=cross-encoder/ms-marco-MiniLM-L-6-v2 max_len=128 cpc3=True sym=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.35 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.461687; elapsed 1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.484764; elapsed 1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.473114 min/max/mean= -0.8967779874801636 9.818795204162598 5.377791881561279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CE smoke model=cross-encoder/ms-marco-MiniLM-L-6-v2 max_len=128 cpc3=False sym=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.64 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.564724; elapsed 1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.550846; elapsed 1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.557887 min/max/mean= -11.372194290161133 8.473657608032227 -5.434383869171143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CE smoke model=cross-encoder/ms-marco-MiniLM-L-12-v2 max_len=192 cpc3=True sym=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.38 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.448868; elapsed 3.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.475624; elapsed 3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.46215 min/max/mean= -1.187737226486206 9.560964584350586 5.876559734344482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CE smoke model=cross-encoder/ms-marco-MiniLM-L-12-v2 max_len=192 cpc3=False sym=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.38 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.553570; elapsed 2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.534756; elapsed 2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.544243 min/max/mean= -11.255294799804688 8.826813697814941 -5.39487361907959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: [('cross-encoder/ms-marco-MiniLM-L-6-v2', 128, True, True, 0.47311434149742126), ('cross-encoder/ms-marco-MiniLM-L-6-v2', 128, False, True, 0.557887077331543), ('cross-encoder/ms-marco-MiniLM-L-12-v2', 192, True, True, 0.4621501863002777), ('cross-encoder/ms-marco-MiniLM-L-12-v2', 192, False, True, 0.5442430377006531)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: ('cross-encoder/ms-marco-MiniLM-L-6-v2', 128, False, True, 0.557887077331543)\n"
          ]
        }
      ]
    },
    {
      "id": "e4aed3d6-cf7f-4637-b66b-bc7d98ef03b3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Full OOF+test CE generation (MiniLM-L-6) with CPU recipe: raw logits, no CPC, symmetry ON, max_length=192\n",
        "import time, numpy as np, pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "folds = pd.read_csv('folds_by_id.csv')\n",
        "train = train.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "train['fold'] = train['fold'].astype(int)\n",
        "NUM_FOLDS = int(train['fold'].max()) + 1\n",
        "\n",
        "def make_pairs(df: pd.DataFrame, reverse: bool = False):\n",
        "    a = df['anchor'].astype(str).tolist()\n",
        "    b = df['target'].astype(str).tolist()\n",
        "    if not reverse:\n",
        "        s1, s2 = a, b\n",
        "    else:\n",
        "        s1, s2 = b, a\n",
        "    return list(zip(s1, s2))\n",
        "\n",
        "model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
        "max_len = 192\n",
        "batch_size = 64\n",
        "use_symmetry = True  # per expert advice: ON\n",
        "print('Loading CE:', model_name, 'cpu, max_len=', max_len, 'symmetry=', use_symmetry, flush=True)\n",
        "t0 = time.time()\n",
        "ce = CrossEncoder(model_name, device='cpu', max_length=max_len)\n",
        "print('Loaded in', round(time.time()-t0,2), 's', flush=True)\n",
        "\n",
        "y = train['score'].astype(np.float32).values\n",
        "oof = np.zeros(len(train), dtype=np.float32)\n",
        "\n",
        "# Precompute test pairs once (no fold dependency) and predict with symmetry if enabled\n",
        "pairs_main_te = make_pairs(test)\n",
        "scores_main_te = ce.predict(pairs_main_te, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "if use_symmetry:\n",
        "    pairs_rev_te = make_pairs(test, reverse=True)\n",
        "    scores_rev_te = ce.predict(pairs_rev_te, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "    te_scores = (scores_main_te + scores_rev_te) / 2.0\n",
        "else:\n",
        "    te_scores = scores_main_te\n",
        "\n",
        "for f in range(NUM_FOLDS):\n",
        "    f0 = time.time()\n",
        "    va_idx = np.where(train['fold'].values == f)[0]\n",
        "    va_df = train.iloc[va_idx]\n",
        "    pairs_main = make_pairs(va_df)\n",
        "    s_main = ce.predict(pairs_main, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "    if use_symmetry:\n",
        "        pairs_rev = make_pairs(va_df, reverse=True)\n",
        "        s_rev = ce.predict(pairs_rev, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "        s = (s_main + s_rev) / 2.0\n",
        "    else:\n",
        "        s = s_main\n",
        "    oof[va_idx] = s\n",
        "    r = pearsonr(s, y[va_idx])[0]\n",
        "    print(f'[Fold {f}] n={len(va_idx)} raw r={r:.6f}; elapsed {time.time()-f0:.1f}s', flush=True)\n",
        "\n",
        "r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "print('Final CE OOF r (raw logits, sym ON, len 192):', round(float(r_all), 6), flush=True)\n",
        "\n",
        "# Save strict schema for downstream transforms\n",
        "pd.DataFrame({'id': train['id'], 'pred': oof.astype(np.float32)}).to_csv('oof_ce_minilm.csv', index=False)\n",
        "pd.DataFrame({'id': test['id'], 'pred': te_scores.astype(np.float32)}).to_csv('submission_ce_minilm.csv', index=False)\n",
        "print('Saved oof_ce_minilm.csv and submission_ce_minilm.csv', flush=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CE: cross-encoder/ms-marco-MiniLM-L-6-v2 cpu, max_len= 192 symmetry= True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.41 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0] n=6086 raw r=0.564206; elapsed 6.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] n=6515 raw r=0.547474; elapsed 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] n=6630 raw r=0.542416; elapsed 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 3] n=6941 raw r=0.545060; elapsed 5.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 4] n=6653 raw r=0.539629; elapsed 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final CE OOF r (raw logits, sym ON, len 192): 0.54733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved oof_ce_minilm.csv and submission_ce_minilm.csv\n"
          ]
        }
      ]
    },
    {
      "id": "4cc17cf4-4809-44b7-b541-d8f87395ec28",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# MiniLM-L-6 template sweep (CPU): test query/passage prompts, CPC prefix3, symmetry\n",
        "import time, numpy as np, pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "assert 'sel' in globals() and 'sel_parity' in globals(), 'Run cell 3 to define sel subset'\n",
        "\n",
        "def make_pairs_template(df: pd.DataFrame, template: str, reverse: bool = False):\n",
        "    a = df['anchor'].astype(str).tolist()\n",
        "    b = df['target'].astype(str).tolist()\n",
        "    c3 = df['context'].astype(str).str[:3].tolist()\n",
        "    s1 = []; s2 = []\n",
        "    if template == 'plain':\n",
        "        s1 = a if not reverse else b\n",
        "        s2 = b if not reverse else a\n",
        "    elif template == 'query_passage':\n",
        "        if not reverse:\n",
        "            s1 = [f'query: {aa}' for aa in a]\n",
        "            s2 = [f'passage: {bb}' for bb in b]\n",
        "        else:\n",
        "            s1 = [f'query: {bb}' for bb in b]\n",
        "            s2 = [f'passage: {aa}' for aa in a]\n",
        "    elif template == 'cpc3_plain':\n",
        "        if not reverse:\n",
        "            s1 = [f'[CPC {c}] {aa}' for c, aa in zip(c3, a)]\n",
        "            s2 = [f'[CPC {c}] {bb}' for c, bb in zip(c3, b)]\n",
        "        else:\n",
        "            s1 = [f'[CPC {c}] {bb}' for c, bb in zip(c3, b)]\n",
        "            s2 = [f'[CPC {c}] {aa}' for c, aa in zip(c3, a)]\n",
        "    elif template == 'cpc3_query_passage':\n",
        "        if not reverse:\n",
        "            s1 = [f'query: [CPC {c}] {aa}' for c, aa in zip(c3, a)]\n",
        "            s2 = [f'passage: [CPC {c}] {bb}' for c, bb in zip(c3, b)]\n",
        "        else:\n",
        "            s1 = [f'query: [CPC {c}] {bb}' for c, bb in zip(c3, b)]\n",
        "            s2 = [f'passage: [CPC {c}] {aa}' for c, aa in zip(c3, a)]\n",
        "    else:\n",
        "        raise ValueError('Unknown template')\n",
        "    return list(zip(s1, s2))\n",
        "\n",
        "def eval_template(model_name: str, template: str, max_len: int = 128, symmetry: bool = True, batch_size: int = 32):\n",
        "    print(f'Model={model_name} tmpl={template} sym={symmetry}', flush=True)\n",
        "    t0 = time.time()\n",
        "    ce = CrossEncoder(model_name, device='cpu', max_length=max_len)\n",
        "    print('Loaded in', round(time.time()-t0,2), 's', flush=True)\n",
        "    y = sel['score'].astype(np.float32).values\n",
        "    oof = np.zeros(len(sel), dtype=np.float32)\n",
        "    for fp in [0,1]:\n",
        "        va_idx = np.where(sel_parity == fp)[0]\n",
        "        if len(va_idx) == 0: continue\n",
        "        va_df = sel.iloc[va_idx]\n",
        "        p_main = make_pairs_template(va_df, template, reverse=False)\n",
        "        t1 = time.time()\n",
        "        s_main = ce.predict(p_main, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "        if symmetry:\n",
        "            p_rev = make_pairs_template(va_df, template, reverse=True)\n",
        "            s_rev = ce.predict(p_rev, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "            s = (s_main + s_rev) / 2.0\n",
        "        else:\n",
        "            s = s_main\n",
        "        oof[va_idx] = s\n",
        "        r = pearsonr(s, y[va_idx])[0]\n",
        "        print(f'  FoldParity={fp} r={r:.6f}; elapsed {time.time()-t1:.1f}s', flush=True)\n",
        "    r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "    print('  OOF r=', round(float(r_all),6), 'min/max/mean=', float(oof.min()), float(oof.max()), float(oof.mean()), flush=True)\n",
        "    return float(r_all)\n",
        "\n",
        "model = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
        "templates = ['plain', 'query_passage', 'cpc3_plain', 'cpc3_query_passage']\n",
        "results = []\n",
        "for tmpl in templates:\n",
        "    try:\n",
        "        r = eval_template(model, tmpl, max_len=128, symmetry=True, batch_size=32)\n",
        "        results.append((tmpl, True, r))\n",
        "    except Exception as e:\n",
        "        print('  ERROR tmpl', tmpl, e, flush=True)\n",
        "for tmpl in templates:\n",
        "    try:\n",
        "        r = eval_template(model, tmpl, max_len=128, symmetry=False, batch_size=32)\n",
        "        results.append((tmpl, False, r))\n",
        "    except Exception as e:\n",
        "        print('  ERROR tmpl', tmpl, e, flush=True)\n",
        "print('Summary (tmpl, sym, r):', results, flush=True)\n",
        "best = max(results, key=lambda x: (x[2] if x[2] is not None else -1.0)) if results else None\n",
        "print('Best:', best, flush=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model=cross-encoder/ms-marco-MiniLM-L-6-v2 tmpl=plain sym=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.57 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.564724; elapsed 1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.550846; elapsed 1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.557887 min/max/mean= -11.372194290161133 8.473657608032227 -5.434383869171143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model=cross-encoder/ms-marco-MiniLM-L-6-v2 tmpl=query_passage sym=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.36 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.568381; elapsed 1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.546066; elapsed 1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.557246 min/max/mean= -11.449594497680664 5.321118354797363 -7.024003028869629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model=cross-encoder/ms-marco-MiniLM-L-6-v2 tmpl=cpc3_plain sym=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.36 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.461687; elapsed 2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.484764; elapsed 1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.473114 min/max/mean= -0.8967779874801636 9.818795204162598 5.377791881561279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model=cross-encoder/ms-marco-MiniLM-L-6-v2 tmpl=cpc3_query_passage sym=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.36 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.445932; elapsed 2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.481770; elapsed 2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.463544 min/max/mean= -1.8124641180038452 7.252917289733887 3.602077007293701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model=cross-encoder/ms-marco-MiniLM-L-6-v2 tmpl=plain sym=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.41 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.568412; elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.548776; elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.558729 min/max/mean= -11.419656753540039 8.438697814941406 -5.534883975982666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model=cross-encoder/ms-marco-MiniLM-L-6-v2 tmpl=query_passage sym=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.35 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.567048; elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.542985; elapsed 0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.555054 min/max/mean= -11.480846405029297 5.321118354797363 -7.06156063079834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model=cross-encoder/ms-marco-MiniLM-L-6-v2 tmpl=cpc3_plain sym=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.37 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.491884; elapsed 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.491177; elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.49172 min/max/mean= -2.258300542831421 9.818795204162598 5.268746376037598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model=cross-encoder/ms-marco-MiniLM-L-6-v2 tmpl=cpc3_query_passage sym=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.37 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.471256; elapsed 1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.485039; elapsed 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.478248 min/max/mean= -3.049187183380127 7.271217346191406 3.5236079692840576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary (tmpl, sym, r): [('plain', True, 0.557887077331543), ('query_passage', True, 0.5572460293769836), ('cpc3_plain', True, 0.47311434149742126), ('cpc3_query_passage', True, 0.4635443091392517), ('plain', False, 0.5587289333343506), ('query_passage', False, 0.5550540089607239), ('cpc3_plain', False, 0.4917197525501251), ('cpc3_query_passage', False, 0.4782479405403137)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: ('plain', False, 0.5587289333343506)\n"
          ]
        }
      ]
    },
    {
      "id": "976b409a-f16b-4f7c-bcf6-a34364bffb6b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# BGE reranker raw-logit smoke + optional full OOF if >= threshold\n",
        "import time, numpy as np, pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "assert 'sel' in globals() and 'sel_parity' in globals(), 'Run cell 3 to define sel subset'\n",
        "\n",
        "def eval_bge_raw(symmetry: bool, batch_size: int = 32, max_len: int = 128):\n",
        "    name = 'BAAI/bge-reranker-base'\n",
        "    print(f'Eval {name} raw logits, symmetry={symmetry}', flush=True)\n",
        "    t0 = time.time()\n",
        "    ce = CrossEncoder(name, device='cpu', max_length=max_len)\n",
        "    print('Loaded in', round(time.time()-t0,2), 's', flush=True)\n",
        "    y = sel['score'].astype(np.float32).values\n",
        "    oof = np.zeros(len(sel), dtype=np.float32)\n",
        "    for fp in [0,1]:\n",
        "        va_idx = np.where(sel_parity == fp)[0]\n",
        "        if len(va_idx) == 0: continue\n",
        "        va = sel.iloc[va_idx]\n",
        "        a = va['anchor'].astype(str).tolist()\n",
        "        b = va['target'].astype(str).tolist()\n",
        "        pairs_main = list(zip(a, b))\n",
        "        t1 = time.time()\n",
        "        s_main = ce.predict(pairs_main, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "        if symmetry:\n",
        "            pairs_rev = list(zip(b, a))\n",
        "            s_rev = ce.predict(pairs_rev, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "            s = (s_main + s_rev) / 2.0\n",
        "        else:\n",
        "            s = s_main\n",
        "        oof[va_idx] = s\n",
        "        r = pearsonr(s, y[va_idx])[0]\n",
        "        print(f'  FoldParity={fp} r={r:.6f}; elapsed {time.time()-t1:.1f}s', flush=True)\n",
        "    r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "    print('  OOF r=', round(float(r_all),6), 'min/max/mean=', float(oof.min()), float(oof.max()), float(oof.mean()), flush=True)\n",
        "    return float(r_all), ce\n",
        "\n",
        "# Smoke both symmetry settings\n",
        "r_sym, _ = eval_bge_raw(symmetry=True)\n",
        "r_nosym, _ = eval_bge_raw(symmetry=False)\n",
        "best_sym = r_sym >= r_nosym\n",
        "best_r = max(r_sym, r_nosym)\n",
        "print('BGE raw best smoke r=', round(best_r,6), 'symmetry=', best_sym, flush=True)\n",
        "\n",
        "# If good enough, run full OOF+test and overwrite ce_minilm artifacts for stacker\n",
        "THRESH = 0.58\n",
        "if best_r >= THRESH:\n",
        "    print('Running full OOF with BGE raw logits; symmetry=', best_sym, flush=True)\n",
        "    train = pd.read_csv('train.csv')\n",
        "    test = pd.read_csv('test.csv')\n",
        "    folds = pd.read_csv('folds_by_id.csv')\n",
        "    train = train.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "    train['fold'] = train['fold'].astype(int)\n",
        "    NUM_FOLDS = int(train['fold'].max()) + 1\n",
        "    ce_full = CrossEncoder('BAAI/bge-reranker-base', device='cpu', max_length=128)\n",
        "    y = train['score'].astype(np.float32).values\n",
        "    oof = np.zeros(len(train), dtype=np.float32)\n",
        "    # test predictions\n",
        "    a_te = test['anchor'].astype(str).tolist(); b_te = test['target'].astype(str).tolist()\n",
        "    te_main = list(zip(a_te, b_te))\n",
        "    te_main_scores = ce_full.predict(te_main, batch_size=32, show_progress_bar=False).astype(np.float32)\n",
        "    if best_sym:\n",
        "        te_rev = list(zip(b_te, a_te))\n",
        "        te_rev_scores = ce_full.predict(te_rev, batch_size=32, show_progress_bar=False).astype(np.float32)\n",
        "        te_scores = (te_main_scores + te_rev_scores) / 2.0\n",
        "    else:\n",
        "        te_scores = te_main_scores\n",
        "    for f in range(NUM_FOLDS):\n",
        "        f0 = time.time()\n",
        "        va_idx = np.where(train['fold'].values == f)[0]\n",
        "        va = train.iloc[va_idx]\n",
        "        a = va['anchor'].astype(str).tolist(); b = va['target'].astype(str).tolist()\n",
        "        va_main = list(zip(a, b))\n",
        "        s_main = ce_full.predict(va_main, batch_size=32, show_progress_bar=False).astype(np.float32)\n",
        "        if best_sym:\n",
        "            va_rev = list(zip(b, a))\n",
        "            s_rev = ce_full.predict(va_rev, batch_size=32, show_progress_bar=False).astype(np.float32)\n",
        "            s = (s_main + s_rev) / 2.0\n",
        "        else:\n",
        "            s = s_main\n",
        "        oof[va_idx] = s\n",
        "        r = pearsonr(s, y[va_idx])[0]\n",
        "        print(f'  [Full Fold {f}] r={r:.6f}; elapsed {time.time()-f0:.1f}s', flush=True)\n",
        "    r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "    print('Full BGE raw OOF r=', round(float(r_all),6), flush=True)\n",
        "    # Overwrite CE artifacts expected by stacker\n",
        "    pd.DataFrame({'id': train['id'], 'pred': oof.astype(np.float32)}).to_csv('oof_ce_minilm.csv', index=False)\n",
        "    pd.DataFrame({'id': test['id'], 'pred': te_scores.astype(np.float32)}).to_csv('submission_ce_minilm.csv', index=False)\n",
        "    print('Overwrote oof_ce_minilm.csv and submission_ce_minilm.csv with BGE raw logits.', flush=True)\n",
        "else:\n",
        "    print('BGE raw did not meet threshold; skip full OOF.', flush=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval BAAI/bge-reranker-base raw logits, symmetry=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.8 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.464254; elapsed 6.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.475629; elapsed 6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.470034 min/max/mean= 3.728556475834921e-05 0.9999665021896362 0.5484459400177002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval BAAI/bge-reranker-base raw logits, symmetry=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 1.01 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=0 r=0.469314; elapsed 3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  FoldParity=1 r=0.483053; elapsed 2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  OOF r= 0.476314 min/max/mean= 3.728599403984845e-05 0.9999665021896362 0.5459015965461731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BGE raw best smoke r= 0.476314 symmetry= False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BGE raw did not meet threshold; skip full OOF.\n"
          ]
        }
      ]
    },
    {
      "id": "f609f5a8-1259-42fb-8dcd-1c5967cb455d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Full OOF+test for additional CEs: MiniLM-L-12 (raw, no CPC, symmetry) and BGE raw (no sigmoid, symmetry)\n",
        "import time, numpy as np, pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "def gen_ce_full(model_name: str, out_tag: str, max_len: int = 192, symmetry: bool = True, batch_size: int = 32):\n",
        "    train = pd.read_csv('train.csv')\n",
        "    test = pd.read_csv('test.csv')\n",
        "    folds = pd.read_csv('folds_by_id.csv')\n",
        "    train = train.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "    train['fold'] = train['fold'].astype(int)\n",
        "    NUM_FOLDS = int(train['fold'].max()) + 1\n",
        "    def make_pairs(df, reverse=False):\n",
        "        a = df['anchor'].astype(str).tolist()\n",
        "        b = df['target'].astype(str).tolist()\n",
        "        if not reverse:\n",
        "            return list(zip(a, b))\n",
        "        else:\n",
        "            return list(zip(b, a))\n",
        "    print(f'Loading CE: {model_name} (cpu) max_len={max_len} symmetry={symmetry}', flush=True)\n",
        "    t0 = time.time()\n",
        "    ce = CrossEncoder(model_name, device='cpu', max_length=max_len)\n",
        "    print('Loaded in', round(time.time()-t0,2), 's', flush=True)\n",
        "    y = train['score'].astype(np.float32).values\n",
        "    oof = np.zeros(len(train), dtype=np.float32)\n",
        "    # test predictions\n",
        "    te_main = make_pairs(test)\n",
        "    te_main_scores = ce.predict(te_main, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "    if symmetry:\n",
        "        te_rev = make_pairs(test, reverse=True)\n",
        "        te_rev_scores = ce.predict(te_rev, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "        te_scores = (te_main_scores + te_rev_scores) / 2.0\n",
        "    else:\n",
        "        te_scores = te_main_scores\n",
        "    for f in range(NUM_FOLDS):\n",
        "        f0 = time.time()\n",
        "        va_idx = np.where(train['fold'].values == f)[0]\n",
        "        va_df = train.iloc[va_idx]\n",
        "        s_main = ce.predict(make_pairs(va_df), batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "        if symmetry:\n",
        "            s_rev = ce.predict(make_pairs(va_df, reverse=True), batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "            s = (s_main + s_rev) / 2.0\n",
        "        else:\n",
        "            s = s_main\n",
        "        oof[va_idx] = s\n",
        "        r = pearsonr(s, y[va_idx])[0]\n",
        "        print(f'  [Fold {f}] r={r:.6f}; elapsed {time.time()-f0:.1f}s', flush=True)\n",
        "    r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "    print(f'Final OOF r for {out_tag} =', round(float(r_all), 6), flush=True)\n",
        "    pd.DataFrame({'id': train['id'], 'pred': oof.astype(np.float32)}).to_csv(f'oof_ce_{out_tag}.csv', index=False)\n",
        "    pd.DataFrame({'id': test['id'], 'pred': te_scores.astype(np.float32)}).to_csv(f'submission_ce_{out_tag}.csv', index=False)\n",
        "    print(f'Saved oof_ce_{out_tag}.csv and submission_ce_{out_tag}.csv', flush=True)\n",
        "\n",
        "# Generate MiniLM-L-12-v2 (raw logits, no CPC, symmetry) -> files oof_ce_l12.csv/submission_ce_l12.csv\n",
        "try:\n",
        "    gen_ce_full('cross-encoder/ms-marco-MiniLM-L-12-v2', out_tag='l12', max_len=192, symmetry=True, batch_size=32)\n",
        "except Exception as e:\n",
        "    print('MiniLM-L-12 generation failed:', e, flush=True)\n",
        "\n",
        "# Generate BGE raw logits (no sigmoid), symmetry -> files oof_ce_bge_rerank.csv/submission_ce_bge_rerank.csv\n",
        "try:\n",
        "    gen_ce_full('BAAI/bge-reranker-base', out_tag='bge_rerank', max_len=128, symmetry=True, batch_size=32)\n",
        "except Exception as e:\n",
        "    print('BGE raw generation failed:', e, flush=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CE: cross-encoder/ms-marco-MiniLM-L-12-v2 (cpu) max_len=192 symmetry=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.43 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Fold 0] r=0.551037; elapsed 15.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Fold 1] r=0.532257; elapsed 14.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Fold 2] r=0.532294; elapsed 15.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Fold 3] r=0.533919; elapsed 15.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Fold 4] r=0.517023; elapsed 14.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final OOF r for l12 = 0.532922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved oof_ce_l12.csv and submission_ce_l12.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CE: BAAI/bge-reranker-base (cpu) max_len=128 symmetry=True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.99 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Fold 0] r=0.453725; elapsed 37.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Fold 1] r=0.455899; elapsed 40.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Fold 2] r=0.442429; elapsed 41.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Fold 3] r=0.468451; elapsed 42.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Fold 4] r=0.456696; elapsed 39.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final OOF r for bge_rerank = 0.455499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved oof_ce_bge_rerank.csv and submission_ce_bge_rerank.csv\n"
          ]
        }
      ]
    },
    {
      "id": "5cef3f0b-0e25-4015-b491-68c38634f5a8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# MiniLM-L-6 Separator Trick (context after [SEP]) smoke + optional full OOF (overwrite ce_minilm artifacts)\n",
        "import time, numpy as np, pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Ensure subset exists; if not, build a 2k parity subset deterministically\n",
        "if 'sel' not in globals() or 'sel_parity' not in globals():\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    folds = pd.read_csv('folds_by_id.csv')\n",
        "    train_df = train_df.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "    train_df['fold'] = train_df['fold'].astype(int)\n",
        "    parity = (train_df['fold'].values % 2)\n",
        "    idx_even = np.where(parity == 0)[0][:1000]\n",
        "    idx_odd  = np.where(parity == 1)[0][:1000]\n",
        "    sel_idx = np.concatenate([idx_even, idx_odd])\n",
        "    sel = train_df.iloc[sel_idx].reset_index(drop=True)\n",
        "    sel_parity = (sel['fold'].values % 2)\n",
        "\n",
        "# Global SEP token placeholder; will be set from tokenizer after model load\n",
        "SEP = '[SEP]'\n",
        "\n",
        "def make_pairs_sep(df: pd.DataFrame, reverse: bool = False):\n",
        "    a = df['anchor'].astype(str).tolist()\n",
        "    b = df['target'].astype(str).tolist()\n",
        "    c = df['context'].astype(str).tolist()\n",
        "    if not reverse:\n",
        "        s1 = a\n",
        "        s2 = [f\"{bb} {SEP} {cc}\" for bb, cc in zip(b, c)]\n",
        "    else:\n",
        "        s1 = b\n",
        "        s2 = [f\"{aa} {SEP} {cc}\" for aa, cc in zip(a, c)]\n",
        "    return list(zip(s1, s2))\n",
        "\n",
        "model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
        "max_len = 192\n",
        "batch_size = 32\n",
        "print('Separator Trick smoke:', model_name, 'max_len=', max_len, flush=True)\n",
        "t0 = time.time()\n",
        "ce = CrossEncoder(model_name, device='cpu', max_length=max_len)  # raw logits\n",
        "# Use the tokenizer's true separator token if available\n",
        "tok_sep = getattr(getattr(ce, 'tokenizer', None), 'sep_token', None)\n",
        "if tok_sep and isinstance(tok_sep, str):\n",
        "    SEP = tok_sep\n",
        "print('Loaded in', round(time.time()-t0,2), 's; sep_token=', repr(SEP), flush=True)\n",
        "\n",
        "y = sel['score'].astype(np.float32).values\n",
        "oof = np.zeros(len(sel), dtype=np.float32)\n",
        "for fp in [0,1]:\n",
        "    va_idx = np.where(sel_parity == fp)[0]\n",
        "    if len(va_idx) == 0: continue\n",
        "    va_df = sel.iloc[va_idx]\n",
        "    p_f = make_pairs_sep(va_df, reverse=False)\n",
        "    p_r = make_pairs_sep(va_df, reverse=True)\n",
        "    t1 = time.time()\n",
        "    s_f = ce.predict(p_f, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "    s_r = ce.predict(p_r, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "    s = (s_f + s_r) / 2.0\n",
        "    oof[va_idx] = s\n",
        "    r = pearsonr(s, y[va_idx])[0]\n",
        "    print(f'  Parity={fp} r={r:.6f}; elapsed {time.time()-t1:.1f}s', flush=True)\n",
        "\n",
        "r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "print('Smoke OOF r (Separator Trick):', round(float(r_all), 6), flush=True)\n",
        "\n",
        "# If strong enough, run full OOF+test and overwrite ce_minilm artifacts\n",
        "THRESH = 0.65\n",
        "if np.isfinite(r_all) and r_all >= THRESH:\n",
        "    print('Running full 5-fold OOF+test with Separator Trick; overwriting ce_minilm artifacts', flush=True)\n",
        "    train = pd.read_csv('train.csv')\n",
        "    test = pd.read_csv('test.csv')\n",
        "    folds = pd.read_csv('folds_by_id.csv')\n",
        "    train = train.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "    train['fold'] = train['fold'].astype(int)\n",
        "    NUM_FOLDS = int(train['fold'].max()) + 1\n",
        "    # Reuse ce; ensure same settings\n",
        "    ce_full = ce\n",
        "    y_full = train['score'].astype(np.float32).values\n",
        "    oof_full = np.zeros(len(train), dtype=np.float32)\n",
        "    # Test predictions (forward+reverse)\n",
        "    pte_f = make_pairs_sep(test, reverse=False)\n",
        "    pte_r = make_pairs_sep(test, reverse=True)\n",
        "    s_te_f = ce_full.predict(pte_f, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "    s_te_r = ce_full.predict(pte_r, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "    te_scores = (s_te_f + s_te_r) / 2.0\n",
        "    for f in range(NUM_FOLDS):\n",
        "        f0 = time.time()\n",
        "        va_idx = np.where(train['fold'].values == f)[0]\n",
        "        va_df = train.iloc[va_idx]\n",
        "        pf = make_pairs_sep(va_df, reverse=False)\n",
        "        pr = make_pairs_sep(va_df, reverse=True)\n",
        "        s_f = ce_full.predict(pf, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "        s_r = ce_full.predict(pr, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "        s = (s_f + s_r) / 2.0\n",
        "        oof_full[va_idx] = s\n",
        "        r = pearsonr(s, y_full[va_idx])[0]\n",
        "        print(f'  [Fold {f}] r={r:.6f}; elapsed {time.time()-f0:.1f}s', flush=True)\n",
        "    r_fin = pearsonr(oof_full, y_full)[0] if np.std(oof_full) > 0 else float('nan')\n",
        "    print('Final CE OOF r (Separator Trick):', round(float(r_fin), 6), flush=True)\n",
        "    pd.DataFrame({'id': train['id'], 'pred': oof_full.astype(np.float32)}).to_csv('oof_ce_minilm.csv', index=False)\n",
        "    pd.DataFrame({'id': test['id'], 'pred': te_scores.astype(np.float32)}).to_csv('submission_ce_minilm.csv', index=False)\n",
        "    print('Saved oof_ce_minilm.csv and submission_ce_minilm.csv', flush=True)\n",
        "else:\n",
        "    print('Separator Trick smoke < threshold; not running full OOF.', flush=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separator Trick smoke: cross-encoder/ms-marco-MiniLM-L-6-v2 max_len= 192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.49 s; sep_token= '[SEP]'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Parity=0 r=0.564983; elapsed 1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Parity=1 r=0.545467; elapsed 1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoke OOF r (Separator Trick): 0.555326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separator Trick smoke < threshold; not running full OOF.\n"
          ]
        }
      ]
    },
    {
      "id": "786bafd9-1595-4bb3-999d-b4cecaef1f2a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CE smoke: MiniLM-L-2-v2 and quora-roberta-base (plain pairs, raw logits), then full OOF if >= 0.60\n",
        "import time, numpy as np, pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Ensure 2k parity subset exists\n",
        "if 'sel' not in globals() or 'sel_parity' not in globals():\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    folds = pd.read_csv('folds_by_id.csv')\n",
        "    train_df = train_df.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "    train_df['fold'] = train_df['fold'].astype(int)\n",
        "    parity = (train_df['fold'].values % 2)\n",
        "    idx_even = np.where(parity == 0)[0][:1000]\n",
        "    idx_odd  = np.where(parity == 1)[0][:1000]\n",
        "    sel_idx = np.concatenate([idx_even, idx_odd])\n",
        "    sel = train_df.iloc[sel_idx].reset_index(drop=True)\n",
        "    sel_parity = (sel['fold'].values % 2)\n",
        "\n",
        "def make_pairs_plain(df: pd.DataFrame, reverse: bool = False):\n",
        "    a = df['anchor'].astype(str).tolist()\n",
        "    b = df['target'].astype(str).tolist()\n",
        "    if not reverse:\n",
        "        return list(zip(a, b))\n",
        "    else:\n",
        "        return list(zip(b, a))\n",
        "\n",
        "def smoke_eval(model_name: str, max_len: int = 256, batch_size: int = 32):\n",
        "    print(f\"Smoke CE: {model_name} max_len={max_len}\", flush=True)\n",
        "    t0 = time.time()\n",
        "    ce = CrossEncoder(model_name, device='cpu', max_length=max_len)\n",
        "    print('Loaded in', round(time.time()-t0,2), 's', flush=True)\n",
        "    y = sel['score'].astype(np.float32).values\n",
        "    results = []  # (symmetry, r)\n",
        "    for symmetry in (False, True):\n",
        "        oof = np.zeros(len(sel), dtype=np.float32)\n",
        "        for fp in [0,1]:\n",
        "            va_idx = np.where(sel_parity == fp)[0]\n",
        "            if len(va_idx) == 0: continue\n",
        "            va = sel.iloc[va_idx]\n",
        "            p_main = make_pairs_plain(va, reverse=False)\n",
        "            t1 = time.time()\n",
        "            s_main = ce.predict(p_main, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "            if symmetry:\n",
        "                p_rev = make_pairs_plain(va, reverse=True)\n",
        "                s_rev = ce.predict(p_rev, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "                s = (s_main + s_rev) / 2.0\n",
        "            else:\n",
        "                s = s_main\n",
        "            oof[va_idx] = s\n",
        "            r = pearsonr(s, y[va_idx])[0]\n",
        "            print(f'  sym={symmetry} parity={fp} r={r:.6f}; elapsed {time.time()-t1:.1f}s', flush=True)\n",
        "        r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "        print(f'  -> OOF r (sym={symmetry}) =', round(float(r_all), 6), 'min/max/mean=', float(oof.min()), float(oof.max()), float(oof.mean()), flush=True)\n",
        "        results.append((symmetry, float(r_all)))\n",
        "    best = max(results, key=lambda x: (x[1] if np.isfinite(x[1]) else -1.0))\n",
        "    print('Best smoke for', model_name, '=>', best, flush=True)\n",
        "    return best, ce\n",
        "\n",
        "def run_full_oof(model_name: str, max_len: int, symmetry: bool, batch_size: int = 32):\n",
        "    print(f'Running full OOF+test for {model_name} max_len={max_len} symmetry={symmetry}', flush=True)\n",
        "    train = pd.read_csv('train.csv')\n",
        "    test = pd.read_csv('test.csv')\n",
        "    folds = pd.read_csv('folds_by_id.csv')\n",
        "    train = train.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "    train['fold'] = train['fold'].astype(int)\n",
        "    NUM_FOLDS = int(train['fold'].max()) + 1\n",
        "    ce = CrossEncoder(model_name, device='cpu', max_length=max_len)\n",
        "    y = train['score'].astype(np.float32).values\n",
        "    oof = np.zeros(len(train), dtype=np.float32)\n",
        "    # test predictions\n",
        "    te_main = make_pairs_plain(test, reverse=False)\n",
        "    te_main_scores = ce.predict(te_main, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "    if symmetry:\n",
        "        te_rev = make_pairs_plain(test, reverse=True)\n",
        "        te_rev_scores = ce.predict(te_rev, batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "        te_scores = (te_main_scores + te_rev_scores) / 2.0\n",
        "    else:\n",
        "        te_scores = te_main_scores\n",
        "    for f in range(NUM_FOLDS):\n",
        "        f0 = time.time()\n",
        "        va_idx = np.where(train['fold'].values == f)[0]\n",
        "        va = train.iloc[va_idx]\n",
        "        s_main = ce.predict(make_pairs_plain(va, reverse=False), batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "        if symmetry:\n",
        "            s_rev = ce.predict(make_pairs_plain(va, reverse=True), batch_size=batch_size, show_progress_bar=False).astype(np.float32)\n",
        "            s = (s_main + s_rev) / 2.0\n",
        "        else:\n",
        "            s = s_main\n",
        "        oof[va_idx] = s\n",
        "        r = pearsonr(s, y[va_idx])[0]\n",
        "        print(f'  [Fold {f}] r={r:.6f}; elapsed {time.time()-f0:.1f}s', flush=True)\n",
        "    r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "    print('Full OOF r =', round(float(r_all), 6), flush=True)\n",
        "    # Overwrite canonical CE artifacts for stacker ingestion\n",
        "    pd.DataFrame({'id': train['id'], 'pred': oof.astype(np.float32)}).to_csv('oof_ce_minilm.csv', index=False)\n",
        "    pd.DataFrame({'id': test['id'], 'pred': te_scores.astype(np.float32)}).to_csv('submission_ce_minilm.csv', index=False)\n",
        "    print('Saved oof_ce_minilm.csv and submission_ce_minilm.csv (overwritten with best CE).', flush=True)\n",
        "    return float(r_all)\n",
        "\n",
        "candidates = [\n",
        "    ('cross-encoder/ms-marco-MiniLM-L-2-v2', 256),\n",
        "    ('cross-encoder/quora-roberta-base', 256),\n",
        "]\n",
        "\n",
        "best_overall = (-1.0, None, None)  # (r, model_name, symmetry)\n",
        "for name, ml in candidates:\n",
        "    try:\n",
        "        (sym_best, r_best), _ = smoke_eval(name, max_len=ml, batch_size=32)\n",
        "        if np.isfinite(r_best) and r_best > best_overall[0]:\n",
        "            best_overall = (r_best, name, sym_best)\n",
        "    except Exception as e:\n",
        "        print(f'ERROR loading/evaluating {name}: {e}', flush=True)\n",
        "\n",
        "print('Best across candidates:', best_overall, flush=True)\n",
        "THRESH = 0.60\n",
        "if best_overall[0] >= THRESH and best_overall[1] is not None:\n",
        "    final_r = run_full_oof(best_overall[1], max_len=256, symmetry=best_overall[2], batch_size=32)\n",
        "    print('Final CE (best candidate) full OOF r=', round(float(final_r), 6), flush=True)\n",
        "else:\n",
        "    print('No candidate reached threshold; skipping full OOF.', flush=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoke CE: cross-encoder/ms-marco-MiniLM-L-2-v2 max_len=256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 2.36 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sym=False parity=0 r=0.517818; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sym=False parity=1 r=0.493694; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> OOF r (sym=False) = 0.505715 min/max/mean= -12.00761890411377 9.67796802520752 -6.1005449295043945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sym=True parity=0 r=0.515791; elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sym=True parity=1 r=0.498911; elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> OOF r (sym=True) = 0.507319 min/max/mean= -11.90707778930664 9.119239807128906 -5.993034362792969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best smoke for cross-encoder/ms-marco-MiniLM-L-2-v2 => (True, 0.5073191523551941)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoke CE: cross-encoder/quora-roberta-base max_len=256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR loading/evaluating cross-encoder/quora-roberta-base: data did not match any variant of untagged enum ModelWrapper at line 250356 column 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best across candidates: (0.5073191523551941, 'cross-encoder/ms-marco-MiniLM-L-2-v2', True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No candidate reached threshold; skipping full OOF.\n"
          ]
        }
      ]
    },
    {
      "id": "145e8314-8a0c-42eb-a85f-bd5d7fcd10b3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CE diagnostic with transformers (AutoTokenizer/AutoModelForSequenceClassification), plain (anchor,target) raw logits\n",
        "import numpy as np, pandas as pd, torch, time\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "folds = pd.read_csv('folds_by_id.csv')\n",
        "train = train.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "train['fold'] = train['fold'].astype(int)\n",
        "\n",
        "# Deterministic 1k sample (first 500 even-fold + 500 odd-fold)\n",
        "parity = (train['fold'].values % 2)\n",
        "idx_even = np.where(parity == 0)[0][:500]\n",
        "idx_odd  = np.where(parity == 1)[0][:500]\n",
        "sel_idx = np.concatenate([idx_even, idx_odd])\n",
        "sel = train.iloc[sel_idx].reset_index(drop=True)\n",
        "\n",
        "name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
        "print('Loading', name, 'with transformers on CPU...', flush=True)\n",
        "t0 = time.time()\n",
        "tok = AutoTokenizer.from_pretrained(name)\n",
        "mdl = AutoModelForSequenceClassification.from_pretrained(name)\n",
        "mdl.eval(); mdl.to('cpu')\n",
        "print('Loaded in', round(time.time()-t0, 2), 's')\n",
        "\n",
        "# Build plain (anchor,target) pairs\n",
        "pairs = list(zip(sel['anchor'].astype(str).tolist(), sel['target'].astype(str).tolist()))\n",
        "y = sel['score'].astype(np.float32).values\n",
        "\n",
        "# Batch inference for raw logits\n",
        "def batched_logits(pairs, bs=64, max_length=192):\n",
        "    out = []\n",
        "    for i in range(0, len(pairs), bs):\n",
        "        a, b = zip(*pairs[i:i+bs])\n",
        "        enc = tok(list(a), list(b), padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            logits = mdl(**{k: v.to('cpu') for k, v in enc.items()}).logits.squeeze(-1).cpu().numpy()\n",
        "        out.append(logits.astype(np.float32))\n",
        "    return np.concatenate(out, axis=0)\n",
        "\n",
        "logit = batched_logits(pairs, bs=64, max_length=192)\n",
        "r_raw = pearsonr(logit, y)[0] if np.std(logit) > 0 else float('nan')\n",
        "sig = 1.0/(1.0 + np.exp(-logit))\n",
        "r_sig = pearsonr(sig.astype(np.float32), y)[0] if np.std(sig) > 0 else float('nan')\n",
        "print('diag raw r=', round(float(r_raw), 6), 'sig r=', round(float(r_sig), 6), 'logit stats:', float(logit.min()), float(logit.max()), float(logit.mean()), flush=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cross-encoder/ms-marco-MiniLM-L-6-v2 with transformers on CPU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.42 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diag raw r= 0.55069 sig r= 0.516399 logit stats: -11.419656753540039 8.316144943237305 -5.684374809265137\n"
          ]
        }
      ]
    },
    {
      "id": "d76adaac-58a1-47cf-93f6-3fe95a03cb5b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Full 5-fold CE (transformers) using STS-B regression head: cross-encoder/stsb-roberta-base\n",
        "import time, numpy as np, pandas as pd, torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "folds = pd.read_csv('folds_by_id.csv')\n",
        "train = train.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "train['fold'] = train['fold'].astype(int)\n",
        "NUM_FOLDS = int(train['fold'].max()) + 1\n",
        "\n",
        "MODEL = 'cross-encoder/stsb-roberta-base'\n",
        "MAX_LEN = 256\n",
        "BATCH = 64\n",
        "print('Loading', MODEL, 'on CPU...', flush=True)\n",
        "t0 = time.time()\n",
        "tok = AutoTokenizer.from_pretrained(MODEL, use_fast=False)\n",
        "mdl = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "mdl.eval(); mdl.to('cpu')\n",
        "print('Loaded in', round(time.time()-t0, 2), 's', flush=True)\n",
        "\n",
        "def batched_scores(pairs, bs=BATCH, max_length=MAX_LEN):\n",
        "    out = []\n",
        "    for i in range(0, len(pairs), bs):\n",
        "        a, b = zip(*pairs[i:i+bs])\n",
        "        enc = tok(list(a), list(b), padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            logits = mdl(**{k: v.to('cpu') for k, v in enc.items()}).logits.squeeze(-1)\n",
        "        out.append(logits.cpu().numpy().astype(np.float32))\n",
        "    return np.concatenate(out, axis=0)\n",
        "\n",
        "def make_pairs(df: pd.DataFrame, reverse: bool = False):\n",
        "    a = df['anchor'].astype(str).tolist()\n",
        "    b = df['target'].astype(str).tolist()\n",
        "    return list(zip(b, a)) if reverse else list(zip(a, b))\n",
        "\n",
        "y = train['score'].astype(np.float32).values\n",
        "oof = np.zeros(len(train), dtype=np.float32)\n",
        "\n",
        "# Precompute test predictions (symmetry avg for stability)\n",
        "pairs_te_f = make_pairs(test, reverse=False)\n",
        "pairs_te_r = make_pairs(test, reverse=True)\n",
        "s_te_f = batched_scores(pairs_te_f)\n",
        "s_te_r = batched_scores(pairs_te_r)\n",
        "te_scores = ((s_te_f + s_te_r) / 2.0).astype(np.float32)\n",
        "\n",
        "for f in range(NUM_FOLDS):\n",
        "    f0 = time.time()\n",
        "    va_idx = np.where(train['fold'].values == f)[0]\n",
        "    va_df = train.iloc[va_idx]\n",
        "    s_f = batched_scores(make_pairs(va_df, reverse=False))\n",
        "    s_r = batched_scores(make_pairs(va_df, reverse=True))\n",
        "    s = ((s_f + s_r) / 2.0).astype(np.float32)\n",
        "    oof[va_idx] = s\n",
        "    r = pearsonr(s, y[va_idx])[0]\n",
        "    print(f'[STS-B Fold {f}] r={r:.6f}; elapsed {time.time()-f0:.1f}s', flush=True)\n",
        "\n",
        "r_all = pearsonr(oof, y)[0] if np.std(oof) > 0 else float('nan')\n",
        "print('STS-B full OOF r=', round(float(r_all), 6), flush=True)\n",
        "\n",
        "# Save with strict schemas\n",
        "pd.DataFrame({'id': train['id'], 'pred': oof}).to_csv('oof_ce_stsb_plain.csv', index=False)\n",
        "pd.DataFrame({'id': test['id'], 'pred': te_scores}).to_csv('submission_ce_stsb_plain.csv', index=False)\n",
        "print('Saved oof_ce_stsb_plain.csv and submission_ce_stsb_plain.csv', flush=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cross-encoder/stsb-roberta-base on CPU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded in 0.28 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STS-B Fold 0] r=0.505154; elapsed 29.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STS-B Fold 1] r=0.518127; elapsed 30.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STS-B Fold 2] r=0.505230; elapsed 33.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STS-B Fold 3] r=0.522861; elapsed 34.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STS-B Fold 4] r=0.507379; elapsed 32.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STS-B full OOF r= 0.51171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved oof_ce_stsb_plain.csv and submission_ce_stsb_plain.csv\n"
          ]
        }
      ]
    },
    {
      "id": "474df135-9725-4788-839c-2746da9285c9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build fold-safe CE feature transforms (raw, iso, z, rank) from existing oof_ce_minilm.csv/submission_ce_minilm.csv\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test  = pd.read_csv('test.csv')\n",
        "folds = pd.read_csv('folds_by_id.csv')\n",
        "oof   = pd.read_csv('oof_ce_minilm.csv')  # [id,pred]\n",
        "sub   = pd.read_csv('submission_ce_minilm.csv')  # [id,pred]\n",
        "\n",
        "# Merge folds\n",
        "train = train.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "train['fold'] = train['fold'].astype(int)\n",
        "NUM_FOLDS = int(train['fold'].max()) + 1\n",
        "\n",
        "y = train['score'].astype(np.float32).values\n",
        "oof_raw = train[['id']].merge(oof, on='id', how='left', validate='one_to_one')['pred'].astype(np.float32).values\n",
        "te_raw  = test[['id']].merge(sub, on='id', how='left', validate='one_to_one')['pred'].astype(np.float32).values\n",
        "\n",
        "# Allocate\n",
        "oof_iso  = np.zeros(len(train), dtype=np.float32)\n",
        "oof_z    = np.zeros(len(train), dtype=np.float32)\n",
        "oof_rank = np.zeros(len(train), dtype=np.float32)\n",
        "te_iso_acc  = np.zeros(len(test), dtype=np.float64)\n",
        "te_z_acc    = np.zeros(len(test), dtype=np.float64)\n",
        "te_rank_acc = np.zeros(len(test), dtype=np.float64)\n",
        "\n",
        "fold_arr = train['fold'].values.astype(int)\n",
        "for f in range(NUM_FOLDS):\n",
        "    tr = fold_arr != f\n",
        "    va = fold_arr == f\n",
        "    # Isotonic on train-only\n",
        "    iso = IsotonicRegression(increasing=True, out_of_bounds='clip')\n",
        "    iso.fit(oof_raw[tr], y[tr])\n",
        "    oof_iso[va] = iso.transform(oof_raw[va]).astype(np.float32)\n",
        "    te_iso_acc += iso.transform(te_raw).astype(np.float64)\n",
        "    # z-score using train-only stats\n",
        "    mu = float(oof_raw[tr].mean()); sd = float(oof_raw[tr].std()) or 1.0\n",
        "    oof_z[va] = (oof_raw[va] - mu) / sd\n",
        "    te_z_acc += (te_raw - mu) / sd\n",
        "    # rank within train-only reference\n",
        "    ref = np.sort(oof_raw[tr].astype(np.float32))\n",
        "    if ref.size > 0:\n",
        "        j_va = np.searchsorted(ref, oof_raw[va], side='right')\n",
        "        oof_rank[va] = j_va / max(ref.size - 1, 1)\n",
        "        j_te = np.searchsorted(ref, te_raw, side='right')\n",
        "        te_rank_acc += (j_te / max(ref.size - 1, 1))\n",
        "\n",
        "te_iso  = (te_iso_acc / NUM_FOLDS).astype(np.float32)\n",
        "te_z    = (te_z_acc / NUM_FOLDS).astype(np.float32)\n",
        "te_rank = (te_rank_acc / NUM_FOLDS).astype(np.float32)\n",
        "\n",
        "# Save feature blocks with consistent schemas\n",
        "oof_df = pd.DataFrame({\n",
        "    'id': train['id'],\n",
        "    'ce_plain_raw': oof_raw,\n",
        "    'ce_plain_iso': oof_iso,\n",
        "    'ce_plain_z': oof_z,\n",
        "    'ce_plain_rank': oof_rank,\n",
        "})\n",
        "te_df = pd.DataFrame({\n",
        "    'id': test['id'],\n",
        "    'ce_plain_raw': te_raw,\n",
        "    'ce_plain_iso': te_iso,\n",
        "    'ce_plain_z': te_z,\n",
        "    'ce_plain_rank': te_rank,\n",
        "})\n",
        "oof_df.to_csv('oof_ce_plain_feats.csv', index=False)\n",
        "te_df.to_csv('ce_plain_feats_test.csv', index=False)\n",
        "print('Saved oof_ce_plain_feats.csv and ce_plain_feats_test.csv')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved oof_ce_plain_feats.csv and ce_plain_feats_test.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}