{
  "cells": [
    {
      "id": "b1f4f799-02b0-4d07-8335-7e89eb599986",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# BM25 Okapi/L/Plus features (A->B and B->A), fold-safe with stemming, ranks, squares, on normalized text.\n",
        "# Outputs: oof_bm25_var_norm.csv and bm25_var_norm_test.csv\n",
        "import time, re, math, gc, unicodedata, numpy as np, pandas as pd\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# ---------- Normalization utilities (NFKC + confusables + number-unit split + de-hyphen) ----------\n",
        "REPL = {\n",
        "    '\\u00b5': 'u',   # micro sign\n",
        "    '\\u03bc': 'u',   # Greek mu\n",
        "    '\\u03a9': 'ohm', # Omega\n",
        "    '\\u2126': 'ohm', # Ohm symbol\n",
        "    '\\u00b0C': 'deg C',  # degree C\n",
        "    '\\u00b0F': 'deg F',  # degree F\n",
        "    '\\u00b0': 'deg',     # bare degree\n",
        "    '\\u00d7': 'x',       # multiplication sign\n",
        "    '\\u2032': \"'\",      # prime\n",
        "    '\\u2033': '\"',      # double prime\n",
        "}\n",
        "_SUBS = str.maketrans('\u2080\u2081\u2082\u2083\u2084\u2085\u2086\u2087\u2088\u2089', '0123456789')\n",
        "_SUPS_MAP = { '\u00b2': '2', '\u00b3': '3', '\u207a': '+', '\u207b': '-' }\n",
        "NUM_UNIT_ATTACH = re.compile(r'(?i)(\\d+(?:[\\./]\\d+)?)([a-zA-Z%][a-zA-Z%/]*)')\n",
        "\n",
        "def nfkc(s: str) -> str:\n",
        "    return unicodedata.normalize('NFKC', s)\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    s = nfkc(str(s))\n",
        "    for k, v in REPL.items():\n",
        "        s = s.replace(k, v)\n",
        "    for k, v in _SUPS_MAP.items():\n",
        "        s = s.replace(k, v)\n",
        "    s = s.translate(_SUBS)\n",
        "    s = s.replace('-', ' ').replace('_', ' ')\n",
        "    s = NUM_UNIT_ATTACH.sub(r'\\1 \\2', s)\n",
        "    s = s.lower()\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    return s\n",
        "\n",
        "# ---------- Tokenizer with Porter stemming ----------\n",
        "try:\n",
        "    from nltk.stem import PorterStemmer\n",
        "    _stemmer = PorterStemmer()\n",
        "    def stem_token(tok: str) -> str:\n",
        "        return _stemmer.stem(tok)\n",
        "except Exception:\n",
        "    def stem_token(tok: str) -> str:\n",
        "        return tok\n",
        "\n",
        "_word_re = re.compile(r\"[a-z0-9]+(?:[./][a-z0-9]+)?\")\n",
        "def tokenize_stems(text: str):\n",
        "    if not isinstance(text, str):\n",
        "        text = ''\n",
        "    text = normalize_text(text)\n",
        "    toks = _word_re.findall(text)\n",
        "    return [stem_token(t) for t in toks if t]\n",
        "\n",
        "# ---------- BM25 IDF and scoring ----------\n",
        "def build_corpus_stats(docs_tokens):\n",
        "    N = len(docs_tokens)\n",
        "    df = Counter()\n",
        "    dl = np.zeros(N, dtype=np.int32)\n",
        "    for i, toks in enumerate(docs_tokens):\n",
        "        dl[i] = len(toks)\n",
        "        if toks:\n",
        "            df.update(set(toks))\n",
        "    avgdl = float(dl.mean() if N > 0 else 0.0)\n",
        "    idf = {t: math.log((N - c + 0.5)/(c + 0.5) + 1.0) for t, c in df.items()}\n",
        "    return {'N': N, 'df': df, 'idf': idf, 'dl': dl, 'avgdl': avgdl}\n",
        "\n",
        "def tf_counts(tokens):\n",
        "    return Counter(tokens)\n",
        "\n",
        "def bm25_okapi_score(query_tokens, doc_tokens, stats, k1=1.5, b=0.75):\n",
        "    if not query_tokens or not doc_tokens:\n",
        "        return 0.0\n",
        "    idf = stats['idf']\n",
        "    dl = len(doc_tokens); avgdl = stats['avgdl'] if stats['avgdl'] > 0 else 1.0\n",
        "    tf = tf_counts(doc_tokens)\n",
        "    score = 0.0\n",
        "    for t in set(query_tokens):\n",
        "        if t not in idf:\n",
        "            continue\n",
        "        f = tf.get(t, 0)\n",
        "        if f == 0:\n",
        "            continue\n",
        "        denom = f + k1 * (1 - b + b * dl / avgdl)\n",
        "        score += idf[t] * (f * (k1 + 1)) / denom\n",
        "    return float(score)\n",
        "\n",
        "def bm25l_score(query_tokens, doc_tokens, stats, k1=1.5, b=0.75, delta=0.5):\n",
        "    if not query_tokens or not doc_tokens:\n",
        "        return 0.0\n",
        "    idf = stats['idf']\n",
        "    dl = len(doc_tokens); avgdl = stats['avgdl'] if stats['avgdl'] > 0 else 1.0\n",
        "    tf = tf_counts(doc_tokens)\n",
        "    score = 0.0\n",
        "    for t in set(query_tokens):\n",
        "        if t not in idf:\n",
        "            continue\n",
        "        f = tf.get(t, 0)\n",
        "        if f == 0:\n",
        "            continue\n",
        "        denom = f + k1 * (1 - b + b * dl / avgdl)\n",
        "        score += idf[t] * ((f + delta) * (k1 + 1)) / (denom + delta)\n",
        "    return float(score)\n",
        "\n",
        "def bm25plus_score(query_tokens, doc_tokens, stats, k1=1.2, b=0.75, delta=1.0):\n",
        "    if not query_tokens or not doc_tokens:\n",
        "        return 0.0\n",
        "    idf = stats['idf']\n",
        "    dl = len(doc_tokens); avgdl = stats['avgdl'] if stats['avgdl'] > 0 else 1.0\n",
        "    tf = tf_counts(doc_tokens)\n",
        "    score = 0.0\n",
        "    for t in set(query_tokens):\n",
        "        if t not in idf:\n",
        "            continue\n",
        "        f = tf.get(t, 0)\n",
        "        if f == 0:\n",
        "            continue\n",
        "        denom = f + k1 * (1 - b + b * dl / avgdl)\n",
        "        score += idf[t] * ((f * (k1 + 1)) / denom + delta)\n",
        "    return float(score)\n",
        "\n",
        "# ---------- Load data and folds ----------\n",
        "t0 = time.time()\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "folds = pd.read_csv('folds_by_id.csv')\n",
        "train = train.merge(folds, on='id', how='left', validate='one_to_one')\n",
        "fold_arr = train['fold'].values.astype(int)\n",
        "NUM_FOLDS = int(train['fold'].max()) + 1\n",
        "print('Found folds:', NUM_FOLDS, flush=True)\n",
        "\n",
        "# Pre-tokenize once (normalized + stemmed)\n",
        "A_tr_tok = [tokenize_stems(x) for x in train['anchor'].astype(str).tolist()]\n",
        "B_tr_tok = [tokenize_stems(x) for x in train['target'].astype(str).tolist()]\n",
        "A_te_tok = [tokenize_stems(x) for x in test['anchor'].astype(str).tolist()]\n",
        "B_te_tok = [tokenize_stems(x) for x in test['target'].astype(str).tolist()]\n",
        "\n",
        "n_tr = len(train); n_te = len(test)\n",
        "cols = [\n",
        "    'bm25_okapi_ab','bm25_okapi_ba',\n",
        "    'bm25l_ab','bm25l_ba',\n",
        "    'bm25p_ab','bm25p_ba',\n",
        "    'bm25_okapi_ab_sq','bm25_okapi_ba_sq',\n",
        "    'bm25l_ab_sq','bm25l_ba_sq',\n",
        "    'bm25p_ab_sq','bm25p_ba_sq',\n",
        "    'bm25_okapi_ab_rank','bm25_okapi_ba_rank',\n",
        "    'bm25l_ab_rank','bm25l_ba_rank',\n",
        "    'bm25p_ab_rank','bm25p_ba_rank',\n",
        "    'bm25_okapi_ab_pct','bm25_okapi_ba_pct',\n",
        "    'bm25l_ab_pct','bm25l_ba_pct',\n",
        "    'bm25p_ab_pct','bm25p_ba_pct'\n",
        "]\n",
        "oof = np.zeros((n_tr, len(cols)), dtype=np.float32)\n",
        "te_accum = np.zeros((n_te, len(cols)), dtype=np.float32)\n",
        "\n",
        "for f in range(NUM_FOLDS):\n",
        "    f0 = time.time()\n",
        "    tr_idx = np.where(fold_arr != f)[0]\n",
        "    va_idx = np.where(fold_arr == f)[0]\n",
        "    print(f'Fold {f}: train {len(tr_idx)} val {len(va_idx)}', flush=True)\n",
        "\n",
        "    # Build train-only corpus stats for B (for A->B scoring) and for A (for B->A scoring)\n",
        "    docs_B = [B_tr_tok[i] for i in tr_idx]\n",
        "    docs_A = [A_tr_tok[i] for i in tr_idx]\n",
        "    stats_B = build_corpus_stats(docs_B)\n",
        "    stats_A = build_corpus_stats(docs_A)\n",
        "\n",
        "    # Compute reference scores on train-only (for rank/pct on val)\n",
        "    ref_ok_ab = []; ref_ok_ba = []\n",
        "    ref_l_ab = []; ref_l_ba = []\n",
        "    ref_p_ab = []; ref_p_ba = []\n",
        "    for i in tr_idx:\n",
        "        qa, db = A_tr_tok[i], B_tr_tok[i]\n",
        "        qb, da = B_tr_tok[i], A_tr_tok[i]\n",
        "        s_ok_ab = bm25_okapi_score(qa, db, stats_B, k1=1.5, b=0.75)\n",
        "        s_ok_ba = bm25_okapi_score(qb, da, stats_A, k1=1.5, b=0.75)\n",
        "        s_l_ab = bm25l_score(qa, db, stats_B, k1=1.5, b=0.75, delta=0.5)\n",
        "        s_l_ba = bm25l_score(qb, da, stats_A, k1=1.5, b=0.75, delta=0.5)\n",
        "        s_p_ab = bm25plus_score(qa, db, stats_B, k1=1.2, b=0.75, delta=1.0)\n",
        "        s_p_ba = bm25plus_score(qb, da, stats_A, k1=1.2, b=0.75, delta=1.0)\n",
        "        ref_ok_ab.append(s_ok_ab); ref_ok_ba.append(s_ok_ba)\n",
        "        ref_l_ab.append(s_l_ab);   ref_l_ba.append(s_l_ba)\n",
        "        ref_p_ab.append(s_p_ab);   ref_p_ba.append(s_p_ba)\n",
        "    ref_ab_by_anchor = defaultdict(list)\n",
        "    ref_ba_by_anchor = defaultdict(list)\n",
        "    for idx_i, i in enumerate(tr_idx):\n",
        "        a = train.at[i, 'anchor']\n",
        "        ref_ab_by_anchor[a].append((ref_ok_ab[idx_i], ref_l_ab[idx_i], ref_p_ab[idx_i]))\n",
        "        ref_ba_by_anchor[a].append((ref_ok_ba[idx_i], ref_l_ba[idx_i], ref_p_ba[idx_i]))\n",
        "    for a in ref_ab_by_anchor:\n",
        "        arr = np.array(ref_ab_by_anchor[a], dtype=np.float32)\n",
        "        ref_ab_by_anchor[a] = np.sort(arr, axis=0)\n",
        "    for a in ref_ba_by_anchor:\n",
        "        arr = np.array(ref_ba_by_anchor[a], dtype=np.float32)\n",
        "        ref_ba_by_anchor[a] = np.sort(arr, axis=0)\n",
        "\n",
        "    # Compute OOF for validation rows\n",
        "    for idx in va_idx:\n",
        "        qa, db = A_tr_tok[idx], B_tr_tok[idx]\n",
        "        qb, da = B_tr_tok[idx], A_tr_tok[idx]\n",
        "        ok_ab = bm25_okapi_score(qa, db, stats_B, k1=1.5, b=0.75)\n",
        "        ok_ba = bm25_okapi_score(qb, da, stats_A, k1=1.5, b=0.75)\n",
        "        l_ab = bm25l_score(qa, db, stats_B, k1=1.5, b=0.75, delta=0.5)\n",
        "        l_ba = bm25l_score(qb, da, stats_A, k1=1.5, b=0.75, delta=0.5)\n",
        "        p_ab = bm25plus_score(qa, db, stats_B, k1=1.2, b=0.75, delta=1.0)\n",
        "        p_ba = bm25plus_score(qb, da, stats_A, k1=1.2, b=0.75, delta=1.0)\n",
        "        vals = [ok_ab, ok_ba, l_ab, l_ba, p_ab, p_ba]\n",
        "        vals_sq = [v*v for v in vals]\n",
        "        a = train.at[idx, 'anchor']\n",
        "        arr_ab = ref_ab_by_anchor.get(a)\n",
        "        arr_ba = ref_ba_by_anchor.get(a)\n",
        "        ranks = [np.nan]*6; pcts = [np.nan]*6\n",
        "        if arr_ab is not None and len(arr_ab) > 0:\n",
        "            for j, v in enumerate([ok_ab, l_ab, p_ab]):\n",
        "                jpos = np.searchsorted(arr_ab[:, j], v, side='right')\n",
        "                pcts[j*2] = jpos / len(arr_ab)\n",
        "                ranks[j*2] = jpos\n",
        "        if arr_ba is not None and len(arr_ba) > 0:\n",
        "            for j, v in enumerate([ok_ba, l_ba, p_ba]):\n",
        "                jpos = np.searchsorted(arr_ba[:, j], v, side='right')\n",
        "                pcts[j*2+1] = jpos / len(arr_ba)\n",
        "                ranks[j*2+1] = jpos\n",
        "        row = [ok_ab, ok_ba, l_ab, l_ba, p_ab, p_ba] + vals_sq + ranks + pcts\n",
        "        oof[idx, :] = np.array(row, dtype=np.float32)\n",
        "\n",
        "    # Test features using this fold's stats\n",
        "    te_vals = np.zeros((n_te, len(cols)), dtype=np.float32)\n",
        "    for j in range(n_te):\n",
        "        qa, db = A_te_tok[j], B_te_tok[j]\n",
        "        qb, da = B_te_tok[j], A_te_tok[j]\n",
        "        ok_ab = bm25_okapi_score(qa, db, stats_B, k1=1.5, b=0.75)\n",
        "        ok_ba = bm25_okapi_score(qb, da, stats_A, k1=1.5, b=0.75)\n",
        "        l_ab = bm25l_score(qa, db, stats_B, k1=1.5, b=0.75, delta=0.5)\n",
        "        l_ba = bm25l_score(qb, da, stats_A, k1=1.5, b=0.75, delta=0.5)\n",
        "        p_ab = bm25plus_score(qa, db, stats_B, k1=1.2, b=0.75, delta=1.0)\n",
        "        p_ba = bm25plus_score(qb, da, stats_A, k1=1.2, b=0.75, delta=1.0)\n",
        "        vals = [ok_ab, ok_ba, l_ab, l_ba, p_ab, p_ba]\n",
        "        vals_sq = [v*v for v in vals]\n",
        "        a = test.at[j, 'anchor']\n",
        "        arr_ab = ref_ab_by_anchor.get(a)\n",
        "        arr_ba = ref_ba_by_anchor.get(a)\n",
        "        ranks = [np.nan]*6; pcts = [np.nan]*6\n",
        "        if arr_ab is not None and len(arr_ab) > 0:\n",
        "            for k, v in enumerate([ok_ab, l_ab, p_ab]):\n",
        "                jpos = np.searchsorted(arr_ab[:, k], v, side='right')\n",
        "                pcts[k*2] = jpos / len(arr_ab)\n",
        "                ranks[k*2] = jpos\n",
        "        if arr_ba is not None and len(arr_ba) > 0:\n",
        "            for k, v in enumerate([ok_ba, l_ba, p_ba]):\n",
        "                jpos = np.searchsorted(arr_ba[:, k], v, side='right')\n",
        "                pcts[k*2+1] = jpos / len(arr_ba)\n",
        "                ranks[k*2+1] = jpos\n",
        "        te_vals[j, :] = np.array([ok_ab, ok_ba, l_ab, l_ba, p_ab, p_ba] + vals_sq + ranks + pcts, dtype=np.float32)\n",
        "    te_accum += te_vals\n",
        "\n",
        "    print(f'Fold {f} done in {time.time()-f0:.2f}s', flush=True)\n",
        "    gc.collect()\n",
        "\n",
        "# Average test across folds\n",
        "te_mean = te_accum / NUM_FOLDS\n",
        "\n",
        "# Save\n",
        "oof_df = pd.DataFrame({'id': train['id']})\n",
        "for k, c in enumerate(cols):\n",
        "    oof_df[c] = oof[:, k]\n",
        "oof_df.to_csv('oof_bm25_var_norm.csv', index=False)\n",
        "\n",
        "te_df = pd.DataFrame({'id': test['id']})\n",
        "for k, c in enumerate(cols):\n",
        "    te_df[c] = te_mean[:, k]\n",
        "te_df.to_csv('bm25_var_norm_test.csv', index=False)\n",
        "\n",
        "print('Saved oof_bm25_var_norm.csv and bm25_var_norm_test.csv; elapsed', round((time.time()-t0)/60,2), 'min', flush=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found folds: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: train 26739 val 6086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 done in 0.58s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: train 26310 val 6515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 done in 0.51s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: train 26195 val 6630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 done in 0.51s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3: train 25884 val 6941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 done in 0.50s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4: train 26172 val 6653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 done in 0.51s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved oof_bm25_var_norm.csv and bm25_var_norm_test.csv; elapsed 0.06 min\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}