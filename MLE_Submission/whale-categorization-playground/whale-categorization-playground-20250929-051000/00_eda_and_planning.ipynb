{
  "cells": [
    {
      "id": "ae552c48-5391-4333-bdaa-c46bb09cb741",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan to Medal: Humpback Whale Identification (MAP@5)\n",
        "\n",
        "## 0) Environment & GPU\n",
        "- Verify GPU with nvidia-smi.\n",
        "- Install PyTorch cu121 stack and key libs (timm, albumentations, torchvision).\n",
        "- Add constraints.txt to lock torch versions.\n",
        "\n",
        "## 1) Data Audit\n",
        "- Inspect train.csv, sample_submission.csv.\n",
        "- Check image counts in train/ and test/; verify filename matching.\n",
        "- Class distribution, #classes, imbalance, images per class.\n",
        "- Create stratified KFold splits (by class) and persist folds.\n",
        "\n",
        "## 2) Baseline Model\n",
        "- Image classification with strong pretrained backbone (timm):\n",
        "  - Start: tf_efficientnet_b0_ns or convnext_tiny, 224\u2013256 px.\n",
        "  - Loss: CrossEntropy with label smoothing (0.05).\n",
        "  - Augs: flips, random resized crop, color jitter, CutMix/Mixup.\n",
        "  - Optim: AdamW, OneCycle/Cosine, AMP, weight decay 1e-4.\n",
        "  - 5-fold CV, early stopping; log per-fold metrics.\n",
        "- Produce OOF logits and test logits.\n",
        "\n",
        "## 3) Iterate\n",
        "- Upgrade backbone (convnext_base, eva02, NFNet), increase res (384).\n",
        "- Fine-tune head-last-only warmup then full.\n",
        "- TTA at inference (hflip, multi-scale).\n",
        "- Calibrate/Blend multiple seeds/backbones (weighted avg).\n",
        "\n",
        "## 4) Validation Discipline\n",
        "- Single saved folds; transforms fit per-fold only.\n",
        "- Monitor MAP@5 on OOF; ensure no leakage.\n",
        "- Cache features/logits to npy for fast iteration.\n",
        "\n",
        "## 5) Submission\n",
        "- Generate top-5 labels per image in required format.\n",
        "- Verify submission.csv shape/columns and spot-check.\n",
        "\n",
        "## Checkpoints for Expert Review\n",
        "- After this plan.\n",
        "- After data audit + folds.\n",
        "- After first baseline OOF.\n",
        "- After each major model/ensemble change."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "22cfb6fc-61aa-4f66-9c3d-d4a8046392d4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment check: GPU + files + quick data audit\n",
        "import os, sys, subprocess, time, json, pandas as pd, numpy as np, glob\n",
        "from pathlib import Path\n",
        "\n",
        "t0 = time.time()\n",
        "print('Python:', sys.version)\n",
        "print('CWD:', os.getcwd())\n",
        "print('Listing top-level:')\n",
        "for p in Path('.').iterdir():\n",
        "    mtime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(p.stat().st_mtime))\n",
        "    print('-', p, ('[DIR]' if p.is_dir() else ''), mtime)\n",
        "\n",
        "print('\\n== nvidia-smi ==')\n",
        "try:\n",
        "    out = subprocess.check_output(['bash','-lc','nvidia-smi || true'], text=True)\n",
        "    print(out)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi error:', e)\n",
        "\n",
        "# Quick file counts\n",
        "train_dir = Path('train')\n",
        "test_dir = Path('test')\n",
        "train_imgs = sorted(str(p.name) for p in train_dir.glob('*') if p.is_file()) if train_dir.exists() else []\n",
        "test_imgs = sorted(str(p.name) for p in test_dir.glob('*') if p.is_file()) if test_dir.exists() else []\n",
        "print(f'Train images: {len(train_imgs)} | Test images: {len(test_imgs)}')\n",
        "print('Sample train imgs:', train_imgs[:5])\n",
        "print('Sample test imgs:', test_imgs[:5])\n",
        "\n",
        "# Load CSVs\n",
        "train_csv = pd.read_csv('train.csv')\n",
        "sample_sub = pd.read_csv('sample_submission.csv')\n",
        "print('\\ntrain.csv shape:', train_csv.shape)\n",
        "print(train_csv.head())\n",
        "print('\\nsample_submission.csv shape:', sample_sub.shape)\n",
        "print(sample_sub.head())\n",
        "\n",
        "# Basic integrity checks\n",
        "img_col = 'Image' if 'Image' in train_csv.columns else train_csv.columns[0]\n",
        "train_fns = set(train_csv[img_col].astype(str))\n",
        "if len(train_imgs) and len(train_fns):\n",
        "    inter = len(set(train_imgs) & train_fns)\n",
        "    print(f'Filename match train.csv vs train/ : {inter}/{len(train_fns)} present')\n",
        "else:\n",
        "    print('Skip filename match check (missing files or column)')\n",
        "\n",
        "print(f'Elapsed: {time.time()-t0:.2f}s')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]\nCWD: /var/lib/simon/agent_run_states/whale-categorization-playground-20250929-051000\nListing top-level:\n- sample_submission.csv  2025-09-29 05:13:46\n- .00_eda_and_planning_kernel_state.json  2025-09-29 05:18:16\n- docker_run.log  2025-09-29 05:18:16\n- requirements.txt  2025-09-29 05:17:55\n- test [DIR] 2025-09-29 05:13:47\n- submission.csv  2025-09-29 05:13:51\n- train [DIR] 2025-09-29 05:13:47\n- train.csv  2025-09-29 05:13:46\n- agent_metadata [DIR] 2025-09-29 05:14:31\n- task.txt  2025-09-29 05:13:19\n- 00_eda_and_planning.ipynb  2025-09-29 05:18:12\n- description.md  2025-09-29 05:13:47\n\n== nvidia-smi ==\nMon Sep 29 05:18:16 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\nTrain images: 7240 | Test images: 2610\nSample train imgs: ['00022e1a.jpg', '000466c4.jpg', '001296d5.jpg', '0025e8c2.jpg', '0026a8ab.jpg']\nSample test imgs: ['00087b01.jpg', '0014cfdf.jpg', '0035632e.jpg', '004c5fb9.jpg', '00863b8c.jpg']\n\ntrain.csv shape: (7240, 2)\n          Image         Id\n0  00022e1a.jpg  w_e15442c\n1  000466c4.jpg  w_1287fbc\n2  001296d5.jpg  w_19e5482\n3  0025e8c2.jpg  w_8b1ca89\n4  0026a8ab.jpg  w_eaad6a8\n\nsample_submission.csv shape: (2610, 2)\n          Image                                                 Id\n0  00087b01.jpg  new_whale w_1287fbc w_98baff9 w_7554f44 w_1eafe46\n1  0014cfdf.jpg  new_whale w_1287fbc w_98baff9 w_7554f44 w_1eafe46\n2  0035632e.jpg  new_whale w_1287fbc w_98baff9 w_7554f44 w_1eafe46\n3  004c5fb9.jpg  new_whale w_1287fbc w_98baff9 w_7554f44 w_1eafe46\n4  00863b8c.jpg  new_whale w_1287fbc w_98baff9 w_7554f44 w_1eafe46\nFilename match train.csv vs train/ : 7240/7240 present\nElapsed: 0.09s\n"
          ]
        }
      ]
    },
    {
      "id": "2e6c69d0-5965-41dc-94b4-2c4ed419fe5d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install PyTorch cu121 stack and key libs; sanity check GPU\n",
        "import os, sys, subprocess, shutil, time\n",
        "from pathlib import Path\n",
        "\n",
        "def pip(*args):\n",
        "    print('> pip', ' '.join(args), flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "t0=time.time()\n",
        "print('Starting install...')\n",
        "# Uninstall any pre-existing torch stack to avoid conflicts\n",
        "for pkg in ('torch','torchvision','torchaudio'):\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "\n",
        "# Clean stray site dirs that can shadow correct wheels (idempotent)\n",
        "for d in (\n",
        "    '/app/.pip-target/torch',\n",
        "    '/app/.pip-target/torchvision',\n",
        "    '/app/.pip-target/torchaudio',\n",
        "    '/app/.pip-target/torch-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torch-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchvision-0.23.0.dist-info',\n",
        "    '/app/.pip-target/torchvision-0.19.1.dist-info',\n",
        "    '/app/.pip-target/torchaudio-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torchaudio-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchgen',\n",
        "    '/app/.pip-target/functorch',\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d)\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# Install exact cu121 wheels\n",
        "pip('install',\n",
        "    '--index-url','https://download.pytorch.org/whl/cu121',\n",
        "    '--extra-index-url','https://pypi.org/simple',\n",
        "    'torch==2.4.1','torchvision==0.19.1','torchaudio==2.4.1')\n",
        "\n",
        "# Freeze torch versions\n",
        "Path('constraints.txt').write_text('torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n')\n",
        "\n",
        "# Install non-torch deps honoring constraints\n",
        "pip('install','-c','constraints.txt',\n",
        "    'timm==1.0.9','albumentations==1.4.14','opencv-python-headless==4.10.0.84',\n",
        "    'faiss-cpu==1.8.0','scikit-learn','pandas','numpy','matplotlib',\n",
        "    '--upgrade-strategy','only-if-needed')\n",
        "\n",
        "# Sanity check torch CUDA\n",
        "import torch\n",
        "print('torch:', torch.__version__, 'built CUDA:', getattr(torch.version,'cuda',None))\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f'Wrong CUDA build: {torch.version.cuda}'\n",
        "assert torch.cuda.is_available(), 'CUDA not available'\n",
        "print('GPU:', torch.cuda.get_device_name(0))\n",
        "print(f'Install done in {time.time()-t0:.1f}s')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting install...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchvision as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install --index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.org/simple torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 438.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 466.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 491.7 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 219.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 243.7 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 236.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 453.6 MB/s eta 0:00:00\nCollecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 366.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 185.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 208.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 191.2 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 312.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 261.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 227.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 481.5 MB/s eta 0:00:00\nCollecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 535.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 364.7 MB/s eta 0:00:00\nCollecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 468.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 426.4 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 200.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 235.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 185.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 247.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 500.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.3 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install -c constraints.txt timm==1.0.9 albumentations==1.4.14 opencv-python-headless==4.10.0.84 faiss-cpu==1.8.0 scikit-learn pandas numpy matplotlib --upgrade-strategy only-if-needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==1.0.9\n  Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.3/2.3 MB 55.3 MB/s eta 0:00:00\nCollecting albumentations==1.4.14\n  Downloading albumentations-1.4.14-py3-none-any.whl (177 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 178.0/178.0 KB 422.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.10.0.84\n  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 49.9/49.9 MB 212.8 MB/s eta 0:00:00\nCollecting faiss-cpu==1.8.0\n  Downloading faiss_cpu-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 27.0/27.0 MB 131.2 MB/s eta 0:00:00\nCollecting scikit-learn\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 9.7/9.7 MB 211.1 MB/s eta 0:00:00\nCollecting pandas\n  Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12.4/12.4 MB 572.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 288.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matplotlib\n  Downloading matplotlib-3.10.6-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 8.7/8.7 MB 407.5 MB/s eta 0:00:00\nCollecting torch\n  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 797.1/797.1 MB 85.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml\n  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 806.6/806.6 KB 526.7 MB/s eta 0:00:00\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 563.3/563.3 KB 529.6 MB/s eta 0:00:00\nCollecting torchvision\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.0/7.0 MB 232.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting safetensors\n  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 485.8/485.8 KB 508.6 MB/s eta 0:00:00\nCollecting typing-extensions>=4.9.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 362.6 MB/s eta 0:00:00\nCollecting eval-type-backport\n  Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\nCollecting albucore>=0.0.13\n  Downloading albucore-0.0.33-py3-none-any.whl (18 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy>=1.10.0\n  Downloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35.9/35.9 MB 549.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic>=2.7.0\n  Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 444.9/444.9 KB 516.9 MB/s eta 0:00:00\nCollecting scikit-image>=0.21.0\n  Downloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.8/14.8 MB 199.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting threadpoolctl>=3.1.0\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nCollecting joblib>=1.2.0\n  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 308.4/308.4 KB 475.7 MB/s eta 0:00:00\nCollecting python-dateutil>=2.8.2\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 229.9/229.9 KB 475.4 MB/s eta 0:00:00\nCollecting tzdata>=2022.7\n  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 347.8/347.8 KB 507.5 MB/s eta 0:00:00\nCollecting pytz>=2020.1\n  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 509.2/509.2 KB 503.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyparsing>=2.3.1\n  Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 113.9/113.9 KB 413.4 MB/s eta 0:00:00\nCollecting cycler>=0.10\n  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\nCollecting kiwisolver>=1.3.1\n  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.4/1.4 MB 532.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fonttools>=4.22.0\n  Downloading fonttools-4.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 5.0/5.0 MB 553.4 MB/s eta 0:00:00\nCollecting packaging>=20.0\n  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 66.5/66.5 KB 391.8 MB/s eta 0:00:00\nCollecting contourpy>=1.0.1\n  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 355.2/355.2 KB 490.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow>=8\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 399.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stringzilla>=3.10.4\n  Downloading stringzilla-4.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (496 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 496.5/496.5 KB 359.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting simsimd>=5.9.2\n  Downloading simsimd-6.5.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.1/1.1 MB 167.1 MB/s eta 0:00:00\nCollecting typing-inspection>=0.4.0\n  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic-core==2.33.2\n  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 519.8 MB/s eta 0:00:00\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nCollecting six>=1.5\n  Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nCollecting tifffile>=2022.8.12\n  Downloading tifffile-2025.9.20-py3-none-any.whl (230 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 230.1/230.1 KB 452.9 MB/s eta 0:00:00\nCollecting networkx>=3.0\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 546.0 MB/s eta 0:00:00\nCollecting lazy-loader>=0.4\n  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imageio!=2.35.0,>=2.33\n  Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 315.8/315.8 KB 500.2 MB/s eta 0:00:00\nCollecting hf-xet<2.0.0,>=1.1.3\n  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.2/3.2 MB 289.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec>=2023.5.0\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 417.1 MB/s eta 0:00:00\nCollecting tqdm>=4.42.1\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 78.5/78.5 KB 450.6 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting requests\n  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.7/64.7 KB 404.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 348.5 MB/s eta 0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 238.3 MB/s eta 0:00:00\nCollecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 227.3 MB/s eta 0:00:00\nCollecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 487.1 MB/s eta 0:00:00\nCollecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 468.4 MB/s eta 0:00:00\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 226.7 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 251.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 285.9 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 244.5 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 192.8 MB/s eta 0:00:00\nCollecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 122.2 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 501.9 MB/s eta 0:00:00\nCollecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 228.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 249.7 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 206.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.10-py3-none-any.whl (70 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 70.4/70.4 KB 390.8 MB/s eta 0:00:00\nCollecting urllib3<3,>=1.21.1\n  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129.8/129.8 KB 411.6 MB/s eta 0:00:00\nCollecting charset_normalizer<4,>=2\n  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 150.3/150.3 KB 488.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting certifi>=2017.4.17\n  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.2/161.2 KB 477.8 MB/s eta 0:00:00\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 294.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: simsimd, pytz, mpmath, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, stringzilla, six, safetensors, pyyaml, pyparsing, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, joblib, idna, hf-xet, fsspec, fonttools, filelock, eval-type-backport, cycler, charset_normalizer, certifi, annotated-types, typing-inspection, triton, tifffile, scipy, requests, python-dateutil, pydantic-core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lazy-loader, jinja2, imageio, faiss-cpu, contourpy, scikit-learn, scikit-image, pydantic, pandas, nvidia-cusolver-cu12, matplotlib, huggingface_hub, albucore, torch, albumentations, torchvision, timm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.3 albucore-0.0.33 albumentations-1.4.14 annotated-types-0.7.0 certifi-2025.8.3 charset_normalizer-3.4.3 contourpy-1.3.3 cycler-0.12.1 eval-type-backport-0.2.2 faiss-cpu-1.8.0 filelock-3.19.1 fonttools-4.60.0 fsspec-2025.9.0 hf-xet-1.1.10 huggingface_hub-0.35.1 idna-3.10 imageio-2.37.0 jinja2-3.1.6 joblib-1.5.2 kiwisolver-1.4.9 lazy-loader-0.4 matplotlib-3.10.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 opencv-python-headless-4.10.0.84 packaging-25.0 pandas-2.3.2 pillow-11.3.0 pydantic-2.11.9 pydantic-core-2.33.2 pyparsing-3.2.5 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 requests-2.32.5 safetensors-0.6.2 scikit-image-0.25.2 scikit-learn-1.7.2 scipy-1.16.2 simsimd-6.5.3 six-1.17.0 stringzilla-4.0.14 sympy-1.14.0 threadpoolctl-3.6.0 tifffile-2025.9.20 timm-1.0.9 torch-2.4.1 torchvision-0.19.1 tqdm-4.67.1 triton-3.0.0 typing-extensions-4.15.0 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe-3.0.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 built CUDA: 12.1\nCUDA available: True\nGPU: NVIDIA A10-24Q\nInstall done in 133.9s\n"
          ]
        }
      ]
    },
    {
      "id": "7fe27831-b5c4-4e7e-9000-20b51263267c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Duplicate-aware folds: pHash clustering + StratifiedGroupKFold\n",
        "import os, time, math, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "\n",
        "t0=time.time()\n",
        "print('Starting duplicate audit and fold creation...')\n",
        "train_df = pd.read_csv('train.csv')\n",
        "img_col = 'Image'\n",
        "id_col = 'Id'\n",
        "train_dir = Path('train')\n",
        "\n",
        "# Fast perceptual hash via DCT (OpenCV), returns 64-bit int as hex string\n",
        "def phash_cv2(img_path, hash_size=8, highfreq_factor=4):\n",
        "    try:\n",
        "        img = cv2.imdecode(np.fromfile(str(img_path), dtype=np.uint8), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            return None\n",
        "        img = cv2.resize(img, (hash_size*highfreq_factor, hash_size*highfreq_factor), interpolation=cv2.INTER_AREA)\n",
        "        img = np.float32(img)\n",
        "        dct = cv2.dct(img)\n",
        "        dctlow = dct[:hash_size, :hash_size]\n",
        "        med = np.median(dctlow)\n",
        "        diff = dctlow > med\n",
        "        bits = ''.join('1' if x else '0' for x in diff.flatten())\n",
        "        return hex(int(bits, 2))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def hamming_hex(h1, h2):\n",
        "    if h1 is None or h2 is None:\n",
        "        return 64\n",
        "    n1 = int(h1, 16); n2 = int(h2, 16)\n",
        "    return (n1 ^ n2).bit_count()\n",
        "\n",
        "# Compute pHash for all train images\n",
        "paths = [train_dir / fn for fn in train_df[img_col].tolist()]\n",
        "hashes = []\n",
        "log_every = 500\n",
        "for i, p in enumerate(paths):\n",
        "    if (i % log_every)==0:\n",
        "        print(f'phash {i}/{len(paths)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "    hashes.append(phash_cv2(p))\n",
        "train_df['phash'] = hashes\n",
        "\n",
        "# Cluster near-duplicates by simple binning + union-find (Hamming <= 4)\n",
        "parent = list(range(len(train_df)))\n",
        "def find(x):\n",
        "    while parent[x]!=x:\n",
        "        parent[x]=parent[parent[x]]\n",
        "        x=parent[x]\n",
        "    return x\n",
        "def union(a,b):\n",
        "    ra, rb = find(a), find(b)\n",
        "    if ra!=rb:\n",
        "        parent[rb]=ra\n",
        "\n",
        "# Bucket by first N hex chars to reduce comparisons\n",
        "prefix = 4  # 16 bits bucket\n",
        "buckets = {}\n",
        "for idx,h in enumerate(train_df['phash']):\n",
        "    if h is None:\n",
        "        key = 'none'\n",
        "    else:\n",
        "        key = h[:2+prefix]  # '0x' + prefix chars\n",
        "    buckets.setdefault(key, []).append(idx)\n",
        "\n",
        "thr = 4\n",
        "checked_pairs = 0\n",
        "for key, idxs in buckets.items():\n",
        "    n = len(idxs)\n",
        "    if n<=1: continue\n",
        "    # compare all pairs within bucket (typically small)\n",
        "    for i in range(n):\n",
        "        hi = train_df.at[idxs[i], 'phash']\n",
        "        for j in range(i+1, n):\n",
        "            hj = train_df.at[idxs[j], 'phash']\n",
        "            d = hamming_hex(hi, hj)\n",
        "            checked_pairs += 1\n",
        "            if d <= thr:\n",
        "                union(idxs[i], idxs[j])\n",
        "print('Buckets:', len(buckets), 'pairs checked:', checked_pairs)\n",
        "\n",
        "# Assign cluster ids\n",
        "cluster_id = [find(i) for i in range(len(train_df))]\n",
        "root_map = {}\n",
        "next_cluster = 0\n",
        "clusters = []\n",
        "for r in cluster_id:\n",
        "    if r not in root_map:\n",
        "        root_map[r] = next_cluster; next_cluster += 1\n",
        "    clusters.append(root_map[r])\n",
        "train_df['dup_cluster'] = clusters\n",
        "\n",
        "print('Unique dup clusters:', train_df['dup_cluster'].nunique())\n",
        "print('Preparing StratifiedGroupKFold with groups = dup_cluster (fallback to Id if needed)')\n",
        "\n",
        "y = train_df[id_col].values\n",
        "groups = train_df['dup_cluster'].values\n",
        "\n",
        "n_splits = 5\n",
        "cv = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "folds = np.full(len(train_df), -1, dtype=int)\n",
        "for fold, (trn_idx, val_idx) in enumerate(cv.split(np.zeros(len(train_df)), y, groups)):\n",
        "    folds[val_idx] = fold\n",
        "    print(f'Fold {fold}: trn {len(trn_idx)} | val {len(val_idx)} | elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "\n",
        "assert (folds>=0).all(), 'Some rows not assigned to folds'\n",
        "train_df['fold'] = folds\n",
        "train_df[['Image','Id','phash','dup_cluster','fold']].to_csv('folds.csv', index=False)\n",
        "print('Saved folds.csv')\n",
        "\n",
        "# Sanity: per-fold label coverage\n",
        "lab_counts = train_df.groupby(['fold'])[id_col].nunique()\n",
        "print('Unique IDs per fold:\\n', lab_counts)\n",
        "print(f'Done in {time.time()-t0:.1f}s')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting duplicate audit and fold creation...\nphash 0/7240 elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 500/7240 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 1000/7240 elapsed 1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 1500/7240 elapsed 2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 2000/7240 elapsed 3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 2500/7240 elapsed 4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 3000/7240 elapsed 5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 3500/7240 elapsed 6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 4000/7240 elapsed 7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 4500/7240 elapsed 7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 5000/7240 elapsed 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 5500/7240 elapsed 9.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 6000/7240 elapsed 10.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 6500/7240 elapsed 11.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phash 7000/7240 elapsed 12.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buckets: 3909 pairs checked: 14350\nUnique dup clusters: 6861\nPreparing StratifiedGroupKFold with groups = dup_cluster (fallback to Id if needed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/model_selection/_split.py:1017: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_of_target_y = type_of_target(y)\n/app/.pip-target/sklearn/model_selection/_split.py:1035: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: trn 5780 | val 1460 | elapsed 16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: trn 5791 | val 1449 | elapsed 16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: trn 5789 | val 1451 | elapsed 16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3: trn 5809 | val 1431 | elapsed 16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4: trn 5791 | val 1449 | elapsed 16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved folds.csv\nUnique IDs per fold:\n fold\n0    1053\n1    1055\n2    1038\n3    1100\n4    1066\nName: Id, dtype: int64\nDone in 16.3s\n"
          ]
        }
      ]
    },
    {
      "id": "b2d414e7-7354-44b0-898c-be3663b86dc5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pretrained embedding retrieval baseline (ConvNeXt-Base @384) + CV MAP@5 + submission\n",
        "import os, time, math, gc, sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import timm\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "folds_df = pd.read_csv('folds.csv')  # Image, Id, phash, dup_cluster, fold\n",
        "train_df = train_df.merge(folds_df[['Image','fold']], on='Image', how='left')\n",
        "test_files = sorted([p.name for p in Path('test').glob('*') if p.is_file()])\n",
        "\n",
        "# Quick label info\n",
        "id_counts = train_df['Id'].value_counts()\n",
        "print('Num train images:', len(train_df), 'Num IDs:', id_counts.shape[0], 'new_whale in train:', ('new_whale' in id_counts.index))\n",
        "\n",
        "IMG_SIZE = 384\n",
        "MODEL_NAME = 'convnext_base.fb_in22k_ft_in1k'\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "IMAGENET_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
        "IMAGENET_STD  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
        "\n",
        "def read_image(path):\n",
        "    data = np.fromfile(path, dtype=np.uint8)\n",
        "    img = cv2.imdecode(data, cv2.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        raise RuntimeError(f'Failed to read {path}')\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "def preprocess(img, size, hflip=False):\n",
        "    h, w = img.shape[:2]\n",
        "    scale = min(size / h, size / w)\n",
        "    nh, nw = int(round(h * scale)), int(round(w * scale))\n",
        "    img_resized = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
        "    top = (size - nh) // 2\n",
        "    bottom = size - nh - top\n",
        "    left = (size - nw) // 2\n",
        "    right = size - nw - left\n",
        "    img_padded = cv2.copyMakeBorder(img_resized, top, bottom, left, right, borderType=cv2.BORDER_CONSTANT, value=(0,0,0))\n",
        "    if hflip:\n",
        "        img_padded = np.ascontiguousarray(img_padded[:, ::-1, :])\n",
        "    x = img_padded.astype(np.float32) / 255.0\n",
        "    x = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "    x = np.transpose(x, (2, 0, 1))  # CHW\n",
        "    return torch.from_numpy(x)\n",
        "\n",
        "class ImgDs(Dataset):\n",
        "    def __init__(self, root_dir, img_names, size, hflip=False):\n",
        "        self.root = Path(root_dir)\n",
        "        self.names = img_names\n",
        "        self.size = size\n",
        "        self.hflip = hflip\n",
        "    def __len__(self): return len(self.names)\n",
        "    def __getitem__(self, i):\n",
        "        fn = self.names[i]\n",
        "        img = read_image(self.root / fn)\n",
        "        tensor = preprocess(img, self.size, hflip=self.hflip)\n",
        "        return fn, tensor\n",
        "\n",
        "class FeatExtractor(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=True, num_classes=0, global_pool='avg')\n",
        "    def forward(self, x):\n",
        "        with torch.cuda.amp.autocast(enabled=True):\n",
        "            feats = self.model(x)\n",
        "        return feats\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_embeddings(model, root_dir, img_names, size, hflip=False):\n",
        "    ds = ImgDs(root_dir, img_names, size=size, hflip=hflip)\n",
        "    dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    dummy = torch.zeros(1,3,size,size, device=device)\n",
        "    emb_dim = model(dummy).shape[1]\n",
        "    embs = np.zeros((len(img_names), emb_dim), dtype=np.float32)\n",
        "    order = []\n",
        "    t0=time.time()\n",
        "    seen=0\n",
        "    for i,(fns, imgs) in enumerate(dl):\n",
        "        imgs = imgs.to(device, non_blocking=True)\n",
        "        feats = model(imgs)\n",
        "        feats = nn.functional.normalize(feats, dim=1).float().cpu().numpy()\n",
        "        embs[seen:seen+feats.shape[0]] = feats\n",
        "        order.extend(fns)\n",
        "        seen += feats.shape[0]\n",
        "        if i%20==0:\n",
        "            print(f'embed batch {i}, total {seen}/{len(img_names)}', flush=True)\n",
        "    return order, embs\n",
        "\n",
        "def mapk(truths, preds, k=5):\n",
        "    score=0.0\n",
        "    for t, ps in zip(truths, preds):\n",
        "        for i,p in enumerate(ps[:k]):\n",
        "            if p==t:\n",
        "                score += 1.0/(i+1)\n",
        "                break\n",
        "    return score/len(truths)\n",
        "\n",
        "def centroid_by_id(names, embs, ids):\n",
        "    df = pd.DataFrame({'Image': names, 'Id': ids})\n",
        "    id_to_idx = {}\n",
        "    for idv, grp in df.groupby('Id').groups.items():\n",
        "        idxs = np.array(list(grp), dtype=int)\n",
        "        id_to_idx[idv] = idxs\n",
        "    centroids = {}\n",
        "    for idv, idxs in id_to_idx.items():\n",
        "        centroids[idv] = nn.functional.normalize(torch.from_numpy(embs[idxs]).mean(0, keepdims=True), dim=1).numpy()[0].astype(np.float32)\n",
        "    labels = list(centroids.keys())\n",
        "    mat = np.stack([centroids[l] for l in labels], axis=0)\n",
        "    return labels, mat\n",
        "\n",
        "def topk_labels(query_embs, gallery_labels, gallery_centroids, k=5):\n",
        "    sims = query_embs @ gallery_centroids.T\n",
        "    k_eff = min(k, sims.shape[1])\n",
        "    topk_idx = np.argpartition(-sims, kth=k_eff-1, axis=1)[:, :k_eff]\n",
        "    rows = np.arange(sims.shape[0])[:,None]\n",
        "    sorted_order = np.argsort(-sims[rows, topk_idx], axis=1)\n",
        "    topk_idx_sorted = topk_idx[rows, sorted_order]\n",
        "    pred_labels = [[gallery_labels[j] for j in row] for row in topk_idx_sorted]\n",
        "    top_scores = np.take_along_axis(sims, topk_idx_sorted, axis=1)\n",
        "    return pred_labels, top_scores\n",
        "\n",
        "# Build model\n",
        "model = FeatExtractor(MODEL_NAME).to(device).eval()\n",
        "\n",
        "# Extract train embeddings (orig + hflip TTA)\n",
        "train_names = train_df['Image'].tolist()\n",
        "print('Extracting train embeddings ...')\n",
        "order1, emb1 = extract_embeddings(model, 'train', train_names, IMG_SIZE, hflip=False)\n",
        "order_flip, emb_flip = extract_embeddings(model, 'train', train_names, IMG_SIZE, hflip=True)\n",
        "assert order1==order_flip==train_names, 'Embedding order mismatch'\n",
        "train_emb = nn.functional.normalize(torch.from_numpy((emb1 + emb_flip)/2.0), dim=1).numpy().astype(np.float32)\n",
        "del emb1, emb_flip; gc.collect()\n",
        "\n",
        "# CV MAP@5 using centroids from train folds\n",
        "n_splits = int(train_df['fold'].max())+1\n",
        "all_scores = []\n",
        "for fold in range(n_splits):\n",
        "    t_start=time.time()\n",
        "    trn_mask = train_df['fold'] != fold\n",
        "    val_mask = train_df['fold'] == fold\n",
        "    trn_names = train_df.loc[trn_mask, 'Image'].tolist()\n",
        "    val_names = train_df.loc[val_mask, 'Image'].tolist()\n",
        "    trn_ids = train_df.loc[trn_mask, 'Id'].tolist()\n",
        "    val_ids = train_df.loc[val_mask, 'Id'].tolist()\n",
        "    idx_map = {name:i for i,name in enumerate(train_names)}\n",
        "    trn_idx = np.array([idx_map[n] for n in trn_names], dtype=int)\n",
        "    val_idx = np.array([idx_map[n] for n in val_names], dtype=int)\n",
        "    labels, centroids = centroid_by_id(trn_names, train_emb[trn_idx], trn_ids)\n",
        "    preds, scores = topk_labels(train_emb[val_idx], labels, centroids, k=5)\n",
        "    score = mapk(val_ids, preds, k=5)\n",
        "    all_scores.append(score)\n",
        "    print(f'Fold {fold} MAP@5: {score:.4f} elapsed {time.time()-t_start:.1f}s with {len(labels)} gallery IDs')\n",
        "print('OOF MAP@5 (mean):', np.mean(all_scores).round(5))\n",
        "\n",
        "# Extract test embeddings with TTA\n",
        "print('Extracting test embeddings ...')\n",
        "test_names = test_files\n",
        "order_t1, test_emb1 = extract_embeddings(model, 'test', test_names, IMG_SIZE, hflip=False)\n",
        "order_tflip, test_emb_flip = extract_embeddings(model, 'test', test_names, IMG_SIZE, hflip=True)\n",
        "assert order_t1==order_tflip==test_names, 'Test order mismatch'\n",
        "test_emb = nn.functional.normalize(torch.from_numpy((test_emb1 + test_emb_flip)/2.0), dim=1).numpy().astype(np.float32)\n",
        "\n",
        "# Build final gallery centroids from full train\n",
        "labels_all, centroids_all = centroid_by_id(train_names, train_emb, train_df['Id'].tolist())\n",
        "preds_test, scores_test = topk_labels(test_emb, labels_all, centroids_all, k=5)\n",
        "\n",
        "# Optional new_whale thresholding (simple v1): if max score < thr, place 'new_whale' at rank-1\n",
        "thr = 0.70\n",
        "has_new = 'new_whale' in labels_all\n",
        "fallback_label = labels_all[0]\n",
        "final_strs = []\n",
        "for i, labs in enumerate(preds_test):\n",
        "    smax = scores_test[i,0]\n",
        "    out = labs[:5]\n",
        "    if (smax < thr) and has_new and ('new_whale' not in out):\n",
        "        out = ['new_whale'] + out[:4]\n",
        "    # ensure 5 unique labels\n",
        "    seen=set()\n",
        "    uniq=[]\n",
        "    for l in out:\n",
        "        if l not in seen:\n",
        "            uniq.append(l); seen.add(l)\n",
        "        if len(uniq)==5: break\n",
        "    while len(uniq)<5:\n",
        "        if has_new and 'new_whale' not in seen:\n",
        "            uniq.append('new_whale'); seen.add('new_whale')\n",
        "        else:\n",
        "            uniq.append(fallback_label)\n",
        "    final_strs.append(' '.join(uniq))\n",
        "\n",
        "sub = pd.DataFrame({'Image': test_names, 'Id': final_strs})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv; head:\\n', sub.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\nNum train images: 7240 Num IDs: 4029 new_whale in train: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting train embeddings ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_196/2159016266.py:76: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=True):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 0, total 64/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 20, total 1344/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 40, total 2624/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 60, total 3904/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 80, total 5184/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 100, total 6464/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 0, total 64/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 20, total 1344/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 40, total 2624/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 60, total 3904/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 80, total 5184/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 100, total 6464/7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 MAP@5: 0.0815 elapsed 0.2s with 3371 gallery IDs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 MAP@5: 0.0794 elapsed 0.2s with 3385 gallery IDs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 MAP@5: 0.0777 elapsed 0.3s with 3399 gallery IDs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 MAP@5: 0.0822 elapsed 0.3s with 3363 gallery IDs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 MAP@5: 0.0950 elapsed 0.2s with 3395 gallery IDs\nOOF MAP@5 (mean): 0.08314\nExtracting test embeddings ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_196/2159016266.py:76: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=True):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 0, total 64/2610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 20, total 1344/2610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 40, total 2610/2610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 0, total 64/2610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 20, total 1344/2610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed batch 40, total 2610/2610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv; head:\n           Image                                                 Id\n0  00087b01.jpg  w_2957331 w_6e47e0e w_0f54cdf w_9df0865 w_da2efe0\n1  0014cfdf.jpg  w_5982299 w_f3b63ba w_790c2aa w_adffd9c w_9874f0d\n2  0035632e.jpg  w_3d0bc7a w_b729b1f w_4c9d3df w_4659acf w_38e4aae\n3  004c5fb9.jpg  w_1a5e7a2 w_17ee910 w_bb2d34d w_d7de1ee w_f4e0748\n4  00863b8c.jpg  w_e09e886 w_7311fe4 w_2c68b75 w_2db01d5 new_whale\n"
          ]
        }
      ]
    },
    {
      "id": "24eba9ce-eb34-4124-b8d1-50a57aa2d3a5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# FAISS per-image retrieval + temperature voting + new_whale calibration; save embs\n",
        "import numpy as np, pandas as pd, time, faiss, torch, math, gc, random\n",
        "\n",
        "# Sanity: expect train_emb and train_names from previous cell\n",
        "assert 'train_emb' in globals() and 'train_names' in globals(), 'Run cell 4 first to build train embeddings'\n",
        "train_df_full = pd.read_csv('train.csv')\n",
        "folds_df = pd.read_csv('folds.csv')\n",
        "train_df_full = train_df_full.merge(folds_df[['Image','fold']], on='Image', how='left')\n",
        "\n",
        "# Exclude new_whale from gallery always\n",
        "is_new = (train_df_full['Id'] == 'new_whale').values\n",
        "\n",
        "# Cache embeddings for reuse\n",
        "np.save('emb_train_avg_tta.npy', train_emb)\n",
        "pd.Series(train_names).to_csv('emb_train_names.txt', index=False, header=False)\n",
        "print('Saved train embeddings to disk')\n",
        "\n",
        "def softmax_temp(x, T=0.07):\n",
        "    x = x / max(T, 1e-6)\n",
        "    x = x - x.max(axis=1, keepdims=True)\n",
        "    ex = np.exp(x)\n",
        "    return ex / (ex.sum(axis=1, keepdims=True) + 1e-9)\n",
        "\n",
        "def vote_labels(nei_idx, nei_sim, labels, T=0.07, topk=5):\n",
        "    # nei_idx: [N, K], nei_sim: [N, K], labels: list length G\n",
        "    w = softmax_temp(nei_sim, T=T)  # [N,K]\n",
        "    N, K = nei_idx.shape\n",
        "    out = []\n",
        "    out_scores = []\n",
        "    for i in range(N):\n",
        "        agg = {}\n",
        "        for j in range(K):\n",
        "            lab = labels[nei_idx[i, j]]\n",
        "            agg[lab] = agg.get(lab, 0.0) + w[i, j]\n",
        "        # sort by agg desc\n",
        "        items = sorted(agg.items(), key=lambda t: -t[1])[:topk]\n",
        "        out.append([k for k,_ in items])\n",
        "        out_scores.append([v for _,v in items])\n",
        "    return out, out_scores\n",
        "\n",
        "def mapk(truths, preds, k=5):\n",
        "    score=0.0\n",
        "    for t, ps in zip(truths, preds):\n",
        "        for i,p in enumerate(ps[:k]):\n",
        "            if p==t:\n",
        "                score += 1.0/(i+1); break\n",
        "    return score/len(truths)\n",
        "\n",
        "def build_index(emb):\n",
        "    d = emb.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    return index\n",
        "\n",
        "def l2norm(a):\n",
        "    na = np.linalg.norm(a, axis=1, keepdims=True) + 1e-9\n",
        "    return a / na\n",
        "\n",
        "def oof_eval_faiss(train_emb, train_names, train_df, T=0.07, K=50, tune_thr=True, unknown_frac=0.3, seed=42):\n",
        "    rng = random.Random(seed)\n",
        "    n_splits = int(train_df['fold'].max())+1\n",
        "    all_scores = []\n",
        "    best_thrs = []\n",
        "    for fold in range(n_splits):\n",
        "        t0=time.time()\n",
        "        trn_mask = (train_df['fold'] != fold) & (train_df['Id'] != 'new_whale')\n",
        "        val_mask = (train_df['fold'] == fold)\n",
        "        trn_df = train_df[trn_mask].reset_index(drop=True)\n",
        "        val_df = train_df[val_mask].reset_index(drop=True)\n",
        "        idx_map = {name:i for i,name in enumerate(train_names)}\n",
        "        trn_idx = np.array([idx_map[n] for n in trn_df['Image']], dtype=int)\n",
        "        val_idx = np.array([idx_map[n] for n in val_df['Image']], dtype=int)\n",
        "        G = train_emb[trn_idx].astype(np.float32)\n",
        "        Q = train_emb[val_idx].astype(np.float32)\n",
        "        # build labels list and faiss index\n",
        "        gallery_labels = trn_df['Id'].tolist()\n",
        "        G = l2norm(G); Q = l2norm(Q)\n",
        "        index = build_index(G)\n",
        "        index.add(G)\n",
        "        D, I = index.search(Q, min(K, len(G)))  # cosine via IP\n",
        "        # temperature voting\n",
        "        pred_top, pred_scores = vote_labels(I, D, gallery_labels, T=T, topk=5)\n",
        "        # Unknowns calibration: hold out some whole IDs from gallery to simulate new_whale\n",
        "        thr_best = 0.7\n",
        "        if tune_thr:\n",
        "            ids_train = list(set(trn_df['Id'].tolist()))\n",
        "            rng.shuffle(ids_train)\n",
        "            hold_n = max(1, int(len(ids_train)*unknown_frac))\n",
        "            hold_ids = set(ids_train[:hold_n])\n",
        "            # mask held-out IDs in voting by zeroing their votes\n",
        "            held_mask = np.array([1.0 if lab not in hold_ids else 0.0 for lab in gallery_labels], dtype=np.float32)\n",
        "            # recompute per-query label scores with held-out masked\n",
        "            w = softmax_temp(D, T=T)  # [Nv, K]\n",
        "            Nv, Kk = I.shape\n",
        "            tuned_preds = []\n",
        "            tuned_max = []\n",
        "            for i in range(Nv):\n",
        "                agg = {}\n",
        "                mx = 0.0\n",
        "                for j in range(Kk):\n",
        "                    lab = gallery_labels[I[i, j]]\n",
        "                    weight = w[i, j] * (1.0 if lab not in hold_ids else 0.0)\n",
        "                    if weight<=0: continue\n",
        "                    agg[lab] = agg.get(lab, 0.0) + weight\n",
        "                    if agg[lab] > mx: mx = agg[lab]\n",
        "                items = sorted(agg.items(), key=lambda t: -t[1])[:5]\n",
        "                tuned_preds.append([k for k,_ in items])\n",
        "                tuned_max.append(mx)\n",
        "            tuned_max = np.array(tuned_max, dtype=np.float32)\n",
        "            # grid search threshold\n",
        "            truths = val_df['Id'].tolist()\n",
        "            grid = [round(x,2) for x in np.arange(0.60, 0.82, 0.02)]\n",
        "            best_score = -1.0\n",
        "            for thr in grid:\n",
        "                preds_thr = []\n",
        "                for i, labs in enumerate(tuned_preds):\n",
        "                    out = labs[:5]\n",
        "                    if tuned_max[i] < thr:\n",
        "                        out = ['new_whale'] + out[:4]\n",
        "                    # ensure unique and fill with new_whale\n",
        "                    seen=set(); uniq=[]\n",
        "                    for l in out:\n",
        "                        if l not in seen: uniq.append(l); seen.add(l)\n",
        "                        if len(uniq)==5: break\n",
        "                    while len(uniq)<5:\n",
        "                        if 'new_whale' not in seen: uniq.append('new_whale'); seen.add('new_whale')\n",
        "                        else: uniq.append(gallery_labels[0])\n",
        "                    preds_thr.append(uniq)\n",
        "                score = mapk(truths, preds_thr, k=5)\n",
        "                if score > best_score:\n",
        "                    best_score = score; thr_best = thr\n",
        "        # Apply best threshold to original predictions\n",
        "        truths = val_df['Id'].tolist()\n",
        "        preds_final = []\n",
        "        # compute max aggregated weight per query for thresholding\n",
        "        w_all = softmax_temp(D, T=T)\n",
        "        Nv, Kk = I.shape\n",
        "        q_max = np.zeros(Nv, dtype=np.float32)\n",
        "        for i in range(Nv):\n",
        "            agg = {}\n",
        "            mx = 0.0\n",
        "            for j in range(Kk):\n",
        "                lab = gallery_labels[I[i, j]]\n",
        "                agg[lab] = agg.get(lab, 0.0) + w_all[i, j]\n",
        "                if agg[lab] > mx: mx = agg[lab]\n",
        "            out = sorted(agg.items(), key=lambda t: -t[1])[:5]\n",
        "            labs = [k for k,_ in out]\n",
        "            if (mx < thr_best):\n",
        "                labs = ['new_whale'] + labs[:4]\n",
        "            # ensure 5 unique labels\n",
        "            seen=set(); uniq=[]\n",
        "            for l in labs:\n",
        "                if l not in seen: uniq.append(l); seen.add(l)\n",
        "                if len(uniq)==5: break\n",
        "            while len(uniq)<5:\n",
        "                if 'new_whale' not in seen: uniq.append('new_whale'); seen.add('new_whale')\n",
        "                else: uniq.append(gallery_labels[0])\n",
        "            preds_final.append(uniq)\n",
        "        score = mapk(truths, preds_final, k=5)\n",
        "        print(f'[FAISS] Fold {fold} MAP@5: {score:.4f} | best_thr {thr_best:.2f} | T {T} | K {K} | elapsed {time.time()-t0:.1f}s')\n",
        "        all_scores.append(score); best_thrs.append(thr_best)\n",
        "    return float(np.mean(all_scores)), float(np.mean(best_thrs))\n",
        "\n",
        "# Run OOF FAISS eval with voting and threshold tuning\n",
        "mean_oof, avg_thr = oof_eval_faiss(train_emb, train_names, train_df_full, T=0.07, K=50, tune_thr=True, unknown_frac=0.3, seed=42)\n",
        "print('OOF (FAISS) MAP@5 mean:', round(mean_oof,5), 'avg tuned thr:', round(avg_thr,2))\n",
        "\n",
        "# Build final gallery on full train excluding new_whale and generate submission via FAISS voting\n",
        "gallery_mask = (train_df_full['Id'] != 'new_whale')\n",
        "gallery_idx = np.array([i for i,n in enumerate(train_names) if gallery_mask.iloc[i]], dtype=int)\n",
        "G_all = l2norm(train_emb[gallery_idx].astype(np.float32))\n",
        "labels_all = train_df_full.loc[gallery_mask, 'Id'].tolist()\n",
        "index_all = build_index(G_all); index_all.add(G_all)\n",
        "\n",
        "# If test embeddings exist from previous cell, reuse; else, skip to only evaluate OOF\n",
        "if 'test_emb' not in globals():\n",
        "    print('Warning: test_emb not found; run extraction cell 4 for test to write submission.')\n",
        "else:\n",
        "    Q = l2norm(test_emb.astype(np.float32))\n",
        "    K = min(50, len(G_all))\n",
        "    D, I = index_all.search(Q, K)\n",
        "    # aggregate votes\n",
        "    w = softmax_temp(D, T=0.07)\n",
        "    final_preds = []\n",
        "    for i in range(Q.shape[0]):\n",
        "        agg = {}\n",
        "        for j in range(K):\n",
        "            lab = labels_all[I[i, j]]\n",
        "            agg[lab] = agg.get(lab, 0.0) + w[i, j]\n",
        "        items = sorted(agg.items(), key=lambda t: -t[1])[:5]\n",
        "        labs = [k for k,_ in items]\n",
        "        mx = items[0][1] if items else 0.0\n",
        "        if mx < avg_thr:\n",
        "            labs = ['new_whale'] + labs[:4]\n",
        "        seen=set(); uniq=[]\n",
        "        for l in labs:\n",
        "            if l not in seen: uniq.append(l); seen.add(l)\n",
        "            if len(uniq)==5: break\n",
        "        while len(uniq)<5:\n",
        "            if 'new_whale' not in seen: uniq.append('new_whale'); seen.add('new_whale')\n",
        "            else: uniq.append(labels_all[0])\n",
        "        final_preds.append(' '.join(uniq))\n",
        "    sub = pd.DataFrame({'Image': pd.read_csv('sample_submission.csv')['Image'], 'Id': final_preds})\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (FAISS voting)')\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved train embeddings to disk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FAISS] Fold 0 MAP@5: 0.1498 | best_thr 0.72 | T 0.07 | K 50 | elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FAISS] Fold 1 MAP@5: 0.1478 | best_thr 0.60 | T 0.07 | K 50 | elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FAISS] Fold 2 MAP@5: 0.1445 | best_thr 0.60 | T 0.07 | K 50 | elapsed 0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FAISS] Fold 3 MAP@5: 0.1347 | best_thr 0.60 | T 0.07 | K 50 | elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FAISS] Fold 4 MAP@5: 0.1431 | best_thr 0.60 | T 0.07 | K 50 | elapsed 0.7s\nOOF (FAISS) MAP@5 mean: 0.14397 avg tuned thr: 0.62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (FAISS voting)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "id": "3687fab8-35bb-4d2e-b046-95d4fea8c526",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ArcFace metric-learning smoke run (fold 0) with ConvNeXt-Base @384; extract embs + FAISS submission\n",
        "import os, time, math, gc, random, sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageOps\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import timm\n",
        "import faiss\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n",
        "\n",
        "# Config\n",
        "IMG_SIZE = 384\n",
        "MODEL_NAME = 'convnext_base.fb_in22k_ft_in1k'\n",
        "BATCH_SIZE_TR = 32\n",
        "BATCH_SIZE_INF = 96\n",
        "NUM_WORKERS = 6\n",
        "EMB_DIM = 512\n",
        "EPOCHS_WARM = 1   # smoke\n",
        "EPOCHS_FT = 2     # smoke\n",
        "LR_BACKBONE = 2e-4\n",
        "LR_HEAD = 1e-3\n",
        "WD = 5e-2\n",
        "MARGIN = 0.35\n",
        "SCALE = 30.0\n",
        "FOLD_TO_RUN = 0\n",
        "\n",
        "IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
        "IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
        "\n",
        "def read_image_pil(path):\n",
        "    img = Image.open(path)\n",
        "    try:\n",
        "        img = ImageOps.exif_transpose(img)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return img.convert('RGB')\n",
        "\n",
        "class TrainDs(Dataset):\n",
        "    def __init__(self, df, root, size, aug=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.root = Path(root)\n",
        "        self.size = size\n",
        "        self.aug = aug\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        img = read_image_pil(self.root / row.Image)\n",
        "        # RandomResizedCrop-like\n",
        "        if self.aug:\n",
        "            scale = random.uniform(0.9, 1.0)\n",
        "        else:\n",
        "            scale = 1.0\n",
        "        w,h = img.size\n",
        "        nw, nh = int(w*scale), int(h*scale)\n",
        "        img = img.resize((nw, nh), Image.BICUBIC)\n",
        "        # pad to square\n",
        "        pad_w = max(0, self.size - nw); pad_h = max(0, self.size - nh)\n",
        "        pad_left = pad_w//2; pad_right = pad_w - pad_left\n",
        "        pad_top = pad_h//2; pad_bottom = pad_h - pad_top\n",
        "        if pad_w>0 or pad_h>0:\n",
        "            img = ImageOps.expand(img, border=(pad_left,pad_top,pad_right,pad_bottom), fill=(0,0,0))\n",
        "        img = img.resize((self.size, self.size), Image.BICUBIC)\n",
        "        if self.aug and random.random()<0.5:\n",
        "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        if self.aug:\n",
        "            # small rotation\n",
        "            angle = random.uniform(-10,10)\n",
        "            img = img.rotate(angle, resample=Image.BICUBIC, fillcolor=(0,0,0))\n",
        "        x = torch.from_numpy(np.array(img)).permute(2,0,1).float()/255.0\n",
        "        x = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        y = int(row['label'])\n",
        "        return x, y\n",
        "\n",
        "class InferDs(Dataset):\n",
        "    def __init__(self, names, root, size, hflip=False):\n",
        "        self.names = names\n",
        "        self.root = Path(root)\n",
        "        self.size = size\n",
        "        self.hflip = hflip\n",
        "    def __len__(self): return len(self.names)\n",
        "    def __getitem__(self, i):\n",
        "        fn = self.names[i]\n",
        "        img = read_image_pil(self.root / fn)\n",
        "        img = img.resize((self.size,self.size), Image.BICUBIC)\n",
        "        if self.hflip:\n",
        "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        x = torch.from_numpy(np.array(img)).permute(2,0,1).float()/255.0\n",
        "        x = (x - IMAGENET_MEAN) / IMAGENET_STD\n",
        "        return fn, x\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3.0, eps=1e-6):\n",
        "        super().__init__(); self.p = nn.Parameter(torch.ones(1)*p); self.eps=eps\n",
        "    def forward(self, x):\n",
        "        x = torch.clamp(x, min=self.eps).pow(self.p)\n",
        "        x = F.avg_pool2d(x, (x.size(-2), x.size(-1))).pow(1.0/self.p)\n",
        "        return x\n",
        "\n",
        "class Backbone(nn.Module):\n",
        "    def __init__(self, name, emb_dim):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(name, pretrained=True, num_classes=0, global_pool='')\n",
        "        self.pool = GeM()\n",
        "        in_ch = self.backbone.num_features\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(in_ch, emb_dim, bias=False),\n",
        "            nn.BatchNorm1d(emb_dim),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        feat = self.backbone.forward_features(x)\n",
        "        feat = self.pool(feat).view(feat.size(0), -1)\n",
        "        emb = self.head(feat)\n",
        "        emb = F.normalize(emb, p=2, dim=1)\n",
        "        return emb\n",
        "\n",
        "class ArcMarginProduct(nn.Module):\n",
        "    def __init__(self, in_features, out_features, s=30.0, m=0.35, easy_margin=False):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.s = s; self.m = m; self.easy_margin = easy_margin\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        self.cos_m = math.cos(m); self.sin_m = math.sin(m)\n",
        "        self.th = math.cos(math.pi - m); self.mm = math.sin(math.pi - m) * m\n",
        "    def forward(self, input, label):\n",
        "        # input: [B, in_features] L2-normalized; weight normalized\n",
        "        W = F.normalize(self.weight, p=2, dim=1)\n",
        "        cosine = F.linear(input, W)  # [B, C]\n",
        "        sine = torch.sqrt(torch.clamp(1.0 - cosine**2, min=1e-9))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = torch.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = torch.zeros_like(cosine)\n",
        "        one_hot.scatter_(1, label.view(-1,1), 1.0)\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output = output * self.s\n",
        "        return output\n",
        "\n",
        "def build_loaders(train_df, fold, label_map):\n",
        "    trn = train_df[(train_df.fold!=fold) & (train_df.Id!='new_whale')].copy()\n",
        "    val = train_df[(train_df.fold==fold) & (train_df.Id!='new_whale')].copy()\n",
        "    trn['label'] = trn['Id'].map(label_map).astype(int)\n",
        "    val['label'] = val['Id'].map(label_map).astype(int)\n",
        "    # class-balanced sampler\n",
        "    cls_counts = trn['label'].value_counts().to_dict()\n",
        "    weights = trn['label'].map(lambda x: 1.0/cls_counts[x]).values\n",
        "    sampler = WeightedRandomSampler(weights=torch.DoubleTensor(weights), num_samples=len(weights), replacement=True)\n",
        "    ds_tr = TrainDs(trn[['Image','label']], 'train', IMG_SIZE, aug=True)\n",
        "    ds_va = TrainDs(val[['Image','label']], 'train', IMG_SIZE, aug=False)\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE_TR, sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    dl_va = DataLoader(ds_va, batch_size=BATCH_SIZE_INF, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    return dl_tr, dl_va, trn, val\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_features(model, names, root='train', hflip=False):\n",
        "    ds = InferDs(names, root, IMG_SIZE, hflip=hflip)\n",
        "    dl = DataLoader(ds, batch_size=BATCH_SIZE_INF, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    embs = np.zeros((len(names), EMB_DIM), dtype=np.float32)\n",
        "    order = []\n",
        "    seen=0; t0=time.time()\n",
        "    for it,(fns, imgs) in enumerate(dl):\n",
        "        imgs = imgs.to(device, non_blocking=True)\n",
        "        with torch.amp.autocast(device_type='cuda', enabled=True):\n",
        "            e = model(imgs)\n",
        "        e = F.normalize(e, dim=1).float().cpu().numpy()\n",
        "        embs[seen:seen+e.shape[0]] = e\n",
        "        order.extend(fns); seen += e.shape[0]\n",
        "        if it%20==0: print(f'feat {it} {seen}/{len(names)}', flush=True)\n",
        "    return order, embs\n",
        "\n",
        "def l2norm(a):\n",
        "    na = np.linalg.norm(a, axis=1, keepdims=True) + 1e-9\n",
        "    return a / na\n",
        "\n",
        "def softmax_temp(x, T=0.07):\n",
        "    x = x / max(T, 1e-6); x = x - x.max(axis=1, keepdims=True); ex = np.exp(x); return ex/(ex.sum(axis=1, keepdims=True)+1e-9)\n",
        "\n",
        "def vote_labels(nei_idx, nei_sim, labels, T=0.07, topk=5):\n",
        "    w = softmax_temp(nei_sim, T=T); out=[]\n",
        "    for i in range(nei_idx.shape[0]):\n",
        "        agg={}\n",
        "        for j in range(nei_idx.shape[1]):\n",
        "            lab = labels[nei_idx[i,j]]; agg[lab]=agg.get(lab,0.0)+w[i,j]\n",
        "        items = sorted(agg.items(), key=lambda t: -t[1])[:topk]\n",
        "        out.append([k for k,_ in items])\n",
        "    return out\n",
        "\n",
        "# Load data and folds\n",
        "train_df = pd.read_csv('train.csv')\n",
        "folds_df = pd.read_csv('folds.csv')\n",
        "df = train_df.merge(folds_df[['Image','fold']], on='Image', how='left')\n",
        "ids = sorted(df.loc[df.Id!='new_whale','Id'].unique().tolist())\n",
        "label_map = {idv:i for i,idv in enumerate(ids)}\n",
        "n_classes = len(label_map)\n",
        "print('Classes (excluding new_whale):', n_classes)\n",
        "\n",
        "# Build model\n",
        "model = Backbone(MODEL_NAME, EMB_DIM).to(device)\n",
        "margin_head = ArcMarginProduct(EMB_DIM, n_classes, s=SCALE, m=MARGIN).to(device)\n",
        "\n",
        "# Optimizers\n",
        "def param_groups(model):\n",
        "    decay, no_decay = [], []\n",
        "    for n,p in model.named_parameters():\n",
        "        if not p.requires_grad: continue\n",
        "        if p.ndim==1 or n.endswith('bias') or 'bn' in n.lower(): no_decay.append(p)\n",
        "        else: decay.append(p)\n",
        "    return [ {'params': decay, 'weight_decay': WD}, {'params': no_decay, 'weight_decay': 0.0} ]\n",
        "\n",
        "dl_tr, dl_va, trn_sub, val_sub = build_loaders(df, FOLD_TO_RUN, label_map)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
        "\n",
        "def train_one_epoch(epoch, warmup=False):\n",
        "    model.train(); margin_head.train()\n",
        "    if warmup:\n",
        "        for p in model.backbone.parameters(): p.requires_grad=False\n",
        "        opt = torch.optim.AdamW(list(model.head.parameters())+list(margin_head.parameters()), lr=LR_HEAD, weight_decay=WD)\n",
        "    else:\n",
        "        for p in model.backbone.parameters(): p.requires_grad=True\n",
        "        opt = torch.optim.AdamW([{'params': model.parameters(), 'lr': LR_BACKBONE, 'weight_decay': WD},\n",
        "                                {'params': margin_head.parameters(), 'lr': LR_HEAD, 'weight_decay': WD}],\n",
        "                                lr=LR_BACKBONE, weight_decay=WD)\n",
        "    running=0.0; n=0; t0=time.time()\n",
        "    for it,(imgs, labels) in enumerate(dl_tr):\n",
        "        imgs = imgs.to(device, non_blocking=True); labels = labels.to(device, non_blocking=True)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast(device_type='cuda', enabled=True):\n",
        "            emb = model(imgs)\n",
        "            logits = margin_head(emb, labels)\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt); scaler.update()\n",
        "        running += loss.item()*imgs.size(0); n += imgs.size(0)\n",
        "        if it%50==0: print(f'ep{epoch} it{it} loss {running/max(1,n):.4f}', flush=True)\n",
        "    print(f'ep{epoch} done loss {running/max(1,n):.4f} elapsed {time.time()-t0:.1f}s')\n",
        "\n",
        "# Train (smoke)\n",
        "for e in range(EPOCHS_WARM):\n",
        "    train_one_epoch(e, warmup=True)\n",
        "for e in range(EPOCHS_WARM, EPOCHS_WARM+EPOCHS_FT):\n",
        "    train_one_epoch(e, warmup=False)\n",
        "\n",
        "# Save checkpoint\n",
        "ckpt_path = f'ckpt_convnext_base_fold{FOLD_TO_RUN}.pt'\n",
        "torch.save({'model': model.state_dict(), 'head': margin_head.state_dict(), 'label_map': label_map}, ckpt_path)\n",
        "print('Saved', ckpt_path)\n",
        "\n",
        "# Extract train/test embeddings using trained model (orig + hflip)\n",
        "train_names = df['Image'].tolist()\n",
        "order_tr1, tr_e1 = extract_features(model, train_names, root='train', hflip=False)\n",
        "order_tr2, tr_e2 = extract_features(model, train_names, root='train', hflip=True)\n",
        "assert order_tr1==order_tr2==train_names, 'order mismatch'\n",
        "train_emb_ml = l2norm(((tr_e1 + tr_e2)/2.0).astype(np.float32))\n",
        "np.save(f'emb_train_ml_fold{FOLD_TO_RUN}.npy', train_emb_ml)\n",
        "\n",
        "test_names = pd.read_csv('sample_submission.csv')['Image'].tolist()\n",
        "order_te1, te_e1 = extract_features(model, test_names, root='test', hflip=False)\n",
        "order_te2, te_e2 = extract_features(model, test_names, root='test', hflip=True)\n",
        "assert order_te1==order_te2==test_names, 'test order mismatch'\n",
        "test_emb_ml = l2norm(((te_e1 + te_e2)/2.0).astype(np.float32))\n",
        "np.save(f'emb_test_ml_fold{FOLD_TO_RUN}.npy', test_emb_ml)\n",
        "\n",
        "# Build FAISS gallery (exclude new_whale) and predict test with temperature voting\n",
        "gallery_mask = (df['Id']!='new_whale')\n",
        "gallery_labels = df.loc[gallery_mask, 'Id'].tolist()\n",
        "gallery_idx = np.where(gallery_mask.values)[0]\n",
        "G = train_emb_ml[gallery_idx].astype(np.float32)\n",
        "index = faiss.IndexFlatIP(G.shape[1]); index.add(G)\n",
        "K = min(50, len(G))\n",
        "D, I = index.search(test_emb_ml, K)\n",
        "def finalize_preds(D, I, labels_all, thr=0.62, T=0.07):\n",
        "    w = softmax_temp(D, T=T)\n",
        "    out=[]\n",
        "    for i in range(I.shape[0]):\n",
        "        agg={}\n",
        "        for j in range(I.shape[1]):\n",
        "            lab = labels_all[I[i,j]]; agg[lab]=agg.get(lab,0.0)+w[i,j]\n",
        "        items = sorted(agg.items(), key=lambda t: -t[1])[:5]\n",
        "        labs = [k for k,_ in items]\n",
        "        mx = items[0][1] if items else 0.0\n",
        "        if mx < thr: labs = ['new_whale'] + labs[:4]\n",
        "        seen=set(); uniq=[]\n",
        "        for l in labs:\n",
        "            if l not in seen: uniq.append(l); seen.add(l)\n",
        "            if len(uniq)==5: break\n",
        "        while len(uniq)<5:\n",
        "            if 'new_whale' not in seen: uniq.append('new_whale'); seen.add('new_whale')\n",
        "            else: uniq.append(labels_all[0])\n",
        "        out.append(' '.join(uniq))\n",
        "    return out\n",
        "\n",
        "pred_strs = finalize_preds(D, I, gallery_labels, thr=0.62, T=0.07)\n",
        "sub = pd.DataFrame({'Image': test_names, 'Id': pred_strs})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv (ArcFace smoke run)')\n",
        "gc.collect()\n",
        "print('Done.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\nClasses (excluding new_whale): 4028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_196/3018318928.py:222: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep0 it0 loss 19.0334\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}