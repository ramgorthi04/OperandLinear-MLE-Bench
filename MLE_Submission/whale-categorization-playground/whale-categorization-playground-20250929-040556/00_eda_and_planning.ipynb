{
  "cells": [
    {
      "id": "ed8aa0d4-cab1-458c-82c9-a4454edf43e9",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Humpback Whale Identification \u2014 Plan\n",
        "\n",
        "Goal: Win a medal (MAP@5). Build a strong, fast baseline and iterate.\n",
        "\n",
        "Plan v0:\n",
        "- Environment & GPU: Verify GPU access; install torch cu121 stack once.\n",
        "- Data audit: Inspect train.csv, image counts, class distribution (long-tail expected).\n",
        "- CV: Stratified KFold on labels (Id). Fix folds to reuse across runs.\n",
        "- Baseline model: timm pretrained classifier (e.g., tf_efficientnet_b3/b4 or convnext_tiny), CE with label smoothing, mixup/cutmix off initially.\n",
        "- Augmentations: Resize ~384, horizontal flip, light color/geo. Keep simple for baseline.\n",
        "- Training: 5 folds, early stopping by val MAP@5 proxy (Top-5 accuracy).\n",
        "- Inference: TTA light (hflip), average logits across TTA and folds.\n",
        "- Submission: Top-5 labels per image.\n",
        "\n",
        "Next:\n",
        "1) Setup GPU and PyTorch\n",
        "2) Explore data and class distribution\n",
        "3) Implement CV split and minimal training loop\n",
        "4) Baseline train (1 seed), evaluate OOF top-5, generate submission\n",
        "5) Iterate: better backbone, arcface head if time, TTA, ensembling\n",
        "\n",
        "Checkpoints: request expert review after plan, after EDA, after baseline OOF."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "abf88642-0679-4732-9220-cc3c4e573c39",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment and GPU check\n",
        "import os, sys, subprocess, shutil, json, time, platform\n",
        "from pathlib import Path\n",
        "\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True).stdout\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('CWD:', os.getcwd())\n",
        "print('nvidia-smi:')\n",
        "print(run(['bash','-lc','nvidia-smi || true']))\n",
        "\n",
        "print('List top-level files:')\n",
        "for p in Path('.').iterdir():\n",
        "    try:\n",
        "        mtime = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(p.stat().st_mtime))\n",
        "        print(mtime, p)\n",
        "    except Exception as e:\n",
        "        print(p, e)\n",
        "\n",
        "train_dir = Path('train')\n",
        "test_dir = Path('test')\n",
        "print('Train images:', len(list(train_dir.glob('*'))))\n",
        "print('Test images:', len(list(test_dir.glob('*'))))\n",
        "\n",
        "print('Preview CSVs:')\n",
        "for f in ['train.csv','sample_submission.csv']:\n",
        "    if Path(f).exists():\n",
        "        print(f'--- {f} head ---')\n",
        "        print('\\n'.join(Path(f).read_text().splitlines()[:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "e5722b6d-f6c6-4f60-a654-1586ef81955b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install CUDA 12.1 torch stack and deps\n",
        "import os, sys, subprocess, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def pip(*args):\n",
        "    print('>', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Uninstall any preexisting torch stack\n",
        "for pkg in ('torch','torchvision','torchaudio'):\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "\n",
        "# Clean stray site dirs (idempotent)\n",
        "for d in (\n",
        "    '/app/.pip-target/torch',\n",
        "    '/app/.pip-target/torchvision',\n",
        "    '/app/.pip-target/torchaudio',\n",
        "    '/app/.pip-target/torch-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torch-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchvision-0.23.0.dist-info',\n",
        "    '/app/.pip-target/torchvision-0.19.1.dist-info',\n",
        "    '/app/.pip-target/torchaudio-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torchaudio-2.4.1.dist-info',\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d)\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# Install exact cu121 torch stack\n",
        "pip('install',\n",
        "    '--index-url', 'https://download.pytorch.org/whl/cu121',\n",
        "    '--extra-index-url', 'https://pypi.org/simple',\n",
        "    'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1')\n",
        "\n",
        "# Freeze constraints\n",
        "Path('constraints.txt').write_text('torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n')\n",
        "\n",
        "# Non-torch deps (avoid upgrading torch)\n",
        "pip('install', '-c', 'constraints.txt',\n",
        "    'timm==1.0.9',\n",
        "    'albumentations==1.4.8',\n",
        "    'scikit-learn==1.5.2',\n",
        "    'pandas', 'numpy',\n",
        "    'opencv-python-headless==4.10.0.84',\n",
        "    'faiss-cpu==1.8.0.post1',\n",
        "    'matplotlib',\n",
        "    '--upgrade-strategy', 'only-if-needed')\n",
        "\n",
        "# Sanity check\n",
        "import torch\n",
        "print('torch:', torch.__version__, 'built CUDA:', getattr(torch.version, 'cuda', None))\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f'Wrong CUDA build: {torch.version.cuda}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "1b06236f-c47e-4b28-8359-6ec871ecb560",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# EDA and CV fold creation\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "df['image_path'] = df['Image'].apply(lambda x: str(Path('train')/x))\n",
        "\n",
        "# Basic stats\n",
        "n_images = len(df)\n",
        "n_ids = df['Id'].nunique()\n",
        "vc = df['Id'].value_counts()\n",
        "singletons = (vc==1).sum()\n",
        "print(f'Train rows: {n_images}, unique Ids: {n_ids}, singletons: {singletons} ({singletons/n_ids:.1%} of classes)')\n",
        "print('Top 5 classes by count:\\n', vc.head().to_string())\n",
        "print('Bottom 5 classes by count:\\n', vc.tail().to_string())\n",
        "\n",
        "# Create 5-fold KFold (stratified by exact Id is impossible due to many singletons).\n",
        "# Retrieval CV tolerates plain KFold well; ensure shuffle and fixed seed.\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "folds = np.full(n_images, -1, dtype=int)\n",
        "for i, (_, val_idx) in enumerate(kf.split(df)):\n",
        "    folds[val_idx] = i\n",
        "df['fold'] = folds\n",
        "assert (df['fold']>=0).all()\n",
        "df[['Image','Id','fold']].to_csv('folds.csv', index=False)\n",
        "print('Saved folds.csv with shape:', df[['Image','Id','fold']].shape)\n",
        "\n",
        "# Quick sanity: distribution by fold\n",
        "by_fold = df.groupby('fold')['Id'].nunique().rename('unique_ids')\n",
        "rows_by_fold = df['fold'].value_counts().sort_index().rename('rows')\n",
        "print('Rows by fold:\\n', rows_by_fold.to_string())\n",
        "print('Unique Ids by fold:\\n', by_fold.to_string())\n",
        "\n",
        "# Preview\n",
        "print(df.head().to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c38c2155-7d77-4fc9-96a2-db9e6b1795e0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Zero-train retrieval baseline with timm convnext_tiny and FAISS (CPU) + tau tuning\n",
        "import os, time, math, gc, faiss, numpy as np, pandas as pd, torch, timm\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "IM_SIZE = 384\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = min(8, os.cpu_count() or 4)\n",
        "K_RETR = 50  # neighbors to retrieve\n",
        "ALPHA = 15.0  # vote sharpness\n",
        "\n",
        "class ImageDS(Dataset):\n",
        "    def __init__(self, df, root='.', tta_hflip=False):\n",
        "        self.paths = df['image_path'].tolist() if 'image_path' in df.columns else [str(Path(root)/p) for p in df]\n",
        "        self.tta_hflip = tta_hflip\n",
        "        self.transform = T.Compose([\n",
        "            T.Resize((IM_SIZE, IM_SIZE), interpolation=T.InterpolationMode.BICUBIC),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "        ])\n",
        "        self.hflip = T.RandomHorizontalFlip(p=1.0)\n",
        "    def __len__(self): return len(self.paths)\n",
        "    def __getitem__(self, i):\n",
        "        p = self.paths[i]\n",
        "        img = Image.open(p).convert('RGB')\n",
        "        x = self.transform(img)\n",
        "        if self.tta_hflip:\n",
        "            x2 = self.transform(self.hflip(img))\n",
        "            return x, x2, p\n",
        "        return x, p\n",
        "\n",
        "def get_backbone():\n",
        "    # num_classes=0 returns feature extractor with global pooling\n",
        "    model = timm.create_model('convnext_tiny', pretrained=True, num_classes=0, global_pool='avg')\n",
        "    model.eval().to(device)\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_embeddings(df_or_paths, tta_hflip=True):\n",
        "    if isinstance(df_or_paths, pd.DataFrame):\n",
        "        ds = ImageDS(df_or_paths, tta_hflip=tta_hflip)\n",
        "    else:\n",
        "        ds = ImageDS(pd.DataFrame({'image_path': df_or_paths}), tta_hflip=tta_hflip)\n",
        "    dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    model = get_backbone()\n",
        "    embs, paths = [], []\n",
        "    t0 = time.time()\n",
        "    for bi, batch in enumerate(dl):\n",
        "        if tta_hflip:\n",
        "            x, x2, p = batch\n",
        "            x, x2 = x.to(device, non_blocking=True), x2.to(device, non_blocking=True)\n",
        "            e1 = model(x)\n",
        "            e2 = model(x2)\n",
        "            e = (e1 + e2) / 2.0\n",
        "        else:\n",
        "            x, p = batch\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            e = model(x)\n",
        "        e = torch.nn.functional.normalize(e, dim=1).cpu().numpy()\n",
        "        embs.append(e)\n",
        "        paths += list(p)\n",
        "        if (bi+1)%20==0:\n",
        "            print(f'Emb batches {bi+1}, elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "    embs = np.concatenate(embs, axis=0) if len(embs)>0 else np.zeros((0, model.num_features), dtype=np.float32)\n",
        "    return embs.astype('float32'), paths\n",
        "\n",
        "def build_index(embs):\n",
        "    # Cosine similarity via inner product on normalized vectors\n",
        "    index = faiss.IndexFlatIP(embs.shape[1])\n",
        "    index.add(embs)\n",
        "    return index\n",
        "\n",
        "def knn_search(index, query_embs, k):\n",
        "    sims, idx = index.search(query_embs, k)\n",
        "    return sims, idx\n",
        "\n",
        "def map5_score(preds, truths):\n",
        "    # preds: list of list of 5 labels; truths: list of true label\n",
        "    s = 0.0\n",
        "    for p, t in zip(preds, truths):\n",
        "        try:\n",
        "            r = p.index(t) + 1\n",
        "            s += 1.0 / r\n",
        "        except ValueError:\n",
        "            s += 0.0\n",
        "    return s / len(truths)\n",
        "\n",
        "def rank_labels(nei_ids, nei_sims, tau=None):\n",
        "    # nei_ids: [K] labels, nei_sims: [K] similarities\n",
        "    scores = {}\n",
        "    for lab, sim in zip(nei_ids, nei_sims):\n",
        "        scores[lab] = scores.get(lab, 0.0) + math.exp(ALPHA * float(sim))\n",
        "    ranked = sorted(scores.items(), key=lambda x: -x[1])\n",
        "    ordered = [lab for lab,_ in ranked]\n",
        "    # ensure unique labels in top-5\n",
        "    ordered = list(dict.fromkeys(ordered))\n",
        "    # new_whale logic handled outside using tau and max sim\n",
        "    return ordered\n",
        "\n",
        "def oof_tau_tune(train_df, folds_df, all_train_embs, all_train_paths, taus):\n",
        "    # Build path->row mapping\n",
        "    path2id = dict(zip((Path('train')/train_df['Image']).astype(str), train_df['Id']))\n",
        "    path2idx = {p:i for i,p in enumerate(all_train_paths)}\n",
        "    best_tau, best_map5 = None, -1.0\n",
        "    for tau in taus:\n",
        "        preds_all, truths_all = [], []\n",
        "        t0 = time.time()\n",
        "        for f in sorted(folds_df['fold'].unique()):\n",
        "            tr_mask = folds_df['fold'] != f\n",
        "            va_mask = folds_df['fold'] == f\n",
        "            va_imgs = (Path('train')/folds_df.loc[va_mask, 'Image']).astype(str).tolist()\n",
        "            tr_imgs = (Path('train')/folds_df.loc[tr_mask, 'Image']).astype(str).tolist()\n",
        "            tr_idx = np.array([path2idx[p] for p in tr_imgs], dtype=np.int64)\n",
        "            va_idx = np.array([path2idx[p] for p in va_imgs], dtype=np.int64)\n",
        "            gallery = all_train_embs[tr_idx]\n",
        "            queries = all_train_embs[va_idx]\n",
        "            index = build_index(gallery)\n",
        "            sims, idxs = knn_search(index, queries, min(K_RETR, gallery.shape[0]))\n",
        "            for i in range(len(va_imgs)):\n",
        "                nei_idx = idxs[i]\n",
        "                nei_sims = sims[i]\n",
        "                labs = [path2id[tr_imgs[j]] for j in nei_idx]\n",
        "                ordered = rank_labels(labs, nei_sims)\n",
        "                top5 = []\n",
        "                if len(nei_sims)>0 and float(nei_sims[0]) < tau:\n",
        "                    top5.append('new_whale')\n",
        "                for lab in ordered:\n",
        "                    if lab not in top5:\n",
        "                        top5.append(lab)\n",
        "                    if len(top5)==5: break\n",
        "                if len(top5)<5:\n",
        "                    # pad with most common label excluding duplicates (rarely needed)\n",
        "                    top5 += ['new_whale']*(5-len(top5))\n",
        "                preds_all.append(top5)\n",
        "            truths_all += folds_df.loc[va_mask, 'Id'].tolist()\n",
        "        m = map5_score(preds_all, truths_all)\n",
        "        print(f'tau {tau:.3f} OOF MAP@5={m:.5f} in {time.time()-t0:.1f}s', flush=True)\n",
        "        if m > best_map5:\n",
        "            best_map5, best_tau = m, tau\n",
        "    print(f'Best tau {best_tau:.3f} OOF MAP@5={best_map5:.5f}')\n",
        "    return best_tau, best_map5\n",
        "\n",
        "# Pipeline: 1) extract all train embeddings once; 2) tau tune via 5-fold OOF; 3) extract test embeddings; 4) build full gallery and predict; 5) write submission\n",
        "t_start = time.time()\n",
        "train_df = pd.read_csv('train.csv')\n",
        "train_df['image_path'] = (Path('train')/train_df['Image']).astype(str)\n",
        "folds = pd.read_csv('folds.csv')\n",
        "\n",
        "print('Extracting train embeddings...')\n",
        "train_embs, train_paths = extract_embeddings(train_df, tta_hflip=True)\n",
        "print('Train embeddings shape:', train_embs.shape)\n",
        "gc.collect();\n",
        "\n",
        "taus = np.linspace(0.35, 0.65, 13)\n",
        "best_tau, best_map5 = oof_tau_tune(train_df, folds, train_embs, train_paths, taus)\n",
        "\n",
        "print('Extracting test embeddings...')\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "test_df = pd.DataFrame({'Image': ss['Image']})\n",
        "test_df['image_path'] = (Path('test')/test_df['Image']).astype(str)\n",
        "test_embs, test_paths = extract_embeddings(test_df, tta_hflip=True)\n",
        "print('Test embeddings shape:', test_embs.shape)\n",
        "\n",
        "# Build full gallery on all train\n",
        "index_full = build_index(train_embs)\n",
        "path2id_full = dict(zip(train_paths, train_df['Id']))\n",
        "\n",
        "print('Retrieving for test...')\n",
        "sims, idxs = knn_search(index_full, test_embs, min(K_RETR, train_embs.shape[0]))\n",
        "pred_rows = []\n",
        "for i in range(len(test_paths)):\n",
        "    nei_idx = idxs[i]\n",
        "    nei_sims = sims[i]\n",
        "    labs = [path2id_full[train_paths[j]] for j in nei_idx]\n",
        "    ordered = rank_labels(labs, nei_sims)\n",
        "    top5 = []\n",
        "    if len(nei_sims)>0 and float(nei_sims[0]) < best_tau:\n",
        "        top5.append('new_whale')\n",
        "    for lab in ordered:\n",
        "        if lab not in top5:\n",
        "            top5.append(lab)\n",
        "        if len(top5)==5: break\n",
        "    if len(top5)<5:\n",
        "        top5 += ['new_whale']*(5-len(top5))\n",
        "    pred_rows.append(' '.join(top5[:5]))\n",
        "\n",
        "sub = pd.DataFrame({'Image': ss['Image'], 'Id': pred_rows})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv with shape', sub.shape, 'Elapsed', f'{time.time()-t_start:.1f}s')\n",
        "\n",
        "# Show head\n",
        "print(sub.head().to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "fb246b9a-cece-46ce-96a4-df4b0ccd36f0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Rebuild folds with perceptual duplicate grouping (aHash) + GroupKFold\n",
        "import numpy as np, pandas as pd, os, time\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def ahash_image(path, size=8):\n",
        "    try:\n",
        "        img = Image.open(path).convert('L').resize((size, size), Image.BILINEAR)\n",
        "        arr = np.asarray(img, dtype=np.float32)\n",
        "        m = arr.mean()\n",
        "        bits = (arr > m).astype(np.uint8)\n",
        "        # pack to 64-bit integer\n",
        "        val = 0\n",
        "        for b in bits.flatten():\n",
        "            val = (val << 1) | int(b)\n",
        "        return val\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "t0 = time.time()\n",
        "df = pd.read_csv('train.csv')\n",
        "df['image_path'] = (Path('train')/df['Image']).astype(str)\n",
        "hashes = []\n",
        "for i, p in enumerate(df['image_path'].tolist()):\n",
        "    h = ahash_image(p)\n",
        "    hashes.append(h)\n",
        "    if (i+1)%1000==0:\n",
        "        print(f'Hashed {i+1}/{len(df)} images...')\n",
        "df['ahash'] = hashes\n",
        "\n",
        "# Group by exact hash (fast). This catches exact/near-duplicates under aHash;\n",
        "# we avoid O(N^2) hamming search for now due to time. Can refine later if needed.\n",
        "df['dup_group'] = pd.factorize(df['ahash'].fillna(-1))[0]\n",
        "print('Unique dup groups:', df['dup_group'].nunique())\n",
        "\n",
        "# Build GroupKFold on dup_group; ensure balanced rows across folds\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "folds = np.full(len(df), -1, dtype=int)\n",
        "for k, (_, va_idx) in enumerate(gkf.split(df, groups=df['dup_group'])):\n",
        "    folds[va_idx] = k\n",
        "df['fold'] = folds\n",
        "assert (df['fold']>=0).all()\n",
        "df[['Image','Id','fold','dup_group','ahash']].to_csv('folds_grouped.csv', index=False)\n",
        "print('Saved folds_grouped.csv:', df.shape, 'elapsed', f'{time.time()-t0:.1f}s')\n",
        "print(df.head().to_string(index=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "74370ee9-b567-44b2-aa6a-c42c4f1c7bca",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ArcFace training: ConvNeXt-Tiny -> GeM -> BNNeck(512) -> ArcFace; PK sampler; 5-fold full training with EMA\n",
        "import os, math, time, gc, random, numpy as np, pandas as pd, faiss, torch, timm\n",
        "import torchvision.transforms as T\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageOps\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, Sampler\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from timm.utils import ModelEmaV2\n",
        "\n",
        "# Reduce fragmentation risk\n",
        "os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "IMG_SIZE = 384\n",
        "P_CLASSES = 24\n",
        "K_IMGS = 2\n",
        "# Use accumulation to keep VRAM safe while achieving effective batch 48\n",
        "BATCH_SIZE = P_CLASSES * K_IMGS // 2  # physical batch 24\n",
        "ACCUM_STEPS = 2  # effective batch = BATCH_SIZE * ACCUM_STEPS\n",
        "EPOCHS = 13\n",
        "NUM_WORKERS = min(8, os.cpu_count() or 4)\n",
        "HEAD_LR = 3e-3\n",
        "BB_LR = 2e-4\n",
        "WD = 0.05\n",
        "SCALE_S = 32.0\n",
        "MARGIN_M = 0.30\n",
        "WARMUP_EPOCHS = 1.0\n",
        "K_RETR = 100\n",
        "ALPHA = 20.0\n",
        "SEED = 42\n",
        "USE_BNNECK_FOR_RETR = False  # epochs 0-1 use GeM; switch to BNNeck from epoch>=2\n",
        "torch.backends.cudnn.benchmark = True\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED);\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "def get_transforms():\n",
        "    train_tf = T.Compose([\n",
        "        T.RandomResizedCrop(IMG_SIZE, scale=(0.6, 1.0), interpolation=T.InterpolationMode.BICUBIC),\n",
        "        T.RandomHorizontalFlip(p=0.5),\n",
        "        T.RandomGrayscale(p=0.1),\n",
        "        T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
        "        T.RandomAffine(degrees=10, translate=(0.08,0.08), scale=(0.9,1.1)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        T.RandomErasing(p=0.22, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0.0),\n",
        "    ])\n",
        "    val_tf = T.Compose([\n",
        "        T.Resize((IMG_SIZE, IMG_SIZE), interpolation=T.InterpolationMode.BICUBIC),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ])\n",
        "    return train_tf, val_tf\n",
        "\n",
        "class WhalesDS(Dataset):\n",
        "    def __init__(self, df, label2idx=None, mode='train', tta_hflip=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.mode = mode\n",
        "        self.tta_hflip = tta_hflip\n",
        "        self.train_tf, self.val_tf = get_transforms()\n",
        "        self.tf = self.train_tf if mode=='train' else self.val_tf\n",
        "        self.label2idx = label2idx\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        img = Image.open(str(row.image_path)).convert('RGB')\n",
        "        x = self.tf(img)\n",
        "        if self.mode != 'train' and self.tta_hflip:\n",
        "            x2 = self.val_tf(ImageOps.mirror(img))\n",
        "        if self.mode=='train':\n",
        "            y = self.label2idx[row.Id]\n",
        "            return x, y\n",
        "        else:\n",
        "            if self.tta_hflip:\n",
        "                return x, x2, row.image_path, row.Id\n",
        "            return x, row.image_path, row.Id\n",
        "\n",
        "class PKSampler(Sampler):\n",
        "    def __init__(self, df, label2idx, p=P_CLASSES, k=K_IMGS):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.p, self.k = p, k\n",
        "        self.label2idx = label2idx\n",
        "        self.cls2idxs = {}\n",
        "        for i, lab in enumerate(self.df['Id']):\n",
        "            self.cls2idxs.setdefault(lab, []).append(i)\n",
        "        self.multi_classes = [c for c, idxs in self.cls2idxs.items() if len(idxs) >= 2]\n",
        "        self.single_classes = [c for c, idxs in self.cls2idxs.items() if len(idxs) == 1]\n",
        "        self.all_classes = list(self.cls2idxs.keys())\n",
        "        self.n_batches = math.ceil(len(self.df) / (p*k))\n",
        "        self.rng = random.Random(SEED)\n",
        "    def __len__(self): return self.n_batches * self.p * self.k\n",
        "    def __iter__(self):\n",
        "        rng = self.rng\n",
        "        for _ in range(self.n_batches):\n",
        "            # 60-70% multi-instance, rest fill (may include singles) with no duplicates\n",
        "            chosen = set()\n",
        "            p_multi = min(len(self.multi_classes), max(0, int(self.p * 0.65)))\n",
        "            if p_multi > 0:\n",
        "                chosen.update(rng.sample(self.multi_classes, p_multi))\n",
        "            pool = [c for c in self.all_classes if c not in chosen]\n",
        "            need = self.p - len(chosen)\n",
        "            if need > 0:\n",
        "                take = min(len(pool), need)\n",
        "                if take > 0:\n",
        "                    chosen.update(rng.sample(pool, take))\n",
        "            while len(chosen) < self.p:\n",
        "                pool = [c for c in self.all_classes if c not in chosen]\n",
        "                if not pool: break\n",
        "                chosen.add(rng.choice(pool))\n",
        "            chosen = list(chosen)\n",
        "            batch_idxs = []\n",
        "            for c in chosen:\n",
        "                idxs = self.cls2idxs[c]\n",
        "                if len(idxs) >= self.k:\n",
        "                    sel = rng.sample(idxs, self.k)\n",
        "                else:\n",
        "                    sel = [rng.choice(idxs) for _ in range(self.k)]\n",
        "                batch_idxs.extend(sel)\n",
        "            yield from batch_idxs\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3.0, eps=1e-6):\n",
        "        super().__init__(); self.p = nn.Parameter(torch.ones(1)*p); self.eps = eps\n",
        "    def forward(self, x):\n",
        "        x = x.clamp(min=self.eps).pow(self.p)\n",
        "        x = torch.mean(x, dim=(-1,-2)).pow(1.0/self.p)\n",
        "        return x\n",
        "\n",
        "class ArcMarginProduct(nn.Module):\n",
        "    def __init__(self, in_features, out_features, s=SCALE_S, m=MARGIN_M):\n",
        "        super().__init__(); self.in_features=in_features; self.out_features=out_features\n",
        "        self.s = s; self.m = m\n",
        "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "    def forward(self, x, labels, margin_override=None):\n",
        "        m = self.m if margin_override is None else margin_override\n",
        "        x = nn.functional.normalize(x, dim=1)\n",
        "        W = nn.functional.normalize(self.weight, dim=1)\n",
        "        cosine = nn.functional.linear(x, W)\n",
        "        cosine = cosine.clamp(-1+1e-7, 1-1e-7)  # clamp for numerical safety\n",
        "        sine = torch.sqrt((1.0 - cosine**2).clamp(0,1))\n",
        "        cos_m = math.cos(m); sin_m = math.sin(m); th = math.cos(math.pi - m); mm = math.sin(math.pi - m) * m\n",
        "        phi = cosine * cos_m - sine * sin_m\n",
        "        phi = torch.where(cosine > th, phi, cosine - mm)\n",
        "        one_hot = torch.zeros_like(cosine); one_hot.scatter_(1, labels.view(-1,1), 1.0)\n",
        "        logits = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        logits *= self.s\n",
        "        return logits\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model('convnext_tiny', pretrained=True, num_classes=0, global_pool='')\n",
        "        in_ch = self.backbone.num_features\n",
        "        self.gem = GeM(p=3.0)\n",
        "        self.emb = nn.Linear(in_ch, 512, bias=False)\n",
        "        self.bnneck = nn.BatchNorm1d(512, eps=1e-5, momentum=0.1)\n",
        "        self.arc = ArcMarginProduct(512, n_classes, s=SCALE_S, m=MARGIN_M)\n",
        "    def forward(self, x, labels=None, margin_override=None):\n",
        "        feat = self.backbone.forward_features(x)\n",
        "        feat = self.gem(feat)\n",
        "        feat_512 = self.emb(feat)\n",
        "        logits = self.arc(feat_512, labels, margin_override=margin_override) if labels is not None else None\n",
        "        feat_bn = self.bnneck(feat_512)\n",
        "        return logits, feat_512, feat_bn\n",
        "\n",
        "def model_feats(model, x, use_bnneck: bool):\n",
        "    with torch.no_grad():\n",
        "        feat = model.backbone.forward_features(x)\n",
        "        feat = model.gem(feat)\n",
        "        if use_bnneck:\n",
        "            f512 = model.emb(feat)\n",
        "            fbn = model.bnneck(f512)\n",
        "            return nn.functional.normalize(fbn, dim=1)\n",
        "        else:\n",
        "            return nn.functional.normalize(feat, dim=1)\n",
        "\n",
        "def build_label_mapping(df):\n",
        "    labs = sorted([x for x in df['Id'].unique().tolist() if x != 'new_whale'])\n",
        "    return {l:i for i,l in enumerate(labs)}\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_feats(model, df, tta_hflip=True):\n",
        "    ds = WhalesDS(df, mode='val', tta_hflip=tta_hflip)\n",
        "    dl = DataLoader(ds, batch_size=64, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    all_feats, paths, labels = [], [], []\n",
        "    t0=time.time()\n",
        "    for bi, batch in enumerate(dl):\n",
        "        if tta_hflip:\n",
        "            x, x2, p, y = batch\n",
        "            x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            x2 = x2.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            f1 = model_feats(model, x, USE_BNNECK_FOR_RETR)\n",
        "            f2 = model_feats(model, x2, USE_BNNECK_FOR_RETR)\n",
        "            f = (f1 + f2) / 2.0\n",
        "        else:\n",
        "            x, p, y = batch\n",
        "            x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            f = model_feats(model, x, USE_BNNECK_FOR_RETR)\n",
        "        all_feats.append(f.cpu().numpy()); paths += list(p); labels += list(y)\n",
        "        if (bi+1)%20==0: print(f'FE bi {bi+1}, {time.time()-t0:.1f}s', flush=True)\n",
        "    if len(all_feats)>0:\n",
        "        feats = np.concatenate(all_feats, axis=0)\n",
        "    else:\n",
        "        dim = int(model.emb.out_features) if USE_BNNECK_FOR_RETR else int(model.backbone.num_features)\n",
        "        feats = np.zeros((0, dim), dtype=np.float32)\n",
        "    return feats.astype('float32'), paths, labels\n",
        "\n",
        "def build_index(embs):\n",
        "    index = faiss.IndexFlatIP(embs.shape[1])\n",
        "    index.add(embs)\n",
        "    return index\n",
        "\n",
        "def vote_rank(nei_ids, nei_sims):\n",
        "    scores = {}; \n",
        "    for lab, sim in zip(nei_ids, nei_sims):\n",
        "        scores[lab] = scores.get(lab, 0.0) + math.exp(ALPHA * float(sim))\n",
        "    ordered = [k for k,_ in sorted(scores.items(), key=lambda x:-x[1])]\n",
        "    return ordered\n",
        "\n",
        "def map5(preds, truths):\n",
        "    s=0.0\n",
        "    for p,t in zip(preds, truths):\n",
        "        try: s+=1.0/(p.index(t)+1)\n",
        "        except ValueError: s+=0.0\n",
        "    return s/len(truths)\n",
        "\n",
        "def oof_eval(model, df_gallery, df_val_fold, taus, ambiguity_gate=True):\n",
        "    tr_feats, tr_paths, tr_ids = extract_feats(model, df_gallery, tta_hflip=True)\n",
        "    va_feats, va_paths, va_ids = extract_feats(model, df_val_fold, tta_hflip=True)\n",
        "    tr_ids_map = dict(zip(tr_paths, tr_ids))\n",
        "    index = build_index(tr_feats)\n",
        "    sims, idxs = index.search(va_feats, min(K_RETR, tr_feats.shape[0]))\n",
        "    try:\n",
        "        max_sims = sims[:,0] if sims.size>0 else np.array([], dtype=np.float32)\n",
        "        q25, q50, q75 = (np.quantile(max_sims, 0.25), np.quantile(max_sims, 0.50), np.quantile(max_sims, 0.75)) if len(max_sims)>0 else (0,0,0)\n",
        "        gal_labels = set(tr_ids)\n",
        "        va_in_gal = sum(1 for v in va_ids if v in gal_labels)\n",
        "        print(f'[OOF] top1 sim q25/q50/q75: {q25:.3f}/{q50:.3f}/{q75:.3f} | val covered in gallery: {va_in_gal}/{len(va_ids)} ({(va_in_gal/len(va_ids))*100:.1f}%)', flush=True)\n",
        "    except Exception as e:\n",
        "        print('[OOF] diag error:', e, flush=True)\n",
        "    gal_labels_set = set(tr_ids)\n",
        "    va_ids_eval = [vid if vid in gal_labels_set else 'new_whale' for vid in va_ids]\n",
        "    best_tau, best_score = None, -1.0\n",
        "    for tau in taus:\n",
        "        preds=[]\n",
        "        for i in range(len(va_paths)):\n",
        "            nei_idx = idxs[i]; nei_sims = sims[i]\n",
        "            labs = [tr_ids_map[tr_paths[j]] for j in nei_idx]\n",
        "            ordered = vote_rank(labs, nei_sims)\n",
        "            top5=[]\n",
        "            s1 = float(nei_sims[0]) if len(nei_sims)>0 else -1.0\n",
        "            s2 = float(nei_sims[1]) if len(nei_sims)>1 else s1\n",
        "            cond_tau = (len(nei_sims)>0 and s1 < tau)\n",
        "            cond_margin = (len(nei_sims)>1 and (s1 - s2) < 0.03)\n",
        "            cond_ratio = (len(nei_sims)>1 and (s1 / max(s2, 1e-6)) < 1.06)\n",
        "            if cond_tau or (ambiguity_gate and (cond_margin or cond_ratio)):\n",
        "                top5.append('new_whale')\n",
        "            for lab in ordered:\n",
        "                if lab not in top5:\n",
        "                    top5.append(lab)\n",
        "                if len(top5)==5: break\n",
        "            if len(top5)<5: top5 += ['new_whale']*(5-len(top5))\n",
        "            preds.append(top5)\n",
        "        sc = map5(preds, va_ids_eval)\n",
        "        if sc>best_score: best_score, best_tau = sc, tau\n",
        "    return best_score, best_tau\n",
        "\n",
        "def train_fold(df_tr_train, df_gallery, df_va, fold_idx):\n",
        "    global USE_BNNECK_FOR_RETR\n",
        "    label2idx = build_label_mapping(df_tr_train)\n",
        "    n_classes = len(label2idx)\n",
        "    print(f'[Fold {fold_idx}] classes (excl new_whale):', n_classes, 'rows:', len(df_tr_train))\n",
        "    ds_tr = WhalesDS(df_tr_train, label2idx=label2idx, mode='train')\n",
        "    sampler = PKSampler(df_tr_train, label2idx, p=P_CLASSES, k=K_IMGS)\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    model = Net(n_classes).to(device)\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    # EMA\n",
        "    ema_model = ModelEmaV2(model, decay=0.999)\n",
        "    try:\n",
        "        if hasattr(model.backbone, 'set_grad_checkpointing'):\n",
        "            model.backbone.set_grad_checkpointing(True)\n",
        "            print('[Fold', fold_idx, '] Grad checkpointing: ON', flush=True)\n",
        "    except Exception as e:\n",
        "        print('[Fold', fold_idx, '] Grad checkpointing not set:', e, flush=True)\n",
        "    bb_params = []; head_params = []\n",
        "    for n,p in model.named_parameters():\n",
        "        if any(k in n for k in ['\\u200bemb','emb','bnneck','arc']): head_params.append(p)\n",
        "        else: bb_params.append(p)\n",
        "    optim = torch.optim.AdamW([{'params': bb_params, 'lr': BB_LR}, {'params': head_params, 'lr': HEAD_LR}], weight_decay=WD)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=max(1,EPOCHS-1))\n",
        "    scaler = GradScaler(enabled=True)\n",
        "    best_oof, best_tau = -1.0, 0.7\n",
        "    best_path = f'model_fold{fold_idx}_best.pth'\n",
        "    for epoch in range(EPOCHS):\n",
        "        USE_BNNECK_FOR_RETR = (epoch >= 2)\n",
        "        taus = np.arange(0.93, 0.99, 0.005) if not USE_BNNECK_FOR_RETR else np.arange(0.68, 0.84, 0.01)\n",
        "        torch.cuda.empty_cache()\n",
        "        if epoch == 0:\n",
        "            for i, g in enumerate(optim.param_groups):\n",
        "                if i == 0: g['lr'] = 0.0\n",
        "                else: g['lr'] = HEAD_LR\n",
        "        else:\n",
        "            for i, g in enumerate(optim.param_groups):\n",
        "                if i == 0: g['lr'] = BB_LR\n",
        "                else: g['lr'] = g['lr']\n",
        "        model.train()\n",
        "        t0=time.time(); run_loss=0.0; n_batches=0\n",
        "        steps_per_epoch = max(1, len(sampler)//BATCH_SIZE)\n",
        "        optim.zero_grad(set_to_none=True)\n",
        "        for bi, (x,y) in enumerate(dl_tr):\n",
        "            x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last); y = torch.as_tensor(y, dtype=torch.long, device=device)\n",
        "            progress = min(1.0, (bi+1)/max(1, steps_per_epoch)/max(1e-6, WARMUP_EPOCHS))\n",
        "            m_cur = MARGIN_M * progress\n",
        "            with autocast(enabled=(device.type=='cuda')):\n",
        "                logits, _, _ = model(x, labels=y, margin_override=m_cur)\n",
        "                loss = nn.functional.cross_entropy(logits, y) / ACCUM_STEPS\n",
        "            scaler.scale(loss).backward()\n",
        "            if ((bi+1) % ACCUM_STEPS) == 0:\n",
        "                scaler.unscale_(optim)\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                scaler.step(optim)\n",
        "                scaler.update()\n",
        "                optim.zero_grad(set_to_none=True)\n",
        "                # EMA update\n",
        "                ema_model.update(model)\n",
        "            run_loss += loss.item()*ACCUM_STEPS; n_batches += 1\n",
        "            if (bi+1) % 100 == 0:\n",
        "                print(f'[Fold {fold_idx}] Ep{epoch+1} B{bi+1} loss {run_loss/n_batches:.4f} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "        if ((bi+1) % ACCUM_STEPS) != 0:\n",
        "            scaler.unscale_(optim)\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optim)\n",
        "            scaler.update()\n",
        "            optim.zero_grad(set_to_none=True)\n",
        "            ema_model.update(model)\n",
        "        print(f'[Fold {fold_idx}] Ep{epoch+1} train_loss {run_loss/max(1,n_batches):.4f} epoch_time {time.time()-t0:.1f}s | retr_feats={\"BNNeck\" if USE_BNNECK_FOR_RETR else \"GeM\"} tau_range=({taus[0]:.2f}-{taus[-1]:.2f})')\n",
        "        if epoch >= 1:\n",
        "            scheduler.step()\n",
        "        # Evaluate with EMA weights\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            oof_sc, oof_tau = oof_eval(ema_model.module, df_gallery[['Image','Id','image_path']], df_va[['Image','Id','image_path']], taus, ambiguity_gate=True)\n",
        "        print(f'[Fold {fold_idx}] Ep{epoch+1} OOF MAP@5={oof_sc:.4f} tau={oof_tau:.3f} (feats={\"BNNeck\" if USE_BNNECK_FOR_RETR else \"GeM\"})')\n",
        "        if oof_sc > best_oof:\n",
        "            best_oof, best_tau = oof_sc, oof_tau\n",
        "            torch.save({'model': ema_model.module.state_dict(), 'best_oof': best_oof, 'best_tau': best_tau, 'epoch': epoch+1}, best_path)\n",
        "            print(f'[Fold {fold_idx}] Saved new best to {best_path}')\n",
        "    return best_oof, best_tau, best_path\n",
        "\n",
        "# Prepare grouped folds and dataframes\n",
        "folds = pd.read_csv('folds_grouped.csv')\n",
        "folds['image_path'] = (Path('train')/folds['Image']).astype(str)\n",
        "\n",
        "# 5-fold full training on all non-new_whale classes; gallery = full train fold excl new_whale\n",
        "all_folds = [0,1,2,3,4]\n",
        "oof_scores = []; taus_best = []; ckpts = []\n",
        "t_all = time.time()\n",
        "for f in all_folds:\n",
        "    tr_df = folds[folds['fold'] != f].copy()\n",
        "    va_df = folds[folds['fold'] == f].copy()\n",
        "    gallery_df = tr_df[tr_df['Id']!='new_whale'].copy()\n",
        "    # Train on ALL non-new_whale (include singletons) per expert advice\n",
        "    tr_df_train = gallery_df.copy()\n",
        "    print(f'[Fold {f}] training rows (all non-new_whale):', len(tr_df_train), 'classes:', tr_df_train['Id'].nunique())\n",
        "    sc, tau, ckpt = train_fold(tr_df_train, gallery_df, va_df, f)\n",
        "    oof_scores.append(sc); taus_best.append(tau); ckpts.append(ckpt)\n",
        "    gc.collect()\n",
        "print('5-fold OOF MAP@5 mean:', float(np.mean(oof_scores)))\n",
        "print('per-fold taus:', taus_best)\n",
        "print('checkpoints:', ckpts)\n",
        "print('Elapsed total', time.time()-t_all)\n",
        "\n",
        "print('Training complete. Next: extract train/test BNNeck embeddings with EMA weights, build ID prototypes, tune global tau (median of per-fold), and generate submission.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "d010ba2c-4fbd-4d84-8f9a-08c7ad0a98bd",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fix albumentations/albucore version mismatch\n",
        "import sys, subprocess\n",
        "def pip(*args):\n",
        "    print('>', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Align versions to resolve ImportError: preserve_channel_dim\n",
        "pip('install', '-c', 'constraints.txt', '--upgrade', 'albumentations==1.4.11', 'albucore==0.0.13', '--upgrade-strategy', 'only-if-needed')\n",
        "\n",
        "import albumentations as A\n",
        "import albucore\n",
        "print('albumentations:', A.__version__)\n",
        "import inspect\n",
        "from albucore import utils as ac_utils\n",
        "print('albucore:', getattr(albucore, '__version__', 'unknown'))\n",
        "print('has preserve_channel_dim:', hasattr(ac_utils, 'preserve_channel_dim'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "09147d81-42e7-4933-bc38-de5823354566",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Micro-overfit sanity: train on ~20 multi-instance classes to validate loop\n",
        "import pandas as pd, numpy as np, torch, time, gc\n",
        "from pathlib import Path\n",
        "from torch import nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "def build_subset(df_all, min_imgs=5, n_classes=20):\n",
        "    dfmi = df_all[df_all['Id']!='new_whale'].copy()\n",
        "    vc = dfmi['Id'].value_counts()\n",
        "    keep_ids = vc[vc>=min_imgs].index.tolist()[:n_classes]\n",
        "    sub = dfmi[dfmi['Id'].isin(keep_ids)].copy().reset_index(drop=True)\n",
        "    return sub\n",
        "\n",
        "def split_train_val(df_sub, val_frac=0.2, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    train_idx = []\n",
        "    val_idx = []\n",
        "    for gid, g in df_sub.groupby('Id'):\n",
        "        idx = g.index.to_numpy()\n",
        "        rng.shuffle(idx)\n",
        "        n_val = max(1, int(len(idx)*val_frac))\n",
        "        val_idx.extend(idx[:n_val].tolist())\n",
        "        train_idx.extend(idx[n_val:].tolist())\n",
        "    tr = df_sub.loc[sorted(train_idx)].reset_index(drop=True)\n",
        "    va = df_sub.loc[sorted(val_idx)].reset_index(drop=True)\n",
        "    return tr, va\n",
        "\n",
        "def build_label_mapping_local(df):\n",
        "    labs = sorted(df['Id'].unique().tolist())\n",
        "    return {l:i for i,l in enumerate(labs)}\n",
        "\n",
        "def micro_overfit_run(img_size=384, p=10, k=4, epochs=5, head_lr=3e-3, bb_lr=0.0, wd=0.05, m_max=0.30):\n",
        "    global IMG_SIZE\n",
        "    IMG_SIZE = img_size\n",
        "    folds = pd.read_csv('folds_grouped.csv')\n",
        "    folds['image_path'] = (Path('train')/folds['Image']).astype(str)\n",
        "    sub = build_subset(folds, min_imgs=5, n_classes=20)\n",
        "    tr, va = split_train_val(sub, val_frac=0.2, seed=42)\n",
        "    print('Subset shapes:', sub.shape, 'train:', tr.shape, 'val:', va.shape)\n",
        "    label2idx = build_label_mapping_local(tr)\n",
        "    ds_tr = WhalesDS(tr, label2idx=label2idx, mode='train')\n",
        "    sampler = PKSampler(tr, label2idx, p=p, k=k)\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=p*k, sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    model = Net(n_classes=len(label2idx)).to(device)\n",
        "    # Freeze backbone if bb_lr==0\n",
        "    bb_params = []; head_params = []\n",
        "    for n, param in model.named_parameters():\n",
        "        if any(t in n for t in ['emb','bnneck','arc']):\n",
        "            head_params.append(param)\n",
        "        else:\n",
        "            if bb_lr==0.0:\n",
        "                param.requires_grad = False\n",
        "            bb_params.append(param)\n",
        "    optim = torch.optim.AdamW([{'params': [p for p in bb_params if p.requires_grad], 'lr': bb_lr}, {'params': head_params, 'lr': head_lr}], weight_decay=wd)\n",
        "    scaler = GradScaler(enabled=True)\n",
        "    taus = np.arange(0.60, 0.86, 0.02)\n",
        "    best_sc=-1.0; best_tau=0.7\n",
        "    for ep in range(epochs):\n",
        "        model.train(); t0=time.time(); run_loss=0.0; nb=0\n",
        "        steps_per_epoch = max(1, len(sampler)//(p*k))\n",
        "        for bi, (x,y) in enumerate(dl_tr):\n",
        "            x = x.to(device, non_blocking=True); y = torch.as_tensor(y, dtype=torch.long, device=device)\n",
        "            progress = min(1.0, (bi+1)/max(1, steps_per_epoch)/max(1e-6, WARMUP_EPOCHS))\n",
        "            m_cur = m_max * progress\n",
        "            optim.zero_grad(set_to_none=True)\n",
        "            with autocast(enabled=(device.type=='cuda')):\n",
        "                logits, _, _ = model(x, labels=y, margin_override=m_cur)\n",
        "                loss = nn.functional.cross_entropy(logits, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optim)\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optim); scaler.update()\n",
        "            run_loss += loss.item(); nb+=1\n",
        "            if (bi+1)%50==0:\n",
        "                print(f'[Micro] Ep{ep+1} B{bi+1} loss {run_loss/nb:.4f} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "        print(f'[Micro] Ep{ep+1} train_loss {run_loss/max(1,nb):.4f} time {time.time()-t0:.1f}s')\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            sc, tau = oof_eval(model, tr[['Image','Id','image_path']], va[['Image','Id','image_path']], taus)\n",
        "        print(f'[Micro] Ep{ep+1} OOF MAP@5={sc:.4f} tau={tau:.3f}')\n",
        "        if sc>best_sc: best_sc, best_tau = sc, tau\n",
        "    print('[Micro] Best OOF:', best_sc, 'tau:', best_tau)\n",
        "    return best_sc, best_tau\n",
        "\n",
        "# Run micro-overfit: expect clear learning (>0.5 MAP@5 on this tiny subset within a few epochs) if pipeline is healthy\n",
        "best_sc, best_tau = micro_overfit_run(img_size=384, p=10, k=4, epochs=5, head_lr=3e-3, bb_lr=0.0)\n",
        "print('Done micro-overfit. Score:', best_sc, 'tau:', best_tau)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "291c1943-4513-4c36-930c-14fced06a14e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Minimal model + feature extractor definitions for inference (no training)\n",
        "import os, math, time, torch, timm\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, ImageOps\n",
        "from pathlib import Path\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "IMG_SIZE = 384\n",
        "NUM_WORKERS = min(8, os.cpu_count() or 4)\n",
        "USE_BNNECK_FOR_RETR = False  # will be overridden by extract_feats_bnneck wrapper\n",
        "\n",
        "def get_infer_transform():\n",
        "    return T.Compose([\n",
        "        T.Resize((IMG_SIZE, IMG_SIZE), interpolation=T.InterpolationMode.BICUBIC),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ])\n",
        "\n",
        "class WhalesDS(Dataset):\n",
        "    def __init__(self, df, tta_hflip=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tta_hflip = tta_hflip\n",
        "        self.tf = get_infer_transform()\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        img = Image.open(str(row.image_path)).convert('RGB')\n",
        "        x = self.tf(img)\n",
        "        if self.tta_hflip:\n",
        "            x2 = self.tf(ImageOps.mirror(img))\n",
        "            return x, x2, row.image_path, row.Id\n",
        "        return x, row.image_path, row.Id\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3.0, eps=1e-6):\n",
        "        super().__init__(); self.p = nn.Parameter(torch.ones(1)*p); self.eps = eps\n",
        "    def forward(self, x):\n",
        "        x = x.clamp(min=self.eps).pow(self.p)\n",
        "        x = torch.mean(x, dim=(-1,-2)).pow(1.0/self.p)\n",
        "        return x\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model('convnext_tiny', pretrained=True, num_classes=0, global_pool='')\n",
        "        in_ch = self.backbone.num_features\n",
        "        self.gem = GeM(p=3.0)\n",
        "        self.emb = nn.Linear(in_ch, 512, bias=False)\n",
        "        self.bnneck = nn.BatchNorm1d(512, eps=1e-5, momentum=0.1)\n",
        "    def forward(self, x):\n",
        "        feat = self.backbone.forward_features(x)\n",
        "        feat = self.gem(feat)\n",
        "        f512 = self.emb(feat)\n",
        "        fbn = self.bnneck(f512)\n",
        "        return f512, fbn\n",
        "\n",
        "@torch.no_grad()\n",
        "def model_feats(model, x, use_bnneck: bool):\n",
        "    feat = model.backbone.forward_features(x)\n",
        "    feat = model.gem(feat)\n",
        "    if use_bnneck:\n",
        "        f512 = model.emb(feat)\n",
        "        fbn = model.bnneck(f512)\n",
        "        return nn.functional.normalize(fbn, dim=1)\n",
        "    else:\n",
        "        return nn.functional.normalize(feat, dim=1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_feats(model, df, tta_hflip=True):\n",
        "    ds = WhalesDS(df, tta_hflip=tta_hflip)\n",
        "    dl = DataLoader(ds, batch_size=64, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    feats, paths, labels = [], [], []\n",
        "    t0=time.time()\n",
        "    for bi, batch in enumerate(dl):\n",
        "        if tta_hflip:\n",
        "            x, x2, p, y = batch\n",
        "            x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            x2 = x2.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            f1 = model_feats(model, x, USE_BNNECK_FOR_RETR)\n",
        "            f2 = model_feats(model, x2, USE_BNNECK_FOR_RETR)\n",
        "            f = (f1 + f2) / 2.0\n",
        "        else:\n",
        "            x, p, y = batch\n",
        "            x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            f = model_feats(model, x, USE_BNNECK_FOR_RETR)\n",
        "        feats.append(f.cpu().numpy()); paths += list(p); labels += list(y)\n",
        "        if (bi+1)%20==0:\n",
        "            print(f'FE bi {bi+1}, {time.time()-t0:.1f}s', flush=True)\n",
        "    if len(feats)>0:\n",
        "        feats = np.concatenate(feats, axis=0)\n",
        "    else:\n",
        "        dim = int(model.emb.out_features) if USE_BNNECK_FOR_RETR else int(model.backbone.num_features)\n",
        "        feats = np.zeros((0, dim), dtype=np.float32)\n",
        "    return feats.astype('float32'), paths, labels"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "id": "619f6bfe-4fb3-4054-a067-1ef315908a23",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference: load EMA checkpoints, extract BNNeck embeddings, build ID prototypes or image-gallery, predict test, write submission.csv\n",
        "import os, math, time, gc, numpy as np, pandas as pd, torch, faiss\n",
        "from pathlib import Path\n",
        "from collections import OrderedDict\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ALPHA = 12.0  # expert: use 12.0\n",
        "\n",
        "def l2_normalize(x, axis=1, eps=1e-9):\n",
        "    x = np.asarray(x)\n",
        "    if x.ndim == 1:\n",
        "        n = np.linalg.norm(x) + eps\n",
        "        return x / n\n",
        "    n = np.linalg.norm(x, axis=axis, keepdims=True) + eps\n",
        "    return x / n\n",
        "\n",
        "def load_ckpt(ckpt_path):\n",
        "    ckpt = torch.load(ckpt_path, map_location='cpu')\n",
        "    state = ckpt.get('model', ckpt)  # tolerate raw state_dict\n",
        "    # Drop ArcFace head weights to avoid class-dimension mismatch at inference\n",
        "    if isinstance(state, (dict, OrderedDict)):\n",
        "        new_state = OrderedDict()\n",
        "        for k, v in state.items():\n",
        "            if ('arc.' in k) or k.endswith('arc.weight') or (k == 'arc.weight') or ('arc_weight' in k):\n",
        "                continue\n",
        "            new_state[k] = v\n",
        "        state = new_state\n",
        "    best_tau = ckpt.get('best_tau', None)\n",
        "    return state, best_tau\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_feats_bnneck(model, df, batch_size=64, tta_hflip=True):\n",
        "    # Force BNNeck features for inference\n",
        "    global USE_BNNECK_FOR_RETR\n",
        "    prev_flag = USE_BNNECK_FOR_RETR\n",
        "    USE_BNNECK_FOR_RETR = True\n",
        "    feats, paths, labels = extract_feats(model, df[['Image','Id','image_path']], tta_hflip=tta_hflip)\n",
        "    USE_BNNECK_FOR_RETR = prev_flag\n",
        "    return feats, paths, labels\n",
        "\n",
        "def build_id_prototypes(embs: np.ndarray, ids: list):\n",
        "    # Average embeddings per ID (no normalization here; we'll normalize after stacking)\n",
        "    df = pd.DataFrame({'Id': ids})\n",
        "    df['idx'] = np.arange(len(ids))\n",
        "    protos = []\n",
        "    labels = []\n",
        "    for gid, g in df.groupby('Id'):\n",
        "        idxs = g['idx'].values\n",
        "        m = embs[idxs].mean(axis=0, dtype=np.float32)\n",
        "        protos.append(m)\n",
        "        labels.append(gid)\n",
        "    return np.stack(protos).astype('float32'), labels\n",
        "\n",
        "def build_index_ip(embs):\n",
        "    index = faiss.IndexFlatIP(embs.shape[1])\n",
        "    index.add(embs)\n",
        "    return index\n",
        "\n",
        "def predict_with_gate(index, gallery_labels, query_embs, k=100, tau=0.74, alpha=12.0, margin=0.0, ratio=0.0):\n",
        "    sims, idxs = index.search(query_embs, min(k, index.ntotal))\n",
        "    preds = []\n",
        "    for i in range(len(query_embs)):\n",
        "        nei_idx = idxs[i]; nei_sims = sims[i]\n",
        "        labs = [gallery_labels[j] for j in nei_idx]\n",
        "        # exponential voting\n",
        "        scores = {}\n",
        "        for lab, sim in zip(labs, nei_sims):\n",
        "            scores[lab] = scores.get(lab, 0.0) + math.exp(alpha * float(sim))\n",
        "        ordered = [k for k,_ in sorted(scores.items(), key=lambda x:-x[1])]\n",
        "        # ambiguity/new_whale gate\n",
        "        s1 = float(nei_sims[0]) if len(nei_sims)>0 else -1.0\n",
        "        s2 = float(nei_sims[1]) if len(nei_sims)>1 else s1\n",
        "        top5 = []\n",
        "        if (len(nei_sims)>0 and s1 < tau) or (margin>0.0 and len(nei_sims)>1 and (s1 - s2) < margin) or (ratio>0.0 and len(nei_sims)>1 and (s1/max(s2,1e-6) < ratio)):\n",
        "            top5.append('new_whale')\n",
        "        for lab in ordered:\n",
        "            if lab not in top5:\n",
        "                top5.append(lab)\n",
        "            if len(top5)==5: break\n",
        "        if len(top5)<5:\n",
        "            top5 += ['new_whale']*(5-len(top5))\n",
        "        preds.append(top5[:5])\n",
        "    return preds\n",
        "\n",
        "def map5_score(preds, truths):\n",
        "    s = 0.0\n",
        "    for p, t in zip(preds, truths):\n",
        "        try:\n",
        "            r = p.index(t) + 1\n",
        "            s += 1.0 / r\n",
        "        except ValueError:\n",
        "            s += 0.0\n",
        "    return s / len(truths) if len(truths)>0 else 0.0\n",
        "\n",
        "def _build_dynamic_tau_grid_from_s1(s1_vals, lo_floor=0.20, hi_cap=0.90, pad=0.01, step=0.001):\n",
        "    v = s1_vals[np.isfinite(s1_vals)]\n",
        "    v = v[v > 0]\n",
        "    if v.size > 0:\n",
        "        p10, p90 = np.quantile(v, [0.10, 0.90])\n",
        "        lo = max(lo_floor, float(p10) - pad)\n",
        "        hi = min(hi_cap, float(p90) + pad)\n",
        "        if hi > lo:\n",
        "            return np.arange(lo, hi + 1e-9, step)\n",
        "    return np.arange(lo_floor, hi_cap, 0.002)\n",
        "\n",
        "def calibrate_tau_fold(model, folds_df, fold_idx, tta_hflip=True, tau_grid=None, margin=0.0, ratio=0.0, enable_dba=False, dba_M=8, dba_lambda=0.3):\n",
        "    tr = folds_df[(folds_df['fold'] != fold_idx) & (folds_df['Id'] != 'new_whale')].copy()\n",
        "    va = folds_df[folds_df['fold'] == fold_idx].copy()\n",
        "    # Extract train/val features\n",
        "    feats_tr, paths_tr, labs_tr = extract_feats_bnneck(model, tr, tta_hflip=tta_hflip)\n",
        "    feats_va, paths_va, labs_va = extract_feats_bnneck(model, va, tta_hflip=tta_hflip)\n",
        "    protos, proto_labels = build_id_prototypes(feats_tr, labs_tr)\n",
        "    protos = l2_normalize(protos, axis=1).astype('float32')\n",
        "    if enable_dba:\n",
        "        protos = dba_smooth(protos, M=dba_M, lam=dba_lambda)\n",
        "    index = build_index_ip(protos)\n",
        "    # Determine eval ground truth (IDs not in gallery become new_whale)\n",
        "    gal_id_set = set(proto_labels)\n",
        "    truths = [lab if lab in gal_id_set else 'new_whale' for lab in labs_va]\n",
        "    sims_all, idxs_all = index.search(l2_normalize(feats_va, axis=1).astype('float32'), min(50, index.ntotal))\n",
        "    # Dynamic tau grid from s1 percentiles\n",
        "    s1 = sims_all[:, 0] if sims_all.size > 0 else np.array([], dtype=np.float32)\n",
        "    dyn_grid = _build_dynamic_tau_grid_from_s1(s1)\n",
        "    if tau_grid is None or len(tau_grid) == 0:\n",
        "        tau_grid = dyn_grid\n",
        "    best_tau, best_sc = None, -1.0\n",
        "    for tau in tau_grid:\n",
        "        preds = []\n",
        "        for i in range(len(paths_va)):\n",
        "            nei_idx = idxs_all[i]; nei_sims = sims_all[i]\n",
        "            ordered = [proto_labels[j] for j in nei_idx]\n",
        "            # Apply gate using predict_with_gate logic but faster inline\n",
        "            s1i = float(nei_sims[0]) if len(nei_sims)>0 else -1.0\n",
        "            s2i = float(nei_sims[1]) if len(nei_sims)>1 else s1i\n",
        "            top5 = []\n",
        "            if (len(nei_sims)>0 and s1i < tau) or (margin>0.0 and len(nei_sims)>1 and (s1i - s2i) < margin) or (ratio>0.0 and len(nei_sims)>1 and (s1i/max(s2i,1e-6) < ratio)):\n",
        "                top5.append('new_whale')\n",
        "            # simple unique ordering based on sims (already by similarity)\n",
        "            for lab in ordered:\n",
        "                if lab not in top5:\n",
        "                    top5.append(lab)\n",
        "                if len(top5)==5: break\n",
        "            if len(top5)<5:\n",
        "                top5 += ['__DUMMY__']*(5-len(top5))  # do not reward the gate during calibration\n",
        "            preds.append(top5[:5])\n",
        "        sc = map5_score(preds, truths)\n",
        "        if sc > best_sc:\n",
        "            best_sc, best_tau = sc, float(tau)\n",
        "    print(f'[Calib] fold {fold_idx} best_tau={best_tau:.3f} map5={best_sc:.4f}')\n",
        "    return best_tau, best_sc\n",
        "\n",
        "def dba_smooth(proto_mat, M=8, lam=0.3):\n",
        "    # Database-side augmentation: smooth each vector with mean of its M nearest neighbors\n",
        "    if M <= 0 or lam <= 0: return proto_mat\n",
        "    index = build_index_ip(proto_mat)\n",
        "    sims, idxs = index.search(proto_mat, min(M+1, index.ntotal))\n",
        "    out = proto_mat.copy()\n",
        "    for i in range(proto_mat.shape[0]):\n",
        "        neigh = idxs[i][1:]  # exclude self at 0\n",
        "        if len(neigh) == 0: continue\n",
        "        mean_nei = proto_mat[neigh].mean(axis=0)\n",
        "        out[i] = l2_normalize(proto_mat[i] + lam * mean_nei)\n",
        "    return out.astype('float32')\n",
        "\n",
        "def query_expansion(index, gallery_vecs, queries, L=8, lam=0.3, conditional_tau=None):\n",
        "    if L <= 0 or lam <= 0: return queries\n",
        "    sims, idxs = index.search(queries, min(L, index.ntotal))\n",
        "    out = queries.copy()\n",
        "    for i in range(queries.shape[0]):\n",
        "        # Conditional QE: skip if top1 sim below (tau-0.02)\n",
        "        if conditional_tau is not None:\n",
        "            s1 = float(sims[i][0]) if sims.shape[1] > 0 else -1.0\n",
        "            if s1 < (conditional_tau - 0.02):\n",
        "                out[i] = queries[i]\n",
        "                continue\n",
        "        neigh = idxs[i]\n",
        "        if len(neigh) == 0: continue\n",
        "        mean_nei = gallery_vecs[neigh].mean(axis=0)\n",
        "        out[i] = l2_normalize(queries[i] + lam * mean_nei)\n",
        "    return out.astype('float32')\n",
        "\n",
        "def calibrate_tau_global(proto_mat, proto_labels, folds_df, val_feats_per_fold, val_labels_per_fold, tau_grid=None, margin=0.0, ratio=0.0):\n",
        "    # Build one index on final gallery (with DBA already applied); QE is OFF here by design\n",
        "    index = build_index_ip(proto_mat)\n",
        "    proto_label_set = set(proto_labels)\n",
        "    # Collect s1 across all folds for dynamic grid\n",
        "    s1_all = []\n",
        "    for f in sorted(folds_df['fold'].unique()):\n",
        "        feats = l2_normalize(val_feats_per_fold[f], axis=1).astype('float32')\n",
        "        sims_all, _ = index.search(feats, min(100, index.ntotal))\n",
        "        if sims_all.size > 0:\n",
        "            s1_all.append(sims_all[:, 0])\n",
        "    if len(s1_all) > 0:\n",
        "        s1_cat = np.concatenate(s1_all, axis=0)\n",
        "    else:\n",
        "        s1_cat = np.array([], dtype=np.float32)\n",
        "    dyn_grid = _build_dynamic_tau_grid_from_s1(s1_cat)\n",
        "    if tau_grid is None or len(tau_grid) == 0:\n",
        "        tau_grid = dyn_grid\n",
        "    try:\n",
        "        if s1_cat.size > 0:\n",
        "            q25, q50, q75 = np.quantile(s1_cat, [0.25, 0.50, 0.75])\n",
        "            print(f'[Calib-Global] s1 q25/q50/q75: {q25:.3f}/{q50:.3f}/{q75:.3f} | tau_grid: {tau_grid[0]:.3f}-{tau_grid[-1]:.3f} (n={len(tau_grid)})')\n",
        "    except Exception:\n",
        "        pass\n",
        "    best_tau, best_sc = None, -1.0\n",
        "    for tau in tau_grid:\n",
        "        scores = []\n",
        "        for f in sorted(folds_df['fold'].unique()):\n",
        "            feats = l2_normalize(val_feats_per_fold[f], axis=1).astype('float32')\n",
        "            labs = val_labels_per_fold[f]\n",
        "            sims_all, idxs_all = index.search(feats, min(100, index.ntotal))\n",
        "            preds = []\n",
        "            truths = []\n",
        "            for i in range(len(labs)):\n",
        "                lab = labs[i]\n",
        "                truths.append(lab if lab in proto_label_set else 'new_whale')\n",
        "                nei_idx = idxs_all[i]; nei_sims = sims_all[i]\n",
        "                # exponential voting\n",
        "                scores_map = {}\n",
        "                for j, sim in zip(nei_idx, nei_sims):\n",
        "                    scores_map[proto_labels[j]] = scores_map.get(proto_labels[j], 0.0) + math.exp(ALPHA * float(sim))\n",
        "                ordered = [k for k,_ in sorted(scores_map.items(), key=lambda x:-x[1])]\n",
        "                s1i = float(nei_sims[0]) if len(nei_sims)>0 else -1.0\n",
        "                s2i = float(nei_sims[1]) if len(nei_sims)>1 else s1i\n",
        "                top5 = []\n",
        "                if (len(nei_sims)>0 and s1i < tau) or (margin>0.0 and len(nei_sims)>1 and (s1i - s2i) < margin) or (ratio>0.0 and len(nei_sims)>1 and (s1i/max(s2i,1e-6) < ratio)):\n",
        "                    top5.append('new_whale')\n",
        "                for lab2 in ordered:\n",
        "                    if lab2 not in top5:\n",
        "                        top5.append(lab2)\n",
        "                    if len(top5)==5: break\n",
        "                if len(top5)<5:\n",
        "                    top5 += ['__DUMMY__']*(5-len(top5))  # do not reward gate during calibration\n",
        "                preds.append(top5[:5])\n",
        "            scores.append(map5_score(preds, truths))\n",
        "        sc = float(np.mean(scores)) if len(scores)>0 else -1.0\n",
        "        if sc > best_sc:\n",
        "            best_sc, best_tau = sc, float(tau)\n",
        "    print(f'[Calib-Global] best_tau={best_tau:.3f} mean_oof_map5={best_sc:.4f}')\n",
        "    return best_tau, best_sc\n",
        "\n",
        "def run_full_inference(ckpt_paths, out_csv='submission.csv', tta_hflip=True, enable_dba=False, dba_M=8, dba_lambda=0.3, enable_qe=False, qe_L=8, qe_lambda=0.3, tau_offset=0.0, margin=0.02, ratio=1.04):\n",
        "    t0_all = time.time()\n",
        "    folds_df = pd.read_csv('folds_grouped.csv')\n",
        "    folds_df['image_path'] = (Path('train')/folds_df['Image']).astype(str)\n",
        "    train_all = folds_df[folds_df['Id']!='new_whale'].copy()\n",
        "    ids_all = sorted(train_all['Id'].unique().tolist())\n",
        "    n_classes = len(ids_all)\n",
        "    # Build model skeleton once\n",
        "    model = Net(n_classes=n_classes).to(device).eval()\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    # Prepare test df\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    test_df = pd.DataFrame({'Image': ss['Image']})\n",
        "    test_df['image_path'] = (Path('test')/test_df['Image']).astype(str)\n",
        "    # Accumulators\n",
        "    tau_list = []\n",
        "    proto_accum = {}  # Id -> sum vector\n",
        "    proto_counts = {} # Id -> count of folds\n",
        "    test_emb_accum = None\n",
        "    # Store per-fold val feats for global tau calibration later\n",
        "    val_feats_per_fold = {}\n",
        "    val_labels_per_fold = {}\n",
        "    for fold_i, ck in enumerate(ckpt_paths):\n",
        "        if not os.path.exists(ck):\n",
        "            print(f'[Infer] Skip missing ckpt: {ck}')\n",
        "            continue\n",
        "        state, _ = load_ckpt(ck)\n",
        "        # Additionally drop any state keys not present/shaped like current model to be extra safe\n",
        "        model_state = model.state_dict()\n",
        "        filtered = OrderedDict()\n",
        "        for k, v in state.items():\n",
        "            if k in model_state and tuple(model_state[k].shape) == tuple(v.shape):\n",
        "                filtered[k] = v\n",
        "        miss = model.load_state_dict(filtered, strict=False)\n",
        "        print(f'[Infer] Loaded {ck}; used keys: {len(filtered)}/{len(state)}; missing keys: {len(miss.missing_keys)}; unexpected: {len(miss.unexpected_keys)}')\n",
        "        # Calibrate tau on this fold using prototype retrieval with BNNeck (dynamic tau grid, tau-only gate, dummy padding)\n",
        "        best_tau_fold, _ = calibrate_tau_fold(model, folds_df, fold_i, tta_hflip=tta_hflip, tau_grid=None, margin=0.0, ratio=0.0, enable_dba=enable_dba, dba_M=dba_M, dba_lambda=dba_lambda)\n",
        "        tau_list.append(best_tau_fold)\n",
        "        # Train embeddings -> prototypes on ALL train (for final gallery)\n",
        "        feats_tr, paths_tr, labs_tr = extract_feats_bnneck(model, train_all, tta_hflip=tta_hflip)\n",
        "        protos, proto_labels = build_id_prototypes(feats_tr, labs_tr)\n",
        "        # accumulate prototypes\n",
        "        for v, lab in zip(protos, proto_labels):\n",
        "            if lab not in proto_accum:\n",
        "                proto_accum[lab] = v.astype('float32').copy()\n",
        "                proto_counts[lab] = 1\n",
        "            else:\n",
        "                proto_accum[lab] += v.astype('float32')\n",
        "                proto_counts[lab] += 1\n",
        "        # Test embeddings\n",
        "        feats_te, paths_te, _ = extract_feats_bnneck(model, test_df.assign(Id='dummy'), tta_hflip=tta_hflip)\n",
        "        if test_emb_accum is None:\n",
        "            test_emb_accum = feats_te.astype('float32')\n",
        "        else:\n",
        "            test_emb_accum += feats_te.astype('float32')\n",
        "        # Store fold val feats for diagnostics/global calib\n",
        "        va = folds_df[folds_df['fold'] == fold_i].copy()\n",
        "        feats_va, _, labs_va = extract_feats_bnneck(model, va, tta_hflip=tta_hflip)\n",
        "        val_feats_per_fold[fold_i] = feats_va.astype('float32')\n",
        "        val_labels_per_fold[fold_i] = list(labs_va)\n",
        "        gc.collect()\n",
        "    # Average accumulators\n",
        "    if len(proto_accum)==0 or test_emb_accum is None:\n",
        "        raise RuntimeError('No checkpoints processed; cannot run inference.')\n",
        "    proto_keys = sorted(proto_accum.keys())\n",
        "    # stack first, then normalize row-wise to avoid 1D normalization pitfalls\n",
        "    proto_raw = np.stack([proto_accum[k] / max(1, proto_counts[k]) for k in proto_keys]).astype('float32')\n",
        "    proto_mat = l2_normalize(proto_raw, axis=1).astype('float32')\n",
        "    test_mat = l2_normalize(test_emb_accum / max(1, len(ckpt_paths))).astype('float32')\n",
        "    # Optional DBA smoothing on prototypes\n",
        "    if enable_dba:\n",
        "        proto_mat = dba_smooth(proto_mat, M=dba_M, lam=dba_lambda)\n",
        "    # Global calibration on FINAL gallery (DBA ON, QE OFF), with safety gates (margin/ratio)\n",
        "    tau_global, oof_mean = calibrate_tau_global(proto_mat, proto_keys, folds_df, val_feats_per_fold, val_labels_per_fold, tau_grid=None, margin=margin, ratio=ratio)\n",
        "    tau_global = float(np.clip(tau_global + float(tau_offset), 0.0, 1.0))\n",
        "    print(f'[Infer] Global calib tau={tau_global:.4f} (offset={float(tau_offset):.4f}) | per-fold taus median={float(np.median(tau_list)):.4f}')\n",
        "    # Build index on prototypes\n",
        "    index = build_index_ip(proto_mat)\n",
        "    # Optional Query Expansion (conditional)\n",
        "    if enable_qe and qe_L>0 and qe_lambda>0:\n",
        "        test_mat_qe = query_expansion(index, proto_mat, test_mat, L=qe_L, lam=qe_lambda, conditional_tau=tau_global)\n",
        "    else:\n",
        "        test_mat_qe = test_mat\n",
        "    preds = predict_with_gate(index, proto_keys, test_mat_qe, k=50, tau=tau_global, alpha=ALPHA, margin=margin, ratio=ratio)\n",
        "    # Write submission\n",
        "    pred_rows = [' '.join(p[:5]) for p in preds]\n",
        "    sub = pd.DataFrame({'Image': ss['Image'], 'Id': pred_rows})\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, 'shape', sub.shape, 'elapsed', f'{time.time()-t0_all:.1f}s')\n",
        "    print(sub.head().to_string(index=False))\n",
        "    print('Per-fold calibrated taus:', tau_list)\n",
        "    return out_csv\n",
        "\n",
        "def run_full_inference_image_gallery(ckpt_paths, out_csv='submission.csv', tta_hflip=True, enable_dba=True, dba_M=8, dba_lambda=0.3, enable_qe=True, qe_L=8, qe_lambda=0.3, tau_offset=0.0, margin=0.0, ratio=0.0):\n",
        "    # Build an image-level gallery (vote-by-ID) by averaging per-image embeddings across folds, then retrieve\n",
        "    t0_all = time.time()\n",
        "    folds_df = pd.read_csv('folds_grouped.csv')\n",
        "    folds_df['image_path'] = (Path('train')/folds_df['Image']).astype(str)\n",
        "    train_all = folds_df[folds_df['Id']!='new_whale'].copy()\n",
        "    ids_all = sorted(train_all['Id'].unique().tolist())\n",
        "    n_classes = len(ids_all)\n",
        "    model = Net(n_classes=n_classes).to(device).eval()\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    test_df = pd.DataFrame({'Image': ss['Image']})\n",
        "    test_df['image_path'] = (Path('test')/test_df['Image']).astype(str)\n",
        "    # Accumulators (per-image embeddings across folds)\n",
        "    gal_feat_sum = None\n",
        "    gal_labels = train_all['Id'].tolist()\n",
        "    gal_paths = train_all['image_path'].tolist()\n",
        "    test_feat_sum = None\n",
        "    # For calibration, collect per-fold val features\n",
        "    val_feat_sums = {}\n",
        "    val_labels_per_fold = {}\n",
        "    n_loaded = 0\n",
        "    for fold_i, ck in enumerate(ckpt_paths):\n",
        "        if not os.path.exists(ck):\n",
        "            print(f'[Infer-IMG] Skip missing ckpt: {ck}')\n",
        "            continue\n",
        "        state, _ = load_ckpt(ck)\n",
        "        model_state = model.state_dict()\n",
        "        filtered = OrderedDict((k,v) for k,v in state.items() if k in model_state and tuple(model_state[k].shape)==tuple(v.shape))\n",
        "        _ = model.load_state_dict(filtered, strict=False)\n",
        "        # Extract gallery (all train non-new_whale, per-image)\n",
        "        feats_gal, _, _ = extract_feats_bnneck(model, train_all, tta_hflip=tta_hflip)\n",
        "        gal_feat_sum = feats_gal.astype('float32') if gal_feat_sum is None else gal_feat_sum + feats_gal.astype('float32')\n",
        "        # Extract test\n",
        "        feats_te, _, _ = extract_feats_bnneck(model, test_df.assign(Id='dummy'), tta_hflip=tta_hflip)\n",
        "        test_feat_sum = feats_te.astype('float32') if test_feat_sum is None else test_feat_sum + feats_te.astype('float32')\n",
        "        # Validation features for this fold for calibration averaging\n",
        "        va_df = folds_df[folds_df['fold']==fold_i].copy()\n",
        "        feats_va, _, labs_va = extract_feats_bnneck(model, va_df, tta_hflip=tta_hflip)\n",
        "        if fold_i not in val_feat_sums:\n",
        "            val_feat_sums[fold_i] = feats_va.astype('float32')\n",
        "            val_labels_per_fold[fold_i] = list(labs_va)\n",
        "        else:\n",
        "            val_feat_sums[fold_i] += feats_va.astype('float32')\n",
        "        n_loaded += 1\n",
        "        gc.collect()\n",
        "    if n_loaded == 0:\n",
        "        raise RuntimeError('No checkpoints processed; cannot run inference.')\n",
        "    gal_mat_raw = l2_normalize(gal_feat_sum / n_loaded, axis=1).astype('float32')\n",
        "    test_mat = l2_normalize(test_feat_sum / n_loaded, axis=1).astype('float32')\n",
        "    for f in val_feat_sums.keys():\n",
        "        val_feat_sums[f] = l2_normalize(val_feat_sums[f] / n_loaded, axis=1).astype('float32')\n",
        "    assert gal_mat_raw.shape[0] == len(gal_labels)\n",
        "    # Leak-free per-fold tau calibration (QE OFF); recompute DBA on each sub-gallery\n",
        "    print('[Infer-IMG] Starting leak-free per-fold tau calibration...')\n",
        "    tau_grid = np.arange(0.95, 1.0001, 0.001)\n",
        "    train_all_idx = train_all.reset_index(drop=True)  # align row order\n",
        "    gal_labels_arr = np.array(gal_labels, dtype=object)\n",
        "    gallery_fold_indices = train_all_idx['fold'].values\n",
        "    taus_best = []\n",
        "    fold_scores = []\n",
        "    for f in sorted(val_feat_sums.keys()):\n",
        "        sub_mask = (gallery_fold_indices != f)\n",
        "        gal_sub = gal_mat_raw[sub_mask]\n",
        "        labels_sub = gal_labels_arr[sub_mask].tolist()\n",
        "        assert gal_sub.shape[0] == len(labels_sub)\n",
        "        # DBA on sub-gallery to avoid leak via neighbors\n",
        "        gal_sub_dba = dba_smooth(gal_sub, M=dba_M, lam=dba_lambda) if enable_dba else gal_sub\n",
        "        index_sub = build_index_ip(gal_sub_dba)\n",
        "        q = val_feat_sums[f]\n",
        "        labs = val_labels_per_fold[f]\n",
        "        assert q.shape[0] == len(labs)\n",
        "        sims_all, idxs_all = index_sub.search(q, min(50, index_sub.ntotal))\n",
        "        truths = [lab if lab in set(labels_sub) else 'new_whale' for lab in labs]\n",
        "        best_tau_f, best_sc_f = None, -1.0\n",
        "        for tau in tau_grid:\n",
        "            preds = []\n",
        "            for i in range(q.shape[0]):\n",
        "                nei_idx = idxs_all[i]; nei_sims = sims_all[i]\n",
        "                nei_ids = [labels_sub[j] for j in nei_idx]\n",
        "                # vote-by-ID\n",
        "                scores_map = {}\n",
        "                for lab2, sim in zip(nei_ids, nei_sims):\n",
        "                    scores_map[lab2] = scores_map.get(lab2, 0.0) + math.exp(ALPHA * float(sim))\n",
        "                ordered = [k for k,_ in sorted(scores_map.items(), key=lambda x: -x[1])]\n",
        "                s1 = float(nei_sims[0]) if len(nei_sims)>0 else -1.0\n",
        "                s2 = float(nei_sims[1]) if len(nei_sims)>1 else s1\n",
        "                top5 = []\n",
        "                if (len(nei_sims)>0 and s1 < tau) or (len(nei_sims)>1 and (s1 - s2) < margin) or (len(nei_sims)>1 and (s1/max(s2,1e-6)) < ratio):\n",
        "                    top5.append('new_whale')\n",
        "                for lab2 in ordered:\n",
        "                    if lab2 not in top5: top5.append(lab2)\n",
        "                    if len(top5)==5: break\n",
        "                if len(top5)<5: top5 += ['new_whale']*(5-len(top5))\n",
        "                preds.append(top5[:5])\n",
        "            sc = map5_score(preds, truths)\n",
        "            if sc > best_sc_f:\n",
        "                best_sc_f, best_tau_f = sc, float(tau)\n",
        "        taus_best.append(best_tau_f if best_tau_f is not None else float(np.median(tau_grid)))\n",
        "        fold_scores.append(best_sc_f if best_sc_f is not None else 0.0)\n",
        "        print(f'[OOF-fold-img] f={f} tau*={taus_best[-1]:.3f} score={fold_scores[-1]:.4f}')\n",
        "    tau_global = float(np.median(taus_best))\n",
        "    mean_oof = float(np.mean(fold_scores))\n",
        "    # Apply user-provided tau_offset to adjust gating for test distribution\n",
        "    tau_global = float(np.clip(tau_global + float(tau_offset), 0.65, 0.999))\n",
        "    print(f'[OOF-img] mean MAP@5={mean_oof:.4f} | median tau={tau_global:.3f} (after offset={float(tau_offset):.4f})')\n",
        "    # Build final gallery (DBA exactly as configured) and index\n",
        "    gal_mat = dba_smooth(gal_mat_raw, M=dba_M, lam=dba_lambda) if enable_dba else gal_mat_raw\n",
        "    index = build_index_ip(gal_mat)\n",
        "    # QE only for final inference (conditional)\n",
        "    if enable_qe:\n",
        "        test_q = query_expansion(index, gal_mat, test_mat, L=qe_L, lam=qe_lambda, conditional_tau=tau_global)\n",
        "    else:\n",
        "        test_q = test_mat\n",
        "    sims_all, idxs_all = index.search(test_q, min(50, index.ntotal))\n",
        "    pred_rows = []\n",
        "    for i in range(test_q.shape[0]):\n",
        "        nei_idx = idxs_all[i]; nei_sims = sims_all[i]\n",
        "        nei_ids = [gal_labels[j] for j in nei_idx]\n",
        "        scores_map = {}\n",
        "        for lab, sim in zip(nei_ids, nei_sims):\n",
        "            scores_map[lab] = scores_map.get(lab, 0.0) + math.exp(ALPHA * float(sim))\n",
        "        ordered = [k for k,_ in sorted(scores_map.items(), key=lambda x:-x[1])]\n",
        "        s1 = float(nei_sims[0]) if len(nei_sims)>0 else -1.0\n",
        "        s2 = float(nei_sims[1]) if len(nei_sims)>1 else s1\n",
        "        top5 = []\n",
        "        if (len(nei_sims)>0 and s1 < tau_global) or (len(nei_sims)>1 and (s1 - s2) < margin) or (len(nei_sims)>1 and (s1/max(s2,1e-6)) < ratio):\n",
        "            top5.append('new_whale')\n",
        "        for lab2 in ordered:\n",
        "            if lab2 not in top5: top5.append(lab2)\n",
        "            if len(top5)==5: break\n",
        "        if len(top5)<5: top5 += ['new_whale']*(5-len(top5))\n",
        "        pred_rows.append(' '.join(top5[:5]))\n",
        "    sub = pd.DataFrame({'Image': ss['Image'], 'Id': pred_rows})\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print('Wrote (IMG) ', out_csv, 'shape', sub.shape, 'elapsed', f'{time.time()-t0_all:.1f}s')\n",
        "    print(sub.head().to_string(index=False))\n",
        "    return out_csv\n",
        "\n",
        "# Example usage after training completes:\n",
        "# ckpts = [f'model_fold{k}_best.pth' for k in range(5)]\n",
        "# run_full_inference(ckpts, out_csv='submission.csv', tta_hflip=True)\n",
        "# run_full_inference_image_gallery(ckpts, out_csv='submission_img.csv', tta_hflip=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "id": "eccbf8da-6d2a-4c63-81b2-2c2eb9bd8e0d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run inference: prototype gallery (Path B) with global open-set calibration, DBA ON, QE OFF\n",
        "from pathlib import Path\n",
        "ckpts = [f'model_fold{k}_best.pth' for k in range(5)]\n",
        "out_csv = run_full_inference(\n",
        "    ckpt_paths=ckpts,\n",
        "    out_csv='submission.csv',\n",
        "    tta_hflip=True,\n",
        "    enable_dba=True,\n",
        "    dba_M=5,\n",
        "    dba_lambda=0.15,\n",
        "    enable_qe=False,\n",
        "    qe_L=0,\n",
        "    qe_lambda=0.0,\n",
        "    tau_offset=-0.45,  # Force tau into the prototype similarity regime to target ~35-55% new_whale@1\n",
        "    margin=0.02,\n",
        "    ratio=1.04\n",
        ")\n",
        "print('submission.csv exists?', Path(out_csv).exists())\n",
        "print('submission.csv size:', Path(out_csv).stat().st_size if Path(out_csv).exists() else -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c57e3be1-e0ed-4bbf-8191-0c0f1a00dbc3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OOF tuner using image-level galleries (vote-by-ID), per-fold models, to match training OOF conditions\n",
        "import math, time, gc, numpy as np, pandas as pd, torch, os\n",
        "from pathlib import Path\n",
        "from collections import OrderedDict\n",
        "\n",
        "@torch.no_grad()\n",
        "def build_fold_gallery_and_val(ckpt_paths, tta_hflip=True):\n",
        "    folds_df = pd.read_csv('folds_grouped.csv')\n",
        "    folds_df['image_path'] = (Path('train')/folds_df['Image']).astype(str)\n",
        "    ids_all = sorted(folds_df.loc[folds_df['Id']!='new_whale', 'Id'].unique().tolist())\n",
        "    n_classes = len(ids_all)\n",
        "    gallery_by_fold = {}   # f -> (gallery_feats[L2], gallery_ids[list of Id])\n",
        "    val_feats_by_fold = {}\n",
        "    val_labels_by_fold = {}\n",
        "    for fold_i, ck in enumerate(ckpt_paths):\n",
        "        if not os.path.exists(ck):\n",
        "            print(f'[Prep] Skip missing ckpt: {ck}')\n",
        "            continue\n",
        "        model = Net(n_classes=n_classes).to(device).eval().to(memory_format=torch.channels_last)\n",
        "        state, _ = load_ckpt(ck)\n",
        "        model_state = model.state_dict()\n",
        "        filtered = OrderedDict((k,v) for k,v in state.items() if k in model_state and tuple(model_state[k].shape)==tuple(v.shape))\n",
        "        _ = model.load_state_dict(filtered, strict=False)\n",
        "        # Gallery = train excluding this fold, exclude new_whale (mirrors training OOF)\n",
        "        gal_df = folds_df[(folds_df['fold']!=fold_i) & (folds_df['Id']!='new_whale')].copy()\n",
        "        gal_feats, _, gal_ids = extract_feats_bnneck(model, gal_df, tta_hflip=tta_hflip)\n",
        "        gal_feats = l2_normalize(gal_feats, axis=1).astype('float32')\n",
        "        gallery_by_fold[fold_i] = (gal_feats, list(gal_ids))\n",
        "        # Validation features for THIS fold with THIS model\n",
        "        va_df = folds_df[folds_df['fold']==fold_i].copy()\n",
        "        feats_va, _, labs_va = extract_feats_bnneck(model, va_df, tta_hflip=tta_hflip)\n",
        "        val_feats_by_fold[fold_i] = l2_normalize(feats_va, axis=1).astype('float32')\n",
        "        val_labels_by_fold[fold_i] = list(labs_va)\n",
        "        gc.collect()\n",
        "    return gallery_by_fold, val_feats_by_fold, val_labels_by_fold\n",
        "\n",
        "def vote_rank_ids(nei_ids, nei_sims, alpha=ALPHA):\n",
        "    scores = {}\n",
        "    for lab, sim in zip(nei_ids, nei_sims):\n",
        "        scores[lab] = scores.get(lab, 0.0) + math.exp(alpha * float(sim))\n",
        "    ordered = [k for k,_ in sorted(scores.items(), key=lambda x:-x[1])]\n",
        "    return ordered\n",
        "\n",
        "def oof_score_image_gallery(gallery_by_fold, val_feats_by_fold, val_labels_by_fold, dba_M=8, dba_lambda=0.3, qe_L=8, qe_lambda=0.3, conditional_qe=True, tau_grid=np.arange(0.65,0.81,0.01)):\n",
        "    taus_best = []\n",
        "    fold_scores = []\n",
        "    for f in sorted(gallery_by_fold.keys()):\n",
        "        gal_feats, gal_ids = gallery_by_fold[f]\n",
        "        # Apply DBA smoothing on gallery embeddings (safe on vectors)\n",
        "        gal_mat = dba_smooth(gal_feats, M=dba_M, lam=dba_lambda) if (dba_M>0 and dba_lambda>0) else gal_feats\n",
        "        index = build_index_ip(gal_mat)\n",
        "        feats = val_feats_by_fold[f]\n",
        "        labs = val_labels_by_fold[f]\n",
        "        # Calibrate tau per-fold (QE OFF for calibration)\n",
        "        best_tau, best_sc = None, -1.0\n",
        "        sims_all, idxs_all = index.search(feats, min(100, index.ntotal))\n",
        "        truths = [lab if lab in set(gal_ids) else 'new_whale' for lab in labs]\n",
        "        for tau in tau_grid:\n",
        "            preds = []\n",
        "            for i in range(len(labs)):\n",
        "                nei_idx = idxs_all[i]; nei_sims = sims_all[i]\n",
        "                nei_lab = [gal_ids[j] for j in nei_idx]\n",
        "                ordered = vote_rank_ids(nei_lab, nei_sims, alpha=ALPHA)\n",
        "                s1 = float(nei_sims[0]) if len(nei_sims)>0 else -1.0\n",
        "                s2 = float(nei_sims[1]) if len(nei_sims)>1 else s1\n",
        "                top5 = []\n",
        "                if (len(nei_sims)>0 and s1 < tau) or (len(nei_sims)>1 and (s1 - s2) < 0.03) or (len(nei_sims)>1 and (s1/max(s2,1e-6) < 1.06)):\n",
        "                    top5.append('new_whale')\n",
        "                for lab2 in ordered:\n",
        "                    if lab2 not in top5: top5.append(lab2)\n",
        "                    if len(top5)==5: break\n",
        "                if len(top5)<5: top5 += ['new_whale']*(5-len(top5))\n",
        "                preds.append(top5[:5])\n",
        "            sc = map5_score(preds, truths)\n",
        "            if sc > best_sc:\n",
        "                best_sc, best_tau = sc, float(tau)\n",
        "        taus_best.append(best_tau if best_tau is not None else float(np.median(tau_grid)))\n",
        "        # QE for final scoring (optional)\n",
        "        if qe_L>0 and qe_lambda>0:\n",
        "            feats_q = query_expansion(index, gal_mat, feats, L=qe_L, lam=qe_lambda, conditional_tau=(best_tau if conditional_qe else None))\n",
        "            sims_all, idxs_all = index.search(feats_q, min(100, index.ntotal))\n",
        "        # Final scoring with best tau\n",
        "        preds = []\n",
        "        for i in range(len(labs)):\n",
        "            nei_idx = idxs_all[i]; nei_sims = sims_all[i]\n",
        "            nei_lab = [gal_ids[j] for j in nei_idx]\n",
        "            ordered = vote_rank_ids(nei_lab, nei_sims, alpha=ALPHA)\n",
        "            s1 = float(nei_sims[0]) if len(nei_sims)>0 else -1.0\n",
        "            s2 = float(nei_sims[1]) if len(nei_sims)>1 else s1\n",
        "            top5 = []\n",
        "            if (len(nei_sims)>0 and s1 < best_tau) or (len(nei_sims)>1 and (s1 - s2) < 0.03) or (len(nei_sims)>1 and (s1/max(s2,1e-6) < 1.06)):\n",
        "                top5.append('new_whale')\n",
        "            for lab2 in ordered:\n",
        "                if lab2 not in top5: top5.append(lab2)\n",
        "                if len(top5)==5: break\n",
        "            if len(top5)<5: top5 += ['new_whale']*(5-len(top5))\n",
        "            preds.append(top5[:5])\n",
        "        sc_final = map5_score(preds, truths)\n",
        "        fold_scores.append(sc_final)\n",
        "        print(f'[OOF-fold-img] f={f} tau*={best_tau:.3f} score={sc_final:.4f}')\n",
        "    mean_sc = float(np.mean(fold_scores)) if len(fold_scores)>0 else -1.0\n",
        "    tau_global = float(np.median(taus_best)) if len(taus_best)>0 else float(np.median(tau_grid))\n",
        "    print(f'[OOF-img] mean MAP@5={mean_sc:.4f} | median tau={tau_global:.3f}')\n",
        "    return mean_sc, tau_global\n",
        "\n",
        "def grid_tune_and_submit(ckpts, dba_M_grid=(5,8,12), dba_lambda_grid=(0.2,0.3,0.4), qe_L_grid=(5,8,12), qe_lambda_grid=(0.2,0.3), conditional_qe=True):\n",
        "    t0=time.time()\n",
        "    gallery_by_fold, val_feats_by_fold, val_labels_by_fold = build_fold_gallery_and_val(ckpts, tta_hflip=True)\n",
        "    print('[Tune] Prepared per-fold image-level galleries and val feats in', f'{time.time()-t0:.1f}s')\n",
        "    best = (-1.0, None)\n",
        "    for M in dba_M_grid:\n",
        "        for lam in dba_lambda_grid:\n",
        "            for L in qe_L_grid:\n",
        "                for qel in qe_lambda_grid:\n",
        "                    sc, tau = oof_score_image_gallery(gallery_by_fold, val_feats_by_fold, val_labels_by_fold, dba_M=M, dba_lambda=lam, qe_L=L, qe_lambda=qel, conditional_qe=conditional_qe)\n",
        "                    print(f'[Tune] DBA(M={M},lam={lam}) QE(L={L},lam={qel},cond={conditional_qe}) -> OOF {sc:.4f} tau {tau:.3f}')\n",
        "                    if sc > best[0]:\n",
        "                        best = (sc, (M, lam, L, qel, tau))\n",
        "    best_sc, (M, lam, L, qel, tau) = best\n",
        "    print(f'[Tune] Best OOF {best_sc:.4f} with DBA(M={M},lam={lam}) QE(L={L},lam={qel}) tau={tau:.3f}')\n",
        "    # Final inference still uses blended prototype pipeline for speed; params carried over\n",
        "    out_csv = run_full_inference(ckpts, out_csv='submission.csv', tta_hflip=True, enable_dba=True, dba_M=M, dba_lambda=lam, enable_qe=True, qe_L=L, qe_lambda=qel)\n",
        "    print('[Tune] Submission written to', out_csv)\n",
        "    return out_csv, {'OOF': best_sc, 'DBA_M': M, 'DBA_lambda': lam, 'QE_L': L, 'QE_lambda': qel, 'tau': tau}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "5ff8108f-09a9-4874-9cac-673c4d007905",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run DBA/QE grid tuning (reduced grid for sanity) and regenerate submission with best params\n",
        "ckpts = [f'model_fold{k}_best.pth' for k in range(5)]\n",
        "print('[Run-Tune] Starting DBA/QE grid (reduced) using per-fold OOF...')\n",
        "t0=time.time()\n",
        "out_csv, best_info = grid_tune_and_submit(\n",
        "    ckpts,\n",
        "    dba_M_grid=(8,),\n",
        "    dba_lambda_grid=(0.3,),\n",
        "    qe_L_grid=(8,),\n",
        "    qe_lambda_grid=(0.3,),\n",
        "    conditional_qe=True\n",
        ")\n",
        "print('[Run-Tune] Done in', f'{time.time()-t0:.1f}s', 'Best:', best_info)\n",
        "from pathlib import Path\n",
        "print('submission.csv exists?', Path(out_csv).exists(), 'size:', Path(out_csv).stat().st_size if Path(out_csv).exists() else -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f4ec168a-989c-40f5-8184-c12d9d77adf5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run per-fold score-level fusion inference (DBA + conditional QE + k-reciprocal rerank) with leak-free calibration\n",
        "ckpts = [f'model_fold{k}_best.pth' for k in range(5)]\n",
        "print('[Infer-Fusion] Starting per-fold score-level fusion (DBA+QE+rerank, calibrated tau)...')\n",
        "from pathlib import Path\n",
        "import time\n",
        "t0=time.time()\n",
        "out_csv = run_infer_img_gallery_score_fusion(\n",
        "    ckpt_paths=ckpts,\n",
        "    out_csv='submission.csv',\n",
        "    cache_dir='cache_feats',\n",
        "    tta_hflip=True,\n",
        "    enable_dba=True, dba_M=8, dba_lambda=0.3,\n",
        "    K=200, alpha=12.0,\n",
        "    margin=0.0, ratio=0.0,   # gates OFF for stable calibration\n",
        "    tau_offset=-0.0020,      # S2: target NH@1 ~55\u201358%\n",
        "    enable_qe=True, qe_L=10, qe_lambda=0.35,\n",
        "    enable_rerank=True, rerank_k1=20, rerank_k2=6, rerank_lam=0.25\n",
        ")\n",
        "print('[Infer-Fusion] Done in', f'{time.time()-t0:.1f}s', '->', out_csv)\n",
        "print('submission.csv exists?', Path(out_csv).exists(), 'size:', Path(out_csv).stat().st_size if Path(out_csv).exists() else -1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-Fusion] Starting per-fold score-level fusion (DBA+QE+rerank, calibrated tau)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7504/1135787474.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG fold 0] sims range: [0.827, 0.997] mean=0.952 K=200 gal=5201 val=1448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG fold 0] sims range: [0.964, 1.000] mean=0.989 K=200 gal=5201 val=1448\n"
          ]
        }
      ]
    },
    {
      "id": "5bcc76ab-6a0e-48bd-a94b-a7660fefcf31",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Per-fold score-level fusion with leak-free calibration + caching + k-reciprocal re-ranking\n",
        "from collections import OrderedDict, defaultdict\n",
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd, math, time, os, gc\n",
        "\n",
        "def _load_cached(npy_path, n_rows=None):\n",
        "    if not Path(npy_path).exists(): return None\n",
        "    arr = np.load(npy_path)\n",
        "    if (n_rows is not None) and (arr.shape[0] != n_rows): return None\n",
        "    return arr.astype('float32')\n",
        "\n",
        "def _save_cached(npy_path, arr):\n",
        "    np.save(npy_path, arr.astype('float32'))\n",
        "\n",
        "def _get_feats_cached(model, df, cache_path, tta_hflip=True):\n",
        "    arr = _load_cached(cache_path, len(df))\n",
        "    if arr is not None: return arr\n",
        "    feats, _, _ = extract_feats_bnneck(model, df, tta_hflip=tta_hflip)\n",
        "    _save_cached(cache_path, feats)\n",
        "    return feats\n",
        "\n",
        "def _accumulate_scores(nei_ids, nei_sims, alpha, store: dict):\n",
        "    for lab, sim in zip(nei_ids, nei_sims):\n",
        "        store[lab] = store.get(lab, 0.0) + math.exp(alpha * float(sim))\n",
        "\n",
        "def _accumulate_max_sims(nei_ids, nei_sims, store: dict):\n",
        "    # Track per-ID maximum similarity across folds\n",
        "    for lab, sim in zip(nei_ids, nei_sims):\n",
        "        cur = store.get(lab, -1.0)\n",
        "        if float(sim) > cur:\n",
        "            store[lab] = float(sim)\n",
        "\n",
        "# k-reciprocal re-ranking helpers\n",
        "def _precompute_gal_nn(index, gal_feats, k2):\n",
        "    _, idxs_g = index.search(gal_feats, min(k2+1, index.ntotal))\n",
        "    return idxs_g\n",
        "\n",
        "def _rerank_k_reciprocal(sims, idxs, gal_nn_idx, k1=20, k2=6, lam=0.3):\n",
        "    if sims.size == 0: return sims, idxs\n",
        "    sims_new = sims.copy()\n",
        "    nq, K = sims.shape\n",
        "    for i in range(nq):\n",
        "        topk = idxs[i][:k1]\n",
        "        topk_set = set(topk.tolist())\n",
        "        for j in range(K):\n",
        "            gid = idxs[i][j]\n",
        "            neigh = gal_nn_idx[gid][1:1+k2]\n",
        "            overlap = len(topk_set.intersection(neigh.tolist()))\n",
        "            bonus = overlap / float(max(1, k2))\n",
        "            sims_new[i][j] = (1.0 - lam) * sims[i][j] + lam * bonus\n",
        "        order = np.argsort(-sims_new[i])\n",
        "        sims_new[i] = sims_new[i][order]\n",
        "        idxs[i] = idxs[i][order]\n",
        "    return sims_new, idxs\n",
        "\n",
        "def _gate_from_fused_max(maxsim_dict: dict, tau: float, margin: float, ratio: float) -> bool:\n",
        "    # Fixed gating: proper s2 handling and clamping; avoid ambiguity when only one candidate\n",
        "    if not maxsim_dict:\n",
        "        return True\n",
        "    vals = [max(0.0, min(1.0, float(v))) for v in maxsim_dict.values()]\n",
        "    if not vals:\n",
        "        return True\n",
        "    vals.sort(reverse=True)\n",
        "    s1 = vals[0]\n",
        "    if s1 < tau:\n",
        "        return True\n",
        "    if len(vals) > 1:\n",
        "        s2 = vals[1]\n",
        "        if (s1 - s2) < margin:\n",
        "            return True\n",
        "        if (s1 / max(s2, 1e-6)) < ratio:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def calibrate_tau_score_fusion(ckpt_paths, folds_df, train_all, cache_dir, alpha=18.0, dba_M=12, dba_lambda=0.4, margin=0.02, ratio=1.04, tau_grid=None, tta_hflip=True, K=200, enable_rerank=True, rerank_k1=20, rerank_k2=6, rerank_lam=0.3):\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    n_classes = train_all['Id'].nunique()\n",
        "    model = Net(n_classes=n_classes).to(device).eval().to(memory_format=torch.channels_last)\n",
        "\n",
        "    gal_labels_all = train_all['Id'].tolist()\n",
        "    gal_folds_all = train_all['fold'].to_numpy()\n",
        "    taus_best = []\n",
        "    for f in sorted(folds_df['fold'].unique()):\n",
        "        va_df = folds_df[folds_df['fold']==f].copy().reset_index(drop=True)\n",
        "        n_q = len(va_df)\n",
        "        fused_scores = [defaultdict(float) for _ in range(n_q)]\n",
        "        fused_maxsim = [dict() for _ in range(n_q)]  # per-query per-ID max similarity\n",
        "\n",
        "        sub_mask = (gal_folds_all != f)\n",
        "        sub_labels = np.array(gal_labels_all, dtype=object)[sub_mask].tolist()\n",
        "        truths = [lab if lab in set(sub_labels) else 'new_whale' for lab in va_df['Id']]\n",
        "\n",
        "        for k, ck in enumerate(ckpt_paths):\n",
        "            if not os.path.exists(ck): continue\n",
        "            state, _ = load_ckpt(ck)\n",
        "            filtered = OrderedDict((kk,vv) for kk,vv in state.items() if kk in model.state_dict() and tuple(model.state_dict()[kk].shape)==tuple(vv.shape))\n",
        "            _ = model.load_state_dict(filtered, strict=False)\n",
        "\n",
        "            gal_all = _get_feats_cached(model, train_all, f'{cache_dir}/gal_feats_k{k}.npy', tta_hflip=tta_hflip)\n",
        "            gal_all = l2_normalize(gal_all, axis=1); gal = gal_all[sub_mask]\n",
        "            assert gal.shape[0] == len(sub_labels)\n",
        "            if dba_M>0 and dba_lambda>0: gal = dba_smooth(gal, M=dba_M, lam=dba_lambda)\n",
        "            index = build_index_ip(gal)\n",
        "            gal_nn_idx = _precompute_gal_nn(index, gal, k2=rerank_k2)\n",
        "\n",
        "            val_feats = _get_feats_cached(model, va_df, f'{cache_dir}/val_feats_k{k}_f{f}.npy', tta_hflip=tta_hflip)\n",
        "            val_feats = l2_normalize(val_feats, axis=1)\n",
        "            sims, idxs = index.search(val_feats, min(K, index.ntotal))\n",
        "            # Debug stats for similarity distribution\n",
        "            try:\n",
        "                print(f\"[DEBUG fold {f}] sims range: [{sims.min():.3f}, {sims.max():.3f}] mean={sims.mean():.3f} K={sims.shape[1]} gal={gal.shape[0]} val={val_feats.shape[0]}\")\n",
        "            except Exception:\n",
        "                pass\n",
        "            if enable_rerank:\n",
        "                sims, idxs = _rerank_k_reciprocal(sims, idxs, gal_nn_idx, k1=rerank_k1, k2=rerank_k2, lam=rerank_lam)\n",
        "            for qi in range(n_q):\n",
        "                ns = sims[qi]; ni = idxs[qi]\n",
        "                if ns.size == 0: continue\n",
        "                nei_ids = [sub_labels[j] for j in ni]\n",
        "                _accumulate_scores(nei_ids, ns, alpha, fused_scores[qi])\n",
        "                _accumulate_max_sims(nei_ids, ns, fused_maxsim[qi])\n",
        "\n",
        "        # Build dynamic tau_grid from fused s1 distribution for this fold\n",
        "        s1_vals = np.array([max(v.values()) if len(v)>0 else -1.0 for v in fused_maxsim], dtype=np.float32)\n",
        "        v = s1_vals[s1_vals > 0]\n",
        "        if v.size > 0:\n",
        "            p10, p90 = np.quantile(v, [0.10, 0.90])\n",
        "            lo = max(0.90, float(p10) - 0.01)\n",
        "            hi = min(0.999, float(p90) + 0.01)\n",
        "            tau_grid_fold = np.arange(lo, hi + 1e-9, 0.001)\n",
        "        else:\n",
        "            tau_grid_fold = np.arange(0.95, 0.999, 0.001)\n",
        "\n",
        "        best_tau, best_sc = None, -1.0\n",
        "        for tau in tau_grid_fold:\n",
        "            preds = []\n",
        "            for qi in range(n_q):\n",
        "                ordered = [k for k,_ in sorted(fused_scores[qi].items(), key=lambda kv: -kv[1])]\n",
        "                # ensure uniqueness for calibration predictions as well\n",
        "                seen = set()\n",
        "                ordered_unique = []\n",
        "                for lab in ordered:\n",
        "                    if lab not in seen:\n",
        "                        ordered_unique.append(lab); seen.add(lab)\n",
        "                top5 = []\n",
        "                # Use the SAME gate as inference (tau + margin/ratio)\n",
        "                if _gate_from_fused_max(fused_maxsim[qi], tau, margin=margin, ratio=ratio):\n",
        "                    top5.append('new_whale')\n",
        "                for lab in ordered_unique:\n",
        "                    if lab not in top5: top5.append(lab)\n",
        "                    if len(top5)==5: break\n",
        "                if len(top5) < 5:\n",
        "                    top5 += ['__DUMMY__'] * (5 - len(top5))  # avoid rewarding gate with 'new_whale'\n",
        "                preds.append(top5)\n",
        "            sc = map5_score(preds, truths)\n",
        "            if sc > best_sc:\n",
        "                best_sc, best_tau = sc, float(tau)\n",
        "        taus_best.append(float(best_tau))\n",
        "        print(f'[Fusion-Calib] fold {f}: tau*={best_tau:.3f} oof_map5={best_sc:.4f}')\n",
        "    tau_global = float(np.median(taus_best))\n",
        "    print(f'[Fusion-Calib] median tau={tau_global:.3f}')\n",
        "    return tau_global\n",
        "\n",
        "def run_infer_img_gallery_score_fusion(ckpt_paths, out_csv='submission.csv', cache_dir='cache_feats', tta_hflip=True, enable_dba=True, dba_M=12, dba_lambda=0.4, K=200, alpha=18.0, margin=0.02, ratio=1.04, tau_offset=0.0, enable_qe=True, qe_L=8, qe_lambda=0.3, enable_rerank=True, rerank_k1=20, rerank_k2=6, rerank_lam=0.3):\n",
        "    t0=time.time()\n",
        "    os.makedirs(cache_dir, exist_ok=True)\n",
        "    folds_df = pd.read_csv('folds_grouped.csv')\n",
        "    folds_df['image_path'] = (Path('train')/folds_df['Image']).astype(str)\n",
        "    train_all = folds_df[folds_df['Id']!='new_whale'].copy().reset_index(drop=True)\n",
        "\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    test_df = pd.DataFrame({'Image': ss['Image']})\n",
        "    test_df['image_path'] = (Path('test')/test_df['Image']).astype(str)\n",
        "\n",
        "    n_classes = train_all['Id'].nunique()\n",
        "    model = Net(n_classes=n_classes).to(device).eval().to(memory_format=torch.channels_last)\n",
        "\n",
        "    # Leak-free tau calibration on fused setup (DBA ON, QE OFF)\n",
        "    tau = calibrate_tau_score_fusion(ckpt_paths, folds_df, train_all, cache_dir, alpha=alpha, dba_M=dba_M, dba_lambda=dba_lambda, margin=margin, ratio=ratio, tta_hflip=tta_hflip, K=K, enable_rerank=enable_rerank, rerank_k1=rerank_k1, rerank_k2=rerank_k2, rerank_lam=rerank_lam)\n",
        "    tau += float(tau_offset)\n",
        "\n",
        "    # Final inference: per-fold retrieval + score fusion\n",
        "    gal_labels_full = train_all['Id'].tolist()\n",
        "    # Precompute fallback IDs (most frequent) to ensure 5 unique labels\n",
        "    fallback_ids = train_all['Id'].value_counts().index.tolist()\n",
        "    fused_scores = [defaultdict(float) for _ in range(len(test_df))]\n",
        "    fused_maxsim = [dict() for _ in range(len(test_df))]  # per-query per-ID max similarity\n",
        "\n",
        "    for k, ck in enumerate(ckpt_paths):\n",
        "        if not os.path.exists(ck): continue\n",
        "        state, _ = load_ckpt(ck)\n",
        "        filtered = OrderedDict((kk,vv) for kk,vv in state.items() if kk in model.state_dict() and tuple(model.state_dict()[kk].shape)==tuple(vv.shape))\n",
        "        _ = model.load_state_dict(filtered, strict=False)\n",
        "\n",
        "        gal_feats = _get_feats_cached(model, train_all, f'{cache_dir}/gal_feats_k{k}.npy', tta_hflip=tta_hflip)\n",
        "        gal_feats = l2_normalize(gal_feats, axis=1)\n",
        "        if enable_dba and dba_M>0 and dba_lambda>0:\n",
        "            gal_feats = dba_smooth(gal_feats, M=dba_M, lam=dba_lambda)\n",
        "        index = build_index_ip(gal_feats)\n",
        "        gal_nn_idx = _precompute_gal_nn(index, gal_feats, k2=rerank_k2)\n",
        "\n",
        "        te_feats = _get_feats_cached(model, test_df.assign(Id='dummy'), f'{cache_dir}/test_feats_k{k}.npy', tta_hflip=tta_hflip)\n",
        "        te_feats = l2_normalize(te_feats, axis=1)\n",
        "        # Conditional QE only for final inference (not during calibration)\n",
        "        if enable_qe and qe_L>0 and qe_lambda>0:\n",
        "            te_feats = query_expansion(index, gal_feats, te_feats, L=qe_L, lam=qe_lambda, conditional_tau=tau)\n",
        "\n",
        "        sims, idxs = index.search(te_feats, min(K, index.ntotal))\n",
        "        if enable_rerank:\n",
        "            sims, idxs = _rerank_k_reciprocal(sims, idxs, gal_nn_idx, k1=rerank_k1, k2=rerank_k2, lam=rerank_lam)\n",
        "        for qi in range(len(test_df)):\n",
        "            ns = sims[qi]; ni = idxs[qi]\n",
        "            if ns.size == 0: continue\n",
        "            nei_ids = [gal_labels_full[j] for j in ni]\n",
        "            _accumulate_scores(nei_ids, ns, alpha, fused_scores[qi])\n",
        "            _accumulate_max_sims(nei_ids, ns, fused_maxsim[qi])\n",
        "        gc.collect()\n",
        "\n",
        "    pred_rows = []\n",
        "    new_whale_first = 0\n",
        "    s1_list = []\n",
        "    for qi in range(len(test_df)):\n",
        "        # Build unique ordered labels by fused score\n",
        "        ordered = [lab for lab,_ in sorted(fused_scores[qi].items(), key=lambda kv: -kv[1])]\n",
        "        seen = set()\n",
        "        ordered_unique = []\n",
        "        for lab in ordered:\n",
        "            if lab not in seen:\n",
        "                ordered_unique.append(lab); seen.add(lab)\n",
        "        top5 = []\n",
        "        if _gate_from_fused_max(fused_maxsim[qi], tau, margin, ratio) and 'new_whale' not in top5:\n",
        "            top5.append('new_whale')\n",
        "        for lab in ordered_unique:\n",
        "            if lab not in top5:\n",
        "                top5.append(lab)\n",
        "            if len(top5)==5: break\n",
        "        # Pad with most frequent training IDs, ensuring uniqueness; only one 'new_whale'\n",
        "        if len(top5) < 5:\n",
        "            for fid in fallback_ids:\n",
        "                if fid not in top5:\n",
        "                    top5.append(fid)\n",
        "                    if len(top5) == 5: break\n",
        "        pred_rows.append(' '.join(top5[:5]))\n",
        "        if len(top5)>0 and top5[0]=='new_whale': new_whale_first += 1\n",
        "        # diagnostics: fused top1 similarity\n",
        "        if len(fused_maxsim[qi])>0:\n",
        "            s1_list.append(max(fused_maxsim[qi].values()))\n",
        "        else:\n",
        "            s1_list.append(-1.0)\n",
        "\n",
        "    # Diagnostics\n",
        "    nh_rate = new_whale_first / max(1, len(test_df))\n",
        "    try:\n",
        "        s1_arr = np.array(s1_list, dtype=np.float32)\n",
        "        q25, q50, q75 = np.quantile(s1_arr, 0.25), np.quantile(s1_arr, 0.50), np.quantile(s1_arr, 0.75)\n",
        "        print(f'[Fusion] new_whale@1 rate={nh_rate*100:.1f}% | fused s1 q25/q50/q75: {q25:.3f}/{q50:.3f}/{q75:.3f}')\n",
        "    except Exception as e:\n",
        "        print(f'[Fusion] new_whale@1 rate={nh_rate*100:.1f}% | diag error:', e)\n",
        "\n",
        "    sub = pd.DataFrame({'Image': ss['Image'], 'Id': pred_rows})\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print(f'[Fusion] Wrote {out_csv} shape {sub.shape} elapsed {time.time()-t0:.1f}s')\n",
        "    return out_csv"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "id": "9ff989a4-fc76-4d40-a8f5-517ccdee95a8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick diagnostics on submission: new_whale@1 rate and basic checks\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "sub_path = Path('submission.csv')\n",
        "assert sub_path.exists(), 'submission.csv not found'\n",
        "sub = pd.read_csv(sub_path)\n",
        "def first_label(s):\n",
        "    try:\n",
        "        return str(s).split()[0]\n",
        "    except Exception:\n",
        "        return ''\n",
        "firsts = sub['Id'].map(first_label)\n",
        "nh_rate = (firsts == 'new_whale').mean() * 100.0\n",
        "print(f'new_whale@1 rate: {nh_rate:.2f}%')\n",
        "print('Unique first labels:', firsts.nunique())\n",
        "print('Head:')\n",
        "print(sub.head().to_string(index=False))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new_whale@1 rate: 45.67%\nUnique first labels: 736\nHead:\n       Image                                                Id\n00087b01.jpg w_d9aab0a w_da2efe0 w_fea7fe6 w_73b705e w_17ee910\n0014cfdf.jpg w_0e4ef50 w_fe8233d w_ea6651e w_823fcbb w_a74742c\n0035632e.jpg w_95874a5 w_da2efe0 w_3c304db w_6e8486d w_8c1e2e4\n004c5fb9.jpg new_whale w_17ee910 w_bb2d34d w_95874a5 w_8c1e2e4\n00863b8c.jpg w_a646643 w_d19a884 w_1eafe46 w_b0e05b1 w_d36f58c\n"
          ]
        }
      ]
    },
    {
      "id": "698ddcec-b04c-4743-85bb-fb9b4a3e1b9d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Image-gallery pipeline inference (DBA, QE OFF) with corrected tau grid and tau_offset=0.0 (per expert backup plan)\n",
        "from pathlib import Path\n",
        "ckpts = [f'model_fold{k}_best.pth' for k in range(5)]\n",
        "out_csv = run_full_inference_image_gallery(\n",
        "    ckpt_paths=ckpts,\n",
        "    out_csv='submission.csv',\n",
        "    tta_hflip=True,\n",
        "    enable_dba=True, dba_M=5, dba_lambda=0.2,\n",
        "    enable_qe=False,\n",
        "    tau_offset=0.0,\n",
        "    margin=0.0, ratio=0.0\n",
        ")\n",
        "print('submission.csv exists?', Path(out_csv).exists())\n",
        "print('submission.csv size:', Path(out_csv).stat().st_size if Path(out_csv).exists() else -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "2264adfd-35e3-4507-9459-78af39b6c61b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Image-gallery inference v2 with explicit tau_grid override and diagnostics\n",
        "import numpy as np, math, time, gc, os, pandas as pd, torch\n",
        "from collections import OrderedDict\n",
        "from pathlib import Path\n",
        "\n",
        "def run_full_inference_image_gallery_v2(\n",
        "    ckpt_paths,\n",
        "    out_csv='submission.csv',\n",
        "    tta_hflip=True,\n",
        "    enable_dba=True, dba_M=5, dba_lambda=0.2,\n",
        "    enable_qe=False, qe_L=0, qe_lambda=0.0,\n",
        "    tau_offset=0.0,\n",
        "    margin=0.0, ratio=0.0,\n",
        "    tau_grid_override=None,\n",
        "):\n",
        "    t0_all = time.time()\n",
        "    folds_df = pd.read_csv('folds_grouped.csv')\n",
        "    folds_df['image_path'] = (Path('train')/folds_df['Image']).astype(str)\n",
        "    train_all = folds_df[folds_df['Id']!='new_whale'].copy()\n",
        "    ids_all = sorted(train_all['Id'].unique().tolist())\n",
        "    n_classes = len(ids_all)\n",
        "    model = Net(n_classes=n_classes).to(device).eval().to(memory_format=torch.channels_last)\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    test_df = pd.DataFrame({'Image': ss['Image']})\n",
        "    test_df['image_path'] = (Path('test')/test_df['Image']).astype(str)\n",
        "\n",
        "    gal_feat_sum = None\n",
        "    gal_labels = train_all['Id'].tolist()\n",
        "    gal_paths = train_all['image_path'].tolist()\n",
        "    test_feat_sum = None\n",
        "    val_feat_sums = {}\n",
        "    val_labels_per_fold = {}\n",
        "    n_loaded = 0\n",
        "    for fold_i, ck in enumerate(ckpt_paths):\n",
        "        if not os.path.exists(ck):\n",
        "            print(f'[Infer-IMG-v2] Skip missing ckpt: {ck}')\n",
        "            continue\n",
        "        state, _ = load_ckpt(ck)\n",
        "        model_state = model.state_dict()\n",
        "        filtered = OrderedDict((k,v) for k,v in state.items() if k in model_state and tuple(model_state[k].shape)==tuple(v.shape))\n",
        "        _ = model.load_state_dict(filtered, strict=False)\n",
        "        feats_gal, _, _ = extract_feats_bnneck(model, train_all, tta_hflip=tta_hflip)\n",
        "        gal_feat_sum = feats_gal.astype('float32') if gal_feat_sum is None else gal_feat_sum + feats_gal.astype('float32')\n",
        "        feats_te, _, _ = extract_feats_bnneck(model, test_df.assign(Id='dummy'), tta_hflip=tta_hflip)\n",
        "        test_feat_sum = feats_te.astype('float32') if test_feat_sum is None else test_feat_sum + feats_te.astype('float32')\n",
        "        va_df = folds_df[folds_df['fold']==fold_i].copy()\n",
        "        feats_va, _, labs_va = extract_feats_bnneck(model, va_df, tta_hflip=tta_hflip)\n",
        "        if fold_i not in val_feat_sums:\n",
        "            val_feat_sums[fold_i] = feats_va.astype('float32')\n",
        "            val_labels_per_fold[fold_i] = list(labs_va)\n",
        "        else:\n",
        "            val_feat_sums[fold_i] += feats_va.astype('float32')\n",
        "        n_loaded += 1\n",
        "        gc.collect()\n",
        "    if n_loaded == 0:\n",
        "        raise RuntimeError('No checkpoints processed; cannot run inference.')\n",
        "    gal_mat_raw = l2_normalize(gal_feat_sum / n_loaded, axis=1).astype('float32')\n",
        "    test_mat = l2_normalize(test_feat_sum / n_loaded, axis=1).astype('float32')\n",
        "    for f in val_feat_sums.keys():\n",
        "        val_feat_sums[f] = l2_normalize(val_feat_sums[f] / n_loaded, axis=1).astype('float32')\n",
        "    assert gal_mat_raw.shape[0] == len(gal_labels)\n",
        "    # Sanity: L2 norms\n",
        "    gal_norms = np.linalg.norm(gal_mat_raw, axis=1)\n",
        "    te_norms = np.linalg.norm(test_mat, axis=1)\n",
        "    assert np.max(np.abs(gal_norms - 1.0)) < 1e-3, f'Gallery not L2-normalized: max|norm-1|={np.max(np.abs(gal_norms-1.0)):.3e}'\n",
        "    assert np.max(np.abs(te_norms - 1.0)) < 1e-3, f'Test not L2-normalized: max|norm-1|={np.max(np.abs(te_norms-1.0)):.3e}'\n",
        "\n",
        "    print('[Infer-IMG-v2] Starting leak-free per-fold tau calibration...')\n",
        "    train_all_idx = train_all.reset_index(drop=True)\n",
        "    gal_labels_arr = np.array(gal_labels, dtype=object)\n",
        "    gallery_fold_indices = train_all_idx['fold'].values\n",
        "    taus_best = []\n",
        "    fold_scores = []\n",
        "    for f in sorted(val_feat_sums.keys()):\n",
        "        sub_mask = (gallery_fold_indices != f)\n",
        "        gal_sub = gal_mat_raw[sub_mask]\n",
        "        labels_sub = gal_labels_arr[sub_mask].tolist()\n",
        "        gal_sub_dba = dba_smooth(gal_sub, M=dba_M, lam=dba_lambda) if enable_dba else gal_sub\n",
        "        index_sub = build_index_ip(gal_sub_dba)\n",
        "        q = val_feat_sums[f]\n",
        "        labs = val_labels_per_fold[f]\n",
        "        sims_all, idxs_all = index_sub.search(q, min(50, index_sub.ntotal))\n",
        "        truths = [lab if lab in set(labels_sub) else 'new_whale' for lab in labs]\n",
        "        # Diagnostics for s1 scale + grid selection\n",
        "        s1 = sims_all[:,0] if sims_all.size>0 else np.array([], dtype=np.float32)\n",
        "        if s1.size > 0:\n",
        "            q25, q50, q75 = np.quantile(s1, [0.25, 0.50, 0.75])\n",
        "        else:\n",
        "            q25=q50=q75=0.0\n",
        "        if tau_grid_override is not None:\n",
        "            tau_grid_fold = np.array(list(tau_grid_override), dtype=float)\n",
        "        else:\n",
        "            if s1.size > 0:\n",
        "                p10, p90 = np.quantile(s1, [0.10, 0.90])\n",
        "                lo = float(max(0.0, min(1.0, p10 - 0.01)))\n",
        "                hi = float(max(0.0, min(1.0, p90 + 0.01)))\n",
        "                if hi <= lo:\n",
        "                    lo, hi = 0.55, 0.75\n",
        "                tau_grid_fold = np.arange(lo, hi + 1e-9, 0.001)\n",
        "            else:\n",
        "                tau_grid_fold = np.arange(0.55, 0.75, 0.005)\n",
        "        print(f\"[OOF-fold-img-v2] f={f} s1 q25/q50/q75={q25:.3f}/{q50:.3f}/{q75:.3f} | grid={tau_grid_fold[0]:.3f}-{tau_grid_fold[-1]:.3f} (n={len(tau_grid_fold)})\", flush=True)\n",
        "        best_tau_f, best_sc_f = None, -1.0\n",
        "        for tau in tau_grid_fold:\n",
        "            preds = []\n",
        "            for i in range(q.shape[0]):\n",
        "                nei_idx = idxs_all[i]; nei_sims = sims_all[i]\n",
        "                nei_ids = [labels_sub[j] for j in nei_idx]\n",
        "                # vote-by-ID\n",
        "                scores_map = {}\n",
        "                for lab2, sim in zip(nei_ids, nei_sims):\n",
        "                    scores_map[lab2] = scores_map.get(lab2, 0.0) + math.exp(ALPHA * float(sim))\n",
        "                ordered = [k for k,_ in sorted(scores_map.items(), key=lambda x: -x[1])]\n",
        "                s1i = float(nei_sims[0]) if len(nei_sims)>0 else -1.0\n",
        "                s2i = float(nei_sims[1]) if len(nei_sims)>1 else s1i\n",
        "                top5 = []\n",
        "                if (len(nei_sims)>0 and s1i < tau) or (len(nei_sims)>1 and (s1i - s2i) < margin) or (len(nei_sims)>1 and (s1i/max(s2i,1e-6)) < ratio):\n",
        "                    top5.append('new_whale')\n",
        "                for lab2 in ordered:\n",
        "                    if lab2 not in top5: top5.append(lab2)\n",
        "                    if len(top5)==5: break\n",
        "                if len(top5)<5: top5 += ['__DUMMY__']*(5-len(top5))  # dummy padding during calib\n",
        "                preds.append(top5[:5])\n",
        "            sc = map5_score(preds, truths)\n",
        "            if sc > best_sc_f:\n",
        "                best_sc_f, best_tau_f = sc, float(tau)\n",
        "        taus_best.append(best_tau_f if best_tau_f is not None else float(np.median(tau_grid_fold)))\n",
        "        fold_scores.append(best_sc_f if best_sc_f is not None else 0.0)\n",
        "        print(f'[OOF-fold-img-v2] f={f} tau*={taus_best[-1]:.3f} score={fold_scores[-1]:.4f}')\n",
        "\n",
        "    tau_global = float(np.median(taus_best))\n",
        "    mean_oof = float(np.mean(fold_scores))\n",
        "    tau_global = float(np.clip(tau_global + float(tau_offset), 0.0, 1.0))\n",
        "    print(f'[OOF-img-v2] mean MAP@5={mean_oof:.4f} | median tau={tau_global:.3f} (after offset={float(tau_offset):.4f})')\n",
        "\n",
        "    # Build final gallery and perform final inference WITHOUT global override and WITHOUT test quantile gate\n",
        "    gal_mat = dba_smooth(gal_mat_raw, M=dba_M, lam=dba_lambda) if enable_dba else gal_mat_raw\n",
        "    index = build_index_ip(gal_mat)\n",
        "\n",
        "    # QE for final inference (conditional if enabled)\n",
        "    if enable_qe and qe_L>0 and qe_lambda>0:\n",
        "        test_q = query_expansion(index, gal_mat, test_mat, L=qe_L, lam=qe_lambda, conditional_tau=tau_global)\n",
        "    else:\n",
        "        test_q = test_mat\n",
        "\n",
        "    sims_all, idxs_all = index.search(test_q, min(50, index.ntotal))\n",
        "    pred_rows = []\n",
        "    new_first = 0\n",
        "    for i in range(test_q.shape[0]):\n",
        "        nei_idx = idxs_all[i]; nei_sims = sims_all[i]\n",
        "        nei_ids = [gal_labels[j] for j in nei_idx]\n",
        "        scores_map = {}\n",
        "        for lab, sim in zip(nei_ids, nei_sims):\n",
        "            scores_map[lab] = scores_map.get(lab, 0.0) + math.exp(ALPHA * float(sim))\n",
        "        ordered = [k for k,_ in sorted(scores_map.items(), key=lambda x:-x[1])]\n",
        "        s1 = float(nei_sims[0]) if len(nei_sims)>0 else -1.0\n",
        "        s2 = float(nei_sims[1]) if len(nei_sims)>1 else s1\n",
        "        top5 = []\n",
        "        if (len(nei_sims)>0 and s1 < tau_global) or (len(nei_sims)>1 and (s1 - s2) < margin) or (len(nei_sims)>1 and (s1/max(s2,1e-6)) < ratio):\n",
        "            top5.append('new_whale')\n",
        "        for lab2 in ordered:\n",
        "            if lab2 not in top5: top5.append(lab2)\n",
        "            if len(top5)==5: break\n",
        "        if len(top5)<5: top5 += ['new_whale']*(5-len(top5))\n",
        "        if len(top5)>0 and top5[0]=='new_whale': new_first += 1\n",
        "        pred_rows.append(' '.join(top5[:5]))\n",
        "    nh_rate = 100.0 * new_first / max(1, len(test_df))\n",
        "    print(f'[Infer-IMG-v2] Test new_whale@1={nh_rate:.2f}% | tau={tau_global:.3f}')\n",
        "\n",
        "    sub = pd.DataFrame({'Image': ss['Image'], 'Id': pred_rows})\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print('Wrote (IMG-v2) ', out_csv, 'shape', sub.shape, 'elapsed', f'{time.time()-t0_all:.1f}s')\n",
        "    print(sub.head().to_string(index=False))\n",
        "    return out_csv\n",
        "\n",
        "# Example run (execute in a separate cell):\n",
        "# out_csv = run_full_inference_image_gallery_v2(\n",
        "#     ckpt_paths=[f'model_fold{k}_best.pth' for k in range(5)],\n",
        "#     out_csv='submission.csv',\n",
        "#     tta_hflip=True,\n",
        "#     enable_dba=True, dba_M=5, dba_lambda=0.2,\n",
        "#     enable_qe=False,\n",
        "#     tau_offset=0.0,\n",
        "#     margin=0.0, ratio=0.0,\n",
        "#     tau_grid_override=np.arange(0.55, 0.75, 0.005),\n",
        "# )"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "id": "238a647e-acd8-4cb3-b918-bbd851a01db6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Execute image-gallery v2 with expert backup params (stabilized gating)\n",
        "ckpts = [f'model_fold{k}_best.pth' for k in range(5)]\n",
        "out_csv = run_full_inference_image_gallery_v2(\n",
        "    ckpt_paths=ckpts,\n",
        "    out_csv='submission.csv',\n",
        "    tta_hflip=True,\n",
        "    enable_dba=True, dba_M=8, dba_lambda=0.3,\n",
        "    enable_qe=False, qe_L=0, qe_lambda=0.0,\n",
        "    tau_offset=-0.05,\n",
        "    margin=0.02, ratio=1.04,\n",
        "    tau_grid_override=np.arange(0.35, 0.55, 0.005),\n",
        ")\n",
        "from pathlib import Path\n",
        "print('submission.csv exists?', Path(out_csv).exists())\n",
        "print('submission.csv size:', Path(out_csv).stat().st_size if Path(out_csv).exists() else -1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7504/1135787474.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 40, 13.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 60, 20.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 80, 26.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 100, 32.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 40, 13.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7504/1135787474.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 40, 14.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 60, 20.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 80, 26.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 100, 32.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 40, 13.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7504/1135787474.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 40, 14.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 60, 20.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 80, 26.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 100, 32.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 40, 14.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7504/1135787474.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 40, 13.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 60, 20.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 80, 26.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 100, 32.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 40, 13.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_7504/1135787474.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 40, 14.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 60, 20.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 80, 26.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 100, 32.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 40, 13.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE bi 20, 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-IMG-v2] Starting leak-free per-fold tau calibration...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-fold-img-v2] f=0 s1 q25/q50/q75=0.411/0.422/0.439 | grid=0.350-0.550 (n=41)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-fold-img-v2] f=0 tau*=0.350 score=0.5828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-fold-img-v2] f=1 s1 q25/q50/q75=0.495/0.502/0.510 | grid=0.350-0.550 (n=41)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-fold-img-v2] f=1 tau*=0.350 score=0.5838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-fold-img-v2] f=2 s1 q25/q50/q75=0.469/0.475/0.480 | grid=0.350-0.550 (n=41)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-fold-img-v2] f=2 tau*=0.350 score=0.5670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-fold-img-v2] f=3 s1 q25/q50/q75=0.387/0.415/0.437 | grid=0.350-0.550 (n=41)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-fold-img-v2] f=3 tau*=0.425 score=0.5795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-fold-img-v2] f=4 s1 q25/q50/q75=0.439/0.443/0.448 | grid=0.350-0.550 (n=41)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-fold-img-v2] f=4 tau*=0.350 score=0.5625\n[OOF-img-v2] mean MAP@5=0.5751 | median tau=0.300 (after offset=-0.0500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-IMG-v2] Test new_whale@1=99.50% | tau=0.300\nWrote (IMG-v2)  submission.csv shape (2610, 2) elapsed 292.1s\n       Image                                                Id\n00087b01.jpg new_whale w_d9aab0a w_3b0894d w_b942708 w_7c7a78c\n0014cfdf.jpg new_whale w_3e0f25d w_a74742c w_ea6651e w_0e4ef50\n0035632e.jpg new_whale w_b942708 w_da2efe0 w_511c464 w_3a7d86d\n004c5fb9.jpg new_whale w_17ee910 w_da2efe0 w_b942708 w_cf00b01\n00863b8c.jpg new_whale w_1eafe46 w_d36f58c w_64f3545 w_3f2a05c\nsubmission.csv exists? True\nsubmission.csv size: 164439\n"
          ]
        }
      ]
    },
    {
      "id": "a12a10e3-2ff2-4699-bd41-f31351241a45",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Override: use high-range tau grid for prototype similarity scale (BNNeck+DBA ~0.95-1.00)\n",
        "import numpy as np\n",
        "\n",
        "def _build_dynamic_tau_grid_from_s1(s1_vals, lo_floor=0.90, hi_cap=0.999, pad=0.01, step=0.001):\n",
        "    v = s1_vals[np.isfinite(s1_vals)]\n",
        "    v = v[v > 0]\n",
        "    if v.size > 0:\n",
        "        p10, p90 = np.quantile(v, [0.10, 0.90])\n",
        "        lo = max(lo_floor, float(p10) - pad)\n",
        "        hi = min(hi_cap, float(p90) + pad)\n",
        "        if hi > lo:\n",
        "            return np.arange(lo, hi + 1e-9, step)\n",
        "    return np.arange(lo_floor, hi_cap + 1e-9, step)\n",
        "\n",
        "print('[Patch] _build_dynamic_tau_grid_from_s1 set to high-range [0.90, 0.999] with step=0.001')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}