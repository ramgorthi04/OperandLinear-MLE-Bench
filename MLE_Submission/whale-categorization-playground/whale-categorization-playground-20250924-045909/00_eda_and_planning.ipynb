{
  "cells": [
    {
      "id": "b9fe25e6-5367-4b1a-a693-05561928bc30",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Humpback Whale Identification - Plan\n",
        "\n",
        "Objectives:\n",
        "- Build a strong baseline fast and iterate to medal territory (MAP@5).\n",
        "\n",
        "High-level plan:\n",
        "1) Environment & sanity checks\n",
        "   - Verify GPU availability (nvidia-smi).\n",
        "   - Only install CUDA 12.1 torch stack when we are ready to train.\n",
        "\n",
        "2) Data understanding\n",
        "   - Inspect train.csv, sample_submission.csv, image folders (/train, /test).\n",
        "   - Confirm label distribution and class cardinality.\n",
        "   - Determine if there are any duplicates or near-duplicates.\n",
        "\n",
        "3) Validation\n",
        "   - Stratified KFold on target label to mirror test distribution.\n",
        "   - Fix a single deterministic CV split and reuse.\n",
        "\n",
        "4) Baseline modeling (fast)\n",
        "   - Start with timm backbone (e.g., efficientnet_b0 or resnet18/34) at 224-256 px.\n",
        "   - Loss: CE with label smoothing; metric: MAP@5.\n",
        "   - Augmentations: light (RandomResizedCrop/CenterCrop, flips, brightness/contrast).\n",
        "   - Mixed precision + cosine LR + warmup; early stopping by CV.\n",
        "\n",
        "5) Improve\n",
        "   - Scale up backbone (efficientnet_b3/b4, convnext_tiny), resolution 384+.\n",
        "   - Use ArcFace/CosFace head (metric learning) or logits ensembling across seeds.\n",
        "   - Hard mining / class-balanced sampling if long-tail severe.\n",
        "\n",
        "6) Ensembling\n",
        "   - Blend diverse models/seeds/resolutions using OOF-driven weights.\n",
        "\n",
        "7) Submission\n",
        "   - Generate top-5 per image; verify format against sample_submission.\n",
        "\n",
        "Checkpoints for expert reviews:\n",
        "- After this plan, after EDA, after first baseline CV, after tuning/ensembling.\n",
        "\n",
        "Time discipline:\n",
        "- Always print progress and elapsed time.\n",
        "- Subsample smoke runs first (e.g., 2 folds, few epochs) before full training."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "67157285-e5d9-49e2-9224-e61f08846556",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, time, subprocess, json, textwrap\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def run(cmd):\n",
        "    print(\">>>\", \" \".join(cmd), flush=True)\n",
        "    try:\n",
        "        out = subprocess.check_output(cmd, stderr=subprocess.STDOUT).decode(\"utf-8\", errors=\"ignore\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        out = e.output.decode(\"utf-8\", errors=\"ignore\")\n",
        "    print(out, flush=True)\n",
        "    return out\n",
        "\n",
        "t0 = time.time()\n",
        "print(\"[Env] Checking GPU (nvidia-smi)...\", flush=True)\n",
        "run([\"bash\",\"-lc\",\"nvidia-smi || true\"])\n",
        "\n",
        "print(\"[Env] Python:\", sys.version)\n",
        "print(\"[Env] CWD:\", os.getcwd())\n",
        "\n",
        "print(\"[FS] Listing key files:\")\n",
        "for p in [\"train.csv\", \"sample_submission.csv\", \"submission.csv\", \"train\", \"test\"]:\n",
        "    pp = Path(p)\n",
        "    if pp.is_file():\n",
        "        print(f\" - {p} file size={pp.stat().st_size:,}\")\n",
        "    elif pp.is_dir():\n",
        "        cnt = sum(1 for _ in pp.iterdir())\n",
        "        print(f\" - {p} dir entries={cnt}\")\n",
        "\n",
        "print(\"[Data] Loading CSVs...\")\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "sub = pd.read_csv(\"sample_submission.csv\")\n",
        "print(\"train.shape:\", train.shape)\n",
        "print(\"train.head():\\n\", train.head())\n",
        "print(\"sample_submission.shape:\", sub.shape)\n",
        "print(\"sample_submission.head():\\n\", sub.head())\n",
        "\n",
        "# Basic schema expectations\n",
        "print(\"[Data] Columns:\", train.columns.tolist())\n",
        "img_col = None\n",
        "label_col = None\n",
        "for c in train.columns:\n",
        "    if c.lower() in (\"image\",\"img\",\"filename\",\"file\",\"file_name\"):\n",
        "        img_col = c\n",
        "    if c.lower() in (\"id\",\"label\",\"target\",\"species\"):\n",
        "        label_col = c\n",
        "if img_col is None:\n",
        "    # Heuristic: first column is image\n",
        "    img_col = train.columns[0]\n",
        "if label_col is None and len(train.columns) > 1:\n",
        "    label_col = train.columns[1]\n",
        "print(f\"[Data] Using columns -> image: {img_col}, label: {label_col}\")\n",
        "\n",
        "n_classes = train[label_col].nunique() if label_col in train.columns else None\n",
        "print(\"[Data] n_images:\", len(train), \"n_classes:\", n_classes)\n",
        "print(\"[Data] Label distribution (top 10):\\n\", train[label_col].value_counts().head(10))\n",
        "\n",
        "# Quick file existence check for a few samples\n",
        "train_dir = Path(\"train\")\n",
        "missing = 0\n",
        "for fn in train[img_col].head(5):\n",
        "    if not (train_dir / fn).exists():\n",
        "        missing += 1\n",
        "print(f\"[FS] Missing first-5 images present? missing={missing}\")\n",
        "\n",
        "print(f\"[Done] Prep EDA in {time.time()-t0:.2f}s\", flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "10a8e91c-1fda-4b36-9861-b2314c23c6d5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup: Install CUDA 12.1 PyTorch stack and deps\n",
        "import os, sys, subprocess, shutil, time\n",
        "from pathlib import Path\n",
        "\n",
        "def pip(*args):\n",
        "    print(\">\", *args, flush=True)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", *args], check=True)\n",
        "\n",
        "# Uninstall any pre-existing torch stack to avoid conflicts\n",
        "for pkg in (\"torch\",\"torchvision\",\"torchaudio\"):\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg], check=False)\n",
        "\n",
        "# Clean stray site dirs that can shadow correct wheels (idempotent)\n",
        "for d in (\n",
        "    \"/app/.pip-target/torch\",\n",
        "    \"/app/.pip-target/torch-2.8.0.dist-info\",\n",
        "    \"/app/.pip-target/torch-2.4.1.dist-info\",\n",
        "    \"/app/.pip-target/torchvision\",\n",
        "    \"/app/.pip-target/torchvision-0.23.0.dist-info\",\n",
        "    \"/app/.pip-target/torchvision-0.19.1.dist-info\",\n",
        "    \"/app/.pip-target/torchaudio\",\n",
        "    \"/app/.pip-target/torchaudio-2.8.0.dist-info\",\n",
        "    \"/app/.pip-target/torchaudio-2.4.1.dist-info\",\n",
        "    \"/app/.pip-target/torchgen\",\n",
        "    \"/app/.pip-target/functorch\",\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print(\"Removing\", d)\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# Install EXACT cu121 torch stack\n",
        "pip(\"install\",\n",
        "    \"--index-url\", \"https://download.pytorch.org/whl/cu121\",\n",
        "    \"--extra-index-url\", \"https://pypi.org/simple\",\n",
        "    \"torch==2.4.1\", \"torchvision==0.19.1\", \"torchaudio==2.4.1\")\n",
        "\n",
        "# Freeze torch versions\n",
        "Path(\"constraints.txt\").write_text(\"\\n\".join([\n",
        "    \"torch==2.4.1\",\n",
        "    \"torchvision==0.19.1\",\n",
        "    \"torchaudio==2.4.1\",\n",
        "]))\n",
        "\n",
        "# Install non-torch deps honoring constraints\n",
        "pip(\"install\", \"-c\", \"constraints.txt\",\n",
        "    \"timm==1.0.9\",\n",
        "    \"albumentations==1.4.14\",\n",
        "    \"opencv-python-headless==4.10.0.84\",\n",
        "    \"scikit-learn==1.5.1\",\n",
        "    \"pandas==2.2.2\",\n",
        "    \"numpy==1.26.4\",\n",
        "    \"faiss-cpu==1.8.0.post1\",\n",
        "    \"torchmetrics==1.4.2\",\n",
        "    \"accelerate==0.34.2\",\n",
        "    \"rich==13.8.1\",\n",
        "    \"matplotlib==3.9.2\",\n",
        "    \"seaborn==0.13.2\",\n",
        "    \"--upgrade-strategy\", \"only-if-needed\")\n",
        "\n",
        "# Sanity check GPU\n",
        "import torch\n",
        "print(\"torch:\", torch.__version__, \"built CUDA:\", getattr(torch.version, \"cuda\", None))\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "assert str(getattr(torch.version, \"cuda\", \"\")).startswith(\"12.1\"), f\"Wrong CUDA build: {torch.version.cuda}\"\n",
        "assert torch.cuda.is_available(), \"CUDA not available\"\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "print(\"[Setup] Done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "80dfb7d8-b23a-4ee9-85df-85995bea89bc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build 5-fold stratified splits with singleton handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "df = pd.read_csv('train.csv')\n",
        "img_col, label_col = 'Image', 'Id'\n",
        "\n",
        "# Identify singleton classes (excluding 'new_whale')\n",
        "vc = df[label_col].value_counts()\n",
        "is_singleton = df[label_col].map(vc) == 1\n",
        "singleton_mask = is_singleton & (df[label_col] != 'new_whale')\n",
        "n_singleton = int(singleton_mask.sum())\n",
        "print(f\"Singleton (train-only) classes (excl. new_whale): {n_singleton}\")\n",
        "\n",
        "# Rows eligible for stratified CV\n",
        "eligible_mask = ~singleton_mask\n",
        "df_elig = df.loc[eligible_mask].copy()\n",
        "\n",
        "# Stratified by label to preserve distribution (including new_whale)\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "folds = np.full(len(df), -1, dtype=int)  # default -1 for train-only\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(df_elig[img_col], df_elig[label_col])):\n",
        "    va_indices_global = df_elig.index.values[va_idx]\n",
        "    folds[va_indices_global] = fold\n",
        "\n",
        "df_folds = df.copy()\n",
        "df_folds['fold'] = folds  # -1 means never used as validation (train-only)\n",
        "df_folds['use_in_val'] = df_folds['fold'] >= 0\n",
        "\n",
        "# Sanity logs\n",
        "print(df_folds['fold'].value_counts(dropna=False).sort_index())\n",
        "for f in range(n_splits):\n",
        "    val_mask = df_folds['fold'] == f\n",
        "    print(f\"Fold {f}: val n={val_mask.sum()} (incl. new_whale {(df_folds.loc[val_mask, label_col]=='new_whale').sum()})\")\n",
        "print(f\"Train-only rows (fold=-1): {(df_folds['fold'] == -1).sum()}\")\n",
        "\n",
        "# Save folds\n",
        "out_path = Path('folds.csv')\n",
        "df_folds.to_csv(out_path, index=False)\n",
        "print(f\"Saved folds to {out_path.resolve()} in {time.time()-t0:.2f}s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "94704351-b4e3-492f-aba5-9032dc7bcaff",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Utils: dataset, transforms, ArcFace head, model wrapper, sampler\n",
        "import math, random, time, os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import timm\n",
        "\n",
        "cv2.setNumThreads(0)\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "\n",
        "IM_DIR_TRAIN = Path('train')\n",
        "IM_DIR_TEST = Path('test')\n",
        "\n",
        "def build_transforms(size=384, train=True):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.RandomResizedCrop(size, size, scale=(0.8, 1.0), ratio=(0.75, 1.33), p=1.0),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.ColorJitter(0.2,0.2,0.2,0.1,p=0.3),\n",
        "            A.Rotate(limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.2),\n",
        "            A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.LongestMaxSize(max_size=size),\n",
        "            A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
        "            A.CenterCrop(size, size),\n",
        "            A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "\n",
        "class ImageDS(Dataset):\n",
        "    def __init__(self, df, img_col='Image', label_col='Id', img_dir=IM_DIR_TRAIN, tfm=None, label2idx=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_col = img_col\n",
        "        self.label_col = label_col\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.tfm = tfm\n",
        "        self.label2idx = label2idx\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        img_path = self.img_dir / row[self.img_col]\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if self.tfm:\n",
        "            img = self.tfm(image=img)['image']\n",
        "        if self.label2idx is not None:\n",
        "            id_ = row[self.label_col]\n",
        "            tgt = self.label2idx.get(id_, -1)\n",
        "            return img, tgt\n",
        "        return img, row[self.img_col]\n",
        "\n",
        "class ArcMarginProduct(nn.Module):\n",
        "    def __init__(self, in_features, out_features, s=30.0, m=0.5, easy_margin=False):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = math.cos(m)\n",
        "        self.sin_m = math.sin(m)\n",
        "        self.th = math.cos(math.pi - m)\n",
        "        self.mm = math.sin(math.pi - m) * m\n",
        "    def forward(self, embeddings, labels):\n",
        "        # embeddings: (B, in_features) L2-normalized\n",
        "        # labels: (B,)\n",
        "        cosine = torch.matmul(embeddings, self.weight.t())\n",
        "        sine = torch.sqrt(torch.clamp(1.0 - cosine**2, min=1e-9))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if not self.easy_margin:\n",
        "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = torch.zeros_like(cosine)\n",
        "        one_hot.scatter_(1, labels.view(-1,1), 1.0)\n",
        "        logits = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        logits = logits * self.s\n",
        "        return logits\n",
        "\n",
        "class EmbeddingModel(nn.Module):\n",
        "    def __init__(self, backbone_name='convnext_tiny', embed_dim=512, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0, global_pool='avg')\n",
        "        feat_dim = self.backbone.num_features\n",
        "        self.head = nn.Linear(feat_dim, embed_dim, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(embed_dim)\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x)\n",
        "        e = self.head(f)\n",
        "        e = self.bn(e)\n",
        "        e = nn.functional.normalize(e, p=2, dim=1)\n",
        "        return e\n",
        "\n",
        "def make_balanced_sampler(labels, pow_k=0.5):\n",
        "    # labels: numpy array of class indices (>=0) for rows used in training\n",
        "    vc = pd.Series(labels).value_counts().to_dict()\n",
        "    weights = np.array([1.0 / (vc[int(y)] ** pow_k) for y in labels], dtype=np.float32)\n",
        "    return WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "\n",
        "def build_label_mapping(train_df, label_col='Id'):\n",
        "    ids = sorted(x for x in train_df[label_col].unique().tolist() if x != 'new_whale')\n",
        "    label2idx = {lbl:i for i,lbl in enumerate(ids)}\n",
        "    idx2label = {i:lbl for lbl,i in label2idx.items()}\n",
        "    return label2idx, idx2label\n",
        "\n",
        "print('[Utils] Loaded utilities: transforms, dataset, ArcFace head, model wrapper, sampler, label mapping.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "73ac301a-c24b-47db-9ffd-a967f8562455",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fix albumentations/albucore compatibility\n",
        "import sys, subprocess\n",
        "def pip(*args):\n",
        "    print(\">\", *args, flush=True)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", *args], check=True)\n",
        "\n",
        "# Upgrade albucore to a version providing preserve_channel_dim\n",
        "pip(\"install\", \"-c\", \"constraints.txt\", \"albucore==0.0.12\", \"--upgrade-strategy\", \"only-if-needed\")\n",
        "import albucore, albumentations\n",
        "import importlib, inspect\n",
        "import albucore.utils as acu\n",
        "print(\"albumentations:\", albumentations.__version__, \"albucore:\", albucore.__version__)\n",
        "print(\"has preserve_channel_dim:\", hasattr(acu, \"preserve_channel_dim\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f00e24de-a1ad-498f-ba0c-b9df12b3f9cc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Bump albucore/albumentations to compatible versions\n",
        "import sys, subprocess, importlib\n",
        "def pip(*args):\n",
        "    print(\">\", *args, flush=True)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", *args], check=True)\n",
        "\n",
        "# Upgrade to versions that include preserve_channel_dim\n",
        "pip(\"install\", \"-c\", \"constraints.txt\", \"albucore>=0.0.20\", \"albumentations>=1.4.20\", \"--upgrade\")\n",
        "import albucore, albumentations\n",
        "from importlib import reload\n",
        "import albucore.utils as acu\n",
        "print(\"albumentations:\", albumentations.__version__, \"albucore:\", albucore.__version__)\n",
        "print(\"has preserve_channel_dim:\", hasattr(acu, \"preserve_channel_dim\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "e2c5cdde-feba-41d0-96f1-61671dea9b24",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Override utils to avoid albumentations: use torchvision transforms + PIL\n",
        "import math, random, time, os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "import timm\n",
        "\n",
        "IM_DIR_TRAIN = Path('train')\n",
        "IM_DIR_TEST = Path('test')\n",
        "\n",
        "def build_transforms(size=384, train=True):\n",
        "    if train:\n",
        "        return T.Compose([\n",
        "            T.RandomResizedCrop(size, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
        "            T.RandomHorizontalFlip(p=0.5),\n",
        "            T.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "            T.RandomRotation(degrees=15, interpolation=T.InterpolationMode.BILINEAR),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "            T.RandomErasing(p=0.15, scale=(0.02, 0.15), ratio=(0.3, 3.3), value='random'),\n",
        "        ])\n",
        "    else:\n",
        "        return T.Compose([\n",
        "            T.Resize(int(size*1.15), interpolation=T.InterpolationMode.BILINEAR),\n",
        "            T.CenterCrop(size),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ])\n",
        "\n",
        "class ImageDS(Dataset):\n",
        "    def __init__(self, df, img_col='Image', label_col='Id', img_dir=IM_DIR_TRAIN, tfm=None, label2idx=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_col = img_col\n",
        "        self.label_col = label_col\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.tfm = tfm\n",
        "        self.label2idx = label2idx\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        img_path = self.img_dir / row[self.img_col]\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert('RGB')\n",
        "            img = self.tfm(im) if self.tfm else T.ToTensor()(im)\n",
        "        if self.label2idx is not None:\n",
        "            id_ = row[self.label_col]\n",
        "            tgt = self.label2idx.get(id_, -1)\n",
        "            return img, tgt\n",
        "        return img, row[self.img_col]\n",
        "\n",
        "class ArcMarginProduct(nn.Module):\n",
        "    def __init__(self, in_features, out_features, s=30.0, m=0.5, easy_margin=False):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = math.cos(m)\n",
        "        self.sin_m = math.sin(m)\n",
        "        self.th = math.cos(math.pi - m)\n",
        "        self.mm = math.sin(math.pi - m) * m\n",
        "    def forward(self, embeddings, labels):\n",
        "        # normalize class weights (critical for ArcFace stability)\n",
        "        W = F.normalize(self.weight, p=2, dim=1)\n",
        "        cosine = F.linear(embeddings, W)\n",
        "        sine = torch.sqrt(torch.clamp(1.0 - cosine**2, min=1e-9))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if not self.easy_margin:\n",
        "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = torch.zeros_like(cosine)\n",
        "        one_hot.scatter_(1, labels.view(-1,1), 1.0)\n",
        "        logits = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        logits = logits * self.s\n",
        "        return logits\n",
        "\n",
        "class EmbeddingModel(nn.Module):\n",
        "    def __init__(self, backbone_name='convnext_tiny', embed_dim=512, pretrained=True, drop_path_rate=0.0):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(backbone_name, pretrained=pretrained, num_classes=0, global_pool='avg', drop_path_rate=drop_path_rate)\n",
        "        feat_dim = self.backbone.num_features\n",
        "        self.head = nn.Linear(feat_dim, embed_dim, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(embed_dim)\n",
        "    def forward(self, x):\n",
        "        f = self.backbone(x)\n",
        "        e = self.head(f)\n",
        "        e = self.bn(e)\n",
        "        e = nn.functional.normalize(e, p=2, dim=1)\n",
        "        return e\n",
        "\n",
        "def make_balanced_sampler(labels, pow_k=0.5):\n",
        "    vc = pd.Series(labels).value_counts().to_dict()\n",
        "    weights = np.array([1.0 / (vc[int(y)] ** pow_k) for y in labels], dtype=np.float32)\n",
        "    return WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "\n",
        "def build_label_mapping(train_df, label_col='Id'):\n",
        "    ids = sorted(x for x in train_df[label_col].unique().tolist() if x != 'new_whale')\n",
        "    label2idx = {lbl:i for i,lbl in enumerate(ids)}\n",
        "    idx2label = {i:lbl for lbl,i in label2idx.items()}\n",
        "    return label2idx, idx2label\n",
        "\n",
        "print('[Utils-TorchVision] Utilities ready: transforms (torchvision), dataset (PIL), ArcFace head (W-normalized), model, sampler, label mapping.')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Utils-TorchVision] Utilities ready: transforms (torchvision), dataset (PIL), ArcFace head (W-normalized), model, sampler, label mapping.\n"
          ]
        }
      ]
    },
    {
      "id": "db5289c6-be91-455d-9e6c-31d96a1f83cc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training + Embedding + Retrieval pipeline (ArcFace, convnext_tiny, torchvision transforms) - 5-fold OOF, tau on OOF, fold-ensemble, hflip TTA\n",
        "import os, time, math, json, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, SequentialLR, LinearLR\n",
        "import faiss\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    import random, os, numpy as np, torch\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def map5_score(y_true_ids, y_pred_ranked_ids):\n",
        "    assert len(y_true_ids) == len(y_pred_ranked_ids)\n",
        "    scores = []\n",
        "    for t, preds in zip(y_true_ids, y_pred_ranked_ids):\n",
        "        score = 0.0\n",
        "        for i, p in enumerate(preds[:5]):\n",
        "            if p == t:\n",
        "                score = 1.0 / (i+1)\n",
        "                break\n",
        "        scores.append(score)\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "def get_device():\n",
        "    return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def train_one_fold(fold, df_folds, img_size=384, epochs=12, batch_size=48, lr=3e-4, weight_decay=0.05, arc_s=30.0, arc_m=0.5, embed_dim=512):\n",
        "    t0 = time.time()\n",
        "    device = get_device()\n",
        "    val_mask = df_folds['fold'] == fold\n",
        "    train_mask = (df_folds['fold'] != fold)\n",
        "    df_tr = df_folds.loc[train_mask].copy()\n",
        "    df_va = df_folds.loc[val_mask].copy()\n",
        "    label2idx, idx2label = build_label_mapping(df_tr, label_col='Id')\n",
        "    n_classes = len(label2idx)\n",
        "    tfm_tr = build_transforms(size=img_size, train=True)\n",
        "    tfm_va = build_transforms(size=img_size, train=False)\n",
        "    ds_tr = ImageDS(df_tr, img_col='Image', label_col='Id', img_dir=IM_DIR_TRAIN, tfm=tfm_tr, label2idx=label2idx)\n",
        "    # Build sampler labels without loading images\n",
        "    y_tr = ds_tr.df['Id'].map(label2idx).fillna(-1).to_numpy()\n",
        "    train_indices = np.where(y_tr != -1)[0]\n",
        "    ds_tr_sub = Subset(ds_tr, train_indices)\n",
        "    y_sub = y_tr[train_indices]\n",
        "    sampler = make_balanced_sampler(y_sub, pow_k=0.5)\n",
        "    dl_tr = DataLoader(ds_tr_sub, batch_size=batch_size, sampler=sampler, num_workers=8, pin_memory=True, persistent_workers=True)\n",
        "    model = EmbeddingModel(backbone_name='convnext_tiny', embed_dim=embed_dim, pretrained=True).to(device)\n",
        "    arc = ArcMarginProduct(embed_dim, n_classes, s=arc_s, m=arc_m).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(list(model.parameters()) + list(arc.parameters()), lr=lr, weight_decay=weight_decay)\n",
        "    # 1-epoch linear warmup then cosine\n",
        "    main = CosineAnnealingLR(optimizer, T_max=max(1, epochs-1))\n",
        "    warm = LinearLR(optimizer, start_factor=0.1, end_factor=1.0, total_iters=1)\n",
        "    scheduler = SequentialLR(optimizer, [warm, main], milestones=[1])\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train(); arc.train()\n",
        "        running = 0.0; n = 0; t_ep = time.time()\n",
        "        for it, (imgs, targets) in enumerate(dl_tr):\n",
        "            imgs = imgs.to(device, non_blocking=True); targets = targets.to(device)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                emb = model(imgs)\n",
        "                logits = arc(emb, targets)\n",
        "                loss = criterion(logits, targets)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            running += loss.item() * targets.size(0); n += targets.size(0)\n",
        "            if (it+1) % 50 == 0:\n",
        "                print(f\"[Fold {fold}] Epoch {ep} Iter {it+1} loss={running/max(n,1):.4f} elapsed={time.time()-t_ep:.1f}s\", flush=True)\n",
        "        scheduler.step()\n",
        "        print(f\"[Fold {fold}] Epoch {ep}/{epochs} tr_loss={running/max(n,1):.4f} lr={scheduler.get_last_lr()[0]:.6f}\")\n",
        "    os.makedirs('checkpoints', exist_ok=True)\n",
        "    torch.save({'model': model.state_dict(), 'arc': arc.state_dict(), 'label2idx': label2idx}, f'checkpoints/fold{fold}.pt')\n",
        "    print(f\"[Fold {fold}] Saved checkpoint. Total fold time {time.time()-t0:.1f}s\")\n",
        "    return model, label2idx, idx2label, df_tr, df_va\n",
        "\n",
        "def extract_embeddings(model, df, img_size=384, batch_size=64, img_dir=IM_DIR_TRAIN, tta_hflip=True):\n",
        "    device = get_device()\n",
        "    model.eval()\n",
        "    tfm = build_transforms(size=img_size, train=False)\n",
        "    ds = ImageDS(df, img_col='Image', label_col='Id', img_dir=img_dir, tfm=tfm, label2idx=None)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=True)\n",
        "    embs = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in dl:\n",
        "            imgs = imgs.to(device, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                e1 = model(imgs)\n",
        "                if tta_hflip:\n",
        "                    e2 = model(torch.flip(imgs, dims=[3]))\n",
        "                    e = (e1 + e2) / 2.0\n",
        "                else:\n",
        "                    e = e1\n",
        "            embs.append(e.detach().cpu().numpy())\n",
        "    embs = np.concatenate(embs, axis=0)\n",
        "    faiss.normalize_L2(embs)\n",
        "    return embs\n",
        "\n",
        "def per_class_max_similarity(query_embs, gallery_embs, gallery_labels, topK=300):\n",
        "    d = gallery_embs.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    index.add(gallery_embs.astype('float32'))\n",
        "    K = min(topK, gallery_embs.shape[0])\n",
        "    sims, idxs = index.search(query_embs.astype('float32'), K)\n",
        "    preds = []\n",
        "    for qi in range(query_embs.shape[0]):\n",
        "        best = {}\n",
        "        for j in range(K):\n",
        "            gi = int(idxs[qi, j]); s = float(sims[qi, j]); cls = gallery_labels[gi]\n",
        "            if cls not in best or s > best[cls]:\n",
        "                best[cls] = s\n",
        "        ranked = sorted(best.items(), key=lambda x: x[1], reverse=True)\n",
        "        preds.append(ranked)\n",
        "    return preds\n",
        "\n",
        "def tune_new_whale_threshold(val_ranked_lists, val_true_ids, grid=None):\n",
        "    if grid is None:\n",
        "        grid = np.linspace(0.2, 0.8, 61)\n",
        "    best_tau, best_map5 = 0.5, -1.0\n",
        "    for tau in grid:\n",
        "        top5 = []\n",
        "        for ranked in val_ranked_lists:\n",
        "            if len(ranked) == 0 or ranked[0][1] < tau:\n",
        "                cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "            else:\n",
        "                cand = [c for c,_ in ranked][:5]\n",
        "            uniq = []\n",
        "            for c in cand:\n",
        "                if c not in uniq:\n",
        "                    uniq.append(c)\n",
        "                if len(uniq) == 5:\n",
        "                    break\n",
        "            while len(uniq) < 5:\n",
        "                uniq.append('new_whale')\n",
        "            top5.append(uniq)\n",
        "        m = map5_score(val_true_ids, top5)\n",
        "        if m > best_map5:\n",
        "            best_map5, best_tau = m, tau\n",
        "    return best_tau, best_map5\n",
        "\n",
        "def combine_fold_scores(rank_lists_per_fold):\n",
        "    # rank_lists_per_fold: list of length n_folds, each is list len N of list[(cls, score)]\n",
        "    n_folds = len(rank_lists_per_fold)\n",
        "    N = len(rank_lists_per_fold[0])\n",
        "    combined = []\n",
        "    for i in range(N):\n",
        "        agg = defaultdict(list)\n",
        "        for f in range(n_folds):\n",
        "            for cls, s in rank_lists_per_fold[f][i]:\n",
        "                agg[cls].append(s)\n",
        "        # average per-class similarities across folds\n",
        "        scored = [(cls, float(np.mean(v))) for cls, v in agg.items()]\n",
        "        scored.sort(key=lambda x: x[1], reverse=True)\n",
        "        combined.append(scored)\n",
        "    return combined\n",
        "\n",
        "def run_full_5fold_pipeline(epochs=12, img_size=384, batch_size=48):\n",
        "    set_seed(42)\n",
        "    df = pd.read_csv('train.csv')\n",
        "    folds = pd.read_csv('folds.csv')\n",
        "    df_folds = df.merge(folds[['Image','fold']], on='Image', how='left')\n",
        "    device = get_device(); print('Device:', device)\n",
        "    oof_ranked = []; oof_true = []\n",
        "    test_df = pd.read_csv('sample_submission.csv')[['Image']].copy(); test_df['Id'] = 'new_whale'\n",
        "    te_ranked_folds = []\n",
        "    os.makedirs('embeddings', exist_ok=True)\n",
        "    for f in range(5):\n",
        "        print(f\"=== Training fold {f} ===\", flush=True)\n",
        "        model, l2i, i2l, df_tr, df_va = train_one_fold(f, df_folds, img_size=img_size, epochs=epochs, batch_size=batch_size)\n",
        "        # Build gallery (train part only), exclude new_whale\n",
        "        gal_df = df_tr[df_tr.Id != 'new_whale'].copy()\n",
        "        assert set(df_va['Image']).isdisjoint(set(gal_df['Image'])), 'Leakage: val images present in gallery!'\n",
        "        tr_embs_gal = extract_embeddings(model, gal_df, img_size=img_size, batch_size=max(32, batch_size), img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "        tr_labels_gal = gal_df['Id'].tolist()\n",
        "        # Val embeddings and ranking\n",
        "        val_embs = extract_embeddings(model, df_va, img_size=img_size, batch_size=max(32, batch_size), img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "        val_ranked = per_class_max_similarity(val_embs, tr_embs_gal, tr_labels_gal, topK=300)\n",
        "        oof_ranked.extend(val_ranked)\n",
        "        oof_true.extend(df_va['Id'].tolist())\n",
        "        # Test rankings for this fold\n",
        "        te_embs = extract_embeddings(model, test_df, img_size=img_size, batch_size=max(32, batch_size), img_dir=IM_DIR_TEST, tta_hflip=True)\n",
        "        te_ranked = per_class_max_similarity(te_embs, tr_embs_gal, tr_labels_gal, topK=300)\n",
        "        te_ranked_folds.append(te_ranked)\n",
        "        # Cache embeddings/dfs\n",
        "        np.save(f'embeddings/f{f}_gal_embs.npy', tr_embs_gal)\n",
        "        np.save(f'embeddings/f{f}_val_embs.npy', val_embs)\n",
        "        np.save(f'embeddings/f{f}_te_embs.npy', te_embs)\n",
        "        gal_df.to_csv(f'embeddings/f{f}_gal_df.csv', index=False)\n",
        "        df_va.to_csv(f'embeddings/f{f}_val_df.csv', index=False)\n",
        "        # free GPU\n",
        "        del model; torch.cuda.empty_cache(); gc.collect()\n",
        "    # Tune tau on OOF\n",
        "    best_tau, best_map5 = tune_new_whale_threshold(oof_ranked, oof_true)\n",
        "    print(f\"OOF tuned new_whale tau={best_tau:.3f}, OOF MAP@5={best_map5:.4f}\")\n",
        "    # Combine fold test scores\n",
        "    te_combined = combine_fold_scores(te_ranked_folds)\n",
        "    # Build final predictions\n",
        "    preds5 = []\n",
        "    for ranked in te_combined:\n",
        "        if len(ranked) == 0 or ranked[0][1] < best_tau:\n",
        "            cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "        else:\n",
        "            cand = [c for c,_ in ranked][:5]\n",
        "        uniq = []\n",
        "        for c in cand:\n",
        "            if c not in uniq:\n",
        "                uniq.append(c)\n",
        "            if len(uniq) == 5:\n",
        "                break\n",
        "        while len(uniq) < 5:\n",
        "            uniq.append('new_whale')\n",
        "        preds5.append(' '.join(uniq))\n",
        "    sub = pd.read_csv('sample_submission.csv')\n",
        "    sub['Id'] = preds5\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv')\n",
        "\n",
        "# Launch full 5-fold training + OOF tuning + fold-ensemble inference\n",
        "run_full_5fold_pipeline(epochs=12, img_size=384, batch_size=48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "6b506cba-a13f-4286-b6d8-090905f92b9f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Post-hoc: Recompute TEST rankings using FULL train gallery per fold; tune tau from cached OOF; write improved submission.csv\n",
        "import os, time, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "def load_model_from_ckpt(ckpt_path, backbone_name='convnext_tiny', embed_dim=512):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = EmbeddingModel(backbone_name=backbone_name, embed_dim=embed_dim, pretrained=False).to(device)\n",
        "    state = torch.load(ckpt_path, map_location=device)\n",
        "    model.load_state_dict(state['model'], strict=True)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def extract_embeddings_df(model, df, img_size=384, batch_size=64, img_dir=IM_DIR_TRAIN, tta_hflip=True):\n",
        "    return extract_embeddings(model, df, img_size=img_size, batch_size=batch_size, img_dir=img_dir, tta_hflip=tta_hflip)\n",
        "\n",
        "def recompute_oof_and_tune_tau_from_cache():\n",
        "    oof_ranked = []; oof_true = []\n",
        "    for f in range(5):\n",
        "        gal_embs = np.load(f'embeddings/f{f}_gal_embs.npy')\n",
        "        val_embs = np.load(f'embeddings/f{f}_val_embs.npy')\n",
        "        gal_df = pd.read_csv(f'embeddings/f{f}_gal_df.csv')\n",
        "        val_df = pd.read_csv(f'embeddings/f{f}_val_df.csv')\n",
        "        gal_labels = gal_df['Id'].tolist()\n",
        "        ranked = per_class_max_similarity(val_embs, gal_embs, gal_labels, topK=300)\n",
        "        oof_ranked.extend(ranked)\n",
        "        oof_true.extend(val_df['Id'].tolist())\n",
        "    tau, map5 = tune_new_whale_threshold(oof_ranked, oof_true, grid=None)\n",
        "    print(f\"[Posthoc] OOF re-tuned tau={tau:.3f}, OOF MAP@5={map5:.4f}\")\n",
        "    return tau\n",
        "\n",
        "def test_full_gallery_inference(epochs_img_size=384, batch_size=64):\n",
        "    t0 = time.time()\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    full_gal_df = train_df[train_df.Id != 'new_whale'].copy()\n",
        "    test_df = pd.read_csv('sample_submission.csv')[['Image']].copy(); test_df['Id'] = 'new_whale'\n",
        "    te_ranked_folds = []\n",
        "    for f in range(5):\n",
        "        print(f\"[Posthoc] Fold {f}: loading checkpoint and extracting FULL train gallery embs...\", flush=True)\n",
        "        model = load_model_from_ckpt(f'checkpoints/fold{f}.pt', backbone_name='convnext_tiny', embed_dim=512)\n",
        "        gal_embs_full = extract_embeddings_df(model, full_gal_df, img_size=epochs_img_size, batch_size=max(32, batch_size), img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "        print(f\"[Posthoc] Fold {f}: gallery embs shape {gal_embs_full.shape}\")\n",
        "        te_embs = np.load(f'embeddings/f{f}_te_embs.npy')\n",
        "        gal_labels_full = full_gal_df['Id'].tolist()\n",
        "        te_ranked = per_class_max_similarity(te_embs, gal_embs_full, gal_labels_full, topK=300)\n",
        "        te_ranked_folds.append(te_ranked)\n",
        "        del model; torch.cuda.empty_cache(); gc.collect()\n",
        "    print(f\"[Posthoc] Combining per-fold per-class scores...\", flush=True)\n",
        "    te_combined = combine_fold_scores(te_ranked_folds)\n",
        "    print(f\"[Posthoc] Recomputing OOF tau from cache...\", flush=True)\n",
        "    tau = recompute_oof_and_tune_tau_from_cache()\n",
        "    preds5 = []\n",
        "    for ranked in te_combined:\n",
        "        if len(ranked) == 0 or ranked[0][1] < tau:\n",
        "            cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "        else:\n",
        "            cand = [c for c,_ in ranked][:5]\n",
        "        uniq = []\n",
        "        for c in cand:\n",
        "            if c not in uniq:\n",
        "                uniq.append(c)\n",
        "            if len(uniq) == 5:\n",
        "                break\n",
        "        while len(uniq) < 5:\n",
        "            uniq.append('new_whale')\n",
        "        preds5.append(' '.join(uniq))\n",
        "    sub = pd.read_csv('sample_submission.csv')\n",
        "    sub['Id'] = preds5\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print(f\"[Posthoc] Saved submission.csv using FULL-train gallery blend. Elapsed {time.time()-t0:.1f}s\")\n",
        "\n",
        "# Run post-hoc full-train gallery inference now\n",
        "test_full_gallery_inference(epochs_img_size=384, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0b40ee65-91e6-4361-b4e3-e10f64c8ed16",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Post-hoc v2: Try per-class top-k mean similarity (k in {2,3}) using cached OOF to pick best, then recompute TEST with FULL-train gallery\n",
        "import os, time, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import faiss\n",
        "\n",
        "def per_class_topk_mean_similarity(query_embs, gallery_embs, gallery_labels, topK=300, topn=2):\n",
        "    d = gallery_embs.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    index.add(gallery_embs.astype('float32'))\n",
        "    K = min(topK, gallery_embs.shape[0])\n",
        "    sims, idxs = index.search(query_embs.astype('float32'), K)\n",
        "    preds = []\n",
        "    for qi in range(query_embs.shape[0]):\n",
        "        buckets = {}\n",
        "        for j in range(K):\n",
        "            gi = int(idxs[qi, j]); s = float(sims[qi, j]); cls = gallery_labels[gi]\n",
        "            if cls not in buckets:\n",
        "                buckets[cls] = [s]\n",
        "            else:\n",
        "                buckets[cls].append(s)\n",
        "        agg = []\n",
        "        for cls, arr in buckets.items():\n",
        "            arr.sort(reverse=True)\n",
        "            m = float(np.mean(arr[:topn]))\n",
        "            agg.append((cls, m))\n",
        "        agg.sort(key=lambda x: x[1], reverse=True)\n",
        "        preds.append(agg)\n",
        "    return preds\n",
        "\n",
        "def eval_oof_with_agg(topn=2, topK=300):\n",
        "    oof_ranked = []; oof_true = []\n",
        "    for f in range(5):\n",
        "        gal_embs = np.load(f'embeddings/f{f}_gal_embs.npy')\n",
        "        val_embs = np.load(f'embeddings/f{f}_val_embs.npy')\n",
        "        gal_df = pd.read_csv(f'embeddings/f{f}_gal_df.csv')\n",
        "        val_df = pd.read_csv(f'embeddings/f{f}_val_df.csv')\n",
        "        gal_labels = gal_df['Id'].tolist()\n",
        "        ranked = per_class_topk_mean_similarity(val_embs, gal_embs, gal_labels, topK=topK, topn=topn)\n",
        "        oof_ranked.extend(ranked)\n",
        "        oof_true.extend(val_df['Id'].tolist())\n",
        "    tau, map5 = tune_new_whale_threshold(oof_ranked, oof_true, grid=None)\n",
        "    print(f\"[Top{topn}-mean] OOF tau={tau:.3f}, MAP@5={map5:.4f}\")\n",
        "    return tau, map5\n",
        "\n",
        "def run_topkmean_full_gallery_submission(img_size=384, batch_size=64, topn=2, topK=300):\n",
        "    t0 = time.time()\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    full_gal_df = train_df[train_df.Id != 'new_whale'].copy()\n",
        "    test_df = pd.read_csv('sample_submission.csv')[['Image']].copy(); test_df['Id'] = 'new_whale'\n",
        "    # Select best aggregator on OOF\n",
        "    tau2, map2 = eval_oof_with_agg(topn=2, topK=topK)\n",
        "    tau3, map3 = eval_oof_with_agg(topn=3, topK=topK)\n",
        "    if map3 > map2 + 0.005:\n",
        "        use_topn, best_tau = 3, tau3\n",
        "    else:\n",
        "        use_topn, best_tau = 2, tau2\n",
        "    print(f\"[Select] Using top-{use_topn} mean; tau={best_tau:.3f}\")\n",
        "    te_ranked_folds = []\n",
        "    for f in range(5):\n",
        "        ckpt = f'checkpoints/fold{f}.pt'\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = EmbeddingModel(backbone_name='convnext_tiny', embed_dim=512, pretrained=False).to(device)\n",
        "        state = torch.load(ckpt, map_location=device)\n",
        "        model.load_state_dict(state['model'], strict=True)\n",
        "        model.eval()\n",
        "        full_emb_path = f'embeddings/f{f}_gal_full_embs.npy'\n",
        "        if os.path.exists(full_emb_path):\n",
        "            gal_embs_full = np.load(full_emb_path)\n",
        "        else:\n",
        "            gal_embs_full = extract_embeddings(model, full_gal_df, img_size=img_size, batch_size=max(32, batch_size), img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "            np.save(full_emb_path, gal_embs_full)\n",
        "        te_embs = np.load(f'embeddings/f{f}_te_embs.npy')\n",
        "        gal_labels_full = full_gal_df['Id'].tolist()\n",
        "        te_ranked = per_class_topk_mean_similarity(te_embs, gal_embs_full, gal_labels_full, topK=topK, topn=use_topn)\n",
        "        te_ranked_folds.append(te_ranked)\n",
        "        del model; torch.cuda.empty_cache(); gc.collect()\n",
        "    te_combined = combine_fold_scores(te_ranked_folds)\n",
        "    preds5 = []\n",
        "    for ranked in te_combined:\n",
        "        if len(ranked) == 0 or ranked[0][1] < best_tau:\n",
        "            cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "        else:\n",
        "            cand = [c for c,_ in ranked][:5]\n",
        "        uniq = []\n",
        "        for c in cand:\n",
        "            if c not in uniq:\n",
        "                uniq.append(c)\n",
        "            if len(uniq) == 5:\n",
        "                break\n",
        "        while len(uniq) < 5:\n",
        "            uniq.append('new_whale')\n",
        "        preds5.append(' '.join(uniq))\n",
        "    sub = pd.read_csv('sample_submission.csv')\n",
        "    sub['Id'] = preds5\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print(f\"[Top{use_topn}-mean] Saved submission.csv (topK={topK}) in {time.time()-t0:.1f}s\")\n",
        "\n",
        "# Execute top-k mean submission build\n",
        "run_topkmean_full_gallery_submission(img_size=384, batch_size=64, topn=2, topK=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "24745aee-40d8-4293-92b9-7005a49fa6fc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ConvNeXt-Small @512 with PK sampler + EMA; train 5 folds; ensemble with Tiny post-hoc using full-train gallery; re-tune tau on combined OOF\n",
        "import os, time, gc, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset, Sampler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
        "import faiss\n",
        "\n",
        "os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF','expandable_segments:True')\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.9998):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}  # store on CPU to save VRAM\n",
        "        self.backup = {}\n",
        "        self.register(model)\n",
        "    def register(self, model):\n",
        "        for name, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[name] = p.detach().cpu().clone()\n",
        "    def update(self, model):\n",
        "        for name, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                w_cpu = p.detach().cpu()\n",
        "                new_avg = (1.0 - self.decay) * w_cpu + self.decay * self.shadow[name]\n",
        "                self.shadow[name] = new_avg.clone()\n",
        "    def apply_shadow(self, model):\n",
        "        self.backup = {}\n",
        "        for name, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.backup[name] = p.detach().clone()\n",
        "                p.data.copy_(self.shadow[name].to(p.device, dtype=p.dtype))\n",
        "    def restore(self, model):\n",
        "        for name, p in model.named_parameters():\n",
        "            if p.requires_grad and name in self.backup:\n",
        "                p.data.copy_(self.backup[name].data)\n",
        "        self.backup = {}\n",
        "\n",
        "def build_pk_batches(labels, P=16, K=4, drop_last=True, rng=None):\n",
        "    # labels: numpy array of class indices for ds_tr_sub (>=0)\n",
        "    if rng is None:\n",
        "        rng = np.random.default_rng(42)\n",
        "    idx_by_cls = defaultdict(list)\n",
        "    for i, y in enumerate(labels):\n",
        "        idx_by_cls[int(y)].append(i)\n",
        "    # include all classes; sample with replacement if class has <K samples\n",
        "    classes = list(idx_by_cls.keys())\n",
        "    if len(classes) == 0:\n",
        "        raise RuntimeError('No classes available for PK batching')\n",
        "    batches = []\n",
        "    total = sum(len(idx_by_cls[c]) for c in classes)\n",
        "    n_batches = max(1, total // (P*K))\n",
        "    for _ in range(n_batches):\n",
        "        chosen = rng.choice(classes, size=min(P, len(classes)), replace=False)\n",
        "        batch = []\n",
        "        for c in chosen:\n",
        "            idxs = idx_by_cls[c]\n",
        "            pick = rng.choice(idxs, size=K, replace=(len(idxs) < K))\n",
        "            batch.extend(int(x) for x in pick)\n",
        "        if len(batch) == P*K:\n",
        "            batches.append(batch)\n",
        "    if not drop_last:\n",
        "        pass\n",
        "    return batches\n",
        "\n",
        "class PKBatchSampler(Sampler):\n",
        "    def __init__(self, labels, P=16, K=4, drop_last=True, seed=42):\n",
        "        self.labels = np.asarray(labels)\n",
        "        self.P = P; self.K = K; self.drop_last = drop_last; self.seed = seed\n",
        "        self.epoch = 0\n",
        "        self.batches = build_pk_batches(self.labels, P=self.P, K=self.K, drop_last=self.drop_last, rng=np.random.default_rng(self.seed))\n",
        "    def __iter__(self):\n",
        "        rng = np.random.default_rng(self.seed + self.epoch)\n",
        "        self.batches = build_pk_batches(self.labels, P=self.P, K=self.K, drop_last=self.drop_last, rng=rng)\n",
        "        self.epoch += 1\n",
        "        for b in self.batches:\n",
        "            yield b\n",
        "    def __len__(self):\n",
        "        return len(self.batches)\n",
        "\n",
        "def per_class_max_similarity(query_embs, gallery_embs, gallery_labels, topK=500):\n",
        "    d = gallery_embs.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    index.add(gallery_embs.astype('float32'))\n",
        "    K = min(topK, gallery_embs.shape[0])\n",
        "    sims, idxs = index.search(query_embs.astype('float32'), K)\n",
        "    preds = []\n",
        "    for qi in range(query_embs.shape[0]):\n",
        "        best = {}\n",
        "        for j in range(K):\n",
        "            gi = int(idxs[qi, j]); s = float(sims[qi, j]); cls = gallery_labels[gi]\n",
        "            if cls not in best or s > best[cls]:\n",
        "                best[cls] = s\n",
        "        ranked = sorted(best.items(), key=lambda x: x[1], reverse=True)\n",
        "        preds.append(ranked)\n",
        "    return preds\n",
        "\n",
        "def merge_rank_lists_weighted(r_tiny, r_small, w=0.5):\n",
        "    # weighted average: (1-w)*tiny + w*small\n",
        "    d = defaultdict(float)\n",
        "    for c, s in r_tiny:\n",
        "        d[c] += (1.0 - w) * s\n",
        "    for c, s in r_small:\n",
        "        d[c] += w * s\n",
        "    out = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
        "    return out\n",
        "\n",
        "def merge_rank_lists_equal(r1, r2):\n",
        "    d = defaultdict(list)\n",
        "    for c, s in r1: d[c].append(s)\n",
        "    for c, s in r2: d[c].append(s)\n",
        "    out = [(c, float(np.mean(v))) for c, v in d.items()]\n",
        "    out.sort(key=lambda x: x[1], reverse=True)\n",
        "    return out\n",
        "\n",
        "def tune_new_whale_threshold(val_ranked_lists, val_true_ids, grid=None):\n",
        "    if grid is None:\n",
        "        grid = np.linspace(0.2, 0.8, 61)\n",
        "    best_tau, best_map5 = 0.5, -1.0\n",
        "    def map5_score(y_true_ids, y_pred_ranked_ids):\n",
        "        scores = []\n",
        "        for t, preds in zip(y_true_ids, y_pred_ranked_ids):\n",
        "            score = 0.0\n",
        "            for i, p in enumerate(preds[:5]):\n",
        "                if p == t:\n",
        "                    score = 1.0 / (i+1); break\n",
        "            scores.append(score)\n",
        "        return float(np.mean(scores))\n",
        "    for tau in grid:\n",
        "        top5 = []\n",
        "        for ranked in val_ranked_lists:\n",
        "            if len(ranked) == 0 or ranked[0][1] < tau:\n",
        "                cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "            else:\n",
        "                cand = [c for c,_ in ranked][:5]\n",
        "            uniq = []\n",
        "            for c in cand:\n",
        "                if c not in uniq: uniq.append(c)\n",
        "                if len(uniq) == 5: break\n",
        "            while len(uniq) < 5: uniq.append('new_whale')\n",
        "            top5.append(uniq)\n",
        "        m = map5_score(val_true_ids, top5)\n",
        "        if m > best_map5: best_map5, best_tau = m, tau\n",
        "    return best_tau, best_map5\n",
        "\n",
        "def extract_embeddings(model, df, img_size=512, batch_size=64, img_dir=IM_DIR_TRAIN, tta_hflip=True):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.eval()\n",
        "    tfm = build_transforms(size=img_size, train=False)\n",
        "    ds = ImageDS(df, img_col='Image', label_col='Id', img_dir=img_dir, tfm=tfm, label2idx=None)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=True)\n",
        "    embs = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in dl:\n",
        "            imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                e1 = model(imgs)\n",
        "                if tta_hflip:\n",
        "                    e2 = model(torch.flip(imgs, dims=[3]))\n",
        "                    e = (e1 + e2) / 2.0\n",
        "                else:\n",
        "                    e = e1\n",
        "            embs.append(e.detach().cpu().numpy())\n",
        "    embs = np.concatenate(embs, axis=0)\n",
        "    faiss.normalize_L2(embs)\n",
        "    return embs\n",
        "\n",
        "def build_transforms_512(train=True):\n",
        "    import torchvision.transforms as T\n",
        "    size = 512\n",
        "    if train:\n",
        "        return T.Compose([\n",
        "            T.RandomResizedCrop(size, scale=(0.88, 1.0), ratio=(0.75, 1.33)),\n",
        "            T.RandomHorizontalFlip(0.5),\n",
        "            T.ColorJitter(0.15,0.15,0.15,0.05),\n",
        "            T.RandomGrayscale(p=0.05),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ])\n",
        "    else:\n",
        "        return T.Compose([\n",
        "            T.Resize(int(size*1.15)),\n",
        "            T.CenterCrop(size),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ])\n",
        "\n",
        "def train_convnext_small_fold(fold, df_folds, epochs=25, P=16, K=4, lr=3e-4, wd=0.05, arc_s=45.0, arc_m=0.35, embed_dim=512):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    val_mask = df_folds['fold'] == fold\n",
        "    train_mask = (df_folds['fold'] != fold)\n",
        "    df_tr = df_folds.loc[train_mask].copy()\n",
        "    df_va = df_folds.loc[val_mask].copy()\n",
        "    label2idx, idx2label = build_label_mapping(df_tr, label_col='Id')\n",
        "    n_classes = len(label2idx)\n",
        "    tfm_tr = build_transforms_512(train=True)\n",
        "    tfm_va = build_transforms_512(train=False)\n",
        "    # dataset\n",
        "    ds_tr = ImageDS(df_tr, img_col='Image', label_col='Id', img_dir=IM_DIR_TRAIN, tfm=tfm_tr, label2idx=label2idx)\n",
        "    y_tr_full = ds_tr.df['Id'].map(label2idx).fillna(-1).to_numpy()\n",
        "    train_indices = np.where(y_tr_full != -1)[0]\n",
        "    ds_tr_sub = Subset(ds_tr, train_indices)\n",
        "    y_sub = y_tr_full[train_indices]\n",
        "    # PK batch sampler on subset\n",
        "    pk_sampler = PKBatchSampler(y_sub, P=P, K=K, drop_last=True, seed=42+fold)\n",
        "    dl_tr = DataLoader(ds_tr_sub, batch_sampler=pk_sampler, num_workers=8, pin_memory=True, persistent_workers=True)\n",
        "    # model\n",
        "    model = EmbeddingModel(backbone_name='convnext_small', embed_dim=embed_dim, pretrained=True, drop_path_rate=0.1).to(device)\n",
        "    model.backbone = model.backbone.to(memory_format=torch.channels_last)\n",
        "    # enable gradient checkpointing on backbone (fallback if not available)\n",
        "    try:\n",
        "        if hasattr(model.backbone, 'set_grad_checkpointing'):\n",
        "            model.backbone.set_grad_checkpointing(True)\n",
        "            print('[Small] Enabled gradient checkpointing on backbone')\n",
        "        else:\n",
        "            print('[Small] Grad checkpointing method not found on backbone; continuing without it')\n",
        "    except Exception as e:\n",
        "        print('[Small] Grad checkpointing not enabled:', e)\n",
        "    arc = ArcMarginProduct(embed_dim, n_classes, s=arc_s, m=arc_m).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = AdamW(list(model.parameters()) + list(arc.parameters()), lr=lr, weight_decay=wd)\n",
        "    main = CosineAnnealingLR(optimizer, T_max=max(1, epochs-1), eta_min=1e-6)\n",
        "    warm = LinearLR(optimizer, start_factor=0.1, end_factor=1.0, total_iters=1)\n",
        "    scheduler = SequentialLR(optimizer, [warm, main], milestones=[1])\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
        "    ema = EMA(model, decay=0.9998)\n",
        "    t0 = time.time()\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train(); arc.train()\n",
        "        running = 0.0; n = 0; t_ep = time.time()\n",
        "        for it, batch in enumerate(dl_tr):\n",
        "            imgs, targets = batch\n",
        "            imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            targets = targets.to(device)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                emb = model(imgs)\n",
        "                logits = arc(emb, targets)\n",
        "                loss = criterion(logits, targets)\n",
        "            scaler.scale(loss).backward()\n",
        "            # gradient clipping for stability\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(list(model.parameters()) + list(arc.parameters()), max_norm=1.0)\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            ema.update(model)\n",
        "            running += loss.item() * targets.size(0); n += targets.size(0)\n",
        "            if (it+1) % 50 == 0:\n",
        "                print(f\"[Small Fold {fold}] Ep {ep} It {it+1} loss={running/max(n,1):.4f} elaps={time.time()-t_ep:.1f}s\", flush=True)\n",
        "        scheduler.step()\n",
        "        print(f\"[Small Fold {fold}] Epoch {ep}/{epochs} tr_loss={running/max(n,1):.4f} lr={scheduler.get_last_lr()[0]:.6f}\")\n",
        "    # save ema weights\n",
        "    ema.apply_shadow(model)\n",
        "    os.makedirs('checkpoints_small', exist_ok=True)\n",
        "    torch.save({'model': model.state_dict(), 'label2idx': label2idx}, f'checkpoints_small/fold{fold}.pt')\n",
        "    ema.restore(model)  # keep training model state clean\n",
        "    print(f\"[Small Fold {fold}] Saved EMA checkpoint. Time {time.time()-t0:.1f}s\")\n",
        "    # Build OOF ranked using train-excl-val gallery (no leakage), exclude new_whale\n",
        "    ema.apply_shadow(model)\n",
        "    gal_df = df_tr[df_tr.Id != 'new_whale'].copy()\n",
        "    tr_embs_gal = extract_embeddings(model, gal_df, img_size=512, batch_size=48, img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "    tr_labels_gal = gal_df['Id'].tolist()\n",
        "    val_embs = extract_embeddings(model, df_va, img_size=512, batch_size=48, img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "    val_ranked = per_class_max_similarity(val_embs, tr_embs_gal, tr_labels_gal, topK=500)\n",
        "    # cache\n",
        "    os.makedirs('embeddings_small', exist_ok=True)\n",
        "    np.save(f'embeddings_small/f{fold}_gal_embs.npy', tr_embs_gal)\n",
        "    np.save(f'embeddings_small/f{fold}_val_embs.npy', val_embs)\n",
        "    gal_df.to_csv(f'embeddings_small/f{fold}_gal_df.csv', index=False)\n",
        "    df_va.to_csv(f'embeddings_small/f{fold}_val_df.csv', index=False)\n",
        "    ema.restore(model)\n",
        "    return model, val_ranked, df_va[['Image','Id']].copy()\n",
        "\n",
        "def run_convnext_small_pipeline(epochs=25, P_first=8, P_others=10, K=4):\n",
        "    set_seed = lambda s=42: (np.random.seed(s), torch.manual_seed(s), torch.cuda.manual_seed_all(s))\n",
        "    set_seed(42)\n",
        "    df = pd.read_csv('train.csv')\n",
        "    folds = pd.read_csv('folds.csv')\n",
        "    df_folds = df.merge(folds[['Image','fold']], on='Image', how='left')\n",
        "    all_oof_ranked_small = []; all_oof_true_small = []; all_oof_img_small = []\n",
        "    for f in range(5):\n",
        "        P_this = P_first if f == 0 else P_others\n",
        "        ckpt_path = f'checkpoints_small/fold{f}.pt'\n",
        "        gal_emb_path = f'embeddings_small/f{f}_gal_embs.npy'\n",
        "        val_emb_path = f'embeddings_small/f{f}_val_embs.npy'\n",
        "        gal_df_path = f'embeddings_small/f{f}_gal_df.csv'\n",
        "        val_df_path = f'embeddings_small/f{f}_val_df.csv'\n",
        "        if os.path.exists(ckpt_path) and os.path.exists(gal_emb_path) and os.path.exists(val_emb_path) and os.path.exists(gal_df_path) and os.path.exists(val_df_path):\n",
        "            print(f\"=== Small: Skipping training fold {f} (cache found) ===\", flush=True)\n",
        "            gal_embs = np.load(gal_emb_path)\n",
        "            val_embs = np.load(val_emb_path)\n",
        "            gal_df = pd.read_csv(gal_df_path)\n",
        "            val_df = pd.read_csv(val_df_path)\n",
        "            gal_labels = gal_df['Id'].tolist()\n",
        "            val_ranked = per_class_max_similarity(val_embs, gal_embs, gal_labels, topK=500)\n",
        "            all_oof_ranked_small.extend(val_ranked); all_oof_true_small.extend(val_df['Id'].tolist()); all_oof_img_small.extend(val_df['Image'].tolist())\n",
        "            continue\n",
        "        elif os.path.exists(ckpt_path):\n",
        "            print(f\"=== Small: Fold {f} checkpoint found; running embedding extraction only ===\", flush=True)\n",
        "            val_mask = df_folds['fold'] == f\n",
        "            train_mask = (df_folds['fold'] != f)\n",
        "            df_tr = df_folds.loc[train_mask].copy()\n",
        "            df_va = df_folds.loc[val_mask].copy()\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            m = EmbeddingModel(backbone_name='convnext_small', embed_dim=512, pretrained=False, drop_path_rate=0.1).to(device)\n",
        "            state = torch.load(ckpt_path, map_location=device)\n",
        "            m.load_state_dict(state['model'], strict=True); m.eval()\n",
        "            gal_df = df_tr[df_tr.Id != 'new_whale'].copy()\n",
        "            tr_embs_gal = extract_embeddings(m, gal_df, img_size=512, batch_size=48, img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "            val_embs = extract_embeddings(m, df_va, img_size=512, batch_size=48, img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "            val_ranked = per_class_max_similarity(val_embs, tr_embs_gal, gal_df['Id'].tolist(), topK=500)\n",
        "            os.makedirs('embeddings_small', exist_ok=True)\n",
        "            np.save(gal_emb_path, tr_embs_gal); np.save(val_emb_path, val_embs)\n",
        "            gal_df.to_csv(gal_df_path, index=False); df_va.to_csv(val_df_path, index=False)\n",
        "            all_oof_ranked_small.extend(val_ranked); all_oof_true_small.extend(df_va['Id'].tolist()); all_oof_img_small.extend(df_va['Image'].tolist())\n",
        "            del m; torch.cuda.empty_cache(); gc.collect()\n",
        "            continue\n",
        "        else:\n",
        "            print(f\"=== Small: Training fold {f} (P={P_this},K={K}) ===\", flush=True)\n",
        "            model, va_ranked, va_df = train_convnext_small_fold(f, df_folds, epochs=epochs, P=P_this, K=K)\n",
        "            all_oof_ranked_small.extend(va_ranked); all_oof_true_small.extend(va_df['Id'].tolist()); all_oof_img_small.extend(va_df['Image'].tolist())\n",
        "            del model; torch.cuda.empty_cache(); gc.collect()\n",
        "    tau_small, map_small = tune_new_whale_threshold(all_oof_ranked_small, all_oof_true_small, grid=None)\n",
        "    print(f\"[Small] OOF tau={tau_small:.3f}, MAP@5={map_small:.4f}\")\n",
        "    # Build ensemble with Tiny using full-train gallery per fold\n",
        "    print('[Ensemble] Computing TEST rankings for Small (full-train gallery) and loading Tiny cached full gallery...')\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    full_gal_df = train_df[train_df.Id != 'new_whale'].copy()\n",
        "    te_df = pd.read_csv('sample_submission.csv')[['Image']].copy(); te_df['Id'] = 'new_whale'\n",
        "    te_ranked_small_folds = []; te_ranked_tiny_folds = []\n",
        "    for f in range(5):\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        # Small model\n",
        "        m_small = EmbeddingModel(backbone_name='convnext_small', embed_dim=512, pretrained=False, drop_path_rate=0.1).to(device)\n",
        "        state = torch.load(f'checkpoints_small/fold{f}.pt', map_location=device)\n",
        "        m_small.load_state_dict(state['model'], strict=True); m_small.eval()\n",
        "        gal_small = extract_embeddings(m_small, full_gal_df, img_size=512, batch_size=48, img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "        te_small_emb_path = f'embeddings_small/te_embs_small_f{f}.npy'\n",
        "        if os.path.exists(te_small_emb_path):\n",
        "            te_embs = np.load(te_small_emb_path)\n",
        "        else:\n",
        "            te_embs = extract_embeddings(m_small, te_df, img_size=512, batch_size=48, img_dir=IM_DIR_TEST, tta_hflip=True)\n",
        "            os.makedirs('embeddings_small', exist_ok=True)\n",
        "            np.save(te_small_emb_path, te_embs)\n",
        "        labs_full = full_gal_df['Id'].tolist()\n",
        "        te_ranked_small = per_class_max_similarity(te_embs, gal_small, labs_full, topK=500)\n",
        "        te_ranked_small_folds.append(te_ranked_small)\n",
        "        del m_small; torch.cuda.empty_cache(); gc.collect()\n",
        "        # Tiny model\n",
        "        if os.path.exists(f'embeddings/f{f}_gal_full_embs.npy'):\n",
        "            gal_tiny = np.load(f'embeddings/f{f}_gal_full_embs.npy')\n",
        "        else:\n",
        "            m_tiny = EmbeddingModel(backbone_name='convnext_tiny', embed_dim=512, pretrained=False).to(device)\n",
        "            st = torch.load(f'checkpoints/fold{f}.pt', map_location=device)\n",
        "            m_tiny.load_state_dict(st['model'], strict=True); m_tiny.eval()\n",
        "            gal_tiny = extract_embeddings(m_tiny, full_gal_df, img_size=384, batch_size=64, img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "            np.save(f'embeddings/f{f}_gal_full_embs.npy', gal_tiny)\n",
        "            del m_tiny; torch.cuda.empty_cache(); gc.collect()\n",
        "        te_embs_tiny = np.load(f'embeddings/f{f}_te_embs.npy')\n",
        "        te_ranked_tiny = per_class_max_similarity(te_embs_tiny, gal_tiny, labs_full, topK=500)\n",
        "        te_ranked_tiny_folds.append(te_ranked_tiny)\n",
        "    # Average across folds within each model\n",
        "    def combine_fold_scores(rank_lists_per_fold):\n",
        "        n_folds = len(rank_lists_per_fold); N = len(rank_lists_per_fold[0]); out = []\n",
        "        for i in range(N):\n",
        "            d = defaultdict(list)\n",
        "            for f in range(n_folds):\n",
        "                for c, s in rank_lists_per_fold[f][i]: d[c].append(s)\n",
        "            arr = [(c, float(np.mean(v))) for c, v in d.items()]\n",
        "            arr.sort(key=lambda x: x[1], reverse=True); out.append(arr)\n",
        "        return out\n",
        "    te_small_comb = combine_fold_scores(te_ranked_small_folds)\n",
        "    te_tiny_comb = combine_fold_scores(te_ranked_tiny_folds)\n",
        "    # Recompute combined OOF (tiny+small) for tau/weight tuning using cached per-model OOFs, aligned by Image\n",
        "    oof_ranked_tiny = {}; oof_true = {}; order_imgs = []\n",
        "    for f in range(5):\n",
        "        gal_embs = np.load(f'embeddings/f{f}_gal_embs.npy')\n",
        "        val_embs = np.load(f'embeddings/f{f}_val_embs.npy')\n",
        "        gal_df = pd.read_csv(f'embeddings/f{f}_gal_df.csv')\n",
        "        val_df = pd.read_csv(f'embeddings/f{f}_val_df.csv')\n",
        "        gal_labels = gal_df['Id'].tolist()\n",
        "        ranked = per_class_max_similarity(val_embs, gal_embs, gal_labels, topK=500)\n",
        "        for img, rnk, true_id in zip(val_df['Image'].tolist(), ranked, val_df['Id'].tolist()):\n",
        "            oof_ranked_tiny[img] = rnk\n",
        "            if img not in oof_true:\n",
        "                oof_true[img] = true_id\n",
        "                order_imgs.append(img)\n",
        "    oof_ranked_small = {}\n",
        "    for img, rnk in zip(all_oof_img_small, all_oof_ranked_small):\n",
        "        oof_ranked_small[img] = rnk\n",
        "    # Grid-search weight w and tau\n",
        "    best_w, best_tau, best_map = 0.5, 0.5, -1.0\n",
        "    w_grid = np.linspace(0.0, 1.0, 21)\n",
        "    for w in w_grid:\n",
        "        merged_ranked = []\n",
        "        true_list = []\n",
        "        for img in order_imgs:\n",
        "            if (img not in oof_ranked_tiny) or (img not in oof_ranked_small):\n",
        "                continue\n",
        "            merged_ranked.append(merge_rank_lists_weighted(oof_ranked_tiny[img], oof_ranked_small[img], w=w))\n",
        "            true_list.append(oof_true[img])\n",
        "        tau, m = tune_new_whale_threshold(merged_ranked, true_list, grid=None)\n",
        "        if m > best_map:\n",
        "            best_map, best_tau, best_w = m, tau, float(w)\n",
        "    print(f\"[Ensemble] OOF weight w={best_w:.2f}, tau={best_tau:.3f}, MAP@5={best_map:.4f}\")\n",
        "    # Ensemble test per-class scores across models with best_w and apply best_tau\n",
        "    preds5 = []\n",
        "    for i in range(len(te_tiny_comb)):\n",
        "        merged = merge_rank_lists_weighted(te_tiny_comb[i], te_small_comb[i], w=best_w)\n",
        "        if len(merged) == 0 or merged[0][1] < best_tau:\n",
        "            cand = ['new_whale'] + [c for c,_ in merged][:4]\n",
        "        else:\n",
        "            cand = [c for c,_ in merged][:5]\n",
        "        uniq = []\n",
        "        for c in cand:\n",
        "            if c not in uniq: uniq.append(c)\n",
        "            if len(uniq) == 5: break\n",
        "        while len(uniq) < 5: uniq.append('new_whale')\n",
        "        preds5.append(' '.join(uniq))\n",
        "    sub = pd.read_csv('sample_submission.csv')\n",
        "    sub['Id'] = preds5\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[Ensemble] Saved submission.csv (Tiny@384 + Small@512, weighted per-class max, full-train gallery, tau tuned on merged OOF)')\n",
        "\n",
        "# Kick off ConvNeXt-Small training + ensemble build\n",
        "run_convnext_small_pipeline(epochs=25, P_first=8, P_others=10, K=4)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Small: Skipping training fold 0 (cache found) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Small: Fold 1 checkpoint found; running embedding extraction only ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2239/4277673817.py:311: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Small: Training fold 2 (P=10,K=4) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Small] Enabled gradient checkpointing on backbone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Small Fold 2] Ep 1 It 50 loss=25.4914 elaps=1099.3s\n"
          ]
        }
      ]
    },
    {
      "id": "b179dffe-c70f-4026-ae86-53332963ba33",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Partial-fold ensemble builder: Tiny (5 folds) + Small (available folds only) with OOF-aligned weighting and tau+margin; caching gal_full; topK=300\n",
        "import os, gc, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "\n",
        "def per_class_max_similarity(query_embs, gallery_embs, gallery_labels, topK=300):\n",
        "    import faiss\n",
        "    d = gallery_embs.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    index.add(gallery_embs.astype('float32'))\n",
        "    K = min(topK, gallery_embs.shape[0])\n",
        "    sims, idxs = index.search(query_embs.astype('float32'), K)\n",
        "    preds = []\n",
        "    for qi in range(query_embs.shape[0]):\n",
        "        best = {}\n",
        "        for j in range(K):\n",
        "            gi = int(idxs[qi, j]); s = float(sims[qi, j]); cls = gallery_labels[gi]\n",
        "            if cls not in best or s > best[cls]:\n",
        "                best[cls] = s\n",
        "        ranked = sorted(best.items(), key=lambda x: x[1], reverse=True)\n",
        "        preds.append(ranked)\n",
        "    return preds\n",
        "\n",
        "def tune_tau_delta(val_ranked_lists, val_true_ids, tau_grid_coarse=None, tau_window=0.05, tau_step_fine=0.005, delta_grid=None):\n",
        "    import numpy as np\n",
        "    if tau_grid_coarse is None:\n",
        "        tau_grid_coarse = np.arange(0.2, 0.801, 0.02)\n",
        "    if delta_grid is None:\n",
        "        delta_grid = [0.0, 0.03, 0.05, 0.08, 0.10, 0.12, 0.15]\n",
        "    def map5_score(y_true_ids, y_pred_ranked_ids):\n",
        "        scores = []\n",
        "        for t, preds in zip(y_true_ids, y_pred_ranked_ids):\n",
        "            sc = 0.0\n",
        "            for i, p in enumerate(preds[:5]):\n",
        "                if p == t: sc = 1.0/(i+1); break\n",
        "            scores.append(sc)\n",
        "        return float(np.mean(scores))\n",
        "    def build_preds(tau, delta):\n",
        "        out = []\n",
        "        for ranked in val_ranked_lists:\n",
        "            if len(ranked) == 0:\n",
        "                out.append(['new_whale']*5); continue\n",
        "            top1 = ranked[0][1]\n",
        "            top2 = ranked[1][1] if len(ranked) > 1 else -1.0\n",
        "            cond_new = (top1 < tau) or ((top1 - top2) < delta)\n",
        "            if cond_new:\n",
        "                cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "            else:\n",
        "                cand = [c for c,_ in ranked][:5]\n",
        "            uniq = []\n",
        "            for c in cand:\n",
        "                if c not in uniq: uniq.append(c)\n",
        "                if len(uniq) == 5: break\n",
        "            while len(uniq) < 5: uniq.append('new_whale')\n",
        "            out.append(uniq)\n",
        "        return out\n",
        "    best = (-1.0, 0.5, 0.0)\n",
        "    for dlt in delta_grid:\n",
        "        for tau in tau_grid_coarse:\n",
        "            preds = build_preds(tau, dlt)\n",
        "            m = map5_score(val_true_ids, preds)\n",
        "            if m > best[0]: best = (m, float(tau), float(dlt))\n",
        "    _, tau_c, dlt_c = best\n",
        "    tau_fine = np.arange(max(0.0, tau_c - tau_window), min(1.0, tau_c + tau_window) + 1e-6, tau_step_fine)\n",
        "    for tau in tau_fine:\n",
        "        preds = build_preds(tau, dlt_c)\n",
        "        m = map5_score(val_true_ids, preds)\n",
        "        if m > best[0]: best = (m, float(tau), float(dlt_c))\n",
        "    return best[1], best[0], best[2]  # tau, map, delta\n",
        "\n",
        "def merge_rank_lists_weighted(r_tiny, r_small, w=0.5):\n",
        "    d = defaultdict(float)\n",
        "    for c, s in r_tiny:\n",
        "        d[c] += (1.0 - w) * s\n",
        "    for c, s in r_small:\n",
        "        d[c] += w * s\n",
        "    out = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
        "    return out\n",
        "\n",
        "def combine_fold_scores(rank_lists_per_fold):\n",
        "    n_folds = len(rank_lists_per_fold); N = len(rank_lists_per_fold[0]); out = []\n",
        "    for i in range(N):\n",
        "        d = defaultdict(list)\n",
        "        for f in range(n_folds):\n",
        "            for c, s in rank_lists_per_fold[f][i]: d[c].append(s)\n",
        "        arr = [(c, float(np.mean(v))) for c, v in d.items()]\n",
        "        arr.sort(key=lambda x: x[1], reverse=True); out.append(arr)\n",
        "    return out\n",
        "\n",
        "def build_partial_ensemble_and_submit():\n",
        "    t0 = time.time()\n",
        "    small_folds = []\n",
        "    for f in range(5):\n",
        "        if os.path.exists(f'checkpoints_small/fold{f}.pt') and \\\n",
        "           os.path.exists(f'embeddings_small/f{f}_gal_embs.npy') and \\\n",
        "           os.path.exists(f'embeddings_small/f{f}_val_embs.npy') and \\\n",
        "           os.path.exists(f'embeddings_small/f{f}_gal_df.csv') and \\\n",
        "           os.path.exists(f'embeddings_small/f{f}_val_df.csv'):\n",
        "            small_folds.append(f)\n",
        "    print(f\"[Partial] Small folds available: {small_folds}\")\n",
        "    assert len(small_folds) > 0, 'No small folds available; run training or switch to Tiny-only submission.'\n",
        "\n",
        "    # Tiny OOF dicts\n",
        "    oof_ranked_tiny = {}; oof_true = {}; order_imgs = []\n",
        "    for f in range(5):\n",
        "        gal_embs = np.load(f'embeddings/f{f}_gal_embs.npy')\n",
        "        val_embs = np.load(f'embeddings/f{f}_val_embs.npy')\n",
        "        gal_df = pd.read_csv(f'embeddings/f{f}_gal_df.csv')\n",
        "        val_df = pd.read_csv(f'embeddings/f{f}_val_df.csv')\n",
        "        gal_labels = gal_df['Id'].tolist()\n",
        "        ranked = per_class_max_similarity(val_embs, gal_embs, gal_labels, topK=300)\n",
        "        for img, rnk, true_id in zip(val_df['Image'].tolist(), ranked, val_df['Id'].tolist()):\n",
        "            oof_ranked_tiny[img] = rnk\n",
        "            if img not in oof_true:\n",
        "                oof_true[img] = true_id\n",
        "                order_imgs.append(img)\n",
        "\n",
        "    # Small OOF dicts\n",
        "    oof_ranked_small = {}\n",
        "    for f in small_folds:\n",
        "        gal_embs = np.load(f'embeddings_small/f{f}_gal_embs.npy')\n",
        "        val_embs = np.load(f'embeddings_small/f{f}_val_embs.npy')\n",
        "        gal_df = pd.read_csv(f'embeddings_small/f{f}_gal_df.csv')\n",
        "        val_df = pd.read_csv(f'embeddings_small/f{f}_val_df.csv')\n",
        "        gal_labels = gal_df['Id'].tolist()\n",
        "        ranked = per_class_max_similarity(val_embs, gal_embs, gal_labels, topK=300)\n",
        "        for img, rnk in zip(val_df['Image'].tolist(), ranked):\n",
        "            oof_ranked_small[img] = rnk\n",
        "\n",
        "    inter_imgs = [img for img in order_imgs if img in oof_ranked_small]\n",
        "    print(f\"[Partial] OOF alignment images: {len(inter_imgs)}\")\n",
        "    assert len(inter_imgs) > 0, 'No overlapping OOF images between tiny and small folds'\n",
        "\n",
        "    # Grid-search weight w and tau+delta\n",
        "    best_w, best_tau, best_delta, best_map = 0.5, 0.5, 0.0, -1.0\n",
        "    for w in np.linspace(0.0, 1.0, 21):\n",
        "        merged_ranked = []; true_list = []\n",
        "        for img in inter_imgs:\n",
        "            merged_ranked.append(merge_rank_lists_weighted(oof_ranked_tiny[img], oof_ranked_small[img], w=float(w)))\n",
        "            true_list.append(oof_true[img])\n",
        "        tau, m, dlt = tune_tau_delta(merged_ranked, true_list, tau_grid_coarse=None)\n",
        "        if m > best_map:\n",
        "            best_map, best_tau, best_w, best_delta = m, tau, float(w), dlt\n",
        "    print(f\"[Partial Ensemble] OOF weight w={best_w:.2f}, tau={best_tau:.3f}, delta={best_delta:.3f}, MAP@5={best_map:.4f}\")\n",
        "\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    full_gal_df = train_df[train_df.Id != 'new_whale'].copy()\n",
        "    labs_full = full_gal_df['Id'].tolist()\n",
        "    te_df = pd.read_csv('sample_submission.csv')[['Image']].copy(); te_df['Id'] = 'new_whale'\n",
        "\n",
        "    # Tiny TEST ranks (use cached full gallery per fold, cached te_embs)\n",
        "    te_ranked_tiny_folds = []\n",
        "    for f in range(5):\n",
        "        full_gal_path = f'embeddings/f{f}_gal_full_embs.npy'\n",
        "        if os.path.exists(full_gal_path):\n",
        "            gal_tiny = np.load(full_gal_path)\n",
        "        else:\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            m_tiny = EmbeddingModel(backbone_name='convnext_tiny', embed_dim=512, pretrained=False).to(device)\n",
        "            st = torch.load(f'checkpoints/fold{f}.pt', map_location=device)\n",
        "            m_tiny.load_state_dict(st['model'], strict=True); m_tiny.eval()\n",
        "            gal_tiny = extract_embeddings(m_tiny, full_gal_df, img_size=384, batch_size=64, img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "            os.makedirs('embeddings', exist_ok=True)\n",
        "            np.save(full_gal_path, gal_tiny)\n",
        "            del m_tiny; torch.cuda.empty_cache(); gc.collect()\n",
        "        te_embs_tiny = np.load(f'embeddings/f{f}_te_embs.npy')\n",
        "        te_ranked_tiny = per_class_max_similarity(te_embs_tiny, gal_tiny, labs_full, topK=300)\n",
        "        te_ranked_tiny_folds.append(te_ranked_tiny)\n",
        "\n",
        "    # Small TEST ranks (cache full gallery embs per available fold; accept te_embs from either embeddings_small or train/ fallback)\n",
        "    os.makedirs('embeddings_small', exist_ok=True)\n",
        "    te_ranked_small_folds = []\n",
        "    for f in small_folds:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        m_small = EmbeddingModel(backbone_name='convnext_small', embed_dim=512, pretrained=False, drop_path_rate=0.1).to(device)\n",
        "        st = torch.load(f'checkpoints_small/fold{f}.pt', map_location=device)\n",
        "        m_small.load_state_dict(st['model'], strict=True); m_small.eval()\n",
        "        gal_small_full_path = f'embeddings_small/f{f}_gal_full_embs.npy'\n",
        "        if os.path.exists(gal_small_full_path):\n",
        "            gal_small = np.load(gal_small_full_path)\n",
        "        else:\n",
        "            gal_small = extract_embeddings(m_small, full_gal_df, img_size=512, batch_size=48, img_dir=IM_DIR_TRAIN, tta_hflip=True)\n",
        "            np.save(gal_small_full_path, gal_small)\n",
        "        te_small_emb_path = f'embeddings_small/te_embs_small_f{f}.npy'\n",
        "        te_embs = None\n",
        "        if os.path.exists(te_small_emb_path):\n",
        "            te_embs = np.load(te_small_emb_path)\n",
        "        elif os.path.exists(f'train/te_embs_small_f{f}.npy'):  # fallback location observed in FS\n",
        "            te_embs = np.load(f'train/te_embs_small_f{f}.npy')\n",
        "        else:\n",
        "            te_embs = extract_embeddings(m_small, te_df, img_size=512, batch_size=48, img_dir=IM_DIR_TEST, tta_hflip=True)\n",
        "            np.save(te_small_emb_path, te_embs)\n",
        "        te_ranked_small = per_class_max_similarity(te_embs, gal_small, labs_full, topK=300)\n",
        "        te_ranked_small_folds.append(te_ranked_small)\n",
        "        del m_small; torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    te_tiny_comb = combine_fold_scores(te_ranked_tiny_folds)\n",
        "    if len(te_ranked_small_folds) > 0:\n",
        "        te_small_comb = combine_fold_scores(te_ranked_small_folds)\n",
        "    else:\n",
        "        te_small_comb = [list() for _ in range(len(te_tiny_comb))]\n",
        "\n",
        "    preds5 = []\n",
        "    for i in range(len(te_tiny_comb)):\n",
        "        merged = merge_rank_lists_weighted(te_tiny_comb[i], te_small_comb[i], w=best_w)\n",
        "        if len(merged) == 0:\n",
        "            preds5.append('new_whale new_whale new_whale new_whale new_whale'); continue\n",
        "        top1 = merged[0][1]; top2 = merged[1][1] if len(merged) > 1 else -1.0\n",
        "        cond_new = (top1 < best_tau) or ((top1 - top2) < best_delta)\n",
        "        cand = (['new_whale'] + [c for c,_ in merged][:4]) if cond_new else [c for c,_ in merged][:5]\n",
        "        uniq = []\n",
        "        for c in cand:\n",
        "            if c not in uniq: uniq.append(c)\n",
        "            if len(uniq) == 5: break\n",
        "        while len(uniq) < 5: uniq.append('new_whale')\n",
        "        preds5.append(' '.join(uniq))\n",
        "\n",
        "    sub = pd.read_csv('sample_submission.csv')\n",
        "    sub['Id'] = preds5\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print(f\"[Partial] Saved submission.csv using Tiny(5f)+Small({len(small_folds)}f). Elapsed {time.time()-t0:.1f}s\")\n",
        "\n",
        "# Execute partial ensemble now\n",
        "build_partial_ensemble_and_submit()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Partial] Small folds available: [0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Partial] OOF alignment images: 1662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Partial Ensemble] OOF weight w=0.00, tau=0.440, delta=0.050, MAP@5=0.4441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2239/266184879.py:178: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  st = torch.load(f'checkpoints_small/fold{f}.pt', map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Partial] Saved submission.csv using Tiny(5f)+Small(2f). Elapsed 3386.9s\n"
          ]
        }
      ]
    },
    {
      "id": "65630e36-88fd-4594-a886-fd488e6da9f2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Tiny-only improved submission with refined tau and margin rule (no model loading, use cached embeddings)\n",
        "import os, time, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "\n",
        "def map5_score(y_true_ids, y_pred_ranked_ids):\n",
        "    scores = []\n",
        "    for t, preds in zip(y_true_ids, y_pred_ranked_ids):\n",
        "        score = 0.0\n",
        "        for i, p in enumerate(preds[:5]):\n",
        "            if p == t:\n",
        "                score = 1.0 / (i+1); break\n",
        "        scores.append(score)\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "def per_class_max_similarity(query_embs, gallery_embs, gallery_labels, topK=300):\n",
        "    d = gallery_embs.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    index.add(gallery_embs.astype('float32'))\n",
        "    K = min(topK, gallery_embs.shape[0])\n",
        "    sims, idxs = index.search(query_embs.astype('float32'), K)\n",
        "    preds = []\n",
        "    for qi in range(query_embs.shape[0]):\n",
        "        best = {}\n",
        "        for j in range(K):\n",
        "            gi = int(idxs[qi, j]); s = float(sims[qi, j]); cls = gallery_labels[gi]\n",
        "            if cls not in best or s > best[cls]:\n",
        "                best[cls] = s\n",
        "        ranked = sorted(best.items(), key=lambda x: x[1], reverse=True)\n",
        "        preds.append(ranked)\n",
        "    return preds\n",
        "\n",
        "def tune_tau_delta(rank_lists, true_ids, tau_grid_coarse=None, tau_window=0.05, tau_step_fine=0.005, delta_grid=None):\n",
        "    if tau_grid_coarse is None:\n",
        "        tau_grid_coarse = np.arange(0.2, 0.801, 0.02)\n",
        "    if delta_grid is None:\n",
        "        delta_grid = [0.0, 0.03, 0.05, 0.08, 0.10, 0.12, 0.15]\n",
        "    best = (-1.0, 0.5, 0.0)\n",
        "    def build_preds(tau, delta):\n",
        "        out = []\n",
        "        for ranked in rank_lists:\n",
        "            if len(ranked) == 0:\n",
        "                out.append(['new_whale']*5); continue\n",
        "            top1 = ranked[0][1]\n",
        "            top2 = ranked[1][1] if len(ranked) > 1 else -1.0\n",
        "            cond_new = (top1 < tau) or ((top1 - top2) < delta)\n",
        "            if cond_new:\n",
        "                cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "            else:\n",
        "                cand = [c for c,_ in ranked][:5]\n",
        "            uniq = []\n",
        "            for c in cand:\n",
        "                if c not in uniq: uniq.append(c)\n",
        "                if len(uniq) == 5: break\n",
        "            while len(uniq) < 5: uniq.append('new_whale')\n",
        "            out.append(uniq)\n",
        "        return out\n",
        "    # coarse\n",
        "    for dlt in delta_grid:\n",
        "        for tau in tau_grid_coarse:\n",
        "            preds = build_preds(tau, dlt)\n",
        "            m = map5_score(true_ids, preds)\n",
        "            if m > best[0]: best = (m, float(tau), float(dlt))\n",
        "    # fine around best tau\n",
        "    _, tau_c, dlt_c = best\n",
        "    tau_fine = np.arange(max(0.0, tau_c - tau_window), min(1.0, tau_c + tau_window) + 1e-6, tau_step_fine)\n",
        "    for tau in tau_fine:\n",
        "        preds = build_preds(tau, dlt_c)\n",
        "        m = map5_score(true_ids, preds)\n",
        "        if m > best[0]: best = (m, float(tau), float(dlt_c))\n",
        "    return best  # (map5, tau, delta)\n",
        "\n",
        "def build_tiny_only_submission(topK=300):\n",
        "    t0 = time.time()\n",
        "    # Recompute OOF ranked from cached tiny embeddings (train-excl-val gallery per fold)\n",
        "    oof_ranked = []; oof_true = []\n",
        "    for f in range(5):\n",
        "        gal_embs = np.load(f'embeddings/f{f}_gal_embs.npy')\n",
        "        val_embs = np.load(f'embeddings/f{f}_val_embs.npy')\n",
        "        gal_df = pd.read_csv(f'embeddings/f{f}_gal_df.csv')\n",
        "        val_df = pd.read_csv(f'embeddings/f{f}_val_df.csv')\n",
        "        gal_labels = gal_df['Id'].tolist()\n",
        "        ranked = per_class_max_similarity(val_embs, gal_embs, gal_labels, topK=topK)\n",
        "        oof_ranked.extend(ranked)\n",
        "        oof_true.extend(val_df['Id'].tolist())\n",
        "    best_map, best_tau, best_delta = tune_tau_delta(oof_ranked, oof_true)\n",
        "    print(f\"[Tiny-only] OOF tuned: tau={best_tau:.3f}, delta={best_delta:.3f}, MAP@5={best_map:.4f}\")\n",
        "    # Compute TEST rankings using FULL-train gallery per fold (cached full gallery embs + test embs)\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    full_gal_df = train_df[train_df.Id != 'new_whale'].copy()\n",
        "    labs_full = full_gal_df['Id'].tolist()\n",
        "    te_ranked_folds = []\n",
        "    for f in range(5):\n",
        "        gal_full_path = f'embeddings/f{f}_gal_full_embs.npy'\n",
        "        assert os.path.exists(gal_full_path), f\"Missing {gal_full_path}; run cell 11/12 first\"\n",
        "        gal_full = np.load(gal_full_path)\n",
        "        te_embs = np.load(f'embeddings/f{f}_te_embs.npy')\n",
        "        te_ranked = per_class_max_similarity(te_embs, gal_full, labs_full, topK=topK)\n",
        "        te_ranked_folds.append(te_ranked)\n",
        "    # Combine folds by mean\n",
        "    N = len(te_ranked_folds[0])\n",
        "    te_comb = []\n",
        "    for i in range(N):\n",
        "        d = {}\n",
        "        for f in range(5):\n",
        "            for c, s in te_ranked_folds[f][i]:\n",
        "                d.setdefault(c, []).append(s)\n",
        "        arr = [(c, float(np.mean(v))) for c, v in d.items()]\n",
        "        arr.sort(key=lambda x: x[1], reverse=True)\n",
        "        te_comb.append(arr)\n",
        "    # Apply decision rule with best tau/delta\n",
        "    preds5 = []\n",
        "    for ranked in te_comb:\n",
        "        if len(ranked) == 0:\n",
        "            preds5.append('new_whale new_whale new_whale new_whale new_whale'); continue\n",
        "        top1 = ranked[0][1]\n",
        "        top2 = ranked[1][1] if len(ranked) > 1 else -1.0\n",
        "        cond_new = (top1 < best_tau) or ((top1 - top2) < best_delta)\n",
        "        if cond_new:\n",
        "            cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "        else:\n",
        "            cand = [c for c,_ in ranked][:5]\n",
        "        uniq = []\n",
        "        for c in cand:\n",
        "            if c not in uniq: uniq.append(c)\n",
        "            if len(uniq) == 5: break\n",
        "        while len(uniq) < 5: uniq.append('new_whale')\n",
        "        preds5.append(' '.join(uniq))\n",
        "    sub = pd.read_csv('sample_submission.csv')\n",
        "    sub['Id'] = preds5\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print(f\"[Tiny-only] Saved submission.csv (topK={topK}). Elapsed {time.time()-t0:.1f}s\")\n",
        "\n",
        "# Run tiny-only improved submission build\n",
        "build_tiny_only_submission(topK=300)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tiny-only] OOF tuned: tau=0.410, delta=0.080, MAP@5=0.4249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tiny-only] Saved submission.csv (topK=300). Elapsed 22.9s\n"
          ]
        }
      ]
    },
    {
      "id": "469661c4-5ca9-4d33-8145-cef42586366a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Tiny-only with Query Expansion (QE) and margin-based new_whale; uses cached tiny embeddings only\n",
        "import os, time, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "\n",
        "def map5_score(y_true_ids, y_pred_ranked_ids):\n",
        "    scores = []\n",
        "    for t, preds in zip(y_true_ids, y_pred_ranked_ids):\n",
        "        score = 0.0\n",
        "        for i, p in enumerate(preds[:5]):\n",
        "            if p == t:\n",
        "                score = 1.0 / (i+1); break\n",
        "        scores.append(score)\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "def faiss_search(query_embs, gallery_embs, topK):\n",
        "    d = gallery_embs.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    index.add(gallery_embs.astype('float32'))\n",
        "    K = min(topK, gallery_embs.shape[0])\n",
        "    sims, idxs = index.search(query_embs.astype('float32'), K)\n",
        "    return sims, idxs, index\n",
        "\n",
        "def query_expansion(query_embs, gallery_embs, idxs, m=5, alpha=0.3):\n",
        "    # expanded_q = normalize(q + alpha * mean(top-m gallery vecs))\n",
        "    q_new = []\n",
        "    for i in range(query_embs.shape[0]):\n",
        "        top_idx = idxs[i, :min(m, idxs.shape[1])]\n",
        "        neigh = gallery_embs[top_idx]\n",
        "        mean_vec = neigh.mean(axis=0)\n",
        "        v = query_embs[i] + alpha * mean_vec\n",
        "        v = v / (np.linalg.norm(v) + 1e-9)\n",
        "        q_new.append(v.astype('float32'))\n",
        "    return np.vstack(q_new)\n",
        "\n",
        "def per_class_rank_from_search(idxs, sims, gallery_labels):\n",
        "    preds = []\n",
        "    for qi in range(idxs.shape[0]):\n",
        "        best = {}\n",
        "        for j in range(idxs.shape[1]):\n",
        "            gi = int(idxs[qi, j]); s = float(sims[qi, j]); cls = gallery_labels[gi]\n",
        "            if cls not in best or s > best[cls]:\n",
        "                best[cls] = s\n",
        "        ranked = sorted(best.items(), key=lambda x: x[1], reverse=True)\n",
        "        preds.append(ranked)\n",
        "    return preds\n",
        "\n",
        "def tune_tau_delta(rank_lists, true_ids, tau_grid_coarse=None, tau_window=0.05, tau_step_fine=0.005, delta_grid=None):\n",
        "    if tau_grid_coarse is None:\n",
        "        tau_grid_coarse = np.arange(0.2, 0.801, 0.02)\n",
        "    if delta_grid is None:\n",
        "        delta_grid = [0.0, 0.03, 0.05, 0.08, 0.10, 0.12, 0.15]\n",
        "    best = (-1.0, 0.5, 0.0)\n",
        "    def build_preds(tau, delta):\n",
        "        out = []\n",
        "        for ranked in rank_lists:\n",
        "            if len(ranked) == 0:\n",
        "                out.append(['new_whale']*5); continue\n",
        "            top1 = ranked[0][1]\n",
        "            top2 = ranked[1][1] if len(ranked) > 1 else -1.0\n",
        "            cond_new = (top1 < tau) or ((top1 - top2) < delta)\n",
        "            if cond_new:\n",
        "                cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "            else:\n",
        "                cand = [c for c,_ in ranked][:5]\n",
        "            uniq = []\n",
        "            for c in cand:\n",
        "                if c not in uniq: uniq.append(c)\n",
        "                if len(uniq) == 5: break\n",
        "            while len(uniq) < 5: uniq.append('new_whale')\n",
        "            out.append(uniq)\n",
        "        return out\n",
        "    for dlt in delta_grid:\n",
        "        for tau in tau_grid_coarse:\n",
        "            preds = build_preds(tau, dlt)\n",
        "            m = map5_score(true_ids, preds)\n",
        "            if m > best[0]: best = (m, float(tau), float(dlt))\n",
        "    _, tau_c, dlt_c = best\n",
        "    tau_fine = np.arange(max(0.0, tau_c - tau_window), min(1.0, tau_c + tau_window) + 1e-6, tau_step_fine)\n",
        "    for tau in tau_fine:\n",
        "        preds = build_preds(tau, dlt_c)\n",
        "        m = map5_score(true_ids, preds)\n",
        "        if m > best[0]: best = (m, float(tau), float(dlt_c))\n",
        "    return best  # (map5, tau, delta)\n",
        "\n",
        "def tiny_qe_submission(topK_search=300, m_qe=5, alpha=0.3):\n",
        "    t0 = time.time()\n",
        "    # OOF with QE on tiny folds (train-excl-val gallery)\n",
        "    oof_ranked = []; oof_true = []\n",
        "    for f in range(5):\n",
        "        gal_embs = np.load(f'embeddings/f{f}_gal_embs.npy')\n",
        "        val_embs = np.load(f'embeddings/f{f}_val_embs.npy')\n",
        "        gal_df = pd.read_csv(f'embeddings/f{f}_gal_df.csv')\n",
        "        val_df = pd.read_csv(f'embeddings/f{f}_val_df.csv')\n",
        "        gal_labels = gal_df['Id'].tolist()\n",
        "        sims1, idxs1, index = faiss_search(val_embs, gal_embs, topK_search)\n",
        "        val_qe = query_expansion(val_embs, gal_embs, idxs1, m=m_qe, alpha=alpha)\n",
        "        sims2, idxs2 = index.search(val_qe.astype('float32'), min(topK_search, gal_embs.shape[0]))\n",
        "        ranked = per_class_rank_from_search(idxs2, sims2, gal_labels)\n",
        "        oof_ranked.extend(ranked)\n",
        "        oof_true.extend(val_df['Id'].tolist())\n",
        "    best_map, best_tau, best_delta = tune_tau_delta(oof_ranked, oof_true)\n",
        "    print(f\"[Tiny-QE] OOF tuned: tau={best_tau:.3f}, delta={best_delta:.3f}, MAP@5={best_map:.4f}\")\n",
        "    # TEST with QE against FULL-train gallery per fold\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    full_gal_df = train_df[train_df.Id != 'new_whale'].copy()\n",
        "    labs_full = full_gal_df['Id'].tolist()\n",
        "    te_ranked_folds = []\n",
        "    for f in range(5):\n",
        "        gal_full_path = f'embeddings/f{f}_gal_full_embs.npy'\n",
        "        assert os.path.exists(gal_full_path), f\"Missing {gal_full_path}; run earlier cells first\"\n",
        "        gal_full = np.load(gal_full_path)\n",
        "        te_embs = np.load(f'embeddings/f{f}_te_embs.npy')\n",
        "        sims1, idxs1, index = faiss_search(te_embs, gal_full, topK_search)\n",
        "        te_qe = query_expansion(te_embs, gal_full, idxs1, m=m_qe, alpha=alpha)\n",
        "        sims2, idxs2 = index.search(te_qe.astype('float32'), min(topK_search, gal_full.shape[0]))\n",
        "        ranked = per_class_rank_from_search(idxs2, sims2, labs_full)\n",
        "        te_ranked_folds.append(ranked)\n",
        "    # Combine folds by mean\n",
        "    N = len(te_ranked_folds[0])\n",
        "    te_comb = []\n",
        "    for i in range(N):\n",
        "        d = {}\n",
        "        for f in range(5):\n",
        "            for c, s in te_ranked_folds[f][i]:\n",
        "                d.setdefault(c, []).append(s)\n",
        "        arr = [(c, float(np.mean(v))) for c, v in d.items()]\n",
        "        arr.sort(key=lambda x: x[1], reverse=True)\n",
        "        te_comb.append(arr)\n",
        "    # Apply decision rule with best tau/delta\n",
        "    preds5 = []\n",
        "    for ranked in te_comb:\n",
        "        if len(ranked) == 0:\n",
        "            preds5.append('new_whale new_whale new_whale new_whale new_whale'); continue\n",
        "        top1 = ranked[0][1]\n",
        "        top2 = ranked[1][1] if len(ranked) > 1 else -1.0\n",
        "        cond_new = (top1 < best_tau) or ((top1 - top2) < best_delta)\n",
        "        if cond_new:\n",
        "            cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "        else:\n",
        "            cand = [c for c,_ in ranked][:5]\n",
        "        uniq = []\n",
        "        for c in cand:\n",
        "            if c not in uniq: uniq.append(c)\n",
        "            if len(uniq) == 5: break\n",
        "        while len(uniq) < 5: uniq.append('new_whale')\n",
        "        preds5.append(' '.join(uniq))\n",
        "    sub = pd.read_csv('sample_submission.csv')\n",
        "    sub['Id'] = preds5\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print(f\"[Tiny-QE] Saved submission.csv (topK={topK_search}, m={m_qe}, alpha={alpha}). Elapsed {time.time()-t0:.1f}s\")\n",
        "\n",
        "# Run Tiny-only QE with light params\n",
        "tiny_qe_submission(topK_search=300, m_qe=5, alpha=0.3)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tiny-QE] OOF tuned: tau=0.495, delta=0.080, MAP@5=0.4255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tiny-QE] Saved submission.csv (topK=300, m=5, alpha=0.3). Elapsed 25.7s\n"
          ]
        }
      ]
    },
    {
      "id": "0cc15dc5-972f-4073-b8e4-9b54ca0276af",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Tiny-only ensemble: baseline + QE + class-prior weighting; OOF-tune blend u, prior alpha, tau, delta; cached embeddings only\n",
        "import os, time, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "\n",
        "def faiss_search(query_embs, gallery_embs, topK):\n",
        "    d = gallery_embs.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    index.add(gallery_embs.astype('float32'))\n",
        "    K = min(topK, gallery_embs.shape[0])\n",
        "    sims, idxs = index.search(query_embs.astype('float32'), K)\n",
        "    return sims, idxs, index\n",
        "\n",
        "def per_class_rank_from_search(idxs, sims, gallery_labels):\n",
        "    preds = []\n",
        "    for qi in range(idxs.shape[0]):\n",
        "        best = {}\n",
        "        for j in range(idxs.shape[1]):\n",
        "            gi = int(idxs[qi, j]); s = float(sims[qi, j]); cls = gallery_labels[gi]\n",
        "            if cls not in best or s > best[cls]:\n",
        "                best[cls] = s\n",
        "        ranked = sorted(best.items(), key=lambda x: x[1], reverse=True)\n",
        "        preds.append(ranked)\n",
        "    return preds\n",
        "\n",
        "def query_expansion(query_embs, gallery_embs, idxs, m=5, alpha=0.3):\n",
        "    q_new = []\n",
        "    for i in range(query_embs.shape[0]):\n",
        "        top_idx = idxs[i, :min(m, idxs.shape[1])]\n",
        "        neigh = gallery_embs[top_idx]\n",
        "        mean_vec = neigh.mean(axis=0)\n",
        "        v = query_embs[i] + alpha * mean_vec\n",
        "        v = v / (np.linalg.norm(v) + 1e-9)\n",
        "        q_new.append(v.astype('float32'))\n",
        "    return np.vstack(q_new)\n",
        "\n",
        "def map5_score(y_true_ids, y_pred_ranked_ids):\n",
        "    scores = []\n",
        "    for t, preds in zip(y_true_ids, y_pred_ranked_ids):\n",
        "        score = 0.0\n",
        "        for i, p in enumerate(preds[:5]):\n",
        "            if p == t:\n",
        "                score = 1.0 / (i+1); break\n",
        "        scores.append(score)\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "def tune_tau_delta(rank_lists, true_ids, tau_grid_coarse=None, tau_window=0.05, tau_step_fine=0.005, delta_grid=None):\n",
        "    if tau_grid_coarse is None:\n",
        "        tau_grid_coarse = np.arange(0.2, 0.801, 0.02)\n",
        "    if delta_grid is None:\n",
        "        delta_grid = [0.0, 0.03, 0.05, 0.08, 0.10, 0.12, 0.15]\n",
        "    best = (-1.0, 0.5, 0.0)\n",
        "    def build_preds(tau, delta):\n",
        "        out = []\n",
        "        for ranked in rank_lists:\n",
        "            if len(ranked) == 0:\n",
        "                out.append(['new_whale']*5); continue\n",
        "            top1 = ranked[0][1]\n",
        "            top2 = ranked[1][1] if len(ranked) > 1 else -1.0\n",
        "            cond_new = (top1 < tau) or ((top1 - top2) < delta)\n",
        "            if cond_new:\n",
        "                cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "            else:\n",
        "                cand = [c for c,_ in ranked][:5]\n",
        "            uniq = []\n",
        "            for c in cand:\n",
        "                if c not in uniq: uniq.append(c)\n",
        "                if len(uniq) == 5: break\n",
        "            while len(uniq) < 5: uniq.append('new_whale')\n",
        "            out.append(uniq)\n",
        "        return out\n",
        "    for dlt in delta_grid:\n",
        "        for tau in tau_grid_coarse:\n",
        "            preds = build_preds(tau, dlt)\n",
        "            m = map5_score(true_ids, preds)\n",
        "            if m > best[0]: best = (m, float(tau), float(dlt))\n",
        "    _, tau_c, dlt_c = best\n",
        "    tau_fine = np.arange(max(0.0, tau_c - tau_window), min(1.0, tau_c + tau_window) + 1e-6, tau_step_fine)\n",
        "    for tau in tau_fine:\n",
        "        preds = build_preds(tau, dlt_c)\n",
        "        m = map5_score(true_ids, preds)\n",
        "        if m > best[0]: best = (m, float(tau), float(dlt_c))\n",
        "    return best  # (map5, tau, delta)\n",
        "\n",
        "def apply_class_prior(ranked_list, freq_map, alpha=0.0):\n",
        "    if alpha <= 0.0: return ranked_list\n",
        "    adj = []\n",
        "    for c, s in ranked_list:\n",
        "        f = freq_map.get(c, 1.0)\n",
        "        adj.append((c, float(s * (f ** alpha))))\n",
        "    adj.sort(key=lambda x: x[1], reverse=True)\n",
        "    return adj\n",
        "\n",
        "def merge_two_rank_lists(r1, r2, u=0.5):\n",
        "    d = {}\n",
        "    for c, s in r1: d.setdefault(c, []).append((1.0 - u) * s)\n",
        "    for c, s in r2: d.setdefault(c, []).append(u * s)\n",
        "    out = [(c, float(np.sum(v))) for c, v in d.items()]\n",
        "    out.sort(key=lambda x: x[1], reverse=True)\n",
        "    return out\n",
        "\n",
        "def tiny_ensemble_qe_prior(topK=300, m_qe=5, alpha_qe=0.3, u_grid=(0.0, 0.2, 0.5, 0.8, 1.0), alpha_prior_grid=(0.0, 0.1, 0.2, 0.3)):\n",
        "    t0 = time.time()\n",
        "    # Build class frequency prior from full train (exclude new_whale)\n",
        "    tr = pd.read_csv('train.csv')\n",
        "    freq = tr[tr.Id != 'new_whale']['Id'].value_counts().to_dict()\n",
        "    # OOF: baseline + QE using train-excl-val gallery\n",
        "    oof_base = []; oof_qe = []; oof_true = []\n",
        "    for f in range(5):\n",
        "        gal = np.load(f'embeddings/f{f}_gal_embs.npy')\n",
        "        val = np.load(f'embeddings/f{f}_val_embs.npy')\n",
        "        gal_df = pd.read_csv(f'embeddings/f{f}_gal_df.csv')\n",
        "        val_df = pd.read_csv(f'embeddings/f{f}_val_df.csv')\n",
        "        labs = gal_df['Id'].tolist()\n",
        "        sims1, idxs1, index = faiss_search(val, gal, topK)\n",
        "        base_rank = per_class_rank_from_search(idxs1, sims1, labs)\n",
        "        val_qe = query_expansion(val, gal, idxs1, m=m_qe, alpha=alpha_qe)\n",
        "        sims2, idxs2 = index.search(val_qe.astype('float32'), min(topK, gal.shape[0]))\n",
        "        qe_rank = per_class_rank_from_search(idxs2, sims2, labs)\n",
        "        oof_base.extend(base_rank); oof_qe.extend(qe_rank)\n",
        "        oof_true.extend(val_df['Id'].tolist())\n",
        "    # Grid over u and alpha_prior\n",
        "    best = (-1.0, 0.5, 0.0, 0.0)  # (map, tau, delta, u, alpha_prior)\n",
        "    best_u, best_ap = 0.0, 0.0\n",
        "    for u in u_grid:\n",
        "        for ap in alpha_prior_grid:\n",
        "            merged = []\n",
        "            for b, q in zip(oof_base, oof_qe):\n",
        "                r = merge_two_rank_lists(b, q, u=u)\n",
        "                r = apply_class_prior(r, freq, alpha=ap)\n",
        "                merged.append(r)\n",
        "            m, tau, dlt = tune_tau_delta(merged, oof_true)\n",
        "            # tune_tau_delta returns (map, tau, delta)\n",
        "            if m > best[0]:\n",
        "                best = (m, tau, dlt, u, ap)\n",
        "                best_u, best_ap = u, ap\n",
        "    print(f\"[Tiny-Ens] OOF best: u={best_u:.2f}, prior_alpha={best_ap:.2f}, tau={best[1]:.3f}, delta={best[2]:.3f}, MAP@5={best[0]:.4f}\")\n",
        "    # TEST on full-train gallery per fold\n",
        "    full_gal_df = tr[tr.Id != 'new_whale'].copy()\n",
        "    labs_full = full_gal_df['Id'].tolist()\n",
        "    te_ranked_folds = []\n",
        "    for f in range(5):\n",
        "        gal_full = np.load(f'embeddings/f{f}_gal_full_embs.npy')\n",
        "        te = np.load(f'embeddings/f{f}_te_embs.npy')\n",
        "        sims1, idxs1, index = faiss_search(te, gal_full, topK)\n",
        "        base_rank = per_class_rank_from_search(idxs1, sims1, labs_full)\n",
        "        te_qe = query_expansion(te, gal_full, idxs1, m=m_qe, alpha=alpha_qe)\n",
        "        sims2, idxs2 = index.search(te_qe.astype('float32'), min(topK, gal_full.shape[0]))\n",
        "        qe_rank = per_class_rank_from_search(idxs2, sims2, labs_full)\n",
        "        # merge + prior\n",
        "        merged = []\n",
        "        for b, q in zip(base_rank, qe_rank):\n",
        "            r = merge_two_rank_lists(b, q, u=best_u)\n",
        "            r = apply_class_prior(r, freq, alpha=best_ap)\n",
        "            merged.append(r)\n",
        "        te_ranked_folds.append(merged)\n",
        "    # Combine folds by mean\n",
        "    N = len(te_ranked_folds[0])\n",
        "    te_comb = []\n",
        "    for i in range(N):\n",
        "        d = {}\n",
        "        for f in range(5):\n",
        "            for c, s in te_ranked_folds[f][i]:\n",
        "                d.setdefault(c, []).append(s)\n",
        "        arr = [(c, float(np.mean(v))) for c, v in d.items()]\n",
        "        arr.sort(key=lambda x: x[1], reverse=True)\n",
        "        te_comb.append(arr)\n",
        "    # Apply decision rule\n",
        "    _, tau_star, dlt_star, _, _ = best\n",
        "    preds5 = []\n",
        "    for ranked in te_comb:\n",
        "        if len(ranked) == 0:\n",
        "            preds5.append('new_whale new_whale new_whale new_whale new_whale'); continue\n",
        "        top1 = ranked[0][1]\n",
        "        top2 = ranked[1][1] if len(ranked) > 1 else -1.0\n",
        "        cond_new = (top1 < tau_star) or ((top1 - top2) < dlt_star)\n",
        "        if cond_new:\n",
        "            cand = ['new_whale'] + [c for c,_ in ranked][:4]\n",
        "        else:\n",
        "            cand = [c for c,_ in ranked][:5]\n",
        "        uniq = []\n",
        "        for c in cand:\n",
        "            if c not in uniq: uniq.append(c)\n",
        "            if len(uniq) == 5: break\n",
        "        while len(uniq) < 5: uniq.append('new_whale')\n",
        "        preds5.append(' '.join(uniq))\n",
        "    sub = pd.read_csv('sample_submission.csv')\n",
        "    sub['Id'] = preds5\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print(f\"[Tiny-Ens] Saved submission.csv (topK={topK}). Elapsed {time.time()-t0:.1f}s\")\n",
        "\n",
        "# Run tiny-only ensemble with prior\n",
        "tiny_ensemble_qe_prior(topK=300, m_qe=5, alpha_qe=0.3, u_grid=(0.0,0.2,0.5,0.8,1.0), alpha_prior_grid=(0.0,0.1,0.2))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tiny-Ens] OOF best: u=0.20, prior_alpha=0.10, tau=0.515, delta=0.080, MAP@5=0.4357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tiny-Ens] Saved submission.csv (topK=300). Elapsed 381.1s\n"
          ]
        }
      ]
    },
    {
      "id": "053b7ef8-a47b-49c0-b4ad-62129ef81f74",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OpenCLIP ViT-L/14@336 retrieval + ensemble with Tiny; OOF-tune weights and tau/delta; fast frozen model\n",
        "import os, time, gc, math, sys, subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import faiss\n",
        "\n",
        "def pip(*args):\n",
        "    print('>', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Ensure open_clip without touching torch stack\n",
        "pip('install', '-c', 'constraints.txt', 'open_clip_torch==2.26.1', '--upgrade-strategy', 'only-if-needed')\n",
        "import open_clip\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('[CLIP] Device:', device)\n",
        "\n",
        "def l2norm_np(x):\n",
        "    n = np.linalg.norm(x, axis=1, keepdims=True) + 1e-9\n",
        "    return (x / n).astype('float32')\n",
        "\n",
        "def build_img_loader(df, preprocess, img_dir, batch_size=128, num_workers=8):\n",
        "    class ImgDS(torch.utils.data.Dataset):\n",
        "        def __init__(self, df, img_dir, preprocess):\n",
        "            self.df = df.reset_index(drop=True); self.img_dir = img_dir; self.pp = preprocess\n",
        "        def __len__(self): return len(self.df)\n",
        "        def __getitem__(self, i):\n",
        "            p = os.path.join(self.img_dir, self.df.iloc[i]['Image'])\n",
        "            with Image.open(p) as im:\n",
        "                im = im.convert('RGB')\n",
        "                return self.pp(im), self.df.iloc[i]['Image']\n",
        "    ds = ImgDS(df, img_dir, preprocess)\n",
        "    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
        "    return dl\n",
        "\n",
        "def extract_openclip_embeddings(model, preprocess, df, img_dir, batch_size=128):\n",
        "    dl = build_img_loader(df, preprocess, img_dir, batch_size=batch_size)\n",
        "    embs = []; t0 = time.time(); n=0\n",
        "    model.eval()\n",
        "    autocast = torch.amp.autocast('cuda', enabled=torch.cuda.is_available())\n",
        "    with torch.no_grad(), autocast:\n",
        "        for i, (imgs, _) in enumerate(dl):\n",
        "            imgs = imgs.to(device, non_blocking=True)\n",
        "            feats = model.encode_image(imgs)\n",
        "            feats = feats.float()\n",
        "            embs.append(feats.detach().cpu().numpy())\n",
        "            n += imgs.size(0)\n",
        "            if (i+1) % 20 == 0:\n",
        "                print(f'[CLIP] {n}/{len(df)} imgs, elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "    embs = np.concatenate(embs, axis=0)\n",
        "    return l2norm_np(embs)\n",
        "\n",
        "def per_class_max_from_search(idxs, sims, labels):\n",
        "    out = []\n",
        "    for qi in range(idxs.shape[0]):\n",
        "        best = {}\n",
        "        for j in range(idxs.shape[1]):\n",
        "            gi = int(idxs[qi, j]); s = float(sims[qi, j]); c = labels[gi]\n",
        "            if c not in best or s > best[c]: best[c] = s\n",
        "        ranked = sorted(best.items(), key=lambda x: x[1], reverse=True)\n",
        "        out.append(ranked)\n",
        "    return out\n",
        "\n",
        "def faiss_ip_search(Q, G, topK=300):\n",
        "    d = G.shape[1]; index = faiss.IndexFlatIP(d); index.add(G.astype('float32'))\n",
        "    K = min(topK, G.shape[0])\n",
        "    sims, idxs = index.search(Q.astype('float32'), K)\n",
        "    return sims, idxs\n",
        "\n",
        "def map5_score(y_true_ids, y_pred_ranked_ids):\n",
        "    scores = []\n",
        "    for t, preds in zip(y_true_ids, y_pred_ranked_ids):\n",
        "        sc = 0.0\n",
        "        for i, p in enumerate(preds[:5]):\n",
        "            if p == t: sc = 1.0/(i+1); break\n",
        "        scores.append(sc)\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "def tune_tau_delta(rank_lists, true_ids, tau_grid_coarse=None, tau_window=0.05, tau_step_fine=0.005, delta_grid=None):\n",
        "    if tau_grid_coarse is None: tau_grid_coarse = np.arange(0.2, 0.801, 0.02)\n",
        "    if delta_grid is None: delta_grid = [0.0, 0.03, 0.05, 0.08, 0.10, 0.12, 0.15]\n",
        "    best = (-1.0, 0.5, 0.0)\n",
        "    def preds_for(tau, delta):\n",
        "        out = []\n",
        "        for ranked in rank_lists:\n",
        "            if len(ranked) == 0: out.append(['new_whale']*5); continue\n",
        "            top1 = ranked[0][1]; top2 = ranked[1][1] if len(ranked)>1 else -1.0\n",
        "            new_flag = (top1 < tau) or ((top1-top2) < delta)\n",
        "            cand = (['new_whale'] + [c for c,_ in ranked][:4]) if new_flag else [c for c,_ in ranked][:5]\n",
        "            uniq = []\n",
        "            for c in cand:\n",
        "                if c not in uniq: uniq.append(c)\n",
        "                if len(uniq)==5: break\n",
        "            while len(uniq)<5: uniq.append('new_whale')\n",
        "            out.append(uniq)\n",
        "        return out\n",
        "    for dlt in delta_grid:\n",
        "        for tau in tau_grid_coarse:\n",
        "            m = map5_score(true_ids, preds_for(tau, dlt))\n",
        "            if m > best[0]: best = (m, float(tau), float(dlt))\n",
        "    _, tau_c, dlt_c = best\n",
        "    tau_fine = np.arange(max(0.0, tau_c-tau_window), min(1.0, tau_c+tau_window)+1e-6, tau_step_fine)\n",
        "    for tau in tau_fine:\n",
        "        m = map5_score(true_ids, preds_for(tau, dlt_c))\n",
        "        if m > best[0]: best = (m, float(tau), float(dlt_c))\n",
        "    return best  # (map, tau, delta)\n",
        "\n",
        "def merge_rank_lists_weighted(r1, r2, w=0.5):\n",
        "    d = {}\n",
        "    for c,s in r1: d.setdefault(c, []).append((1.0-w)*s)\n",
        "    for c,s in r2: d.setdefault(c, []).append(w*s)\n",
        "    arr = [(c, float(np.sum(v))) for c,v in d.items()]\n",
        "    arr.sort(key=lambda x: x[1], reverse=True)\n",
        "    return arr\n",
        "\n",
        "def combine_folds_mean(rank_lists_per_fold):\n",
        "    n_f = len(rank_lists_per_fold); N = len(rank_lists_per_fold[0]); out = []\n",
        "    for i in range(N):\n",
        "        d = {}\n",
        "        for f in range(n_f):\n",
        "            for c,s in rank_lists_per_fold[f][i]: d.setdefault(c, []).append(s)\n",
        "        arr = [(c, float(np.mean(v))) for c,v in d.items()]\n",
        "        arr.sort(key=lambda x: x[1], reverse=True)\n",
        "        out.append(arr)\n",
        "    return out\n",
        "\n",
        "def build_clip_and_ensemble_with_tiny(topK=300, batch_size=128):\n",
        "    t_all = time.time()\n",
        "    # Load OpenCLIP model+preprocess\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14', pretrained='laion2b_s32b_b82k')\n",
        "    model = model.to(device)\n",
        "    # Ensure output features are float32\n",
        "    if hasattr(model, 'float'): model = model.float()\n",
        "    # DataFrames\n",
        "    tr = pd.read_csv('train.csv')\n",
        "    te = pd.read_csv('sample_submission.csv')[['Image']].copy(); te['Id'] = 'new_whale'\n",
        "    folds = pd.read_csv('folds.csv')\n",
        "    tr = tr.merge(folds[['Image','fold']], on='Image', how='left')\n",
        "    # Extract embeddings (cached to disk to re-use)\n",
        "    os.makedirs('embeddings_clip', exist_ok=True)\n",
        "    train_emb_path = 'embeddings_clip/train_clip.npy'\n",
        "    test_emb_path = 'embeddings_clip/test_clip.npy'\n",
        "    if os.path.exists(train_emb_path):\n",
        "        E_tr = np.load(train_emb_path)\n",
        "    else:\n",
        "        print('[CLIP] Extracting train embeddings...')\n",
        "        E_tr = extract_openclip_embeddings(model, preprocess, tr, 'train', batch_size=batch_size)\n",
        "        np.save(train_emb_path, E_tr)\n",
        "    if os.path.exists(test_emb_path):\n",
        "        E_te = np.load(test_emb_path)\n",
        "    else:\n",
        "        print('[CLIP] Extracting test embeddings...')\n",
        "        E_te = extract_openclip_embeddings(model, preprocess, te, 'test', batch_size=batch_size)\n",
        "        np.save(test_emb_path, E_te)\n",
        "    # Build OOF ranks for CLIP using train-excl-val gallery (exclude new_whale)\n",
        "    oof_clip = []; oof_true = []; order_imgs = []\n",
        "    for f in range(5):\n",
        "        mask_val = tr['fold'] == f\n",
        "        df_va = tr.loc[mask_val].reset_index(drop=True)\n",
        "        df_tr = tr.loc[~mask_val].reset_index(drop=True)\n",
        "        gal_df = df_tr[df_tr.Id != 'new_whale'].reset_index(drop=True)\n",
        "        if len(gal_df)==0 or len(df_va)==0: continue\n",
        "        G = E_tr[df_tr.index[df_tr['Id'] != 'new_whale']]; Q = E_tr[mask_val.values]\n",
        "        labs = gal_df['Id'].tolist()\n",
        "        sims, idxs = faiss_ip_search(Q, G, topK=topK)\n",
        "        ranked = per_class_max_from_search(idxs, sims, labs)\n",
        "        oof_clip.extend(ranked); oof_true.extend(df_va['Id'].tolist()); order_imgs.extend(df_va['Image'].tolist())\n",
        "    # Build Test ranks for CLIP using FULL-train gallery (exclude new_whale)\n",
        "    full_gal_df = tr[tr.Id!='new_whale'].reset_index(drop=True)\n",
        "    G_full = E_tr[tr.index[tr['Id']!='new_whale']]; labs_full = full_gal_df['Id'].tolist()\n",
        "    sims_te, idxs_te = faiss_ip_search(E_te, G_full, topK=topK)\n",
        "    te_rank_clip = per_class_max_from_search(idxs_te, sims_te, labs_full)\n",
        "    # Tiny OOF and Tiny Test ranks from cached embeddings (already implemented in prior cells)\n",
        "    # OOF Tiny\n",
        "    oof_tiny = []; oof_true_tiny = []; order_tiny = []\n",
        "    for f in range(5):\n",
        "        gal_embs = np.load(f'embeddings/f{f}_gal_embs.npy')\n",
        "        val_embs = np.load(f'embeddings/f{f}_val_embs.npy')\n",
        "        gal_df = pd.read_csv(f'embeddings/f{f}_gal_df.csv')\n",
        "        val_df = pd.read_csv(f'embeddings/f{f}_val_df.csv')\n",
        "        labs = gal_df['Id'].tolist()\n",
        "        ranked = per_class_max_from_search(faiss_ip_search(val_embs, gal_embs, topK=topK)[1],\n",
        "                                          faiss_ip_search(val_embs, gal_embs, topK=topK)[0],\n",
        "                                          labs)\n",
        "        # Avoid double FAISS search; recompute once properly:\n",
        "        sims, idxs = faiss_ip_search(val_embs, gal_embs, topK=topK)\n",
        "        ranked = per_class_max_from_search(idxs, sims, labs)\n",
        "        oof_tiny.extend(ranked); oof_true_tiny.extend(val_df['Id'].tolist()); order_tiny.extend(val_df['Image'].tolist())\n",
        "    # Align OOF by Image intersection\n",
        "    oof_tiny_map = {img:r for img,r in zip(order_tiny, oof_tiny)}\n",
        "    oof_true_map = {img:t for img,t in zip(order_tiny, oof_true_tiny)}\n",
        "    inter = [img for img in order_imgs if img in oof_tiny_map]\n",
        "    print(f\"[Ensemble] OOF alignment (CLIP \u2229 Tiny): {len(inter)}\")\n",
        "    # Grid-search weight u for CLIP vs Tiny and tune tau/delta on merged ranks\n",
        "    best = (-1.0, 0.5, 0.0, 0.5)  # (map, tau, delta, w_clip)\n",
        "    for w in np.linspace(0.0, 1.0, 21):\n",
        "        merged = []; truth = []\n",
        "        for img in inter:\n",
        "            r_clip = oof_clip[order_imgs.index(img)]  # order_imgs aligned to oof_clip\n",
        "            r_tiny = oof_tiny_map[img]\n",
        "            r = merge_rank_lists_weighted(r_tiny, r_clip, w=w)  # w applied to CLIP\n",
        "            merged.append(r); truth.append(oof_true_map[img])\n",
        "        m, tau, dlt = tune_tau_delta(merged, truth)\n",
        "        if m > best[0]: best = (m, tau, dlt, float(w))\n",
        "    print(f\"[Ensemble] OOF best: w_clip={best[3]:.2f}, tau={best[1]:.3f}, delta={best[2]:.3f}, MAP@5={best[0]:.4f}\")\n",
        "    # Build Tiny Test combined (across 5 folds) using cached full gallery\n",
        "    train_csv = pd.read_csv('train.csv'); full_gal_df2 = train_csv[train_csv.Id!='new_whale'].copy(); labs_full2 = full_gal_df2['Id'].tolist()\n",
        "    te_rank_tiny_folds = []\n",
        "    for f in range(5):\n",
        "        gal_full = np.load(f'embeddings/f{f}_gal_full_embs.npy')\n",
        "        te_embs = np.load(f'embeddings/f{f}_te_embs.npy')\n",
        "        sims, idxs = faiss_ip_search(te_embs, gal_full, topK=topK)\n",
        "        ranked = per_class_max_from_search(idxs, sims, labs_full2)\n",
        "        te_rank_tiny_folds.append(ranked)\n",
        "    te_rank_tiny = combine_folds_mean(te_rank_tiny_folds)\n",
        "    # Merge Tiny and CLIP test ranks with best weight and apply tau/delta\n",
        "    w_clip = best[3]; tau_star = best[1]; dlt_star = best[2]\n",
        "    preds5 = []\n",
        "    for i in range(len(te_rank_clip)):\n",
        "        merged = merge_rank_lists_weighted(te_rank_tiny[i], te_rank_clip[i], w=w_clip)\n",
        "        if len(merged)==0:\n",
        "            preds5.append('new_whale new_whale new_whale new_whale new_whale'); continue\n",
        "        top1 = merged[0][1]; top2 = merged[1][1] if len(merged)>1 else -1.0\n",
        "        is_new = (top1 < tau_star) or ((top1-top2) < dlt_star)\n",
        "        cand = (['new_whale'] + [c for c,_ in merged][:4]) if is_new else [c for c,_ in merged][:5]\n",
        "        uniq = []\n",
        "        for c in cand:\n",
        "            if c not in uniq: uniq.append(c)\n",
        "            if len(uniq)==5: break\n",
        "        while len(uniq)<5: uniq.append('new_whale')\n",
        "        preds5.append(' '.join(uniq))\n",
        "    sub = pd.read_csv('sample_submission.csv')\n",
        "    sub['Id'] = preds5\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print(f\"[Ensemble] Saved submission.csv (Tiny + OpenCLIP ViT-L/14). Total elapsed {time.time()-t_all:.1f}s\")\n",
        "\n",
        "# Execute CLIP extraction and Tiny+CLIP ensemble\n",
        "build_clip_and_ensemble_with_tiny(topK=300, batch_size=128)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> install -c constraints.txt open_clip_torch==2.26.1 --upgrade-strategy only-if-needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open_clip_torch==2.26.1\n  Downloading open_clip_torch-2.26.1-py3-none-any.whl (1.5 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.5/1.5 MB 55.9 MB/s eta 0:00:00\nCollecting huggingface-hub\n  Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 563.3/563.3 KB 531.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch>=1.9.0\n  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 797.1/797.1 MB 224.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n  Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.8/44.8 KB 351.9 MB/s eta 0:00:00\nCollecting timm\n  Downloading timm-1.0.20-py3-none-any.whl (2.5 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.5/2.5 MB 236.1 MB/s eta 0:00:00\nCollecting torchvision\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.0/7.0 MB 224.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting regex\n  Downloading regex-2025.9.18-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (798 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 KB 551.1 MB/s eta 0:00:00\nCollecting tqdm\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 78.5/78.5 KB 446.3 MB/s eta 0:00:00\nCollecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 433.3 MB/s eta 0:00:00\nCollecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 326.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 315.8 MB/s eta 0:00:00\nCollecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 547.7 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 277.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 521.0 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 484.2 MB/s eta 0:00:00\nCollecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 275.3 MB/s eta 0:00:00\nCollecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 395.4 MB/s eta 0:00:00\nCollecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 265.2 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 289.0 MB/s eta 0:00:00\nCollecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 196.0 MB/s eta 0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 308.0 MB/s eta 0:00:00\nCollecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 382.0 MB/s eta 0:00:00\nCollecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 475.2 MB/s eta 0:00:00\nCollecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 150.5 MB/s eta 0:00:00\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 315.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 229.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wcwidth\n  Downloading wcwidth-0.2.14-py2.py3-none-any.whl (37 kB)\nCollecting pyyaml>=5.1\n  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 763.0/763.0 KB 502.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hf-xet<2.0.0,>=1.1.3\n  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.2/3.2 MB 358.3 MB/s eta 0:00:00\nCollecting packaging>=20.9\n  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 66.5/66.5 KB 431.3 MB/s eta 0:00:00\nCollecting requests\n  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.7/64.7 KB 412.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting safetensors\n  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 485.8/485.8 KB 241.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 357.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 370.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nCollecting charset_normalizer<4,>=2\n  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 150.3/150.3 KB 460.0 MB/s eta 0:00:00\nCollecting urllib3<3,>=1.21.1\n  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129.8/129.8 KB 492.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting certifi>=2017.4.17\n  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.2/161.2 KB 509.6 MB/s eta 0:00:00\nCollecting idna<4,>=2.5\n  Downloading idna-3.10-py3-none-any.whl (70 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 70.4/70.4 KB 426.0 MB/s eta 0:00:00\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 472.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, wcwidth, urllib3, typing-extensions, tqdm, sympy, safetensors, regex, pyyaml, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, ftfy, nvidia-cusolver-cu12, huggingface-hub, torch, torchvision, timm, open_clip_torch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nalbumentations 2.0.8 requires albucore==0.0.24, but you have albucore 0.0.33 which is incompatible.\nWARNING: Target directory /app/.pip-target/timm already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision-0.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch-2.4.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/huggingface_hub-0.35.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/huggingface_hub already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/requests-2.32.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/requests already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/certifi-2025.8.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/certifi already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/charset_normalizer-3.4.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/charset_normalizer already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/hf_xet-1.1.10.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/hf_xet already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/idna-3.10.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/idna already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging-25.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/_yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PyYAML-6.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/safetensors already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/safetensors-0.6.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tqdm-4.67.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tqdm already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/urllib3-2.5.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/urllib3 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 certifi-2025.8.3 charset_normalizer-3.4.3 filelock-3.19.1 fsspec-2025.9.0 ftfy-6.3.1 hf-xet-1.1.10 huggingface-hub-0.35.1 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 open_clip_torch-2.26.1 packaging-25.0 pillow-11.3.0 pyyaml-6.0.2 regex-2025.9.18 requests-2.32.5 safetensors-0.6.2 sympy-1.14.0 timm-1.0.20 torch-2.4.1 torchvision-0.19.1 tqdm-4.67.1 triton-3.0.0 typing-extensions-4.15.0 urllib3-2.5.0 wcwidth-0.2.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIP] Device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/open_clip/factory.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=map_location)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIP] Extracting train embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLIP] 2560/7240 imgs, elapsed 367.7s\n"
          ]
        }
      ]
    },
    {
      "id": "1abad70b-aea0-4b78-b891-cbd0b2a6aa55",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Tiny-only with k-reciprocal re-ranking (OOF-tuned tau/delta); uses cached tiny embeddings; single-config (k1=20,k2=6,lambda=0.3) with gal_full fallback\n",
        "import os, time, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def map5_score(y_true_ids, y_pred_ranked_ids):\n",
        "    scores = []\n",
        "    for t, preds in zip(y_true_ids, y_pred_ranked_ids):\n",
        "        sc = 0.0\n",
        "        for i, p in enumerate(preds[:5]):\n",
        "            if p == t:\n",
        "                sc = 1.0/(i+1); break\n",
        "        scores.append(sc)\n",
        "    return float(np.mean(scores))\n",
        "\n",
        "def tune_tau_delta(rank_lists, true_ids, tau_grid_coarse=None, tau_window=0.05, tau_step_fine=0.005, delta_grid=None):\n",
        "    if tau_grid_coarse is None:\n",
        "        tau_grid_coarse = np.arange(0.2, 0.801, 0.02)\n",
        "    if delta_grid is None:\n",
        "        delta_grid = [0.0, 0.03, 0.05, 0.08, 0.10, 0.12, 0.15]\n",
        "    best = (-1.0, 0.5, 0.0)\n",
        "    def build_preds(tau, delta):\n",
        "        out = []\n",
        "        for ranked in rank_lists:\n",
        "            if len(ranked) == 0:\n",
        "                out.append(['new_whale']*5); continue\n",
        "            top1 = ranked[0][1]\n",
        "            top2 = ranked[1][1] if len(ranked) > 1 else -1.0\n",
        "            cond_new = (top1 < tau) or ((top1 - top2) < delta)\n",
        "            cand = (['new_whale'] + [c for c,_ in ranked][:4]) if cond_new else [c for c,_ in ranked][:5]\n",
        "            uniq = []\n",
        "            for c in cand:\n",
        "                if c not in uniq: uniq.append(c)\n",
        "                if len(uniq) == 5: break\n",
        "            while len(uniq) < 5: uniq.append('new_whale')\n",
        "            out.append(uniq)\n",
        "        return out\n",
        "    for dlt in delta_grid:\n",
        "        for tau in tau_grid_coarse:\n",
        "            m = map5_score(true_ids, build_preds(tau, dlt))\n",
        "            if m > best[0]: best = (m, float(tau), float(dlt))\n",
        "    _, tau_c, dlt_c = best\n",
        "    tau_fine = np.arange(max(0.0, tau_c - tau_window), min(1.0, tau_c + tau_window)+1e-6, tau_step_fine)\n",
        "    for tau in tau_fine:\n",
        "        m = map5_score(true_ids, build_preds(tau, dlt_c))\n",
        "        if m > best[0]: best = (m, float(tau), float(dlt_c))\n",
        "    return best  # (map5, tau, delta)\n",
        "\n",
        "def _compute_distance_mats(Q, G):\n",
        "    # Assumes L2-normalized embeddings. Euclidean^2 = 2 - 2*cos\n",
        "    Q = Q.astype('float32'); G = G.astype('float32')\n",
        "    qg = 2.0 - 2.0 * (Q @ G.T)\n",
        "    qq = 2.0 - 2.0 * (Q @ Q.T)\n",
        "    gg = 2.0 - 2.0 * (G @ G.T)\n",
        "    # clamp to non-negative for numerical stability\n",
        "    np.maximum(qg, 0.0, out=qg); np.maximum(qq, 0.0, out=qq); np.maximum(gg, 0.0, out=gg)\n",
        "    return qg, qq, gg\n",
        "\n",
        "def re_ranking_kreciprocal(Q, G, k1=20, k2=6, lambda_value=0.3, print_log=False):\n",
        "    # Adapted from Zhong et al. (CVPR'17) re-ranking; numpy version\n",
        "    # Returns re-ranked distance matrix of shape (nq, ng)\n",
        "    q_g_dist, q_q_dist, g_g_dist = _compute_distance_mats(Q, G)\n",
        "    nq, ng = q_g_dist.shape\n",
        "    all_num = nq + ng\n",
        "    # Combine query and gallery for unified k-reciprocal computation\n",
        "    orig_dist = np.zeros((all_num, all_num), dtype=np.float32)\n",
        "    orig_dist[:nq, :nq] = q_q_dist\n",
        "    orig_dist[:nq, nq:] = q_g_dist\n",
        "    orig_dist[nq:, :nq] = q_g_dist.T\n",
        "    orig_dist[nq:, nq:] = g_g_dist\n",
        "    del q_q_dist, g_g_dist\n",
        "    V = np.zeros_like(orig_dist, dtype=np.float32)\n",
        "    initial_rank = np.argsort(orig_dist, axis=1).astype(np.int32)\n",
        "    for i in range(all_num):\n",
        "        forward_k_neigh_index = initial_rank[i, :min(k1+1, 500)]\n",
        "        backward_k_neigh_index = initial_rank[forward_k_neigh_index, :min(k1+1, 500)]\n",
        "        fi = np.where(backward_k_neigh_index == i)[0]\n",
        "        k_reciprocal_index = forward_k_neigh_index[fi]\n",
        "        k_reciprocal_expansion_index = k_reciprocal_index\n",
        "        for candidate in k_reciprocal_index:\n",
        "            candidate_forward_k = initial_rank[candidate, :int(np.around(k1/2))+1]\n",
        "            candidate_backward_k = initial_rank[candidate_forward_k, :int(np.around(k1/2))+1]\n",
        "            fi2 = np.where(candidate_backward_k == candidate)[0]\n",
        "            if len(np.intersect1d(fi2, np.where(candidate_forward_k==i)[0])) > 2/3*len(fi2):\n",
        "                k_reciprocal_expansion_index = np.append(k_reciprocal_expansion_index, candidate_forward_k)\n",
        "        k_reciprocal_expansion_index = np.unique(k_reciprocal_expansion_index)\n",
        "        weights = np.exp(-orig_dist[i, k_reciprocal_expansion_index])\n",
        "        V[i, k_reciprocal_expansion_index] = weights / np.sum(weights)\n",
        "    if print_log:\n",
        "        print('[ReRank] V computed')\n",
        "    if k2 > 1:\n",
        "        V_qe = np.zeros_like(V, dtype=np.float32)\n",
        "        for i in range(all_num):\n",
        "            idx = initial_rank[i, :k2]\n",
        "            V_qe[i] = V[idx].mean(axis=0)\n",
        "        V = V_qe\n",
        "        if print_log:\n",
        "            print('[ReRank] Query expansion applied')\n",
        "    invIndex = []\n",
        "    for i in range(all_num):\n",
        "        invIndex.append(np.where(V[:, i] != 0)[0])\n",
        "    if print_log:\n",
        "        print('[ReRank] Inverted index built')\n",
        "    jaccard_dist = np.zeros((all_num, all_num), dtype=np.float32)\n",
        "    for i in range(all_num):\n",
        "        temp_min = np.zeros((1, all_num), dtype=np.float32)\n",
        "        indNonZero = np.where(V[i, :] != 0)[0]\n",
        "        indImages = []\n",
        "        for j in indNonZero:\n",
        "            indImages += invIndex[j].tolist()\n",
        "        indImages = np.unique(np.array(indImages))\n",
        "        temp_min[0, indImages] = np.minimum(V[i, indImages], V[indImages, i]).sum(axis=0)\n",
        "        jaccard_dist[i] = 1 - temp_min / (2 - temp_min)\n",
        "    final_dist = jaccard_dist * (1 - lambda_value) + orig_dist * lambda_value\n",
        "    del jaccard_dist, V, orig_dist, initial_rank\n",
        "    # Return only query-gallery part\n",
        "    return final_dist[:nq, nq:]\n",
        "\n",
        "def per_class_rank_from_sim(sim_mat, gallery_labels):\n",
        "    # sim_mat: (nq, ng) similarities in [0,1]\n",
        "    preds = []\n",
        "    for i in range(sim_mat.shape[0]):\n",
        "        best = {}\n",
        "        sims = sim_mat[i]\n",
        "        for gi, s in enumerate(sims):\n",
        "            cls = gallery_labels[gi]\n",
        "            v = float(s)\n",
        "            if (cls not in best) or (v > best[cls]):\n",
        "                best[cls] = v\n",
        "        arr = sorted(best.items(), key=lambda x: x[1], reverse=True)\n",
        "        preds.append(arr)\n",
        "    return preds\n",
        "\n",
        "# Minimal fallback: load convnext_tiny checkpoint and compute FULL gallery embeddings if missing\n",
        "def _fallback_compute_full_gallery_embs(fold, full_gal_df, img_size=384, batch_size=64):\n",
        "    import torch, torchvision.transforms as T\n",
        "    from PIL import Image\n",
        "    import timm\n",
        "    IM_DIR_TRAIN = 'train'\n",
        "    class ImageDS(torch.utils.data.Dataset):\n",
        "        def __init__(self, df, img_dir, tfm):\n",
        "            self.df = df.reset_index(drop=True); self.dir = img_dir; self.tfm = tfm\n",
        "        def __len__(self): return len(self.df)\n",
        "        def __getitem__(self, i):\n",
        "            p = os.path.join(self.dir, self.df.iloc[i]['Image'])\n",
        "            with Image.open(p) as im:\n",
        "                im = im.convert('RGB')\n",
        "                return self.tfm(im), self.df.iloc[i]['Image']\n",
        "    class EmbeddingModel(torch.nn.Module):\n",
        "        def __init__(self, backbone_name='convnext_tiny', embed_dim=512):\n",
        "            super().__init__()\n",
        "            self.backbone = timm.create_model(backbone_name, pretrained=False, num_classes=0, global_pool='avg')\n",
        "            feat_dim = self.backbone.num_features\n",
        "            self.head = torch.nn.Linear(feat_dim, embed_dim, bias=False)\n",
        "            self.bn = torch.nn.BatchNorm1d(embed_dim)\n",
        "        def forward(self, x):\n",
        "            f = self.backbone(x)\n",
        "            e = self.head(f)\n",
        "            e = self.bn(e)\n",
        "            e = torch.nn.functional.normalize(e, p=2, dim=1)\n",
        "            return e\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    tfm = T.Compose([\n",
        "        T.Resize(int(img_size*1.15), interpolation=T.InterpolationMode.BILINEAR),\n",
        "        T.CenterCrop(img_size),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ])\n",
        "    ds = ImageDS(full_gal_df, IM_DIR_TRAIN, tfm)\n",
        "    dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=True)\n",
        "    model = EmbeddingModel('convnext_tiny', 512).to(device)\n",
        "    state = torch.load(f'checkpoints/fold{fold}.pt', map_location=device)\n",
        "    model.load_state_dict(state['model'], strict=True); model.eval()\n",
        "    embs = []\n",
        "    with torch.no_grad():\n",
        "        autocast = torch.amp.autocast('cuda', enabled=torch.cuda.is_available())\n",
        "        with autocast:\n",
        "            for imgs, _ in dl:\n",
        "                imgs = imgs.to(device, non_blocking=True)\n",
        "                e1 = model(imgs)\n",
        "                e2 = model(torch.flip(imgs, dims=[3]))\n",
        "                e = (e1 + e2) / 2.0\n",
        "                embs.append(e.detach().cpu().numpy())\n",
        "    E = np.concatenate(embs, axis=0).astype('float32')\n",
        "    # L2-normalize\n",
        "    E /= (np.linalg.norm(E, axis=1, keepdims=True) + 1e-9)\n",
        "    return E\n",
        "\n",
        "def tiny_krecip_rerank_and_submit(k1_grid=(20,), k2_grid=(6,), lam_grid=(0.3,), topK=None):\n",
        "    t_all = time.time()\n",
        "    k1, k2, lam = int(k1_grid[0]), int(k2_grid[0]), float(lam_grid[0])\n",
        "    # OOF: single-config re-ranking across 5 folds\n",
        "    oof_true = []; oof_ranked = []\n",
        "    for f in range(5):\n",
        "        t_fold = time.time()\n",
        "        gal_embs = np.load(f'embeddings/f{f}_gal_embs.npy')  # (ng, d), L2-normalized\n",
        "        val_embs = np.load(f'embeddings/f{f}_val_embs.npy')  # (nq, d), L2-normalized\n",
        "        gal_df = pd.read_csv(f'embeddings/f{f}_gal_df.csv')\n",
        "        val_df = pd.read_csv(f'embeddings/f{f}_val_df.csv')\n",
        "        gal_labels = gal_df['Id'].tolist()\n",
        "        dist_qg = re_ranking_kreciprocal(val_embs, gal_embs, k1=k1, k2=k2, lambda_value=lam, print_log=False)\n",
        "        sim_qg = 1.0 / (1.0 + dist_qg)  # convert distance to [0,1] similarity\n",
        "        ranked = per_class_rank_from_sim(sim_qg, gal_labels)\n",
        "        oof_ranked.extend(ranked); oof_true.extend(val_df['Id'].tolist())\n",
        "        print(f'[ReRank OOF] fold {f} processed (val={len(val_df)}, gal={len(gal_df)}) in {time.time()-t_fold:.1f}s', flush=True)\n",
        "    # Tune tau/delta on OOF\n",
        "    best_map, best_tau, best_delta = tune_tau_delta(oof_ranked, oof_true)\n",
        "    print(f\"[ReRank OOF] cfg k1={k1}, k2={k2}, lambda={lam} | tau={best_tau:.3f}, delta={best_delta:.3f}, MAP@5={best_map:.4f}\")\n",
        "    # TEST: compute re-ranked sim for each fold using FULL-train gallery embeddings (fallback if missing)\n",
        "    tr = pd.read_csv('train.csv')\n",
        "    full_gal_df = tr[tr.Id != 'new_whale'].copy()\n",
        "    labs_full = full_gal_df['Id'].tolist()\n",
        "    te_ranked_folds = []\n",
        "    for f in range(5):\n",
        "        t_fold = time.time()\n",
        "        gal_full_path = f'embeddings/f{f}_gal_full_embs.npy'\n",
        "        if os.path.exists(gal_full_path):\n",
        "            gal_full = np.load(gal_full_path)\n",
        "        else:\n",
        "            print(f'[ReRank TEST] fold {f}: gal_full missing; computing via checkpoint...', flush=True)\n",
        "            gal_full = _fallback_compute_full_gallery_embs(f, full_gal_df, img_size=384, batch_size=64)\n",
        "            os.makedirs('embeddings', exist_ok=True)\n",
        "            np.save(gal_full_path, gal_full)\n",
        "        te_embs = np.load(f'embeddings/f{f}_te_embs.npy')\n",
        "        dist_qg = re_ranking_kreciprocal(te_embs, gal_full, k1=k1, k2=k2, lambda_value=lam, print_log=False)\n",
        "        sim_qg = 1.0 / (1.0 + dist_qg)\n",
        "        ranked = per_class_rank_from_sim(sim_qg, labs_full)\n",
        "        te_ranked_folds.append(ranked)\n",
        "        print(f'[ReRank TEST] fold {f} processed (test={sim_qg.shape[0]}, gal_full={sim_qg.shape[1]}) in {time.time()-t_fold:.1f}s', flush=True)\n",
        "    # Combine folds by mean score per class\n",
        "    N = len(te_ranked_folds[0])\n",
        "    te_comb = []\n",
        "    for i in range(N):\n",
        "        d = {}\n",
        "        for f in range(5):\n",
        "            for c, s in te_ranked_folds[f][i]:\n",
        "                d.setdefault(c, []).append(s)\n",
        "        arr = [(c, float(np.mean(v))) for c, v in d.items()]\n",
        "        arr.sort(key=lambda x: x[1], reverse=True)\n",
        "        te_comb.append(arr)\n",
        "    # Apply decision rule with best tau/delta\n",
        "    preds5 = []\n",
        "    for ranked in te_comb:\n",
        "        if len(ranked) == 0:\n",
        "            preds5.append('new_whale new_whale new_whale new_whale new_whale'); continue\n",
        "        top1 = ranked[0][1]\n",
        "        top2 = ranked[1][1] if len(ranked) > 1 else -1.0\n",
        "        cond_new = (top1 < best_tau) or ((top1 - top2) < best_delta)\n",
        "        cand = (['new_whale'] + [c for c,_ in ranked][:4]) if cond_new else [c for c,_ in ranked][:5]\n",
        "        uniq = []\n",
        "        for c in cand:\n",
        "            if c not in uniq: uniq.append(c)\n",
        "            if len(uniq) == 5: break\n",
        "        while len(uniq) < 5: uniq.append('new_whale')\n",
        "        preds5.append(' '.join(uniq))\n",
        "    sub = pd.read_csv('sample_submission.csv')\n",
        "    sub['Id'] = preds5\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print(f\"[ReRank] Saved submission.csv | Total elapsed {time.time()-t_all:.1f}s\")\n",
        "\n",
        "# Execute single-config k-reciprocal re-ranking\n",
        "tiny_krecip_rerank_and_submit(k1_grid=(20,), k2_grid=(6,), lam_grid=(0.3,))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}