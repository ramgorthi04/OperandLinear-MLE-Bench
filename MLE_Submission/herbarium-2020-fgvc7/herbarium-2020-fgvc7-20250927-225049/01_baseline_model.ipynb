{
  "cells": [
    {
      "id": "cd571947-59cd-491a-b757-ee60db9be806",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "print(torch.__version__, torch.version.cuda, torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    import torch.backends.cudnn as b\n",
        "    print('cuDNN:', b.version(), 'GPU:', torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "dad2e6e8-f45e-4886-a0c5-7f5d75645c07",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CPU-only PyTorch via direct wheels (exact versions)\n",
        "import sys, subprocess\n",
        "\n",
        "# Uninstall first (ignore failures)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"torch\", \"torchvision\", \"torchaudio\", \"timm\"], check=False)\n",
        "\n",
        "wheels = [\n",
        "  \"https://download.pytorch.org/whl/cpu/torch-2.4.1%2Bcpu-cp311-cp311-linux_x86_64.whl\",\n",
        "  \"https://download.pytorch.org/whl/cpu/torchvision-0.19.1%2Bcpu-cp311-cp311-linux_x86_64.whl\"\n",
        "]\n",
        "for w in wheels:\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"--no-cache-dir\", \"--force-reinstall\", \"--no-deps\", w], check=True)\n",
        "\n",
        "# timm without deps so it can't upgrade torch\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"--no-deps\", \"timm==1.0.20\"], check=True)\n",
        "\n",
        "# other deps (safe)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--user\",\n",
        "                \"albumentations==2.0.8\", \"albucore==0.0.24\",\n",
        "                \"opencv-python-headless==4.11.0.86\", \"scikit-learn==1.4.2\",\n",
        "                \"huggingface_hub\", \"safetensors\"], check=True)\n",
        "\n",
        "print(\"CPU-only stack installed. RESTART KERNEL NOW.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "29dd3b29-6557-408a-a6ff-90d7d2307aef",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "print(torch.__version__, torch.version.cuda, torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    import torch.backends.cudnn as b\n",
        "    print('cuDNN:', b.version(), 'GPU:', torch.cuda.get_device_name(0))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '_C' is not defined",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(torch.__version__, torch.version.cuda, torch.cuda.is_available())\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/torch/__init__.py:764\u001b[39m\n\u001b[32m    761\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[32m    763\u001b[39m __name, __obj = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m __name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m):\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m __name[\u001b[32m0\u001b[39m] != \u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m __name.endswith(\u001b[33m'\u001b[39m\u001b[33mBase\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    766\u001b[39m         __all__.append(__name)\n",
            "\u001b[31mNameError\u001b[39m: name '_C' is not defined"
          ]
        }
      ]
    },
    {
      "id": "84f85971-adc7-42c7-a792-ad0cbf457de4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 0: Hard cleanup\n",
        "import os, sys, subprocess, glob, site, shutil, pathlib\n",
        "\n",
        "# Nuke shadow dirs\n",
        "for d in [\"/app/.pip-target\", os.path.expanduser(\"~/.pip-target\"), \"./pip_pkgs\"]:\n",
        "    try: shutil.rmtree(d); print(\"Removed\", d)\n",
        "    except Exception as e: print(\"Skip/remove failed:\", d, e)\n",
        "\n",
        "# Remove .pth that inject .pip-target/pip_pkgs\n",
        "for sp in [p for p in (site.getsitepackages() + [site.getusersitepackages()]) if p]:\n",
        "    for pth in glob.glob(os.path.join(sp, \"*.pth\")):\n",
        "        try:\n",
        "            txt = open(pth).read()\n",
        "            if \".pip-target\" in txt or \"pip_pkgs\" in txt:\n",
        "                os.remove(pth); print(\"Removed bad .pth:\", pth)\n",
        "        except Exception: pass\n",
        "\n",
        "# Drop refs\n",
        "sys.path = [p for p in sys.path if \".pip-target\" not in p and \"pip_pkgs\" not in p]\n",
        "for k in [\"PIP_TARGET\",\"PYTHONPATH\",\"PYTHONUSERBASE\",\"LD_LIBRARY_PATH\"]:\n",
        "    os.environ.pop(k, None)\n",
        "\n",
        "# Purge cache and uninstall torch stack (ignore failures)\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"cache\",\"purge\"], check=False)\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"uninstall\",\"-y\",\n",
        "                \"torch\",\"torchvision\",\"torchaudio\",\"timm\",\n",
        "                \"nvidia-cudnn-cu12\",\"nvidia-cublas-cu12\",\"nvidia-cufft-cu12\",\n",
        "                \"nvidia-curand-cu12\",\"nvidia-cusolver-cu12\",\"nvidia-cusparse-cu12\",\n",
        "                \"nvidia-nccl-cu12\",\"nvidia-nvjitlink-cu12\",\"nvidia-cuda-runtime-cu12\"], check=False)\n",
        "\n",
        "# Also wipe user-site torch/nvidia dists\n",
        "user_site = pathlib.Path(site.getusersitepackages() or \"\")\n",
        "if user_site.exists():\n",
        "    for pat in (\"torch*\", \"torchvision*\", \"torchaudio*\", \"nvidia*\", \"timm*\", \"albumentations*\", \"albucore*\"):\n",
        "        for p in user_site.glob(pat):\n",
        "            shutil.rmtree(p, ignore_errors=True)\n",
        "print(\"Cleanup done\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skip/remove failed: /app/.pip-target [Errno 16] Device or resource busy: '/app/.pip-target'\nSkip/remove failed: /app/.pip-target [Errno 16] Device or resource busy: '/app/.pip-target'\nSkip/remove failed: ./pip_pkgs [Errno 2] No such file or directory: './pip_pkgs'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip cache commands can not function since cache is disabled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: nvidia-nccl-cu12 2.28.3\nUninstalling nvidia-nccl-cu12-2.28.3:\nCleanup done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\nWARNING: Skipping torchvision as it is not installed.\nWARNING: Skipping torchaudio as it is not installed.\nWARNING: Skipping timm as it is not installed.\nWARNING: Skipping nvidia-cudnn-cu12 as it is not installed.\nWARNING: Skipping nvidia-cublas-cu12 as it is not installed.\nWARNING: Skipping nvidia-cufft-cu12 as it is not installed.\nWARNING: Skipping nvidia-curand-cu12 as it is not installed.\nWARNING: Skipping nvidia-cusolver-cu12 as it is not installed.\nWARNING: Skipping nvidia-cusparse-cu12 as it is not installed.\nERROR: Exception:\nTraceback (most recent call last):\n  File \"/usr/lib/python3.11/shutil.py\", line 824, in move\n    os.rename(src, real_dst)\nOSError: [Errno 18] Invalid cross-device link: '/usr/local/lib/python3.11/dist-packages/nvidia/nccl/include/' -> '/tmp/pip-uninstall-v0rty6cv'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3/dist-packages/pip/_internal/cli/base_command.py\", line 165, in exc_logging_wrapper\n    status = run_func(*args)\n             ^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3/dist-packages/pip/_internal/commands/uninstall.py\", line 97, in run\n    uninstall_pathset = req.uninstall(\n                        ^^^^^^^^^^^^^^\n  File \"/usr/lib/python3/dist-packages/pip/_internal/req/req_install.py\", line 638, in uninstall\n    uninstalled_pathset.remove(auto_confirm, verbose)\n  File \"/usr/lib/python3/dist-packages/pip/_internal/req/req_uninstall.py\", line 369, in remove\n    moved.stash(path)\n  File \"/usr/lib/python3/dist-packages/pip/_internal/req/req_uninstall.py\", line 267, in stash\n    renames(path, new_path)\n  File \"/usr/lib/python3/dist-packages/pip/_internal/utils/misc.py\", line 305, in renames\n    shutil.move(old, new)\n  File \"/usr/lib/python3.11/shutil.py\", line 842, in move\n    rmtree(src)\n  File \"/usr/lib/python3.11/shutil.py\", line 731, in rmtree\n    _rmtree_safe_fd(fd, path, onerror)\n  File \"/usr/lib/python3.11/shutil.py\", line 682, in _rmtree_safe_fd\n    onerror(os.unlink, fullname, sys.exc_info())\n  File \"/usr/lib/python3.11/shutil.py\", line 680, in _rmtree_safe_fd\n    os.unlink(entry.name, dir_fd=topfd)\nOSError: [Errno 30] Read-only file system: 'nccl.h'\n"
          ]
        }
      ]
    },
    {
      "id": "f2532d53-9095-43a1-b1f0-d27dfcaec8bb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 1A: Install torch 2.1.2 + cu118 into user site (no deps upgrades)\n",
        "import sys, subprocess\n",
        "# Use direct wheel URLs to avoid any resolver surprises\n",
        "wheels = [\n",
        " 'https://download.pytorch.org/whl/cu118/torch-2.1.2%2Bcu118-cp311-cp311-linux_x86_64.whl',\n",
        " 'https://download.pytorch.org/whl/cu118/torchvision-0.16.2%2Bcu118-cp311-cp311-linux_x86_64.whl',\n",
        " 'https://download.pytorch.org/whl/cu118/torchaudio-2.1.2%2Bcu118-cp311-cp311-linux_x86_64.whl'\n",
        "]\n",
        "for w in wheels:\n",
        "    subprocess.run([sys.executable,\"-m\",\"pip\",\"install\",\"--user\",\"--no-cache-dir\",\"--force-reinstall\", w], check=True)\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"install\",\"--user\",\"--no-deps\",\"timm==1.0.20\"], check=True)\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"install\",\"--user\",\n",
        "                \"albumentations==2.0.8\",\"albucore==0.0.24\",\n",
        "                \"opencv-python-headless==4.11.0.86\",\"scikit-learn==1.4.2\",\n",
        "                \"huggingface_hub\",\"safetensors\"], check=True)\n",
        "print(\"cu118 stack installed. RESTART KERNEL NOW.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "cbdfb103-6950-412e-840d-1b01dc81d7b2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 1B: Install torch 2.4.1 + cu121 (fallback)\n",
        "import sys, subprocess\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"install\",\"--user\",\"--no-cache-dir\",\"--force-reinstall\",\n",
        "                \"--index-url\",\"https://download.pytorch.org/whl/cu121\",\n",
        "                \"torch==2.4.1\",\"torchvision==0.19.1\",\"torchaudio==2.4.1\"], check=True)\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"install\",\"--user\",\"--no-cache-dir\",\"--force-reinstall\",\n",
        "                \"nvidia-cudnn-cu12==9.1.0.70\"], check=True)\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"install\",\"--user\",\"--no-deps\",\"timm==1.0.20\"], check=True)\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"install\",\"--user\",\n",
        "                \"albumentations==2.0.8\",\"albucore==0.0.24\",\n",
        "                \"opencv-python-headless==4.11.0.86\",\"scikit-learn==1.4.2\",\n",
        "                \"huggingface_hub\",\"safetensors\"], check=True)\n",
        "print(\"cu121 stack installed. RESTART KERNEL NOW.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "edd6e2bd-7f68-4bbc-bf44-ca9c8557729d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "print(torch.__version__, torch.version.cuda, torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    import torch.backends.cudnn as b\n",
        "    print('cuDNN:', b.version(), 'GPU:', torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "837752d3-f2b9-426e-9f38-77b7f30b7bea",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import site\n",
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "home = os.environ.get('HOME', '/app')\n",
        "print('HOME:', home)\n",
        "\n",
        "user_site = site.getusersitepackages()\n",
        "print('site.getusersitepackages():', user_site)\n",
        "\n",
        "expected_user_site = Path(home) / '.local' / 'lib' / 'python3.11' / 'site-packages'\n",
        "print('Expected user site:', expected_user_site)\n",
        "\n",
        "# Check contents\n",
        "print('\\nContents of site.getusersitepackages():')\n",
        "if Path(user_site).exists():\n",
        "    for item in Path(user_site).iterdir():\n",
        "        print('  ', item.name)\n",
        "else:\n",
        "    print('  Directory does not exist')\n",
        "\n",
        "print('\\nContents of expected user site:')\n",
        "if expected_user_site.exists():\n",
        "    for item in expected_user_site.iterdir():\n",
        "        if 'torch' in item.name.lower() or 'nvidia' in item.name.lower():\n",
        "            print('  ', item.name)\n",
        "else:\n",
        "    print('  Directory does not exist')\n",
        "\n",
        "# Add both to sys.path if not present\n",
        "paths_to_add = []\n",
        "if user_site not in sys.path:\n",
        "    paths_to_add.append(user_site)\n",
        "if str(expected_user_site) not in sys.path:\n",
        "    paths_to_add.append(str(expected_user_site))\n",
        "\n",
        "for p in paths_to_add:\n",
        "    sys.path.insert(0, p)\n",
        "    print(f'Added to sys.path: {p}')\n",
        "\n",
        "print('\\nUpdated sys.path[0:3]:', sys.path[:3])\n",
        "\n",
        "# Set LD_LIBRARY_PATH for C extensions before import\n",
        "lib_paths = []\n",
        "\n",
        "# Torch lib\n",
        "torch_lib = str(expected_user_site / 'torch' / 'lib')\n",
        "if Path(torch_lib).exists():\n",
        "    lib_paths.append(torch_lib)\n",
        "    print('Found torch lib:', torch_lib)\n",
        "\n",
        "# NVIDIA libs in user site\n",
        "nvidia_base = expected_user_site / 'nvidia'\n",
        "if nvidia_base.exists():\n",
        "    for subpkg in ['cudnn', 'cublas', 'cufft', 'curand', 'cusolver', 'cusparse', 'nvtx', 'cuda_runtime', 'nvjitlink']:\n",
        "        lib_dir = nvidia_base / subpkg / 'lib'\n",
        "        if lib_dir.exists():\n",
        "            lib_paths.append(str(lib_dir))\n",
        "            print(f'Found nvidia {subpkg} lib:', lib_dir)\n",
        "\n",
        "# System CUDA paths\n",
        "system_paths = ['/usr/local/cuda/lib64', '/usr/lib/x86_64-linux-gnu']\n",
        "for sp in system_paths:\n",
        "    if Path(sp).exists():\n",
        "        lib_paths.append(sp)\n",
        "        print('Added system lib:', sp)\n",
        "\n",
        "# Set LD_LIBRARY_PATH\n",
        "ld_path = ':'.join(lib_paths) + ':' + os.environ.get('LD_LIBRARY_PATH', '')\n",
        "os.environ['LD_LIBRARY_PATH'] = ld_path\n",
        "print('\\nLD_LIBRARY_PATH set to:', ld_path[:200] + '...' if len(ld_path) > 200 else ld_path)\n",
        "\n",
        "# Verify cuDNN so files\n",
        "cudnn_libs = []\n",
        "for lib_dir in lib_paths:\n",
        "    cands = glob.glob(os.path.join(lib_dir, 'libcudnn.so*'))\n",
        "    if cands:\n",
        "        cudnn_libs.extend(cands)\n",
        "        print('Found cuDNN libs:', cands[:3])  # First 3\n",
        "if not cudnn_libs:\n",
        "    print('No cuDNN .so files found - installation incomplete')\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('\\nTorch version:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('CUDA version:', torch.version.cuda)\n",
        "        print('cuDNN version:', torch.backends.cudnn.version() if torch.backends.cudnn.enabled else 'cuDNN not enabled')\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "    else:\n",
        "        print('GPU not available - environment still blocked')\n",
        "    print('Verification complete - SUCCESS')\n",
        "except Exception as e:\n",
        "    print('Import failed:', type(e).__name__, ':', e)\n",
        "    print('Environment still blocked')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "ac0f0e65-8add-4aed-9542-febed17d2cc3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 0 \u2014 Clean user site and install GPU stack (Option 1)\n",
        "import os, sys, subprocess, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Clean user site packages related to torch/nvidia/timm\n",
        "user_site = Path.home() / '.local' / 'lib' / 'python3.11' / 'site-packages'\n",
        "if user_site.exists():\n",
        "    for pkg_dir in user_site.glob('torch*'): shutil.rmtree(pkg_dir, ignore_errors=True)\n",
        "    for pkg_dir in user_site.glob('nvidia*cu12*'): shutil.rmtree(pkg_dir, ignore_errors=True)\n",
        "    for pkg_dir in user_site.glob('timm*'): shutil.rmtree(pkg_dir, ignore_errors=True)\n",
        "    for pkg_dir in user_site.glob('albumentations*'): shutil.rmtree(pkg_dir, ignore_errors=True)\n",
        "    print('Cleaned user site packages')\n",
        "\n",
        "# Uninstall with pip (no --user for uninstall)\n",
        "packages_to_uninstall = ['torch', 'torchvision', 'torchaudio', 'nvidia-cudnn-cu12', 'timm', 'albumentations', 'albucore', 'opencv-python-headless', 'huggingface_hub', 'safetensors']\n",
        "for pkg in packages_to_uninstall:\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "print('Uninstalled packages')\n",
        "\n",
        "# Install torch first with --user\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install', '--user',\n",
        "    '--index-url', 'https://download.pytorch.org/whl/cu121',\n",
        "    'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1'\n",
        "], check=True)\n",
        "print('Torch installed with --user')\n",
        "\n",
        "# Install cuDNN with --user\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install', '--user', '-U',\n",
        "    'nvidia-cudnn-cu12==9.1.0.70'\n",
        "], check=True)\n",
        "print('cuDNN installed with --user')\n",
        "\n",
        "# Install timm with --no-deps --user\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install', '--user', '--no-deps',\n",
        "    'timm==1.0.20'\n",
        "], check=True)\n",
        "print('timm installed with --no-deps --user')\n",
        "\n",
        "# Install other deps with --user\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install', '--user',\n",
        "    'albumentations==2.0.8', 'albucore==0.0.24',\n",
        "    'opencv-python-headless==4.11.0.86', 'scikit-learn==1.4.2',\n",
        "    'huggingface_hub', 'safetensors'\n",
        "], check=True)\n",
        "print('Other deps installed with --user')\n",
        "print('Installs done - restart kernel next')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "481bc8a0-9e93-4b91-bf62-153aba2a2111",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 0 \u2014 Private target install for isolated GPU stack (Option 2)\n",
        "import os, sys, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Create private pip dir\n",
        "PIP_DIR = './pip_pkgs'\n",
        "Path(PIP_DIR).mkdir(exist_ok=True)\n",
        "print('Created PIP_DIR:', PIP_DIR)\n",
        "\n",
        "# Install torch cu121 to target\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install', '--target', PIP_DIR,\n",
        "    '--index-url', 'https://download.pytorch.org/whl/cu121',\n",
        "    'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1'\n",
        "], check=True)\n",
        "print('Torch installed to target')\n",
        "\n",
        "# Install cuDNN to target\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install', '--target', PIP_DIR,\n",
        "    'nvidia-cudnn-cu12==9.1.0.70'\n",
        "], check=True)\n",
        "print('cuDNN installed to target')\n",
        "\n",
        "# Install timm with --no-deps to avoid upgrades\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install', '--target', PIP_DIR, '--no-deps',\n",
        "    'timm==1.0.20'\n",
        "], check=True)\n",
        "print('timm installed to target')\n",
        "\n",
        "# Install other deps to target\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install', '--target', PIP_DIR,\n",
        "    'albumentations==2.0.8', 'albucore==0.0.24',\n",
        "    'opencv-python-headless==4.11.0.86', 'scikit-learn==1.4.2',\n",
        "    'huggingface_hub', 'safetensors'\n",
        "], check=True)\n",
        "print('Other deps installed to target')\n",
        "\n",
        "# Prepend to sys.path and PYTHONPATH\n",
        "if PIP_DIR not in sys.path:\n",
        "    sys.path.insert(0, PIP_DIR)\n",
        "os.environ['PYTHONPATH'] = PIP_DIR + ':' + os.environ.get('PYTHONPATH', '')\n",
        "print('sys.path and PYTHONPATH updated')\n",
        "\n",
        "# Set LD_LIBRARY_PATH to include torch lib and nvidia libs\n",
        "lib_paths = [os.path.join(PIP_DIR, 'torch', 'lib')]\n",
        "for sub in ['nvidia/cudnn/lib', 'nvidia/cublas/lib', 'nvidia/cufft/lib', 'nvidia/curand/lib',\n",
        "            'nvidia/cusolver/lib', 'nvidia/cusparse/lib', 'nvidia/nvtx/lib', 'nvidia/cuda_runtime/lib']:\n",
        "    p = os.path.join(PIP_DIR, sub)\n",
        "    if os.path.isdir(p):\n",
        "        lib_paths.append(p)\n",
        "lib_paths += ['/usr/local/cuda/lib64', '/usr/lib/x86_64-linux-gnu']\n",
        "os.environ['LD_LIBRARY_PATH'] = ':'.join(lib_paths) + ':' + os.environ.get('LD_LIBRARY_PATH', '')\n",
        "print('LD_LIBRARY_PATH set to:', os.environ['LD_LIBRARY_PATH'])\n",
        "\n",
        "# Verify\n",
        "import torch\n",
        "import torch.backends.cudnn as tb\n",
        "print('Torch:', torch.__version__, 'CUDA:', torch.version.cuda)\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "print('cuDNN version:', tb.version() if torch.backends.cudnn.enabled else 'Not enabled')\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('GPU not available')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "50ba0f82-6123-4644-aac0-bc04a71c3fd7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 0 \u2014 Nuke .pip-target, remove path hooks, clean pip, uninstall torch/nvidia\n",
        "import os, sys, subprocess, glob, site, shutil\n",
        "\n",
        "for d in [\"/app/.pip-target\", os.path.expanduser(\"~/.pip-target\")]:\n",
        "    try:\n",
        "        shutil.rmtree(d); print(\"Removed\", d)\n",
        "    except Exception as e:\n",
        "        print(\"Skip/remove failed:\", d, e)\n",
        "\n",
        "# Remove .pth files that add .pip-target to sys.path\n",
        "for sp in [p for p in (site.getsitepackages() + [site.getusersitepackages()]) if p]:\n",
        "    for pth in glob.glob(os.path.join(sp, \"*.pth\")):\n",
        "        try:\n",
        "            txt = open(pth).read()\n",
        "            if \".pip-target\" in txt:\n",
        "                os.remove(pth); print(\"Removed .pth pointing to .pip-target:\", pth)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "sys.path = [p for p in sys.path if \".pip-target\" not in p]\n",
        "for k in [\"PIP_TARGET\",\"PYTHONPATH\",\"PYTHONUSERBASE\"]:\n",
        "    os.environ.pop(k, None)\n",
        "\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"cache\",\"purge\"], check=False)\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"uninstall\",\"-y\",\n",
        "                \"torch\",\"torchvision\",\"torchaudio\",\n",
        "                \"nvidia-cudnn-cu12\",\"nvidia-cublas-cu12\",\"nvidia-cufft-cu12\",\n",
        "                \"nvidia-curand-cu12\",\"nvidia-cusolver-cu12\",\"nvidia-cusparse-cu12\",\n",
        "                \"nvidia-nccl-cu12\",\"nvidia-nvjitlink-cu12\",\"nvidia-cuda-runtime-cu12\"], check=False)\n",
        "print(\"Cleanup done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b7faae8f-7003-43c4-8170-ba605d396416",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 1 \u2014 Install GPU stack cleanly (cu121) with --user to avoid read-only issues\n",
        "import sys, subprocess\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"install\", \"--user\",\n",
        "                \"--index-url\",\"https://download.pytorch.org/whl/cu121\",\n",
        "                \"torch==2.4.1\",\"torchvision==0.19.1\",\"torchaudio==2.4.1\",\"-U\"], check=True)\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"install\", \"--user\", \"-U\",\"nvidia-cudnn-cu12==9.1.0.70\"], check=True)\n",
        "subprocess.run([sys.executable,\"-m\",\"pip\",\"install\", \"--user\",\n",
        "                \"timm==1.0.20\",\"albumentations==2.0.8\",\"albucore==0.0.24\",\n",
        "                \"opencv-python-headless==4.11.0.86\",\"scikit-learn==1.4.2\",\n",
        "                \"huggingface_hub\",\"safetensors\"], check=True)\n",
        "print(\"Installs done with --user\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "2532500a-0f0c-465b-a588-9becbc910ee4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 2 \u2014 Set LD_LIBRARY_PATH and verify GPU\n",
        "import os, importlib, site, glob, sys\n",
        "\n",
        "# Add user site-packages to sys.path for --user installs\n",
        "user_site = site.getusersitepackages()\n",
        "if user_site not in sys.path:\n",
        "    sys.path.insert(0, user_site)\n",
        "print('Added user site to sys.path:', user_site)\n",
        "\n",
        "def lib_dir(modname):\n",
        "    try:\n",
        "        m = importlib.import_module(modname)\n",
        "        base = os.path.dirname(m.__file__)\n",
        "        for sub in (\"lib\",\"lib64\"):\n",
        "            p = os.path.join(base, sub)\n",
        "            if os.path.isdir(p): return p\n",
        "    except Exception as e:\n",
        "        print(f'Failed to find lib for {modname}: {e}')\n",
        "        return None\n",
        "\n",
        "lib_paths = []\n",
        "for m in [\"nvidia.cudnn\",\"nvidia.cublas\",\"nvidia.cufft\",\"nvidia.curand\",\n",
        "          \"nvidia.cusolver\",\"nvidia.cusparse\",\"nvidia.nvtx\",\"nvidia.cuda_runtime\",\"nvidia.nvjitlink\"]:\n",
        "    p = lib_dir(m)\n",
        "    if p: lib_paths.append(p)\n",
        "\n",
        "# Torch lib in user site\n",
        "user_torch_lib = os.path.join(user_site, \"torch\", \"lib\")\n",
        "if os.path.isdir(user_torch_lib): \n",
        "    lib_paths.append(user_torch_lib)\n",
        "    print('Found torch lib in user site:', user_torch_lib)\n",
        "\n",
        "torch_lib = os.path.join(site.getsitepackages()[0], \"torch\", \"lib\")\n",
        "if os.path.isdir(torch_lib): lib_paths.append(torch_lib)\n",
        "for p in [\"/usr/local/cuda/lib64\",\"/usr/lib/x86_64-linux-gnu\"]:\n",
        "    if os.path.isdir(p): lib_paths.append(p)\n",
        "\n",
        "print('Discovered lib paths:', lib_paths)\n",
        "\n",
        "# Ensure libcudnn.so.9 soname exists\n",
        "cudnn = lib_dir(\"nvidia.cudnn\")\n",
        "if cudnn:\n",
        "    cands = sorted(glob.glob(os.path.join(cudnn, \"libcudnn.so.9*\")))\n",
        "    if cands and not os.path.exists(os.path.join(cudnn, \"libcudnn.so.9\")):\n",
        "        try: os.symlink(os.path.basename(cands[-1]), os.path.join(cudnn, \"libcudnn.so.9\"))\n",
        "        except FileExistsError: pass\n",
        "    print('cuDNN lib dir:', cudnn)\n",
        "\n",
        "os.environ[\"LD_LIBRARY_PATH\"] = \":\".join(lib_paths) + \":\" + os.environ.get(\"LD_LIBRARY_PATH\",\"\")\n",
        "print(\"LD_LIBRARY_PATH set\")\n",
        "\n",
        "import torch, torch.backends.cudnn as tb\n",
        "print(\"Torch:\", torch.__version__, \"CUDA:\", torch.version.cuda)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"cuDNN:\", tb.version())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('GPU not available')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "9140243c-1e92-4b07-a62b-1fd32e5a51d9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cell 0 \u2014 GPU env setup (Plan B: switch to cu118 torch to unblock cuDNN)\n",
        "import os, glob, importlib, site\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# 1) Uninstall current torch and install cu118 version (uses cuDNN 8, likely available in system)\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'torch', 'torchvision', 'torchaudio', 'nvidia-cudnn-cu12'], check=False)\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install', '--user',\n",
        "    '--index-url', 'https://download.pytorch.org/whl/cu118',\n",
        "    'torch==2.1.2', 'torchvision==0.16.2', 'torchaudio==2.1.2'\n",
        "], check=True)\n",
        "print('Torch cu118 version installed')\n",
        "\n",
        "# 2) Set basic LD_LIBRARY_PATH with system and torch paths BEFORE any imports\n",
        "lib_paths = [\n",
        "    os.path.join(site.getsitepackages()[0], 'torch', 'lib'),\n",
        "    '/usr/local/cuda/lib64',\n",
        "    '/usr/lib/x86_64-linux-gnu'\n",
        "]\n",
        "os.environ['LD_LIBRARY_PATH'] = ':'.join([p for p in lib_paths if os.path.isdir(p)]) + ':' + os.environ.get('LD_LIBRARY_PATH', '')\n",
        "print('Basic LD_LIBRARY_PATH set:', os.environ['LD_LIBRARY_PATH'])\n",
        "\n",
        "# 3) Verify import\n",
        "import torch\n",
        "import torch.backends.cudnn as tb\n",
        "print('Torch:', torch.__version__, 'CUDA:', torch.version.cuda)\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "print('cuDNN version:', tb.version() if torch.backends.cudnn.enabled else 'cuDNN not enabled')\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('GPU still not available - need further fix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f15993a1-bebf-40b6-8f4a-d0bea889bd1c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Imports (non-torch for now)\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# Load train metadata\n",
        "with open('nybg2020/train/metadata.json', 'r') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "train_images_df = pd.DataFrame(train_data['images'])\n",
        "train_annotations_df = pd.DataFrame(train_data['annotations'])\n",
        "\n",
        "# Merge to get train_df with file_name and category_id\n",
        "train_df = train_images_df.merge(train_annotations_df, left_on='id', right_on='image_id')[['file_name', 'category_id']]\n",
        "\n",
        "# Filter to existing files\n",
        "def file_exists(file_name):\n",
        "    return os.path.exists(f'nybg2020/train/{file_name}')\n",
        "\n",
        "train_df = train_df[train_df['file_name'].apply(file_exists)].reset_index(drop=True)\n",
        "print(f'Filtered train samples: {len(train_df)}')\n",
        "\n",
        "# Compute class counts\n",
        "class_counts = Counter(train_df['category_id'])\n",
        "used_classes = sorted(class_counts.keys())\n",
        "num_classes = len(used_classes)\n",
        "print(f'Number of classes: {num_classes}')\n",
        "\n",
        "# Label maps\n",
        "cat2idx = {cid: idx for idx, cid in enumerate(used_classes)}\n",
        "idx2cat = {idx: cid for cid, idx in cat2idx.items()}\n",
        "\n",
        "# Class weights as numpy for now\n",
        "class_weights_np = np.array([1.0 / class_counts[cid] for cid in used_classes])\n",
        "print('Class weights computed (numpy):', class_weights_np.shape)\n",
        "print('Sample weights:', class_weights_np[:5])\n",
        "\n",
        "# Save for later use\n",
        "np.save('class_weights.npy', class_weights_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b6e5a5b0-d5d9-42f3-8220-bef6d29de198",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install required packages with constraints to pin torch versions\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Create constraints file\n",
        "constraints_content = '''torch==2.4.1+cu121\\ntorchvision==0.19.1+cu121\\ntorchaudio==2.4.1+cu121'''\n",
        "Path('constraints.txt').write_text(constraints_content)\n",
        "\n",
        "# Purge cache and reinstall torch with no deps\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'cache', 'purge'], check=False)\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install',\n",
        "    '--index-url', 'https://download.pytorch.org/whl/cu121',\n",
        "    'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1',\n",
        "    '--no-deps', '-U'\n",
        "], check=True)\n",
        "\n",
        "# Install other packages with constraints and no deps\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install', '-c', 'constraints.txt',\n",
        "    '--no-deps',\n",
        "    'opencv-python-headless==4.11.0.86', 'timm==1.0.20', 'albumentations==2.0.8', 'scikit-learn==1.4.2'\n",
        "], check=True)\n",
        "\n",
        "print('Packages installed with constraints')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "3d7e3537-f678-4ad4-8a5f-450d844c9a9c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Class-aware split and subsampling\n",
        "random.seed(42)\n",
        "grouped = train_df.groupby('category_id')\n",
        "train_indices = []\n",
        "val_indices = []\n",
        "for name, group in grouped:\n",
        "    if len(group) >= 2:\n",
        "        val_idx = random.choice(group.index.tolist())\n",
        "        val_indices.append(val_idx)\n",
        "        train_indices += [i for i in group.index if i != val_idx]\n",
        "    else:\n",
        "        train_indices.append(group.index[0])\n",
        "train_full_df = train_df.loc[train_indices].reset_index(drop=True)\n",
        "val_df = train_df.loc[val_indices].reset_index(drop=True)\n",
        "print(f'Train full size: {len(train_full_df)}, Val size: {len(val_df)}')\n",
        "\n",
        "# Subsample for quick baseline (up to 10 per class)\n",
        "train_sub_df = pd.concat([\n",
        "    group.sample(n=min(10, len(group)), random_state=42)\n",
        "    for name, group in train_full_df.groupby('category_id')\n",
        "]).reset_index(drop=True)\n",
        "print(f'Subsample train size: {len(train_sub_df)}')\n",
        "\n",
        "# Save for later use\n",
        "train_sub_df.to_pickle('train_sub.pkl')\n",
        "val_df.to_pickle('val.pkl')\n",
        "print('Splits saved')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a83c353b-907d-4d9d-acd0-5121940bf879",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import site\n",
        "\n",
        "# Install cuDNN\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'install', '-U', 'nvidia-cudnn-cu12==9.1.0.70'], check=True)\n",
        "\n",
        "# Set LD_LIBRARY_PATH to include cuDNN libs\n",
        "site_packages = site.getsitepackages()[0]\n",
        "cudnn_path = os.path.join(site_packages, 'nvidia', 'cudnn', 'lib')\n",
        "if os.path.exists(cudnn_path):\n",
        "    os.environ['LD_LIBRARY_PATH'] = f\"{cudnn_path}:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "    print(f'Set LD_LIBRARY_PATH to include {cudnn_path}')\n",
        "else:\n",
        "    print('cuDNN lib path not found')\n",
        "\n",
        "# Also add standard CUDA paths\n",
        "os.environ['LD_LIBRARY_PATH'] = f\"/usr/local/cuda/lib64:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "print('Environment updated')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "9a16ebb9-e7bd-47a8-b5be-2c4c809ec745",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Import verification\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch version:', torch.__version__)\n",
        "    print('CUDA version:', torch.version.cuda)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU device:', torch.cuda.get_device_name(0))\n",
        "    else:\n",
        "        print('Warning: CUDA not available')\n",
        "    import cv2\n",
        "    import albumentations as A\n",
        "    import timm\n",
        "    from sklearn.metrics import f1_score\n",
        "    print('All key packages imported successfully')\n",
        "except ImportError as e:\n",
        "    print('Import error:', e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "cef22cc0-e248-44af-8ada-946e13db34d2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Fix dependency conflicts: uninstall mismatched nvidia packages\n",
        "mismatched_packages = [\n",
        "    'nvidia-cublas-cu12',\n",
        "    'nvidia-nccl-cu12',\n",
        "    'nvidia-cudnn-cu12'\n",
        "]\n",
        "for pkg in mismatched_packages:\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "print('Uninstalled mismatched packages')\n",
        "\n",
        "# Reinstall torch with full dependencies to get correct nvidia versions\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'torch', 'torchvision', 'torchaudio'], check=False)\n",
        "subprocess.run([\n",
        "    sys.executable, '-m', 'pip', 'install',\n",
        "    '--index-url', 'https://download.pytorch.org/whl/cu121',\n",
        "    '--extra-index-url', 'https://pypi.org/simple',\n",
        "    'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1'\n",
        "], check=True)\n",
        "print('Torch reinstalled with dependencies')\n",
        "\n",
        "# Install missing python deps if needed\n",
        "missing_deps = ['filelock', 'jinja2', 'sympy', 'triton==3.0.0']\n",
        "for dep in missing_deps:\n",
        "    try:\n",
        "        __import__(dep.split('==')[0])\n",
        "    except ImportError:\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', dep], check=True)\n",
        "        print(f'Installed {dep}')\n",
        "\n",
        "# Find and set LD_LIBRARY_PATH for cuDNN\n",
        "import site\n",
        "site_packages = site.getsitepackages()[0]\n",
        "\n",
        "# Search for libcudnn.so.9\n",
        "import glob\n",
        "cudnn_files = glob.glob('/usr/local/lib/python3.11/site-packages/**/libcudnn.so.9*', recursive=True)\n",
        "if cudnn_files:\n",
        "    cudnn_dir = os.path.dirname(cudnn_files[0])\n",
        "    os.environ['LD_LIBRARY_PATH'] = f'{cudnn_dir}:{os.environ.get(\"LD_LIBRARY_PATH\", \"\")}'\n",
        "    print(f'Found cuDNN at {cudnn_dir} and set LD_LIBRARY_PATH')\n",
        "else:\n",
        "    # Fallback search\n",
        "    cudnn_dir = os.path.join(site_packages, 'torch', 'lib')\n",
        "    if os.path.exists(os.path.join(cudnn_dir, 'libcudnn.so.9')):\n",
        "        os.environ['LD_LIBRARY_PATH'] = f'{cudnn_dir}:{os.environ.get(\"LD_LIBRARY_PATH\", \"\")}'\n",
        "        print(f'Set LD_LIBRARY_PATH to torch lib: {cudnn_dir}')\n",
        "    else:\n",
        "        print('cuDNN .so not found, searching system...')\n",
        "        result = subprocess.run(['find', '/usr', '-name', 'libcudnn.so.9*', '2>/dev/null'], capture_output=True, text=True)\n",
        "        print('Search result:', result.stdout)\n",
        "\n",
        "# Add CUDA paths\n",
        "os.environ['LD_LIBRARY_PATH'] = f'/usr/local/cuda/lib64:{os.environ.get(\"LD_LIBRARY_PATH\", \"\")}'\n",
        "print('Environment updated')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "3dd0386a-3517-42ee-bdd5-c8ea4bbca242",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json, pandas as pd, collections\n",
        "tr = json.load(open(\"nybg2020/train/metadata.json\"))\n",
        "te = json.load(open(\"nybg2020/test/metadata.json\"))\n",
        "train_df = pd.DataFrame(tr[\"images\"]).merge(pd.DataFrame(tr[\"annotations\"]), left_on=\"id\", right_on=\"image_id\")\n",
        "major = collections.Counter(train_df[\"category_id\"]).most_common(1)[0][0]\n",
        "test_df = pd.DataFrame(te[\"images\"])\n",
        "pd.DataFrame({\"Id\": test_df[\"id\"], \"Predicted\": major}).to_csv(\"submission.csv\", index=False)\n",
        "print(\"submission.csv created\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b1746156-1e65-438e-b60a-6fc54bc64eca",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, subprocess\n",
        "for w in [\n",
        "  \"https://download.pytorch.org/whl/cpu/torch-2.1.2%2Bcpu-cp311-cp311-linux_x86_64.whl\",\n",
        "  \"https://download.pytorch.org/whl/cpu/torchvision-0.16.2%2Bcpu-cp311-cp311-linux_x86_64.whl\"\n",
        "]:\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"--no-cache-dir\", \"--force-reinstall\", \"--no-deps\", w], check=True)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", \"--no-deps\", \"timm==1.0.20\"], check=True)\n",
        "print(\"CPU 2.1.2 stack installed. RESTART KERNEL NOW.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.1.2+cpu\n  Downloading https://download.pytorch.org/whl/cpu/torch-2.1.2%2Bcpu-cp311-cp311-linux_x86_64.whl (184.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 184.9/184.9 MB 384.3 MB/s eta 0:00:00\nInstalling collected packages: torch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/app/.local/bin' which is not on PATH.\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed torch-2.8.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.16.2+cpu\n  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.16.2%2Bcpu-cp311-cp311-linux_x86_64.whl (1.5 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.5/1.5 MB 39.9 MB/s eta 0:00:00\nInstalling collected packages: torchvision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed torchvision-0.23.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==1.0.20\n  Downloading timm-1.0.20-py3-none-any.whl (2.5 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.5/2.5 MB 63.9 MB/s eta 0:00:00\nInstalling collected packages: timm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed timm-1.0.20\nCPU 2.1.2 stack installed. RESTART KERNEL NOW.\n"
          ]
        }
      ]
    },
    {
      "id": "1064a284-0444-497d-81d8-890195dfe228",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pickle\n",
        "from collections import Counter, defaultdict\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import time\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import normalize\n",
        "import subprocess\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
        "random.seed(42)\n",
        "\n",
        "# Install TensorFlow with --user if not available\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "except ImportError:\n",
        "    print('Installing TensorFlow with --user...')\n",
        "    subprocess.run([\"pip\", \"install\", \"--user\", \"tensorflow==2.17.0\"], check=True)\n",
        "    import tensorflow as tf\n",
        "print(f'TF version: {tf.__version__}, GPUs: {len(tf.config.list_physical_devices(\"GPU\"))}')\n",
        "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
        "    for gpu in tf.config.list_physical_devices('GPU'):\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# Load full train data, exclude val\n",
        "with open('nybg2020/train/metadata.json', 'r') as f:\n",
        "    train_data = json.load(f)\n",
        "train_images_df = pd.DataFrame(train_data['images'])\n",
        "train_annotations_df = pd.DataFrame(train_data['annotations'])\n",
        "train_df_full = train_images_df.merge(train_annotations_df, left_on='id', right_on='image_id')[['file_name', 'category_id']]\n",
        "\n",
        "# Load val to exclude\n",
        "val_df = pd.read_pickle('val.pkl')\n",
        "val_files = set(val_df['file_name'])\n",
        "train_df = train_df_full[~train_df_full['file_name'].isin(val_files)].reset_index(drop=True)\n",
        "\n",
        "# Filter existing files\n",
        "def file_exists(file_name):\n",
        "    return os.path.exists(f'nybg2020/train/{file_name}')\n",
        "train_df = train_df[train_df['file_name'].apply(file_exists)].reset_index(drop=True)\n",
        "print(f'Full train size: {len(train_df)}')\n",
        "\n",
        "used_classes = sorted(train_df['category_id'].unique())\n",
        "cat2idx = {c: i for i, c in enumerate(used_classes)}\n",
        "idx2cat = {i: c for c, i in cat2idx.items()}\n",
        "num_classes = len(used_classes)\n",
        "print(f'Classes: {num_classes}')\n",
        "\n",
        "# No ROI\n",
        "file2roi = {}\n",
        "print('No ROI available; using full images')\n",
        "\n",
        "# Load EfficientNetV2S at 384\n",
        "input_size = 384\n",
        "model = tf.keras.applications.EfficientNetV2S(weights='imagenet', include_top=False, pooling='avg', input_shape=(input_size, input_size, 3))\n",
        "model.trainable = False\n",
        "print('EfficientNetV2S loaded at 384x384')\n",
        "\n",
        "# Load and augment single image\n",
        "def load_and_augment_image(img_path, file_name, file2roi):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        return None, None\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    if file2roi and file_name in file2roi:\n",
        "        x1, y1, x2, y2 = file2roi[file_name]\n",
        "        img = img[y1:y2, x1:x2]\n",
        "    h, w = img.shape[:2]\n",
        "    s = min(h, w)\n",
        "    y0, x0 = (h - s) // 2, (w - s) // 2\n",
        "    img = img[y0:y0 + s, x0:x0 + s]\n",
        "    img = cv2.resize(img, (input_size, input_size))\n",
        "    img_flip = cv2.flip(img, 1)\n",
        "    return img, img_flip\n",
        "\n",
        "# Extract features with TTA, mode for L2\n",
        "def extract_features(data_list, batch_size=128, mode='l2', labels=None):\n",
        "    features = []\n",
        "    start_time = time.time()\n",
        "    for i in range(0, len(data_list), batch_size):\n",
        "        end = min(i + batch_size, len(data_list))\n",
        "        batch_data = data_list[i:end]\n",
        "        batch_paths = [d[0] for d in batch_data]\n",
        "        batch_fnames = [d[1] for d in batch_data]\n",
        "        batch_imgs = []\n",
        "        batch_flips = []\n",
        "        for p, f in zip(batch_paths, batch_fnames):\n",
        "            img, img_flip = load_and_augment_image(p, f, file2roi)\n",
        "            if img is not None:\n",
        "                batch_imgs.append(img)\n",
        "                batch_flips.append(img_flip)\n",
        "            else:\n",
        "                z = np.zeros((input_size, input_size, 3), dtype=np.uint8)\n",
        "                batch_imgs.append(z)\n",
        "                batch_flips.append(z)\n",
        "        imgs_pre = np.array(batch_imgs, dtype=np.float32)\n",
        "        imgs_pre = preprocess_input(imgs_pre)\n",
        "        feats_orig = model.predict(imgs_pre, verbose=0)\n",
        "        flips_pre = np.array(batch_flips, dtype=np.float32)\n",
        "        flips_pre = preprocess_input(flips_pre)\n",
        "        feats_flip = model.predict(flips_pre, verbose=0)\n",
        "        feats_avg = (feats_orig + feats_flip) / 2\n",
        "        if mode == 'pre_l2':\n",
        "            batch_feats = feats_avg\n",
        "        else:\n",
        "            batch_feats = normalize(feats_avg, norm='l2', axis=1)\n",
        "        features.append(batch_feats)\n",
        "        elapsed = (time.time() - start_time) / 60\n",
        "        print(f'Batch {i//batch_size +1}: processed {end}/{len(data_list)}, Elapsed: {elapsed:.1f} min')\n",
        "    if mode == 'pre_l2':\n",
        "        return np.vstack(features), [d[2] for d in data_list]\n",
        "    else:\n",
        "        return np.vstack(features)\n",
        "\n",
        "# Train data list with labels\n",
        "print('Preparing full train data list...')\n",
        "train_data_list = [(f'nybg2020/train/{row.file_name}', row.file_name, cat2idx[row.category_id]) for _, row in train_df.iterrows()]\n",
        "\n",
        "# Streamed centroid computation: pre-L2 average\n",
        "print('Extracting train features streamed for centroids...')\n",
        "feat_dim = 1280  # EfficientNetV2S\n",
        "sums = np.zeros((num_classes, feat_dim), dtype=np.float32)\n",
        "counts = np.zeros(num_classes, dtype=np.int64)\n",
        "start_time = time.time()\n",
        "for i in range(0, len(train_data_list), 128):\n",
        "    end = min(i + 128, len(train_data_list))\n",
        "    batch_list = train_data_list[i:end]\n",
        "    feats_pre, batch_labels = extract_features(batch_list, batch_size=128, mode='pre_l2')\n",
        "    for j, lbl in enumerate(batch_labels):\n",
        "        sums[lbl] += feats_pre[j]\n",
        "        counts[lbl] += 1\n",
        "    elapsed = (time.time() - start_time) / 60\n",
        "    print(f'Train batch {i//128 +1}: processed {end}/{len(train_data_list)}, Elapsed: {elapsed:.1f} min')\n",
        "\n",
        "# Compute centroids: mean then L2\n",
        "print('Computing centroids...')\n",
        "centroids = np.divide(sums, counts[:, np.newaxis], out=np.zeros_like(sums), where=counts[:, np.newaxis] != 0)\n",
        "centroids = normalize(centroids, norm='l2', axis=1)\n",
        "print(f'Centroids shape: {centroids.shape}, non-zero classes: {np.sum(counts > 0)}')\n",
        "\n",
        "# Test data\n",
        "with open('nybg2020/test/metadata.json') as f:\n",
        "    test_data = json.load(f)\n",
        "test_df = pd.DataFrame(test_data['images'])[['file_name', 'id']]\n",
        "print(f'Test size: {len(test_df)}')\n",
        "\n",
        "# Extract test features L2\n",
        "print('Extracting test features with TTA...')\n",
        "test_data_list = [(f'nybg2020/test/{row.file_name}', row.file_name) for _, row in test_df.iterrows()]\n",
        "test_features = extract_features(test_data_list, batch_size=128, mode='l2')\n",
        "print(f'Test features shape: {test_features.shape}')\n",
        "\n",
        "# Predict k=1 nearest centroid\n",
        "scores = test_features @ centroids.T\n",
        "test_preds_idx = np.argmax(scores, axis=1)\n",
        "test_category_ids = [idx2cat.get(p, used_classes[0]) for p in test_preds_idx]  # fallback\n",
        "\n",
        "# Submission\n",
        "submission = pd.DataFrame({'Id': test_df['id'].values, 'Predicted': test_category_ids})\n",
        "submission = submission.sort_values('Id').reset_index(drop=True)\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print('Full train EfficientNetV2S 384 + Centroids + TTA submission.csv created')\n",
        "print(f'Predicted {len(set(test_category_ids))} unique classes out of {num_classes}')\n",
        "\n",
        "# Local eval on val sample\n",
        "val_sample = val_df.sample(n=min(10000, len(val_df)), random_state=42)\n",
        "val_data_list = [(f'nybg2020/train/{row.file_name}', row.file_name) for _, row in val_sample.iterrows()]\n",
        "val_true_idx = [cat2idx.get(row.category_id, 0) for _, row in val_sample.iterrows()]\n",
        "print('Extracting val features with TTA...')\n",
        "val_features = extract_features(val_data_list, batch_size=128, mode='l2')\n",
        "val_scores = val_features @ centroids.T\n",
        "val_preds_idx = np.argmax(val_scores, axis=1)\n",
        "local_f1 = f1_score(val_true_idx, val_preds_idx, average='macro')\n",
        "print(f'Local macro F1 on val sample: {local_f1:.4f}')\n",
        "if local_f1 >= 0.05334:\n",
        "    print('Local F1 meets bronze threshold - ready to submit')\n",
        "else:\n",
        "    print('Local F1 below bronze - consider k>1 or auto-ROI')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.17.0, GPUs: 1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}