{
  "cells": [
    {
      "id": "5f3d4e34-a67b-4adf-9b1a-e27b4d381bd6",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Herbarium 2020 - FGVC7: Plan\n",
        "\n",
        "Objectives:\n",
        "- Establish environment (GPU) and data layout quickly\n",
        "- Build a fast, correct baseline (strong pretrained CNN) with solid CV\n",
        "- Iterate with efficient augmentations and long-tail strategies\n",
        "- Save predictions to submission.csv\n",
        "\n",
        "Workflow:\n",
        "1) Env check: GPU via nvidia-smi; verify CUDA; print Python/pip; ensure torch stack\n",
        "2) Data audit: list nybg2020, locate train/test images and metadata (COCO-like JSON)\n",
        "3) Minimal loader: dataset + transforms; sanity dataloader preview\n",
        "4) Baseline model: timm pretrained (e.g., convnext_base or efficientnetv2), label smoothing, CE focal optional\n",
        "5) CV: StratifiedKFold by category_id; log macro-F1 on val; save OOF/test logits\n",
        "6) Train at moderate resolution (224\u2192384), mixup/cutmix off initially; AMP; cosine LR; early stop\n",
        "7) Inference TTA; generate submission.csv\n",
        "8) Error analysis; if time: debias long-tail via class-balanced loss / reweight / higher res\n",
        "\n",
        "Major checkpoints to request expert review:\n",
        "- After this plan + env/data audit\n",
        "- After baseline CV ready\n",
        "- After first scoring run and before heavy training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7377c2df-c5fa-49d5-88aa-64e39424df4b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, json, time, shutil, subprocess, textwrap\n",
        "from pathlib import Path\n",
        "\n",
        "t0 = time.time()\n",
        "print('=== ENV CHECK ===', flush=True)\n",
        "print('CWD:', os.getcwd(), flush=True)\n",
        "print('Python:', sys.version.replace('\\n',' '), flush=True)\n",
        "print('pip list (top 20):', flush=True)\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'list', '--format=columns'], check=False)\n",
        "print('\\n--- nvidia-smi ---', flush=True)\n",
        "subprocess.run(['bash','-lc','nvidia-smi || true'], check=False)\n",
        "\n",
        "print('\\n=== DATA AUDIT ===', flush=True)\n",
        "root = Path('.')\n",
        "data_dir = root / 'nybg2020'\n",
        "print('Exists nybg2020:', data_dir.exists(), flush=True)\n",
        "\n",
        "# List top-level and a couple of sublevels for nybg2020\n",
        "def list_dir(p: Path, max_entries=50):\n",
        "    try:\n",
        "        items = sorted(p.iterdir())\n",
        "    except Exception as e:\n",
        "        print('Cannot list', p, e, flush=True); return\n",
        "    for i, it in enumerate(items[:max_entries]):\n",
        "        kind = 'DIR ' if it.is_dir() else 'FILE'\n",
        "        size = it.stat().st_size if it.is_file() else -1\n",
        "        print(f'{kind}\\t{it}', ('', f'\\t{size:,} bytes')[it.is_file()], flush=True)\n",
        "    if len(items) > max_entries:\n",
        "        print(f'... ({len(items)-max_entries} more)', flush=True)\n",
        "\n",
        "if data_dir.exists():\n",
        "    list_dir(data_dir)\n",
        "    # Find json metadata files\n",
        "    metas = []\n",
        "    for dirpath, dirnames, filenames in os.walk(data_dir):\n",
        "        for f in filenames:\n",
        "            if f.lower().endswith('.json'):\n",
        "                metas.append(os.path.join(dirpath, f))\n",
        "    print('\\nFound JSON files:', len(metas), flush=True)\n",
        "    for m in metas[:20]:\n",
        "        print(' -', m, flush=True)\n",
        "\n",
        "# Inspect sample_submission\n",
        "ss_path = Path('sample_submission.csv')\n",
        "if ss_path.exists():\n",
        "    import pandas as pd\n",
        "    ss_head = pd.read_csv(ss_path, nrows=10)\n",
        "    total_rows = sum(1 for _ in open(ss_path, 'r')) - 1\n",
        "    print('\\nsample_submission head:\\n', ss_head, flush=True)\n",
        "    print('sample_submission rows (excluding header):', total_rows, flush=True)\n",
        "\n",
        "print('\\nElapsed: %.2fs' % (time.time()-t0), flush=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ENV CHECK ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CWD: /var/lib/simon/agent_run_states/herbarium-2020-fgvc7-20250923-034836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip list (top 20):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n----------------------------- ------------\naccelerate                    0.34.2\nalbucore                      0.0.33\nalbumentations                1.4.10\nannotated-types               0.7.0\nanyio                         4.10.0\nasttokens                     3.0.0\ncachetools                    5.5.2\ncatboost                      1.2.8\ncertifi                       2025.8.3\nchardet                       5.2.0\ncharset-normalizer            3.4.3\ncomm                          0.2.3\ncontourpy                     1.3.3\ncramjam                       2.11.0\ncycler                        0.12.1\ndb-dtypes                     1.2.0\ndebugpy                       1.8.17\ndecorator                     5.2.1\net_xmlfile                    2.0.0\nexecuting                     2.2.1\nfastparquet                   2024.2.0\nfilelock                      3.19.1\nfonttools                     4.60.0\nfsspec                        2025.9.0\ngoogle-api-core               2.25.1\ngoogle-auth                   2.40.3\ngoogle-cloud-bigquery         3.25.0\ngoogle-cloud-bigquery-storage 2.24.0\ngoogle-cloud-core             2.4.3\ngoogle-crc32c                 1.7.1\ngoogle-genai                  1.29.0\ngoogle-resumable-media        2.7.2\ngoogleapis-common-protos      1.70.0\ngraphviz                      0.21\ngrpcio                        1.75.0\ngrpcio-status                 1.62.3\nh11                           0.16.0\nhf-xet                        1.1.10\nhttpcore                      1.0.9\nhttpx                         0.28.1\nhuggingface-hub               0.35.0\nidna                          3.10\nimageio                       2.37.0\nipykernel                     6.29.5\nipython                       9.5.0\nipython_pygments_lexers       1.1.1\njedi                          0.19.2\nJinja2                        3.1.6\njoblib                        1.5.2\njupyter_client                8.6.1\njupyter_core                  5.8.1\nkiwisolver                    1.4.9\nlazy_loader                   0.4\nlightgbm                      4.6.0\nmarkdown-it-py                4.0.0\nMarkupSafe                    3.0.2\nmatplotlib                    3.10.5\nmatplotlib-inline             0.1.7\nmdurl                         0.1.2\nmpmath                        1.3.0\nnarwhals                      2.5.0\nnest-asyncio                  1.6.0\nnetworkx                      3.5\nnumpy                         1.26.4\nnvidia-cublas-cu12            12.1.3.1\nnvidia-cuda-cupti-cu12        12.1.105\nnvidia-cuda-nvrtc-cu12        12.1.105\nnvidia-cuda-runtime-cu12      12.1.105\nnvidia-cudnn-cu12             9.1.0.70\nnvidia-cufft-cu12             11.0.2.54\nnvidia-curand-cu12            10.3.2.106\nnvidia-cusolver-cu12          11.4.5.107\nnvidia-cusparse-cu12          12.1.0.106\nnvidia-nccl-cu12              2.20.5\nnvidia-nvjitlink-cu12         12.9.86\nnvidia-nvtx-cu12              12.1.105\nopencv-python-headless        4.11.0.86\nopenpyxl                      3.1.2\npackaging                     25.0\npandas                        2.2.2\nparso                         0.8.5\npatsy                         1.0.1\npexpect                       4.9.0\npillow                        11.3.0\npip                           22.0.2\nplatformdirs                  4.4.0\nplotly                        6.3.0\npolars                        1.31.0\nprompt_toolkit                3.0.52\nproto-plus                    1.26.1\nprotobuf                      4.25.8\npsutil                        7.1.0\nptyprocess                    0.7.0\npure_eval                     0.2.3\npyarrow                       15.0.2\npyasn1                        0.6.1\npyasn1_modules                0.4.2\npydantic                      2.11.9\npydantic_core                 2.33.2\nPygments                      2.19.2\npyparsing                     3.2.5\npython-dateutil               2.9.0.post0\npytz                          2025.2\npyxlsb                        1.0.10\nPyYAML                        6.0.2\npyzmq                         27.1.0\nrequests                      2.32.5\nrich                          13.7.1\nrsa                           4.9.1\nsafetensors                   0.6.2\nscikit-image                  0.25.2\nscikit-learn                  1.7.2\nscipy                         1.16.2\nseaborn                       0.13.2\nsetuptools                    59.6.0\nsimsimd                       6.5.3\nsix                           1.17.0\nsniffio                       1.3.1\nstack-data                    0.6.3\nstatsmodels                   0.14.2\nstringzilla                   4.0.14\nsympy                         1.14.0\ntenacity                      9.0.0\nthreadpoolctl                 3.6.0\ntifffile                      2025.9.20\ntimm                          1.0.9\ntorch                         2.4.1+cu121\ntorchaudio                    2.4.1+cu121\ntorchvision                   0.19.1+cu121\ntornado                       6.5.2\ntqdm                          4.67.1\ntraitlets                     5.14.3\ntriton                        3.0.0\ntyping_extensions             4.15.0\ntyping-inspection             0.4.1\ntzdata                        2025.2\nurllib3                       2.5.0\nwcwidth                       0.2.13\nwebsockets                    15.0.1\nwheel                         0.37.1\nxgboost                       2.1.4\nxlrd                          2.0.1\n\n--- nvidia-smi ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 23 07:38:45 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |    2420MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n=== DATA AUDIT ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists nybg2020: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DIR \tnybg2020/test \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DIR \tnybg2020/train \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nFound JSON files: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - nybg2020/test/metadata.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " - nybg2020/train/metadata.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nsample_submission head:\n    Id  Predicted\n0   0          0\n1   1          0\n2   2          0\n3   3          0\n4   4          0\n5   5          0\n6   6          0\n7   7          0\n8   8          0\n9   9          0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_submission rows (excluding header): 219124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nElapsed: 1.84s\n"
          ]
        }
      ]
    },
    {
      "id": "5adf7451-bf7b-4b54-ab3f-2ff7f719f8fa",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json, os, time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "t0 = time.time()\n",
        "train_meta_path = Path('nybg2020/train/metadata.json')\n",
        "test_meta_path = Path('nybg2020/test/metadata.json')\n",
        "assert train_meta_path.exists() and test_meta_path.exists(), 'metadata.json not found'\n",
        "\n",
        "with open(train_meta_path, 'r') as f:\n",
        "    train_meta = json.load(f)\n",
        "with open(test_meta_path, 'r') as f:\n",
        "    test_meta = json.load(f)\n",
        "\n",
        "# Build dataframes\n",
        "train_imgs = pd.DataFrame(train_meta['images'])[['id','file_name','width','height']].rename(columns={'id':'image_id'})\n",
        "train_anns = pd.DataFrame(train_meta['annotations'])[['image_id','category_id','region_id','id']].rename(columns={'id':'ann_id'})\n",
        "train_df = train_anns.merge(train_imgs, on='image_id', how='left')\n",
        "\n",
        "categories = pd.DataFrame(train_meta['categories'])[['id','name','family','genus']].rename(columns={'id':'category_id'})\n",
        "num_classes = categories.shape[0]\n",
        "\n",
        "test_imgs = pd.DataFrame(test_meta['images'])[['id','file_name','width','height']].rename(columns={'id':'image_id'})\n",
        "\n",
        "print('Train rows:', len(train_df), 'Images:', len(train_imgs), 'Test images:', len(test_imgs), flush=True)\n",
        "print('Unique categories in train:', train_df['category_id'].nunique(), 'Categories listed:', num_classes, flush=True)\n",
        "\n",
        "# Build contiguous class index mapping\n",
        "uniq_cats = sorted(train_df['category_id'].unique())\n",
        "catid2idx = {int(cid): int(i) for i, cid in enumerate(uniq_cats)}\n",
        "idx2catid = {int(i): int(cid) for cid, i in catid2idx.items()}\n",
        "print('Min/Max category_id:', min(uniq_cats), max(uniq_cats), '\u2192 mapped to [0..', len(uniq_cats)-1, ']', flush=True)\n",
        "\n",
        "train_df['class_idx'] = train_df['category_id'].map(catid2idx)\n",
        "\n",
        "# Compose full file paths\n",
        "train_df['filepath'] = train_df['file_name'].apply(lambda x: str(Path('nybg2020/train')/x))\n",
        "test_imgs['filepath'] = test_imgs['file_name'].apply(lambda x: str(Path('nybg2020/test')/x))\n",
        "\n",
        "# Sanity checks: files exist (sample)\n",
        "missing_train = sum(not Path(p).exists() for p in train_df['filepath'].head(100))\n",
        "missing_test = sum(not Path(p).exists() for p in test_imgs['filepath'].head(100))\n",
        "print('Missing (sample) train files:', missing_train, 'Missing (sample) test files:', missing_test, flush=True)\n",
        "\n",
        "# Class distribution summary\n",
        "cnt = train_df['class_idx'].value_counts().sort_index()\n",
        "print('Class count stats \u2192 min:', int(cnt.min()), 'median:', int(cnt.median()), 'p95:', int(cnt.quantile(0.95)), 'max:', int(cnt.max()), flush=True)\n",
        "\n",
        "# Save mappings (ensure JSON-serializable types)\n",
        "Path('artifacts').mkdir(exist_ok=True)\n",
        "catid2idx_json = {str(int(k)): int(v) for k, v in catid2idx.items()}\n",
        "idx2catid_json = {str(int(k)): int(v) for k, v in idx2catid.items()}\n",
        "with open('artifacts/catid2idx.json','w') as f: json.dump(catid2idx_json, f)\n",
        "with open('artifacts/idx2catid.json','w') as f: json.dump(idx2catid_json, f)\n",
        "\n",
        "# Preview few rows\n",
        "print(train_df.head(3)[['image_id','category_id','class_idx','filepath']])\n",
        "print(test_imgs.head(3))\n",
        "print('Elapsed: %.2fs' % (time.time()-t0), flush=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rows: 811623 Images: 811623 Test images: 219124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique categories in train: 32093 Categories listed: 32094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min/Max category_id: 0 32093 \u2192 mapped to [0.. 32092 ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing (sample) train files: 0 Missing (sample) test files: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class count stats \u2192 min: 1 median: 7 p95: 116 max: 1412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   image_id  category_id  class_idx                                 filepath\n0    124136        15672      15672  nybg2020/train/images/156/72/124136.jpg\n1      5327        15672      15672    nybg2020/train/images/156/72/5327.jpg\n2    449419        15672      15672  nybg2020/train/images/156/72/449419.jpg\n  image_id         file_name  width  height                        filepath\n0        0  images/000/0.jpg    667    1000  nybg2020/test/images/000/0.jpg\n1        1  images/000/1.jpg    667    1000  nybg2020/test/images/000/1.jpg\n2        2  images/000/2.jpg    675    1000  nybg2020/test/images/000/2.jpg\nElapsed: 6.76s\n"
          ]
        }
      ]
    },
    {
      "id": "05b9e797-23b6-49cc-9ba8-eb39e19d9da1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install correct CUDA 12.1 torch stack + timm and sanity check GPU\n",
        "import os, sys, subprocess, shutil, time\n",
        "from pathlib import Path\n",
        "\n",
        "t0 = time.time()\n",
        "def pip(*args):\n",
        "    print('> pip', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Uninstall any preexisting torch stack to avoid mismatches\n",
        "for pkg in ('torch','torchvision','torchaudio'):\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "\n",
        "# Clean stray site dirs (idempotent)\n",
        "for d in (\n",
        "    '/app/.pip-target/torch',\n",
        "    '/app/.pip-target/torchvision',\n",
        "    '/app/.pip-target/torchaudio',\n",
        "    '/app/.pip-target/torchgen',\n",
        "    '/app/.pip-target/functorch',\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d, flush=True)\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# Install cu121 torch stack\n",
        "pip('install','--index-url','https://download.pytorch.org/whl/cu121','--extra-index-url','https://pypi.org/simple','torch==2.4.1','torchvision==0.19.1','torchaudio==2.4.1')\n",
        "\n",
        "# Freeze versions\n",
        "Path('constraints.txt').write_text('torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n')\n",
        "\n",
        "# Install timm and helpers without upgrading torch\n",
        "pip('install','-c','constraints.txt','timm==1.0.9','albumentations==1.4.10','opencv-python-headless==4.10.0.84','accelerate==0.34.2','--upgrade-strategy','only-if-needed')\n",
        "\n",
        "import torch\n",
        "print('torch:', torch.__version__, 'CUDA build:', getattr(torch.version, 'cuda', None), flush=True)\n",
        "print('CUDA available:', torch.cuda.is_available(), flush=True)\n",
        "assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f'Wrong CUDA build: {torch.version.cuda}'\n",
        "assert torch.cuda.is_available(), 'CUDA not available'\n",
        "print('GPU:', torch.cuda.get_device_name(0), flush=True)\n",
        "print('Elapsed install/check: %.1fs' % (time.time()-t0), flush=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling torch-2.4.1:\n  Successfully uninstalled torch-2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchvision 0.19.1\nUninstalling torchvision-0.19.1:\n  Successfully uninstalled torchvision-0.19.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install --index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.org/simple torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 531.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 523.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 512.4 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 427.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 495.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 263.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 447.0 MB/s eta 0:00:00\nCollecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 395.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 464.4 MB/s eta 0:00:00\nCollecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 265.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 173.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 251.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 502.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 197.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 119.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 465.5 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 214.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 185.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 153.3 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 456.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 335.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 531.4 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 296.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 494.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install -c constraints.txt timm==1.0.9 albumentations==1.4.10 opencv-python-headless==4.10.0.84 accelerate==0.34.2 --upgrade-strategy only-if-needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==1.0.9\n  Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.3/2.3 MB 69.1 MB/s eta 0:00:00\nCollecting albumentations==1.4.10\n  Downloading albumentations-1.4.10-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.9/161.9 KB 21.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.10.0.84\n  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 49.9/49.9 MB 340.1 MB/s eta 0:00:00\nCollecting accelerate==0.34.2\n  Downloading accelerate-0.34.2-py3-none-any.whl (324 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 324.4/324.4 KB 244.3 MB/s eta 0:00:00\nCollecting pyyaml\n  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 763.0/763.0 KB 474.5 MB/s eta 0:00:00\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.35.0-py3-none-any.whl (563 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 563.4/563.4 KB 511.2 MB/s eta 0:00:00\nCollecting torch\n  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 797.1/797.1 MB 301.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.0/7.0 MB 368.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting safetensors\n  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 485.8/485.8 KB 393.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic>=2.7.0\n  Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 444.9/444.9 KB 496.9 MB/s eta 0:00:00\nCollecting scipy>=1.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35.9/35.9 MB 92.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.9.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 385.2 MB/s eta 0:00:00\nCollecting scikit-learn>=1.3.2\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 9.7/9.7 MB 284.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albucore>=0.0.11\n  Downloading albucore-0.0.33-py3-none-any.whl (18 kB)\nCollecting scikit-image>=0.21.0\n  Downloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.8/14.8 MB 253.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2,>=1.24.4\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 260.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting psutil\n  Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 291.2/291.2 KB 479.6 MB/s eta 0:00:00\nCollecting packaging>=20.0\n  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 66.5/66.5 KB 414.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stringzilla>=3.10.4\n  Downloading stringzilla-4.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (496 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 496.5/496.5 KB 495.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting simsimd>=5.9.2\n  Downloading simsimd-6.5.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.1/1.1 MB 465.2 MB/s eta 0:00:00\nCollecting requests\n  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.7/64.7 KB 428.8 MB/s eta 0:00:00\nCollecting tqdm>=4.42.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 78.5/78.5 KB 404.5 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting fsspec>=2023.5.0\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 395.9 MB/s eta 0:00:00\nCollecting hf-xet<2.0.0,>=1.1.3\n  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.2/3.2 MB 518.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic-core==2.33.2\n  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 508.0 MB/s eta 0:00:00\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nCollecting typing-inspection>=0.4.0\n  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\nCollecting tifffile>=2022.8.12\n  Downloading tifffile-2025.9.20-py3-none-any.whl (230 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 230.1/230.1 KB 453.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow>=10.1\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 276.0 MB/s eta 0:00:00\nCollecting lazy-loader>=0.4\n  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\nCollecting networkx>=3.0\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 501.0 MB/s eta 0:00:00\nCollecting imageio!=2.35.0,>=2.33\n  Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 315.8/315.8 KB 442.8 MB/s eta 0:00:00\nCollecting threadpoolctl>=3.1.0\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting joblib>=1.2.0\n  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 308.4/308.4 KB 494.4 MB/s eta 0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 226.2 MB/s eta 0:00:00\nCollecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 157.7 MB/s eta 0:00:00\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 66.7 MB/s eta 0:00:00\nCollecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 215.7 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 137.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 276.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 406.9 MB/s eta 0:00:00\nCollecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 418.0 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 486.1 MB/s eta 0:00:00\nCollecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 282.8 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 297.2 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 223.5 MB/s eta 0:00:00\nCollecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 299.6 MB/s eta 0:00:00\nCollecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 458.8 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 300.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.10-py3-none-any.whl (70 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 70.4/70.4 KB 400.1 MB/s eta 0:00:00\nCollecting certifi>=2017.4.17\n  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.2/161.2 KB 449.9 MB/s eta 0:00:00\nCollecting urllib3<3,>=1.21.1\n  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129.8/129.8 KB 430.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting charset_normalizer<4,>=2\n  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 150.3/150.3 KB 451.4 MB/s eta 0:00:00\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 531.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: simsimd, mpmath, urllib3, typing-extensions, tqdm, threadpoolctl, sympy, stringzilla, safetensors, pyyaml, psutil, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, joblib, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, annotated-types, typing-inspection, triton, tifffile, scipy, requests, pydantic-core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lazy-loader, jinja2, imageio, scikit-learn, scikit-image, pydantic, nvidia-cusolver-cu12, huggingface_hub, albucore, torch, albumentations, torchvision, accelerate, timm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 accelerate-0.34.2 albucore-0.0.33 albumentations-1.4.10 annotated-types-0.7.0 certifi-2025.8.3 charset_normalizer-3.4.3 filelock-3.19.1 fsspec-2025.9.0 hf-xet-1.1.10 huggingface_hub-0.35.0 idna-3.10 imageio-2.37.0 jinja2-3.1.6 joblib-1.5.2 lazy-loader-0.4 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 opencv-python-headless-4.10.0.84 packaging-25.0 pillow-11.3.0 psutil-7.1.0 pydantic-2.11.9 pydantic-core-2.33.2 pyyaml-6.0.2 requests-2.32.5 safetensors-0.6.2 scikit-image-0.25.2 scikit-learn-1.7.2 scipy-1.16.2 simsimd-6.5.3 stringzilla-4.0.14 sympy-1.14.0 threadpoolctl-3.6.0 tifffile-2025.9.20 timm-1.0.9 torch-2.4.1 torchvision-0.19.1 tqdm-4.67.1 triton-3.0.0 typing-extensions-4.15.0 typing-inspection-0.4.1 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/timm already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/timm-1.0.9.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/accelerate-0.34.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/accelerate already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/albumentations-1.4.10.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/albumentations already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/albucore-0.0.33.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/albucore already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/huggingface_hub-0.35.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/huggingface_hub already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pydantic-2.11.9.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pydantic already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scikit_image-0.25.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/skimage already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scikit_learn-1.7.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sklearn already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scikit_learn.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/imageio-2.37.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/imageio already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/lazy_loader-0.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/lazy_loader already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/cv2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/opencv_python_headless.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/opencv_python_headless-4.10.0.84.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pydantic_core already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pydantic_core-2.33.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/requests-2.32.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/requests already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy-1.16.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tifffile-2025.9.20.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tifffile already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_inspection-0.4.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_inspection already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/annotated_types-0.7.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/annotated_types already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/certifi-2025.8.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/certifi already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/charset_normalizer-3.4.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/charset_normalizer already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/hf_xet-1.1.10.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/hf_xet already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/idna-3.10.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/idna already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/joblib-1.5.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/joblib already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging-25.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/psutil-7.1.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/psutil already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/_yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PyYAML-6.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/safetensors already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/safetensors-0.6.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/cli already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/stringzilla-4.0.14.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/stringzilla.cpython-311-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/threadpoolctl-3.6.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/threadpoolctl.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tqdm-4.67.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tqdm already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/urllib3-2.5.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/urllib3 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/simsimd-6.5.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/simsimd.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/simsimd already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/simsimd.cpython-311-x86_64-linux-gnu.so already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 CUDA build: 12.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: NVIDIA A10-24Q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed install/check: 131.6s\n"
          ]
        }
      ]
    },
    {
      "id": "694f0067-ea60-41c1-bc8b-87d013c357c0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dataset, transforms, folds, and utilities (torchvision-based to avoid albumentations issues)\n",
        "import math, random, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_transforms(img_size: int = 384, train: bool = True):\n",
        "    if train:\n",
        "        return T.Compose([\n",
        "            T.RandomResizedCrop(img_size, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
        "            T.RandomHorizontalFlip(p=0.5),\n",
        "            # Mild, stable augs for fast convergence\n",
        "            T.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "            T.RandomErasing(p=0.05, scale=(0.02, 0.2), ratio=(0.3, 3.3), value=0),\n",
        "        ])\n",
        "    else:\n",
        "        return T.Compose([\n",
        "            T.Resize(img_size),\n",
        "            T.CenterCrop(img_size),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "\n",
        "class HerbariumDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, img_col: str = 'filepath', label_col: str | None = 'class_idx', transforms=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.imgs = self.df[img_col].tolist()\n",
        "        self.labels = None if label_col is None else self.df[label_col].astype(int).tolist()\n",
        "        self.transforms = transforms\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.imgs[idx]\n",
        "        with Image.open(p) as im:\n",
        "            im = im.convert('RGB')\n",
        "            img = self.transforms(im) if self.transforms else T.ToTensor()(im)\n",
        "        if self.labels is None:\n",
        "            return img, -1\n",
        "        return img, self.labels[idx]\n",
        "\n",
        "def make_folds(df: pd.DataFrame, n_splits: int = 5, seed: int = 42) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    # Long-tail safe stratification via frequency bins\n",
        "    counts = df['class_idx'].map(df['class_idx'].value_counts()).values\n",
        "    bins = np.array([1,2,3,5,10,20,50,100,200,500,1000,1e9], dtype=float)\n",
        "    y_bins = np.digitize(counts, bins)\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    splits = []\n",
        "    for fi, (tr, va) in enumerate(skf.split(np.zeros(len(y_bins)), y_bins)):\n",
        "        print(f'Fold {fi}: train {len(tr)} val {len(va)}', flush=True)\n",
        "        splits.append((tr, va))\n",
        "    return splits\n",
        "\n",
        "def compute_class_weights(df: pd.DataFrame, col='class_idx', power: float = 0.5) -> torch.Tensor:\n",
        "    counts = df[col].value_counts().sort_index().values.astype(float)\n",
        "    w = 1.0 / np.power(counts, power)\n",
        "    w = w / w.mean()\n",
        "    return torch.tensor(w, dtype=torch.float32)\n",
        "\n",
        "# Build (or load) folds and example loaders (smoke-test ready)\n",
        "GLOBAL_IMG_SIZE = 384\n",
        "set_seed(42)\n",
        "folds_cache = Path('artifacts/folds.npy')\n",
        "if not folds_cache.exists():\n",
        "    assert 'train_df' in globals(), 'train_df not found; run previous cell'\n",
        "    splits = make_folds(train_df, n_splits=5, seed=42)\n",
        "    np.save(folds_cache, np.array(splits, dtype=object))\n",
        "else:\n",
        "    splits = np.load(folds_cache, allow_pickle=True).tolist()\n",
        "    print('Loaded cached folds:', len(splits))\n",
        "\n",
        "# Prepare a tiny stratified subset for smoke run (limit classes to keep it small)\n",
        "def stratified_sample(df: pd.DataFrame, per_class: int = 1, max_classes: int = 512, seed: int = 42) -> pd.DataFrame:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    classes = df['class_idx'].unique()\n",
        "    if len(classes) > max_classes:\n",
        "        classes = rng.choice(classes, size=max_classes, replace=False)\n",
        "        df = df[df['class_idx'].isin(classes)]\n",
        "    parts = []\n",
        "    for k, g in df.groupby('class_idx', sort=False):\n",
        "        take = min(per_class, len(g))\n",
        "        parts.append(g.sample(n=take, random_state=seed))\n",
        "    return pd.concat(parts, axis=0).reset_index(drop=True)\n",
        "\n",
        "smoke_df = stratified_sample(train_df[['filepath','class_idx']], per_class=1, max_classes=512, seed=42)\n",
        "print('Smoke subset size:', len(smoke_df), 'unique classes:', smoke_df['class_idx'].nunique(), flush=True)\n",
        "\n",
        "# Example DataLoaders for smoke test\n",
        "train_tfms = get_transforms(GLOBAL_IMG_SIZE, train=True)\n",
        "val_tfms = get_transforms(GLOBAL_IMG_SIZE, train=False)\n",
        "smoke_ds = HerbariumDataset(smoke_df, transforms=train_tfms)\n",
        "smoke_loader = DataLoader(smoke_ds, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, drop_last=False)\n",
        "print('Smoke loader ready, batches:', len(smoke_loader), flush=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded cached folds: 5\nSmoke subset size: 512 unique classes: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Smoke loader ready, batches: 16\n"
          ]
        }
      ]
    },
    {
      "id": "79efa912-738d-4fb9-8742-e1c27c12a129",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training loop (smoke run) with ConvNeXt-B @384, AMP, CE+LS, class weights\n",
        "import time, math, os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import timm\n",
        "\n",
        "def build_model(num_classes: int, model_name: str = 'convnext_base.fb_in22k', pretrained: bool = True):\n",
        "    m = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes)\n",
        "    m.to(memory_format=torch.channels_last)\n",
        "    return m\n",
        "\n",
        "def train_smoke_epoch():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    num_classes = int(train_df['class_idx'].nunique())\n",
        "    print('Num classes:', num_classes, flush=True)\n",
        "    model = build_model(num_classes, 'convnext_base.fb_in22k', pretrained=True).to(device)\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    cls_weights = compute_class_weights(train_df).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=cls_weights, label_smoothing=0.10).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=2e-3, weight_decay=0.05)\n",
        "    scaler = GradScaler(enabled=True)\n",
        "\n",
        "    model.train()\n",
        "    total, correct, running_loss = 0, 0, 0.0\n",
        "    t0 = time.time()\n",
        "    for bi, (imgs, labels) in enumerate(smoke_loader):\n",
        "        imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast(enabled=True):\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += imgs.size(0)\n",
        "        if (bi+1) % 5 == 0:\n",
        "            elapsed = time.time()-t0\n",
        "            print(f'[Smoke] Batch {bi+1}/{len(smoke_loader)}  loss={running_loss/total:.4f} acc={correct/total:.4f} elapsed={elapsed:.1f}s', flush=True)\n",
        "    print(f'[Smoke] Done. Loss={running_loss/total:.4f} Acc={correct/total:.4f} total={total}', flush=True)\n",
        "\n",
        "# Note: Run this once to validate end-to-end before full 5-fold training\n",
        "print('Ready to run smoke epoch once installations finish. Call train_smoke_epoch() next.', flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "96ed53ea-6ca3-4a27-8857-30cb93222df2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fix albumentations dependency: install/upgrade albucore to match A>=1.4\n",
        "import sys, subprocess, time\n",
        "t0=time.time()\n",
        "def pip(*args):\n",
        "    print('> pip', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Honor torch constraints; only install albucore\n",
        "pip('install','-c','constraints.txt','albucore>=0.0.12','--upgrade','--upgrade-strategy','only-if-needed')\n",
        "\n",
        "import albucore, albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "print('albucore:', getattr(albucore,'__version__','?'), 'albumentations:', getattr(A,'__version__','?'), flush=True)\n",
        "print('Albumentations import OK. Elapsed: %.1fs' % (time.time()-t0), flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "448c63db-305e-437f-a528-23ae7c9eddec",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run smoke training epoch to validate pipeline\n",
        "train_smoke_epoch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "e0a5c9b7-a9f6-4ba0-ae53-0eb5c431f0f5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fast prototype-based inference with ConvNeXt features (no training)\n",
        "import torch, torch.nn.functional as F, time\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n",
        "import pandas as pd\n",
        "\n",
        "def build_feature_extractor(model_name: str = 'convnext_base.fb_in22k', img_size: int = 256):\n",
        "    # num_classes=0 makes model forward return pooled features\n",
        "    model = timm.create_model(model_name, pretrained=True, num_classes=0, global_pool='avg')\n",
        "    model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "    model.to(memory_format=torch.channels_last)\n",
        "    model.eval()\n",
        "    tfm = get_transforms(img_size, train=False)\n",
        "    return model, tfm\n",
        "\n",
        "def select_prototypes(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # one image per class (first occurrence) for speed\n",
        "    return df[['filepath','class_idx']].drop_duplicates('class_idx', keep='first').reset_index(drop=True)\n",
        "\n",
        "def extract_embeddings(model, df: pd.DataFrame, batch_size: int = 128, img_size: int = 256, log_prefix: str = '', num_workers: int = 4):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    ds = HerbariumDataset(df, transforms=get_transforms(img_size, train=False))\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "    embs = []\n",
        "    t0 = time.time()\n",
        "    with torch.no_grad():\n",
        "        for bi, (imgs, _) in enumerate(dl):\n",
        "            imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            with torch.amp.autocast(device_type='cuda', enabled=device.type=='cuda'):\n",
        "                feat = model(imgs)\n",
        "            feat = F.normalize(feat.float(), dim=1)\n",
        "            embs.append(feat.cpu())\n",
        "            if (bi+1) % 50 == 0:\n",
        "                print(f'{log_prefix} batch {bi+1}/{len(dl)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "    embs = torch.cat(embs, dim=0)\n",
        "    return embs\n",
        "\n",
        "def run_prototype_submission(img_size: int = 256, batch_size: int = 128):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # Build feature extractor\n",
        "    print('Building feature extractor...', flush=True)\n",
        "    model, _ = build_feature_extractor('convnext_base.fb_in22k', img_size)\n",
        "\n",
        "    # Prototypes (one per class)\n",
        "    print('Selecting prototypes...', flush=True)\n",
        "    proto_df = select_prototypes(train_df)\n",
        "    print('Prototype images:', len(proto_df), 'num classes:', train_df['class_idx'].nunique(), flush=True)\n",
        "    proto_embs = extract_embeddings(model, proto_df, batch_size=batch_size, img_size=img_size, log_prefix='PROT', num_workers=4)\n",
        "    proto_embs = proto_embs.to(device, non_blocking=True).half() if device.type=='cuda' else proto_embs\n",
        "\n",
        "    # Test embeddings streamed and classified on the fly\n",
        "    print('Classifying test...', flush=True)\n",
        "    # Ensure test order by image_id matching sample_submission Id\n",
        "    test_order = test_imgs.sort_values('image_id').reset_index(drop=True)\n",
        "    test_ds = HerbariumDataset(test_order[['filepath']], label_col=None, transforms=get_transforms(img_size, train=False))\n",
        "    test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    preds_idx = []\n",
        "    t0 = time.time()\n",
        "    with torch.no_grad():\n",
        "        for bi, (imgs, _) in enumerate(test_dl):\n",
        "            imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            with torch.amp.autocast(device_type='cuda', enabled=device.type=='cuda'):\n",
        "                feats = model(imgs)\n",
        "            feats = F.normalize(feats.float(), dim=1)\n",
        "            if device.type=='cuda':\n",
        "                feats = feats.half()\n",
        "            # cosine similarity via dot product of normalized vectors\n",
        "            sims = feats @ proto_embs.T\n",
        "            top_idx = sims.argmax(dim=1).int().cpu().tolist()\n",
        "            preds_idx.extend(top_idx)\n",
        "            if (bi+1) % 50 == 0:\n",
        "                print(f'TEST batch {bi+1}/{len(test_dl)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "\n",
        "    # Map prototype class_idx back to original category_id\n",
        "    # proto_df rows correspond to columns in proto_embs\n",
        "    proto_class_idx = proto_df['class_idx'].tolist()\n",
        "    mapped_catid = [idx2catid[str(int(proto_class_idx[i]))] if isinstance(list(idx2catid.keys())[0], str) else idx2catid[int(proto_class_idx[i])] for i in preds_idx]\n",
        "\n",
        "    sub = pd.DataFrame({'Id': test_order['image_id'].astype(int), 'Predicted': pd.Series(mapped_catid).astype(int)})\n",
        "    sub = sub.sort_values('Id').reset_index(drop=True)\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Wrote submission.csv with', len(sub), 'rows')\n",
        "\n",
        "print('Prototype pipeline ready. Call run_prototype_submission() to generate submission.csv', flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "d49f65ee-e0d9-4359-9d2f-fb7170e516e3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate submission with prototype-based classifier (replaces any existing submission.csv)\n",
        "run_prototype_submission(img_size=224, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "37fbbbd6-7eb3-4d35-b987-77b55a57d8a8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Finetune ConvNeXt-B @224 with head-warmup + full FT; CE+LS (no class weights) + WRS; EMA; step-capped epochs\n",
        "import os, math, time, gc, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "\n",
        "os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "# Global hyperparams\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64  # drop to 48 if OOM\n",
        "EPOCHS = 8\n",
        "WARMUP_EPOCHS = 2  # head-only warmup\n",
        "LR_BACKBONE = 3e-3\n",
        "LR_HEAD = 1e-2\n",
        "WD = 0.05\n",
        "NUM_WORKERS = 8  # after clean torch install, use workers for speed\n",
        "STEPS_PER_EPOCH = 1000  # cap steps/epoch via sampler (reduced for faster iterations)\n",
        "VAL_MAX_BATCHES = 400   # cap validation to speed up\n",
        "EVAL_EVERY = 1          # validate every epoch\n",
        "ART_DIR = Path('artifacts'); ART_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "def build_convnext_b(num_classes: int):\n",
        "    m = timm.create_model('convnext_base.fb_in22k', pretrained=True, num_classes=num_classes)\n",
        "    # DO NOT enable grad checkpointing (it broke grads earlier)\n",
        "    # Init classifier bias to -log(num_classes) to avoid large initial logits\n",
        "    try:\n",
        "        head = m.get_classifier() if hasattr(m, 'get_classifier') else getattr(m, 'head', None)\n",
        "        if head is None:\n",
        "            head = getattr(m, 'head', None)\n",
        "        bias = getattr(head, 'bias', None)\n",
        "        if bias is not None:\n",
        "            nn.init.constant_(bias, -math.log(float(num_classes)))\n",
        "            print('Init head bias to -log(C)', flush=True)\n",
        "    except Exception as e:\n",
        "        print('Head bias init skipped:', e, flush=True)\n",
        "    m.to(memory_format=torch.channels_last)\n",
        "    return m.to(DEVICE)\n",
        "\n",
        "def make_loaders_for_fold(fold_idx: int):\n",
        "    tr_idx, va_idx = splits[fold_idx]\n",
        "    tr_df = train_df.iloc[tr_idx][['filepath','class_idx']].reset_index(drop=True)\n",
        "    va_df = train_df.iloc[va_idx][['filepath','class_idx']].reset_index(drop=True)\n",
        "    # per-sample weights for sampler (inverse sqrt of class freq)\n",
        "    counts = train_df['class_idx'].value_counts().sort_index().values.astype(float)\n",
        "    samp_w_cls = 1.0 / np.sqrt(counts)\n",
        "    samp_w_cls = samp_w_cls / samp_w_cls.mean()\n",
        "    samp_w = torch.tensor(samp_w_cls, dtype=torch.float32)\n",
        "    per_sample_w = samp_w[torch.tensor(tr_df['class_idx'].values, dtype=torch.long)]\n",
        "    # Limit epoch length\n",
        "    num_samples = int(STEPS_PER_EPOCH * BATCH_SIZE)\n",
        "    sampler = WeightedRandomSampler(weights=per_sample_w, num_samples=num_samples, replacement=True)\n",
        "\n",
        "    tr_ds = HerbariumDataset(tr_df, transforms=get_transforms(IMG_SIZE, train=True))\n",
        "    va_ds = HerbariumDataset(va_df, transforms=get_transforms(IMG_SIZE, train=False))\n",
        "\n",
        "    # Build DataLoader kwargs safely when NUM_WORKERS==0 (no prefetch/persistent)\n",
        "    tr_kwargs = dict(batch_size=BATCH_SIZE, sampler=sampler, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "    va_kwargs = dict(batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, drop_last=False)\n",
        "    if NUM_WORKERS > 0:\n",
        "        tr_kwargs.update(dict(persistent_workers=True, prefetch_factor=2))\n",
        "        va_kwargs.update(dict(persistent_workers=True, prefetch_factor=2))\n",
        "\n",
        "    tr_loader = DataLoader(tr_ds, **tr_kwargs)\n",
        "    va_loader = DataLoader(va_ds, **va_kwargs)\n",
        "    return tr_loader, va_loader\n",
        "\n",
        "def split_head_backbone_params(model):\n",
        "    head_names = set()\n",
        "    # ConvNeXt in timm uses m.head.fc as classifier\n",
        "    if hasattr(model, 'head') and hasattr(model.head, 'fc'):\n",
        "        for n, _ in model.head.fc.named_parameters(prefix='head.fc'):\n",
        "            head_names.add(n)\n",
        "    elif hasattr(model, 'get_classifier'):\n",
        "        for n, _ in model.get_classifier().named_parameters():\n",
        "            head_names.add(n)\n",
        "    head_params, backbone_params = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        if ('head' in n and 'fc' in n) or (n in head_names):\n",
        "            head_params.append(p)\n",
        "        else:\n",
        "            backbone_params.append(p)\n",
        "    return head_params, backbone_params\n",
        "\n",
        "def train_one_fold(fold_idx: int):\n",
        "    if DEVICE.type=='cuda': torch.cuda.empty_cache()\n",
        "    num_classes = int(train_df['class_idx'].nunique())\n",
        "    model = build_convnext_b(num_classes)\n",
        "    ema = ModelEmaV2(model, decay=0.9998)\n",
        "    tr_loader, va_loader = make_loaders_for_fold(fold_idx)\n",
        "    print(f'[F{fold_idx}] len(tr_loader)={len(tr_loader)} expected={STEPS_PER_EPOCH}', flush=True)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05).to(DEVICE)\n",
        "\n",
        "    # Phase 1: head-only warmup\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "    head_params, _ = split_head_backbone_params(model)\n",
        "    for p in head_params:\n",
        "        p.requires_grad = True\n",
        "    optimizer = optim.AdamW(head_params, lr=LR_HEAD, weight_decay=0.0)\n",
        "    scheduler = None  # no scheduler in warmup\n",
        "    scaler = GradScaler(enabled=(DEVICE.type=='cuda'))\n",
        "    best_f1 = -1.0\n",
        "    ckpt_path = ART_DIR / f'convnext_b_fold{fold_idx}.pt'\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        t0 = time.time()\n",
        "        tr_loss, seen = 0.0, 0\n",
        "        print(f'[F{fold_idx}] Epoch {epoch+1} steps this epoch: {len(tr_loader)}', flush=True)\n",
        "        for bi, (imgs, labels) in enumerate(tr_loader):\n",
        "            imgs = imgs.to(DEVICE, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            labels = labels.to(DEVICE, non_blocking=True)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast(device_type='cuda', enabled=(DEVICE.type=='cuda')):\n",
        "                logits = model(imgs)\n",
        "                loss = criterion(logits, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            ema.update(model)\n",
        "            tr_loss += loss.item() * imgs.size(0)\n",
        "            seen += imgs.size(0)\n",
        "            if (bi+1) % 200 == 0:\n",
        "                print(f'[F{fold_idx}] ep{epoch+1} step{bi+1}/{len(tr_loader)} loss={tr_loss/max(seen,1):.4f} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "\n",
        "        # Transition to Phase 2 after warmup epochs\n",
        "        if epoch + 1 == WARMUP_EPOCHS:\n",
        "            # Unfreeze all, set two param groups\n",
        "            for p in model.parameters():\n",
        "                p.requires_grad = True\n",
        "            head_params, backbone_params = split_head_backbone_params(model)\n",
        "            optimizer = optim.AdamW([\n",
        "                {'params': backbone_params, 'lr': LR_BACKBONE, 'weight_decay': WD},\n",
        "                {'params': head_params, 'lr': LR_HEAD * 1.5, 'weight_decay': WD},\n",
        "            ])\n",
        "            scheduler = CosineAnnealingLR(optimizer, T_max=max(EPOCHS - WARMUP_EPOCHS, 1), eta_min=1e-6)\n",
        "\n",
        "        # Scheduler step in Phase 2\n",
        "        if scheduler is not None and (epoch + 1) > WARMUP_EPOCHS:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Validation each epoch (EMA weights), capped batches\n",
        "        ema_model = ema.module\n",
        "        ema_model.eval()\n",
        "        val_logits, val_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            max_batches = min(len(va_loader), VAL_MAX_BATCHES)\n",
        "            for bi, (imgs, labels) in enumerate(va_loader):\n",
        "                imgs = imgs.to(DEVICE, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                with torch.amp.autocast(device_type='cuda', enabled=(DEVICE.type=='cuda')):\n",
        "                    logits = ema_model(imgs)\n",
        "                val_logits.append(logits.float().cpu())\n",
        "                val_labels.append(labels.cpu())\n",
        "                if (bi+1) % 100 == 0:\n",
        "                    print(f'[F{fold_idx}] val batch {bi+1}/{max_batches}', flush=True)\n",
        "                if (bi + 1) >= VAL_MAX_BATCHES:\n",
        "                    break\n",
        "        val_logits = torch.cat(val_logits, dim=0)\n",
        "        val_labels = torch.cat(val_labels, dim=0).numpy()\n",
        "        val_preds = val_logits.argmax(dim=1).numpy()\n",
        "        f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "        print(f'[F{fold_idx}] Epoch {epoch+1}/{EPOCHS} steps/ep={len(tr_loader)} train_loss={tr_loss/max(seen,1):.4f} val_macroF1={f1:.5f} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            torch.save({'model': ema_model.state_dict(), 'f1': best_f1}, ckpt_path)\n",
        "            print(f'[F{fold_idx}] New best F1 {best_f1:.5f}. Saved {ckpt_path}', flush=True)\n",
        "\n",
        "        gc.collect();\n",
        "        if DEVICE.type=='cuda': torch.cuda.empty_cache()\n",
        "\n",
        "    print(f'[F{fold_idx}] Best val macro-F1: {best_f1:.5f}', flush=True)\n",
        "    return str(ckpt_path), best_f1\n",
        "\n",
        "def train_n_folds(n_first_folds: int = 1):\n",
        "    ckpts, scores = [], []\n",
        "    for f in range(n_first_folds):\n",
        "        print(f'=== Training fold {f} ===', flush=True)\n",
        "        ck, sc = train_one_fold(f)\n",
        "        ckpts.append(ck); scores.append(sc)\n",
        "    print('Fold scores:', scores, 'avg:', float(np.mean(scores)) if scores else -1, flush=True)\n",
        "    Path(ART_DIR/'trained_folds.json').write_text(json.dumps({'ckpts': ckpts, 'scores': scores}))\n",
        "    return ckpts, scores\n",
        "\n",
        "print('Finetune pipeline ready. Call train_n_folds(1) to start.', flush=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finetune pipeline ready. Call train_n_folds(1) to start.\n"
          ]
        }
      ]
    },
    {
      "id": "6ab99a09-79ca-4f24-8ad6-191f8d2a2812",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Launch finetuning: train 3 folds for ensemble\n",
        "ckpts, scores = train_n_folds(3)\n",
        "print('Trained folds:', ckpts, 'Scores:', scores)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Training fold 0 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init head bias to -log(C)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] len(tr_loader)=1000 expected=1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 1 steps this epoch: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_629/2598049193.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler(enabled=(DEVICE.type=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep1 step200/1000 loss=11.3310 elapsed=24.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep1 step400/1000 loss=11.2726 elapsed=45.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep1 step600/1000 loss=11.1530 elapsed=67.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep1 step800/1000 loss=11.0239 elapsed=88.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep1 step1000/1000 loss=10.8841 elapsed=110.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 100/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 200/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 300/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 400/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 1/8 steps/ep=1000 train_loss=10.8841 val_macroF1=0.01399 elapsed=151.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] New best F1 0.01399. Saved artifacts/convnext_b_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 2 steps this epoch: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep2 step200/1000 loss=10.1689 elapsed=22.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep2 step400/1000 loss=10.0721 elapsed=44.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep2 step600/1000 loss=9.9590 elapsed=65.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep2 step800/1000 loss=9.8625 elapsed=87.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep2 step1000/1000 loss=9.7734 elapsed=109.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 100/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 200/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 300/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 400/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 2/8 steps/ep=1000 train_loss=9.7734 val_macroF1=0.04860 elapsed=146.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] New best F1 0.04860. Saved artifacts/convnext_b_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 3 steps this epoch: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep3 step200/1000 loss=8.7229 elapsed=61.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep3 step400/1000 loss=8.7125 elapsed=122.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep3 step600/1000 loss=8.6495 elapsed=183.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep3 step800/1000 loss=8.5406 elapsed=244.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep3 step1000/1000 loss=8.4248 elapsed=305.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 100/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 200/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 300/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 400/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 3/8 steps/ep=1000 train_loss=8.4248 val_macroF1=0.06758 elapsed=343.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] New best F1 0.06758. Saved artifacts/convnext_b_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 4 steps this epoch: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep4 step200/1000 loss=7.6868 elapsed=61.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep4 step400/1000 loss=7.5446 elapsed=122.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep4 step600/1000 loss=7.4283 elapsed=183.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep4 step800/1000 loss=7.3281 elapsed=245.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep4 step1000/1000 loss=7.2434 elapsed=306.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 100/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 200/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 300/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 400/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 4/8 steps/ep=1000 train_loss=7.2434 val_macroF1=0.08087 elapsed=344.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] New best F1 0.08087. Saved artifacts/convnext_b_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 5 steps this epoch: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep5 step200/1000 loss=6.2975 elapsed=62.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep5 step400/1000 loss=6.0409 elapsed=123.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep5 step600/1000 loss=5.8902 elapsed=184.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep5 step800/1000 loss=5.7981 elapsed=245.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep5 step1000/1000 loss=5.7225 elapsed=307.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 100/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 200/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 300/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 400/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 5/8 steps/ep=1000 train_loss=5.7225 val_macroF1=0.10612 elapsed=344.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] New best F1 0.10612. Saved artifacts/convnext_b_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 6 steps this epoch: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep6 step200/1000 loss=5.0576 elapsed=61.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep6 step400/1000 loss=4.9197 elapsed=123.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep6 step600/1000 loss=4.8367 elapsed=184.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep6 step800/1000 loss=4.7792 elapsed=245.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep6 step1000/1000 loss=4.7329 elapsed=306.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 100/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 200/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 300/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 400/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 6/8 steps/ep=1000 train_loss=4.7329 val_macroF1=0.12689 elapsed=345.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] New best F1 0.12689. Saved artifacts/convnext_b_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 7 steps this epoch: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep7 step200/1000 loss=4.1085 elapsed=61.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep7 step400/1000 loss=3.9005 elapsed=123.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep7 step600/1000 loss=3.7656 elapsed=184.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep7 step800/1000 loss=3.6691 elapsed=245.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep7 step1000/1000 loss=3.5911 elapsed=306.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 100/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 200/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 300/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 400/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 7/8 steps/ep=1000 train_loss=3.5911 val_macroF1=0.14769 elapsed=344.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] New best F1 0.14769. Saved artifacts/convnext_b_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 8 steps this epoch: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep8 step200/1000 loss=3.0637 elapsed=61.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep8 step400/1000 loss=2.9928 elapsed=122.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep8 step600/1000 loss=2.9515 elapsed=183.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep8 step800/1000 loss=2.9227 elapsed=244.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] ep8 step1000/1000 loss=2.8904 elapsed=306.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 100/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 200/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 300/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] val batch 400/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Epoch 8/8 steps/ep=1000 train_loss=2.8904 val_macroF1=0.16330 elapsed=343.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] New best F1 0.16330. Saved artifacts/convnext_b_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F0] Best val macro-F1: 0.16330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Training fold 1 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init head bias to -log(C)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] len(tr_loader)=1000 expected=1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] Epoch 1 steps this epoch: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_629/2598049193.py:113: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler(enabled=(DEVICE.type=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep1 step200/1000 loss=11.3274 elapsed=24.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep1 step400/1000 loss=11.2767 elapsed=46.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep1 step600/1000 loss=11.1542 elapsed=68.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep1 step800/1000 loss=11.0078 elapsed=90.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep1 step1000/1000 loss=10.8730 elapsed=111.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] val batch 100/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] val batch 200/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] val batch 300/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] val batch 400/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] Epoch 1/8 steps/ep=1000 train_loss=10.8730 val_macroF1=0.01322 elapsed=153.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] New best F1 0.01322. Saved artifacts/convnext_b_fold1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] Epoch 2 steps this epoch: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep2 step200/1000 loss=10.1018 elapsed=22.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep2 step400/1000 loss=10.0015 elapsed=44.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep2 step600/1000 loss=9.9143 elapsed=65.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep2 step800/1000 loss=9.8220 elapsed=87.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep2 step1000/1000 loss=9.7418 elapsed=109.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] val batch 100/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] val batch 200/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] val batch 300/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] val batch 400/400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] Epoch 2/8 steps/ep=1000 train_loss=9.7418 val_macroF1=0.04911 elapsed=146.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] New best F1 0.04911. Saved artifacts/convnext_b_fold1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] Epoch 3 steps this epoch: 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep3 step200/1000 loss=8.6458 elapsed=62.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep3 step400/1000 loss=8.6592 elapsed=122.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep3 step600/1000 loss=8.6033 elapsed=183.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep3 step800/1000 loss=8.5048 elapsed=244.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] ep3 step1000/1000 loss=8.3952 elapsed=306.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[F1] val batch 100/400\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Launch finetuning: train 3 folds for ensemble\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ckpts, scores = \u001b[43mtrain_n_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mTrained folds:\u001b[39m\u001b[33m'\u001b[39m, ckpts, \u001b[33m'\u001b[39m\u001b[33mScores:\u001b[39m\u001b[33m'\u001b[39m, scores)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 192\u001b[39m, in \u001b[36mtrain_n_folds\u001b[39m\u001b[34m(n_first_folds)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_first_folds):\n\u001b[32m    191\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m=== Training fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ===\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     ck, sc = \u001b[43mtrain_one_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m     ckpts.append(ck); scores.append(sc)\n\u001b[32m    194\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mFold scores:\u001b[39m\u001b[33m'\u001b[39m, scores, \u001b[33m'\u001b[39m\u001b[33mavg:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(np.mean(scores)) \u001b[38;5;28;01mif\u001b[39;00m scores \u001b[38;5;28;01melse\u001b[39;00m -\u001b[32m1\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 165\u001b[39m, in \u001b[36mtrain_one_fold\u001b[39m\u001b[34m(fold_idx)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.amp.autocast(device_type=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m, enabled=(DEVICE.type==\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m)):\n\u001b[32m    164\u001b[39m     logits = ema_model(imgs)\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m val_logits.append(\u001b[43mlogits\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    166\u001b[39m val_labels.append(labels.cpu())\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (bi+\u001b[32m1\u001b[39m) % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "ed60a9ad-df62-4873-9024-68cfa3fb8ad4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference: load fold checkpoints, 2x TTA (orig + hflip), average logits, write submission.csv\n",
        "import json, math, time\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def load_fold_models(ckpt_paths):\n",
        "    num_classes = int(train_df['class_idx'].nunique())\n",
        "    models = []\n",
        "    for p in ckpt_paths:\n",
        "        if not Path(p).exists():\n",
        "            print('Missing ckpt:', p, flush=True); continue\n",
        "        m = timm.create_model('convnext_base.fb_in22k', pretrained=False, num_classes=num_classes)\n",
        "        m.to(memory_format=torch.channels_last)\n",
        "        sd = torch.load(p, map_location='cpu')\n",
        "        m.load_state_dict(sd['model'], strict=True)\n",
        "        m.to(DEVICE).eval()\n",
        "        models.append(m)\n",
        "        print('Loaded ckpt:', p, 'F1=', sd.get('f1', None), flush=True)\n",
        "    return models\n",
        "\n",
        "def infer_test(models, img_size: int = 384, batch_size: int = 64, num_workers: int = 8):\n",
        "    assert len(models) > 0, 'No models provided for inference'\n",
        "    test_order = test_imgs.sort_values('image_id').reset_index(drop=True)\n",
        "    ds = HerbariumDataset(test_order[['filepath']], label_col=None, transforms=get_transforms(img_size, train=False))\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "    all_logits_sum = []\n",
        "    t0 = time.time()\n",
        "    with torch.no_grad():\n",
        "        for bi, (imgs, _) in enumerate(dl):\n",
        "            imgs = imgs.to(DEVICE, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            # TTA: original + hflip\n",
        "            with torch.amp.autocast(device_type='cuda', enabled=(DEVICE.type=='cuda')):\n",
        "                logits_ens = None\n",
        "                for m in models:\n",
        "                    l1 = m(imgs)\n",
        "                    l2 = m(torch.flip(imgs, dims=[3]))  # horizontal flip\n",
        "                    l = (l1 + l2) * 0.5\n",
        "                    logits_ens = l if logits_ens is None else (logits_ens + l)\n",
        "            all_logits_sum.append(logits_ens.float().cpu())\n",
        "            if (bi+1) % 50 == 0:\n",
        "                print(f'INF batch {bi+1}/{len(dl)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "    all_logits_sum = torch.cat(all_logits_sum, dim=0)\n",
        "    return all_logits_sum, test_order\n",
        "\n",
        "# Precompute smoothed log-prior for inference-time logit adjustment (long-tail debiasing)\n",
        "counts = train_df['class_idx'].value_counts().sort_index().values.astype(np.float64)\n",
        "C = counts.shape[0]\n",
        "alpha = 1.0  # Laplace smoothing\n",
        "prior = (counts + alpha) / (counts.sum() + alpha * C)\n",
        "prior = torch.tensor(prior, dtype=torch.float32)\n",
        "log_prior = prior.log()\n",
        "\n",
        "# Defaults per expert advice\n",
        "BETA = 0.7   # power/soften prior via effective tau scaling\n",
        "TEMP = 1.5   # temperature\n",
        "LAM = 0.5    # blend weight\n",
        "\n",
        "def adjust_logits(logits_sum: torch.Tensor, tau: float, beta: float = BETA, T: float = TEMP, lam: float = LAM) -> torch.Tensor:\n",
        "    # Temperature\n",
        "    logits = logits_sum / float(T)\n",
        "    # Adjust with smoothed prior\n",
        "    adj = logits - (tau * beta) * log_prior[None, :]\n",
        "    # Blend with unadjusted logits\n",
        "    blended = (1.0 - lam) * logits + lam * adj\n",
        "    return blended\n",
        "\n",
        "def write_submission_from_logits(logits_sum: torch.Tensor, test_order: pd.DataFrame, tau: float, out_path: str = 'submission.csv', lam: float = LAM, T: float = TEMP, beta: float = BETA):\n",
        "    blended = adjust_logits(logits_sum, tau=tau, beta=beta, T=T, lam=lam)\n",
        "    preds_idx = blended.argmax(dim=1).numpy().tolist()\n",
        "    # idx2catid keys may be str; handle both\n",
        "    if isinstance(next(iter(idx2catid.keys())), str):\n",
        "        mapped = [int(idx2catid[str(int(i))]) for i in preds_idx]\n",
        "    else:\n",
        "        mapped = [int(idx2catid[int(i)]) for i in preds_idx]\n",
        "    sub = pd.DataFrame({'Id': test_order['image_id'].astype(int), 'Predicted': mapped})\n",
        "    sub = sub.sort_values('Id').reset_index(drop=True)\n",
        "    sub.to_csv(out_path, index=False)\n",
        "    print(f'Saved {out_path} rows:', len(sub), flush=True)\n",
        "\n",
        "def cache_test_logits(ckpt_paths, logits_path: str = 'artifacts/test_logits_fold0.pt', ids_path: str = 'artifacts/test_ids.npy', img_size: int = None):\n",
        "    img_sz = IMG_SIZE if img_size is None else img_size\n",
        "    models = load_fold_models(ckpt_paths)\n",
        "    logits_sum, test_order = infer_test(models, img_size=img_sz, batch_size=64, num_workers=NUM_WORKERS)\n",
        "    Path('artifacts').mkdir(exist_ok=True)\n",
        "    torch.save(logits_sum, logits_path)\n",
        "    np.save(ids_path, test_order['image_id'].values.astype(np.int64))\n",
        "    print('Cached:', logits_path, 'and', ids_path, flush=True)\n",
        "    return logits_sum, test_order\n",
        "\n",
        "def write_submission_from_cached(logits_path: str, ids_path: str, tau: float, out_path: str = 'submission.csv', lam: float = LAM, T: float = TEMP, beta: float = BETA):\n",
        "    logits_sum = torch.load(logits_path, map_location='cpu')\n",
        "    ids = np.load(ids_path)\n",
        "    blended = adjust_logits(logits_sum, tau=tau, beta=beta, T=T, lam=lam)\n",
        "    preds_idx = blended.argmax(dim=1).numpy().tolist()\n",
        "    if isinstance(next(iter(idx2catid.keys())), str):\n",
        "        mapped = [int(idx2catid[str(int(i))]) for i in preds_idx]\n",
        "    else:\n",
        "        mapped = [int(idx2catid[int(i)]) for i in preds_idx]\n",
        "    sub = pd.DataFrame({'Id': ids.astype(int), 'Predicted': mapped})\n",
        "    sub = sub.sort_values('Id').reset_index(drop=True)\n",
        "    sub.to_csv(out_path, index=False)\n",
        "    print(f'Saved {out_path} rows:', len(sub), 'tau=', tau, 'lam=', lam, 'T=', T, 'beta=', beta, flush=True)\n",
        "\n",
        "def run_inference_from_trained(n_folds_to_use: int = 1, tau: float = 1.5):\n",
        "    # Try to read ckpt list from artifacts/trained_folds.json, else fallback to default paths\n",
        "    ckpt_paths = []\n",
        "    trained_json = ART_DIR / 'trained_folds.json'\n",
        "    if trained_json.exists():\n",
        "        meta = json.loads(trained_json.read_text())\n",
        "        ckpt_paths = meta.get('ckpts', [])[:n_folds_to_use]\n",
        "    if not ckpt_paths:\n",
        "        # Default guess\n",
        "        ckpt_paths = [str(ART_DIR / f'convnext_b_fold{i}.pt') for i in range(n_folds_to_use)]\n",
        "    print('Using ckpts:', ckpt_paths, flush=True)\n",
        "    models = load_fold_models(ckpt_paths)\n",
        "    logits_sum, test_order = infer_test(models, img_size=IMG_SIZE, batch_size=64, num_workers=NUM_WORKERS)\n",
        "    write_submission_from_logits(logits_sum, test_order, tau=tau, out_path='submission.csv', lam=LAM, T=TEMP, beta=BETA)\n",
        "\n",
        "print('Inference pipeline ready with tau/T/beta/lambda adjustment. Use cache_test_logits once, then write_submission_from_cached for fast tau sweep.', flush=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference pipeline ready with tau/T/beta/lambda adjustment. Use cache_test_logits once, then write_submission_from_cached for fast tau sweep.\n"
          ]
        }
      ]
    },
    {
      "id": "7fdc8ead-b618-4046-b353-7737a63b9fee",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cache test logits once, then write submissions for tau sweeps (two presets) quickly\n",
        "from pathlib import Path\n",
        "import shutil, os\n",
        "\n",
        "candidates = ['artifacts/convnext_b_fold0.pt', 'nybg2020/convnext_b_fold0.pt']\n",
        "existing = [p for p in candidates if Path(p).exists()]\n",
        "print('Candidate ckpts:', candidates, '-> existing:', existing, flush=True)\n",
        "assert len(existing) > 0, 'No checkpoint found. Ensure training saved a ckpt.'\n",
        "\n",
        "# Prefer the newest checkpoint (by mtime) to avoid averaging mismatched epochs\n",
        "chosen_ckpt = max(existing, key=lambda p: Path(p).stat().st_mtime)\n",
        "ckpt_paths = [chosen_ckpt]\n",
        "print('Using newest ckpt:', ckpt_paths[0], flush=True)\n",
        "\n",
        "logits_path = 'artifacts/test_logits_fold0.pt'\n",
        "ids_path = 'artifacts/test_ids.npy'\n",
        "force_recache = True  # Force refresh with latest checkpoint\n",
        "\n",
        "if force_recache:\n",
        "    for fp in (logits_path, ids_path):\n",
        "        if Path(fp).exists():\n",
        "            try:\n",
        "                os.remove(fp)\n",
        "                print('Removed stale cache:', fp, flush=True)\n",
        "            except Exception as e:\n",
        "                print('Could not remove', fp, e, flush=True)\n",
        "\n",
        "if not Path(logits_path).exists() or not Path(ids_path).exists():\n",
        "    print('Caching test logits/ids...', flush=True)\n",
        "    cache_test_logits(ckpt_paths, logits_path=logits_path, ids_path=ids_path, img_size=IMG_SIZE)\n",
        "else:\n",
        "    print('Using cached logits/ids:', logits_path, ids_path, flush=True)\n",
        "\n",
        "# Tau sweeps per expert advice\n",
        "taus_wide = [0.7, 1.0, 1.2, 1.5, 1.8, 2.0, 2.5, 3.0, 3.5]\n",
        "presets = [\n",
        "    {'name':'p1','beta':0.7,'T':1.5,'lam':0.5, 'taus': taus_wide},\n",
        "    {'name':'p2','beta':0.5,'T':1.2,'lam':0.3, 'taus': [1.5, 2.0, 2.5, 3.0, 3.5]},\n",
        "]\n",
        "out_root = Path('artifacts/submissions'); out_root.mkdir(parents=True, exist_ok=True)\n",
        "for ps in presets:\n",
        "    name, beta, T, lam, taus = ps['name'], ps['beta'], ps['T'], ps['lam'], ps['taus']\n",
        "    out_dir = out_root / name\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for t in taus:\n",
        "        outp = out_dir / f'submission_{name}_tau_{t:.2f}.csv'\n",
        "        write_submission_from_cached(logits_path, ids_path, tau=float(t), out_path=str(outp), lam=lam, T=T, beta=beta)\n",
        "\n",
        "# Choose one to copy to submission.csv for immediate submit (preset p1, tau=3.00 as new try)\n",
        "best_preset = 'p1'; best_tau = 3.00\n",
        "chosen = out_root / best_preset / f'submission_{best_preset}_tau_{best_tau:.2f}.csv'\n",
        "assert chosen.exists(), f'Missing expected {chosen}'\n",
        "shutil.copyfile(chosen, 'submission.csv')\n",
        "print('Copied', chosen, '-> submission.csv', flush=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Candidate ckpts: ['artifacts/convnext_b_fold0.pt', 'nybg2020/convnext_b_fold0.pt'] -> existing: ['artifacts/convnext_b_fold0.pt']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using newest ckpt: artifacts/convnext_b_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed stale cache: artifacts/test_logits_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed stale cache: artifacts/test_ids.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching test logits/ids...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_629/3204309005.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  sd = torch.load(p, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded ckpt: artifacts/convnext_b_fold0.pt F1= 0.16330388671425206\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}