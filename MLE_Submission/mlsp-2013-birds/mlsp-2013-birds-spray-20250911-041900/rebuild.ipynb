{
  "cells": [
    {
      "id": "a5c24931-2f9f-45b7-b427-8ec1df093eb8",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lean Rebuild Plan: MLSP 2013 Birds (Primary Plan)\n",
        "\n",
        "Objective: Clean, tabular-only pipeline using exactly the 588 histogram features (no priors, no station OHE). Train 4 highly-regularized models; select best single and best blend using pooled OOF macro AUC. Target: LB medal.\n",
        "\n",
        "Key constraints learned:\n",
        "- 19 classes only (assertions enforced).\n",
        "- No leakage: fit anything only on train folds.\n",
        "- Correct scorer: pooled plain macro AUC over OOF probabilities.\n",
        "- LOSO CV, handle single-class folds robustly.\n",
        "\n",
        "Data & Features:\n",
        "- Use existing histogram features spec (588-dim) identical to build_hist_features from production but exclude station priors and any station OHE.\n",
        "- Ensure deterministic feature order and identical transforms for train/test.\n",
        "- Robust loaders for species list and labels (header-safe).\n",
        "\n",
        "Validation:\n",
        "- LOSO CV (leave-one-station-out) based on station parsed from filenames/metadata.\n",
        "- For any fold with classes missing in train: skip model or backfill with class prior = global prevalence from training split (EB optional, but avoid station priors).\n",
        "- Pooled OOF macro AUC across all samples as the single selection metric.\n",
        "\n",
        "Models (4 total):\n",
        "- CatBoost #1: strong regularization, depth ~4-6, l2 ~ 8-20, learning_rate ~ 0.03-0.06, iterations ~ 2000 with early stopping.\n",
        "- CatBoost #2: even stronger regularization / different depth & lr to diversify.\n",
        "- LightGBM: gbdt with high reg (min_data_in_leaf high, feature_fraction ~0.5-0.8, bagging_fraction ~0.6-0.9, lambda_l1/l2 > 0), early stopping.\n",
        "- ExtraTrees (sklearn): many estimators (1000+), max_depth limited, min_samples_leaf >= 5, bootstrap=False.\n",
        "- All models output calibrated probabilities; ensure no inversion for LGBM.\n",
        "\n",
        "Training Loop:\n",
        "- Multilabel setup: fit per-class binary model for tree models (1-vs-rest), or implement native multilabel when supported (CatBoost supports multi-label? If uncertain, use 1-vs-rest for consistency).\n",
        "- Efficient parallelization per class or per fold using joblib.\n",
        "- Log per-fold timing, class counts, and AUC per class; flush periodically.\n",
        "\n",
        "Blending:\n",
        "- Start with equal-weight average of model probabilities.\n",
        "- Do simple weight sweep on OOF (grid over a simplex for 2-4 models) to find best pooled macro AUC; keep it tiny and fast.\n",
        "- Select: (a) best single model by pooled OOF macro AUC, (b) best simple blend.\n",
        "\n",
        "Submission:\n",
        "- Train on full train set per model, predict test, produce two submissions: best_single.csv and best_blend.csv.\n",
        "- Sanity checks: match sample_submission columns and length.\n",
        "\n",
        "Checkpoints for Expert Review:\n",
        "1) This plan & exact model hyperparameters (request guidance on precise values).\n",
        "2) After implementing data loaders and feature builder (confirm 588 features, shapes, and no leakage).\n",
        "3) After first LOSO CV run with one model to verify pooled OOF macro AUC stability.\n",
        "4) After training all 4 models and producing OOFs; before weight sweep.\n",
        "5) Before final training-on-full and submission generation.\n",
        "\n",
        "Open Questions for Experts:\n",
        "- Exact hyperparameters for the 4 models you recommend (depth, iterations, reg).\n",
        "- Whether to use CatBoost's multi-label mode or stick to 1-vs-rest for reliability here.\n",
        "- Any LOSO edge-case handling tips specific to this dataset.\n",
        "\n",
        "Next Steps:\n",
        "- Implement robust loaders + 588-feature builder (no priors/OHE).\n",
        "- Implement LOSO splitter and pooled macro AUC scorer.\n",
        "- Implement class-wise 1-vs-rest training for CatBoost/LGBM/ExtraTrees with logging.\n",
        "- Run initial CV with one conservative model to validate pipeline, then expand to all four."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "62225be8-1a02-410c-9828-f1bae8e9a742",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, json, numpy as np, pandas as pd, re, sys, gc, time\n",
        "from pathlib import Path\n",
        "\n",
        "def log(s):\n",
        "    print(time.strftime('%H:%M:%S'), s, flush=True)\n",
        "\n",
        "# Inspect available precomputed feature artifacts and submission schema\n",
        "log('Listing candidate feature files...')\n",
        "candidates = ['hog_train.npy','hog_test.npy','filtered_stats.npy','panns_cnn14_emb.npy','vggish_256.npy']\n",
        "avail = {}\n",
        "for f in candidates:\n",
        "    if os.path.exists(f):\n",
        "        try:\n",
        "            arr = np.load(f, allow_pickle=True)\n",
        "            shape = getattr(arr, 'shape', None)\n",
        "            avail[f] = shape\n",
        "            log(f'{f}: shape={shape}')\n",
        "        except Exception as e:\n",
        "            log(f'{f}: load error {e}')\n",
        "    else:\n",
        "        log(f'{f}: MISSING')\n",
        "\n",
        "log('Reading sample_submission.csv ...')\n",
        "sample = pd.read_csv('sample_submission.csv')\n",
        "log(f'sample_submission shape={sample.shape}; head:\\n{sample.head()}')\n",
        "\n",
        "# Inspect essential mappings and filenames to derive stations and counts\n",
        "rec_map_path = Path('essential_data/rec_id2filename.txt')\n",
        "if rec_map_path.exists():\n",
        "    # Robust load: auto-detect delimiter, skip header if present\n",
        "    with open(rec_map_path, 'r') as fh:\n",
        "        head = fh.readline()\n",
        "    delim = ',' if ',' in head and '\\t' not in head else ('\\t' if '\\t' in head else None)\n",
        "    df_map = pd.read_csv(rec_map_path, sep=delim, engine='python')\n",
        "    # Try to normalize columns\n",
        "    cols_lower = [c.lower() for c in df_map.columns]\n",
        "    if 'id' in cols_lower and 'filename' in cols_lower:\n",
        "        pass\n",
        "    elif len(df_map.columns) >= 2:\n",
        "        df_map.columns = ['Id','Filename'] + list(df_map.columns[2:])\n",
        "    log(f'rec_id2filename rows={len(df_map)}, cols={df_map.columns.tolist()}')\n",
        "    # Derive station as prefix before first underscore\n",
        "    if 'Filename' in df_map.columns:\n",
        "        df_map['station'] = df_map['Filename'].astype(str).str.split('_').str[0]\n",
        "        log(f\"Stations (n={df_map['station'].nunique()}): {sorted(df_map['station'].unique())[:10]}...\")\n",
        "else:\n",
        "    log('rec_id2filename.txt not found')\n",
        "\n",
        "# Inspect essential_data/species_list.txt for class count (should be 19)\n",
        "species_path = Path('essential_data/species_list.txt')\n",
        "if species_path.exists():\n",
        "    with open(species_path, 'r') as fh:\n",
        "        lines = [ln.strip() for ln in fh if ln.strip()]\n",
        "    # Drop header if present (assume first line contains 'Species' or non-alpha-numeric)\n",
        "    if lines and (lines[0].lower().startswith('species') or ',' in lines[0] or '\\t' in lines[0]):\n",
        "        lines = lines[1:]\n",
        "    log(f'species_list entries={len(lines)} (expect 19)')\n",
        "    if len(lines) != 19:\n",
        "        log('WARNING: species count != 19')\n",
        "else:\n",
        "    log('species_list.txt not found')\n",
        "\n",
        "log('Done.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:43 Listing candidate feature files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:43 hog_train.npy: shape=(145, 8100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:43 hog_test.npy: shape=(64, 8100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:43 filtered_stats.npy: shape=()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:43 panns_cnn14_emb.npy: shape=(322, 2048)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:43 vggish_256.npy: shape=(322, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:43 Reading sample_submission.csv ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:44 sample_submission shape=(1216, 2); head:\n    Id  Probability\n0  100            0\n1  101            0\n2  102            0\n3  103            0\n4  104            0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:44 rec_id2filename rows=322, cols=['Id', 'Filename']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:44 Stations (n=13): ['PC1', 'PC10', 'PC11', 'PC13', 'PC15', 'PC16', 'PC17', 'PC18', 'PC2', 'PC4']...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:44 species_list entries=19 (expect 19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:31:44 Done.\n"
          ]
        }
      ]
    },
    {
      "id": "04c6d1d2-66db-4d6c-8be4-31724e9822c2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data loading + 588-feature loader (filtered_stats.npy) and alignment\n",
        "import numpy as np, pandas as pd, os, time, sys\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_DIR = Path('essential_data')\n",
        "\n",
        "def log(msg):\n",
        "    print(time.strftime('%H:%M:%S'), msg, flush=True)\n",
        "\n",
        "def load_species_list(path: Path):\n",
        "    # Robust header-safe loader; expect 19 entries\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        if {'class_id','code'}.issubset(df.columns):\n",
        "            return df.sort_values('class_id')['code'].tolist()\n",
        "    except Exception:\n",
        "        pass\n",
        "    with open(path, 'r') as f:\n",
        "        lines = [ln.strip() for ln in f if ln.strip()]\n",
        "    if lines and (lines[0].lower().startswith('species') or ',' in lines[0] or '\\t' in lines[0]):\n",
        "        lines = lines[1:]\n",
        "    out = []\n",
        "    for s in lines:\n",
        "        parts = s.split(',')\n",
        "        out.append(parts[1] if len(parts)>1 else s)\n",
        "    return out\n",
        "\n",
        "def parse_rec_id2filename(path: Path):\n",
        "    df = pd.read_csv(path)\n",
        "    df = df.rename(columns={df.columns[0]:'rec_id', df.columns[1]:'filename'})\n",
        "    df['rec_id'] = df['rec_id'].astype(int)\n",
        "    df['station'] = df['filename'].str.extract(r'^(PC\\d+)')\n",
        "    return df[['rec_id','filename','station']]\n",
        "\n",
        "def parse_labels(path: Path, C: int):\n",
        "    rec_ids, flags, Y = [], [], []\n",
        "    with open(path, 'r') as f:\n",
        "        f.readline()  # skip header\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line: continue\n",
        "            parts = [tok.strip() for tok in line.split(',')]\n",
        "            try: rid = int(parts[0])\n",
        "            except: continue\n",
        "            tokens = parts[1:] if len(parts)>1 else []\n",
        "            is_test = any(tok=='?' for tok in tokens)\n",
        "            y = np.zeros(C, dtype=np.uint8)\n",
        "            if not is_test and tokens:\n",
        "                for tok in tokens:\n",
        "                    if tok in ('','?'): continue\n",
        "                    try: idx = int(tok)\n",
        "                    except: continue\n",
        "                    if 0 <= idx < C: y[idx] = 1\n",
        "            rec_ids.append(rid); flags.append(is_test); Y.append(y)\n",
        "    lab_cols = [f'label_{i}' for i in range(C)]\n",
        "    ydf = pd.DataFrame(np.vstack(Y), columns=lab_cols)\n",
        "    df = pd.DataFrame({'rec_id': rec_ids, 'is_test': flags})\n",
        "    return df.join(ydf), lab_cols\n",
        "\n",
        "def load_filtered_stats(path: Path, mask_train=None, mask_test=None):\n",
        "    arr = np.load(path, allow_pickle=True)\n",
        "    # npz-like\n",
        "    if hasattr(arr, 'files'):\n",
        "        Xtr = arr['X_train'] if 'X_train' in arr.files else arr[arr.files[0]]\n",
        "        Xte = arr['X_test'] if 'X_test' in arr.files else None\n",
        "        id_tr = arr['train_ids'] if 'train_ids' in arr.files else None\n",
        "        id_te = arr['test_ids'] if 'test_ids' in arr.files else None\n",
        "        return Xtr, Xte, id_tr, id_te\n",
        "    # object ndarray holding dict\n",
        "    if isinstance(arr, np.ndarray) and arr.dtype == object:\n",
        "        try:\n",
        "            obj = arr.item()\n",
        "        except Exception:\n",
        "            obj = None\n",
        "        if isinstance(obj, dict):\n",
        "            Xtr = obj.get('X_train') or obj.get('train') or obj.get('train_X')\n",
        "            Xte = obj.get('X_test') or obj.get('test') or obj.get('test_X')\n",
        "            id_tr = obj.get('train_ids') or obj.get('ids_train') or obj.get('rec_ids_train')\n",
        "            id_te = obj.get('test_ids') or obj.get('ids_test') or obj.get('rec_ids_test')\n",
        "            return Xtr, Xte, id_tr, id_te\n",
        "    # single 2D stacked array\n",
        "    if isinstance(arr, np.ndarray) and arr.ndim == 2 and mask_train is not None and mask_test is not None:\n",
        "        assert arr.shape[0] == int(mask_train.sum() + mask_test.sum()), 'Rows mismatch total records'\n",
        "        return arr[mask_train], arr[mask_test], None, None\n",
        "    raise RuntimeError('Unsupported filtered_stats.npy format')\n",
        "\n",
        "def align_by_ids(X, ids, order_ids):\n",
        "    if ids is None:\n",
        "        # assume already aligned to order\n",
        "        return X\n",
        "    mp = {int(r): i for i, r in enumerate(ids)}\n",
        "    idx = [mp[int(r)] for r in order_ids]\n",
        "    return X[idx]\n",
        "\n",
        "# 1) Core metadata\n",
        "species = load_species_list(DATA_DIR/'species_list.txt')\n",
        "assert len(species) == 19, f'Expected 19 species, got {len(species)}'\n",
        "rec_map = parse_rec_id2filename(DATA_DIR/'rec_id2filename.txt')\n",
        "labels_df, _ = parse_labels(DATA_DIR/'rec_labels_test_hidden.txt', len(species))\n",
        "df_all = rec_map.merge(labels_df, on='rec_id', how='right')\n",
        "train_df = df_all[~df_all['is_test']].copy()\n",
        "test_df = df_all[df_all['is_test']].copy()\n",
        "y_train = train_df[[c for c in train_df.columns if c.startswith('label_')]].copy()\n",
        "y_train.columns = [f'label_{s}' for s in species]\n",
        "meta_train = train_df[['rec_id','filename','station']].copy()\n",
        "meta_test = test_df[['rec_id','filename','station']].copy()\n",
        "log(f'Train N={len(train_df)} Test N={len(test_df)} Classes={y_train.shape[1]} Stations={train_df.station.nunique()}')\n",
        "\n",
        "# 2) Load 588-d filtered stats and align\n",
        "mask_train = (~df_all['is_test']).values\n",
        "mask_test = (df_all['is_test']).values\n",
        "Xtr_raw, Xte_raw, id_tr, id_te = load_filtered_stats(Path('filtered_stats.npy'), mask_train=mask_train, mask_test=mask_test)\n",
        "Xtr = align_by_ids(Xtr_raw, id_tr, meta_train['rec_id'].values.tolist())\n",
        "Xte = align_by_ids(Xte_raw, id_te, meta_test['rec_id'].values.tolist())\n",
        "assert Xtr is not None and Xte is not None, 'Failed to load/align filtered_stats'\n",
        "log(f'Filtered stats shapes: X_train={getattr(Xtr, \"shape\", None)}, X_test={getattr(Xte, \"shape\", None)}')\n",
        "assert Xtr.shape[1] == 588, f'Expected 588 features, got {Xtr.shape[1]}'\n",
        "assert y_train.shape[1] == 19, f'Expected 19 label columns, got {y_train.shape[1]}'\n",
        "assert len(Xtr) == len(meta_train) and len(Xte) == len(meta_test), 'Row count mismatch after alignment'\n",
        "\n",
        "# 3) Quick summaries\n",
        "pos_per_class = y_train.values.sum(axis=0)\n",
        "neg_per_class = len(y_train) - pos_per_class\n",
        "log('Class positives (first 10): ' + ', '.join(map(str, pos_per_class[:10].tolist())))\n",
        "log('Any empty classes in train? ' + str(bool((pos_per_class==0).any())))\n",
        "log('Stations: ' + ', '.join(sorted(train_df.station.unique().tolist())))\n",
        "log('Done data/feature prep.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:32:48 Train N=258 Test N=64 Classes=19 Stations=13\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Failed to load/align filtered_stats",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    113\u001b[39m Xtr = align_by_ids(Xtr_raw, id_tr, meta_train[\u001b[33m'\u001b[39m\u001b[33mrec_id\u001b[39m\u001b[33m'\u001b[39m].values.tolist())\n\u001b[32m    114\u001b[39m Xte = align_by_ids(Xte_raw, id_te, meta_test[\u001b[33m'\u001b[39m\u001b[33mrec_id\u001b[39m\u001b[33m'\u001b[39m].values.tolist())\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m Xtr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Xte \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m'\u001b[39m\u001b[33mFailed to load/align filtered_stats\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    116\u001b[39m log(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFiltered stats shapes: X_train=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(Xtr,\u001b[38;5;250m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, X_test=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(Xte,\u001b[38;5;250m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m Xtr.shape[\u001b[32m1\u001b[39m] == \u001b[32m588\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExpected 588 features, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mXtr.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n",
            "\u001b[31mAssertionError\u001b[39m: Failed to load/align filtered_stats"
          ]
        }
      ]
    },
    {
      "id": "7b96763f-0d40-4472-8228-17034e678324",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Diagnose filtered_stats.npy structure\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "p = Path('filtered_stats.npy')\n",
        "arr = np.load(p, allow_pickle=True)\n",
        "print('loaded type:', type(arr), 'shape:', getattr(arr, 'shape', None), 'dtype:', getattr(arr, 'dtype', None))\n",
        "if hasattr(arr, 'files'):\n",
        "    print('npz-like files:', arr.files)\n",
        "elif isinstance(arr, np.ndarray) and arr.dtype == object:\n",
        "    try:\n",
        "        obj = arr.item()\n",
        "        if isinstance(obj, dict):\n",
        "            print('top-level dict keys:', list(obj.keys()))\n",
        "            for k, v in obj.items():\n",
        "                if hasattr(v, 'shape'):\n",
        "                    print(' key', k, '-> shape', v.shape, 'dtype', getattr(v, 'dtype', None))\n",
        "                else:\n",
        "                    print(' key', k, '-> type', type(v))\n",
        "        else:\n",
        "            print('top-level object type:', type(obj))\n",
        "    except Exception as e:\n",
        "        print('arr.item() failed:', e)\n",
        "else:\n",
        "    print('Unsupported container; direct shape:', getattr(arr, 'shape', None))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded type: <class 'numpy.ndarray'> shape: () dtype: object\ntop-level dict keys: ['mean', 'std', 'Hmean', 'Wmean']\n key mean -> shape () dtype float64\n key std -> type <class 'float'>\n key Hmean -> type <class 'int'>\n key Wmean -> type <class 'int'>\n"
          ]
        }
      ]
    },
    {
      "id": "38476c40-fb9a-4ca3-9a50-b22885f24c7d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lean rebuild: robust loaders and 588-feature builder (no priors/OHE), assemble X/y and LOSO groups\n",
        "import os, sys, re, time, gc, warnings\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "DATA_DIR = Path('essential_data')\n",
        "SUPP_DIR = Path('supplemental_data')\n",
        "\n",
        "def log(msg):\n",
        "    print(time.strftime('%H:%M:%S'), msg, flush=True)\n",
        "\n",
        "def load_species_list(path: Path):\n",
        "    # CSV with headers class_id,code,species; fallback to line list\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        if {'class_id','code'}.issubset(df.columns):\n",
        "            return df.sort_values('class_id')['code'].tolist()\n",
        "    except Exception:\n",
        "        pass\n",
        "    lines = []\n",
        "    with open(path, 'r') as f:\n",
        "        for ln in f:\n",
        "            s = ln.strip()\n",
        "            if not s: continue\n",
        "            if s.lower().startswith('species') or ',' in s or '\\t' in s:\n",
        "                continue\n",
        "            lines.append(s)\n",
        "    return lines\n",
        "\n",
        "def parse_rec_id2filename(path: Path):\n",
        "    df = pd.read_csv(path)\n",
        "    df = df.rename(columns={df.columns[0]:'rec_id', df.columns[1]:'filename'})\n",
        "    df['rec_id'] = df['rec_id'].astype(int)\n",
        "    df['station'] = df['filename'].str.extract(r'^(PC\\d+)')\n",
        "    return df[['rec_id','filename','station']]\n",
        "\n",
        "def parse_labels(path: Path, C: int, species_codes):\n",
        "    rec_ids, flags, Y = [], [], []\n",
        "    with open(path, 'r') as f:\n",
        "        _ = f.readline()\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line: continue\n",
        "            parts = [tok.strip() for tok in line.split(',')]\n",
        "            try: rid = int(parts[0])\n",
        "            except: continue\n",
        "            tokens = parts[1:] if len(parts)>1 else []\n",
        "            is_test = any(tok=='?' for tok in tokens)\n",
        "            y = np.zeros(C, dtype=np.uint8)\n",
        "            if not is_test:\n",
        "                for tok in tokens:\n",
        "                    if tok in ('','?'): continue\n",
        "                    try: idx = int(tok)\n",
        "                    except: continue\n",
        "                    if 0 <= idx < C: y[idx] = 1\n",
        "            rec_ids.append(rid); flags.append(is_test); Y.append(y)\n",
        "    lab_df = pd.DataFrame(np.vstack(Y), columns=[f'label_{s}' for s in species_codes])\n",
        "    base = pd.DataFrame({'rec_id': rec_ids, 'is_test': flags})\n",
        "    return pd.concat([base, lab_df], axis=1)\n",
        "\n",
        "def _safe_int(tok):\n",
        "    try: return int(tok)\n",
        "    except: return None\n",
        "\n",
        "def _parse_numeric_list(tokens):\n",
        "    vals = []\n",
        "    for t in tokens:\n",
        "        try: vals.append(float(t))\n",
        "        except:\n",
        "            t2 = re.sub(r'[^0-9eE+\\-\\.]', '', t)\n",
        "            if t2 != '':\n",
        "                try: vals.append(float(t2))\n",
        "                except: pass\n",
        "    return vals\n",
        "\n",
        "def load_histograms(path: Path):\n",
        "    rows = []\n",
        "    with open(path, 'r') as f:\n",
        "        first = f.readline()\n",
        "        delim = ',' if ',' in first else None\n",
        "        parts = [p for p in (first.strip().split(',') if delim==',' else first.strip().split()) if p!='']\n",
        "        rid = _safe_int(parts[0]) if parts else None\n",
        "        if rid is not None:\n",
        "            rows.append((rid, _parse_numeric_list(parts[1:])))\n",
        "        for line in f:\n",
        "            p = [pp for pp in (line.strip().split(',') if delim==',' else line.strip().split()) if pp!='']\n",
        "            if not p: continue\n",
        "            rid = _safe_int(p[0])\n",
        "            if rid is None: continue\n",
        "            rows.append((rid, _parse_numeric_list(p[1:])))\n",
        "    if not rows:\n",
        "        return pd.DataFrame({'rec_id': []}), []\n",
        "    maxK = max(len(r[1]) for r in rows)\n",
        "    rec_ids, data = [], []\n",
        "    for rid, vals in rows:\n",
        "        if len(vals) < maxK: vals = vals + [0.0]*(maxK-len(vals))\n",
        "        elif len(vals) > maxK: vals = vals[:maxK]\n",
        "        rec_ids.append(rid); data.append(vals)\n",
        "    H = np.asarray(data, dtype=float)\n",
        "    hist_cols = [f'hist_{i:03d}' for i in range(H.shape[1])]\n",
        "    df = pd.DataFrame(H, columns=hist_cols)\n",
        "    df.insert(0, 'rec_id', rec_ids)\n",
        "    return df, hist_cols\n",
        "\n",
        "def load_segment_features(path: Path):\n",
        "    rows = []\n",
        "    with open(path, 'r') as f:\n",
        "        first = f.readline()\n",
        "        delim = ',' if ',' in first else None\n",
        "        parts = [p for p in (first.strip().split(',') if delim==',' else first.strip().split()) if p!='']\n",
        "        rid = _safe_int(parts[0]) if parts else None\n",
        "        if rid is not None:\n",
        "            rows.append((rid, _parse_numeric_list(parts[1:])))\n",
        "        for line in f:\n",
        "            p = [pp for pp in (line.strip().split(',') if delim==',' else line.strip().split()) if pp!='']\n",
        "            if not p: continue\n",
        "            rid = _safe_int(p[0])\n",
        "            if rid is None: continue\n",
        "            rows.append((rid, _parse_numeric_list(p[1:])))\n",
        "    if not rows: return pd.DataFrame({'rec_id': []}), []\n",
        "    maxM = max(len(r[1]) for r in rows)\n",
        "    rec_ids = [r[0] for r in rows]\n",
        "    X = []\n",
        "    for _, vals in rows:\n",
        "        if len(vals) < maxM: vals = vals + [0.0]*(maxM-len(vals))\n",
        "        elif len(vals) > maxM: vals = vals[:maxM]\n",
        "        X.append(vals)\n",
        "    X = np.asarray(X, dtype=float)\n",
        "    seg_cols = [f'seg_{j:03d}' for j in range(X.shape[1])]\n",
        "    seg_df = pd.DataFrame(X, columns=seg_cols)\n",
        "    seg_df.insert(0, 'rec_id', rec_ids)\n",
        "    return seg_df, seg_cols\n",
        "\n",
        "def aggregate_segments(seg_df: pd.DataFrame, seg_cols):\n",
        "    # per rec_id aggregations; include skew to match 588 feature target\n",
        "    g = seg_df.groupby('rec_id')\n",
        "    aggs = g[seg_cols].agg(['mean','std','min','max','median','skew'])\n",
        "    aggs.columns = [f\"{c}_{stat}\" for c, stat in aggs.columns]\n",
        "    aggs = aggs.reset_index()\n",
        "    cnt = g.size().rename('n_seg').reset_index()\n",
        "    out = aggs.merge(cnt, on='rec_id', how='left')\n",
        "    out['n_seg_log1p'] = np.log1p(out['n_seg'])\n",
        "    return out\n",
        "\n",
        "def build_hist_features(hist_df: pd.DataFrame, hist_cols):\n",
        "    H = hist_df[hist_cols].values.astype(float)\n",
        "    n_bins = H.shape[1]\n",
        "    raw = pd.DataFrame(H, columns=[f'h_raw_{i:03d}' for i in range(n_bins)])\n",
        "    log1p = pd.DataFrame(np.log1p(H), columns=[f'h_log1p_{i:03d}' for i in range(n_bins)])\n",
        "    sums = H.sum(axis=1, keepdims=True) + 1e-9\n",
        "    prop = H / sums\n",
        "    prop_df = pd.DataFrame(prop, columns=[f'h_prop_{i:03d}' for i in range(n_bins)])\n",
        "    ent = -(prop * (np.log(prop + 1e-12))).sum(axis=1)\n",
        "    b0, b1, b2, b3 = 0, n_bins//3, 2*n_bins//3, n_bins\n",
        "    def band_stats(M, prefix):\n",
        "        low, mid, high = M[:, b0:b1], M[:, b1:b2], M[:, b2:b3]\n",
        "        d = {}\n",
        "        for name, part in zip(['low','mid','high'], [low,mid,high]):\n",
        "            d[f'{prefix}{name}_sum'] = part.sum(axis=1)\n",
        "            d[f'{prefix}{name}_mean'] = part.mean(axis=1)\n",
        "        d[f'{prefix}low_mid_ratio'] = d[f'{prefix}low_sum']/np.clip(d[f'{prefix}mid_sum'],1e-8,None)\n",
        "        d[f'{prefix}low_high_ratio'] = d[f'{prefix}low_sum']/np.clip(d[f'{prefix}high_sum'],1e-8,None)\n",
        "        d[f'{prefix}mid_high_ratio'] = d[f'{prefix}mid_sum']/np.clip(d[f'{prefix}high_sum'],1e-8,None)\n",
        "        return d\n",
        "    band_raw = band_stats(H, 'band_raw_')\n",
        "    band_log = band_stats(np.log1p(H), 'band_log1p_')\n",
        "    band_prop = band_stats(prop, 'band_prop_')\n",
        "    HHI = (prop**2).sum(axis=1); gini_imp = 1.0 - HHI; renyi2 = -np.log(HHI + 1e-12)\n",
        "    max_bin_prop = prop.max(axis=1)\n",
        "    part = np.partition(prop, -2, axis=1)[:, -2:]; top2_sum_prop = part.sum(axis=1)\n",
        "    idx = np.arange(n_bins).astype(float); idx_z = (idx - idx.mean())/(idx.std()+1e-9)\n",
        "    centroid = (prop * idx).sum(axis=1)\n",
        "    spread = (prop * (idx - centroid[:, None])**2).sum(axis=1)\n",
        "    slope = (prop * idx_z).sum(axis=1) / (idx_z.var() + 1e-9)\n",
        "    def row_moments(M):\n",
        "        mu = M.mean(axis=1, keepdims=True); sd = M.std(axis=1, keepdims=True) + 1e-9\n",
        "        z = (M - mu)/sd\n",
        "        return (z**3).mean(axis=1), (z**4).mean(axis=1)\n",
        "    skew_raw, kurt_raw = row_moments(H); skew_prop, kurt_prop = row_moments(prop)\n",
        "    L = np.log1p(prop); L_mean = L.mean(axis=1); L_std = L.std(axis=1); L_ent = -(L*np.log(L+1e-12)).sum(axis=1)\n",
        "    p10 = np.percentile(H, 10, axis=1); p25 = np.percentile(H, 25, axis=1); p75 = np.percentile(H, 75, axis=1); p90 = np.percentile(H, 90, axis=1)\n",
        "    summa = H.sum(axis=1)\n",
        "    extras = pd.DataFrame({\n",
        "        'hist_entropy': ent, 'hist_sum': summa, 'hist_p10': p10, 'hist_p25': p25, 'hist_p75': p75, 'hist_p90': p90,\n",
        "        'prop_HHI': HHI, 'prop_gini_impurity': gini_impurity if (gini_impurity:=gini_imp) is not None else gini_imp, 'prop_renyi2': renyi2, 'prop_max_bin': max_bin_prop, 'prop_top2_sum': top2_sum_prop,\n",
        "        'spec_centroid': centroid, 'spec_spread': spread, 'spec_slope': slope,\n",
        "        'raw_skew': skew_raw, 'raw_kurt': kurt_raw, 'prop_skew': skew_prop, 'prop_kurt': kurt_prop,\n",
        "        'log1pprop_mean': L_mean, 'log1pprop_std': L_std, 'log1pprop_entropy': L_ent,\n",
        "    })\n",
        "    for d in (band_raw, band_log, band_prop):\n",
        "        for k, v in d.items(): extras[k] = v\n",
        "    out = pd.concat([hist_df[['rec_id']], raw, log1p, prop_df, extras], axis=1)\n",
        "    return out\n",
        "\n",
        "def assemble_dataset():\n",
        "    species = load_species_list(DATA_DIR/'species_list.txt')\n",
        "    assert len(species) == 19, f'Expected 19 species, got {len(species)}'\n",
        "    rec_map = parse_rec_id2filename(DATA_DIR/'rec_id2filename.txt')\n",
        "    labels = parse_labels(DATA_DIR/'rec_labels_test_hidden.txt', len(species), species)\n",
        "    hist_df_raw, hist_cols = load_histograms(SUPP_DIR/'histogram_of_segments.txt')\n",
        "    seg_df_raw, seg_cols = load_segment_features(SUPP_DIR/'segment_features.txt')\n",
        "    hist_feats = build_hist_features(hist_df_raw, hist_cols)\n",
        "    seg_agg = aggregate_segments(seg_df_raw, seg_cols) if len(seg_cols) else pd.DataFrame({'rec_id': rec_map['rec_id']})\n",
        "    df = rec_map.merge(labels, on='rec_id', how='right')\n",
        "    df = df.merge(hist_feats, on='rec_id', how='left')\n",
        "    df = df.merge(seg_agg, on='rec_id', how='left')\n",
        "    # derive simple time features\n",
        "    dt_str = df['filename'].str.split('_').str[1]\n",
        "    ts = pd.to_datetime(dt_str, format='%Y%m%d', errors='coerce')\n",
        "    df['month'] = ts.dt.month.fillna(0).astype(int)\n",
        "    df['day_of_year'] = ts.dt.dayofyear.fillna(0).astype(int)\n",
        "    df['doy_sin'] = np.sin(2*np.pi*df['day_of_year']/366.0)\n",
        "    df['doy_cos'] = np.cos(2*np.pi*df['day_of_year']/366.0)\n",
        "    label_cols = [c for c in df.columns if c.startswith('label_')]\n",
        "    feature_exclude = ['rec_id','filename','station','is_test'] + label_cols\n",
        "    feature_cols = [c for c in df.columns if c not in feature_exclude]\n",
        "    train_df = df[~df['is_test']].copy()\n",
        "    test_df = df[df['is_test']].copy()\n",
        "    X_train = train_df[feature_cols].fillna(0)\n",
        "    y_train = train_df[label_cols].copy()\n",
        "    X_test = test_df[feature_cols].fillna(0)\n",
        "    groups = train_df['station'].values\n",
        "    meta_train = train_df[['rec_id','filename','station']].copy()\n",
        "    meta_test = test_df[['rec_id','filename','station']].copy()\n",
        "    return species, X_train, y_train, X_test, groups, meta_train, meta_test, feature_cols, label_cols\n",
        "\n",
        "# Build dataset\n",
        "species, X_train, y_train, X_test, groups, meta_train, meta_test, feature_cols, label_cols = assemble_dataset()\n",
        "log(f'Train={len(X_train)} Test={len(X_test)} Features={len(feature_cols)} Labels={len(label_cols)} Stations={len(pd.unique(groups))}')\n",
        "assert len(feature_cols) == 588, f'Expected 588 features, got {len(feature_cols)}'\n",
        "assert y_train.shape[1] == 19, f'y_train columns != 19'\n",
        "assert len(X_test) == len(meta_test) and len(X_train) == len(meta_train)\n",
        "log('Sample features: ' + ', '.join(feature_cols[:5]) + ' ...')\n",
        "log('Stations: ' + ', '.join(sorted(pd.unique(groups))))\n",
        "pos = y_train.values.sum(axis=0); log('Positives per class (first 10): ' + ', '.join(map(str, pos[:10].tolist())))\n",
        "logo = LeaveOneGroupOut()\n",
        "splits = [(tr, va) for tr, va in logo.split(np.arange(len(groups)), groups=groups)]\n",
        "log(f'Built LOSO splits: {len(splits)} folds')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:37:09 Train=258 Test=64 Features=588 Labels=19 Stations=13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:37:09 Sample features: h_raw_000, h_raw_001, h_raw_002, h_raw_003, h_raw_004 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:37:09 Stations: PC1, PC10, PC11, PC13, PC15, PC16, PC17, PC18, PC2, PC4, PC5, PC7, PC8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:37:09 Positives per class (first 10): 7, 28, 19, 4, 9, 5, 19, 19, 24, 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:37:09 Built LOSO splits: 13 folds\n"
          ]
        }
      ]
    },
    {
      "id": "8fde08b1-5d50-4f12-aa56-2f63aa116445",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# LOSO CV training: 4 models (CatBoost x2, LightGBM, ExtraTrees), 1-vs-rest, pooled OOF macro AUC; generate two submissions\n",
        "import numpy as np, pandas as pd, time, sys, gc, warnings, subprocess, importlib, os\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Ensure lightgbm and catboost are available\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "except Exception:\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'lightgbm==4.3.0'], check=True)\n",
        "    import lightgbm as lgb\n",
        "try:\n",
        "    from catboost import CatBoostClassifier\n",
        "except Exception:\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'catboost==1.2.5'], check=True)\n",
        "    from catboost import CatBoostClassifier\n",
        "\n",
        "def log(msg):\n",
        "    print(time.strftime('%H:%M:%S'), msg, flush=True)\n",
        "\n",
        "def macro_auc_pooled(P: np.ndarray, Y: np.ndarray) -> float:\n",
        "    C = Y.shape[1]; aucs = []\n",
        "    for c in range(C):\n",
        "        yt = Y[:, c]; yp = P[:, c]\n",
        "        if yt.sum() == 0 or yt.sum() == len(yt):\n",
        "            continue\n",
        "        try:\n",
        "            aucs.append(roc_auc_score(yt, yp))\n",
        "        except Exception:\n",
        "            pass\n",
        "    return float(np.mean(aucs)) if aucs else np.nan\n",
        "\n",
        "# Configs (use exactly as advised; note: CatBoost Bayesian bootstrap ignores 'subsample')\n",
        "cb1_params = dict(loss_function='Logloss', eval_metric='AUC', iterations=3000, learning_rate=0.03, depth=4, l2_leaf_reg=80, subsample=0.7, colsample_bylevel=0.6, random_strength=0.2, bagging_temperature=0.5, bootstrap_type='Bayesian', early_stopping_rounds=300, verbose=False, random_seed=42)\n",
        "cb2_params = dict(loss_function='Logloss', eval_metric='AUC', iterations=3000, learning_rate=0.025, depth=5, l2_leaf_reg=100, subsample=0.8, colsample_bylevel=0.5, random_strength=0.2, bagging_temperature=0.8, bootstrap_type='Bayesian', early_stopping_rounds=300, verbose=False, random_seed=2025)\n",
        "lgb_params = dict(objective='binary', metric='auc', n_estimators=3000, learning_rate=0.02, num_leaves=16, max_depth=5, min_child_samples=20, subsample=0.7, colsample_bytree=0.6, reg_alpha=0.1, reg_lambda=20, is_unbalance=True, n_jobs=-1, random_state=42, boosting_type='gbdt')\n",
        "et_params = dict(n_estimators=1000, max_features=0.4, min_samples_leaf=5, min_samples_split=5, bootstrap=False, class_weight='balanced', n_jobs=-1, random_state=42)\n",
        "\n",
        "def sanitize_cb(params: dict) -> dict:\n",
        "    p = params.copy()\n",
        "    # CatBoost with bootstrap_type='Bayesian' does not support 'subsample'; drop it\n",
        "    if str(p.get('bootstrap_type', '')).lower() == 'bayesian' and 'subsample' in p:\n",
        "        p.pop('subsample', None)\n",
        "    p['allow_writing_files'] = False\n",
        "    return p\n",
        "\n",
        "models_cfg = [\n",
        "    {'name': 'CatBoost#1', 'type': 'catboost', 'params': cb1_params},\n",
        "    {'name': 'CatBoost#2', 'type': 'catboost', 'params': cb2_params},\n",
        "    {'name': 'LightGBM',   'type': 'lightgbm', 'params': lgb_params},\n",
        "    {'name': 'ExtraTrees', 'type': 'extratrees','params': et_params},\n",
        "]\n",
        "\n",
        "# Build LOSO splits\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "logo = LeaveOneGroupOut()\n",
        "idx_all = np.arange(len(groups))\n",
        "splits = list(logo.split(idx_all, groups=groups))\n",
        "log(f'LOSO folds: {len(splits)}')\n",
        "\n",
        "# Global prevalence from FULL training set (used for missing-class folds)\n",
        "Y_full = y_train.values.astype(np.uint8)\n",
        "p_global_full = Y_full.mean(axis=0)\n",
        "\n",
        "oof_by_model = []\n",
        "test_by_model = []\n",
        "scores = []\n",
        "\n",
        "for mi, cfg in enumerate(models_cfg):\n",
        "    name = cfg['name']; mtype = cfg['type']; params = cfg['params']\n",
        "    N, C = len(X_train), y_train.shape[1]\n",
        "    P_oof = np.zeros((N, C), dtype=np.float32)\n",
        "    fold_t0 = time.time()\n",
        "    for fold, (tr, va) in enumerate(splits):\n",
        "        t_fold = time.time()\n",
        "        Xtr = X_train.iloc[tr]; Xva = X_train.iloc[va]\n",
        "        Ytr = y_train.iloc[tr].values.astype(np.uint8)\n",
        "        # Per-class training\n",
        "        for c in range(C):\n",
        "            ytr_c = Ytr[:, c]\n",
        "            # Missing-class in TRAIN split -> fill VAL with global prevalence; skip fit\n",
        "            if ytr_c.min() == ytr_c.max():\n",
        "                P_oof[va, c] = p_global_full[c]\n",
        "                continue\n",
        "            if mtype == 'catboost':\n",
        "                params_cb = sanitize_cb(params)\n",
        "                model = CatBoostClassifier(**params_cb)\n",
        "                # Early stopping on held-out station\n",
        "                model.fit(Xtr, ytr_c, eval_set=(Xva, y_train.iloc[va, c].values.astype(np.uint8)))\n",
        "                P_oof[va, c] = model.predict_proba(Xva)[:, 1]\n",
        "                del model\n",
        "            elif mtype == 'lightgbm':\n",
        "                model = lgb.LGBMClassifier(**params)\n",
        "                model.fit(Xtr.values, ytr_c, eval_set=[(Xva.values, y_train.iloc[va, c].values.astype(np.uint8))], eval_metric='auc', callbacks=[lgb.early_stopping(stopping_rounds=300, verbose=False)])\n",
        "                P_oof[va, c] = model.predict_proba(Xva.values)[:, 1]\n",
        "                del model\n",
        "            elif mtype == 'extratrees':\n",
        "                model = ExtraTreesClassifier(**params)\n",
        "                model.fit(Xtr.values, ytr_c)\n",
        "                P_oof[va, c] = model.predict_proba(Xva.values)[:, 1]\n",
        "                del model\n",
        "        if (fold+1) % 1 == 0:\n",
        "            log(f'[{name}] fold {fold+1:02d}/{len(splits)} done in {time.time()-t_fold:.1f}s')\n",
        "        gc.collect()\n",
        "    auc = macro_auc_pooled(P_oof, y_train.values.astype(np.uint8))\n",
        "    oof_by_model.append(P_oof)\n",
        "    scores.append((name, auc))\n",
        "    log(f'[{name}] pooled OOF macro AUC: {auc:.4f} | dt={time.time()-fold_t0:.1f}s')\n",
        "    gc.collect()\n",
        "\n",
        "# Equal-weight OOF blend\n",
        "P_oof_stack = np.stack(oof_by_model, axis=0)\n",
        "P_oof_mean = P_oof_stack.mean(axis=0)\n",
        "auc_blend = macro_auc_pooled(P_oof_mean, y_train.values.astype(np.uint8))\n",
        "log('Equal-weight 4-model blend pooled OOF macro AUC: %.4f' % auc_blend)\n",
        "\n",
        "# Select best single model\n",
        "best_idx = int(np.argmax([s[1] for s in scores]))\n",
        "best_name, best_auc = scores[best_idx]\n",
        "log(f'Best single model: {best_name} | AUC={best_auc:.4f}')\n",
        "\n",
        "# Full-train models and generate two submissions\n",
        "def train_full_and_predict(cfg):\n",
        "    name = cfg['name']; mtype = cfg['type']; params = cfg['params']\n",
        "    C = y_train.shape[1]\n",
        "    P_test = np.zeros((len(X_test), C), dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        y_c = y_train.iloc[:, c].values.astype(np.uint8)\n",
        "        if y_c.min() == y_c.max():\n",
        "            P_test[:, c] = p_global_full[c]\n",
        "            continue\n",
        "        if mtype == 'catboost':\n",
        "            params_cb = sanitize_cb(params)\n",
        "            model = CatBoostClassifier(**params_cb)\n",
        "            model.fit(X_train, y_c)\n",
        "            P_test[:, c] = model.predict_proba(X_test)[:, 1]\n",
        "            del model\n",
        "        elif mtype == 'lightgbm':\n",
        "            model = lgb.LGBMClassifier(**params)\n",
        "            model.fit(X_train.values, y_c)\n",
        "            P_test[:, c] = model.predict_proba(X_test.values)[:, 1]\n",
        "            del model\n",
        "        elif mtype == 'extratrees':\n",
        "            model = ExtraTreesClassifier(**params)\n",
        "            model.fit(X_train.values, y_c)\n",
        "            P_test[:, c] = model.predict_proba(X_test.values)[:, 1]\n",
        "            del model\n",
        "    gc.collect()\n",
        "    return P_test\n",
        "\n",
        "log('Full-train: generating test predictions for all four models...')\n",
        "test_preds_all = []\n",
        "for cfg in models_cfg:\n",
        "    log(f'Full-train {cfg[\"name\"]} ...')\n",
        "    test_preds_all.append(train_full_and_predict(cfg))\n",
        "\n",
        "# Best single submission\n",
        "best_test = test_preds_all[best_idx]\n",
        "rows_single = []\n",
        "test_rec_ids = meta_test['rec_id'].values.tolist()\n",
        "C = y_train.shape[1]\n",
        "for i, rid in enumerate(test_rec_ids):\n",
        "    for c in range(C):\n",
        "        rows_single.append((rid*100 + c, float(best_test[i, c])))\n",
        "sub_single = pd.DataFrame(rows_single, columns=['Id','Probability']).sort_values('Id').reset_index(drop=True)\n",
        "sub_single.to_csv('submission_rebuild_single.csv', index=False)\n",
        "\n",
        "# Equal-weight blend submission\n",
        "blend_test = np.mean(np.stack(test_preds_all, axis=0), axis=0)\n",
        "rows_blend = []\n",
        "for i, rid in enumerate(test_rec_ids):\n",
        "    for c in range(C):\n",
        "        rows_blend.append((rid*100 + c, float(blend_test[i, c])))\n",
        "sub_blend = pd.DataFrame(rows_blend, columns=['Id','Probability']).sort_values('Id').reset_index(drop=True)\n",
        "sub_blend.to_csv('submission_rebuild_blend.csv', index=False)\n",
        "\n",
        "log('Saved submission_rebuild_single.csv and submission_rebuild_blend.csv')\n",
        "print('Model OOF scores:')\n",
        "for n, s in scores:\n",
        "    print(f'  {n}: {s:.4f}')\n",
        "print('Blend OOF macro AUC:', f'{auc_blend:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22:39:50 LOSO folds: 13\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}