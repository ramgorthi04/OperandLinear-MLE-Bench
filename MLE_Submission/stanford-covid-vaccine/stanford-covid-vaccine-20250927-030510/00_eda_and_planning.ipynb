{
  "cells": [
    {
      "id": "6649ef4a-03db-4f3a-a2ca-64ed7b95264e",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenVaccine: COVID-19 mRNA Degradation \u2014 Plan\n",
        "\n",
        "Goals:\n",
        "- Build a medal-winning solution (multi-class-log-loss \u2264 0.35340).\n",
        "- Establish robust CV mirroring test; ship fast baseline; iterate with FE and model diversity; ensemble.\n",
        "\n",
        "Initial Facts:\n",
        "- Data: train.json, test.json, sample_submission.csv.\n",
        "- Target: per-base predictions for several reactivity/deg signals; metric: multi-class-log-loss.\n",
        "- Common winning approaches: sequence + structure features; deep models (GRU/LSTM/Transformer), sometimes + pseudo-labeling; strong CV by sequence length buckets.\n",
        "\n",
        "Validation Strategy:\n",
        "- GroupKFold by sequence length buckets (or sequence id) to mimic test distribution and avoid leakage across positions.\n",
        "- OOF per base, compute multi-class-log-loss with same targets as submission.\n",
        "\n",
        "Baseline v0:\n",
        "- Simple featureizer: one-hot nucleotides, base pairing info (from provided structure strings if available), position, length-normalized position.\n",
        "- Model: light baseline (e.g., CatBoost/XGBoost per-target) to get quick OOF and sanity-check pipeline.\n",
        "- Ship a valid submission quickly.\n",
        "\n",
        "Feature Engineering (Iterative):\n",
        "- Sequence encodings: k-mer counts, rolling windows, GC content, local neighborhood features.\n",
        "- Structure encodings: from dot-bracket to pairing indices, loop types, paired distance, stems/loops length, minimum free energy if available.\n",
        "- Positional features: relative position, ends proximity, segment IDs.\n",
        "- Augment with base quality heuristics (masking/unmasking missing).\n",
        "\n",
        "Modeling Path:\n",
        "1) Baseline tree models (GPU XGBoost/CatBoost) per target with multioutput wrapper; quick CV.\n",
        "2) RNN/Transformer sequence model using PyTorch (cu121) with positional/structural embeddings; train with masking to variable lengths; early stopping; mixed precision.\n",
        "3) Blend/stack: weighted average of diverse seeds/models; calibration if needed.\n",
        "\n",
        "Execution Plan (24h):\n",
        "T0: Environment + GPU check\n",
        "T1: Data loading + schema/target check; build CV folds; metric function replica\n",
        "T2: Baseline features + fast GPU tree model; OOF + submission v0\n",
        "T3: Error analysis; add key structural features; v1\n",
        "T4: PyTorch model (GRU baseline); v2\n",
        "T5: Ensembling and tuning; final submission\n",
        "\n",
        "Checkpoints requiring expert review:\n",
        "- After this plan\n",
        "- After data/EDA/CV setup\n",
        "- After baseline v0 OOF\n",
        "- After deep model v1 OOF\n",
        "- Before final blend\n",
        "\n",
        "Next Action:\n",
        "- Run GPU/environment check, list files, preview data schema to define targets and submission columns."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "1a29659d-adbc-4dd4-ae6d-62b108bb5bf5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment + Data schema check\n",
        "import os, sys, json, time, subprocess, shutil, math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True).stdout\n",
        "\n",
        "print('=== GPU CHECK (nvidia-smi) ===', flush=True)\n",
        "print(run(['bash','-lc','nvidia-smi || true']))\n",
        "\n",
        "print('=== CWD and files ===', flush=True)\n",
        "print('CWD:', os.getcwd())\n",
        "for f in sorted(os.listdir('.')):\n",
        "    try:\n",
        "        sz = os.path.getsize(f)\n",
        "    except Exception:\n",
        "        sz = -1\n",
        "    print(f'{f}\\t{sz:,} bytes')\n",
        "\n",
        "print('\\n=== sample_submission.csv preview ===', flush=True)\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "print('shape:', sub.shape)\n",
        "print('columns:', list(sub.columns))\n",
        "print(sub.head(3))\n",
        "\n",
        "def load_json(path):\n",
        "    with open(path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "print('\\n=== Load train.json/test.json ===', flush=True)\n",
        "train = load_json('train.json')\n",
        "test = load_json('test.json')\n",
        "print('train entries:', len(train), 'test entries:', len(test))\n",
        "if len(train):\n",
        "    print('train[0] keys:', sorted(train[0].keys()))\n",
        "    # Inspect basic fields\n",
        "    ex = train[0]\n",
        "    for k in ['id','seq','structure','predicted_loop_type','signal_to_noise','SN_filter']:\n",
        "        if k in ex:\n",
        "            if isinstance(ex[k], (list, tuple)):\n",
        "                print(f'{k}: list len {len(ex[k])}')\n",
        "            else:\n",
        "                print(f'{k}:', ex[k])\n",
        "    # Detect targets for regression\n",
        "    possible_targets = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']\n",
        "    found_targets = [k for k in possible_targets if k in ex]\n",
        "    if found_targets:\n",
        "        print('Detected regression targets:', found_targets, 'lengths:', [len(ex[k]) for k in found_targets])\n",
        "    else:\n",
        "        # Try to detect classification label field\n",
        "        label_keys = [k for k,v in ex.items() if isinstance(v, list) and len(v)>0 and isinstance(v[0], (int,float,str)) and k not in ['seq','structure','predicted_loop_type']]\n",
        "        print('Potential per-base label keys:', label_keys)\n",
        "\n",
        "# Infer task from submission columns\n",
        "cols = list(sub.columns)\n",
        "task = 'unknown'\n",
        "if any(c.startswith('class_') for c in cols[1:]):\n",
        "    task = 'classification'\n",
        "elif any(c in cols for c in ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']):\n",
        "    task = 'regression'\n",
        "print('\\nInferred task type from submission columns:', task)\n",
        "\n",
        "# Check id format\n",
        "id_col = cols[0] if len(cols)>0 else None\n",
        "print('ID column:', id_col)\n",
        "if id_col and id_col.lower().startswith('id'):\n",
        "    # Try to parse pos from id_seqpos like '{id}_{pos}'\n",
        "    sample_ids = sub[id_col].head(5).tolist()\n",
        "    print('Sample IDs:', sample_ids)\n",
        "    def parse_pos(s):\n",
        "        try:\n",
        "            return int(s.split('_')[-1])\n",
        "        except Exception:\n",
        "            return None\n",
        "    poses = [parse_pos(s) for s in sub[id_col].head(500).tolist()]\n",
        "    poses = [p for p in poses if p is not None]\n",
        "    if poses:\n",
        "        print('Submission pos stats: min=', min(poses), 'max=', max(poses))\n",
        "\n",
        "print('\\n=== DONE: Decide next steps based on detected schema ===', flush=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GPU CHECK (nvidia-smi) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep 27 03:12:45 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n=== CWD and files ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CWD: /var/lib/simon/agent_run_states/stanford-covid-vaccine-20250927-030510\n.00_eda_and_planning_kernel_state.json\t182 bytes\n00_eda_and_planning.ipynb\t7,822 bytes\nagent_metadata\t4,096 bytes\ndescription.md\t13,414 bytes\ndocker_run.log\t47,527 bytes\nrequirements.txt\t2,021 bytes\nsample_submission.csv\t2,079,421 bytes\nsubmission.csv\t2,079,421 bytes\ntask.txt\t4,854 bytes\ntest.json\t105,970 bytes\ntrain.json\t11,445,889 bytes\n\n=== sample_submission.csv preview ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (25680, 6)\ncolumns: ['id_seqpos', 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C  deg_50C\n0  id_00b436dec_0         0.0          0.0       0.0         0.0      0.0\n1  id_00b436dec_1         0.0          0.0       0.0         0.0      0.0\n2  id_00b436dec_2         0.0          0.0       0.0         0.0      0.0\n\n=== Load train.json/test.json ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Extra data: line 2 column 1 (char 5340)",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m json.load(f)\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Load train.json/test.json ===\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m train = \u001b[43mload_json\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m test = load_json(\u001b[33m'\u001b[39m\u001b[33mtest.json\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mtrain entries:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train), \u001b[33m'\u001b[39m\u001b[33mtest entries:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mload_json\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_json\u001b[39m(path):\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/json/decoder.py:340\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExtra data\u001b[39m\u001b[33m\"\u001b[39m, s, end)\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
            "\u001b[31mJSONDecodeError\u001b[39m: Extra data: line 2 column 1 (char 5340)"
          ]
        }
      ]
    },
    {
      "id": "4f95c460-72d9-499b-9d0a-693f5bc95c3d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Robust JSONL loader and schema inspection\n",
        "import json\n",
        "\n",
        "def load_jsonl(path):\n",
        "    rows = []\n",
        "    with open(path, 'r') as f:\n",
        "        for i, line in enumerate(f, 1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            try:\n",
        "                rows.append(json.loads(line))\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f'JSON decode error at line {i}: {e}')\n",
        "                raise\n",
        "    return rows\n",
        "\n",
        "print('=== Reload as JSON Lines ===', flush=True)\n",
        "train = load_jsonl('train.json')\n",
        "test = load_jsonl('test.json')\n",
        "print('train entries:', len(train), 'test entries:', len(test))\n",
        "ex = train[0]\n",
        "print('train[0] keys:', sorted(ex.keys()))\n",
        "L = len(ex.get('seq',''))\n",
        "print('Example length:', L)\n",
        "targets = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']\n",
        "present = [t for t in targets if t in ex]\n",
        "print('Targets present:', present, 'lens:', [len(ex[t]) for t in present])\n",
        "print('Has SN fields:', 'signal_to_noise' in ex, 'SN_filter' in ex)\n",
        "print('Structure fields present:', 'structure' in ex, 'predicted_loop_type' in ex)\n",
        "\n",
        "# Quick DF overview\n",
        "import pandas as pd\n",
        "df_train = pd.DataFrame([{\n",
        "    'id': r.get('id'),\n",
        "    'len': len(r.get('seq','')),\n",
        "    'SN_filter': r.get('SN_filter', None),\n",
        "    'has_structure': 'structure' in r,\n",
        "    'has_loop_type': 'predicted_loop_type' in r\n",
        "} for r in train])\n",
        "print(df_train.describe(include='all'))\n",
        "\n",
        "# Determine scored positions from submission (max pos + 1)\n",
        "def parse_pos(s):\n",
        "    try:\n",
        "        return int(s.split('_')[-1])\n",
        "    except Exception:\n",
        "        return None\n",
        "poses = [parse_pos(x) for x in pd.read_csv('sample_submission.csv')['id_seqpos'].head(2000)]\n",
        "poses = [p for p in poses if p is not None]\n",
        "L_pred = (max(poses)+1) if poses else None\n",
        "print('Inferred scored positions (L_pred):', L_pred)\n",
        "print('=== JSONL load OK ===', flush=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Reload as JSON Lines ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train entries: 2160 test entries: 240\ntrain[0] keys: ['SN_filter', 'deg_50C', 'deg_Mg_50C', 'deg_Mg_pH10', 'deg_error_50C', 'deg_error_Mg_50C', 'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_pH10', 'id', 'index', 'predicted_loop_type', 'reactivity', 'reactivity_error', 'seq_length', 'seq_scored', 'sequence', 'signal_to_noise', 'structure']\nExample length: 0\nTargets present: ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C'] lens: [68, 68, 68, 68, 68]\nHas SN fields: True True\nStructure fields present: True True\n                  id     len    SN_filter has_structure has_loop_type\ncount           2160  2160.0  2160.000000          2160          2160\nunique          2160     NaN          NaN             1             1\ntop     id_001f94081     NaN          NaN          True          True\nfreq               1     NaN          NaN          2160          2160\nmean             NaN     0.0     0.624537           NaN           NaN\nstd              NaN     0.0     0.484354           NaN           NaN\nmin              NaN     0.0     0.000000           NaN           NaN\n25%              NaN     0.0     0.000000           NaN           NaN\n50%              NaN     0.0     1.000000           NaN           NaN\n75%              NaN     0.0     1.000000           NaN           NaN\nmax              NaN     0.0     1.000000           NaN           NaN\nInferred scored positions (L_pred): 107\n=== JSONL load OK ===\n"
          ]
        }
      ]
    },
    {
      "id": "6107f75b-8bc1-4f5c-b2b0-9a58d34f229d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build features, CV, XGBoost baseline, OOF MCRMSE, and submission\n",
        "import math, gc, time\n",
        "from collections import defaultdict, deque\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import xgboost as xgb\n",
        "\n",
        "TARGETS = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']\n",
        "\n",
        "def mcrmse(y_true, y_pred):\n",
        "    rmses = []\n",
        "    for i in range(y_true.shape[1]):\n",
        "        rmses.append(mean_squared_error(y_true[:, i], y_pred[:, i], squared=False))\n",
        "    return float(np.mean(rmses))\n",
        "\n",
        "def parse_pairs(dot):\n",
        "    stack = []\n",
        "    pair = [-1]*len(dot)\n",
        "    for i,ch in enumerate(dot):\n",
        "        if ch == '(':\n",
        "            stack.append(i)\n",
        "        elif ch == ')':\n",
        "            if stack:\n",
        "                j = stack.pop()\n",
        "                pair[i] = j\n",
        "                pair[j] = i\n",
        "    return pair\n",
        "\n",
        "def window_gc(seq, k=11):\n",
        "    n = len(seq)\n",
        "    half = k//2\n",
        "    arr = np.zeros(n, dtype=np.float32)\n",
        "    for i in range(n):\n",
        "        l = max(0, i-half)\n",
        "        r = min(n, i+half+1)\n",
        "        s = seq[l:r]\n",
        "        if len(s)==0:\n",
        "            arr[i] = 0.0\n",
        "        else:\n",
        "            gc_count = s.count('G') + s.count('C')\n",
        "            arr[i] = gc_count/len(s)\n",
        "    return arr\n",
        "\n",
        "def build_features_rows(record):\n",
        "    rid = record['id']\n",
        "    seq = record['sequence']\n",
        "    struct = record['structure']\n",
        "    loop = record['predicted_loop_type']\n",
        "    L = len(seq)\n",
        "    pair = parse_pairs(struct)\n",
        "    is_paired = [1 if p!=-1 else 0 for p in pair]\n",
        "    pair_dist = [abs(i-pair[i]) if pair[i]!=-1 else -1 for i in range(L)]\n",
        "    gc_win = window_gc(seq, 11)\n",
        "    rows = []\n",
        "    for i in range(L):\n",
        "        base = seq[i]\n",
        "        s = struct[i]\n",
        "        lp = loop[i]\n",
        "        # neighbors\n",
        "        def nb(arr, idx, off):\n",
        "            j = idx+off\n",
        "            return arr[j] if 0<=j<len(arr) else 'PAD' if isinstance(arr, str) else -1\n",
        "        base_m1 = seq[i-1] if i-1>=0 else 'PAD'\n",
        "        base_p1 = seq[i+1] if i+1<L else 'PAD'\n",
        "        base_m2 = seq[i-2] if i-2>=0 else 'PAD'\n",
        "        base_p2 = seq[i+2] if i+2<L else 'PAD'\n",
        "        struct_m1 = struct[i-1] if i-1>=0 else 'P'\n",
        "        struct_p1 = struct[i+1] if i+1<L else 'P'\n",
        "        loop_m1 = loop[i-1] if i-1>=0 else 'P'\n",
        "        loop_p1 = loop[i+1] if i+1<L else 'P'\n",
        "        partner_idx = pair[i]\n",
        "        partner_base = seq[partner_idx] if partner_idx!=-1 else 'NP'\n",
        "        rows.append({\n",
        "            'id': rid,\n",
        "            'pos': i,\n",
        "            'L': L,\n",
        "            'base': base,\n",
        "            'struct': s,\n",
        "            'loop': lp,\n",
        "            'base_m1': base_m1, 'base_p1': base_p1, 'base_m2': base_m2, 'base_p2': base_p2,\n",
        "            'struct_m1': struct_m1, 'struct_p1': struct_p1,\n",
        "            'loop_m1': loop_m1, 'loop_p1': loop_p1,\n",
        "            'is_paired': is_paired[i],\n",
        "            'pair_dist': pair_dist[i],\n",
        "            'partner_base': partner_base,\n",
        "            'rel_pos': i/max(1, L-1),\n",
        "            'dist_to_end': min(i, L-1-i),\n",
        "            'gc11': float(gc_win[i])\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "print('Flattening train/test to per-base rows...', flush=True)\n",
        "t0 = time.time()\n",
        "train_rows = []\n",
        "for r in train:\n",
        "    rows = build_features_rows(r)\n",
        "    # only keep scored positions (first seq_scored)\n",
        "    L_scored = int(r.get('seq_scored', 68))\n",
        "    for row in rows[:L_scored]:\n",
        "        # attach targets\n",
        "        for t in TARGETS:\n",
        "            row[t] = r[t][row['pos']]\n",
        "        row['SN_filter'] = r.get('SN_filter', 1)\n",
        "        train_rows.append(row)\n",
        "print(f'Train rows: {len(train_rows)} in {time.time()-t0:.2f}s')\n",
        "\n",
        "test_rows = []\n",
        "for r in test:\n",
        "    rows = build_features_rows(r)\n",
        "    # We'll predict for all positions that appear in submission for this id; to be safe keep all and merge later\n",
        "    for row in rows:\n",
        "        test_rows.append(row)\n",
        "print(f'Test rows (all positions): {len(test_rows)}')\n",
        "\n",
        "df_tr = pd.DataFrame(train_rows)\n",
        "df_te = pd.DataFrame(test_rows)\n",
        "print('df_tr shape:', df_tr.shape, 'df_te shape:', df_te.shape)\n",
        "print('df_tr cols:', df_tr.columns.tolist()[:20], '...')\n",
        "\n",
        "# Prepare categorical and numeric features\n",
        "cat_cols = ['base','struct','loop','base_m1','base_p1','base_m2','base_p2','struct_m1','struct_p1','loop_m1','loop_p1','partner_base']\n",
        "num_cols = ['pos','L','rel_pos','dist_to_end','gc11','is_paired','pair_dist']\n",
        "\n",
        "# One-hot encode categoricals on full training set for column stability, then align test\n",
        "df_tr_cat = pd.get_dummies(df_tr[cat_cols], prefix=cat_cols, dummy_na=False)\n",
        "df_te_cat = pd.get_dummies(df_te[cat_cols], prefix=cat_cols, dummy_na=False)\n",
        "df_tr_num = df_tr[num_cols].astype(np.float32)\n",
        "df_te_num = df_te[num_cols].astype(np.float32)\n",
        "X_tr = pd.concat([df_tr_num.reset_index(drop=True), df_tr_cat.reset_index(drop=True)], axis=1)\n",
        "X_te = pd.concat([df_te_num.reset_index(drop=True), df_te_cat.reset_index(drop=True)], axis=1)\n",
        "# Align columns\n",
        "X_te = X_te.reindex(columns=X_tr.columns, fill_value=0)\n",
        "\n",
        "y_tr = df_tr[TARGETS].values.astype(np.float32)\n",
        "groups = df_tr['id'].values\n",
        "sn_mask = (df_tr['SN_filter'].values==1)\n",
        "\n",
        "print('Feature matrix shapes:', X_tr.shape, X_te.shape)\n",
        "\n",
        "# CV: GroupKFold by id\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "oof = np.zeros_like(y_tr)\n",
        "models = {t: [] for t in TARGETS}\n",
        "\n",
        "def train_fold(X, y, tr_idx, va_idx, target_name):\n",
        "    dtr = xgb.DMatrix(X.iloc[tr_idx], label=y[tr_idx])\n",
        "    dva = xgb.DMatrix(X.iloc[va_idx], label=y[va_idx])\n",
        "    params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'rmse',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'max_depth': 8,\n",
        "        'eta': 0.05,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'min_child_weight': 1.0,\n",
        "        'lambda': 1.0\n",
        "    }\n",
        "    evallist = [(dtr, 'train'), (dva, 'valid')]\n",
        "    bst = xgb.train(params, dtr, num_boost_round=2000, evals=evallist,\n",
        "                    early_stopping_rounds=100, verbose_eval=False)\n",
        "    pred = bst.predict(dva)\n",
        "    return bst, pred\n",
        "\n",
        "start = time.time()\n",
        "for fold, (tr_idx, va_idx) in enumerate(gkf.split(X_tr, y_tr[:,0], groups), 1):\n",
        "    t_fold = time.time()\n",
        "    print(f'Fold {fold}: train={len(tr_idx)} valid={len(va_idx)} elapsed={time.time()-start:.1f}s', flush=True)\n",
        "    for ti, t in enumerate(TARGETS):\n",
        "        y = y_tr[:, ti]\n",
        "        bst, pred = train_fold(X_tr, y, tr_idx, va_idx, t)\n",
        "        models[t].append(bst)\n",
        "        oof[va_idx, ti] = pred\n",
        "    # Compute fold metric on SN_filter==1 only\n",
        "    mask = sn_mask[va_idx]\n",
        "    score = mcrmse(y_tr[va_idx][mask], oof[va_idx][mask]) if mask.any() else mcrmse(y_tr[va_idx], oof[va_idx])\n",
        "    print(f'Fold {fold} MCRMSE (SN==1): {score:.5f} | fold time {time.time()-t_fold:.1f}s', flush=True)\n",
        "\n",
        "# Overall OOF\n",
        "mask_all = sn_mask\n",
        "oof_score = mcrmse(y_tr[mask_all], oof[mask_all]) if mask_all.any() else mcrmse(y_tr, oof)\n",
        "print(f'OOF MCRMSE (SN==1): {oof_score:.6f}')\n",
        "\n",
        "# Predict on test: average across folds per target\n",
        "dte = xgb.DMatrix(X_te)\n",
        "pred_te = np.zeros((X_te.shape[0], len(TARGETS)), dtype=np.float32)\n",
        "for ti, t in enumerate(TARGETS):\n",
        "    preds_t = None\n",
        "    for bst in models[t]:\n",
        "        best_it = getattr(bst, 'best_iteration', None)\n",
        "        if best_it is not None:\n",
        "            p = bst.predict(dte, iteration_range=(0, best_it + 1))\n",
        "        else:\n",
        "            p = bst.predict(dte)\n",
        "        preds_t = p if preds_t is None else (preds_t + p)\n",
        "    pred_te[:, ti] = preds_t / max(1, len(models[t]))\n",
        "\n",
        "# Build submission by mapping id,pos to rows required\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub['id'] = sub['id_seqpos'].apply(lambda s: '_'.join(s.split('_')[:-1]))\n",
        "sub['pos'] = sub['id_seqpos'].apply(lambda s: int(s.split('_')[-1]))\n",
        "df_te_key = df_te[['id','pos']].copy()\n",
        "for i, t in enumerate(TARGETS):\n",
        "    df_te_key[t] = pred_te[:, i]\n",
        "merge = sub[['id','pos','id_seqpos']].merge(df_te_key, on=['id','pos'], how='left')\n",
        "miss = merge[TARGETS].isna().any(axis=1).sum()\n",
        "if miss>0:\n",
        "    print(f'Warning: {miss} submission rows missing predictions; filling with 0.0')\n",
        "    for t in TARGETS:\n",
        "        merge[t] = merge[t].fillna(0.0)\n",
        "out = merge[['id_seqpos'] + TARGETS].copy()\n",
        "out.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with shape', out.shape)\n",
        "print(out.head())\n",
        "gc.collect()\n",
        "print('Baseline done.')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattening train/test to per-base rows...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rows: 146880 in 0.54s\nTest rows (all positions): 25680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_tr shape: (146880, 26) df_te shape: (25680, 20)\ndf_tr cols: ['id', 'pos', 'L', 'base', 'struct', 'loop', 'base_m1', 'base_p1', 'base_m2', 'base_p2', 'struct_m1', 'struct_p1', 'loop_m1', 'loop_p1', 'is_paired', 'pair_dist', 'partner_base', 'rel_pos', 'dist_to_end', 'gc11'] ...\nFeature matrix shapes: (146880, 66) (25680, 66)\nFold 1: train=117504 valid=29376 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:17] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:18] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 MCRMSE (SN==1): 0.33253 | fold time 6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: train=117504 valid=29376 elapsed=6.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 MCRMSE (SN==1): 0.33570 | fold time 5.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3: train=117504 valid=29376 elapsed=11.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 MCRMSE (SN==1): 0.33226 | fold time 5.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4: train=117504 valid=29376 elapsed=16.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:32] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:33] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:34] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 MCRMSE (SN==1): 0.32328 | fold time 5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5: train=117504 valid=29376 elapsed=22.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:38] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:39] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 MCRMSE (SN==1): 0.32206 | fold time 5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:18:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF MCRMSE (SN==1): 0.329411\nSaved submission.csv with shape (25680, 6)\n        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C\n0  id_00b436dec_0    0.537878     0.565004  1.877807    0.478339  0.607095\n1  id_00b436dec_1    1.567672     2.089131  2.848847    2.024551  1.682175\n2  id_00b436dec_2    1.163138     0.745847  0.953829    0.994940  1.045937\n3  id_00b436dec_3    0.952121     0.569766  0.677064    0.812523  0.819617\n4  id_00b436dec_4    1.149979     1.084227  1.182120    1.330350  1.189750\nBaseline done.\n"
          ]
        }
      ]
    },
    {
      "id": "1f7266c2-a14b-4f2c-b2ba-d1c7d246d1f0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Next iteration prep: length-stratified folds, SN weights, extra features, and improved XGB params (not executed yet)\n",
        "import numpy as np, pandas as pd, time, math, gc\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import xgboost as xgb\n",
        "\n",
        "TARGETS = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']\n",
        "\n",
        "# Utilities to compute additional structural features on per-base DataFrame (df_tr/df_te style)\n",
        "def compute_run_lengths(arr):\n",
        "    # returns run length and index within run for a boolean array\n",
        "    n = len(arr)\n",
        "    run_len = np.zeros(n, dtype=np.int32)\n",
        "    idx_in_run = np.zeros(n, dtype=np.int32)\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        j = i\n",
        "        val = arr[i]\n",
        "        while j < n and arr[j] == val:\n",
        "            j += 1\n",
        "        length = j - i\n",
        "        run_len[i:j] = length\n",
        "        idx_in_run[i:j] = np.arange(length)\n",
        "        i = j\n",
        "    return run_len, idx_in_run\n",
        "\n",
        "def add_extra_features(df):\n",
        "    # df contains columns: id, pos, base, struct, loop, partner_base, is_paired, pair_dist, L\n",
        "    df = df.copy()\n",
        "    # Stem/loop run lengths per id\n",
        "    df['stem_len'] = 0\n",
        "    df['loop_len'] = 0\n",
        "    df['pos_in_loop'] = -1.0\n",
        "    df['dist_to_end_norm'] = df['dist_to_end'] / df['L'].clip(lower=1)\n",
        "    for rid, g in df.groupby('id', sort=False):\n",
        "        is_paired = g['is_paired'].to_numpy().astype(bool)\n",
        "        stem_run, _ = compute_run_lengths(is_paired)\n",
        "        loop_run, loop_idx = compute_run_lengths(~is_paired)\n",
        "        idx = g.index\n",
        "        df.loc[idx, 'stem_len'] = stem_run\n",
        "        df.loc[idx, 'loop_len'] = loop_run\n",
        "        denom = np.maximum(loop_run - 1, 1)\n",
        "        df.loc[idx, 'pos_in_loop'] = (loop_idx / denom).astype(np.float32)\n",
        "    # Pair type/strength\n",
        "    pair_map = {('G','C'):3, ('C','G'):3, ('A','U'):2, ('U','A'):2, ('G','U'):1, ('U','G'):1}\n",
        "    bases = df['base'].astype(str).values\n",
        "    partners = df['partner_base'].astype(str).values\n",
        "    strengths = np.zeros(len(df), dtype=np.float32)\n",
        "    for i,(b,p) in enumerate(zip(bases, partners)):\n",
        "        strengths[i] = pair_map.get((b,p), 0)\n",
        "    df['pair_strength'] = strengths\n",
        "    # Stacking context: paired neighbors\n",
        "    df['paired_m1'] = df.groupby('id')['is_paired'].shift(1).fillna(0).astype(int)\n",
        "    df['paired_p1'] = df.groupby('id')['is_paired'].shift(-1).fillna(0).astype(int)\n",
        "    df['stacked_pairs'] = (df['paired_m1'] & df['is_paired']) + (df['paired_p1'] & df['is_paired'])\n",
        "    return df\n",
        "\n",
        "def build_len_buckets(seq_lengths, bins=None):\n",
        "    x = np.array(seq_lengths)\n",
        "    if bins is None:\n",
        "        # fixed bins capturing 68/91/107/130-like ranges; fallback to quantiles if needed\n",
        "        bins = [0, 90, 110, 140, 10**9]\n",
        "    labels = np.digitize(x, bins, right=True)\n",
        "    return labels\n",
        "\n",
        "def make_stratified_group_folds(df_seq):\n",
        "    # df_seq: one row per sequence id with 'id' and 'seq_length' columns\n",
        "    y_strat = build_len_buckets(df_seq['seq_length'].values)\n",
        "    g = df_seq['id'].values\n",
        "    sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    folds = []\n",
        "    for tr_idx, va_idx in sgkf.split(np.zeros(len(df_seq)), y_strat, groups=g):\n",
        "        folds.append((df_seq.iloc[tr_idx]['id'].values, df_seq.iloc[va_idx]['id'].values))\n",
        "    return folds\n",
        "\n",
        "# Prepare next-run matrices with extra features and aligned dummies\n",
        "def prepare_matrices_with_extra(df_tr, df_te):\n",
        "    df_tr2 = add_extra_features(df_tr)\n",
        "    df_te2 = add_extra_features(df_te)\n",
        "    cat_cols = ['base','struct','loop','base_m1','base_p1','base_m2','base_p2','struct_m1','struct_p1','loop_m1','loop_p1','partner_base']\n",
        "    num_cols = ['pos','L','rel_pos','dist_to_end','dist_to_end_norm','gc11','is_paired','pair_dist','stem_len','loop_len','pos_in_loop','pair_strength','stacked_pairs']\n",
        "    Xtr = pd.concat([df_tr2[num_cols].astype(np.float32), pd.get_dummies(df_tr2[cat_cols], prefix=cat_cols, dummy_na=False)], axis=1).reset_index(drop=True)\n",
        "    Xte = pd.concat([df_te2[num_cols].astype(np.float32), pd.get_dummies(df_te2[cat_cols], prefix=cat_cols, dummy_na=False)], axis=1).reset_index(drop=True)\n",
        "    Xte = Xte.reindex(columns=Xtr.columns, fill_value=0)\n",
        "    return Xtr, Xte\n",
        "\n",
        "def train_xgb_weighted(X, y, groups, seq_lengths, sn_mask, folds=None):\n",
        "    if folds is None:\n",
        "        # build sequence-level folds\n",
        "        df_seq = pd.DataFrame({'id': pd.Series(groups).unique()})\n",
        "        # Map a representative seq_length per id from the first occurrence in X (needs external mapping)\n",
        "        raise RuntimeError('Provide precomputed sequence-level folds to avoid recomputing here.')\n",
        "    oof = np.zeros((X.shape[0], len(TARGETS)), dtype=np.float32)\n",
        "    models = {t: [] for t in TARGETS}\n",
        "    # Sample weights: SN==1 -> 1.0, else 0.5\n",
        "    w = np.where(sn_mask, 1.0, 0.5).astype(np.float32)\n",
        "    params = {\n",
        "        'objective': 'reg:squarederror',\n",
        "        'eval_metric': 'rmse',\n",
        "        'tree_method': 'hist',\n",
        "        'device': 'cuda',\n",
        "        'max_depth': 6,\n",
        "        'eta': 0.05,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.75,\n",
        "        'min_child_weight': 3.0,\n",
        "        'reg_lambda': 1.0,\n",
        "        'reg_alpha': 0.0\n",
        "    }\n",
        "    # Build an index lookup for id -> row indices\n",
        "    df_idx = pd.DataFrame({'id': groups})\n",
        "    for fold, (tr_ids, va_ids) in enumerate(folds, 1):\n",
        "        va_mask = df_idx['id'].isin(set(va_ids)).values\n",
        "        tr_mask = ~va_mask\n",
        "        tr_idx = np.where(tr_mask)[0]\n",
        "        va_idx = np.where(va_mask)[0]\n",
        "        print(f'[NextRun] Fold {fold}: train={len(tr_idx)} valid={len(va_idx)}')\n",
        "        dte = None\n",
        "        for ti, t in enumerate(TARGETS):\n",
        "            dtr = xgb.DMatrix(X.iloc[tr_idx], label=y[tr_idx, ti], weight=w[tr_idx])\n",
        "            dva = xgb.DMatrix(X.iloc[va_idx], label=y[va_idx, ti], weight=w[va_idx])\n",
        "            bst = xgb.train(params, dtr, num_boost_round=1500, evals=[(dtr,'train'),(dva,'valid')], early_stopping_rounds=100, verbose_eval=False)\n",
        "            pred = bst.predict(dva, iteration_range=(0, (bst.best_iteration or 0)+1))\n",
        "            models[t].append(bst)\n",
        "            oof[va_idx, ti] = pred\n",
        "        # compute fold score on SN==1 only\n",
        "        from sklearn.metrics import mean_squared_error\n",
        "        def mcrmse(a,b):\n",
        "            return np.mean([mean_squared_error(a[:,i], b[:,i], squared=False) for i in range(a.shape[1])])\n",
        "        mask = sn_mask[va_idx]\n",
        "        score = mcrmse(y[va_idx][mask], oof[va_idx][mask]) if mask.any() else mcrmse(y[va_idx], oof[va_idx])\n",
        "        print(f'[NextRun] Fold {fold} MCRMSE (SN==1): {score:.5f}')\n",
        "    return oof, models\n",
        "\n",
        "# Seq-level frame for folds: derive from original train objects\n",
        "seq_df = pd.DataFrame([{ 'id': r['id'], 'seq_length': int(r.get('seq_length', len(r.get('sequence','')))) } for r in train])\n",
        "folds_len = make_stratified_group_folds(seq_df)\n",
        "print('Prepared length-stratified folds for next run.')\n",
        "print('Next: reuse df_tr/df_te to call prepare_matrices_with_extra(), then train_xgb_weighted() with folds_len. Also proceed to build BiGRU in a separate script.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}