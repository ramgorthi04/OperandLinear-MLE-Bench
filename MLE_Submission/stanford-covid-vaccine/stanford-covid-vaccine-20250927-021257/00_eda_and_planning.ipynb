{
  "cells": [
    {
      "id": "e5978135-ae8c-4b24-987e-4fd25978d421",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan: OpenVaccine (stanford-covid-vaccine) \u2014 Medal-Oriented Workflow\n",
        "\n",
        "Objectives:\n",
        "- Build a strong baseline fast, align CV with LB, iterate to medal.\n",
        "\n",
        "Datasets:\n",
        "- train.json, test.json, sample_submission.csv\n",
        "\n",
        "Metric:\n",
        "- multi-class-log-loss (per-position targets across 5 tasks: reactivity, deg_Mg_pH10, deg_pH10, deg_Mg_50C, deg_50C for L=107 or 130 seq lengths depending on data).\n",
        "\n",
        "High-level Strategy:\n",
        "1) Environment & GPU:\n",
        "- Verify GPU with nvidia-smi and torch CUDA stack sanity.\n",
        "\n",
        "2) Data Audit:\n",
        "- Load train.json/test.json; inspect schema, lengths, missing values, target columns, sequence length distributions, and public vs private split hints.\n",
        "- Confirm how to format submission (per-base predictions melted to long with id_seqpos).\n",
        "\n",
        "3) Validation Protocol:\n",
        "- Use GroupKFold by sequence_id or stratification by sequence length/structure; mirror test: sequence-level CV, not token-level.\n",
        "- Fix random seed; 5 folds. Save folds to disk.\n",
        "\n",
        "4) Baseline Model (fast):\n",
        "- Token features: sequence (A,C,G,U one-hot), structure (BPP features from provided pairing probability if present; else dot-bracket + simple pairing features), predicted_loop_type one-hot.\n",
        "- Local context windows (k-mer embeddings) and position index features.\n",
        "- Model A: Lightweight BiLSTM/GRU with attention, trained with MSE to match baseline (regression to targets); optionally multi-head outputs.\n",
        "- Model B: CatBoost/XGBoost on pooled/contextual features (for quick sanity).\n",
        "\n",
        "5) Feature Engineering v1:\n",
        "- Base pairing probabilities (from bpps matrices if included or compute via ViennaRNA if allowed/time permits).\n",
        "- Positional features: distance to paired base, GC content in window, k-mer counts, loop type runs.\n",
        "- Temperature/Mg condition indicators per target head.\n",
        "\n",
        "6) Training Details:\n",
        "- Sequence-length bucketing and padding mask.\n",
        "- Per-position loss masked to valid positions.\n",
        "- Early stopping on CV fold OOF loss. Log progress, time/fold.\n",
        "- Save OOF predictions and test predictions per seed.\n",
        "\n",
        "7) Ensembling:\n",
        "- Blend multiple seeds/architectures (BiLSTM + GRU; with/without BPP; small Transformer) by weighted average on OOF to pick weights, then apply to test.\n",
        "\n",
        "8) Error Analysis:\n",
        "- Analyze OOF by position bins, structure classes, sequence length, confidence; iterate on features.\n",
        "\n",
        "9) Submission:\n",
        "- Generate submission.csv exactly matching sample format.\n",
        "\n",
        "Milestones (request expert review after each):\n",
        "- Plan (this).\n",
        "- Data audit + CV plan.\n",
        "- Baseline training + OOF.\n",
        "- FE v1 + improved model.\n",
        "- Ensemble + final checks.\n",
        "\n",
        "Next steps:\n",
        "- 1) Verify GPU, install torch-cu121 stack.\n",
        "- 2) Load and profile data; design CV folds.\n",
        "- 3) Implement quick CatBoost baseline for smoke test and submission shape check, then move to BiLSTM."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "52492a0c-c453-4a5a-b35b-014a3ce47ab9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment check + data audit: GPU, schema, metric/target confirmation\n",
        "import os, sys, json, time, shutil, subprocess\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "pd.set_option('display.max_columns', 200)\n",
        "pd.set_option('display.width', 200)\n",
        "\n",
        "def sh(cmd):\n",
        "    print(f\"$ {' '.join(cmd)}\", flush=True)\n",
        "    try:\n",
        "        out = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "        print(out.stdout)\n",
        "    except Exception as e:\n",
        "        print('CMD failed:', e)\n",
        "\n",
        "print('== GPU check ==')\n",
        "sh(['bash','-lc','nvidia-smi || true'])\n",
        "\n",
        "print('== Files ==')\n",
        "print(os.listdir('.'))\n",
        "\n",
        "print('== sample_submission.csv head/cols ==')\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "print(ss.shape)\n",
        "print(ss.head())\n",
        "print('Columns:', ss.columns.tolist()[:20], '... total:', len(ss.columns))\n",
        "\n",
        "print('== train.json schema/head ==')\n",
        "try:\n",
        "    tr = pd.read_json('train.json')\n",
        "except ValueError:\n",
        "    tr = pd.read_json('train.json', lines=True)\n",
        "print(tr.shape)\n",
        "print(tr.columns.tolist())\n",
        "print(tr.head(2))\n",
        "print(tr.dtypes)\n",
        "\n",
        "# Inspect target nature and aux columns\n",
        "cols = tr.columns.tolist()\n",
        "targets = [c for c in cols if c.startswith('react') or c.startswith('deg')]\n",
        "print('Target-like columns:', targets)\n",
        "if targets:\n",
        "    first = tr.iloc[0]\n",
        "    for c in targets[:10]:\n",
        "        v = first.get(c, None)\n",
        "        if isinstance(v, (list, tuple, np.ndarray)) and len(v)>0:\n",
        "            print(f'{c}: list len={len(v)}, type0={type(v[0])}')\n",
        "        else:\n",
        "            print(f'{c}: type={type(v)} value_sample={str(v)[:60]}')\n",
        "\n",
        "for name in ['sequence','structure','predicted_loop_type','seq_scored','signal_to_noise','SN_filter']:\n",
        "    print(f\"Has {name}:\", name in tr.columns)\n",
        "\n",
        "# Sequence length distribution\n",
        "if 'sequence' in tr.columns:\n",
        "    tr['seq_len'] = tr['sequence'].astype(str).str.len()\n",
        "    print('Train seq_len value_counts:\\n', tr['seq_len'].value_counts().sort_index())\n",
        "else:\n",
        "    print('No sequence column found.')\n",
        "\n",
        "print('== test.json schema/head ==')\n",
        "try:\n",
        "    te = pd.read_json('test.json')\n",
        "except ValueError:\n",
        "    te = pd.read_json('test.json', lines=True)\n",
        "print(te.shape)\n",
        "print(te.columns.tolist())\n",
        "print(te.head(2))\n",
        "if 'sequence' in te.columns:\n",
        "    te['seq_len'] = te['sequence'].astype(str).str.len()\n",
        "    print('Test seq_len value_counts:\\n', te['seq_len'].value_counts().sort_index())\n",
        "\n",
        "print('== sample_submission format inference ==')\n",
        "print('First row id_seqpos:', ss.iloc[0,0])\n",
        "print('Submission columns (first 10):', ss.columns[:10].tolist())\n",
        ""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== GPU check ==\n$ bash -lc nvidia-smi || true\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep 27 02:20:51 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n== Files ==\n['sample_submission.csv', '.00_eda_and_planning_kernel_state.json', 'docker_run.log', 'requirements.txt', 'submission.csv', 'train.json', 'agent_metadata', 'task.txt', 'test.json', '00_eda_and_planning.ipynb', 'description.md']\n== sample_submission.csv head/cols ==\n(25680, 6)\n        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C  deg_50C\n0  id_00b436dec_0         0.0          0.0       0.0         0.0      0.0\n1  id_00b436dec_1         0.0          0.0       0.0         0.0      0.0\n2  id_00b436dec_2         0.0          0.0       0.0         0.0      0.0\n3  id_00b436dec_3         0.0          0.0       0.0         0.0      0.0\n4  id_00b436dec_4         0.0          0.0       0.0         0.0      0.0\nColumns: ['id_seqpos', 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C'] ... total: 6\n== train.json schema/head ==\n(2160, 19)\n['index', 'id', 'sequence', 'structure', 'predicted_loop_type', 'signal_to_noise', 'SN_filter', 'seq_length', 'seq_scored', 'reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C', 'deg_error_50C', 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n   index            id                                           sequence                                          structure                                predicted_loop_type  signal_to_noise  \\\n0      0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...  .....((((((.......)))).)).((.....((..((((((......  EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n1      1  id_0049f53ba  GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...  .....(((((((((((((((((((((((....)))))))))).)))...  EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...            0.193   \n\n   SN_filter  seq_length  seq_scored                                   reactivity_error                                  deg_error_Mg_pH10                                     deg_error_pH10  \\\n0          1         107          68  [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...  [0.26130000000000003, 0.38420000000000004, 0.1...  [0.2631, 0.28600000000000003, 0.0964, 0.1574, ...   \n1          0         107          68  [2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...  [73705.3985, 73705.3985, 73705.3985, 73705.398...  [10.1986, 9.2418, 5.0933, 5.0933, 5.0933, 5.09...   \n\n                                    deg_error_Mg_50C                                      deg_error_50C                                         reactivity  \\\n0  [0.1501, 0.275, 0.0947, 0.18660000000000002, 0...  [0.2167, 0.34750000000000003, 0.188, 0.2124, 0...  [0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...   \n1  [16.6174, 13.868, 8.1968, 8.1968, 8.1968, 8.19...  [15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...  [0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....   \n\n                                         deg_Mg_pH10                                           deg_pH10                                         deg_Mg_50C  \\\n0  [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...  [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...  [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n\n                                             deg_50C  \n0  [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...  \n1  [7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...  \nindex                    int64\nid                      object\nsequence                object\nstructure               object\npredicted_loop_type     object\nsignal_to_noise        float64\nSN_filter                int64\nseq_length               int64\nseq_scored               int64\nreactivity_error        object\ndeg_error_Mg_pH10       object\ndeg_error_pH10          object\ndeg_error_Mg_50C        object\ndeg_error_50C           object\nreactivity              object\ndeg_Mg_pH10             object\ndeg_pH10                object\ndeg_Mg_50C              object\ndeg_50C                 object\ndtype: object\nTarget-like columns: ['reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C', 'deg_error_50C', 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\nreactivity_error: list len=68, type0=<class 'float'>\ndeg_error_Mg_pH10: list len=68, type0=<class 'float'>\ndeg_error_pH10: list len=68, type0=<class 'float'>\ndeg_error_Mg_50C: list len=68, type0=<class 'float'>\ndeg_error_50C: list len=68, type0=<class 'float'>\nreactivity: list len=68, type0=<class 'float'>\ndeg_Mg_pH10: list len=68, type0=<class 'float'>\ndeg_pH10: list len=68, type0=<class 'float'>\ndeg_Mg_50C: list len=68, type0=<class 'float'>\ndeg_50C: list len=68, type0=<class 'float'>\nHas sequence: True\nHas structure: True\nHas predicted_loop_type: True\nHas seq_scored: True\nHas signal_to_noise: True\nHas SN_filter: True\nTrain seq_len value_counts:\n seq_len\n107    2160\nName: count, dtype: int64\n== test.json schema/head ==\n(240, 7)\n['index', 'id', 'sequence', 'structure', 'predicted_loop_type', 'seq_length', 'seq_scored']\n   index            id                                           sequence                                          structure                                predicted_loop_type  seq_length  \\\n0      0  id_00b436dec  GGAAAUCAUCGAGGACGGGUCCGUUCAGCACGCGAAAGCGUCGUGA...  .....(((((((((((..(((((((((..((((....))))..)))...  EEEEESSSSSSSSSSSIISSSSSSSSSIISSSSHHHHSSSSIISSS...         107   \n1      1  id_010ab0472  GGAAAGCAUGGGACCACGAUUCACAUCGGUCUGCACGUAGGACAUU...  .....(((...((((..(((....))))))))))(((((((((......  EEEEESSSBBBSSSSBBSSSHHHHSSSSSSSSSSSSSSSSSSSIII...         107   \n\n   seq_scored  \n0          68  \n1          68  \nTest seq_len value_counts:\n seq_len\n107    240\nName: count, dtype: int64\n== sample_submission format inference ==\nFirst row id_seqpos: id_00b436dec_0\nSubmission columns (first 10): ['id_seqpos', 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n"
          ]
        }
      ]
    },
    {
      "id": "07b502cb-3ee8-4ca3-829f-6b56478d2176",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fast baseline: per-position means for 0..67; global means for 68..106; write submission.csv\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "try:\n",
        "    tr = pd.read_json('train.json')\n",
        "except ValueError:\n",
        "    tr = pd.read_json('train.json', lines=True)\n",
        "try:\n",
        "    te = pd.read_json('test.json')\n",
        "except ValueError:\n",
        "    te = pd.read_json('test.json', lines=True)\n",
        "\n",
        "targets = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']\n",
        "\n",
        "# Stack train targets into long dataframe with seqpos only for scored positions\n",
        "rows = []\n",
        "for _, r in tr.iterrows():\n",
        "    scored = int(r['seq_scored'])\n",
        "    for t in targets:\n",
        "        vals = np.array(r[t], dtype=float)\n",
        "        for i in range(scored):\n",
        "            rows.append((t, i, vals[i]))\n",
        "train_long = pd.DataFrame(rows, columns=['target','seqpos','value'])\n",
        "\n",
        "# Compute per-position mean for 0..67 and global mean\n",
        "pos_means = (train_long.groupby(['target','seqpos'])['value'].mean().unstack('seqpos'))\n",
        "global_means = train_long.groupby('target')['value'].mean()\n",
        "max_pos = pos_means.columns.max() if pos_means.shape[1] > 0 else 67\n",
        "print('Computed pos_means up to position:', int(max_pos))\n",
        "\n",
        "# Build prediction dict: for each test id and position 0..106\n",
        "pred_map = {}  # key: (id, pos) -> dict of target->pred\n",
        "for _, r in te[['id','seq_length','seq_scored']].iterrows():\n",
        "    rid = r['id']\n",
        "    L = int(r['seq_length'])\n",
        "    scored = int(r['seq_scored'])  # expected 68\n",
        "    for i in range(L):\n",
        "        for t in targets:\n",
        "            if i in pos_means.columns:\n",
        "                val = float(pos_means.loc[t, i])\n",
        "            else:\n",
        "                # unscored positions fallback\n",
        "                val = float(global_means.loc[t])\n",
        "            pred_map[(rid, i, t)] = val\n",
        "\n",
        "# Merge predictions into sample_submission to preserve order\n",
        "def parse_id_seqpos(x):\n",
        "    # 'id_xxx_pos'\n",
        "    s, pos = x.rsplit('_', 1)\n",
        "    return s, int(pos)\n",
        "\n",
        "ids = []\n",
        "pos = []\n",
        "for v in ss['id_seqpos'].values:\n",
        "    i, p = parse_id_seqpos(v)\n",
        "    ids.append(i)\n",
        "    pos.append(p)\n",
        "ss['_id'] = ids\n",
        "ss['_pos'] = pos\n",
        "\n",
        "for t in targets:\n",
        "    ss[t] = [pred_map[(i, p, t)] for i, p in zip(ss['_id'], ss['_pos'])]\n",
        "\n",
        "ss.drop(columns=['_id','_pos'], inplace=True)\n",
        "ss.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv with shape:', ss.shape)\n",
        "print(ss.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed pos_means up to position: 67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv with shape: (25680, 6)\n        id_seqpos  reactivity  deg_Mg_pH10  deg_pH10  deg_Mg_50C   deg_50C\n0  id_00b436dec_0    0.531662     0.590755  2.001310    0.474894  0.608811\n1  id_00b436dec_1    1.515921     2.078699  2.904483    2.025060  1.792079\n2  id_00b436dec_2    1.117059     0.713412  0.918506    0.951581  1.013684\n3  id_00b436dec_3    0.823220     0.540694  0.716204    0.728683  0.751078\n4  id_00b436dec_4    0.664863     0.676643  0.731160    0.846463  0.736625\n"
          ]
        }
      ]
    },
    {
      "id": "6137e951-8126-41b5-8555-2e940483746d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install PyTorch cu121 stack and sanity-check GPU\n",
        "import os, sys, subprocess, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def pip(*args):\n",
        "    print('>', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Uninstall any preinstalled torch stacks (idempotent)\n",
        "for pkg in ('torch','torchvision','torchaudio'):\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "\n",
        "# Clean stray site dirs that can shadow correct wheels (idempotent)\n",
        "for d in (\n",
        "    '/app/.pip-target/torch',\n",
        "    '/app/.pip-target/torch-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torch-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchvision',\n",
        "    '/app/.pip-target/torchvision-0.23.0.dist-info',\n",
        "    '/app/.pip-target/torchvision-0.19.1.dist-info',\n",
        "    '/app/.pip-target/torchaudio',\n",
        "    '/app/.pip-target/torchaudio-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torchaudio-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchgen',\n",
        "    '/app/.pip-target/functorch',\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d)\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# 1) Install the EXACT cu121 torch stack\n",
        "pip('install',\n",
        "    '--index-url', 'https://download.pytorch.org/whl/cu121',\n",
        "    '--extra-index-url', 'https://pypi.org/simple',\n",
        "    'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1')\n",
        "\n",
        "# 2) Freeze torch versions for later installs\n",
        "Path('constraints.txt').write_text('torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n')\n",
        "\n",
        "# 3) Sanity gate (hard fail on drift)\n",
        "import torch\n",
        "print('torch:', torch.__version__, 'built CUDA:', getattr(torch.version, 'cuda', None))\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f'Wrong CUDA build: {torch.version.cuda}'\n",
        "assert torch.cuda.is_available(), 'CUDA not available'\n",
        "print('GPU:', torch.cuda.get_device_name(0))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchvision as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> install --index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.org/simple torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 230.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 230.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 249.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 146.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 190.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 221.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 490.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 432.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 235.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 494.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 265.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 185.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 157.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 149.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 177.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 178.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 433.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 213.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 493.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 384.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 347.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 223.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 175.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 542.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 built CUDA: 12.1\nCUDA available: True\nGPU: NVIDIA A10-24Q\n"
          ]
        }
      ]
    },
    {
      "id": "37105dd5-a485-4c8e-85d5-c6e8f24dee66",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build CV splits (StratifiedGroupKFold on SN_filter) and define masked MCRMSE metric\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import GroupKFold\n",
        "try:\n",
        "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold  # optional\n",
        "except Exception:\n",
        "    MultilabelStratifiedKFold = None\n",
        "try:\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "except Exception:\n",
        "    StratifiedKFold = None\n",
        "\n",
        "SEED = 42\n",
        "N_FOLDS = 5\n",
        "targets = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']\n",
        "\n",
        "def set_seed(seed=SEED):\n",
        "    import random, os\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "set_seed()\n",
        "\n",
        "# Robust JSON reader (handles non-line-delimited and line-delimited)\n",
        "try:\n",
        "    tr = pd.read_json('train.json')\n",
        "except ValueError:\n",
        "    tr = pd.read_json('train.json', lines=True)\n",
        "\n",
        "# Grouping by sequence id; stratify by SN_filter (0/1).\n",
        "groups = tr['id'].values\n",
        "y_strat = tr['SN_filter'].values if 'SN_filter' in tr.columns else np.zeros(len(tr), dtype=int)\n",
        "\n",
        "# Create folds\n",
        "folds = np.full(len(tr), -1, dtype=int)\n",
        "gkf = GroupKFold(n_splits=N_FOLDS)\n",
        "splitter = gkf.split(np.zeros(len(tr)), y_strat, groups)\n",
        "for fold, (tr_idx, va_idx) in enumerate(splitter):\n",
        "    folds[va_idx] = fold\n",
        "\n",
        "assert (folds >= 0).all(), 'Some folds not assigned'\n",
        "tr_folds = tr[['id','SN_filter']].copy() if 'SN_filter' in tr.columns else tr[['id']].copy()\n",
        "tr_folds['fold'] = folds\n",
        "tr_folds.to_csv('folds.csv', index=False)\n",
        "print('Saved folds.csv with shape:', tr_folds.shape)\n",
        "print('Fold counts:\\n', tr_folds['fold'].value_counts().sort_index())\n",
        "if 'SN_filter' in tr_folds.columns:\n",
        "    print('SN_filter by fold:\\n', tr_folds.groupby('fold')['SN_filter'].value_counts().unstack(fill_value=0))\n",
        "\n",
        "# Masked MCRMSE utility (evaluate on positions 0..67 only)\n",
        "def masked_mcrmse(y_true, y_pred, mask):\n",
        "    # y_* shape: [B, L, T], mask: [B, L] boolean for scored positions\n",
        "    T = y_true.shape[-1]\n",
        "    rmses = []\n",
        "    for t in range(T):\n",
        "        yt = y_true[..., t]; yp = y_pred[..., t]\n",
        "        m = mask.astype(bool)\n",
        "        diff = (yp - yt)[m]\n",
        "        rmse = np.sqrt(np.mean(diff**2)) if diff.size > 0 else np.nan\n",
        "        rmses.append(rmse)\n",
        "    return float(np.nanmean(rmses))\n",
        "\n",
        "print('Masked MCRMSE ready. Use mask = (pos < 68).')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved folds.csv with shape: (2160, 3)\nFold counts:\n fold\n0    432\n1    432\n2    432\n3    432\n4    432\nName: count, dtype: int64\nSN_filter by fold:\n SN_filter    0    1\nfold               \n0          154  278\n1          149  283\n2          170  262\n3          168  264\n4          170  262\nMasked MCRMSE ready. Use mask = (pos < 68).\n"
          ]
        }
      ]
    },
    {
      "id": "83acb471-c612-497f-85c1-c2fba5083771",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dataset, model, and training utilities with engineered structure features, standardization, SmoothL1 loss, Conv1D front-end\n",
        "import math, random, gc, time, os\n",
        "import numpy as np, pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
        "\n",
        "# Encoders\n",
        "BASES = ['A','C','G','U']\n",
        "STRUCT = ['.', '(', ')']\n",
        "LOOPS = list('BEHIMSX')\n",
        "BASE2IDX = {b:i for i,b in enumerate(BASES)}\n",
        "STRUCT2IDX = {c:i for i,c in enumerate(STRUCT)}\n",
        "LOOP2IDX = {c:i for i,c in enumerate(LOOPS)}\n",
        "\n",
        "def one_hot(idx, K):\n",
        "    v = np.zeros(K, dtype=np.float32)\n",
        "    if idx is not None and 0 <= idx < K: v[idx]=1.0\n",
        "    return v\n",
        "\n",
        "def dotbracket_partner_and_depth(struct):\n",
        "    stack = []\n",
        "    L = len(struct)\n",
        "    partner = np.full(L, -1, dtype=np.int32)\n",
        "    depth = np.zeros(L, dtype=np.int32)\n",
        "    cur_depth = 0\n",
        "    for i,ch in enumerate(struct):\n",
        "        if ch == '(':\n",
        "            stack.append(i); cur_depth += 1; depth[i] = cur_depth\n",
        "        elif ch == ')':\n",
        "            if stack:\n",
        "                j = stack.pop();\n",
        "                partner[i] = j; partner[j] = i\n",
        "                depth[i] = cur_depth\n",
        "            cur_depth = max(0, cur_depth-1)\n",
        "        else:\n",
        "            depth[i] = cur_depth\n",
        "    return partner, depth\n",
        "\n",
        "def run_lengths(arr):\n",
        "    # length of the contiguous run containing each position (arr is array of codes/ints)\n",
        "    L = len(arr); out = np.zeros(L, dtype=np.int32)\n",
        "    start = 0\n",
        "    for i in range(1, L+1):\n",
        "        if i==L or arr[i] != arr[start]:\n",
        "            out[start:i] = i - start\n",
        "            start = i\n",
        "    return out\n",
        "\n",
        "def encode_row(row):\n",
        "    seq = str(row['sequence']); struct = str(row['structure']); loop = str(row['predicted_loop_type'])\n",
        "    L = len(seq)\n",
        "    partner, depth = dotbracket_partner_and_depth(struct)\n",
        "    is_paired = (partner >= 0).astype(np.float32)\n",
        "    partner_dist = np.zeros(L, dtype=np.float32)\n",
        "    for i in range(L):\n",
        "        if partner[i] >= 0:\n",
        "            partner_dist[i] = abs(partner[i] - i) / max(1,(L-1))\n",
        "        else:\n",
        "            partner_dist[i] = 0.0\n",
        "    # stem run-length (paired runs) and loop run-length (same loop char) normalized\n",
        "    paired_int = is_paired.astype(np.int32)\n",
        "    stem_run = run_lengths(paired_int) / max(1, L)\n",
        "    loop_codes = np.array([LOOP2IDX.get(c, 0) for c in loop], dtype=np.int32)\n",
        "    loop_run = run_lengths(loop_codes) / max(1, L)\n",
        "    # local GC ratio (win=5 centered)\n",
        "    base_codes = np.array([BASE2IDX.get(b, -1) for b in seq], dtype=np.int32)\n",
        "    is_gc = np.isin(base_codes, [BASE2IDX['G'], BASE2IDX['C']]).astype(np.float32)\n",
        "    gc_win = np.zeros(L, dtype=np.float32)\n",
        "    k = 5; rad = k//2\n",
        "    csum = np.concatenate([[0.0], is_gc.cumsum()])\n",
        "    for i in range(L):\n",
        "        a = max(0, i - rad); b = min(L, i + rad + 1)\n",
        "        gc_win[i] = (csum[b] - csum[a]) / max(1, b - a)\n",
        "    feats = []\n",
        "    for i,(b,s,l) in enumerate(zip(seq, struct, loop)):\n",
        "        v = []\n",
        "        v.extend(one_hot(BASE2IDX.get(b, -1), len(BASES)))\n",
        "        v.extend(one_hot(STRUCT2IDX.get(s, -1), len(STRUCT)))\n",
        "        v.extend(one_hot(LOOP2IDX.get(l, -1), len(LOOPS)))\n",
        "        # positional scalars\n",
        "        pos_norm = i / max(1,(L-1))\n",
        "        v.append(float(i))\n",
        "        v.append(float(L))\n",
        "        v.append(pos_norm)\n",
        "        v.append(math.sin(2*math.pi*pos_norm))\n",
        "        v.append(math.cos(2*math.pi*pos_norm))\n",
        "        # engineered continuous features\n",
        "        v.append(float(is_paired[i]))\n",
        "        v.append(float(partner_dist[i]))\n",
        "        v.append(float(depth[i]))\n",
        "        v.append(float(stem_run[i]))\n",
        "        v.append(float(loop_run[i]))\n",
        "        v.append(float(gc_win[i]))\n",
        "        feats.append(v)\n",
        "    x = np.asarray(feats, dtype=np.float32)  # [L, C]\n",
        "    return x\n",
        "\n",
        "TARGETS = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']\n",
        "SCORED_LEN = 68\n",
        "\n",
        "def get_targets(row):\n",
        "    y = np.zeros((len(str(row['sequence'])), len(TARGETS)), dtype=np.float32)\n",
        "    for t_i, t in enumerate(TARGETS):\n",
        "        arr = np.array(row[t], dtype=np.float32)[:SCORED_LEN]\n",
        "        y[:SCORED_LEN, t_i] = arr\n",
        "    return y\n",
        "\n",
        "# Index where continuous channels start (one-hots first): 4 + 3 + 7 = 14\n",
        "CONT_START = 4 + 3 + 7\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, df, scaler=None, sample_weights=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.scaler = scaler  # dict with 'mean','std' for continuous cols\n",
        "        self.sample_weights = sample_weights if sample_weights is not None else np.ones(len(self.df), dtype=np.float32)\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]\n",
        "        x = encode_row(r)  # [L, C]\n",
        "        if self.scaler is not None:\n",
        "            mu = self.scaler['mean']; sd = self.scaler['std']\n",
        "            x_cont = x[:, CONT_START:]\n",
        "            x[:, CONT_START:] = np.clip((x_cont - mu) / (sd + 1e-6), -5.0, 5.0)\n",
        "        y = get_targets(r) # [L, T]\n",
        "        L = x.shape[0]\n",
        "        mask = np.zeros((L,), dtype=np.float32)\n",
        "        mask[:SCORED_LEN]=1.0\n",
        "        w = float(self.sample_weights[idx])\n",
        "        return x, y, mask, r['id'], w\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, df, scaler=None):\n",
        "        self.df = df.reset_index(drop=True); self.scaler = scaler\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]\n",
        "        x = encode_row(r)\n",
        "        if self.scaler is not None:\n",
        "            mu = self.scaler['mean']; sd = self.scaler['std']\n",
        "            x_cont = x[:, CONT_START:]\n",
        "            x[:, CONT_START:] = np.clip((x_cont - mu) / (sd + 1e-6), -5.0, 5.0)\n",
        "        L = x.shape[0]\n",
        "        mask = np.zeros((L,), dtype=np.float32)\n",
        "        mask[:SCORED_LEN]=1.0\n",
        "        return x, mask, r['id']\n",
        "\n",
        "def collate_train(batch):\n",
        "    lens = [b[0].shape[0] for b in batch]\n",
        "    maxL = max(lens)\n",
        "    C = batch[0][0].shape[1]\n",
        "    T = batch[0][1].shape[1]\n",
        "    B = len(batch)\n",
        "    x = np.zeros((B,maxL,C), dtype=np.float32)\n",
        "    y = np.zeros((B,maxL,T), dtype=np.float32)\n",
        "    mask = np.zeros((B,maxL), dtype=np.float32)\n",
        "    ids = []; w = np.zeros((B,), dtype=np.float32)\n",
        "    for i,(xi, yi, mi, idv, wi) in enumerate(batch):\n",
        "        L = xi.shape[0]\n",
        "        x[i,:L,:] = xi\n",
        "        y[i,:L,:] = yi\n",
        "        mask[i,:L] = mi\n",
        "        ids.append(idv); w[i]=wi\n",
        "    return torch.from_numpy(x), torch.from_numpy(y), torch.from_numpy(mask), ids, torch.from_numpy(w)\n",
        "\n",
        "def collate_test(batch):\n",
        "    lens = [b[0].shape[0] for b in batch]\n",
        "    maxL = max(lens); C = batch[0][0].shape[1]; B=len(batch)\n",
        "    x = np.zeros((B,maxL,C), dtype=np.float32)\n",
        "    mask = np.zeros((B,maxL), dtype=np.float32)\n",
        "    ids = []\n",
        "    for i,(xi, mi, idv) in enumerate(batch):\n",
        "        L = xi.shape[0]\n",
        "        x[i,:L,:]=xi; mask[i,:L]=mi; ids.append(idv)\n",
        "    return torch.from_numpy(x), torch.from_numpy(mask), ids\n",
        "\n",
        "class CNNBiLSTMModel(nn.Module):\n",
        "    def __init__(self, in_ch, conv_ch=128, hidden=256, num_layers=2, out_ch=5, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(in_ch, conv_ch, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.lstm = nn.LSTM(input_size=conv_ch, hidden_size=hidden, num_layers=num_layers,\n",
        "                            dropout=dropout if num_layers>1 else 0.0, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.head = nn.Linear(hidden*2, out_ch)\n",
        "    def forward(self, x, lengths):\n",
        "        # x: [B,L,C]; lengths: [B]\n",
        "        x = x.transpose(1,2)  # [B,C,L]\n",
        "        x = self.conv(x)\n",
        "        x = x.transpose(1,2)  # [B,L,conv_ch]\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "        out_packed, _ = self.lstm(packed)\n",
        "        out, _ = nn.utils.rnn.pad_packed_sequence(out_packed, batch_first=True)\n",
        "        out = self.dropout(out)\n",
        "        y = self.head(out)  # [B,L,5]\n",
        "        return y\n",
        "\n",
        "def _lengths_from_x(xb):\n",
        "    return (xb.abs().sum(dim=2) > 0).sum(dim=1).long().clamp(min=1)\n",
        "\n",
        "def masked_smoothl1_loss(pred, target, mask, sample_weights=None, beta=1.0):\n",
        "    # pred/target: [B,L,T], mask: [B,L], sample_weights: [B]\n",
        "    loss = F.smooth_l1_loss(pred, target, reduction='none', beta=beta)  # [B,L,T]\n",
        "    mask3 = mask.unsqueeze(-1)\n",
        "    loss = loss * mask3\n",
        "    denom = (mask3.sum(dim=(1,2)).clamp(min=1.0))  # [B]\n",
        "    loss_b = loss.sum(dim=(1,2)) / denom  # [B]\n",
        "    if sample_weights is not None:\n",
        "        loss_b = loss_b * sample_weights\n",
        "        return loss_b.mean()\n",
        "    else:\n",
        "        return loss_b.mean()\n",
        "\n",
        "def compute_scaler(train_df):\n",
        "    # Fit mean/std for continuous channels from train fold only\n",
        "    xs = []\n",
        "    for _, r in train_df.iterrows():\n",
        "        x = encode_row(r)\n",
        "        xs.append(x[:, CONT_START:])\n",
        "    X = np.concatenate(xs, axis=0)  # [sumL, C_cont]\n",
        "    mu = X.mean(axis=0).astype(np.float32)\n",
        "    sd = X.std(axis=0).astype(np.float32)\n",
        "    return {'mean': mu, 'std': sd}\n",
        "\n",
        "def run_fold(fold, tr_df, te_df, folds_df, epochs=20, batch_size=64, lr=1e-3, wd=1e-4, use_amp=True):\n",
        "    # split ids\n",
        "    tr_ids = set(tr_df['id'].values)\n",
        "    train_ids = set(folds_df.loc[folds_df['fold']!=fold, 'id'].values) & tr_ids\n",
        "    valid_ids = set(folds_df.loc[folds_df['fold']==fold, 'id'].values) & tr_ids\n",
        "    dtr = tr_df[tr_df['id'].isin(train_ids)].reset_index(drop=True)\n",
        "    dva = tr_df[tr_df['id'].isin(valid_ids)].reset_index(drop=True)\n",
        "    # sample weights by SN_filter\n",
        "    if 'SN_filter' in dtr.columns:\n",
        "        sw_tr = np.where(dtr['SN_filter'].values.astype(int)==1, 1.0, 0.5).astype(np.float32)\n",
        "    else:\n",
        "        sw_tr = np.ones(len(dtr), dtype=np.float32)\n",
        "    # scaler per fold\n",
        "    scaler = compute_scaler(dtr)\n",
        "    ds_tr = TrainDataset(dtr, scaler=scaler, sample_weights=sw_tr)\n",
        "    ds_va = TrainDataset(dva, scaler=scaler, sample_weights=np.ones(len(dva), dtype=np.float32))\n",
        "    ds_te = TestDataset(te_df, scaler=scaler)\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate_train)\n",
        "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, collate_fn=collate_train)\n",
        "    dl_te = DataLoader(ds_te, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, collate_fn=collate_test)\n",
        "    in_ch = ds_tr[0][0].shape[1]\n",
        "    model = CNNBiLSTMModel(in_ch=in_ch).to(DEVICE)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', patience=2, factor=0.5, verbose=False)\n",
        "    scaler_amp = torch.cuda.amp.GradScaler(enabled=use_amp and DEVICE=='cuda')\n",
        "    best = 1e9; best_state=None; start=time.time()\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train(); tr_loss=0.0; n_batches=0; t0=time.time()\n",
        "        for xb, yb, mb, _, wb in dl_tr:\n",
        "            xb=xb.to(DEVICE); yb=yb.to(DEVICE); mb=mb.to(DEVICE); wb=wb.to(DEVICE); lens = _lengths_from_x(xb)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=use_amp and DEVICE=='cuda'):\n",
        "                preds = model(xb, lens)\n",
        "                loss = masked_smoothl1_loss(preds, yb, mb, sample_weights=wb, beta=1.0)\n",
        "            scaler_amp.scale(loss).backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler_amp.step(opt); scaler_amp.update()\n",
        "            tr_loss += loss.item(); n_batches+=1\n",
        "        # validate\n",
        "        model.eval(); ys=[]; ps=[]; ms=[]\n",
        "        with torch.no_grad():\n",
        "            for xb, yb, mb, _, _ in dl_va:\n",
        "                xb=xb.to(DEVICE); yb=yb.to(DEVICE); mb=mb.to(DEVICE); lens = _lengths_from_x(xb)\n",
        "                preds = model(xb, lens)\n",
        "                ys.append(yb.cpu().numpy()); ps.append(preds.cpu().numpy()); ms.append(mb.cpu().numpy())\n",
        "        y_true = np.concatenate(ys, axis=0); y_pred = np.concatenate(ps, axis=0); m = np.concatenate(ms, axis=0).astype(bool)\n",
        "        # MCRMSE\n",
        "        rmses=[]\n",
        "        for t in range(y_true.shape[-1]):\n",
        "            diff = (y_pred[...,t]-y_true[...,t])[m]\n",
        "            rmse = float(np.sqrt(np.mean(diff**2))) if diff.size>0 else np.nan\n",
        "            rmses.append(rmse)\n",
        "        mcrmse = float(np.nanmean(rmses))\n",
        "        scheduler.step(mcrmse)\n",
        "        per_target_str = '[' + ', '.join(str(round(r,5)) for r in rmses) + ']'\n",
        "        print(f'Fold {fold} Epoch {ep}/{epochs} tr_loss={tr_loss/max(1,n_batches):.5f} val_MCRMSE={mcrmse:.5f} per-target={per_target_str} time_ep={time.time()-t0:.1f}s elapsed={time.time()-start:.1f}s', flush=True)\n",
        "        if mcrmse < best: best=mcrmse; best_state = {k:v.cpu() for k,v in model.state_dict().items()}\n",
        "    if best_state is not None: model.load_state_dict(best_state)\n",
        "    # OOF preds\n",
        "    model.eval(); ys=[]; ps=[]; ms=[]; va_ids=[]\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, mb, ids, _ in dl_va:\n",
        "            xb=xb.to(DEVICE); mb=mb.to(DEVICE); lens = _lengths_from_x(xb)\n",
        "            preds = model(xb, lens)\n",
        "            ys.append(yb.cpu().numpy()); ps.append(preds.cpu().numpy()); ms.append(mb.cpu().numpy()); va_ids.extend(ids)\n",
        "    oof_y = np.concatenate(ys, axis=0); oof_p = np.concatenate(ps, axis=0); oof_m = np.concatenate(ms, axis=0).astype(bool)\n",
        "    # Test preds with reverse TTA\n",
        "    test_preds = [] ; test_ids = []\n",
        "    with torch.no_grad():\n",
        "        for xb, mb, ids in dl_te:\n",
        "            xb=xb.to(DEVICE); mb=mb.to(DEVICE); lens = _lengths_from_x(xb)\n",
        "            preds_fwd = model(xb, lens)\n",
        "            xb_rev = xb.flip(1); lens_rev = lens  # same lengths\n",
        "            preds_rev = model(xb_rev, lens_rev).flip(1)\n",
        "            preds = 0.5*(preds_fwd + preds_rev)\n",
        "            test_preds.append(preds.cpu().numpy()); test_ids.extend(ids)\n",
        "    test_pred = np.concatenate(test_preds, axis=0)\n",
        "    return oof_y, oof_p, oof_m, va_ids, test_pred, test_ids, best\n",
        "\n",
        "print('Dataset/model utilities ready (engineered features + standardization + SmoothL1 + Conv1D + reverse TTA).')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset/model utilities ready (engineered features + standardization + SmoothL1 + Conv1D + reverse TTA).\n"
          ]
        }
      ]
    },
    {
      "id": "07a0cfe5-d941-4c70-a2ae-38dc7d8b099b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Orchestrate 5-fold training, aggregate OOF and test preds, and build submission\n",
        "import pandas as pd, numpy as np, time, os\n",
        "\n",
        "# Load data and folds\n",
        "try:\n",
        "    tr = pd.read_json('train.json')\n",
        "except ValueError:\n",
        "    tr = pd.read_json('train.json', lines=True)\n",
        "try:\n",
        "    te = pd.read_json('test.json')\n",
        "except ValueError:\n",
        "    te = pd.read_json('test.json', lines=True)\n",
        "folds_df = pd.read_csv('folds.csv')\n",
        "\n",
        "N_FOLDS = 5\n",
        "EPOCHS = 20  # increased for stronger training with engineered features\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "WD = 1e-4\n",
        "\n",
        "all_oof_true = []\n",
        "all_oof_pred = []\n",
        "all_oof_mask = []\n",
        "all_oof_ids = []\n",
        "test_pred_accum = None\n",
        "test_ids_ref = None\n",
        "fold_scores = []\n",
        "\n",
        "t0 = time.time()\n",
        "for fold in range(N_FOLDS):\n",
        "    print(f'===== Fold {fold} / {N_FOLDS} =====', flush=True)\n",
        "    oof_y, oof_p, oof_m, va_ids, te_pred, te_ids, best = run_fold(\n",
        "        fold, tr, te, folds_df, epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR, wd=WD, use_amp=True\n",
        "    )\n",
        "    # compute fold MCRMSE\n",
        "    m = oof_m.astype(bool)\n",
        "    rmses=[]\n",
        "    for t in range(oof_y.shape[-1]):\n",
        "        diff = (oof_p[...,t]-oof_y[...,t])[m]\n",
        "        rmse = float(np.sqrt(np.mean(diff**2))) if diff.size>0 else np.nan\n",
        "        rmses.append(rmse)\n",
        "    mcrmse = float(np.nanmean(rmses))\n",
        "    fold_scores.append(mcrmse)\n",
        "    print(f'Fold {fold} best_val_MCRMSE={best:.5f} OOF_MCRMSE={mcrmse:.5f} per-target={[round(r,5) for r in rmses]}', flush=True)\n",
        "    all_oof_true.append(oof_y); all_oof_pred.append(oof_p); all_oof_mask.append(oof_m); all_oof_ids.extend(va_ids)\n",
        "    # accumulate test preds (align by te_ids order)\n",
        "    if test_pred_accum is None:\n",
        "        test_pred_accum = te_pred.copy()\n",
        "        test_ids_ref = te_ids\n",
        "    else:\n",
        "        # ensure same order\n",
        "        assert test_ids_ref == te_ids, 'Test id order mismatch across folds'\n",
        "        test_pred_accum += te_pred\n",
        "\n",
        "print('Fold scores:', fold_scores, 'mean:', float(np.nanmean(fold_scores)))\n",
        "\n",
        "# Average test predictions across folds\n",
        "test_pred_mean = test_pred_accum / N_FOLDS\n",
        "print('Test pred shape:', test_pred_mean.shape)\n",
        "\n",
        "# Build submission by merging onto sample_submission order\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "# Map test id to row index in te dataframe to access its prediction row\n",
        "id_to_idx = {idv:i for i, idv in enumerate(test_ids_ref)}\n",
        "targets = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']\n",
        "\n",
        "def parse_id_seqpos(x):\n",
        "    s, pos = x.rsplit('_', 1)\n",
        "    return s, int(pos)\n",
        "\n",
        "ids = []\n",
        "pos = []\n",
        "for v in ss['id_seqpos'].values:\n",
        "    i, p = parse_id_seqpos(v)\n",
        "    ids.append(i); pos.append(p)\n",
        "ss['_id'] = ids; ss['_pos'] = pos\n",
        "\n",
        "for t_i, t in enumerate(targets):\n",
        "    vals = []\n",
        "    for i, p in zip(ss['_id'].values, ss['_pos'].values):\n",
        "        idx = id_to_idx[i]\n",
        "        vals.append(float(test_pred_mean[idx, p, t_i]))\n",
        "    ss[t] = vals\n",
        "\n",
        "ss.drop(columns=['_id','_pos'], inplace=True)\n",
        "ss.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv with shape:', ss.shape)\n",
        "\n",
        "# Compute overall OOF MCRMSE\n",
        "oof_y_full = np.concatenate(all_oof_true, axis=0)\n",
        "oof_p_full = np.concatenate(all_oof_pred, axis=0)\n",
        "oof_m_full = np.concatenate(all_oof_mask, axis=0).astype(bool)\n",
        "rmses=[]\n",
        "for t in range(oof_y_full.shape[-1]):\n",
        "    diff = (oof_p_full[...,t]-oof_y_full[...,t])[oof_m_full]\n",
        "    rmse = float(np.sqrt(np.mean(diff**2))) if diff.size>0 else np.nan\n",
        "    rmses.append(rmse)\n",
        "mcrmse = float(np.nanmean(rmses))\n",
        "print(f'OOF MCRMSE={mcrmse:.5f} per-target={[round(r,5) for r in rmses]} total_time={time.time()-t0:.1f}s')\n",
        "\n",
        "print('Done. Next: consider adding BPP features and reverse TTA to improve scores.')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 0 / 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n/tmp/ipykernel_196/502443009.py:257: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler_amp = torch.cuda.amp.GradScaler(enabled=use_amp and DEVICE=='cuda')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1/20 tr_loss=0.51085 val_MCRMSE=0.92862 per-target=[0.67074, 0.69005, 1.28625, 0.88451, 1.11155] time_ep=1.7s elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2/20 tr_loss=0.40382 val_MCRMSE=0.91585 per-target=[0.65898, 0.67288, 1.26874, 0.87228, 1.10636] time_ep=1.6s elapsed=3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3/20 tr_loss=0.38127 val_MCRMSE=0.90645 per-target=[0.65106, 0.65795, 1.25803, 0.86288, 1.10235] time_ep=1.6s elapsed=4.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4/20 tr_loss=0.36253 val_MCRMSE=0.89826 per-target=[0.64627, 0.64102, 1.25088, 0.8542, 1.09891] time_ep=1.6s elapsed=6.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5/20 tr_loss=0.34706 val_MCRMSE=0.89244 per-target=[0.64385, 0.63046, 1.2471, 0.84525, 1.09555] time_ep=1.6s elapsed=8.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6/20 tr_loss=0.33905 val_MCRMSE=0.89179 per-target=[0.64342, 0.62961, 1.24624, 0.84501, 1.09465] time_ep=1.6s elapsed=9.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7/20 tr_loss=0.33453 val_MCRMSE=0.88966 per-target=[0.64127, 0.6265, 1.24456, 0.84262, 1.09333] time_ep=1.6s elapsed=11.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8/20 tr_loss=0.32971 val_MCRMSE=0.88885 per-target=[0.64043, 0.62524, 1.24457, 0.84119, 1.09282] time_ep=1.6s elapsed=13.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9/20 tr_loss=0.32711 val_MCRMSE=0.88758 per-target=[0.6389, 0.62364, 1.24292, 0.8403, 1.09216] time_ep=1.6s elapsed=14.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 10/20 tr_loss=0.32342 val_MCRMSE=0.88594 per-target=[0.63785, 0.62098, 1.24222, 0.83769, 1.09096] time_ep=1.6s elapsed=16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 11/20 tr_loss=0.32138 val_MCRMSE=0.88633 per-target=[0.63799, 0.62166, 1.24163, 0.83925, 1.09111] time_ep=1.6s elapsed=17.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 12/20 tr_loss=0.32051 val_MCRMSE=0.88428 per-target=[0.63727, 0.61827, 1.24026, 0.83618, 1.0894] time_ep=1.6s elapsed=19.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 13/20 tr_loss=0.31701 val_MCRMSE=0.88388 per-target=[0.6354, 0.61779, 1.2403, 0.83675, 1.08914] time_ep=1.6s elapsed=21.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 14/20 tr_loss=0.31452 val_MCRMSE=0.88270 per-target=[0.63515, 0.61649, 1.23905, 0.83415, 1.08868] time_ep=1.7s elapsed=22.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 15/20 tr_loss=0.31170 val_MCRMSE=0.88287 per-target=[0.63435, 0.61698, 1.23924, 0.83566, 1.08812] time_ep=1.9s elapsed=24.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 16/20 tr_loss=0.30897 val_MCRMSE=0.88185 per-target=[0.63428, 0.61598, 1.23776, 0.83367, 1.08755] time_ep=1.7s elapsed=26.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 17/20 tr_loss=0.30751 val_MCRMSE=0.87929 per-target=[0.63185, 0.61141, 1.23646, 0.83092, 1.0858] time_ep=1.6s elapsed=28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 18/20 tr_loss=0.30406 val_MCRMSE=0.87942 per-target=[0.63271, 0.61187, 1.23589, 0.83101, 1.0856] time_ep=1.6s elapsed=29.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 19/20 tr_loss=0.30252 val_MCRMSE=0.87758 per-target=[0.63068, 0.60897, 1.23472, 0.8291, 1.08446] time_ep=1.6s elapsed=31.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 20/20 tr_loss=0.30118 val_MCRMSE=0.87828 per-target=[0.63152, 0.61001, 1.23496, 0.82997, 1.08496] time_ep=1.6s elapsed=32.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 best_val_MCRMSE=0.87758 OOF_MCRMSE=0.87758 per-target=[0.63068, 0.60897, 1.23472, 0.8291, 1.08446]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 1 / 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 1/20 tr_loss=0.50783 val_MCRMSE=0.90326 per-target=[0.66619, 0.68628, 1.19572, 0.78906, 1.17906] time_ep=1.7s elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 2/20 tr_loss=0.41065 val_MCRMSE=0.88989 per-target=[0.65052, 0.67053, 1.17806, 0.77648, 1.17388] time_ep=1.6s elapsed=3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 3/20 tr_loss=0.38421 val_MCRMSE=0.87952 per-target=[0.64074, 0.65444, 1.16716, 0.76602, 1.16925] time_ep=1.6s elapsed=4.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 4/20 tr_loss=0.36266 val_MCRMSE=0.87066 per-target=[0.63506, 0.63709, 1.1602, 0.75549, 1.16545] time_ep=1.6s elapsed=6.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 5/20 tr_loss=0.34713 val_MCRMSE=0.86677 per-target=[0.63378, 0.62857, 1.15775, 0.74962, 1.16413] time_ep=1.6s elapsed=8.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 6/20 tr_loss=0.33974 val_MCRMSE=0.86542 per-target=[0.63266, 0.62651, 1.15711, 0.74803, 1.1628] time_ep=1.6s elapsed=9.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 7/20 tr_loss=0.33606 val_MCRMSE=0.86428 per-target=[0.63172, 0.62516, 1.15575, 0.74604, 1.16271] time_ep=1.7s elapsed=11.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 8/20 tr_loss=0.33284 val_MCRMSE=0.86334 per-target=[0.63111, 0.62337, 1.15501, 0.74547, 1.16171] time_ep=1.7s elapsed=13.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 9/20 tr_loss=0.33173 val_MCRMSE=0.86274 per-target=[0.62956, 0.62238, 1.15494, 0.74494, 1.16189] time_ep=2.0s elapsed=15.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 10/20 tr_loss=0.32728 val_MCRMSE=0.86175 per-target=[0.62837, 0.62125, 1.15397, 0.74339, 1.16176] time_ep=2.2s elapsed=17.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 11/20 tr_loss=0.32440 val_MCRMSE=0.86017 per-target=[0.62706, 0.61846, 1.15285, 0.74204, 1.16043] time_ep=1.7s elapsed=19.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 12/20 tr_loss=0.32151 val_MCRMSE=0.86020 per-target=[0.62708, 0.61971, 1.1526, 0.74138, 1.16022] time_ep=1.7s elapsed=20.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 13/20 tr_loss=0.31869 val_MCRMSE=0.85905 per-target=[0.62667, 0.61697, 1.15135, 0.74088, 1.15937] time_ep=1.7s elapsed=22.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 14/20 tr_loss=0.31600 val_MCRMSE=0.85950 per-target=[0.62703, 0.61823, 1.15144, 0.74088, 1.15994] time_ep=1.7s elapsed=24.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 15/20 tr_loss=0.31417 val_MCRMSE=0.85723 per-target=[0.62541, 0.61427, 1.14974, 0.73874, 1.158] time_ep=1.7s elapsed=25.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 16/20 tr_loss=0.31166 val_MCRMSE=0.85601 per-target=[0.62411, 0.61302, 1.14933, 0.73598, 1.15759] time_ep=1.6s elapsed=27.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 17/20 tr_loss=0.30909 val_MCRMSE=0.85581 per-target=[0.62414, 0.612, 1.1498, 0.7354, 1.15772] time_ep=1.7s elapsed=29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 18/20 tr_loss=0.30781 val_MCRMSE=0.85568 per-target=[0.62403, 0.61181, 1.14896, 0.7361, 1.15748] time_ep=1.7s elapsed=30.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 19/20 tr_loss=0.30543 val_MCRMSE=0.85458 per-target=[0.62376, 0.61004, 1.14804, 0.73478, 1.15627] time_ep=1.6s elapsed=32.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 20/20 tr_loss=0.30426 val_MCRMSE=0.85327 per-target=[0.62234, 0.6071, 1.14723, 0.73367, 1.15601] time_ep=1.7s elapsed=34.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 best_val_MCRMSE=0.85327 OOF_MCRMSE=0.85327 per-target=[0.62234, 0.6071, 1.14723, 0.73367, 1.15601]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 2 / 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 1/20 tr_loss=0.50759 val_MCRMSE=0.88423 per-target=[0.69684, 0.66298, 1.22714, 0.80654, 1.02763] time_ep=1.6s elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 2/20 tr_loss=0.40464 val_MCRMSE=0.87333 per-target=[0.68665, 0.64785, 1.20921, 0.7989, 1.02405] time_ep=1.6s elapsed=3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 3/20 tr_loss=0.38138 val_MCRMSE=0.86607 per-target=[0.68286, 0.63566, 1.20072, 0.79007, 1.02105] time_ep=1.7s elapsed=4.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 4/20 tr_loss=0.36436 val_MCRMSE=0.85875 per-target=[0.67912, 0.62112, 1.19348, 0.78177, 1.01824] time_ep=1.6s elapsed=6.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 5/20 tr_loss=0.35152 val_MCRMSE=0.85414 per-target=[0.67607, 0.6134, 1.1902, 0.77545, 1.01557] time_ep=1.7s elapsed=8.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 6/20 tr_loss=0.34415 val_MCRMSE=0.85395 per-target=[0.67729, 0.61222, 1.18935, 0.77538, 1.01553] time_ep=1.6s elapsed=10.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 7/20 tr_loss=0.33975 val_MCRMSE=0.85200 per-target=[0.67455, 0.60981, 1.18857, 0.77314, 1.01393] time_ep=1.7s elapsed=11.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 8/20 tr_loss=0.33622 val_MCRMSE=0.85062 per-target=[0.67329, 0.60791, 1.18817, 0.77103, 1.01272] time_ep=1.7s elapsed=13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 9/20 tr_loss=0.33327 val_MCRMSE=0.84966 per-target=[0.67256, 0.60691, 1.18533, 0.7707, 1.01282] time_ep=1.6s elapsed=15.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 10/20 tr_loss=0.32995 val_MCRMSE=0.84713 per-target=[0.67081, 0.60283, 1.1843, 0.76725, 1.01046] time_ep=1.6s elapsed=16.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 11/20 tr_loss=0.32662 val_MCRMSE=0.84609 per-target=[0.66983, 0.60187, 1.18275, 0.76608, 1.00989] time_ep=1.7s elapsed=18.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 12/20 tr_loss=0.32493 val_MCRMSE=0.84511 per-target=[0.66848, 0.59969, 1.18251, 0.76521, 1.00965] time_ep=1.7s elapsed=19.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 13/20 tr_loss=0.32263 val_MCRMSE=0.84405 per-target=[0.66786, 0.59869, 1.18116, 0.76415, 1.00838] time_ep=1.6s elapsed=21.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 14/20 tr_loss=0.32021 val_MCRMSE=0.84427 per-target=[0.66807, 0.59823, 1.18113, 0.76442, 1.00949] time_ep=1.6s elapsed=23.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 15/20 tr_loss=0.31778 val_MCRMSE=0.84297 per-target=[0.6665, 0.59677, 1.18, 0.7634, 1.00819] time_ep=1.7s elapsed=24.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 16/20 tr_loss=0.31563 val_MCRMSE=0.84167 per-target=[0.66524, 0.5951, 1.17898, 0.76148, 1.00753] time_ep=1.6s elapsed=26.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 17/20 tr_loss=0.31371 val_MCRMSE=0.84096 per-target=[0.6648, 0.59325, 1.17864, 0.76168, 1.00644] time_ep=1.7s elapsed=28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 18/20 tr_loss=0.31210 val_MCRMSE=0.83968 per-target=[0.66352, 0.59186, 1.17738, 0.75981, 1.0058] time_ep=1.7s elapsed=29.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 19/20 tr_loss=0.30965 val_MCRMSE=0.83859 per-target=[0.66287, 0.58975, 1.17682, 0.75815, 1.00538] time_ep=1.6s elapsed=31.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 20/20 tr_loss=0.30827 val_MCRMSE=0.83932 per-target=[0.66475, 0.59064, 1.17636, 0.75967, 1.00516] time_ep=1.6s elapsed=33.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 best_val_MCRMSE=0.83859 OOF_MCRMSE=0.83859 per-target=[0.66287, 0.58975, 1.17682, 0.75815, 1.00538]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 3 / 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 1/20 tr_loss=0.50378 val_MCRMSE=1.02185 per-target=[0.74329, 0.7111, 1.4657, 0.93761, 1.25153] time_ep=1.6s elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 2/20 tr_loss=0.39808 val_MCRMSE=1.00971 per-target=[0.73049, 0.69632, 1.44888, 0.92693, 1.2459] time_ep=1.7s elapsed=3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 3/20 tr_loss=0.37798 val_MCRMSE=1.00252 per-target=[0.72607, 0.68441, 1.43958, 0.91928, 1.24328] time_ep=1.7s elapsed=5.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 4/20 tr_loss=0.35886 val_MCRMSE=0.99726 per-target=[0.72349, 0.67317, 1.43515, 0.91284, 1.24163] time_ep=1.7s elapsed=6.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 5/20 tr_loss=0.34356 val_MCRMSE=0.99162 per-target=[0.72205, 0.66145, 1.42878, 0.90667, 1.23913] time_ep=1.6s elapsed=8.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 6/20 tr_loss=0.33408 val_MCRMSE=0.98912 per-target=[0.71928, 0.65783, 1.42786, 0.90307, 1.23754] time_ep=1.6s elapsed=9.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 7/20 tr_loss=0.32911 val_MCRMSE=0.98776 per-target=[0.71815, 0.65559, 1.42699, 0.90151, 1.23656] time_ep=1.7s elapsed=11.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 8/20 tr_loss=0.32453 val_MCRMSE=0.98653 per-target=[0.7171, 0.65361, 1.42609, 0.90003, 1.23579] time_ep=1.6s elapsed=13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 9/20 tr_loss=0.32178 val_MCRMSE=0.98590 per-target=[0.7169, 0.65243, 1.42579, 0.89907, 1.23532] time_ep=1.7s elapsed=14.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 10/20 tr_loss=0.31886 val_MCRMSE=0.98607 per-target=[0.71579, 0.65238, 1.42726, 0.89892, 1.23597] time_ep=1.7s elapsed=16.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 11/20 tr_loss=0.31639 val_MCRMSE=0.98504 per-target=[0.71581, 0.6517, 1.42393, 0.89902, 1.23473] time_ep=1.7s elapsed=18.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 12/20 tr_loss=0.31460 val_MCRMSE=0.98351 per-target=[0.71475, 0.64901, 1.42377, 0.89627, 1.23377] time_ep=1.7s elapsed=19.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 13/20 tr_loss=0.31141 val_MCRMSE=0.98198 per-target=[0.71381, 0.64654, 1.42222, 0.8949, 1.23242] time_ep=1.7s elapsed=21.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 14/20 tr_loss=0.30819 val_MCRMSE=0.98012 per-target=[0.71158, 0.64378, 1.42076, 0.89303, 1.23145] time_ep=1.6s elapsed=23.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 15/20 tr_loss=0.30567 val_MCRMSE=0.97972 per-target=[0.71162, 0.64353, 1.41977, 0.89252, 1.23119] time_ep=1.6s elapsed=24.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 16/20 tr_loss=0.30372 val_MCRMSE=0.97905 per-target=[0.71088, 0.64193, 1.42061, 0.89105, 1.23078] time_ep=1.7s elapsed=26.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 17/20 tr_loss=0.30021 val_MCRMSE=0.97836 per-target=[0.71047, 0.6408, 1.41964, 0.89059, 1.23031] time_ep=1.7s elapsed=28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 18/20 tr_loss=0.29998 val_MCRMSE=0.97901 per-target=[0.71206, 0.64282, 1.41912, 0.89087, 1.23018] time_ep=1.6s elapsed=29.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 19/20 tr_loss=0.29789 val_MCRMSE=0.97666 per-target=[0.70901, 0.63791, 1.41909, 0.88885, 1.22841] time_ep=1.6s elapsed=31.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 20/20 tr_loss=0.29532 val_MCRMSE=0.97609 per-target=[0.70899, 0.63708, 1.41783, 0.88773, 1.22881] time_ep=1.7s elapsed=33.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 best_val_MCRMSE=0.97609 OOF_MCRMSE=0.97609 per-target=[0.70899, 0.63708, 1.41783, 0.88773, 1.22881]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 4 / 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 1/20 tr_loss=0.49804 val_MCRMSE=0.95594 per-target=[0.73223, 0.67484, 1.33571, 0.87283, 1.16411] time_ep=1.7s elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 2/20 tr_loss=0.40235 val_MCRMSE=0.94718 per-target=[0.72487, 0.66295, 1.32261, 0.86427, 1.1612] time_ep=1.6s elapsed=3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 3/20 tr_loss=0.37977 val_MCRMSE=0.93897 per-target=[0.71835, 0.64843, 1.31486, 0.85532, 1.1579] time_ep=1.6s elapsed=4.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 4/20 tr_loss=0.35885 val_MCRMSE=0.93274 per-target=[0.71627, 0.63472, 1.30976, 0.84791, 1.15504] time_ep=1.6s elapsed=6.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 5/20 tr_loss=0.34607 val_MCRMSE=0.93034 per-target=[0.71546, 0.6298, 1.30885, 0.84389, 1.15369] time_ep=1.6s elapsed=8.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 6/20 tr_loss=0.33951 val_MCRMSE=0.92848 per-target=[0.71306, 0.6276, 1.30694, 0.84216, 1.15264] time_ep=1.6s elapsed=9.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 7/20 tr_loss=0.33650 val_MCRMSE=0.92807 per-target=[0.71346, 0.62658, 1.30655, 0.84145, 1.15233] time_ep=1.7s elapsed=11.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 8/20 tr_loss=0.33324 val_MCRMSE=0.92737 per-target=[0.71246, 0.62554, 1.30588, 0.84078, 1.15218] time_ep=1.6s elapsed=13.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 9/20 tr_loss=0.33027 val_MCRMSE=0.92623 per-target=[0.71054, 0.62377, 1.30628, 0.83928, 1.15126] time_ep=1.7s elapsed=14.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 10/20 tr_loss=0.32863 val_MCRMSE=0.92667 per-target=[0.71196, 0.62369, 1.3051, 0.84039, 1.15222] time_ep=1.6s elapsed=16.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 11/20 tr_loss=0.32585 val_MCRMSE=0.92396 per-target=[0.70887, 0.62065, 1.30332, 0.83737, 1.14958] time_ep=1.7s elapsed=18.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 12/20 tr_loss=0.32271 val_MCRMSE=0.92408 per-target=[0.70902, 0.62029, 1.30357, 0.8374, 1.15012] time_ep=1.7s elapsed=19.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 13/20 tr_loss=0.32101 val_MCRMSE=0.92198 per-target=[0.70752, 0.61716, 1.30076, 0.8358, 1.14867] time_ep=1.6s elapsed=21.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 14/20 tr_loss=0.31747 val_MCRMSE=0.92126 per-target=[0.70577, 0.61621, 1.30104, 0.83537, 1.14792] time_ep=1.6s elapsed=23.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 15/20 tr_loss=0.31456 val_MCRMSE=0.92023 per-target=[0.70506, 0.61467, 1.3004, 0.83378, 1.14723] time_ep=1.6s elapsed=24.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 16/20 tr_loss=0.31284 val_MCRMSE=0.91981 per-target=[0.70475, 0.61371, 1.29932, 0.83418, 1.14709] time_ep=1.7s elapsed=26.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 17/20 tr_loss=0.31039 val_MCRMSE=0.91913 per-target=[0.70442, 0.61278, 1.29894, 0.83295, 1.14654] time_ep=1.7s elapsed=28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 18/20 tr_loss=0.30794 val_MCRMSE=0.91841 per-target=[0.70403, 0.61184, 1.29845, 0.83202, 1.14571] time_ep=1.7s elapsed=29.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 19/20 tr_loss=0.30789 val_MCRMSE=0.91808 per-target=[0.70334, 0.61112, 1.29839, 0.83162, 1.14593] time_ep=1.6s elapsed=31.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 20/20 tr_loss=0.30603 val_MCRMSE=0.91724 per-target=[0.70284, 0.61073, 1.29717, 0.83062, 1.14483] time_ep=1.7s elapsed=33.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 best_val_MCRMSE=0.91724 OOF_MCRMSE=0.91724 per-target=[0.70284, 0.61073, 1.29717, 0.83062, 1.14483]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold scores: [0.8775848388671875, 0.8532713294029236, 0.8385927438735962, 0.976087236404419, 0.917236077785492] mean: 0.8925544452667236\nTest pred shape: (240, 107, 5)\nWrote submission.csv with shape: (25680, 6)\nOOF MCRMSE=0.89440 per-target=[0.6665, 0.61091, 1.25845, 0.80975, 1.12639] total_time=179.1s\nDone. Next: consider adding BPP features and reverse TTA to improve scores.\n"
          ]
        }
      ]
    },
    {
      "id": "f0359c0d-1829-4994-84f9-78af66fb0ce3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install ViennaRNA (RNAplfold), compute BPP features for all ids, and cache per-position aggregates\n",
        "import os, sys, time, math, json, shutil, subprocess\n",
        "import numpy as np, pandas as pd\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from pathlib import Path\n",
        "\n",
        "def sh(cmd):\n",
        "    print(f\"$ {cmd}\", flush=True)\n",
        "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    print(p.stdout)\n",
        "    return p.returncode\n",
        "\n",
        "start = time.time()\n",
        "print('== Install ViennaRNA (RNAplfold) ==', flush=True)\n",
        "rc = sh('apt-get update -qq && apt-get install -y -qq viennarna')\n",
        "if rc != 0:\n",
        "    print('APT install failed; trying pip ViennaRNAx (fallback).', flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'ViennaRNAx'], check=True)\n",
        "print('RNAplfold version/help:')\n",
        "sh('RNAplfold -h || true')\n",
        "\n",
        "# Load train/test and collect sequences\n",
        "try:\n",
        "    tr = pd.read_json('train.json')\n",
        "except ValueError:\n",
        "    tr = pd.read_json('train.json', lines=True)\n",
        "try:\n",
        "    te = pd.read_json('test.json')\n",
        "except ValueError:\n",
        "    te = pd.read_json('test.json', lines=True)\n",
        "\n",
        "all_df = pd.concat([tr[['id','sequence']], te[['id','sequence']]], ignore_index=True)\n",
        "ids = all_df['id'].tolist()\n",
        "seqs = all_df['sequence'].tolist()\n",
        "\n",
        "work_root = Path('plfold_work'); work_root.mkdir(exist_ok=True)\n",
        "out_root = Path('plfold_out'); out_root.mkdir(exist_ok=True)\n",
        "feat_root = Path('bpp_features'); feat_root.mkdir(exist_ok=True)\n",
        "\n",
        "def run_plfold(one):\n",
        "    idv, seq = one\n",
        "    d = work_root / idv\n",
        "    out_dp = out_root / f'{idv}_dp.ps'\n",
        "    out_lunp = out_root / f'{idv}_lunp'\n",
        "    if out_dp.exists() and out_lunp.exists():\n",
        "        return idv, True\n",
        "    if d.exists():\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "    fasta = d / f'{idv}.fa'\n",
        "    fasta.write_text(f'>{idv}\\n{seq}\\n')\n",
        "    env = os.environ.copy()\n",
        "    env['OMP_NUM_THREADS'] = '1'\n",
        "    cmd = f'RNAplfold -W 150 -L 120 -u 3 -noLP < {fasta.name}'\n",
        "    p = subprocess.run(cmd, shell=True, cwd=str(d), env=env, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        return idv, False\n",
        "    # Move outputs\n",
        "    dp_src = d / 'plfold_dp.ps'\n",
        "    lunp_src = d / 'plfold_lunp'\n",
        "    if dp_src.exists():\n",
        "        shutil.move(str(dp_src), str(out_dp))\n",
        "    if lunp_src.exists():\n",
        "        shutil.move(str(lunp_src), str(out_lunp))\n",
        "    shutil.rmtree(d, ignore_errors=True)\n",
        "    return idv, (out_dp.exists() and out_lunp.exists())\n",
        "\n",
        "print('== Running RNAplfold in parallel ==', flush=True)\n",
        "ok = 0; fail = 0; t0 = time.time()\n",
        "with ThreadPoolExecutor(max_workers=min(16, os.cpu_count() or 8)) as ex:\n",
        "    futures = {ex.submit(run_plfold, item): item[0] for item in zip(ids, seqs)}\n",
        "    for i, fut in enumerate(as_completed(futures), 1):\n",
        "        idv = futures[fut]\n",
        "        try:\n",
        "            _, success = fut.result()\n",
        "            if success: ok += 1\n",
        "            else: fail += 1\n",
        "        except Exception:\n",
        "            fail += 1\n",
        "        if i % 100 == 0 or i == len(futures):\n",
        "            print(f'Processed {i}/{len(futures)} ok={ok} fail={fail} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "\n",
        "def parse_lunp(path):\n",
        "    # Returns pu1 (unpaired prob for u=1) per position, length L\n",
        "    lines = Path(path).read_text().strip().splitlines()\n",
        "    vals = []\n",
        "    # Try two formats: with leading position index or not\n",
        "    for ln in lines:\n",
        "        parts = ln.strip().split()\n",
        "        if not parts: continue\n",
        "        # Expect at least pu1 present\n",
        "        if len(parts) == 1:\n",
        "            # Single column unlikely; treat as pu1\n",
        "            vals.append(float(parts[0]))\n",
        "        else:\n",
        "            # If first token is integer index\n",
        "            try:\n",
        "                int(parts[0]); has_idx = True\n",
        "            except ValueError:\n",
        "                has_idx = False\n",
        "            pu1 = float(parts[1] if has_idx else parts[0])\n",
        "            vals.append(pu1)\n",
        "    return np.array(vals, dtype=np.float32)\n",
        "\n",
        "def parse_dp_ps(path, L):\n",
        "    # Build LxL probability matrix from _dp.ps; lines like: i j p_sqrt ubox\n",
        "    P = np.zeros((L, L), dtype=np.float32)\n",
        "    for ln in Path(path).read_text().splitlines():\n",
        "        ln = ln.strip()\n",
        "        if not ln or ln.startswith('%'):\n",
        "            continue\n",
        "        parts = ln.split()\n",
        "        if len(parts) >= 4 and parts[-1] == 'ubox':\n",
        "            try:\n",
        "                i = int(parts[0]) - 1\n",
        "                j = int(parts[1]) - 1\n",
        "                psqrt = float(parts[2])\n",
        "            except Exception:\n",
        "                continue\n",
        "            p = psqrt * psqrt\n",
        "            if 0 <= i < L and 0 <= j < L:\n",
        "                P[i, j] = max(P[i, j], p)\n",
        "                P[j, i] = max(P[j, i], p)\n",
        "    return P\n",
        "\n",
        "def build_features(P, pu1):\n",
        "    L = P.shape[0]\n",
        "    eps = 1e-8\n",
        "    row_sum = P.sum(axis=1)  # [L]\n",
        "    row_max = P.max(axis=1)\n",
        "    # entropy on normalized rows\n",
        "    Q = P / (row_sum[:, None] + eps)\n",
        "    entropy = -(Q * (np.log(Q + eps))).sum(axis=1)\n",
        "    # expected distance normalized\n",
        "    idx = np.arange(L, dtype=np.float32)\n",
        "    D = np.abs(idx[None, :] - idx[:, None])\n",
        "    exp_dist = (P * D).sum(axis=1) / (row_sum + eps) / max(1.0, (L - 1))\n",
        "    # local mass windows\n",
        "    feats = [row_sum, row_max, entropy, exp_dist]\n",
        "    for k in (3, 7, 15):\n",
        "        mask = (D <= k).astype(np.float32)\n",
        "        lm = (P * mask).sum(axis=1)\n",
        "        feats.append(lm)\n",
        "    # append pu1 and pairedness\n",
        "    pu1 = pu1.astype(np.float32)\n",
        "    if pu1.shape[0] != L:\n",
        "        # pad or trim\n",
        "        pu1_fix = np.zeros((L,), dtype=np.float32)\n",
        "        m = min(L, pu1.shape[0])\n",
        "        pu1_fix[:m] = pu1[:m]\n",
        "        pu1 = pu1_fix\n",
        "    paired = 1.0 - pu1\n",
        "    feats.append(pu1); feats.append(paired)\n",
        "    X = np.stack(feats, axis=1).astype(np.float32)  # [L, C]\n",
        "    return X\n",
        "\n",
        "print('== Parsing RNAplfold outputs and caching features ==', flush=True)\n",
        "n_done = 0\n",
        "for idv, seq in zip(ids, seqs):\n",
        "    npy_out = feat_root / f'{idv}.npy'\n",
        "    if npy_out.exists():\n",
        "        n_done += 1; continue\n",
        "    dp = out_root / f'{idv}_dp.ps'\n",
        "    lunp = out_root / f'{idv}_lunp'\n",
        "    if not (dp.exists() and lunp.exists()):\n",
        "        # missing outputs; write zeros as fallback\n",
        "        L = len(seq)\n",
        "        np.save(npy_out, np.zeros((L, 10), dtype=np.float32))\n",
        "        continue\n",
        "    L = len(seq)\n",
        "    P = parse_dp_ps(dp, L)\n",
        "    pu1 = parse_lunp(lunp)\n",
        "    X = build_features(P, pu1)  # [L, ~10]\n",
        "    np.save(npy_out, X)\n",
        "    n_done += 1\n",
        "    if n_done % 200 == 0:\n",
        "        print(f'Cached {n_done}/{len(ids)} feature arrays...', flush=True)\n",
        "\n",
        "print(f'Done BPP features. Cached {n_done} arrays. Total time {time.time()-start:.1f}s', flush=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Install ViennaRNA (RNAplfold) ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ apt-get update -qq && apt-get install -y -qq viennarna\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: List directory /var/lib/apt/lists/partial is missing. - Acquire (30: Read-only file system)\n\nAPT install failed; trying pip ViennaRNAx (fallback).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement ViennaRNAx (from versions: none)\nERROR: No matching distribution found for ViennaRNAx\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command '['/usr/bin/python3.11', '-m', 'pip', 'install', 'ViennaRNAx']' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m rc != \u001b[32m0\u001b[39m:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mAPT install failed; trying pip ViennaRNAx (fallback).\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-m\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpip\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minstall\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mViennaRNAx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mRNAplfold version/help:\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     20\u001b[39m sh(\u001b[33m'\u001b[39m\u001b[33mRNAplfold -h || true\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/subprocess.py:569\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    567\u001b[39m     retcode = process.poll()\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process.args,\n\u001b[32m    570\u001b[39m                                  output=stdout, stderr=stderr)\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process.args, retcode, stdout, stderr)\n",
            "\u001b[31mCalledProcessError\u001b[39m: Command '['/usr/bin/python3.11', '-m', 'pip', 'install', 'ViennaRNAx']' returned non-zero exit status 1."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}