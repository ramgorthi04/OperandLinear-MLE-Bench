{
  "cells": [
    {
      "id": "64390f1d-fc2f-4cb7-9eec-94e45b814add",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan\n",
        "- Goal: Win a medal (AUC-ROC).\n",
        "- Steps:\n",
        "  1) Inspect provided artifacts: sampleSubmission.csv, train2.zip, test2.zip.\n",
        "  2) Determine data format (tabular, images, audio, features).\n",
        "  3) Parse/prepare training/test data.\n",
        "  4) Baseline model with fast CV (StratifiedKFold, strong classifiers e.g., LightGBM/XGBoost/CatBoost).\n",
        "  5) Iterate with feature engineering and model ensembling.\n",
        "  6) Generate submission.csv and evaluate with CV.\n",
        "\n",
        "## Immediate next actions\n",
        "- Preview zips (list contents), sampleSubmission columns/shape, and infer target/ids.\n",
        "- If zips contain precomputed features, load them; else extract and build minimal features quickly.\n",
        "\n",
        "## Logging\n",
        "- Print progress and timings in loops.\n",
        "\n",
        "## Checkpoints\n",
        "- After data inspection: request expert review for data strategy.\n",
        "- After baseline CV: request expert review for improvements.\n",
        "\n",
        "## Assumptions\n",
        "- Prepared artifacts likely include ready-to-train tabular features or spectrogram features.\n",
        "- Keep runtime efficient; avoid heavy DL unless necessary.\n",
        "\n",
        "----"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "acbda5ef-3c95-48fb-95a4-f654cfcf260b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, zipfile, pandas as pd, time\n",
        "from pathlib import Path\n",
        "\n",
        "print('CWD:', os.getcwd())\n",
        "print('Files in CWD:')\n",
        "for p in Path('.').iterdir():\n",
        "    print('-', p.name, p.stat().st_size//1024, 'KB')\n",
        "\n",
        "print('\\nReading sampleSubmission.csv...')\n",
        "sub = pd.read_csv('sampleSubmission.csv')\n",
        "print(sub.shape)\n",
        "print(sub.head())\n",
        "print(sub.columns.tolist())\n",
        "\n",
        "def list_zip(zpath, max_items=20):\n",
        "    print(f'\\nListing {zpath} ...')\n",
        "    with zipfile.ZipFile(zpath) as z:\n",
        "        infos = z.infolist()\n",
        "        print('n_files:', len(infos))\n",
        "        for i, info in enumerate(infos[:max_items]):\n",
        "            print(f'{i:3d}:', info.filename, info.file_size//1024, 'KB')\n",
        "        if len(infos) > max_items:\n",
        "            print('...')\n",
        "\n",
        "list_zip('train2.zip')\n",
        "list_zip('test2.zip')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CWD: /app/agent_run_states/the-icml-2013-whale-challenge-right-whale-redux-spray-20250911-051236\nFiles in CWD:\n- test2.zip 104741 KB\n- train2.zip 93044 KB\n- main.ipynb 3 KB\n- agent_metadata 4 KB\n- requirements.txt 1 KB\n- task.txt 2 KB\n- sampleSubmission.csv 1017 KB\n- docker_run.log 13 KB\n- description.md 3 KB\n\nReading sampleSubmission.csv...\n(25149, 2)\n                                clip  probability\n0  20090330_000000_015s2ms_Test0.aif            0\n1  20090330_000000_020s0ms_Test1.aif            0\n2  20090330_000000_025s8ms_Test2.aif            0\n3  20090330_000000_028s0ms_Test3.aif            0\n4  20090330_000000_035s4ms_Test4.aif            0\n['clip', 'probability']\n\nListing train2.zip ...\nn_files: 22693\n  0: train2/ 0 KB\n  1: train2/20090328_121500_44292s1ms_TRAIN3930_0.aif 7 KB\n  2: train2/20090328_040000_14754s3ms_TRAIN1536_0.aif 7 KB\n  3: train2/20090329_190000_68809s7ms_TRAIN20079_0.aif 7 KB\n  4: train2/20090328_170000_61317s6ms_TRAIN5011_0.aif 7 KB\n  5: train2/20090329_050000_18012s6ms_TRAIN11800_0.aif 7 KB\n  6: train2/20090329_191500_69780s9ms_TRAIN20291_0.aif 7 KB\n  7: train2/20090328_113000_41563s5ms_TRAIN3815_0.aif 7 KB\n  8: train2/20090328_194500_71180s5ms_TRAIN5818_0.aif 7 KB\n  9: train2/20090328_101500_37143s2ms_TRAIN3463_0.aif 7 KB\n 10: train2/20090329_181500_66414s2ms_TRAIN19609_0.aif 7 KB\n 11: train2/20090329_154500_56865s7ms_TRAIN16987_0.aif 7 KB\n 12: train2/20090328_211500_76538s5ms_TRAIN6564_0.aif 7 KB\n 13: train2/20090329_141500_51382s3ms_TRAIN15732_0.aif 7 KB\n 14: train2/20090328_094500_35176s5ms_TRAIN3112_0.aif 7 KB\n 15: train2/20090329_161500_58532s0ms_TRAIN17444_0.aif 7 KB\n 16: train2/20090329_094500_35429s8ms_TRAIN13596_0.aif 5 KB\n 17: train2/20090329_151500_55778s8ms_TRAIN16675_0.aif 6 KB\n 18: train2/20090328_143000_52458s8ms_TRAIN4318_0.aif 7 KB\n 19: train2/20090329_053000_20477s3ms_TRAIN12128_0.aif 7 KB\n...\n\nListing test2.zip ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_files: 25150\n  0: test2/ 0 KB\n  1: test2/20090330_211500_76911s3ms_Test9103.aif 7 KB\n  2: test2/20090331_093000_34786s9ms_Test16890.aif 7 KB\n  3: test2/20090331_164500_60302s0ms_Test20173.aif 7 KB\n  4: test2/20090331_061500_23065s5ms_Test15089.aif 7 KB\n  5: test2/20090330_103000_38310s6ms_Test4068.aif 7 KB\n  6: test2/20090331_173000_63548s4ms_Test20737.aif 7 KB\n  7: test2/20090331_204500_74792s1ms_Test22617.aif 7 KB\n  8: test2/20090330_184500_67999s0ms_Test7115.aif 7 KB\n  9: test2/20090330_203000_74285s8ms_Test8581.aif 7 KB\n 10: test2/20090331_054500_21339s8ms_Test14792.aif 7 KB\n 11: test2/20090330_211500_76623s1ms_Test9047.aif 7 KB\n 12: test2/20090331_181500_66381s2ms_Test21309.aif 7 KB\n 13: test2/20090330_183000_66957s4ms_Test7017.aif 7 KB\n 14: test2/20090330_144500_53767s4ms_Test5595.aif 7 KB\n 15: test2/20090331_201500_73585s2ms_Test22419.aif 7 KB\n 16: test2/20090330_191500_70183s0ms_Test7551.aif 7 KB\n 17: test2/20090331_020000_7418s6ms_Test12846.aif 7 KB\n 18: test2/20090330_191500_70086s1ms_Test7521.aif 6 KB\n 19: test2/20090331_000000_056s1ms_Test11109.aif 7 KB\n...\n"
          ]
        }
      ]
    },
    {
      "id": "0627000a-20e1-4fd9-8125-4e8b02ebc9a6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, re, zipfile, shutil, time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure train2/ and test2/ exist by extracting only if missing\n",
        "train_dir = Path('train2')\n",
        "test_dir = Path('test2')\n",
        "if not train_dir.exists():\n",
        "    t0 = time.time()\n",
        "    with zipfile.ZipFile('train2.zip') as z:\n",
        "        print('Extracting train2.zip ...')\n",
        "        z.extractall('.')\n",
        "    print(f'Done train2 in {time.time()-t0:.1f}s')\n",
        "else:\n",
        "    print('train2/ exists; skipping extraction')\n",
        "if not test_dir.exists():\n",
        "    t0 = time.time()\n",
        "    with zipfile.ZipFile('test2.zip') as z:\n",
        "        print('Extracting test2.zip ...')\n",
        "        z.extractall('.')\n",
        "    print(f'Done test2 in {time.time()-t0:.1f}s')\n",
        "else:\n",
        "    print('test2/ exists; skipping extraction')\n",
        "\n",
        "assert train_dir.exists() and test_dir.exists()\n",
        "\n",
        "# Collect file lists\n",
        "train_files = sorted([p for p in train_dir.iterdir() if p.suffix.lower()=='.aif'])\n",
        "test_files = sorted([p for p in test_dir.iterdir() if p.suffix.lower()=='.aif'])\n",
        "print('n_train_files:', len(train_files), 'n_test_files:', len(test_files))\n",
        "\n",
        "# Parse labels and groups\n",
        "label_re = re.compile(r'_(?P<label>[01])\\.aif$', re.IGNORECASE)\n",
        "def parse_train(p):\n",
        "    name = p.name\n",
        "    m = label_re.search(name)\n",
        "    if not m:\n",
        "        return None\n",
        "    label = int(m.group('label'))\n",
        "    group_hour = name[:11]  # YYYYMMDD_HH\n",
        "    group_date = name[:8]   # YYYYMMDD\n",
        "    return name, str(p), label, group_hour, group_date\n",
        "\n",
        "rows = []\n",
        "bad = 0\n",
        "for i, p in enumerate(train_files):\n",
        "    r = parse_train(p)\n",
        "    if r is None:\n",
        "        bad += 1\n",
        "    else:\n",
        "        rows.append(r)\n",
        "print('parsed rows:', len(rows), 'bad:', bad)\n",
        "\n",
        "train_df = pd.DataFrame(rows, columns=['clip','path','label','group_hour','group_date'])\n",
        "dup = train_df.duplicated('clip').sum()\n",
        "print('duplicates by clip:', dup)\n",
        "print('class distribution:\\n', train_df['label'].value_counts())\n",
        "print('unique groups (hour/date):', train_df['group_hour'].nunique(), train_df['group_date'].nunique())\n",
        "\n",
        "# Build test df aligned to sampleSubmission order\n",
        "sample = pd.read_csv('sampleSubmission.csv')\n",
        "test_map = {p.name: str(p) for p in test_files}\n",
        "miss = []\n",
        "paths = []\n",
        "for name in sample['clip'].tolist():\n",
        "    path = test_map.get(name)\n",
        "    if path is None:\n",
        "        miss.append(name)\n",
        "        paths.append(None)\n",
        "    else:\n",
        "        paths.append(path)\n",
        "if miss:\n",
        "    print('Missing test paths for', len(miss))\n",
        "else:\n",
        "    print('All test clips found')\n",
        "test_df = pd.DataFrame({'clip': sample['clip'], 'path': paths})\n",
        "print(train_df.shape, test_df.shape)\n",
        "\n",
        "# Group sanity for leakage prevention\n",
        "grp_counts = train_df.groupby('group_hour')['label'].agg(['count','sum'])\n",
        "print('Groups (hour) count summary:')\n",
        "print(grp_counts.describe())\n",
        "pos_per_group = (grp_counts['sum']>0).sum()\n",
        "print('Groups with at least one positive:', pos_per_group, 'of', len(grp_counts))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting train2.zip ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done train2 in 3.7s\nExtracting test2.zip ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done test2 in 4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_train_files: 22692 n_test_files: 25149\nparsed rows: 22692 bad: 0\nduplicates by clip: 0\nclass distribution:\n label\n0    20426\n1     2266\nName: count, dtype: int64\nunique groups (hour/date): 48 2\nAll test clips found\n(22692, 5) (25149, 2)\nGroups (hour) count summary:\n            count         sum\ncount    48.00000   48.000000\nmean    472.75000   47.208333\nstd     231.27643   46.122390\nmin     138.00000    0.000000\n25%     291.50000   12.750000\n50%     444.00000   30.500000\n75%     564.25000   78.500000\nmax    1150.00000  207.000000\nGroups with at least one positive: 45 of 48\n"
          ]
        }
      ]
    },
    {
      "id": "635ba9c3-5b98-4873-9e85-3fe7b98daab1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, math, warnings, time, gc, multiprocessing as mp, traceback\n",
        "os.environ['NUMBA_NUM_THREADS'] = '1'\n",
        "os.environ['OMP_NUM_THREADS'] = '1'\n",
        "os.environ['MKL_NUM_THREADS'] = '1'\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Install missing packages if needed\n",
        "def _lazy_imports():\n",
        "    global sf, scipy_signal, sosfiltfilt, butter, librosa, scipy_stats, resample_poly\n",
        "    import soundfile as sf  # noqa: F811\n",
        "    from scipy import signal as scipy_signal  # noqa: F811\n",
        "    from scipy.signal import sosfiltfilt, butter, resample_poly  # noqa: F811\n",
        "    import librosa  # noqa: F811\n",
        "    from scipy import stats as scipy_stats  # noqa: F811\n",
        "\n",
        "try:\n",
        "    import soundfile as sf  # type: ignore\n",
        "    from scipy import signal as scipy_signal\n",
        "    from scipy.signal import sosfiltfilt, butter, resample_poly\n",
        "    import librosa\n",
        "    from scipy import stats as scipy_stats\n",
        "except Exception as e:\n",
        "    print('Installing dependencies...', e)\n",
        "    import sys, subprocess\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'soundfile', 'librosa', 'scipy', 'joblib'])\n",
        "    from scipy import signal as scipy_signal\n",
        "    from scipy.signal import sosfiltfilt, butter, resample_poly\n",
        "    import soundfile as sf\n",
        "    import librosa\n",
        "    from scipy import stats as scipy_stats\n",
        "\n",
        "# Feature extraction parameters (per expert guidance)\n",
        "SR_TARGET = 2000\n",
        "BP_LO, BP_HI = 40.0, 500.0\n",
        "N_FFT = 1024\n",
        "HOP = 64\n",
        "N_MELS = 80\n",
        "FMIN, FMAX = 40.0, 450.0\n",
        "\n",
        "def read_mono(path):\n",
        "    try:\n",
        "        y, sr = sf.read(path, dtype='float32', always_2d=False)\n",
        "        if y.ndim == 2:\n",
        "            y = y.mean(axis=1)\n",
        "        return y, int(sr)\n",
        "    except Exception:\n",
        "        # Fallback to librosa backend\n",
        "        y, sr = librosa.load(path, sr=None, mono=True)\n",
        "        return y.astype('float32'), int(sr)\n",
        "\n",
        "def ensure_sr(y, sr, target=SR_TARGET):\n",
        "    if sr == target:\n",
        "        return y, sr\n",
        "    # use resample_poly for speed/quality\n",
        "    g = math.gcd(sr, target)\n",
        "    up, down = target//g, sr//g\n",
        "    y2 = scipy_signal.resample_poly(y, up, down).astype('float32')\n",
        "    return y2, target\n",
        "\n",
        "def bandpass(y, sr, lo=BP_LO, hi=BP_HI, order=4):\n",
        "    lo_n = lo/(sr/2.0)\n",
        "    hi_n = min(0.999, hi/(sr/2.0))\n",
        "    if hi_n <= lo_n:\n",
        "        return y\n",
        "    sos = butter(order, [lo_n, hi_n], btype='bandpass', output='sos')\n",
        "    try:\n",
        "        return sosfiltfilt(sos, y).astype('float32')\n",
        "    except Exception:\n",
        "        return y.astype('float32')\n",
        "\n",
        "def logmel_features(y, sr):\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP, n_mels=N_MELS, fmin=FMIN, fmax=FMAX, window='hann', power=2.0, center=True)\n",
        "    S = np.maximum(S, 1e-12)\n",
        "    logS = np.log(S).astype('float32')\n",
        "    d1 = librosa.feature.delta(logS, order=1, mode='nearest')\n",
        "    d2 = librosa.feature.delta(logS, order=2, mode='nearest')\n",
        "    return logS, d1, d2\n",
        "\n",
        "def spectral_summaries(y, sr):\n",
        "    # RMS, centroid, bandwidth, rolloff\n",
        "    S = np.abs(librosa.stft(y=y, n_fft=N_FFT, hop_length=HOP, window='hann', center=True))**2\n",
        "    if S.size == 0:\n",
        "        return { 'rms_mean':0.0, 'rms_std':0.0, 'centroid_mean':0.0, 'bw_mean':0.0, 'roll85_mean':0.0, 'roll95_mean':0.0 }\n",
        "    # Ensure frame_length matches the STFT n_fft used for S\n",
        "    n_fft_used = 2 * (S.shape[0] - 1)\n",
        "    rms = librosa.feature.rms(S=S, frame_length=n_fft_used, hop_length=HOP, center=True).flatten()\n",
        "    cen = librosa.feature.spectral_centroid(S=S, sr=sr).flatten()\n",
        "    bw = librosa.feature.spectral_bandwidth(S=S, sr=sr).flatten()\n",
        "    roll85 = librosa.feature.spectral_rolloff(S=S, sr=sr, roll_percent=0.85).flatten()\n",
        "    roll95 = librosa.feature.spectral_rolloff(S=S, sr=sr, roll_percent=0.95).flatten()\n",
        "    def stats(x):\n",
        "        return {\n",
        "            'mean': float(np.nanmean(x)) if x.size else 0.0,\n",
        "            'std': float(np.nanstd(x)) if x.size else 0.0\n",
        "        }\n",
        "    out = {}\n",
        "    out['rms_mean'] = stats(rms)['mean']; out['rms_std'] = stats(rms)['std']\n",
        "    out['centroid_mean'] = stats(cen)['mean']\n",
        "    out['bw_mean'] = stats(bw)['mean']\n",
        "    out['roll85_mean'] = stats(roll85)['mean']\n",
        "    out['roll95_mean'] = stats(roll95)['mean']\n",
        "    return out\n",
        "\n",
        "def aggregate_stats(mat, prefix):\n",
        "    # mat shape: (bands, frames)\n",
        "    if mat.ndim != 2 or mat.size == 0:\n",
        "        return {}\n",
        "    feats = {}\n",
        "    # per-band stats\n",
        "    p10 = np.percentile(mat, 10, axis=1)\n",
        "    p50 = np.percentile(mat, 50, axis=1)\n",
        "    p90 = np.percentile(mat, 90, axis=1)\n",
        "    mean = mat.mean(axis=1)\n",
        "    std = mat.std(axis=1)\n",
        "    mx = mat.max(axis=1)\n",
        "    # skew/kurtosis per band\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter('ignore')\n",
        "        sk = scipy_stats.skew(mat, axis=1, nan_policy='omit')\n",
        "        ku = scipy_stats.kurtosis(mat, axis=1, fisher=True, nan_policy='omit')\n",
        "    for i in range(mat.shape[0]):\n",
        "        feats[f'{prefix}_b{i:02d}_mean'] = float(mean[i])\n",
        "        feats[f'{prefix}_b{i:02d}_std'] = float(std[i])\n",
        "        feats[f'{prefix}_b{i:02d}_p10'] = float(p10[i])\n",
        "        feats[f'{prefix}_b{i:02d}_p50'] = float(p50[i])\n",
        "        feats[f'{prefix}_b{i:02d}_p90'] = float(p90[i])\n",
        "        feats[f'{prefix}_b{i:02d}_max'] = float(mx[i])\n",
        "        feats[f'{prefix}_b{i:02d}_skew'] = float(sk[i]) if np.isfinite(sk[i]) else 0.0\n",
        "        feats[f'{prefix}_b{i:02d}_kurt'] = float(ku[i]) if np.isfinite(ku[i]) else 0.0\n",
        "    # global summaries\n",
        "    feats[f'{prefix}_global_mean'] = float(mean.mean())\n",
        "    feats[f'{prefix}_global_std'] = float(std.mean())\n",
        "    return feats\n",
        "\n",
        "def energy_ratio_features(logmel, sr):\n",
        "    # Compute mel center freqs to define bands\n",
        "    mel_cf = librosa.mel_frequencies(n_mels=logmel.shape[0], fmin=FMIN, fmax=FMAX)\n",
        "    def band_mask(lo, hi):\n",
        "        return (mel_cf >= lo) & (mel_cf < hi)\n",
        "    bands = {\n",
        "        'low': band_mask(40, 120),\n",
        "        'mid': band_mask(120, 250),\n",
        "        'high': band_mask(250, 450)\n",
        "    }\n",
        "    feats = {}\n",
        "    for k, m in bands.items():\n",
        "        if m.sum() == 0:\n",
        "            feats[f'band_{k}_mean'] = 0.0\n",
        "        else:\n",
        "            feats[f'band_{k}_mean'] = float(np.mean(logmel[m, :]))\n",
        "    denom = 1e-6 + feats['band_low_mean'] + feats['band_mid_mean'] + feats['band_high_mean']\n",
        "    feats['ratio_low'] = feats['band_low_mean'] / denom\n",
        "    feats['ratio_mid'] = feats['band_mid_mean'] / denom\n",
        "    feats['ratio_high'] = feats['band_high_mean'] / denom\n",
        "    return feats\n",
        "\n",
        "def eventness_features(logmel):\n",
        "    # Threshold frames in 80-400 Hz region\n",
        "    mel_cf = librosa.mel_frequencies(n_mels=logmel.shape[0], fmin=FMIN, fmax=FMAX)\n",
        "    mask = (mel_cf >= 80) & (mel_cf <= 400)\n",
        "    band = logmel[mask, :]\n",
        "    if band.size == 0:\n",
        "        return {'evt_frac':0.0, 'evt_runs':0, 'evt_longest':0}\n",
        "    b = (band - band.mean(axis=1, keepdims=True))/ (1e-6 + band.std(axis=1, keepdims=True))\n",
        "    s = b.mean(axis=0)\n",
        "    thr = s.mean() + 0.5*s.std()\n",
        "    flags = (s > thr).astype(np.int32)\n",
        "    if flags.size == 0:\n",
        "        return {'evt_frac':0.0, 'evt_runs':0, 'evt_longest':0}\n",
        "    frac = float(flags.mean())\n",
        "    runs = 0; longest = 0; cur = 0\n",
        "    for v in flags:\n",
        "        if v == 1:\n",
        "            cur += 1; longest = max(longest, cur);\n",
        "        else:\n",
        "            if cur>0: runs += 1\n",
        "            cur = 0\n",
        "    if cur>0: runs += 1\n",
        "    return {'evt_frac': frac, 'evt_runs': runs, 'evt_longest': int(longest)}\n",
        "\n",
        "def extract_one(row):\n",
        "    # Ensure heavy deps are imported in each worker\n",
        "    try:\n",
        "        _ = sf  # type: ignore\n",
        "    except NameError:\n",
        "        _lazy_imports()\n",
        "    path = row['path']\n",
        "    clip = row['clip']\n",
        "    try:\n",
        "        y, sr = read_mono(path)\n",
        "        if y.size == 0:\n",
        "            raise ValueError('empty')\n",
        "        y, sr = ensure_sr(y, sr, SR_TARGET)\n",
        "        y = bandpass(y, sr, BP_LO, BP_HI, order=4)\n",
        "        logS, d1, d2 = logmel_features(y, sr)\n",
        "        feats = {}\n",
        "        # Aggregated mel and deltas\n",
        "        feats.update(aggregate_stats(logS, 'mel'))\n",
        "        feats.update(aggregate_stats(d1, 'd1'))\n",
        "        feats.update(aggregate_stats(d2, 'd2'))\n",
        "        # Additional low-cost features\n",
        "        expS = np.exp(logS).astype('float32')\n",
        "        # Spectral flux on mel spectrogram (half-wave rectified frame diff)\n",
        "        if expS.shape[1] >= 2:\n",
        "            dS = np.diff(expS, axis=1)\n",
        "            dS_pos = np.maximum(dS, 0.0)\n",
        "            flux = dS_pos.sum(axis=0).astype('float32')  # length T-1\n",
        "            feats['flux_mean'] = float(np.nanmean(flux)) if flux.size else 0.0\n",
        "            feats['flux_std']  = float(np.nanstd(flux)) if flux.size else 0.0\n",
        "            feats['flux_p90']  = float(np.nanpercentile(flux, 90)) if flux.size else 0.0\n",
        "            feats['flux_max']  = float(np.nanmax(flux)) if flux.size else 0.0\n",
        "        else:\n",
        "            feats['flux_mean']=feats['flux_std']=feats['flux_p90']=feats['flux_max']=0.0\n",
        "        # Spectral flatness\n",
        "        try:\n",
        "            flat = librosa.feature.spectral_flatness(S=expS).flatten()\n",
        "            feats['flat_mean'] = float(np.nanmean(flat)) if flat.size else 0.0\n",
        "            feats['flat_std']  = float(np.nanstd(flat)) if flat.size else 0.0\n",
        "        except Exception:\n",
        "            feats['flat_mean']=feats['flat_std']=0.0\n",
        "        # Centroid slope from STFT power\n",
        "        try:\n",
        "            P = np.abs(librosa.stft(y=y, n_fft=N_FFT, hop_length=HOP, window='hann', center=True))**2\n",
        "            cen = librosa.feature.spectral_centroid(S=P, sr=sr).flatten()\n",
        "            if cen.size > 1:\n",
        "                x = np.arange(cen.size, dtype=np.float32)\n",
        "                slope = float(np.polyfit(x, cen, 1)[0])\n",
        "            else:\n",
        "                slope = 0.0\n",
        "            feats['centroid_slope'] = slope\n",
        "        except Exception:\n",
        "            feats['centroid_slope'] = 0.0\n",
        "        # Energy timing percentiles\n",
        "        ene = expS.mean(axis=0) if expS.size else np.zeros(0, dtype=np.float32)\n",
        "        if ene.size:\n",
        "            c = np.cumsum(ene)\n",
        "            tot = c[-1] if c.size else 0.0\n",
        "            if tot <= 0:\n",
        "                t10=t50=t90=spread=0.0\n",
        "            else:\n",
        "                c = c/(tot + 1e-12)\n",
        "                nT = len(c)\n",
        "                t10 = float(np.searchsorted(c, 0.1)/nT)\n",
        "                t50 = float(np.searchsorted(c, 0.5)/nT)\n",
        "                t90 = float(np.searchsorted(c, 0.9)/nT)\n",
        "                spread = t90 - t10\n",
        "        else:\n",
        "            t10=t50=t90=spread=0.0\n",
        "        feats['t10'] = t10; feats['t50'] = t50; feats['t90'] = t90; feats['t_spread'] = spread\n",
        "        # Spectral summaries + ratios + eventness\n",
        "        feats.update(spectral_summaries(y, sr))\n",
        "        feats.update(energy_ratio_features(logS, sr))\n",
        "        feats.update(eventness_features(logS))\n",
        "        feats['n_frames'] = int(logS.shape[1])\n",
        "        feats['clip'] = clip\n",
        "        feats['failed'] = 0\n",
        "        return feats\n",
        "    except Exception as e:\n",
        "        # Robust fallback with error info\n",
        "        f = {'clip': clip, 'n_frames': 0, 'failed': 1, 'err': repr(e)}\n",
        "        return f\n",
        "\n",
        "def parallel_extract_joblib(df, out_path, n_jobs=16, batch_log=200):\n",
        "    t0 = time.time()\n",
        "    rows = df.to_dict('records')\n",
        "    print(f'Extracting features for {len(rows)} clips -> {out_path} with joblib loky, n_jobs={n_jobs}')\n",
        "    feats = Parallel(n_jobs=n_jobs, backend='loky', verbose=10)(\n",
        "        delayed(extract_one)(row) for row in rows\n",
        "    )\n",
        "    # Collect stats and small sample errors\n",
        "    err = sum(1 for f in feats if f.get('failed', 0)==1)\n",
        "    if err:\n",
        "        print('Total failures:', err)\n",
        "        sample_errs = [f.get('err','') for f in feats if f.get('failed',0)==1][:5]\n",
        "        for se in sample_errs:\n",
        "            if se:\n",
        "                print('Sample worker error:', se)\n",
        "    feat_df = pd.DataFrame(feats)\n",
        "    feat_df = feat_df.set_index('clip').reindex(df['clip'].values)\n",
        "    if 'err' in feat_df.columns:\n",
        "        feat_df = feat_df.drop(columns=['err'])\n",
        "    feat_df = feat_df.fillna(0).reset_index()\n",
        "    feat_df.to_parquet(out_path, index=False)\n",
        "    print(f'Saved {out_path} with shape {feat_df.shape} in {time.time()-t0:.1f}s')\n",
        "    return feat_df\n",
        "\n",
        "# Debug small subset first to ensure rich columns\n",
        "debug_pq = Path('train_features_debug.parquet')\n",
        "if debug_pq.exists():\n",
        "    try:\n",
        "        _tmpd = pd.read_parquet(debug_pq)\n",
        "        if _tmpd.shape[1] <= 5:\n",
        "            print('Existing debug parquet invalid; removing')\n",
        "            debug_pq.unlink(missing_ok=True)\n",
        "    except Exception:\n",
        "        print('Could not read existing debug parquet; removing')\n",
        "        debug_pq.unlink(missing_ok=True)\n",
        "if not debug_pq.exists():\n",
        "    _ = parallel_extract_joblib(train_df[['clip','path']].head(200), debug_pq, n_jobs=8, batch_log=50)\n",
        "else:\n",
        "    print('Found', debug_pq)\n",
        "\n",
        "# Run full extraction if cache missing or invalid - TRAIN ONLY for now\n",
        "train_feat_pq = Path('train_features.parquet')\n",
        "need_full = True\n",
        "if train_feat_pq.exists():\n",
        "    try:\n",
        "        _tmp = pd.read_parquet(train_feat_pq)\n",
        "        if _tmp.shape[1] > 5:\n",
        "            need_full = False\n",
        "        else:\n",
        "            print('Existing train_features.parquet has too few columns; regenerating...')\n",
        "            train_feat_pq.unlink(missing_ok=True)\n",
        "    except Exception:\n",
        "        print('Could not read existing train_features.parquet; regenerating...')\n",
        "        train_feat_pq.unlink(missing_ok=True)\n",
        "if need_full:\n",
        "    _ = parallel_extract_joblib(train_df[['clip','path']], train_feat_pq, n_jobs=16, batch_log=200)\n",
        "else:\n",
        "    print('Found valid', train_feat_pq)\n",
        "\n",
        "gc.collect()\n",
        "print('Feature extraction (train) complete.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing debug parquet invalid; removing\nExtracting features for 200 clips -> train_features_debug.parquet with joblib loky, n_jobs=8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    1.6s\n[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:    1.7s\n[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:    1.9s\n[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    2.0s\n[Parallel(n_jobs=8)]: Batch computation too fast (0.19683571019612733s.) Setting batch_size=2.\n[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:    2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:    2.3s\n[Parallel(n_jobs=8)]: Batch computation too fast (0.19902801513671875s.) Setting batch_size=4.\n[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:    2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Done 128 tasks      | elapsed:    2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=8)]: Done 173 tasks      | elapsed:    3.1s\n[Parallel(n_jobs=8)]: Done 200 out of 200 | elapsed:    3.2s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved train_features_debug.parquet with shape (200, 1955) in 3.5s\nExtracting features for 22692 clips -> train_features.parquet with joblib loky, n_jobs=16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    2.1s\n[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    2.3s\n[Parallel(n_jobs=16)]: Done  40 tasks      | elapsed:    2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done  53 tasks      | elapsed:    2.7s\n[Parallel(n_jobs=16)]: Done  66 tasks      | elapsed:    2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done  81 tasks      | elapsed:    2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done  96 tasks      | elapsed:    3.1s\n[Parallel(n_jobs=16)]: Done 113 tasks      | elapsed:    3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 130 tasks      | elapsed:    3.5s\n[Parallel(n_jobs=16)]: Done 149 tasks      | elapsed:    3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    3.8s\n[Parallel(n_jobs=16)]: Done 189 tasks      | elapsed:    4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 210 tasks      | elapsed:    4.2s\n[Parallel(n_jobs=16)]: Done 233 tasks      | elapsed:    4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 256 tasks      | elapsed:    4.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 281 tasks      | elapsed:    4.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 306 tasks      | elapsed:    5.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 333 tasks      | elapsed:    5.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 360 tasks      | elapsed:    5.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 389 tasks      | elapsed:    5.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 449 tasks      | elapsed:    6.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 480 tasks      | elapsed:    6.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 513 tasks      | elapsed:    7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 546 tasks      | elapsed:    7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 581 tasks      | elapsed:    7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 616 tasks      | elapsed:    8.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 653 tasks      | elapsed:    8.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 690 tasks      | elapsed:    8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 729 tasks      | elapsed:    9.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    9.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 809 tasks      | elapsed:    9.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=891\n  warnings.warn(\n/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=891\n  warnings.warn(\n[Parallel(n_jobs=16)]: Done 850 tasks      | elapsed:   10.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 893 tasks      | elapsed:   10.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 936 tasks      | elapsed:   11.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 981 tasks      | elapsed:   11.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1026 tasks      | elapsed:   11.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1073 tasks      | elapsed:   12.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1120 tasks      | elapsed:   12.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1169 tasks      | elapsed:   13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1218 tasks      | elapsed:   13.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1269 tasks      | elapsed:   14.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1320 tasks      | elapsed:   14.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1373 tasks      | elapsed:   15.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1426 tasks      | elapsed:   15.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1481 tasks      | elapsed:   16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1536 tasks      | elapsed:   16.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1593 tasks      | elapsed:   17.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1650 tasks      | elapsed:   18.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1709 tasks      | elapsed:   18.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1768 tasks      | elapsed:   19.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1829 tasks      | elapsed:   19.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1890 tasks      | elapsed:   20.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1953 tasks      | elapsed:   20.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2016 tasks      | elapsed:   21.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2081 tasks      | elapsed:   22.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2146 tasks      | elapsed:   22.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2213 tasks      | elapsed:   23.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2280 tasks      | elapsed:   23.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2349 tasks      | elapsed:   24.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2418 tasks      | elapsed:   25.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2489 tasks      | elapsed:   26.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2560 tasks      | elapsed:   26.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2633 tasks      | elapsed:   27.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2706 tasks      | elapsed:   28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2781 tasks      | elapsed:   28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2856 tasks      | elapsed:   29.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2933 tasks      | elapsed:   30.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3010 tasks      | elapsed:   31.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3089 tasks      | elapsed:   31.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3168 tasks      | elapsed:   32.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3249 tasks      | elapsed:   33.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3330 tasks      | elapsed:   34.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3413 tasks      | elapsed:   35.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3496 tasks      | elapsed:   35.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3581 tasks      | elapsed:   36.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3666 tasks      | elapsed:   37.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3753 tasks      | elapsed:   38.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3840 tasks      | elapsed:   39.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3929 tasks      | elapsed:   40.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4018 tasks      | elapsed:   40.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4109 tasks      | elapsed:   41.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4200 tasks      | elapsed:   42.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4293 tasks      | elapsed:   43.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4386 tasks      | elapsed:   44.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4481 tasks      | elapsed:   45.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4576 tasks      | elapsed:   46.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4673 tasks      | elapsed:   47.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4770 tasks      | elapsed:   48.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4869 tasks      | elapsed:   49.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4968 tasks      | elapsed:   50.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5069 tasks      | elapsed:   51.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5170 tasks      | elapsed:   52.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5273 tasks      | elapsed:   53.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5376 tasks      | elapsed:   54.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5481 tasks      | elapsed:   55.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5586 tasks      | elapsed:   56.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5693 tasks      | elapsed:   56.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5800 tasks      | elapsed:   57.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5909 tasks      | elapsed:   58.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6018 tasks      | elapsed:   59.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6129 tasks      | elapsed:  1.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6240 tasks      | elapsed:  1.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6353 tasks      | elapsed:  1.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6466 tasks      | elapsed:  1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6581 tasks      | elapsed:  1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6696 tasks      | elapsed:  1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6813 tasks      | elapsed:  1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6930 tasks      | elapsed:  1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7049 tasks      | elapsed:  1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7168 tasks      | elapsed:  1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7289 tasks      | elapsed:  1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7410 tasks      | elapsed:  1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7533 tasks      | elapsed:  1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7656 tasks      | elapsed:  1.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7781 tasks      | elapsed:  1.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7906 tasks      | elapsed:  1.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8033 tasks      | elapsed:  1.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8160 tasks      | elapsed:  1.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8289 tasks      | elapsed:  1.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8418 tasks      | elapsed:  1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8549 tasks      | elapsed:  1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8680 tasks      | elapsed:  1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8813 tasks      | elapsed:  1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8946 tasks      | elapsed:  1.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9081 tasks      | elapsed:  1.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9216 tasks      | elapsed:  1.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9353 tasks      | elapsed:  1.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9490 tasks      | elapsed:  1.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9629 tasks      | elapsed:  1.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9768 tasks      | elapsed:  1.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9909 tasks      | elapsed:  1.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10050 tasks      | elapsed:  1.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10193 tasks      | elapsed:  1.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10336 tasks      | elapsed:  1.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1009\n  warnings.warn(\n/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=1009\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10481 tasks      | elapsed:  1.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10626 tasks      | elapsed:  1.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10773 tasks      | elapsed:  1.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10920 tasks      | elapsed:  1.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 11069 tasks      | elapsed:  1.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 11218 tasks      | elapsed:  1.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 11369 tasks      | elapsed:  1.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 11520 tasks      | elapsed:  1.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 11673 tasks      | elapsed:  1.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 11826 tasks      | elapsed:  1.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 11981 tasks      | elapsed:  2.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 12136 tasks      | elapsed:  2.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 12293 tasks      | elapsed:  2.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 12450 tasks      | elapsed:  2.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 12609 tasks      | elapsed:  2.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 12768 tasks      | elapsed:  2.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 12929 tasks      | elapsed:  2.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 13090 tasks      | elapsed:  2.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 13253 tasks      | elapsed:  2.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 13416 tasks      | elapsed:  2.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 13581 tasks      | elapsed:  2.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 13746 tasks      | elapsed:  2.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 13913 tasks      | elapsed:  2.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 14080 tasks      | elapsed:  2.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 14249 tasks      | elapsed:  2.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 14418 tasks      | elapsed:  2.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 14589 tasks      | elapsed:  2.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 14760 tasks      | elapsed:  2.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 14933 tasks      | elapsed:  2.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 15106 tasks      | elapsed:  2.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 15281 tasks      | elapsed:  2.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 15456 tasks      | elapsed:  2.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 15633 tasks      | elapsed:  2.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 15810 tasks      | elapsed:  2.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 15989 tasks      | elapsed:  2.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 16168 tasks      | elapsed:  2.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=560\n  warnings.warn(\n/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=560\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 16349 tasks      | elapsed:  2.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 16530 tasks      | elapsed:  2.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 16713 tasks      | elapsed:  2.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 16896 tasks      | elapsed:  2.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 17081 tasks      | elapsed:  2.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 17266 tasks      | elapsed:  2.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 17453 tasks      | elapsed:  2.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 17640 tasks      | elapsed:  2.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 17829 tasks      | elapsed:  2.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=813\n  warnings.warn(\n/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=813\n  warnings.warn(\n[Parallel(n_jobs=16)]: Done 18018 tasks      | elapsed:  2.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 18209 tasks      | elapsed:  2.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 18400 tasks      | elapsed:  3.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 18593 tasks      | elapsed:  3.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 18786 tasks      | elapsed:  3.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 18981 tasks      | elapsed:  3.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 19176 tasks      | elapsed:  3.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 19373 tasks      | elapsed:  3.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 19570 tasks      | elapsed:  3.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 19769 tasks      | elapsed:  3.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 19968 tasks      | elapsed:  3.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 20169 tasks      | elapsed:  3.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 20370 tasks      | elapsed:  3.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 20573 tasks      | elapsed:  3.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 20776 tasks      | elapsed:  3.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 20981 tasks      | elapsed:  3.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 21186 tasks      | elapsed:  3.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 21393 tasks      | elapsed:  3.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 21600 tasks      | elapsed:  3.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 21809 tasks      | elapsed:  3.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 22018 tasks      | elapsed:  3.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 22229 tasks      | elapsed:  3.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 22440 tasks      | elapsed:  3.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 22653 tasks      | elapsed:  3.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 22692 out of 22692 | elapsed:  3.6min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved train_features.parquet with shape (22692, 1955) in 234.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature extraction (train) complete.\n"
          ]
        }
      ]
    },
    {
      "id": "833e1fe9-77f0-4416-88db-441e430a0846",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Debug: inspect extracted feature parquet and a single-file feature dict\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "pq = Path('train_features.parquet')\n",
        "if pq.exists():\n",
        "    dfp = pd.read_parquet(pq)\n",
        "    print('parquet shape:', dfp.shape)\n",
        "    print('columns (first 20):', list(dfp.columns[:20]))\n",
        "    print(dfp.head(3))\n",
        "else:\n",
        "    print('train_features.parquet not found')\n",
        "\n",
        "# Try extracting one sample to inspect keys and any exceptions\n",
        "row0 = train_df[['clip','path']].iloc[0].to_dict()\n",
        "print('Testing extract_one on:', row0['clip'])\n",
        "feat0 = extract_one(row0)\n",
        "print('n_keys:', len(feat0))\n",
        "print('keys sample:', list(feat0.keys())[:20])\n",
        "print('n_frames:', feat0.get('n_frames'))\n",
        "\n",
        "# If features are minimal, hint next steps\n",
        "if len(feat0) <= 3:\n",
        "    print('Warning: feature dict minimal. Investigate mel/logS sizes and exceptions inside extract_one.')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parquet shape: (22692, 2)\ncolumns (first 20): ['clip', 'n_frames']\n                                   clip  n_frames\n0  20090328_000000_002s3ms_TRAIN0_0.aif         0\n1  20090328_000000_010s8ms_TRAIN1_0.aif         0\n2  20090328_000000_021s6ms_TRAIN2_0.aif         0\nTesting extract_one on: 20090328_000000_002s3ms_TRAIN0_0.aif\nn_keys: 2\nkeys sample: ['clip', 'n_frames']\nn_frames: 0\nWarning: feature dict minimal. Investigate mel/logS sizes and exceptions inside extract_one.\n"
          ]
        }
      ]
    },
    {
      "id": "18d1c2da-4c1d-406e-9ad0-f1105a92d5cd",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Deep debug: can we read AIFF and produce mel for a single file?\n",
        "import soundfile as sf, librosa, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "sample_row = train_df.iloc[0]\n",
        "p = sample_row['path']\n",
        "print('Path:', p)\n",
        "try:\n",
        "    info = sf.info(p)\n",
        "    print('sf.info:', info)\n",
        "except Exception as e:\n",
        "    print('sf.info failed:', e)\n",
        "\n",
        "try:\n",
        "    y_sf, sr_sf = sf.read(p, dtype='float32', always_2d=False)\n",
        "    print('sf.read ok. shape:', y_sf.shape, 'sr:', sr_sf, 'min/max:', float(np.min(y_sf)) if y_sf.size else None, float(np.max(y_sf)) if y_sf.size else None)\n",
        "except Exception as e:\n",
        "    print('sf.read failed:', e)\n",
        "    y_sf, sr_sf = np.array([], dtype=np.float32), None\n",
        "\n",
        "try:\n",
        "    y_lb, sr_lb = librosa.load(p, sr=None, mono=True)\n",
        "    print('librosa.load ok. len:', len(y_lb), 'sr:', sr_lb, 'min/max:', float(np.min(y_lb)) if y_lb.size else None, float(np.max(y_lb)) if y_lb.size else None)\n",
        "except Exception as e:\n",
        "    print('librosa.load failed:', e)\n",
        "    y_lb, sr_lb = np.array([], dtype=np.float32), None\n",
        "\n",
        "# Try pipeline steps explicitly using whichever loaded signal is non-empty\n",
        "y0, sr0 = (y_sf, sr_sf) if (y_sf is not None and y_sf.size>0) else (y_lb, sr_lb)\n",
        "print('Chosen source:', 'soundfile' if (y_sf is not None and y_sf.size>0) else 'librosa', 'len:', (len(y0) if y0 is not None else None), 'sr:', sr0)\n",
        "if y0 is not None and y0.size>0 and sr0 is not None:\n",
        "    if y0.ndim==2:\n",
        "        y0 = y0.mean(axis=1)\n",
        "    # Resample, bandpass, mel\n",
        "    y1, _ = ensure_sr(y0, sr0, SR_TARGET)\n",
        "    print('After resample len:', len(y1))\n",
        "    y2 = bandpass(y1, SR_TARGET, BP_LO, BP_HI, order=4)\n",
        "    print('After bandpass len:', len(y2), 'min/max:', float(np.min(y2)), float(np.max(y2)))\n",
        "    try:\n",
        "        logS, d1, d2 = logmel_features(y2, SR_TARGET)\n",
        "        print('logS shape:', logS.shape, 'd1:', d1.shape, 'd2:', d2.shape, 'n_frames:', logS.shape[1])\n",
        "        feats = aggregate_stats(logS, 'mel')\n",
        "        print('aggregate mel keys:', len(feats))\n",
        "    except Exception as e:\n",
        "        print('mel computation failed:', e)\n",
        "else:\n",
        "    print('No audio loaded to proceed pipeline')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path: train2/20090328_000000_002s3ms_TRAIN0_0.aif\nsf.info: train2/20090328_000000_002s3ms_TRAIN0_0.aif\nsamplerate: 2000 Hz\nchannels: 1\nduration: 2.000 s\nformat: AIFF (Apple/SGI) [AIFF]\nsubtype: Signed 16 bit PCM [PCM_16]\nsf.read ok. shape: (4000,) sr: 2000 min/max: -0.04150390625 -0.00439453125\nlibrosa.load ok. len: 4000 sr: 2000 min/max: -0.04150390625 -0.00439453125\nChosen source: soundfile len: 4000 sr: 2000\nAfter resample len: 4000\nAfter bandpass len: 4000 min/max: -0.009670577943325043 0.007527660112828016\nlogS shape: (80, 63) d1: (80, 63) d2: (80, 63) n_frames: 63\naggregate mel keys: 642\n"
          ]
        }
      ]
    },
    {
      "id": "39356eae-85c2-4801-b8a2-b1456dd839c7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Validate train features cache and extract test features; align columns\n",
        "import pandas as pd, numpy as np, os, time\n",
        "from pathlib import Path\n",
        "\n",
        "t0 = time.time()\n",
        "train_feat_pq = Path('train_features.parquet')\n",
        "assert train_feat_pq.exists(), 'train_features.parquet missing; run extraction first.'\n",
        "train_feat = pd.read_parquet(train_feat_pq)\n",
        "print('Loaded train_features.parquet:', train_feat.shape)\n",
        "assert train_feat.shape[1] > 1000, f'Unexpected low feature count: {train_feat.shape}'\n",
        "assert any(c.startswith('mel_b00_') for c in train_feat.columns), 'mel_b00_* columns not found'\n",
        "if 'failed' in train_feat.columns:\n",
        "    n_failed = int((train_feat['failed']==1).sum())\n",
        "    print('Train failed rows:', n_failed)\n",
        "else:\n",
        "    n_failed = 0\n",
        "\n",
        "# Extract test features if missing or invalid\n",
        "test_feat_pq = Path('test_features.parquet')\n",
        "need_test = True\n",
        "if test_feat_pq.exists():\n",
        "    try:\n",
        "        _t = pd.read_parquet(test_feat_pq)\n",
        "        if _t.shape[1] > 1000 and len(_t) == len(test_df):\n",
        "            need_test = False\n",
        "            print('Found valid test_features.parquet:', _t.shape)\n",
        "        else:\n",
        "            print('Existing test_features invalid; will regenerate...')\n",
        "            test_feat_pq.unlink(missing_ok=True)\n",
        "    except Exception:\n",
        "        print('Could not read existing test_features; regenerating...')\n",
        "        test_feat_pq.unlink(missing_ok=True)\n",
        "\n",
        "if need_test:\n",
        "    _ = parallel_extract_joblib(test_df[['clip','path']], test_feat_pq, n_jobs=16, batch_log=200)\n",
        "test_feat = pd.read_parquet(test_feat_pq)\n",
        "print('Loaded test_features.parquet:', test_feat.shape)\n",
        "if 'failed' in test_feat.columns:\n",
        "    print('Test failed rows:', int((test_feat['failed']==1).sum()))\n",
        "\n",
        "# Align columns: ensure test has same feature columns as train (excluding clip)\n",
        "drop_cols = ['failed'] if 'failed' in train_feat.columns else []\n",
        "train_cols = [c for c in train_feat.columns if c not in drop_cols]\n",
        "test_cols = [c for c in test_feat.columns if c not in drop_cols]\n",
        "\n",
        "# Ensure 'clip' is present and first\n",
        "assert 'clip' in train_cols and 'clip' in test_cols, 'clip column missing'\n",
        "feat_cols = [c for c in train_cols if c != 'clip']\n",
        "\n",
        "# Add any missing columns to test, fill with 0; drop extras not in train\n",
        "missing_in_test = sorted(list(set(feat_cols) - set([c for c in test_cols if c != 'clip'])))\n",
        "if missing_in_test:\n",
        "    print('Adding missing cols to test:', len(missing_in_test))\n",
        "    for c in missing_in_test:\n",
        "        test_feat[c] = 0.0\n",
        "extra_in_test = sorted(list(set([c for c in test_cols if c != 'clip']) - set(feat_cols)))\n",
        "if extra_in_test:\n",
        "    print('Dropping extra cols from test:', len(extra_in_test))\n",
        "    test_feat = test_feat.drop(columns=extra_in_test)\n",
        "\n",
        "# Reorder test columns to match train\n",
        "test_feat = test_feat[['clip'] + feat_cols]\n",
        "train_feat = train_feat[['clip'] + feat_cols]\n",
        "print('Aligned shapes:', train_feat.shape, test_feat.shape)\n",
        "\n",
        "# Save aligned versions for modeling convenience\n",
        "train_feat.to_parquet('train_features_aligned.parquet', index=False)\n",
        "test_feat.to_parquet('test_features_aligned.parquet', index=False)\n",
        "print('Saved aligned parquet files in', f'{time.time()-t0:.1f}s')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded train_features.parquet: (22692, 1955)\nTrain failed rows: 0\nExtracting features for 25149 clips -> test_features.parquet with joblib loky, n_jobs=16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n[Parallel(n_jobs=16)]: Batch computation too fast (0.036685943603515625s.) Setting batch_size=2.\n[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done  48 tasks      | elapsed:    0.6s\n[Parallel(n_jobs=16)]: Done  74 tasks      | elapsed:    0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 100 tasks      | elapsed:    0.9s\n[Parallel(n_jobs=16)]: Done 130 tasks      | elapsed:    1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 160 tasks      | elapsed:    1.3s\n[Parallel(n_jobs=16)]: Done 194 tasks      | elapsed:    1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 228 tasks      | elapsed:    1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 266 tasks      | elapsed:    1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 304 tasks      | elapsed:    2.2s\n[Parallel(n_jobs=16)]: Done 346 tasks      | elapsed:    2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 388 tasks      | elapsed:    2.6s\n[Parallel(n_jobs=16)]: Done 434 tasks      | elapsed:    2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 480 tasks      | elapsed:    3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 530 tasks      | elapsed:    3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 580 tasks      | elapsed:    3.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 634 tasks      | elapsed:    3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 688 tasks      | elapsed:    4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 746 tasks      | elapsed:    4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 804 tasks      | elapsed:    4.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 866 tasks      | elapsed:    5.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 928 tasks      | elapsed:    5.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 994 tasks      | elapsed:    5.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1060 tasks      | elapsed:    6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1130 tasks      | elapsed:    6.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1200 tasks      | elapsed:    7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1274 tasks      | elapsed:    7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1348 tasks      | elapsed:    7.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1426 tasks      | elapsed:    8.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1504 tasks      | elapsed:    8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1586 tasks      | elapsed:    9.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1668 tasks      | elapsed:    9.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1754 tasks      | elapsed:   10.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1840 tasks      | elapsed:   10.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 1930 tasks      | elapsed:   11.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2020 tasks      | elapsed:   11.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2114 tasks      | elapsed:   12.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2208 tasks      | elapsed:   12.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2306 tasks      | elapsed:   13.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2404 tasks      | elapsed:   13.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2506 tasks      | elapsed:   14.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2608 tasks      | elapsed:   14.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2714 tasks      | elapsed:   15.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2820 tasks      | elapsed:   15.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 2930 tasks      | elapsed:   16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3040 tasks      | elapsed:   16.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3154 tasks      | elapsed:   17.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3268 tasks      | elapsed:   17.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3386 tasks      | elapsed:   18.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3504 tasks      | elapsed:   18.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3626 tasks      | elapsed:   19.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3748 tasks      | elapsed:   20.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 3874 tasks      | elapsed:   20.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4000 tasks      | elapsed:   21.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4130 tasks      | elapsed:   22.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4260 tasks      | elapsed:   23.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4394 tasks      | elapsed:   23.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4528 tasks      | elapsed:   24.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4666 tasks      | elapsed:   25.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4804 tasks      | elapsed:   26.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 4946 tasks      | elapsed:   26.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5088 tasks      | elapsed:   27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5234 tasks      | elapsed:   28.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5380 tasks      | elapsed:   29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5530 tasks      | elapsed:   30.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5680 tasks      | elapsed:   31.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5834 tasks      | elapsed:   31.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 5988 tasks      | elapsed:   32.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6146 tasks      | elapsed:   33.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6304 tasks      | elapsed:   34.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6466 tasks      | elapsed:   35.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6628 tasks      | elapsed:   36.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6794 tasks      | elapsed:   37.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 6960 tasks      | elapsed:   38.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7130 tasks      | elapsed:   39.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7300 tasks      | elapsed:   40.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7474 tasks      | elapsed:   41.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7648 tasks      | elapsed:   42.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 7826 tasks      | elapsed:   43.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8004 tasks      | elapsed:   45.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8186 tasks      | elapsed:   46.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8368 tasks      | elapsed:   47.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8554 tasks      | elapsed:   48.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8740 tasks      | elapsed:   49.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 8930 tasks      | elapsed:   50.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=940\n  warnings.warn(\n/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=940\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9120 tasks      | elapsed:   51.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9314 tasks      | elapsed:   52.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9508 tasks      | elapsed:   53.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9706 tasks      | elapsed:   54.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 9904 tasks      | elapsed:   55.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10106 tasks      | elapsed:   57.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10308 tasks      | elapsed:   58.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10514 tasks      | elapsed:   59.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10720 tasks      | elapsed:  1.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 10930 tasks      | elapsed:  1.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 11140 tasks      | elapsed:  1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 11354 tasks      | elapsed:  1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 11568 tasks      | elapsed:  1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 11786 tasks      | elapsed:  1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=539\n  warnings.warn(\n/app/.pip-target/librosa/core/spectrum.py:266: UserWarning: n_fft=1024 is too large for input signal of length=539\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 12004 tasks      | elapsed:  1.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 12226 tasks      | elapsed:  1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 12448 tasks      | elapsed:  1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 12674 tasks      | elapsed:  1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 12900 tasks      | elapsed:  1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 13130 tasks      | elapsed:  1.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 13360 tasks      | elapsed:  1.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 13594 tasks      | elapsed:  1.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 13828 tasks      | elapsed:  1.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 14066 tasks      | elapsed:  1.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 14304 tasks      | elapsed:  1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 14546 tasks      | elapsed:  1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 14788 tasks      | elapsed:  1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 15034 tasks      | elapsed:  1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 15280 tasks      | elapsed:  1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 15530 tasks      | elapsed:  1.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 15780 tasks      | elapsed:  1.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 16034 tasks      | elapsed:  1.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 16288 tasks      | elapsed:  1.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 16546 tasks      | elapsed:  1.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 16804 tasks      | elapsed:  1.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 17066 tasks      | elapsed:  1.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 17328 tasks      | elapsed:  1.6min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 17594 tasks      | elapsed:  1.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 17860 tasks      | elapsed:  1.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 18130 tasks      | elapsed:  1.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 18400 tasks      | elapsed:  1.7min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 18674 tasks      | elapsed:  1.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 18948 tasks      | elapsed:  1.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 19226 tasks      | elapsed:  1.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 19504 tasks      | elapsed:  1.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 19786 tasks      | elapsed:  1.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 20068 tasks      | elapsed:  1.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 20354 tasks      | elapsed:  1.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 20640 tasks      | elapsed:  1.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 20930 tasks      | elapsed:  2.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 21220 tasks      | elapsed:  2.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 21514 tasks      | elapsed:  2.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 21808 tasks      | elapsed:  2.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 22106 tasks      | elapsed:  2.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 22404 tasks      | elapsed:  2.1min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 22706 tasks      | elapsed:  2.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 23008 tasks      | elapsed:  2.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 23314 tasks      | elapsed:  2.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 23620 tasks      | elapsed:  2.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 23930 tasks      | elapsed:  2.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 24240 tasks      | elapsed:  2.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 24554 tasks      | elapsed:  2.3min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 24868 tasks      | elapsed:  2.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=16)]: Done 25118 out of 25149 | elapsed:  2.4min remaining:    0.2s\n[Parallel(n_jobs=16)]: Done 25149 out of 25149 | elapsed:  2.4min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved test_features.parquet with shape (25149, 1955) in 160.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded test_features.parquet: (25149, 1955)\nTest failed rows: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned shapes: (22692, 1954) (25149, 1954)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved aligned parquet files in 175.2s\n"
          ]
        }
      ]
    },
    {
      "id": "10102bbe-9770-4d7e-966a-ec94f76532d2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Modeling: StratifiedGroupKFold LightGBM (sklearn API for stable logging), OOF AUC, test prediction, submission\n",
        "import pandas as pd, numpy as np, time, os\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.utils import check_random_state\n",
        "\n",
        "t0 = time.time()\n",
        "# Load aligned features\n",
        "train_feat = pd.read_parquet('train_features_aligned.parquet')\n",
        "test_feat = pd.read_parquet('test_features_aligned.parquet')\n",
        "# Merge labels and groups\n",
        "aux = train_df[['clip','label','group_hour','group_date']].copy()\n",
        "df = train_feat.merge(aux, on='clip', how='left')\n",
        "assert df['label'].notnull().all(), 'Missing labels after merge'\n",
        "X_cols = [c for c in df.columns if c not in ['clip','label','group_hour','group_date']]\n",
        "print('n_feature_cols:', len(X_cols))\n",
        "\n",
        "# Remove constant cols\n",
        "vt = VarianceThreshold(threshold=0.0)\n",
        "X = df[X_cols].astype('float32').values\n",
        "X = vt.fit_transform(X)\n",
        "kept_mask = vt.get_support()\n",
        "X_cols_kept = [c for c, k in zip(X_cols, kept_mask) if k]\n",
        "print('Removed constant cols:', len(X_cols) - len(X_cols_kept))\n",
        "\n",
        "# Apply same to test\n",
        "Xt = test_feat[X_cols].astype('float32').values\n",
        "Xt = vt.transform(Xt)\n",
        "\n",
        "y = df['label'].values.astype(np.int32)\n",
        "groups = df['group_hour'].values\n",
        "rng = check_random_state(42)\n",
        "\n",
        "# LightGBM (sklearn API for better notebook logging)\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "except Exception:\n",
        "    import sys, subprocess\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'lightgbm'])\n",
        "    import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "pos = (y==1).sum(); neg = (y==0).sum()\n",
        "scale_pos_weight = float(neg)/float(pos)\n",
        "print('Class counts pos/neg:', pos, neg, 'scale_pos_weight:', round(scale_pos_weight,3))\n",
        "\n",
        "clf_params = {\n",
        "    'objective': 'binary',\n",
        "    'learning_rate': 0.05,\n",
        "    'n_estimators': 4000,\n",
        "    'num_leaves': 63,\n",
        "    'max_depth': -1,\n",
        "    'min_child_samples': 100,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'subsample': 0.8,\n",
        "    'subsample_freq': 1,\n",
        "    'reg_alpha': 0.3,\n",
        "    'reg_lambda': 12.0,\n",
        "    'scale_pos_weight': scale_pos_weight,\n",
        "    'n_jobs': 8,\n",
        "    'random_state': 1337\n",
        "}\n",
        "\n",
        "n_splits = 5\n",
        "skf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "oof = np.zeros(len(df), dtype=np.float32)\n",
        "test_preds = np.zeros(len(test_feat), dtype=np.float32)\n",
        "fold_aucs = []\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y, groups), 1):\n",
        "    t_fold = time.time()\n",
        "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "    pos_tr, pos_va = int(y_tr.sum()), int(y_va.sum())\n",
        "    print(f'Fold {fold}/{n_splits} | train:{len(tr_idx)} (pos {pos_tr}) valid:{len(va_idx)} (pos {pos_va})', flush=True)\n",
        "    if pos_va < 50:\n",
        "        print('Warning: low positives in validation fold')\n",
        "    model = LGBMClassifier(**clf_params)\n",
        "    # Use callbacks for early stopping/logging to support older sklearn API versions\n",
        "    callbacks = [\n",
        "        lgb.early_stopping(stopping_rounds=200, verbose=True),\n",
        "        lgb.log_evaluation(period=200)\n",
        "    ]\n",
        "    model.fit(\n",
        "        X[tr_idx], y_tr,\n",
        "        eval_set=[(X[va_idx], y_va)],\n",
        "        eval_metric='auc',\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "    best_iter = getattr(model, 'best_iteration_', None)\n",
        "    if best_iter is None:\n",
        "        best_iter = clf_params['n_estimators']\n",
        "    p_va = model.predict_proba(X[va_idx], num_iteration=best_iter)[:,1]\n",
        "    oof[va_idx] = p_va.astype(np.float32)\n",
        "    auc = roc_auc_score(y_va, p_va)\n",
        "    fold_aucs.append(auc)\n",
        "    print(f'  Fold {fold} AUC: {auc:.5f} | best_iter {best_iter} | time {time.time()-t_fold:.1f}s', flush=True)\n",
        "    test_preds += model.predict_proba(Xt, num_iteration=best_iter)[:,1].astype(np.float32) / n_splits\n",
        "\n",
        "oof_auc = roc_auc_score(y, oof)\n",
        "print('OOF AUC:', f'{oof_auc:.5f}', 'folds:', [f'{a:.5f}' for a in fold_aucs], 'mean\u00b1std:', f'{np.mean(fold_aucs):.5f}\u00b1{np.std(fold_aucs):.5f}')\n",
        "\n",
        "# Sanity 2-fold date-based CV\n",
        "dates = df['group_date'].values\n",
        "date_uni = np.unique(dates)\n",
        "if len(date_uni) >= 2:\n",
        "    mask_date = (dates == date_uni[0])\n",
        "    tr_idx = np.where(~mask_date)[0]; va_idx = np.where(mask_date)[0]\n",
        "    if va_idx.size > 0 and tr_idx.size > 0:\n",
        "        model_tmp = LGBMClassifier(**clf_params)\n",
        "        model_tmp.fit(X[tr_idx], y[tr_idx], eval_set=[(X[va_idx], y[va_idx])], eval_metric='auc', callbacks=[lgb.early_stopping(100, verbose=False)])\n",
        "        best_iter_tmp = getattr(model_tmp, 'best_iteration_', None)\n",
        "        if best_iter_tmp is None:\n",
        "            best_iter_tmp = clf_params['n_estimators']\n",
        "        p_va = model_tmp.predict_proba(X[va_idx], num_iteration=best_iter_tmp)[:,1]\n",
        "        auc_date = roc_auc_score(y[va_idx], p_va)\n",
        "        print('Date-based sanity AUC:', f'{auc_date:.5f}', 'date:', date_uni[0])\n",
        "\n",
        "# Build submission\n",
        "sample = pd.read_csv('sampleSubmission.csv')\n",
        "sub = pd.DataFrame({'clip': test_feat['clip'].values, 'probability': test_preds})\n",
        "sub = sample[['clip']].merge(sub, on='clip', how='left')\n",
        "miss = sub['probability'].isna().sum()\n",
        "if miss:\n",
        "    print('Warning: missing predictions for', miss, 'clips; filling with mean')\n",
        "    sub['probability'] = sub['probability'].fillna(float(test_preds.mean()))\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv', sub.shape, 'in', f'{time.time()-t0:.1f}s')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_feature_cols: 1953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed constant cols: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts pos/neg: 2266 20426 scale_pos_weight: 9.014\nFold 1/5 | train:19139 (pos 1872) valid:3553 (pos 394)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}