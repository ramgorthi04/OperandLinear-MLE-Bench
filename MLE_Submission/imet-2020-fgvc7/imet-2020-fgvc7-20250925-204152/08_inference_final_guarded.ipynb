{
  "cells": [
    {
      "id": "3662c7d8-35f2-425f-8639-62ecdf25d242",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from torchvision import transforms as T\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "class CFG:\n",
        "    # General\n",
        "    num_workers = 4\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Data paths\n",
        "    data_dir = './'\n",
        "    labels_csv_path = os.path.join(data_dir, 'labels.csv')\n",
        "    sample_submission_path = os.path.join(data_dir, 'sample_submission.csv')\n",
        "    test_img_dir = os.path.join(data_dir, 'test')\n",
        "    # MODIFIED: Use final robust thresholds from expert advice\n",
        "    thresholds_path = 'thresholds_final.npy'\n",
        "\n",
        "    # Model\n",
        "    model_name = 'tf_efficientnet_b4_ns'\n",
        "    img_size = 384\n",
        "    model_paths = [\n",
        "        'models/tf_efficientnet_b4_ns_fold0_best.pth',\n",
        "        'models/tf_efficientnet_b4_ns_fold1_best.pth',\n",
        "        'models/tf_efficientnet_b4_ns_fold2_best.pth'\n",
        "    ]\n",
        "\n",
        "    # Inference\n",
        "    # Using a very safe batch size as per expert advice\n",
        "    batch_size = 8\n",
        "\n",
        "# Load label mappings\n",
        "labels_df = pd.read_csv(CFG.labels_csv_path)\n",
        "CFG.attr_ids = labels_df['attribute_id'].values\n",
        "CFG.attr_id_to_idx = {attr_id: i for i, attr_id in enumerate(CFG.attr_ids)}\n",
        "CFG.idx_to_attr_id = {i: attr_id for i, attr_id in enumerate(CFG.attr_ids)}\n",
        "CFG.num_classes = len(labels_df)\n",
        "\n",
        "# Clean up memory\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "id": "23de3dea-76ce-4b40-a7f6-7e51c76ce12a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_test_transforms():\n",
        "    # This uses aspect-ratio preserving resize, center crop, and ImageNet normalization.\n",
        "    # TTA is disabled as per expert advice for the final run to save time and reduce complexity.\n",
        "    print(\"--- Applying CORRECTED validation transforms (Resize+CenterCrop, ImageNet Norm) ---\")\n",
        "    \n",
        "    return T.Compose([\n",
        "        T.Resize(CFG.img_size), # Preserves aspect ratio\n",
        "        T.CenterCrop(CFG.img_size),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406], # ImageNet stats\n",
        "            std=[0.229, 0.224, 0.225],\n",
        "        ),\n",
        "    ])\n",
        "\n",
        "class iMetTestDataset(Dataset):\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filepath = self.filepaths[idx]\n",
        "        image = Image.open(filepath).convert('RGB')\n",
        "        \n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return image\n",
        "\n",
        "class iMetModel(nn.Module):\n",
        "    def __init__(self, model_name, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=CFG.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "id": "9680a34d-dd2a-492d-a56d-edfc3df176ee",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Prepare Test Data\n",
        "sub_df = pd.read_csv(CFG.sample_submission_path)\n",
        "sub_df['filepath'] = sub_df['id'].apply(lambda x: os.path.join(CFG.test_img_dir, x + '.png'))\n",
        "display(sub_df.head())\n",
        "\n",
        "# Create the test dataset and loader (NO TTA)\n",
        "test_dataset = iMetTestDataset(sub_df, transforms=get_test_transforms())\n",
        "test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
        "\n",
        "print(\"Test data prepared.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                 id attribute_ids  \\\n0  347c119163f84420f10f7a8126c1b8a2         0 1 2   \n1  98c91458324cba5415c5f5d8ead68328         0 1 2   \n2  3f75d332f579af62ff88d369c0736c76         0 1 2   \n3  3fa35a29218b7449c8f03e2a368a708d         0 1 2   \n4  c848b91558e4edd8034cb7d334b4e448         0 1 2   \n\n                                      filepath  \n0  ./test/347c119163f84420f10f7a8126c1b8a2.png  \n1  ./test/98c91458324cba5415c5f5d8ead68328.png  \n2  ./test/3f75d332f579af62ff88d369c0736c76.png  \n3  ./test/3fa35a29218b7449c8f03e2a368a708d.png  \n4  ./test/c848b91558e4edd8034cb7d334b4e448.png  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>attribute_ids</th>\n      <th>filepath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>347c119163f84420f10f7a8126c1b8a2</td>\n      <td>0 1 2</td>\n      <td>./test/347c119163f84420f10f7a8126c1b8a2.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>98c91458324cba5415c5f5d8ead68328</td>\n      <td>0 1 2</td>\n      <td>./test/98c91458324cba5415c5f5d8ead68328.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3f75d332f579af62ff88d369c0736c76</td>\n      <td>0 1 2</td>\n      <td>./test/3f75d332f579af62ff88d369c0736c76.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3fa35a29218b7449c8f03e2a368a708d</td>\n      <td>0 1 2</td>\n      <td>./test/3fa35a29218b7449c8f03e2a368a708d.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c848b91558e4edd8034cb7d334b4e448</td>\n      <td>0 1 2</td>\n      <td>./test/c848b91558e4edd8034cb7d334b4e448.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Applying CORRECTED validation transforms (Resize+CenterCrop, ImageNet Norm) ---\nTest data prepared.\n"
          ]
        }
      ]
    },
    {
      "id": "81084458-2386-496b-8c7c-d16556dd6268",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Inference (Ensemble, NO TTA)\n",
        "\n",
        "# Pre-allocate array for summed predictions for memory efficiency\n",
        "n_samples = len(sub_df)\n",
        "total_preds = np.zeros((n_samples, CFG.num_classes), dtype=np.float32)\n",
        "\n",
        "for i, model_path in enumerate(CFG.model_paths):\n",
        "    print(f\"--- Inferencing with model {i+1}/{len(CFG.model_paths)}: {model_path} ---\")\n",
        "    \n",
        "    # FIX for OOM: Create model on CPU, load weights, THEN move to GPU.\n",
        "    model = iMetModel(CFG.model_name, pretrained=False) # 1. Create on CPU\n",
        "    state_dict = torch.load(model_path, map_location='cpu', weights_only=True) # 2. Load weights to CPU\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(CFG.device) # 3. Move fully loaded model to GPU\n",
        "    model.eval()\n",
        "\n",
        "    pbar = tqdm(test_loader, desc=f\"Predicting (Model {i+1})\")\n",
        "    current_pos = 0\n",
        "    with torch.no_grad():\n",
        "        for images in pbar:\n",
        "            images = images.to(CFG.device)\n",
        "            logits = model(images)\n",
        "            preds = logits.sigmoid().cpu().numpy()\n",
        "            \n",
        "            batch_size = images.size(0)\n",
        "            total_preds[current_pos : current_pos + batch_size] += preds\n",
        "            current_pos += batch_size\n",
        "            \n",
        "    # Clean up memory after each model\n",
        "    del model, state_dict\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# Average the predictions (3 models)\n",
        "all_preds = total_preds / len(CFG.model_paths)\n",
        "print(\"\\nEnsemble predictions calculated.\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "id": "1780deb2-de7d-401c-bdad-c5d4157acce9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Create Submission with Guarded, Robust Thresholds\n",
        "\n",
        "# Load the final thresholds\n",
        "thresholds = np.load(CFG.thresholds_path)\n",
        "print(f\"Loaded final thresholds from: {CFG.thresholds_path}\")\n",
        "print(f\"Thresholds shape: {thresholds.shape}\")\n",
        "\n",
        "# Define the guarded apply_thresholds function from expert advice\n",
        "def apply_thresholds_guarded(probs, th):\n",
        "    y = (probs > th).astype(np.uint8)\n",
        "    # At-least-one fallback\n",
        "    empty = y.sum(axis=1) == 0\n",
        "    if np.any(empty):\n",
        "        idx = probs[empty].argmax(axis=1)\n",
        "        rows = np.where(empty)[0]\n",
        "        y[rows, idx] = 1\n",
        "    # Optional: cap max positives per image\n",
        "    max_k = 3\n",
        "    row_sum = y.sum(axis=1)\n",
        "    too_many = np.where(row_sum > max_k)[0]\n",
        "    if too_many.size:\n",
        "        # This loop is slow, but for the final submission it's acceptable for correctness\n",
        "        for r in tqdm(too_many, desc=\"Applying max-k cap\"):\n",
        "            # Find the indices of the top-k probabilities for this row\n",
        "            topk_indices = np.argpartition(-probs[r], max_k)[:max_k]\n",
        "            # Create a new row of zeros and set only the top-k predictions to 1\n",
        "            new_row = np.zeros_like(y[r])\n",
        "            new_row[topk_indices] = 1\n",
        "            y[r] = new_row\n",
        "    return y\n",
        "\n",
        "print(\"Applying final thresholds with guards...\")\n",
        "final_preds_binary = apply_thresholds_guarded(all_preds, thresholds)\n",
        "\n",
        "# Format for submission\n",
        "predictions = []\n",
        "for pred_labels in tqdm(final_preds_binary, desc=\"Formatting submission strings\"):\n",
        "    # pred_labels is already a binary vector (0s and 1s)\n",
        "    attr_ids = [CFG.idx_to_attr_id[i] for i, label in enumerate(pred_labels) if label == 1]\n",
        "    predictions.append(' '.join(map(str, attr_ids)))\n",
        "\n",
        "sub_df['attribute_ids'] = predictions\n",
        "sub_df[['id', 'attribute_ids']].to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created successfully!\")\n",
        "display(sub_df.head())"
      ],
      "execution_count": 4,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}