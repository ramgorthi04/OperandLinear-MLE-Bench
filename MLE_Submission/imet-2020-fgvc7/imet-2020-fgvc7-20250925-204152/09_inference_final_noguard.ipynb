{
  "cells": [
    {
      "id": "71a53ccf-bef0-4263-a269-5947500b904e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from torchvision import transforms as T\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "class CFG:\n",
        "    # General\n",
        "    num_workers = 4\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Data paths\n",
        "    data_dir = './'\n",
        "    labels_csv_path = os.path.join(data_dir, 'labels.csv')\n",
        "    sample_submission_path = os.path.join(data_dir, 'sample_submission.csv')\n",
        "    test_img_dir = os.path.join(data_dir, 'test')\n",
        "    # FINAL STRATEGY: Use the newly generated thresholds with alpha=0.20\n",
        "    thresholds_path = 'thresholds_final.npy'\n",
        "\n",
        "    # Model\n",
        "    model_name = 'tf_efficientnet_b4_ns'\n",
        "    img_size = 384\n",
        "    model_paths = [\n",
        "        'models/tf_efficientnet_b4_ns_fold0_best.pth',\n",
        "        'models/tf_efficientnet_b4_ns_fold1_best.pth',\n",
        "        'models/tf_efficientnet_b4_ns_fold2_best.pth'\n",
        "    ]\n",
        "\n",
        "    # Inference\n",
        "    batch_size = 8\n",
        "\n",
        "# Load label mappings\n",
        "labels_df = pd.read_csv(CFG.labels_csv_path)\n",
        "CFG.attr_ids = labels_df['attribute_id'].values\n",
        "CFG.attr_id_to_idx = {attr_id: i for i, attr_id in enumerate(CFG.attr_ids)}\n",
        "CFG.idx_to_attr_id = {i: attr_id for i, attr_id in enumerate(CFG.attr_ids)}\n",
        "CFG.num_classes = len(labels_df)\n",
        "\n",
        "# Clean up memory\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "id": "3e40af57-1f56-4ea6-9e61-693dfc718e7f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_test_transforms():\n",
        "    # This uses aspect-ratio preserving resize, center crop, and ImageNet normalization.\n",
        "    print(\"--- Applying CORRECTED validation transforms (Resize+CenterCrop, ImageNet Norm) ---\")\n",
        "    \n",
        "    return T.Compose([\n",
        "        T.Resize(CFG.img_size), # Preserves aspect ratio\n",
        "        T.CenterCrop(CFG.img_size),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406], # ImageNet stats\n",
        "            std=[0.229, 0.224, 0.225],\n",
        "        ),\n",
        "    ])\n",
        "\n",
        "class iMetTestDataset(Dataset):\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filepath = self.filepaths[idx]\n",
        "        image = Image.open(filepath).convert('RGB')\n",
        "        \n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return image\n",
        "\n",
        "class iMetModel(nn.Module):\n",
        "    def __init__(self, model_name, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=CFG.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "id": "8cabe519-25e0-4762-a988-b5c5dc26face",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Prepare Test Data\n",
        "sub_df = pd.read_csv(CFG.sample_submission_path)\n",
        "sub_df['filepath'] = sub_df['id'].apply(lambda x: os.path.join(CFG.test_img_dir, x + '.png'))\n",
        "display(sub_df.head())\n",
        "\n",
        "# Create the test dataset and loader (NO TTA)\n",
        "test_dataset = iMetTestDataset(sub_df, transforms=get_test_transforms())\n",
        "test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
        "\n",
        "print(\"Test data prepared.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                 id attribute_ids  \\\n0  347c119163f84420f10f7a8126c1b8a2         0 1 2   \n1  98c91458324cba5415c5f5d8ead68328         0 1 2   \n2  3f75d332f579af62ff88d369c0736c76         0 1 2   \n3  3fa35a29218b7449c8f03e2a368a708d         0 1 2   \n4  c848b91558e4edd8034cb7d334b4e448         0 1 2   \n\n                                      filepath  \n0  ./test/347c119163f84420f10f7a8126c1b8a2.png  \n1  ./test/98c91458324cba5415c5f5d8ead68328.png  \n2  ./test/3f75d332f579af62ff88d369c0736c76.png  \n3  ./test/3fa35a29218b7449c8f03e2a368a708d.png  \n4  ./test/c848b91558e4edd8034cb7d334b4e448.png  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>attribute_ids</th>\n      <th>filepath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>347c119163f84420f10f7a8126c1b8a2</td>\n      <td>0 1 2</td>\n      <td>./test/347c119163f84420f10f7a8126c1b8a2.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>98c91458324cba5415c5f5d8ead68328</td>\n      <td>0 1 2</td>\n      <td>./test/98c91458324cba5415c5f5d8ead68328.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3f75d332f579af62ff88d369c0736c76</td>\n      <td>0 1 2</td>\n      <td>./test/3f75d332f579af62ff88d369c0736c76.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3fa35a29218b7449c8f03e2a368a708d</td>\n      <td>0 1 2</td>\n      <td>./test/3fa35a29218b7449c8f03e2a368a708d.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>c848b91558e4edd8034cb7d334b4e448</td>\n      <td>0 1 2</td>\n      <td>./test/c848b91558e4edd8034cb7d334b4e448.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Applying CORRECTED validation transforms (Resize+CenterCrop, ImageNet Norm) ---\nTest data prepared.\n"
          ]
        }
      ]
    },
    {
      "id": "0604a595-6605-4ae7-ad82-00876da85083",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Inference (Ensemble, NO TTA)\n",
        "\n",
        "# Pre-allocate array for summed predictions for memory efficiency\n",
        "n_samples = len(sub_df)\n",
        "total_preds = np.zeros((n_samples, CFG.num_classes), dtype=np.float32)\n",
        "\n",
        "for i, model_path in enumerate(CFG.model_paths):\n",
        "    print(f\"--- Inferencing with model {i+1}/{len(CFG.model_paths)}: {model_path} ---\")\n",
        "    \n",
        "    # FIX for OOM: Create model on CPU, load weights, THEN move to GPU.\n",
        "    model = iMetModel(CFG.model_name, pretrained=False) # 1. Create on CPU\n",
        "    state_dict = torch.load(model_path, map_location='cpu', weights_only=True) # 2. Load weights to CPU\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to(CFG.device) # 3. Move fully loaded model to GPU\n",
        "    model.eval()\n",
        "\n",
        "    pbar = tqdm(test_loader, desc=f\"Predicting (Model {i+1})\")\n",
        "    current_pos = 0\n",
        "    with torch.no_grad():\n",
        "        for images in pbar:\n",
        "            images = images.to(CFG.device)\n",
        "            logits = model(images)\n",
        "            preds = logits.sigmoid().cpu().numpy()\n",
        "            \n",
        "            batch_size = images.size(0)\n",
        "            total_preds[current_pos : current_pos + batch_size] += preds\n",
        "            current_pos += batch_size\n",
        "            \n",
        "    # Clean up memory after each model\n",
        "    del model, state_dict\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# Average the predictions (3 models)\n",
        "all_preds = total_preds / len(CFG.model_paths)\n",
        "print(\"\\nEnsemble predictions calculated.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Inferencing with model 1/3: models/tf_efficientnet_b4_ns_fold0_best.pth ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   0%|          | 0/2665 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   0%|          | 1/2665 [00:00<08:47,  5.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   0%|          | 4/2665 [00:00<02:59, 14.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   0%|          | 7/2665 [00:00<02:15, 19.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   0%|          | 10/2665 [00:00<01:58, 22.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   0%|          | 13/2665 [00:00<01:49, 24.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   1%|          | 16/2665 [00:00<01:45, 25.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   1%|          | 19/2665 [00:00<01:42, 25.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   1%|          | 22/2665 [00:00<01:40, 26.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   1%|          | 25/2665 [00:01<01:39, 26.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   1%|          | 28/2665 [00:01<01:38, 26.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   1%|          | 31/2665 [00:01<01:38, 26.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   1%|\u258f         | 34/2665 [00:01<01:37, 27.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   1%|\u258f         | 37/2665 [00:01<01:36, 27.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   2%|\u258f         | 40/2665 [00:01<01:36, 27.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   2%|\u258f         | 43/2665 [00:01<01:36, 27.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   2%|\u258f         | 46/2665 [00:01<01:36, 27.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   2%|\u258f         | 49/2665 [00:01<01:36, 27.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   2%|\u258f         | 52/2665 [00:02<01:36, 27.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   2%|\u258f         | 55/2665 [00:02<01:36, 27.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   2%|\u258f         | 58/2665 [00:02<01:36, 27.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   2%|\u258f         | 61/2665 [00:02<01:36, 27.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   2%|\u258f         | 64/2665 [00:02<01:35, 27.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   3%|\u258e         | 67/2665 [00:02<01:35, 27.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   3%|\u258e         | 70/2665 [00:02<01:35, 27.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   3%|\u258e         | 73/2665 [00:02<01:34, 27.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   3%|\u258e         | 76/2665 [00:02<01:34, 27.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   3%|\u258e         | 79/2665 [00:03<01:34, 27.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   3%|\u258e         | 82/2665 [00:03<01:34, 27.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   3%|\u258e         | 85/2665 [00:03<01:34, 27.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   3%|\u258e         | 88/2665 [00:03<01:34, 27.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   3%|\u258e         | 91/2665 [00:03<01:34, 27.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   4%|\u258e         | 94/2665 [00:03<01:34, 27.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   4%|\u258e         | 97/2665 [00:03<01:33, 27.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   4%|\u258d         | 100/2665 [00:03<01:33, 27.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   4%|\u258d         | 103/2665 [00:03<01:33, 27.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   4%|\u258d         | 106/2665 [00:04<01:33, 27.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   4%|\u258d         | 109/2665 [00:04<01:33, 27.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   4%|\u258d         | 112/2665 [00:04<01:33, 27.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   4%|\u258d         | 115/2665 [00:04<01:33, 27.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   4%|\u258d         | 118/2665 [00:04<01:32, 27.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   5%|\u258d         | 121/2665 [00:04<01:32, 27.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rPredicting (Model 1):   5%|\u258d         | 124/2665 [00:04<01:32, 27.41it/s]"
          ]
        }
      ]
    },
    {
      "id": "4e6770b7-48be-40c0-aaca-6d90648b1eea",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Create Submission with Blended Thresholds (NO MAX-K GUARD)\n",
        "\n",
        "# Load the blended thresholds\n",
        "try:\n",
        "    thresholds = np.load(CFG.thresholds_path)\n",
        "    print(f\"Loaded blended thresholds from: {CFG.thresholds_path}\")\n",
        "    print(f\"Thresholds shape: {thresholds.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Threshold file not found at {CFG.thresholds_path}. Make sure it exists.\")\n",
        "    # Stop execution if the file is missing\n",
        "    raise\n",
        "\n",
        "predictions = []\n",
        "for pred_row in tqdm(all_preds, desc=\"Formatting submission\"):\n",
        "    # Apply blended per-class thresholds\n",
        "    pred_labels = (pred_row > thresholds).astype(int)\n",
        "    \n",
        "    # If no labels are predicted, take the one with the highest probability as a fallback\n",
        "    if pred_labels.sum() == 0:\n",
        "        pred_labels[pred_row.argmax()] = 1\n",
        "        \n",
        "    # Convert indices to attribute_ids\n",
        "    attr_ids = [CFG.idx_to_attr_id[i] for i, label in enumerate(pred_labels) if label == 1]\n",
        "    predictions.append(' '.join(map(str, attr_ids)))\n",
        "\n",
        "sub_df['attribute_ids'] = predictions\n",
        "sub_df[['id', 'attribute_ids']].to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created successfully!\")\n",
        "display(sub_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}