{
  "cells": [
    {
      "id": "9d48e070-cf0e-4d36-be78-74a8b7f72117",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from torchvision import transforms as T\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "class CFG:\n",
        "    # General\n",
        "    num_workers = 4\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Data paths\n",
        "    data_dir = './'\n",
        "    labels_csv_path = os.path.join(data_dir, 'labels.csv')\n",
        "    sample_submission_path = os.path.join(data_dir, 'sample_submission.csv')\n",
        "    test_img_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "    # Model\n",
        "    model_name = 'tf_efficientnet_b4_ns'\n",
        "    img_size = 384\n",
        "    model_paths = [\n",
        "        'models/tf_efficientnet_b4_ns_fold0_best.pth',\n",
        "        'models/tf_efficientnet_b4_ns_fold1_best.pth',\n",
        "        'models/tf_efficientnet_b4_ns_fold2_best.pth'\n",
        "    ]\n",
        "\n",
        "    # Inference\n",
        "    batch_size = 32\n",
        "    # This threshold was found by optimizing sample-wise F2 on the OOF predictions.\n",
        "    threshold = 0.9300\n",
        "\n",
        "# Load label mappings\n",
        "labels_df = pd.read_csv(CFG.labels_csv_path)\n",
        "CFG.attr_ids = labels_df['attribute_id'].values\n",
        "CFG.attr_id_to_idx = {attr_id: i for i, attr_id in enumerate(CFG.attr_ids)}\n",
        "CFG.idx_to_attr_id = {i: attr_id for i, attr_id in enumerate(CFG.attr_ids)}\n",
        "CFG.num_classes = len(labels_df)\n",
        "\n",
        "# Clean up memory\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7d2070ee-73e9-4d5a-b882-f2becef3a805",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_test_transforms(flipped=False):\n",
        "    # CORRECTED: Based on 01_training_pipeline.ipynb and successful OOF generation.\n",
        "    # This uses aspect-ratio preserving resize, center crop, and ImageNet normalization.\n",
        "    print(\"--- Applying CORRECTED validation transforms (Resize+CenterCrop, ImageNet Norm) ---\")\n",
        "    \n",
        "    transforms_list = [\n",
        "        T.Resize(CFG.img_size), # Preserves aspect ratio\n",
        "        T.CenterCrop(CFG.img_size),\n",
        "    ]\n",
        "    \n",
        "    if flipped:\n",
        "        # Apply horizontal flip for TTA\n",
        "        transforms_list.append(T.RandomHorizontalFlip(p=1.0))\n",
        "\n",
        "    transforms_list.extend([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406], # ImageNet stats\n",
        "            std=[0.229, 0.224, 0.225],\n",
        "        ),\n",
        "    ])\n",
        "    \n",
        "    return T.Compose(transforms_list)\n",
        "\n",
        "class iMetTestDataset(Dataset):\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filepath = self.filepaths[idx]\n",
        "        image = Image.open(filepath).convert('RGB')\n",
        "        \n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return image\n",
        "\n",
        "class iMetModel(nn.Module):\n",
        "    def __init__(self, model_name, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=CFG.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "3193007e-21b3-4249-975e-55e2cf00e9fc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Prepare Test Data\n",
        "sub_df = pd.read_csv(CFG.sample_submission_path)\n",
        "sub_df['filepath'] = sub_df['id'].apply(lambda x: os.path.join(CFG.test_img_dir, x + '.png'))\n",
        "display(sub_df.head())\n",
        "\n",
        "# Create two datasets: one for original images, one for flipped\n",
        "test_dataset_normal = iMetTestDataset(sub_df, transforms=get_test_transforms(flipped=False))\n",
        "test_loader_normal = DataLoader(test_dataset_normal, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
        "\n",
        "test_dataset_flipped = iMetTestDataset(sub_df, transforms=get_test_transforms(flipped=True))\n",
        "test_loader_flipped = DataLoader(test_dataset_flipped, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0dc1b712-5350-4114-a74f-c4211b61e0c3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Inference with TTA (Ensemble)\n",
        "\n",
        "# Pre-allocate array for summed predictions for memory efficiency\n",
        "n_samples = len(sub_df)\n",
        "# We will sum predictions from 3 models * 2 augmentations (normal, flipped)\n",
        "total_preds = np.zeros((n_samples, CFG.num_classes), dtype=np.float32)\n",
        "tta_loaders = {\n",
        "    \"normal\": test_loader_normal,\n",
        "    \"flipped\": test_loader_flipped\n",
        "}\n",
        "\n",
        "for i, model_path in enumerate(CFG.model_paths):\n",
        "    print(f\"--- Inferencing with model {i+1}/{len(CFG.model_paths)}: {model_path} ---\")\n",
        "    \n",
        "    # Load model\n",
        "    model = iMetModel(CFG.model_name, pretrained=False).to(CFG.device)\n",
        "    # Set weights_only=True for security\n",
        "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
        "    model.eval()\n",
        "\n",
        "    # TTA loop\n",
        "    for tta_type, test_loader in tta_loaders.items():\n",
        "        print(f\"  -- TTA: {tta_type} --\")\n",
        "        pbar = tqdm(test_loader, desc=f\"Predicting (Model {i+1}, {tta_type})\")\n",
        "        current_pos = 0\n",
        "        with torch.no_grad():\n",
        "            for images in pbar:\n",
        "                images = images.to(CFG.device)\n",
        "                logits = model(images)\n",
        "                preds = logits.sigmoid().cpu().numpy()\n",
        "                \n",
        "                batch_size = images.size(0)\n",
        "                total_preds[current_pos : current_pos + batch_size] += preds\n",
        "                current_pos += batch_size\n",
        "            \n",
        "    # Clean up memory after each model\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# Average the predictions (3 models * 2 TTA = 6 total predictions per image)\n",
        "all_preds = total_preds / (len(CFG.model_paths) * len(tta_loaders))\n",
        "print(\"\\nEnsemble TTA predictions calculated.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a3b34421-ce42-44eb-bf94-3c9e1fdab84d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Create Submission\n",
        "predictions = []\n",
        "for pred_row in tqdm(all_preds, desc=\"Formatting submission\"):\n",
        "    # Apply threshold\n",
        "    pred_labels = (pred_row > CFG.threshold).astype(int)\n",
        "    \n",
        "    # If no labels are predicted, take the one with the highest probability\n",
        "    if pred_labels.sum() == 0:\n",
        "        pred_labels[pred_row.argmax()] = 1\n",
        "        \n",
        "    # Convert indices to attribute_ids\n",
        "    attr_ids = [CFG.idx_to_attr_id[i] for i, label in enumerate(pred_labels) if label == 1]\n",
        "    predictions.append(' '.join(map(str, attr_ids)))\n",
        "\n",
        "sub_df['attribute_ids'] = predictions\n",
        "sub_df[['id', 'attribute_ids']].to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created successfully!\")\n",
        "display(sub_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}