{
  "cells": [
    {
      "id": "bafbdcab-7cad-450b-966b-668a96e88471",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# iMet Collection 2020 - FGVC7: Plan and EDA\n",
        "\n",
        "## 1. Goal\n",
        "The objective is to classify artworks from The Met's collection with fine-grained attributes. This is a multi-label image classification problem. The evaluation metric is the micro F1-score.\n",
        "\n",
        "**Medal Targets:**\n",
        "- **Gold:** \u2265 0.696\n",
        "- **Silver:** \u2265 0.649\n",
        "- **Bronze:** \u2265 0.649\n",
        "\n",
        "## 2. Revised Workflow Plan (Post-Expert Review)\n",
        "The initial plan has been updated based on expert feedback to accelerate progress towards a medal-winning solution. The focus is on using proven high-impact techniques for multi-label classification from the start.\n",
        "\n",
        "### Key Changes from Initial Plan:\n",
        "- **Model:** Start directly with a strong baseline: `tf_efficientnet_b4_ns` at 384px.\n",
        "- **Validation:** Use `MultilabelStratifiedKFold` immediately. It's critical for this problem.\n",
        "- **Loss Function:** Prioritize `Asymmetric Loss (ASL)` or `BCEWithLogitsLoss` with `pos_weight` to handle class imbalance.\n",
        "- **Training:** Employ Automatic Mixed Precision (AMP) and potentially Exponential Moving Average (EMA) for faster and more stable training.\n",
        "- **Thresholding:** **Do not use a fixed 0.5 threshold.** Tune a global threshold on Out-of-Fold (OOF) predictions. Implement a fallback to predict the highest-scoring class if no prediction exceeds the threshold.\n",
        "- **TTA:** Use horizontal flip Test-Time Augmentation (TTA) during inference.\n",
        "\n",
        "### Phase 1: Fast-Track Setup & EDA (Hours 0-4)\n",
        "1.  **Essential EDA:**\n",
        "    - Load `train.csv` and `labels.csv`.\n",
        "    - Create the multi-hot encoded label matrix.\n",
        "    - Analyze label frequencies and the distribution of labels per image to understand the imbalance.\n",
        "    - Create stable mappings: `attribute_id <-> class_index`.\n",
        "2.  **Validation Strategy:**\n",
        "    - Implement a `MultilabelStratifiedKFold` split (e.g., 5 folds). We will start by training on just one fold to iterate quickly.\n",
        "3.  **Dataloader Pipeline:**\n",
        "    - Create a PyTorch `Dataset`.\n",
        "    - Use `albumentations` for augmentations: `RandomResizedCrop(384)`, `HorizontalFlip`, light color jitter.\n",
        "    - Ensure dataloaders are fast: set `num_workers`, `pin_memory=True`.\n",
        "\n",
        "### Phase 2: Strong Baseline Training (Hours 4-14)\n",
        "1.  **Model & Training Recipe:**\n",
        "    - **Model:** `timm.create_model('tf_efficientnet_b4_ns', pretrained=True, num_classes=N_CLASSES)`.\n",
        "    - **Image Size:** 384x384.\n",
        "    - **Loss:** `BCEWithLogitsLoss` with pre-calculated `pos_weight`. (ASL is a later improvement if needed).\n",
        "    - **Optimizer:** `AdamW`.\n",
        "    - **Scheduler:** `CosineAnnealingLR` with warmup.\n",
        "    - **Training:** Use AMP (`torch.cuda.amp`). Train for 6-8 epochs on a single fold to establish a baseline score and training time.\n",
        "2.  **Evaluation & Checkpointing:**\n",
        "    - In the validation loop, save OOF predictions (logits/probabilities).\n",
        "    - Track both validation loss and micro F1-score.\n",
        "    - Save the model checkpoint with the best micro F1-score.\n",
        "\n",
        "### Phase 3: Optimization & Scaling (Hours 14-20)\n",
        "1.  **Threshold Optimization:**\n",
        "    - Using the saved OOF predictions from the first fold, perform a grid search to find the optimal global threshold for the micro F1-score.\n",
        "    - Implement the \"at-least-one\" fallback: if an image has no predictions above the threshold, assign it the label with the highest probability.\n",
        "2.  **Cross-Validation Training:**\n",
        "    - If time permits and the single-fold model is promising, train models on the remaining folds of the `MultilabelStratifiedKFold` split.\n",
        "3.  **Inference:**\n",
        "    - Write a clean inference loop for the test set.\n",
        "    - Implement horizontal flip TTA: predict on original and flipped images, then average the logits.\n",
        "\n",
        "### Phase 4: Final Submission (Hours 20-24)\n",
        "1.  **Ensembling & Prediction:**\n",
        "    - Average the (TTA-enhanced) logit predictions from all trained fold models.\n",
        "2.  **Final Prediction Generation:**\n",
        "    - Apply the globally optimized threshold to the averaged predictions.\n",
        "    - Apply the \"at-least-one\" fallback rule.\n",
        "    - Convert the binary predictions back to `attribute_ids`.\n",
        "3.  **Submission:**\n",
        "    - Format the predictions into `submission.csv` ensuring the `id` order matches `sample_submission.csv` and `attribute_ids` are space-separated strings.\n",
        "    - Perform a final sanity check on the file format."
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}