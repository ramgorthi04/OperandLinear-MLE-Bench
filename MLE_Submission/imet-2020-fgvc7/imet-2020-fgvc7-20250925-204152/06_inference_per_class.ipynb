{
  "cells": [
    {
      "id": "a407020b-4c4c-4f27-923f-94afb68c1901",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from torchvision import transforms as T\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "class CFG:\n",
        "    # General\n",
        "    num_workers = 4\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Data paths\n",
        "    data_dir = './'\n",
        "    labels_csv_path = os.path.join(data_dir, 'labels.csv')\n",
        "    sample_submission_path = os.path.join(data_dir, 'sample_submission.csv')\n",
        "    test_img_dir = os.path.join(data_dir, 'test')\n",
        "    per_class_thresholds_path = 'per_class_thresholds.npy'\n",
        "\n",
        "    # Model\n",
        "    model_name = 'tf_efficientnet_b4_ns'\n",
        "    img_size = 384\n",
        "    model_paths = [\n",
        "        'models/tf_efficientnet_b4_ns_fold0_best.pth',\n",
        "        'models/tf_efficientnet_b4_ns_fold1_best.pth',\n",
        "        'models/tf_efficientnet_b4_ns_fold2_best.pth'\n",
        "    ]\n",
        "\n",
        "    # Inference\n",
        "    batch_size = 32\n",
        "\n",
        "# Load label mappings\n",
        "labels_df = pd.read_csv(CFG.labels_csv_path)\n",
        "CFG.attr_ids = labels_df['attribute_id'].values\n",
        "CFG.attr_id_to_idx = {attr_id: i for i, attr_id in enumerate(CFG.attr_ids)}\n",
        "CFG.idx_to_attr_id = {i: attr_id for i, attr_id in enumerate(CFG.attr_ids)}\n",
        "CFG.num_classes = len(labels_df)\n",
        "\n",
        "# Clean up memory\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "21fa156b-1688-4f1d-9428-32b38084412a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_test_transforms(flipped=False):\n",
        "    # This uses aspect-ratio preserving resize, center crop, and ImageNet normalization.\n",
        "    print(\"--- Applying CORRECTED validation transforms (Resize+CenterCrop, ImageNet Norm) ---\")\n",
        "    \n",
        "    transforms_list = [\n",
        "        T.Resize(CFG.img_size), # Preserves aspect ratio\n",
        "        T.CenterCrop(CFG.img_size),\n",
        "    ]\n",
        "    \n",
        "    if flipped:\n",
        "        transforms_list.append(T.RandomHorizontalFlip(p=1.0))\n",
        "\n",
        "    transforms_list.extend([\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406], # ImageNet stats\n",
        "            std=[0.229, 0.224, 0.225],\n",
        "        ),\n",
        "    ])\n",
        "    \n",
        "    return T.Compose(transforms_list)\n",
        "\n",
        "class iMetTestDataset(Dataset):\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filepath = self.filepaths[idx]\n",
        "        image = Image.open(filepath).convert('RGB')\n",
        "        \n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        return image\n",
        "\n",
        "class iMetModel(nn.Module):\n",
        "    def __init__(self, model_name, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=CFG.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "3c598b5d-9b38-47a1-a865-ef24cd2e9ff9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Prepare Test Data\n",
        "sub_df = pd.read_csv(CFG.sample_submission_path)\n",
        "sub_df['filepath'] = sub_df['id'].apply(lambda x: os.path.join(CFG.test_img_dir, x + '.png'))\n",
        "display(sub_df.head())\n",
        "\n",
        "# Create two datasets: one for original images, one for flipped\n",
        "test_dataset_normal = iMetTestDataset(sub_df, transforms=get_test_transforms(flipped=False))\n",
        "test_loader_normal = DataLoader(test_dataset_normal, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
        "\n",
        "test_dataset_flipped = iMetTestDataset(sub_df, transforms=get_test_transforms(flipped=True))\n",
        "test_loader_flipped = DataLoader(test_dataset_flipped, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "2bfed6fd-6693-4e50-a9a9-ee46b6955ed8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Inference with TTA (Ensemble)\n",
        "\n",
        "# Pre-allocate array for summed predictions for memory efficiency\n",
        "n_samples = len(sub_df)\n",
        "# We will sum predictions from 3 models * 2 augmentations (normal, flipped)\n",
        "total_preds = np.zeros((n_samples, CFG.num_classes), dtype=np.float32)\n",
        "tta_loaders = {\n",
        "    \"normal\": test_loader_normal,\n",
        "    \"flipped\": test_loader_flipped\n",
        "}\n",
        "\n",
        "for i, model_path in enumerate(CFG.model_paths):\n",
        "    print(f\"--- Inferencing with model {i+1}/{len(CFG.model_paths)}: {model_path} ---\")\n",
        "    \n",
        "    # Load model\n",
        "    model = iMetModel(CFG.model_name, pretrained=False).to(CFG.device)\n",
        "    # Set weights_only=True for security\n",
        "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
        "    model.eval()\n",
        "\n",
        "    # TTA loop\n",
        "    for tta_type, test_loader in tta_loaders.items():\n",
        "        print(f\"  -- TTA: {tta_type} --\")\n",
        "        pbar = tqdm(test_loader, desc=f\"Predicting (Model {i+1}, {tta_type})\")\n",
        "        current_pos = 0\n",
        "        with torch.no_grad():\n",
        "            for images in pbar:\n",
        "                images = images.to(CFG.device)\n",
        "                logits = model(images)\n",
        "                preds = logits.sigmoid().cpu().numpy()\n",
        "                \n",
        "                batch_size = images.size(0)\n",
        "                total_preds[current_pos : current_pos + batch_size] += preds\n",
        "                current_pos += batch_size\n",
        "            \n",
        "    # Clean up memory after each model\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# Average the predictions (3 models * 2 TTA = 6 total predictions per image)\n",
        "all_preds = total_preds / (len(CFG.model_paths) * len(tta_loaders))\n",
        "print(\"\\nEnsemble TTA predictions calculated.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f0ce3b5a-ac80-4b7a-8780-606b865b40cd",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Create Submission with Per-Class Thresholds\n",
        "\n",
        "# Load the per-class thresholds\n",
        "per_class_thresholds = np.load(CFG.per_class_thresholds_path)\n",
        "print(f\"Loaded per-class thresholds from: {CFG.per_class_thresholds_path}\")\n",
        "print(f\"Thresholds shape: {per_class_thresholds.shape}\")\n",
        "\n",
        "predictions = []\n",
        "for pred_row in tqdm(all_preds, desc=\"Formatting submission\"):\n",
        "    # Apply per-class thresholds\n",
        "    # The thresholds array has shape (num_classes,), so it will broadcast correctly\n",
        "    pred_labels = (pred_row > per_class_thresholds).astype(int)\n",
        "    \n",
        "    # If no labels are predicted, take the one with the highest probability\n",
        "    if pred_labels.sum() == 0:\n",
        "        pred_labels[pred_row.argmax()] = 1\n",
        "        \n",
        "    # Convert indices to attribute_ids\n",
        "    attr_ids = [CFG.idx_to_attr_id[i] for i, label in enumerate(pred_labels) if label == 1]\n",
        "    predictions.append(' '.join(map(str, attr_ids)))\n",
        "\n",
        "sub_df['attribute_ids'] = predictions\n",
        "sub_df[['id', 'attribute_ids']].to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created successfully!\")\n",
        "display(sub_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}