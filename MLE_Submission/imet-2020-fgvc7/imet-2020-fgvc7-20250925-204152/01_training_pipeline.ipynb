{
  "cells": [
    {
      "id": "8acc657c-eb54-4377-b507-fc6414695953",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import timm\n",
        "from torchvision import transforms as T\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import time\n",
        "\n",
        "# For multi-label stratification\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "class CFG:\n",
        "    # General\n",
        "    debug = False  # Set to True to run on a small subset for quick debugging\n",
        "    seed = 42\n",
        "    num_workers = 4\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Data paths\n",
        "    data_dir = './'\n",
        "    train_csv_path = os.path.join(data_dir, 'train.csv')\n",
        "    labels_csv_path = os.path.join(data_dir, 'labels.csv')\n",
        "    sample_submission_path = os.path.join(data_dir, 'sample_submission.csv')\n",
        "    train_img_dir = os.path.join(data_dir, 'train')\n",
        "    test_img_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "    # Model\n",
        "    model_name = 'tf_efficientnet_b4_ns'\n",
        "    img_size = 384\n",
        "\n",
        "    # Training\n",
        "    epochs = 8\n",
        "    batch_size = 32\n",
        "    lr = 1e-4\n",
        "    weight_decay = 1e-6\n",
        "    n_folds = 3\n",
        "    target_fold = 2 # Train fold 2\n",
        "\n",
        "    # Output\n",
        "    output_dir = 'models'\n",
        "\n",
        "if not os.path.exists(CFG.output_dir):\n",
        "    os.makedirs(CFG.output_dir)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "id": "4a470750-e760-40f2-8a76-bc868db9ab28",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## 1.2 Data Loading and Preprocessing\n",
        "\n",
        "def get_df():\n",
        "    # Load dataframes\n",
        "    train_df = pd.read_csv(CFG.train_csv_path)\n",
        "    labels_df = pd.read_csv(CFG.labels_csv_path)\n",
        "    \n",
        "    # If in debug mode, sample the dataframe first for speed\n",
        "    if CFG.debug:\n",
        "        print(\"Running in debug mode, sampling 1000 unique images.\")\n",
        "        unique_ids = train_df['id'].unique()\n",
        "        sampled_ids = np.random.choice(unique_ids, size=1000, replace=False)\n",
        "        train_df = train_df[train_df['id'].isin(sampled_ids)].reset_index(drop=True)\n",
        "\n",
        "    # Create a mapping from attribute_id to a continuous index\n",
        "    CFG.attr_ids = labels_df['attribute_id'].values\n",
        "    CFG.attr_id_to_idx = {attr_id: i for i, attr_id in enumerate(CFG.attr_ids)}\n",
        "    CFG.idx_to_attr_id = {i: attr_id for i, attr_id in enumerate(CFG.attr_ids)}\n",
        "    CFG.num_classes = len(labels_df)\n",
        "    print(f\"Number of classes: {CFG.num_classes}\")\n",
        "\n",
        "    # Process train_df to create multi-hot encoded labels\n",
        "    # Group by id and aggregate attribute_ids\n",
        "    train_agg = train_df.groupby('id')['attribute_ids'].apply(lambda x: ' '.join(x)).reset_index()\n",
        "    \n",
        "    # Create the multi-hot encoded matrix\n",
        "    targets = np.zeros((len(train_agg), CFG.num_classes), dtype=np.int8)\n",
        "    for i, row in tqdm(train_agg.iterrows(), total=len(train_agg), desc=\"Processing labels\"):\n",
        "        attr_ids = [int(attr_id) for attr_id in row['attribute_ids'].split()]\n",
        "        for attr_id in attr_ids:\n",
        "            if attr_id in CFG.attr_id_to_idx:\n",
        "                targets[i, CFG.attr_id_to_idx[attr_id]] = 1\n",
        "    \n",
        "    train_agg['targets'] = list(targets)\n",
        "    \n",
        "    # Add file paths\n",
        "    train_agg['filepath'] = train_agg['id'].apply(lambda x: os.path.join(CFG.train_img_dir, x + '.png'))\n",
        "    \n",
        "    # Create folds with MultilabelStratifiedKFold\n",
        "    print(\"Creating folds with MultilabelStratifiedKFold...\")\n",
        "    y_labels = np.array(train_agg['targets'].tolist())\n",
        "    mskf = MultilabelStratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
        "    train_agg['fold'] = -1\n",
        "    for fold, (_, val_idx) in enumerate(mskf.split(np.zeros(len(train_agg)), y_labels)):\n",
        "        train_agg.loc[val_idx, 'fold'] = fold\n",
        "        \n",
        "    return train_agg\n",
        "\n",
        "df = get_df()\n",
        "display(df.head())\n",
        "print(f\"Shape of the dataframe: {df.shape}\")\n",
        "print(f\"Fold distribution:\\n{df['fold'].value_counts()}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 3474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:   0%|          | 0/120801 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:   3%|\u258e         | 3688/120801 [00:00<00:03, 36875.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:   6%|\u258b         | 7654/120801 [00:00<00:02, 38512.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  10%|\u2589         | 11662/120801 [00:00<00:02, 39226.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  13%|\u2588\u258e        | 15637/120801 [00:00<00:02, 39430.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  16%|\u2588\u258c        | 19610/120801 [00:00<00:02, 39535.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  20%|\u2588\u2589        | 23564/120801 [00:00<00:02, 39448.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  23%|\u2588\u2588\u258e       | 27521/120801 [00:00<00:02, 39485.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  26%|\u2588\u2588\u258c       | 31508/120801 [00:00<00:02, 39607.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  29%|\u2588\u2588\u2589       | 35469/120801 [00:00<00:02, 39603.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  33%|\u2588\u2588\u2588\u258e      | 39468/120801 [00:01<00:02, 39721.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  36%|\u2588\u2588\u2588\u258c      | 43444/120801 [00:01<00:01, 39732.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  39%|\u2588\u2588\u2588\u2589      | 47503/120801 [00:01<00:01, 39993.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  43%|\u2588\u2588\u2588\u2588\u258e     | 51557/120801 [00:01<00:01, 40158.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  46%|\u2588\u2588\u2588\u2588\u258c     | 55573/120801 [00:01<00:01, 40122.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  49%|\u2588\u2588\u2588\u2588\u2589     | 59586/120801 [00:01<00:01, 40083.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 63595/120801 [00:01<00:01, 39973.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 67593/120801 [00:01<00:01, 39918.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 71591/120801 [00:01<00:01, 39934.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 75594/120801 [00:01<00:01, 39961.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 79596/120801 [00:02<00:01, 39976.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 83594/120801 [00:02<00:00, 39955.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 87590/120801 [00:02<00:00, 39818.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 91572/120801 [00:02<00:00, 39762.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 95560/120801 [00:02<00:00, 39794.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 99540/120801 [00:02<00:00, 39742.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 103515/120801 [00:02<00:00, 39664.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 107499/120801 [00:02<00:00, 39715.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 111471/120801 [00:02<00:00, 39715.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 115484/120801 [00:02<00:00, 39839.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 119468/120801 [00:03<00:00, 39765.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing labels: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 120801/120801 [00:03<00:00, 39719.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating folds with MultilabelStratifiedKFold...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                                 id                      attribute_ids  \\\n0  000040d66f14ced4cdd18cd95d91800f                       448 2429 782   \n1  0000ef13e37ef70412166725ec034a8a  2997 3231 2730 3294 3099 2017 784   \n2  0001eeb4a06e8daa7c6951bcd124c3c7                       2436 1715 23   \n3  000226398d224de78b191e6db45fd94e                  2997 3433 448 782   \n4  00029c3b0171158d63b1bbf803a7d750            3465 3322 3170 1553 781   \n\n                                             targets  \\\n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n\n                                       filepath  fold  \n0  ./train/000040d66f14ced4cdd18cd95d91800f.png     2  \n1  ./train/0000ef13e37ef70412166725ec034a8a.png     2  \n2  ./train/0001eeb4a06e8daa7c6951bcd124c3c7.png     1  \n3  ./train/000226398d224de78b191e6db45fd94e.png     2  \n4  ./train/00029c3b0171158d63b1bbf803a7d750.png     2  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>attribute_ids</th>\n      <th>targets</th>\n      <th>filepath</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000040d66f14ced4cdd18cd95d91800f</td>\n      <td>448 2429 782</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>./train/000040d66f14ced4cdd18cd95d91800f.png</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000ef13e37ef70412166725ec034a8a</td>\n      <td>2997 3231 2730 3294 3099 2017 784</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>./train/0000ef13e37ef70412166725ec034a8a.png</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0001eeb4a06e8daa7c6951bcd124c3c7</td>\n      <td>2436 1715 23</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>./train/0001eeb4a06e8daa7c6951bcd124c3c7.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000226398d224de78b191e6db45fd94e</td>\n      <td>2997 3433 448 782</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>./train/000226398d224de78b191e6db45fd94e.png</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00029c3b0171158d63b1bbf803a7d750</td>\n      <td>3465 3322 3170 1553 781</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>./train/00029c3b0171158d63b1bbf803a7d750.png</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the dataframe: (120801, 5)\nFold distribution:\nfold\n0    40294\n1    40256\n2    40251\nName: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "id": "d2076a76-3dcd-474d-b9e4-9bffb175efa2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## 1.3 Dataset and Augmentations\n",
        "\n",
        "def get_transforms(*, data):\n",
        "    if data == 'train':\n",
        "        return T.Compose([\n",
        "            T.RandomResizedCrop(CFG.img_size, scale=(0.8, 1.0)),\n",
        "            T.RandomHorizontalFlip(p=0.5),\n",
        "            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "            ),\n",
        "        ])\n",
        "    elif data == 'valid':\n",
        "        return T.Compose([\n",
        "            T.Resize(CFG.img_size),\n",
        "            T.CenterCrop(CFG.img_size),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "class iMetDataset(Dataset):\n",
        "    def __init__(self, df, transforms=None):\n",
        "        self.df = df\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['targets'].values\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filepath = self.filepaths[idx]\n",
        "        image = Image.open(filepath).convert('RGB')\n",
        "        \n",
        "        if self.transforms:\n",
        "            image = self.transforms(image)\n",
        "            \n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return image, label"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "id": "a6d73a0c-213c-4466-a3e0-5280f2d74c7b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## 2.1 Model, Loss, and Optimizer\n",
        "\n",
        "class iMetModel(nn.Module):\n",
        "    def __init__(self, model_name, pretrained=True):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=CFG.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Calculate pos_weight for BCEWithLogitsLoss\n",
        "# This is important for handling class imbalance\n",
        "targets_matrix = np.stack(df['targets'].values)\n",
        "pos_counts = targets_matrix.sum(axis=0)\n",
        "neg_counts = len(df) - pos_counts\n",
        "pos_weight = neg_counts / (pos_counts + 1e-6) # Add epsilon to avoid division by zero\n",
        "pos_weight = torch.tensor(pos_weight, dtype=torch.float).to(CFG.device)\n",
        "\n",
        "print(f\"pos_weight tensor shape: {pos_weight.shape}\")\n",
        "print(f\"Device: {CFG.device}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_weight tensor shape: torch.Size([3474])\nDevice: cuda\n"
          ]
        }
      ]
    },
    {
      "id": "45ce764e-1959-49df-8065-df631b6b4c68",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## 2.2 Training and Validation Functions\n",
        "\n",
        "def train_fn(loader, model, criterion, optimizer, scaler, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(loader, desc=\"Training\")\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        with autocast():\n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        pbar.set_postfix(loss=loss.item())\n",
        "        \n",
        "    avg_loss = running_loss / len(loader)\n",
        "    return avg_loss\n",
        "\n",
        "def valid_fn(loader, model, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    pbar = tqdm(loader, desc=\"Validating\")\n",
        "    with torch.no_grad():\n",
        "        for images, labels in pbar:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            logits = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            all_preds.append(logits.sigmoid().cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            \n",
        "    avg_loss = running_loss / len(loader)\n",
        "    \n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    \n",
        "    return avg_loss, all_preds, all_labels\n",
        "\n",
        "def get_best_f1_score(preds, labels):\n",
        "    best_f1 = 0\n",
        "    best_thresh = 0\n",
        "    for thresh in np.arange(0.05, 0.5, 0.01):\n",
        "        binary_preds = (preds > thresh).astype(int)\n",
        "        # Handle 'at-least-one' fallback\n",
        "        for i in range(len(binary_preds)):\n",
        "            if binary_preds[i].sum() == 0:\n",
        "                binary_preds[i, preds[i].argmax()] = 1\n",
        "        \n",
        "        f1 = f1_score(labels, binary_preds, average='micro')\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_thresh = thresh\n",
        "    return best_f1, best_thresh"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "id": "f8ca7d31-6c31-4213-9615-4d2bf3ea9e14",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## 2.3 Main Training Loop\n",
        "\n",
        "def run_training(fold):\n",
        "    print(f\"========== Fold: {fold} ==========\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_df = df[df['fold'] != fold].reset_index(drop=True)\n",
        "    valid_df = df[df['fold'] == fold].reset_index(drop=True)\n",
        "    \n",
        "    train_dataset = iMetDataset(train_df, transforms=get_transforms(data='train'))\n",
        "    valid_dataset = iMetDataset(valid_df, transforms=get_transforms(data='valid'))\n",
        "    \n",
        "    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size * 2, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "    \n",
        "    # Init model, criterion, optimizer\n",
        "    model = iMetModel(CFG.model_name, pretrained=True).to(CFG.device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
        "    scaler = GradScaler()\n",
        "    \n",
        "    best_f1 = 0\n",
        "    best_epoch = -1\n",
        "    \n",
        "    for epoch in range(CFG.epochs):\n",
        "        start_time = time.time()\n",
        "        \n",
        "        train_loss = train_fn(train_loader, model, criterion, optimizer, scaler, CFG.device)\n",
        "        valid_loss, preds, labels = valid_fn(valid_loader, model, criterion, CFG.device)\n",
        "        \n",
        "        f1, thresh = get_best_f1_score(preds, labels)\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}/{CFG.epochs} - Train Loss: {train_loss:.4f}, Val Loss: {valid_loss:.4f}, F1: {f1:.4f}, Best Thresh: {thresh:.2f}, Time: {elapsed:.0f}s\")\n",
        "        \n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_epoch = epoch\n",
        "            torch.save(model.state_dict(), os.path.join(CFG.output_dir, f'{CFG.model_name}_fold{fold}_best.pth'))\n",
        "            print(f\"  -> New best F1 score: {best_f1:.4f}. Model saved.\")\n",
        "            \n",
        "    print(f\"\\nBest F1 score for fold {fold} was {best_f1:.4f} at epoch {best_epoch+1}\")\n",
        "    return best_f1\n",
        "\n",
        "# Start training for the target fold\n",
        "run_training(CFG.target_fold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Fold: 2 ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_203/1850885298.py:20: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/2518 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_203/3283525578.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/2518 [00:00<?, ?it/s, loss=1.14]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 1/2518 [00:00<38:25,  1.09it/s, loss=1.14]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 1/2518 [00:01<38:25,  1.09it/s, loss=1.38]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 2/2518 [00:01<21:43,  1.93it/s, loss=1.38]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 2/2518 [00:01<21:43,  1.93it/s, loss=1.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 3/2518 [00:01<16:22,  2.56it/s, loss=1.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 3/2518 [00:01<16:22,  2.56it/s, loss=2.36]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 4/2518 [00:01<13:55,  3.01it/s, loss=2.36]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 4/2518 [00:01<13:55,  3.01it/s, loss=1.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 5/2518 [00:01<12:32,  3.34it/s, loss=1.37]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 5/2518 [00:02<12:32,  3.34it/s, loss=1.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 6/2518 [00:02<11:41,  3.58it/s, loss=1.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 6/2518 [00:02<11:41,  3.58it/s, loss=1.22]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 7/2518 [00:02<11:09,  3.75it/s, loss=1.22]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 7/2518 [00:02<11:09,  3.75it/s, loss=1.3] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 8/2518 [00:02<10:49,  3.87it/s, loss=1.3]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 8/2518 [00:02<10:49,  3.87it/s, loss=1.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 9/2518 [00:02<10:35,  3.95it/s, loss=1.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 9/2518 [00:03<10:35,  3.95it/s, loss=1.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 10/2518 [00:03<10:25,  4.01it/s, loss=1.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 10/2518 [00:03<10:25,  4.01it/s, loss=1]   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 11/2518 [00:03<10:18,  4.05it/s, loss=1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 11/2518 [00:03<10:18,  4.05it/s, loss=1.02]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 12/2518 [00:03<10:14,  4.08it/s, loss=1.02]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 12/2518 [00:03<10:14,  4.08it/s, loss=1.49]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|          | 13/2518 [00:03<10:10,  4.10it/s, loss=1.49]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|          | 13/2518 [00:04<10:10,  4.10it/s, loss=1.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|          | 14/2518 [00:04<10:07,  4.12it/s, loss=1.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|          | 14/2518 [00:04<10:07,  4.12it/s, loss=1.01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|          | 15/2518 [00:04<10:05,  4.13it/s, loss=1.01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|          | 15/2518 [00:04<10:05,  4.13it/s, loss=1.31]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}