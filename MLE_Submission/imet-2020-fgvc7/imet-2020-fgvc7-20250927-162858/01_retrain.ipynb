{
  "cells": [
    {
      "id": "7d017674-df91-4a5f-a21d-b9b1c6b5bb44",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import subprocess, shlex, sys, os, time\n",
        "cmd = f\"{sys.executable} -u train_b4_mem.py --model tf_efficientnet_b4_ns --img-size 448 --epochs 3 --batch-size 4 --accum-steps 16 --val-batch-size 12 --num-workers 4 --folds 0 --out-dir out_b4_fix --lr 3e-4 --warmup-epochs 0.5 --early-stop-patience 2 --pretrained --limit-train-steps 4096 --limit-val-steps 0 --subsample-train 60000\"\n",
        "print(\"Running:\", cmd, flush=True)\n",
        "p = subprocess.Popen(shlex.split(cmd), stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
        "t0=time.time()\n",
        "try:\n",
        "    for line in p.stdout:\n",
        "        print(line, end='')\n",
        "        sys.stdout.flush()\n",
        "        if (time.time()-t0)>60*60*2:\n",
        "            print(\"[Timeout] Terminating process after 2h\", flush=True)\n",
        "            p.terminate(); break\n",
        "    ret = p.wait()\n",
        "    print(f\"Process exited with code {ret}\")\n",
        "except KeyboardInterrupt:\n",
        "    print(\"KeyboardInterrupt: terminating child process\", flush=True)\n",
        "    try: p.terminate()\n",
        "    except Exception: pass"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: /usr/bin/python3.11 -u train_b4_mem.py --model tf_efficientnet_b4_ns --img-size 448 --epochs 3 --batch-size 4 --accum-steps 16 --val-batch-size 12 --num-workers 4 --folds 0 --out-dir out_b4_fix --lr 3e-4 --warmup-epochs 0.5 --early-stop-patience 2 --pretrained --limit-train-steps 4096 --limit-val-steps 0 --subsample-train 60000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected image extension: .png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Fold 0 start ====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 100/15000 loss 0.0154 it/s 7.21 lr 0.000014 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 200/15000 loss 0.0152 it/s 8.93 lr 0.000028 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 300/15000 loss 0.0150 it/s 9.74 lr 0.000042 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 400/15000 loss 0.0146 it/s 10.20 lr 0.000059 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 500/15000 loss 0.0141 it/s 10.46 lr 0.000073 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 600/15000 loss 0.0135 it/s 10.65 lr 0.000087 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 700/15000 loss 0.0127 it/s 10.79 lr 0.000101 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 800/15000 loss 0.0120 it/s 10.92 lr 0.000117 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 900/15000 loss 0.0112 it/s 11.01 lr 0.000131 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1000/15000 loss 0.0106 it/s 11.08 lr 0.000145 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1100/15000 loss 0.0100 it/s 11.14 lr 0.000159 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1200/15000 loss 0.0094 it/s 11.19 lr 0.000176 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1300/15000 loss 0.0090 it/s 11.23 lr 0.000190 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1400/15000 loss 0.0086 it/s 11.27 lr 0.000204 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1500/15000 loss 0.0082 it/s 11.29 lr 0.000218 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1600/15000 loss 0.0079 it/s 11.32 lr 0.000234 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1700/15000 loss 0.0077 it/s 11.36 lr 0.000248 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1800/15000 loss 0.0074 it/s 11.39 lr 0.000262 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1900/15000 loss 0.0072 it/s 11.41 lr 0.000277 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2000/15000 loss 0.0070 it/s 11.42 lr 0.000293 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2100/15000 loss 0.0069 it/s 11.43 lr 0.000300 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2200/15000 loss 0.0067 it/s 11.44 lr 0.000300 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2300/15000 loss 0.0065 it/s 11.46 lr 0.000300 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2400/15000 loss 0.0064 it/s 11.48 lr 0.000299 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2500/15000 loss 0.0063 it/s 11.50 lr 0.000299 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2600/15000 loss 0.0062 it/s 11.51 lr 0.000298 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2700/15000 loss 0.0060 it/s 11.52 lr 0.000297 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2800/15000 loss 0.0059 it/s 11.54 lr 0.000296 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2900/15000 loss 0.0058 it/s 11.55 lr 0.000295 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3000/15000 loss 0.0057 it/s 11.56 lr 0.000294 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3100/15000 loss 0.0056 it/s 11.56 lr 0.000292 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3200/15000 loss 0.0056 it/s 11.57 lr 0.000291 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3300/15000 loss 0.0055 it/s 11.59 lr 0.000289 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3400/15000 loss 0.0054 it/s 11.59 lr 0.000287 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3500/15000 loss 0.0054 it/s 11.59 lr 0.000286 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3600/15000 loss 0.0053 it/s 11.60 lr 0.000283 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3700/15000 loss 0.0052 it/s 11.60 lr 0.000281 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3800/15000 loss 0.0052 it/s 11.60 lr 0.000279 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3900/15000 loss 0.0051 it/s 11.61 lr 0.000277 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4000/15000 loss 0.0051 it/s 11.61 lr 0.000274 mem_gb 0.79 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 val micro-f1 0.33022 @ thr 0.340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 100/15000 loss 0.0029 it/s 17.82 lr 0.000269 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 200/15000 loss 0.0029 it/s 17.99 lr 0.000266 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 300/15000 loss 0.0028 it/s 18.03 lr 0.000263 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 400/15000 loss 0.0028 it/s 18.09 lr 0.000260 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 500/15000 loss 0.0029 it/s 18.23 lr 0.000257 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 600/15000 loss 0.0028 it/s 18.33 lr 0.000253 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 700/15000 loss 0.0028 it/s 18.40 lr 0.000250 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 800/15000 loss 0.0028 it/s 18.45 lr 0.000246 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 900/15000 loss 0.0028 it/s 18.49 lr 0.000243 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1000/15000 loss 0.0028 it/s 18.53 lr 0.000239 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1100/15000 loss 0.0028 it/s 18.55 lr 0.000236 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1200/15000 loss 0.0028 it/s 18.58 lr 0.000231 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1300/15000 loss 0.0028 it/s 18.57 lr 0.000228 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1400/15000 loss 0.0028 it/s 18.54 lr 0.000224 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1500/15000 loss 0.0028 it/s 18.50 lr 0.000220 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1600/15000 loss 0.0028 it/s 18.49 lr 0.000215 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1700/15000 loss 0.0028 it/s 18.51 lr 0.000211 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1800/15000 loss 0.0028 it/s 18.49 lr 0.000207 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1900/15000 loss 0.0028 it/s 18.46 lr 0.000203 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2000/15000 loss 0.0028 it/s 18.44 lr 0.000198 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2100/15000 loss 0.0028 it/s 18.42 lr 0.000194 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2200/15000 loss 0.0028 it/s 18.40 lr 0.000190 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2300/15000 loss 0.0028 it/s 18.40 lr 0.000186 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2400/15000 loss 0.0028 it/s 18.40 lr 0.000181 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2500/15000 loss 0.0028 it/s 18.39 lr 0.000176 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2600/15000 loss 0.0028 it/s 18.38 lr 0.000172 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2700/15000 loss 0.0028 it/s 18.37 lr 0.000168 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2800/15000 loss 0.0028 it/s 18.36 lr 0.000163 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2900/15000 loss 0.0028 it/s 18.35 lr 0.000158 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3000/15000 loss 0.0028 it/s 18.34 lr 0.000154 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3100/15000 loss 0.0028 it/s 18.35 lr 0.000149 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3200/15000 loss 0.0028 it/s 18.35 lr 0.000144 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3300/15000 loss 0.0028 it/s 18.33 lr 0.000140 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3400/15000 loss 0.0028 it/s 18.33 lr 0.000135 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3500/15000 loss 0.0028 it/s 18.32 lr 0.000131 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3600/15000 loss 0.0028 it/s 18.31 lr 0.000126 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3700/15000 loss 0.0028 it/s 18.30 lr 0.000121 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3800/15000 loss 0.0028 it/s 18.29 lr 0.000117 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3900/15000 loss 0.0028 it/s 18.29 lr 0.000113 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 4000/15000 loss 0.0028 it/s 18.30 lr 0.000108 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 val micro-f1 0.39356 @ thr 0.390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 100/15000 loss 0.0026 it/s 18.12 lr 0.000099 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 200/15000 loss 0.0027 it/s 18.01 lr 0.000095 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 300/15000 loss 0.0027 it/s 17.99 lr 0.000091 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 400/15000 loss 0.0027 it/s 17.97 lr 0.000087 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 500/15000 loss 0.0026 it/s 17.95 lr 0.000083 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 600/15000 loss 0.0027 it/s 17.98 lr 0.000079 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 700/15000 loss 0.0027 it/s 17.97 lr 0.000075 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 800/15000 loss 0.0027 it/s 18.04 lr 0.000070 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 900/15000 loss 0.0027 it/s 18.09 lr 0.000067 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1000/15000 loss 0.0026 it/s 18.14 lr 0.000063 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1100/15000 loss 0.0026 it/s 18.19 lr 0.000059 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1200/15000 loss 0.0026 it/s 18.22 lr 0.000055 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1300/15000 loss 0.0026 it/s 18.25 lr 0.000052 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1400/15000 loss 0.0026 it/s 18.24 lr 0.000049 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1500/15000 loss 0.0026 it/s 18.21 lr 0.000046 mem_gb 2.13 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyboardInterrupt: terminating child process\n"
          ]
        }
      ]
    },
    {
      "id": "32e797f7-b54f-4c4d-8f27-3e13e9bb69a6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import subprocess, sys, time, os\n",
        "cmd = [\n",
        "    sys.executable, \"-u\", \"train_b4_mem.py\",\n",
        "    \"--model\", \"tf_efficientnet_b4_ns\",\n",
        "    \"--img-size\", \"448\",\n",
        "    \"--epochs\", \"4\",\n",
        "    \"--batch-size\", \"4\",\n",
        "    \"--accum-steps\", \"16\",\n",
        "    \"--val-batch-size\", \"16\",\n",
        "    \"--num-workers\", \"4\",\n",
        "    \"--folds\", \"0,2\",\n",
        "    \"--out-dir\", \"out_b4_mem_448_fixed\",\n",
        "    \"--lr\", \"3e-4\",\n",
        "    \"--warmup-epochs\", \"1.5\",\n",
        "    \"--early-stop-patience\", \"2\",\n",
        "    \"--pretrained\",\n",
        "    \"--use-ema\"\n",
        "]\n",
        "print(\"Running:\", \" \".join(cmd), flush=True)\n",
        "t0 = time.time()\n",
        "proc = subprocess.run(cmd, check=False)\n",
        "print(\"Return code:\", proc.returncode, \"elapsed:\", f\"{(time.time()-t0)/60:.1f}m\", flush=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: /usr/bin/python3.11 -u train_b4_mem.py --model tf_efficientnet_b4_ns --img-size 448 --epochs 4 --batch-size 4 --accum-steps 16 --val-batch-size 16 --num-workers 4 --folds 0,2 --out-dir out_b4_mem_448_fixed --lr 3e-4 --warmup-epochs 1.5 --early-stop-patience 2 --pretrained --use-ema\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected image extension: .png\n==== Fold 0 start ====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 100/24153 loss 0.0043 it/s 7.15 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 200/24153 loss 0.0043 it/s 8.84 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 300/24153 loss 0.0044 it/s 9.59 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 400/24153 loss 0.0044 it/s 10.02 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 500/24153 loss 0.0043 it/s 10.32 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 600/24153 loss 0.0043 it/s 10.50 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 700/24153 loss 0.0043 it/s 10.64 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 800/24153 loss 0.0043 it/s 10.73 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 900/24153 loss 0.0043 it/s 10.82 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1000/24153 loss 0.0043 it/s 10.88 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1100/24153 loss 0.0043 it/s 10.95 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1200/24153 loss 0.0043 it/s 11.00 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1300/24153 loss 0.0042 it/s 11.04 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1400/24153 loss 0.0042 it/s 11.08 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1500/24153 loss 0.0042 it/s 11.13 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1600/24153 loss 0.0042 it/s 11.17 lr 0.000013 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1700/24153 loss 0.0042 it/s 11.22 lr 0.000014 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1800/24153 loss 0.0042 it/s 11.25 lr 0.000015 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1900/24153 loss 0.0041 it/s 11.29 lr 0.000016 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2000/24153 loss 0.0041 it/s 11.32 lr 0.000017 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2100/24153 loss 0.0041 it/s 11.34 lr 0.000017 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2200/24153 loss 0.0041 it/s 11.37 lr 0.000018 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2300/24153 loss 0.0040 it/s 11.39 lr 0.000019 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2400/24153 loss 0.0040 it/s 11.41 lr 0.000020 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2500/24153 loss 0.0040 it/s 11.43 lr 0.000021 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2600/24153 loss 0.0040 it/s 11.45 lr 0.000021 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2700/24153 loss 0.0039 it/s 11.47 lr 0.000022 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2800/24153 loss 0.0039 it/s 11.48 lr 0.000023 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2900/24153 loss 0.0039 it/s 11.50 lr 0.000024 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3000/24153 loss 0.0039 it/s 11.51 lr 0.000025 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3100/24153 loss 0.0038 it/s 11.52 lr 0.000026 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3200/24153 loss 0.0038 it/s 11.52 lr 0.000026 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3300/24153 loss 0.0038 it/s 11.52 lr 0.000027 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3400/24153 loss 0.0038 it/s 11.52 lr 0.000028 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3500/24153 loss 0.0037 it/s 11.52 lr 0.000029 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3600/24153 loss 0.0037 it/s 11.53 lr 0.000030 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3700/24153 loss 0.0037 it/s 11.53 lr 0.000031 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3800/24153 loss 0.0037 it/s 11.54 lr 0.000031 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3900/24153 loss 0.0036 it/s 11.54 lr 0.000032 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4000/24153 loss 0.0036 it/s 11.54 lr 0.000033 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4100/24153 loss 0.0036 it/s 11.54 lr 0.000034 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4200/24153 loss 0.0036 it/s 11.54 lr 0.000035 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4300/24153 loss 0.0036 it/s 11.54 lr 0.000035 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4400/24153 loss 0.0035 it/s 11.54 lr 0.000036 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4500/24153 loss 0.0035 it/s 11.54 lr 0.000037 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4600/24153 loss 0.0035 it/s 11.54 lr 0.000038 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4700/24153 loss 0.0035 it/s 11.54 lr 0.000039 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4800/24153 loss 0.0035 it/s 11.53 lr 0.000040 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4900/24153 loss 0.0035 it/s 11.54 lr 0.000041 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5000/24153 loss 0.0034 it/s 11.54 lr 0.000041 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5100/24153 loss 0.0034 it/s 11.54 lr 0.000042 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5200/24153 loss 0.0034 it/s 11.54 lr 0.000043 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5300/24153 loss 0.0034 it/s 11.54 lr 0.000044 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5400/24153 loss 0.0034 it/s 11.55 lr 0.000045 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5500/24153 loss 0.0034 it/s 11.55 lr 0.000045 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5600/24153 loss 0.0034 it/s 11.55 lr 0.000046 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5700/24153 loss 0.0033 it/s 11.55 lr 0.000047 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5800/24153 loss 0.0033 it/s 11.55 lr 0.000048 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5900/24153 loss 0.0033 it/s 11.55 lr 0.000049 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6000/24153 loss 0.0033 it/s 11.54 lr 0.000050 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6100/24153 loss 0.0033 it/s 11.55 lr 0.000050 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6200/24153 loss 0.0033 it/s 11.55 lr 0.000051 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6300/24153 loss 0.0033 it/s 11.55 lr 0.000052 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6400/24153 loss 0.0033 it/s 11.55 lr 0.000053 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6500/24153 loss 0.0033 it/s 11.56 lr 0.000054 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6600/24153 loss 0.0032 it/s 11.56 lr 0.000055 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6700/24153 loss 0.0032 it/s 11.56 lr 0.000055 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6800/24153 loss 0.0032 it/s 11.56 lr 0.000056 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6900/24153 loss 0.0032 it/s 11.56 lr 0.000057 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7000/24153 loss 0.0032 it/s 11.56 lr 0.000058 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7100/24153 loss 0.0032 it/s 11.56 lr 0.000059 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7200/24153 loss 0.0032 it/s 11.56 lr 0.000060 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7300/24153 loss 0.0032 it/s 11.56 lr 0.000060 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7400/24153 loss 0.0032 it/s 11.56 lr 0.000061 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7500/24153 loss 0.0032 it/s 11.56 lr 0.000062 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7600/24153 loss 0.0031 it/s 11.56 lr 0.000063 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7700/24153 loss 0.0031 it/s 11.56 lr 0.000064 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7800/24153 loss 0.0031 it/s 11.56 lr 0.000065 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7900/24153 loss 0.0031 it/s 11.56 lr 0.000065 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8000/24153 loss 0.0031 it/s 11.56 lr 0.000066 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8100/24153 loss 0.0031 it/s 11.56 lr 0.000067 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8200/24153 loss 0.0031 it/s 11.56 lr 0.000068 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8300/24153 loss 0.0031 it/s 11.56 lr 0.000069 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8400/24153 loss 0.0031 it/s 11.57 lr 0.000070 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8500/24153 loss 0.0031 it/s 11.57 lr 0.000070 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8600/24153 loss 0.0031 it/s 11.57 lr 0.000071 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8700/24153 loss 0.0031 it/s 11.58 lr 0.000072 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8800/24153 loss 0.0031 it/s 11.58 lr 0.000073 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8900/24153 loss 0.0030 it/s 11.58 lr 0.000074 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9000/24153 loss 0.0030 it/s 11.58 lr 0.000074 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9100/24153 loss 0.0030 it/s 11.58 lr 0.000075 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9200/24153 loss 0.0030 it/s 11.59 lr 0.000076 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9300/24153 loss 0.0030 it/s 11.59 lr 0.000077 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9400/24153 loss 0.0030 it/s 11.59 lr 0.000078 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9500/24153 loss 0.0030 it/s 11.59 lr 0.000079 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9600/24153 loss 0.0030 it/s 11.59 lr 0.000079 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9700/24153 loss 0.0030 it/s 11.59 lr 0.000080 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9800/24153 loss 0.0030 it/s 11.59 lr 0.000081 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9900/24153 loss 0.0030 it/s 11.59 lr 0.000082 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10000/24153 loss 0.0030 it/s 11.59 lr 0.000083 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10100/24153 loss 0.0030 it/s 11.59 lr 0.000084 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10200/24153 loss 0.0030 it/s 11.59 lr 0.000084 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10300/24153 loss 0.0030 it/s 11.59 lr 0.000085 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10400/24153 loss 0.0029 it/s 11.59 lr 0.000086 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10500/24153 loss 0.0029 it/s 11.60 lr 0.000087 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10600/24153 loss 0.0029 it/s 11.60 lr 0.000088 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10700/24153 loss 0.0029 it/s 11.60 lr 0.000088 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10800/24153 loss 0.0029 it/s 11.60 lr 0.000089 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10900/24153 loss 0.0029 it/s 11.60 lr 0.000090 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11000/24153 loss 0.0029 it/s 11.60 lr 0.000091 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11100/24153 loss 0.0029 it/s 11.60 lr 0.000092 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11200/24153 loss 0.0029 it/s 11.60 lr 0.000093 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11300/24153 loss 0.0029 it/s 11.60 lr 0.000094 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11400/24153 loss 0.0029 it/s 11.60 lr 0.000094 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11500/24153 loss 0.0029 it/s 11.60 lr 0.000095 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11600/24153 loss 0.0029 it/s 11.60 lr 0.000096 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11700/24153 loss 0.0029 it/s 11.60 lr 0.000097 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11800/24153 loss 0.0029 it/s 11.60 lr 0.000098 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11900/24153 loss 0.0029 it/s 11.60 lr 0.000098 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12000/24153 loss 0.0029 it/s 11.60 lr 0.000099 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12100/24153 loss 0.0029 it/s 11.61 lr 0.000100 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12200/24153 loss 0.0029 it/s 11.61 lr 0.000101 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12300/24153 loss 0.0029 it/s 11.61 lr 0.000102 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12400/24153 loss 0.0028 it/s 11.61 lr 0.000103 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12500/24153 loss 0.0028 it/s 11.61 lr 0.000103 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12600/24153 loss 0.0028 it/s 11.61 lr 0.000104 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12700/24153 loss 0.0028 it/s 11.61 lr 0.000105 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12800/24153 loss 0.0028 it/s 11.61 lr 0.000106 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12900/24153 loss 0.0028 it/s 11.61 lr 0.000107 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13000/24153 loss 0.0028 it/s 11.61 lr 0.000108 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13100/24153 loss 0.0028 it/s 11.61 lr 0.000108 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13200/24153 loss 0.0028 it/s 11.61 lr 0.000109 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13300/24153 loss 0.0028 it/s 11.61 lr 0.000110 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13400/24153 loss 0.0028 it/s 11.60 lr 0.000111 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13500/24153 loss 0.0028 it/s 11.60 lr 0.000112 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13600/24153 loss 0.0028 it/s 11.60 lr 0.000113 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13700/24153 loss 0.0028 it/s 11.60 lr 0.000113 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13800/24153 loss 0.0028 it/s 11.60 lr 0.000114 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13900/24153 loss 0.0028 it/s 11.60 lr 0.000115 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14000/24153 loss 0.0028 it/s 11.60 lr 0.000116 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14100/24153 loss 0.0028 it/s 11.60 lr 0.000117 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14200/24153 loss 0.0028 it/s 11.60 lr 0.000117 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14300/24153 loss 0.0028 it/s 11.61 lr 0.000118 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14400/24153 loss 0.0028 it/s 11.60 lr 0.000119 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14500/24153 loss 0.0028 it/s 11.60 lr 0.000120 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14600/24153 loss 0.0028 it/s 11.60 lr 0.000121 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14700/24153 loss 0.0028 it/s 11.60 lr 0.000122 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14800/24153 loss 0.0028 it/s 11.60 lr 0.000123 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14900/24153 loss 0.0027 it/s 11.60 lr 0.000123 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15000/24153 loss 0.0027 it/s 11.60 lr 0.000124 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15100/24153 loss 0.0027 it/s 11.60 lr 0.000125 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15200/24153 loss 0.0027 it/s 11.60 lr 0.000126 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15300/24153 loss 0.0027 it/s 11.60 lr 0.000127 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15400/24153 loss 0.0027 it/s 11.61 lr 0.000127 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15500/24153 loss 0.0027 it/s 11.61 lr 0.000128 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15600/24153 loss 0.0027 it/s 11.61 lr 0.000129 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15700/24153 loss 0.0027 it/s 11.61 lr 0.000130 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15800/24153 loss 0.0027 it/s 11.61 lr 0.000131 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15900/24153 loss 0.0027 it/s 11.61 lr 0.000132 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16000/24153 loss 0.0027 it/s 11.61 lr 0.000132 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16100/24153 loss 0.0027 it/s 11.61 lr 0.000133 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16200/24153 loss 0.0027 it/s 11.61 lr 0.000134 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16300/24153 loss 0.0027 it/s 11.61 lr 0.000135 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16400/24153 loss 0.0027 it/s 11.61 lr 0.000136 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16500/24153 loss 0.0027 it/s 11.61 lr 0.000137 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16600/24153 loss 0.0027 it/s 11.61 lr 0.000137 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16700/24153 loss 0.0027 it/s 11.61 lr 0.000138 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16800/24153 loss 0.0027 it/s 11.61 lr 0.000139 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16900/24153 loss 0.0027 it/s 11.61 lr 0.000140 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17000/24153 loss 0.0027 it/s 11.61 lr 0.000141 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17100/24153 loss 0.0027 it/s 11.60 lr 0.000141 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17200/24153 loss 0.0027 it/s 11.60 lr 0.000142 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17300/24153 loss 0.0027 it/s 11.60 lr 0.000143 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17400/24153 loss 0.0027 it/s 11.60 lr 0.000144 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17500/24153 loss 0.0027 it/s 11.60 lr 0.000145 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17600/24153 loss 0.0027 it/s 11.60 lr 0.000146 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17700/24153 loss 0.0027 it/s 11.60 lr 0.000146 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17800/24153 loss 0.0027 it/s 11.60 lr 0.000147 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17900/24153 loss 0.0027 it/s 11.60 lr 0.000148 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18000/24153 loss 0.0026 it/s 11.60 lr 0.000149 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18100/24153 loss 0.0026 it/s 11.60 lr 0.000150 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18200/24153 loss 0.0026 it/s 11.60 lr 0.000151 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18300/24153 loss 0.0026 it/s 11.60 lr 0.000151 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18400/24153 loss 0.0026 it/s 11.61 lr 0.000152 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18500/24153 loss 0.0026 it/s 11.61 lr 0.000153 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18600/24153 loss 0.0026 it/s 11.61 lr 0.000154 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18700/24153 loss 0.0026 it/s 11.61 lr 0.000155 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18800/24153 loss 0.0026 it/s 11.61 lr 0.000156 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18900/24153 loss 0.0026 it/s 11.61 lr 0.000156 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19000/24153 loss 0.0026 it/s 11.61 lr 0.000157 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19100/24153 loss 0.0026 it/s 11.61 lr 0.000158 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19200/24153 loss 0.0026 it/s 11.61 lr 0.000159 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19300/24153 loss 0.0026 it/s 11.61 lr 0.000160 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19400/24153 loss 0.0026 it/s 11.61 lr 0.000161 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19500/24153 loss 0.0026 it/s 11.61 lr 0.000161 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19600/24153 loss 0.0026 it/s 11.61 lr 0.000162 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19700/24153 loss 0.0026 it/s 11.61 lr 0.000163 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19800/24153 loss 0.0026 it/s 11.61 lr 0.000164 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19900/24153 loss 0.0026 it/s 11.61 lr 0.000165 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20000/24153 loss 0.0026 it/s 11.61 lr 0.000166 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20100/24153 loss 0.0026 it/s 11.61 lr 0.000166 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20200/24153 loss 0.0026 it/s 11.61 lr 0.000167 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20300/24153 loss 0.0026 it/s 11.61 lr 0.000168 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20400/24153 loss 0.0026 it/s 11.61 lr 0.000169 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20500/24153 loss 0.0026 it/s 11.61 lr 0.000170 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20600/24153 loss 0.0026 it/s 11.61 lr 0.000170 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20700/24153 loss 0.0026 it/s 11.61 lr 0.000171 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20800/24153 loss 0.0026 it/s 11.61 lr 0.000172 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20900/24153 loss 0.0026 it/s 11.61 lr 0.000173 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21000/24153 loss 0.0026 it/s 11.61 lr 0.000174 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21100/24153 loss 0.0026 it/s 11.61 lr 0.000175 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21200/24153 loss 0.0026 it/s 11.61 lr 0.000175 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21300/24153 loss 0.0026 it/s 11.61 lr 0.000176 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21400/24153 loss 0.0026 it/s 11.61 lr 0.000177 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21500/24153 loss 0.0026 it/s 11.61 lr 0.000178 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21600/24153 loss 0.0026 it/s 11.61 lr 0.000179 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21700/24153 loss 0.0026 it/s 11.61 lr 0.000180 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21800/24153 loss 0.0026 it/s 11.61 lr 0.000180 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21900/24153 loss 0.0026 it/s 11.61 lr 0.000181 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22000/24153 loss 0.0025 it/s 11.61 lr 0.000182 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22100/24153 loss 0.0025 it/s 11.62 lr 0.000183 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22200/24153 loss 0.0025 it/s 11.62 lr 0.000184 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22300/24153 loss 0.0025 it/s 11.62 lr 0.000185 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22400/24153 loss 0.0025 it/s 11.62 lr 0.000185 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22500/24153 loss 0.0025 it/s 11.62 lr 0.000186 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22600/24153 loss 0.0025 it/s 11.62 lr 0.000187 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22700/24153 loss 0.0025 it/s 11.62 lr 0.000188 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22800/24153 loss 0.0025 it/s 11.62 lr 0.000189 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22900/24153 loss 0.0025 it/s 11.62 lr 0.000190 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23000/24153 loss 0.0025 it/s 11.62 lr 0.000190 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23100/24153 loss 0.0025 it/s 11.62 lr 0.000191 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23200/24153 loss 0.0025 it/s 11.62 lr 0.000192 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23300/24153 loss 0.0025 it/s 11.62 lr 0.000193 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23400/24153 loss 0.0025 it/s 11.62 lr 0.000194 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23500/24153 loss 0.0025 it/s 11.62 lr 0.000194 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23600/24153 loss 0.0025 it/s 11.62 lr 0.000195 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23700/24153 loss 0.0025 it/s 11.62 lr 0.000196 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23800/24153 loss 0.0025 it/s 11.62 lr 0.000197 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23900/24153 loss 0.0025 it/s 11.63 lr 0.000198 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 24000/24153 loss 0.0025 it/s 11.63 lr 0.000199 mem_gb 0.88 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 24100/24153 loss 0.0025 it/s 11.63 lr 0.000199 mem_gb 0.88 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 val micro-f1 0.31442 @ thr 0.400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 100/24153 loss 0.0020 it/s 11.68 lr 0.000201 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 200/24153 loss 0.0020 it/s 11.66 lr 0.000202 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 300/24153 loss 0.0020 it/s 11.62 lr 0.000202 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 400/24153 loss 0.0020 it/s 11.59 lr 0.000203 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 500/24153 loss 0.0020 it/s 11.58 lr 0.000204 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 600/24153 loss 0.0020 it/s 11.57 lr 0.000205 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 700/24153 loss 0.0020 it/s 11.56 lr 0.000206 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 800/24153 loss 0.0020 it/s 11.56 lr 0.000207 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 900/24153 loss 0.0020 it/s 11.56 lr 0.000207 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1000/24153 loss 0.0020 it/s 11.57 lr 0.000208 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1100/24153 loss 0.0020 it/s 11.57 lr 0.000209 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1200/24153 loss 0.0020 it/s 11.56 lr 0.000210 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1300/24153 loss 0.0020 it/s 11.56 lr 0.000211 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1400/24153 loss 0.0020 it/s 11.56 lr 0.000212 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1500/24153 loss 0.0020 it/s 11.56 lr 0.000212 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1600/24153 loss 0.0020 it/s 11.56 lr 0.000213 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1700/24153 loss 0.0020 it/s 11.56 lr 0.000214 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1800/24153 loss 0.0020 it/s 11.55 lr 0.000215 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1900/24153 loss 0.0020 it/s 11.55 lr 0.000216 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2000/24153 loss 0.0020 it/s 11.55 lr 0.000217 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2100/24153 loss 0.0020 it/s 11.56 lr 0.000217 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2200/24153 loss 0.0020 it/s 11.56 lr 0.000218 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2300/24153 loss 0.0020 it/s 11.56 lr 0.000219 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2400/24153 loss 0.0020 it/s 11.56 lr 0.000220 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2500/24153 loss 0.0020 it/s 11.57 lr 0.000221 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2600/24153 loss 0.0020 it/s 11.57 lr 0.000221 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2700/24153 loss 0.0020 it/s 11.58 lr 0.000222 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2800/24153 loss 0.0020 it/s 11.58 lr 0.000223 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2900/24153 loss 0.0020 it/s 11.59 lr 0.000224 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3000/24153 loss 0.0020 it/s 11.58 lr 0.000225 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3100/24153 loss 0.0020 it/s 11.59 lr 0.000226 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3200/24153 loss 0.0020 it/s 11.59 lr 0.000226 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3300/24153 loss 0.0020 it/s 11.58 lr 0.000227 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3400/24153 loss 0.0020 it/s 11.58 lr 0.000228 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3500/24153 loss 0.0020 it/s 11.58 lr 0.000229 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3600/24153 loss 0.0020 it/s 11.58 lr 0.000230 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3700/24153 loss 0.0020 it/s 11.58 lr 0.000231 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3800/24153 loss 0.0020 it/s 11.58 lr 0.000231 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 3900/24153 loss 0.0020 it/s 11.58 lr 0.000232 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 4000/24153 loss 0.0020 it/s 11.58 lr 0.000233 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 4100/24153 loss 0.0020 it/s 11.58 lr 0.000234 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 4200/24153 loss 0.0020 it/s 11.58 lr 0.000235 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 4300/24153 loss 0.0020 it/s 11.58 lr 0.000235 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 4400/24153 loss 0.0020 it/s 11.57 lr 0.000236 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 4500/24153 loss 0.0020 it/s 11.57 lr 0.000237 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 4600/24153 loss 0.0020 it/s 11.57 lr 0.000238 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 4700/24153 loss 0.0020 it/s 11.57 lr 0.000239 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 4800/24153 loss 0.0020 it/s 11.57 lr 0.000240 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 4900/24153 loss 0.0020 it/s 11.57 lr 0.000241 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 5000/24153 loss 0.0020 it/s 11.56 lr 0.000241 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 5100/24153 loss 0.0020 it/s 11.56 lr 0.000242 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 5200/24153 loss 0.0020 it/s 11.56 lr 0.000243 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 5300/24153 loss 0.0020 it/s 11.56 lr 0.000244 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 5400/24153 loss 0.0020 it/s 11.56 lr 0.000245 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 5500/24153 loss 0.0020 it/s 11.55 lr 0.000245 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 5600/24153 loss 0.0020 it/s 11.55 lr 0.000246 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 5700/24153 loss 0.0020 it/s 11.55 lr 0.000247 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 5800/24153 loss 0.0020 it/s 11.55 lr 0.000248 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 5900/24153 loss 0.0020 it/s 11.55 lr 0.000249 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 6000/24153 loss 0.0020 it/s 11.55 lr 0.000250 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 6100/24153 loss 0.0020 it/s 11.54 lr 0.000250 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 6200/24153 loss 0.0020 it/s 11.54 lr 0.000251 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 6300/24153 loss 0.0020 it/s 11.54 lr 0.000252 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 6400/24153 loss 0.0020 it/s 11.54 lr 0.000253 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 6500/24153 loss 0.0020 it/s 11.54 lr 0.000254 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 6600/24153 loss 0.0020 it/s 11.54 lr 0.000255 mem_gb 1.60 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 6700/24153 loss 0.0020 it/s 11.54 lr 0.000255 mem_gb 1.60 scale 65536.0\n"
          ]
        }
      ]
    },
    {
      "id": "2c95f3e5-d750-4bd1-b6c5-37a907278da9",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01_retrain: Memory-optimized retraining plan\n",
        "\n",
        "Goal: Unblock training and produce stronger backbones (tf_efficientnet_b4_ns/b5_ns) to reach medal F1.\n",
        "\n",
        "Milestones:\n",
        "- M1: Stabilize env + memory knobs; smoke-train b4@384 on 1 fold without OOM.\n",
        "- M2: b4@448 5-fold OOF >= 0.64 micro-F1 by epoch 2-3.\n",
        "- M3: b5_ns@456 or 512 single-fold confirms > b4; then selective 3 folds.\n",
        "- M4: Generate test logits, blend with existing b3 models, minimal post-proc.\n",
        "\n",
        "Memory tactics (enable incrementally, verify each):\n",
        "- Set PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128, expandable_segments:True\n",
        "- torch.set_float32_matmul_precision('high'); use AMP autocast + GradScaler\n",
        "- Grad accumulation (effective batch 64 via microbatch 8 x 8 steps)\n",
        "- Gradient checkpointing (timm: model.set_grad_checkpointing(True))\n",
        "- channels_last + pinned memory + non_blocking transfers\n",
        "- Smaller start res (384) \u2192 progressive resize (448/456) only after stable\n",
        "- Reduce activation/layernorm memory (torch.backends.cuda.matmul.allow_tf32=True)\n",
        "- Drop unnecessary augments for memory; keep simple A.Resize + Flip + ColorJitter\n",
        "- num_workers 4-6; persistent_workers; prefetch_factor=2\n",
        "- Disable bias init tricks that spike early activations; keep ASL stable eps\n",
        "\n",
        "Training config (per fold):\n",
        "- Model: tf_efficientnet_b4_ns (then b5_ns if fits). Pretrained=True.\n",
        "- Optim: AdamW(lr=2e-4, wd=1e-4). Scheduler: OneCycle or Cosine w/ warmup.\n",
        "- Epochs: 6-8 (early-stop by flat val F1).\n",
        "- Loss: fixed ASL (float32 compute, eps clamp).\n",
        "- Accum steps: 8. Micro-batch: 8 (tune based on OOM).\n",
        "- Image size: 384 \u2192 448 (if headroom).\n",
        "- Save best by val micro-F1 (manual TP/FP/FN), log every 50 iters.\n",
        "\n",
        "Implementation steps:\n",
        "1) Add env/setup cell (torch CUDA sanity, env vars).\n",
        "2) Create train_b4_mem.py (clone train.py; add accum, chkpt, channels_last, amp, checkpointing).\n",
        "3) Smoke run: 1 fold, 1000 train imgs sampled, bs=8, size=384 \u2192 verify F1 increases, no NaN/OOM.\n",
        "4) Full run: 5 folds, b4@384 (or 448 if fits); cache OOF/test probs.\n",
        "5) Evaluate OOF micro-F1; if >=0.64, proceed to test+blend; else adjust.\n",
        "6) If GPU headroom: b5_ns single fold @456; proceed if stable.\n",
        "\n",
        "Expert checkpoints:\n",
        "- After env/setup code (M1 pre-run) \u2013 confirm memory knobs.\n",
        "- After smoke run logs \u2013 confirm curves/hparams.\n",
        "- After first fold full run \u2013 confirm scaling to 5 folds.\n",
        "\n",
        "Time budget (remaining ~4h):\n",
        "- Setup + smoke: 20-30m\n",
        "- Fold 0 full: 45-60m\n",
        "- Remaining folds parallelized sequentially: 2h (monitor), else do 3 folds\n",
        "- Inference + blend: 20m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "bf2a12ba-3e50-46fe-a800-2e975d09773b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Env + CUDA sanity + memory knobs\n",
        "import os, sys, time, gc, platform, shutil\n",
        "import torch\n",
        "import numpy as np\n",
        "try:\n",
        "    import timm\n",
        "except Exception as e:\n",
        "    timm = None\n",
        "\n",
        "# Strongly recommend running this cell first in every session\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128,expandable_segments:True'\n",
        "os.environ.setdefault('CUDA_DEVICE_ORDER', 'PCI_BUS_ID')\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "print('Torch:', torch.__version__, 'CUDA build:', getattr(torch.version, 'cuda', None), flush=True)\n",
        "\n",
        "assert torch.cuda.is_available(), 'CUDA not available - cannot proceed'\n",
        "dev = torch.device('cuda:0')\n",
        "print('GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# Enable TF32 and optimized matmul on Ampere+\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.set_float32_matmul_precision('high')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cudnn.deterministic = False\n",
        "\n",
        "# Optional: reduce IPC handle leak risk in dataloader heavy runs\n",
        "try:\n",
        "    torch.multiprocessing.set_sharing_strategy('file_system')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "def cuda_mem_gb():\n",
        "    stats = torch.cuda.get_device_properties(0)\n",
        "    total = stats.total_memory / (1024**3)\n",
        "    reserved = torch.cuda.memory_reserved(0) / (1024**3)\n",
        "    allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
        "    free_est = total - reserved\n",
        "    return dict(total_gb=round(total,2), reserved_gb=round(reserved,2), allocated_gb=round(allocated,2), est_free_gb=round(free_est,2))\n",
        "\n",
        "torch.cuda.empty_cache(); gc.collect()\n",
        "print('CUDA mem:', cuda_mem_gb(), flush=True)\n",
        "print('timm available:', timm is not None, flush=True)\n",
        "\n",
        "# Quick tensor alloc to confirm AMP/TF32 path works\n",
        "x = torch.randn(4096, 4096, device=dev, dtype=torch.float32)\n",
        "with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n",
        "    y = x @ x.t()\n",
        "torch.cuda.synchronize()\n",
        "del x, y\n",
        "torch.cuda.empty_cache(); gc.collect()\n",
        "print('Sanity OK. Ready for smoke training.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]\nPlatform: Linux-6.8.0-1031-azure-x86_64-with-glibc2.35\nTorch: 2.4.1+cu121 CUDA build: 12.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: NVIDIA A10-24Q\nCUDA mem: {'total_gb': 23.72, 'reserved_gb': 0.0, 'allocated_gb': 0.0, 'est_free_gb': 23.72}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timm available: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity OK. Ready for smoke training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_16543/1102878925.py:49: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.bfloat16):\n"
          ]
        }
      ]
    },
    {
      "id": "1205569c-5669-41bc-8f40-e47f897b13aa",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Smoke run: b4@384 fold0 using existing train.py (no accum/ckpt yet)\n",
        "import subprocess, shlex, os, time, sys\n",
        "args = [\n",
        "    sys.executable, 'train.py',\n",
        "    '--model', 'tf_efficientnet_b4_ns',\n",
        "    '--img-size', '384',\n",
        "    '--epochs', '2',\n",
        "    '--batch-size', '8',\n",
        "    '--val-batch-size', '16',\n",
        "    '--num-workers', '4',\n",
        "    '--folds', '0',\n",
        "    '--out-dir', 'out_b4_384_top512_smoke',\n",
        "    '--train-csv', 'train.csv',\n",
        "    '--labels-csv', 'labels.csv',\n",
        "    '--folds-csv', 'train_folds_top512.csv',\n",
        "    '--sample-sub', 'sample_submission.csv',\n",
        "    '--lr', '2e-4',\n",
        "    '--early-stop-patience', '1',\n",
        "    '--limit-train-steps', '300',\n",
        "    '--limit-val-steps', '150',\n",
        "    '--pretrained'\n",
        "]\n",
        "print('Running:', ' '.join(shlex.quote(a) for a in args))\n",
        "t0 = time.time()\n",
        "proc = subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "print(proc.stdout)\n",
        "print(f'Elapsed: {(time.time()-t0)/60:.2f} min', flush=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: /usr/bin/python3.11 train.py --model tf_efficientnet_b4_ns --img-size 384 --epochs 2 --batch-size 8 --val-batch-size 16 --num-workers 4 --folds 0 --out-dir out_b4_384_top512_smoke --train-csv train.csv --labels-csv labels.csv --folds-csv train_folds_top512.csv --sample-sub sample_submission.csv --lr 2e-4 --early-stop-patience 1 --limit-train-steps 300 --limit-val-steps 150 --pretrained\n"
          ]
        }
      ]
    },
    {
      "id": "31ef9d0c-9ef9-45e3-9e93-c9389963f871",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate memory-optimized training script: train_b4_mem.py\n",
        "from pathlib import Path\n",
        "script = r'''#!/usr/bin/env python3\n",
        "import os, sys, math, time, json, argparse, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "\n",
        "os.environ.setdefault('OMP_NUM_THREADS','1')\n",
        "try: cv2.setNumThreads(0)\n",
        "except Exception: pass\n",
        "try:\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "except Exception: pass\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def detect_ext(train_dir: Path, ids):\n",
        "    for ext in ('.png','.jpg','.jpeg','.webp','.bmp'):\n",
        "        p = train_dir / f\"{ids[0]}{ext}\"\n",
        "        if p.exists(): return ext\n",
        "    cands = list(train_dir.glob(f\"{ids[0]}.*\"))\n",
        "    return cands[0].suffix if cands else '.png'\n",
        "\n",
        "def ensure_folds(train_csv: str, labels_csv: str, out_csv: str, seed: int = 42, n_splits: int = 5):\n",
        "    p_out = Path(out_csv)\n",
        "    if p_out.exists(): return pd.read_csv(p_out)\n",
        "    t0 = time.time()\n",
        "    df = pd.read_csv(train_csv)\n",
        "    labels_df = pd.read_csv(labels_csv)\n",
        "    attr_ids = sorted(labels_df['attribute_id'].unique().tolist())\n",
        "    attr_to_idx = {a:i for i,a in enumerate(attr_ids)}\n",
        "    num_labels = len(attr_ids)\n",
        "    attrs = df['attribute_ids'].fillna('').tolist()\n",
        "    rows, cols = [], []\n",
        "    for i, s in enumerate(attrs):\n",
        "        if s:\n",
        "            for a in map(int, s.split()):\n",
        "                if a in attr_to_idx:\n",
        "                    rows.append(i); cols.append(attr_to_idx[a])\n",
        "    method='unknown'\n",
        "    try:\n",
        "        from scipy.sparse import csr_matrix\n",
        "        y = csr_matrix((np.ones(len(rows), dtype=np.uint8), (rows, cols)), shape=(len(df), num_labels), dtype=np.uint8)\n",
        "        mskf = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "        folds = np.full(len(df), -1, np.int16)\n",
        "        for f, (_, vidx) in enumerate(mskf.split(np.zeros(len(df)), y)):\n",
        "            folds[vidx] = f\n",
        "        method='MSKF_sparse'\n",
        "    except Exception:\n",
        "        lens = np.array([len(s.split()) if s else 0 for s in attrs])\n",
        "        bins = np.clip(lens, 0, 8)\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "        folds = np.full(len(df), -1, np.int16)\n",
        "        for f, (_, vidx) in enumerate(skf.split(np.zeros(len(df)), bins)):\n",
        "            folds[vidx] = f\n",
        "        method='cardinality'\n",
        "    out = df.copy(); out['fold'] = folds\n",
        "    out.to_csv(p_out, index=False)\n",
        "    print(f\"Saved folds to {out_csv} using {method} in {time.time()-t0:.1f}s\", flush=True)\n",
        "    return out\n",
        "\n",
        "class IMetDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, img_root: Path, ext: str, num_classes: int, img_size: int, is_train: bool, attr_to_idx=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_root = img_root; self.ext = ext\n",
        "        self.num_classes = num_classes; self.img_size = img_size\n",
        "        self.is_train = is_train; self.attr_to_idx = attr_to_idx\n",
        "        if is_train:\n",
        "            self.transform = A.Compose([\n",
        "                A.RandomResizedCrop(img_size, img_size, scale=(0.85,1.0), ratio=(0.9,1.1), interpolation=cv2.INTER_CUBIC),\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.ColorJitter(0.2,0.2,0.2,0.05, p=0.3),\n",
        "                A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "                ToTensorV2(),\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = A.Compose([\n",
        "                A.Resize(img_size, img_size, interpolation=cv2.INTER_CUBIC),\n",
        "                A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "                ToTensorV2(),\n",
        "            ])\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]; img_id = r['id']\n",
        "        path = self.img_root / f\"{img_id}{self.ext}\"\n",
        "        img = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
        "        if img is None: raise FileNotFoundError(str(path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = self.transform(image=img)['image']\n",
        "        target = torch.zeros(self.num_classes, dtype=torch.float32)\n",
        "        s = r.get('attribute_ids','')\n",
        "        if isinstance(s,str) and s:\n",
        "            ids = [int(x) for x in s.split() if x!='']\n",
        "            if self.attr_to_idx is not None:\n",
        "                idxs = [self.attr_to_idx[i] for i in ids if i in self.attr_to_idx]\n",
        "            else:\n",
        "                idxs = ids\n",
        "            if idxs:\n",
        "                target[torch.tensor(idxs, dtype=torch.long)] = 1.0\n",
        "        return img, target\n",
        "\n",
        "class ASL(nn.Module):\n",
        "    def __init__(self, gamma_neg=4, gamma_pos=0, margin=0.05, clip=0.0, eps=1e-6):\n",
        "        super().__init__(); self.gn=gamma_neg; self.gp=gamma_pos; self.margin=margin; self.clip=clip; self.eps=eps\n",
        "    def forward(self, logits, targets):\n",
        "        logits = logits.float(); targets = targets.float()\n",
        "        if self.margin and self.margin>0: logits = logits - self.margin*(2*targets-1)\n",
        "        p = torch.sigmoid(logits)\n",
        "        if self.clip and self.clip>0: p = torch.clamp(p, self.clip, 1.0-self.clip)\n",
        "        p = torch.clamp(p, self.eps, 1.0-self.eps); q = 1.0 - p\n",
        "        loss_pos = targets * torch.pow(1.0 - p, self.gp) * torch.log(p)\n",
        "        loss_neg = (1.0 - targets) * torch.pow(p, self.gn) * torch.log(q)\n",
        "        loss = -(loss_pos + loss_neg)\n",
        "        return torch.nan_to_num(loss, nan=0.0, posinf=0.0, neginf=0.0).mean()\n",
        "\n",
        "def micro_f1_from_probs(probs, targets, thr=0.2):\n",
        "    preds = (probs >= thr).astype(np.uint8); t = targets.astype(np.uint8)\n",
        "    tp = np.logical_and(preds==1, t==1).sum(dtype=np.int64)\n",
        "    fp = np.logical_and(preds==1, t==0).sum(dtype=np.int64)\n",
        "    fn = np.logical_and(preds==0, t==1).sum(dtype=np.int64)\n",
        "    denom = 2*tp + fp + fn\n",
        "    return float((2*tp)/denom) if denom>0 else 0.0\n",
        "\n",
        "def init_classifier_bias(model, num_classes, bias_vec, device):\n",
        "    with torch.no_grad():\n",
        "        head = model.get_classifier() if hasattr(model,'get_classifier') else None\n",
        "        if isinstance(head, nn.Linear) and head.out_features==num_classes and head.bias is not None:\n",
        "            head.bias.copy_(torch.from_numpy(bias_vec).to(device)); return\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.Linear) and m.out_features==num_classes and m.bias is not None:\n",
        "                m.bias.copy_(torch.from_numpy(bias_vec).to(device)); return\n",
        "\n",
        "def train_one_fold(cfg, fold, train_df, num_classes, img_ext, attr_to_idx):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    trn_idx = np.where(train_df['fold'] != fold)[0]\n",
        "    val_idx = np.where(train_df['fold'] == fold)[0]\n",
        "    trn_df = train_df.iloc[trn_idx].reset_index(drop=True)\n",
        "    val_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
        "    if cfg.subsample_train>0 and len(trn_df)>cfg.subsample_train:\n",
        "        trn_df = trn_df.sample(cfg.subsample_train, random_state=cfg.seed).reset_index(drop=True)\n",
        "\n",
        "    train_ds = IMetDataset(trn_df, cfg.train_dir, img_ext, num_classes, cfg.img_size, is_train=True, attr_to_idx=attr_to_idx)\n",
        "    val_ds = IMetDataset(val_df, cfg.train_dir, img_ext, num_classes, cfg.img_size, is_train=False, attr_to_idx=attr_to_idx)\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers, pin_memory=True, drop_last=True, persistent_workers=True, prefetch_factor=2)\n",
        "    val_loader = DataLoader(val_ds, batch_size=cfg.val_batch_size, shuffle=False, num_workers=cfg.num_workers, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "\n",
        "    model = timm.create_model(cfg.model, pretrained=cfg.pretrained, num_classes=num_classes)\n",
        "    if hasattr(model, 'set_grad_checkpointing'): model.set_grad_checkpointing(True)\n",
        "    model = model.to(device).to(memory_format=torch.channels_last)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=1e-4)\n",
        "    steps_per_epoch = max(1, len(train_loader))\n",
        "    total_steps = steps_per_epoch * cfg.epochs\n",
        "    warmup = max(1, int(steps_per_epoch*1)) if cfg.warmup_epochs>0 else max(1, int(0.05*total_steps))\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup: return float(step)/float(max(1,warmup))\n",
        "        progress = float(step - warmup) / float(max(1, total_steps - warmup))\n",
        "        return 0.5*(1.0 + math.cos(math.pi*progress))\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "    scaler = torch.amp.GradScaler('cuda', init_scale=2**15, growth_interval=1500)\n",
        "    criterion = ASL(gamma_neg=4, gamma_pos=0, margin=0.05, clip=0.0, eps=1e-6)\n",
        "\n",
        "    counts = np.zeros(num_classes, dtype=np.int64)\n",
        "    for s in trn_df['attribute_ids'].fillna(''):\n",
        "        if s:\n",
        "            for a in map(int, s.split()):\n",
        "                if a in attr_to_idx: counts[attr_to_idx[a]] += 1\n",
        "    p = np.clip(counts / max(1, len(trn_df)), 1e-6, 1-1e-6)\n",
        "    bias_vec = np.log(p/(1-p)).astype(np.float32) * 0.25\n",
        "    init_classifier_bias(model, num_classes, bias_vec, device)\n",
        "\n",
        "    ema = ModelEmaV2(model, decay=0.9995) if cfg.use_ema else None\n",
        "\n",
        "    best_f1 = -1.0; best_state=None; step=0; no_improve=0\n",
        "    torch.cuda.reset_peak_memory_stats(device) if device.type=='cuda' else None\n",
        "    for epoch in range(cfg.epochs):\n",
        "        model.train();\n",
        "        running_loss = 0.0;\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        start = time.time()\n",
        "        for bi, (imgs, targets) in enumerate(train_loader):\n",
        "            imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            targets = targets.to(device, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda', enabled=True):\n",
        "                logits = model(imgs)\n",
        "                loss = criterion(logits, targets) / cfg.accum_steps\n",
        "            if torch.isnan(loss): continue\n",
        "            scaler.scale(loss).backward()\n",
        "            if ((bi+1) % cfg.accum_steps == 0) or (bi+1 == len(train_loader)) or (cfg.limit_train_steps and (bi+1)>=cfg.limit_train_steps):\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                scaler.step(optimizer); scaler.update(); optimizer.zero_grad(set_to_none=True); scheduler.step()\n",
        "                if ema is not None: ema.update(model)\n",
        "            running_loss += float(loss.detach().cpu().item()) * cfg.accum_steps\n",
        "            step += 1\n",
        "            if (bi+1) % 100 == 0:\n",
        "                mem = torch.cuda.max_memory_allocated()/1024**3 if device.type=='cuda' else 0.0\n",
        "                it_s = (bi+1)/max(1,(time.time()-start))\n",
        "                print(f\"fold {fold} epoch {epoch+1} iter {bi+1}/{len(train_loader)} loss {running_loss/(bi+1):.4f} it/s {it_s:.2f} lr {scheduler.get_last_lr()[0]:.6f} mem_gb {mem:.2f} scale {scaler.get_scale():.1f}\", flush=True)\n",
        "            if cfg.limit_train_steps and (bi+1)>=cfg.limit_train_steps: break\n",
        "\n",
        "        # Validation\n",
        "        model.eval(); eval_model = ema.module if (ema is not None) else model\n",
        "        all_probs=[]; all_tgts=[]\n",
        "        with torch.no_grad():\n",
        "            for bi, (imgs, targets) in enumerate(val_loader):\n",
        "                imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                logits = eval_model(imgs)\n",
        "                probs = torch.sigmoid(logits).float().cpu().numpy()\n",
        "                all_probs.append(probs); all_tgts.append((targets>0.5).cpu().numpy().astype(np.uint8))\n",
        "                if cfg.limit_val_steps and (bi+1)>=cfg.limit_val_steps: break\n",
        "        all_probs = np.concatenate(all_probs, axis=0) if all_probs else np.zeros((len(val_df), num_classes), dtype=np.float32)\n",
        "        all_tgts  = np.concatenate(all_tgts , axis=0) if all_tgts  else np.zeros((len(val_df), num_classes), dtype=np.uint8)\n",
        "        thrs = np.arange(0.05, 0.501, 0.01)\n",
        "        f1s = [micro_f1_from_probs(all_probs, all_tgts, thr=t) for t in thrs]\n",
        "        best_idx = int(np.argmax(f1s)); f1 = float(f1s[best_idx]); thr = float(thrs[best_idx])\n",
        "        print(f\"fold {fold} epoch {epoch+1} val micro-f1 {f1:.5f} @ thr {thr:.3f}\", flush=True)\n",
        "        if f1>best_f1:\n",
        "            best_f1=f1; \n",
        "            best_state={'model': eval_model.state_dict(), 'f1': best_f1, 'thr': thr, 'epoch': epoch+1}\n",
        "            no_improve=0\n",
        "        else:\n",
        "            no_improve+=1\n",
        "            if no_improve>=cfg.early_stop_patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\", flush=True);\n",
        "                \n",
        "                \n",
        "                \n",
        "                \n",
        "                \n",
        "                \n",
        "                \n",
        "                \n",
        "                \n",
        "                break\n",
        "\n",
        "    out_dir = Path(cfg.out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    torch.save(best_state, out_dir / f\"{cfg.model.replace('/','_')}_fold{fold}.pth\")\n",
        "\n",
        "    # OOF extraction\n",
        "    if best_state is not None:\n",
        "        eval_model = timm.create_model(cfg.model, pretrained=False, num_classes=num_classes).to(device).to(memory_format=torch.channels_last)\n",
        "        eval_model.load_state_dict(best_state['model'], strict=True); eval_model.eval()\n",
        "        val_loader2 = DataLoader(val_ds, batch_size=cfg.val_batch_size, shuffle=False, num_workers=cfg.num_workers, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "        oof_probs=[]\n",
        "        with torch.no_grad():\n",
        "            for imgs,_ in val_loader2:\n",
        "                imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                probs = torch.sigmoid(eval_model(imgs)).float().cpu().numpy()\n",
        "                oof_probs.append(probs)\n",
        "        oof_probs = np.concatenate(oof_probs, axis=0)\n",
        "    else:\n",
        "        oof_probs = np.zeros((len(val_df), num_classes), dtype=np.float32)\n",
        "    return val_idx, oof_probs, (best_state['thr'] if best_state else 0.2), best_f1\n",
        "\n",
        "def infer_test(cfg, model_paths, num_classes, img_ext, attr_to_idx, idx_to_attr):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    sub = pd.read_csv(cfg.sample_sub); test_df = sub[['id']].copy()\n",
        "    test_ds = IMetDataset(test_df, cfg.test_dir, img_ext, num_classes, cfg.img_size, is_train=False, attr_to_idx=attr_to_idx)\n",
        "    test_loader = DataLoader(test_ds, batch_size=cfg.val_batch_size, shuffle=False, num_workers=cfg.num_workers, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "    all_logits=[]\n",
        "    for pth in model_paths:\n",
        "        state = torch.load(pth, map_location='cpu')\n",
        "        model = timm.create_model(cfg.model, pretrained=False, num_classes=num_classes).to(device).to(memory_format=torch.channels_last)\n",
        "        model.load_state_dict(state['model'], strict=True); model.eval()\n",
        "        logits_list=[]\n",
        "        with torch.no_grad():\n",
        "            for imgs,_ in test_loader:\n",
        "                imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                logits = model(imgs); logits_list.append(logits.float().cpu().numpy())\n",
        "        all_logits.append(np.concatenate(logits_list, axis=0))\n",
        "    probs = 1.0/(1.0+np.exp(-np.mean(all_logits, axis=0)))\n",
        "    return test_df['id'].values, probs\n",
        "\n",
        "def probs_to_submission(ids, probs, thr, idx_to_attr, topk_fallback=1):\n",
        "    rows=[]\n",
        "    for i in range(len(ids)):\n",
        "        p = probs[i]; pred_idx = np.where(p>=thr)[0].tolist()\n",
        "        if len(pred_idx)==0: pred_idx=[int(np.argmax(p))]\n",
        "        pred_attr=[int(idx_to_attr[j]) for j in sorted(set(pred_idx))]\n",
        "        rows.append({'id': ids[i], 'attribute_ids': ' '.join(str(x) for x in pred_attr)})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument('--model', type=str, default='tf_efficientnet_b4_ns')\n",
        "    ap.add_argument('--img-size', type=int, default=384)\n",
        "    ap.add_argument('--epochs', type=int, default=6)\n",
        "    ap.add_argument('--batch-size', type=int, default=8)  # micro-batch\n",
        "    ap.add_argument('--accum-steps', type=int, default=8)\n",
        "    ap.add_argument('--val-batch-size', type=int, default=16)\n",
        "    ap.add_argument('--num-workers', type=int, default=4)\n",
        "    ap.add_argument('--seed', type=int, default=42)\n",
        "    ap.add_argument('--use-ema', action='store_true')\n",
        "    ap.add_argument('--tta', action='store_true')\n",
        "    ap.add_argument('--folds', type=str, default='0')\n",
        "    ap.add_argument('--out-dir', type=str, default='out_b4_mem')\n",
        "    ap.add_argument('--train-csv', type=str, default='train.csv')\n",
        "    ap.add_argument('--labels-csv', type=str, default='labels.csv')\n",
        "    ap.add_argument('--folds-csv', type=str, default='train_folds_top512.csv')\n",
        "    ap.add_argument('--sample-sub', type=str, default='sample_submission.csv')\n",
        "    ap.add_argument('--train-dir', type=Path, default=Path('train'))\n",
        "    ap.add_argument('--test-dir', type=Path, default=Path('test'))\n",
        "    ap.add_argument('--lr', type=float, default=2e-4)\n",
        "    ap.add_argument('--limit-train-steps', type=int, default=0)\n",
        "    ap.add_argument('--limit-val-steps', type=int, default=0)\n",
        "    ap.add_argument('--early-stop-patience', type=int, default=2)\n",
        "    ap.add_argument('--subsample-train', type=int, default=0)\n",
        "    # warmup epochs for cosine\n",
        "    ap.add_argument('--warmup-epochs', type=float, default=1.0)\n",
        "    ap.add_argument('--pretrained', dest='pretrained', action='store_true')\n",
        "    ap.add_argument('--no-pretrained', dest='pretrained', action='store_false')\n",
        "    ap.set_defaults(pretrained=True)\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    class Cfg: pass\n",
        "    cfg = Cfg()\n",
        "    for k,v in vars(args).items(): setattr(cfg, k.replace('-', '_'), v)\n",
        "\n",
        "    set_seed(cfg.seed)\n",
        "    train_df = ensure_folds(cfg.train_csv, cfg.labels_csv, cfg.folds_csv, seed=cfg.seed, n_splits=5)\n",
        "    labels_df = pd.read_csv(cfg.labels_csv)\n",
        "    attr_ids = sorted(labels_df['attribute_id'].unique().tolist())\n",
        "    attr_to_idx = {a:i for i,a in enumerate(attr_ids)}\n",
        "    idx_to_attr = np.array(attr_ids, dtype=np.int32)\n",
        "    num_classes = len(attr_ids)\n",
        "    img_ext = detect_ext(cfg.train_dir, [train_df['id'].iloc[0]])\n",
        "    print(f\"Detected image extension: {img_ext}\", flush=True)\n",
        "\n",
        "    folds = [int(x) for x in str(cfg.folds).split(',') if x!='']\n",
        "    all_val_idx=[]; all_oof_probs=[]; model_paths=[]; fold_thrs=[]; fold_f1s=[]\n",
        "    for f in folds:\n",
        "        print(f\"==== Fold {f} start ====\", flush=True)\n",
        "        val_idx, oof_probs, thr, f1 = train_one_fold(cfg, f, train_df, num_classes, img_ext, attr_to_idx)\n",
        "        all_val_idx.append(val_idx); all_oof_probs.append(oof_probs); fold_thrs.append(thr); fold_f1s.append(f1)\n",
        "        model_paths.append(Path(cfg.out_dir) / f\"{cfg.model.replace('/','_')}_fold{f}.pth\")\n",
        "        print(f\"==== Fold {f} done: best_f1 {f1:.5f} thr {thr:.3f} ====\", flush=True)\n",
        "\n",
        "    oof = np.zeros((len(train_df), num_classes), dtype=np.float32)\n",
        "    for val_idx, probs in zip(all_val_idx, all_oof_probs): oof[val_idx,:] = probs\n",
        "    Path(cfg.out_dir).mkdir(parents=True, exist_ok=True)\n",
        "    np.save(Path(cfg.out_dir)/'oof_probs.npy', oof)\n",
        "    train_df[['id','attribute_ids','fold']].to_csv(Path(cfg.out_dir)/'oof_meta.csv', index=False)\n",
        "    y_true = np.zeros((len(train_df), num_classes), dtype=np.uint8)\n",
        "    for i,s in enumerate(train_df['attribute_ids'].fillna('').tolist()):\n",
        "        if s:\n",
        "            for a in map(int, s.split()):\n",
        "                j = attr_to_idx.get(a, None)\n",
        "                if j is not None: y_true[i,j]=1\n",
        "    thrs = np.arange(0.05, 0.501, 0.005)\n",
        "    f1s = [micro_f1_from_probs(oof, y_true, thr=t) for t in thrs]\n",
        "    best_idx = int(np.argmax(f1s)); best_thr=float(thrs[best_idx]); best_f1=float(f1s[best_idx])\n",
        "    print(f\"OOF micro-f1 {best_f1:.5f} @ thr {best_thr:.3f}\", flush=True)\n",
        "\n",
        "    ids, test_probs = infer_test(cfg, model_paths, num_classes, img_ext, attr_to_idx, idx_to_attr)\n",
        "    np.save(Path(cfg.out_dir)/'test_probs.npy', test_probs)\n",
        "    sub_df = probs_to_submission(ids, test_probs, best_thr, idx_to_attr, topk_fallback=1)\n",
        "    sub_df.to_csv('submission.csv', index=False)\n",
        "    print('Wrote submission.csv', flush=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "'''\n",
        "Path('train_b4_mem.py').write_text(script)\n",
        "print('Wrote train_b4_mem.py')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote train_b4_mem.py\n"
          ]
        }
      ]
    },
    {
      "id": "c72f9fa1-9357-4600-9850-363483967ac1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Smoke run using train_b4_mem.py: b4@384, mb=8, accum=8, subsample=1000\n",
        "import subprocess, shlex, time, sys\n",
        "args = [\n",
        "    sys.executable, 'train_b4_mem.py',\n",
        "    '--model', 'tf_efficientnet_b4_ns',\n",
        "    '--img-size', '384',\n",
        "    '--epochs', '2',\n",
        "    '--batch-size', '8',\n",
        "    '--accum-steps', '8',\n",
        "    '--val-batch-size', '16',\n",
        "    '--num-workers', '4',\n",
        "    '--folds', '0',\n",
        "    '--out-dir', 'out_b4_mem_384_smoke',\n",
        "    '--train-csv', 'train.csv',\n",
        "    '--labels-csv', 'labels.csv',\n",
        "    '--folds-csv', 'train_folds_top512.csv',\n",
        "    '--sample-sub', 'sample_submission.csv',\n",
        "    '--lr', '2e-4',\n",
        "    '--early-stop-patience', '1',\n",
        "    '--limit-train-steps', '300',\n",
        "    '--limit-val-steps', '150',\n",
        "    '--subsample-train', '1000',\n",
        "    '--pretrained'\n",
        "]\n",
        "print('Running:', ' '.join(shlex.quote(a) for a in args), flush=True)\n",
        "t0 = time.time()\n",
        "proc = subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "print(proc.stdout)\n",
        "print(f'Elapsed: {(time.time()-t0)/60:.2f} min', flush=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: /usr/bin/python3.11 train_b4_mem.py --model tf_efficientnet_b4_ns --img-size 384 --epochs 2 --batch-size 8 --accum-steps 8 --val-batch-size 16 --num-workers 4 --folds 0 --out-dir out_b4_mem_384_smoke --train-csv train.csv --labels-csv labels.csv --folds-csv train_folds_top512.csv --sample-sub sample_submission.csv --lr 2e-4 --early-stop-patience 1 --limit-train-steps 300 --limit-val-steps 150 --subsample-train 1000 --pretrained\n"
          ]
        }
      ]
    },
    {
      "id": "f428838e-91aa-4c2b-a22a-a1fed1f9d8cd",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Full fold-0 run: b4@448, mb=4, accum=16 (OOM-safe)\n",
        "import subprocess, shlex, time, sys\n",
        "args = [\n",
        "    sys.executable, 'train_b4_mem.py',\n",
        "    '--model', 'tf_efficientnet_b4_ns',\n",
        "    '--img-size', '448',\n",
        "    '--epochs', '6',\n",
        "    '--batch-size', '4',\n",
        "    '--accum-steps', '16',\n",
        "    '--val-batch-size', '16',\n",
        "    '--num-workers', '4',\n",
        "    '--folds', '0',\n",
        "    '--out-dir', 'out_b4_mem_448_f0',\n",
        "    '--train-csv', 'train.csv',\n",
        "    '--labels-csv', 'labels.csv',\n",
        "    '--folds-csv', 'train_folds_top512.csv',\n",
        "    '--sample-sub', 'sample_submission.csv',\n",
        "    '--lr', '2e-4',\n",
        "    '--early-stop-patience', '2',\n",
        "    '--pretrained'\n",
        "]\n",
        "print('Running:', ' '.join(shlex.quote(a) for a in args), flush=True)\n",
        "t0 = time.time()\n",
        "proc = subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "print(proc.stdout)\n",
        "print(f'Elapsed: {(time.time()-t0)/60:.2f} min', flush=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: /usr/bin/python3.11 train_b4_mem.py --model tf_efficientnet_b4_ns --img-size 448 --epochs 6 --batch-size 4 --accum-steps 16 --val-batch-size 16 --num-workers 4 --folds 0 --out-dir out_b4_mem_448_f0 --train-csv train.csv --labels-csv labels.csv --folds-csv train_folds_top512.csv --sample-sub sample_submission.csv --lr 2e-4 --early-stop-patience 2 --pretrained\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mRunning:\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(shlex.quote(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args), flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     23\u001b[39m t0 = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m proc = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(proc.stdout)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mElapsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time.time()-t0)/\u001b[32m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m min\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/subprocess.py:548\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    547\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    550\u001b[39m         process.kill()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/subprocess.py:1192\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1190\u001b[39m     \u001b[38;5;28mself\u001b[39m._stdin_write(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stdout:\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     stdout = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1193\u001b[39m     \u001b[38;5;28mself\u001b[39m.stdout.close()\n\u001b[32m   1194\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stderr:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "ad68cb39-5426-4d79-bf31-8d6f63de59be",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Relaunch fold-0 with streaming logs: b4@448, mb=4, accum=16, val_bs=32, EMA on, step limits, allocator fix\n",
        "import os, sys, time, shlex, subprocess\n",
        "\n",
        "def run_stream(cmd_list, env=None):\n",
        "    print('Running:', ' '.join(shlex.quote(x) for x in cmd_list), flush=True)\n",
        "    proc = subprocess.Popen(cmd_list, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, env=env)\n",
        "    t0 = time.time()\n",
        "    try:\n",
        "        for line in iter(proc.stdout.readline, ''):\n",
        "            if line == '' and proc.poll() is not None:\n",
        "                break\n",
        "            print(line.rstrip(), flush=True)\n",
        "    finally:\n",
        "        proc.stdout.close()\n",
        "        ret = proc.wait()\n",
        "        print(f'Exit code: {ret} | Elapsed {(time.time()-t0)/60:.2f} min', flush=True)\n",
        "    return ret\n",
        "\n",
        "env = os.environ.copy()\n",
        "env['PYTHONUNBUFFERED'] = '1'\n",
        "# Avoid allocator expandable segments during eval to prevent INTERNAL ASSERT\n",
        "env['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "\n",
        "args = [\n",
        "    sys.executable, '-u', 'train_b4_mem.py',\n",
        "    '--model', 'tf_efficientnet_b4_ns',\n",
        "    '--img-size', '448',\n",
        "    '--epochs', '4',\n",
        "    '--batch-size', '4',\n",
        "    '--accum-steps', '16',\n",
        "    '--val-batch-size', '32',\n",
        "    '--num-workers', '4',\n",
        "    '--folds', '0',\n",
        "    '--out-dir', 'out_b4_mem_448_f0',\n",
        "    '--train-csv', 'train.csv',\n",
        "    '--labels-csv', 'labels.csv',\n",
        "    '--folds-csv', 'train_folds_top512.csv',\n",
        "    '--sample-sub', 'sample_submission.csv',\n",
        "    '--lr', '2e-4',\n",
        "    '--early-stop-patience', '2',\n",
        "    '--limit-train-steps', '6000',\n",
        "    '--limit-val-steps', '2000',\n",
        "    '--pretrained',\n",
        "    '--use-ema'\n",
        "]\n",
        "ret = run_stream(args, env=env)\n",
        "print('Done with fold-0 run (streaming).')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: /usr/bin/python3.11 -u train_b4_mem.py --model tf_efficientnet_b4_ns --img-size 448 --epochs 6 --batch-size 4 --accum-steps 16 --val-batch-size 32 --num-workers 4 --folds 0 --out-dir out_b4_mem_448_f0 --train-csv train.csv --labels-csv labels.csv --folds-csv train_folds_top512.csv --sample-sub sample_submission.csv --lr 2e-4 --early-stop-patience 2 --pretrained --use-ema\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected image extension: .png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Fold 0 start ====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 100/24153 loss 0.0019 it/s 7.08 lr 0.000000 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 200/24153 loss 0.0019 it/s 8.77 lr 0.000000 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 300/24153 loss 0.0019 it/s 9.53 lr 0.000000 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 400/24153 loss 0.0019 it/s 10.01 lr 0.000000 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 500/24153 loss 0.0019 it/s 10.34 lr 0.000000 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 600/24153 loss 0.0019 it/s 10.56 lr 0.000000 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 700/24153 loss 0.0019 it/s 10.73 lr 0.000000 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 800/24153 loss 0.0019 it/s 10.86 lr 0.000000 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 900/24153 loss 0.0019 it/s 10.96 lr 0.000000 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1000/24153 loss 0.0019 it/s 11.04 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1100/24153 loss 0.0019 it/s 11.11 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1200/24153 loss 0.0019 it/s 11.17 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1300/24153 loss 0.0019 it/s 11.22 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1400/24153 loss 0.0019 it/s 11.25 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1500/24153 loss 0.0019 it/s 11.28 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1600/24153 loss 0.0019 it/s 11.31 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1700/24153 loss 0.0019 it/s 11.34 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1800/24153 loss 0.0019 it/s 11.37 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1900/24153 loss 0.0019 it/s 11.39 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2000/24153 loss 0.0019 it/s 11.41 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2100/24153 loss 0.0019 it/s 11.43 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2200/24153 loss 0.0019 it/s 11.43 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2300/24153 loss 0.0019 it/s 11.44 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2400/24153 loss 0.0019 it/s 11.44 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2500/24153 loss 0.0019 it/s 11.45 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2600/24153 loss 0.0019 it/s 11.45 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2700/24153 loss 0.0019 it/s 11.46 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2800/24153 loss 0.0019 it/s 11.46 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2900/24153 loss 0.0019 it/s 11.46 lr 0.000001 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3000/24153 loss 0.0019 it/s 11.47 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3100/24153 loss 0.0019 it/s 11.47 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3200/24153 loss 0.0019 it/s 11.48 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3300/24153 loss 0.0019 it/s 11.48 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3400/24153 loss 0.0019 it/s 11.48 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3500/24153 loss 0.0019 it/s 11.48 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3600/24153 loss 0.0019 it/s 11.48 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3700/24153 loss 0.0019 it/s 11.48 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3800/24153 loss 0.0019 it/s 11.49 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 3900/24153 loss 0.0019 it/s 11.50 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4000/24153 loss 0.0019 it/s 11.50 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4100/24153 loss 0.0019 it/s 11.51 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4200/24153 loss 0.0019 it/s 11.51 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4300/24153 loss 0.0019 it/s 11.51 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4400/24153 loss 0.0019 it/s 11.51 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4500/24153 loss 0.0019 it/s 11.51 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4600/24153 loss 0.0019 it/s 11.51 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4700/24153 loss 0.0019 it/s 11.51 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4800/24153 loss 0.0019 it/s 11.50 lr 0.000002 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 4900/24153 loss 0.0019 it/s 11.50 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5000/24153 loss 0.0019 it/s 11.50 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5100/24153 loss 0.0019 it/s 11.50 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5200/24153 loss 0.0019 it/s 11.50 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5300/24153 loss 0.0019 it/s 11.50 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5400/24153 loss 0.0019 it/s 11.51 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5500/24153 loss 0.0019 it/s 11.51 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5600/24153 loss 0.0019 it/s 11.51 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5700/24153 loss 0.0019 it/s 11.51 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5800/24153 loss 0.0019 it/s 11.51 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 5900/24153 loss 0.0019 it/s 11.52 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6000/24153 loss 0.0019 it/s 11.52 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6100/24153 loss 0.0019 it/s 11.52 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6200/24153 loss 0.0019 it/s 11.52 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6300/24153 loss 0.0019 it/s 11.52 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6400/24153 loss 0.0019 it/s 11.52 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6500/24153 loss 0.0019 it/s 11.52 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6600/24153 loss 0.0019 it/s 11.52 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6700/24153 loss 0.0019 it/s 11.52 lr 0.000003 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6800/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 6900/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7000/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7100/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7200/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7300/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7400/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7500/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7600/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7700/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7800/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 7900/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8000/24153 loss 0.0019 it/s 11.52 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8100/24153 loss 0.0019 it/s 11.53 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8200/24153 loss 0.0019 it/s 11.53 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8300/24153 loss 0.0019 it/s 11.53 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8400/24153 loss 0.0019 it/s 11.53 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8500/24153 loss 0.0019 it/s 11.53 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8600/24153 loss 0.0019 it/s 11.53 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8700/24153 loss 0.0019 it/s 11.53 lr 0.000004 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8800/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 8900/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9000/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9100/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9200/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9300/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9400/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9500/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9600/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9700/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9800/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 9900/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10000/24153 loss 0.0019 it/s 11.53 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10100/24153 loss 0.0019 it/s 11.54 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10200/24153 loss 0.0019 it/s 11.54 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10300/24153 loss 0.0019 it/s 11.54 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10400/24153 loss 0.0019 it/s 11.54 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10500/24153 loss 0.0019 it/s 11.54 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10600/24153 loss 0.0019 it/s 11.54 lr 0.000005 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10700/24153 loss 0.0019 it/s 11.54 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10800/24153 loss 0.0019 it/s 11.55 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 10900/24153 loss 0.0019 it/s 11.55 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11000/24153 loss 0.0019 it/s 11.55 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11100/24153 loss 0.0019 it/s 11.55 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11200/24153 loss 0.0019 it/s 11.55 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11300/24153 loss 0.0019 it/s 11.55 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11400/24153 loss 0.0019 it/s 11.56 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11500/24153 loss 0.0019 it/s 11.56 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11600/24153 loss 0.0019 it/s 11.56 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11700/24153 loss 0.0019 it/s 11.56 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11800/24153 loss 0.0019 it/s 11.56 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 11900/24153 loss 0.0019 it/s 11.56 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12000/24153 loss 0.0019 it/s 11.56 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12100/24153 loss 0.0019 it/s 11.56 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12200/24153 loss 0.0019 it/s 11.56 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12300/24153 loss 0.0019 it/s 11.57 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12400/24153 loss 0.0019 it/s 11.57 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12500/24153 loss 0.0019 it/s 11.57 lr 0.000006 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12600/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12700/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12800/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 12900/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13000/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13100/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13200/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13300/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13400/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13500/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13600/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13700/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13800/24153 loss 0.0019 it/s 11.56 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 13900/24153 loss 0.0019 it/s 11.56 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14000/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14100/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14200/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14300/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14400/24153 loss 0.0019 it/s 11.57 lr 0.000007 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14500/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14600/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14700/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14800/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 14900/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15000/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15100/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15200/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15300/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15400/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15500/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15600/24153 loss 0.0019 it/s 11.57 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15700/24153 loss 0.0019 it/s 11.58 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15800/24153 loss 0.0019 it/s 11.58 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 15900/24153 loss 0.0019 it/s 11.58 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16000/24153 loss 0.0019 it/s 11.58 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16100/24153 loss 0.0019 it/s 11.58 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16200/24153 loss 0.0019 it/s 11.58 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16300/24153 loss 0.0019 it/s 11.58 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16400/24153 loss 0.0019 it/s 11.58 lr 0.000008 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16500/24153 loss 0.0019 it/s 11.59 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16600/24153 loss 0.0019 it/s 11.59 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16700/24153 loss 0.0019 it/s 11.59 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16800/24153 loss 0.0019 it/s 11.59 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 16900/24153 loss 0.0019 it/s 11.59 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17000/24153 loss 0.0019 it/s 11.59 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17100/24153 loss 0.0019 it/s 11.59 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17200/24153 loss 0.0019 it/s 11.59 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17300/24153 loss 0.0019 it/s 11.59 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17400/24153 loss 0.0019 it/s 11.59 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17500/24153 loss 0.0019 it/s 11.59 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17600/24153 loss 0.0019 it/s 11.60 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17700/24153 loss 0.0019 it/s 11.60 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17800/24153 loss 0.0019 it/s 11.60 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 17900/24153 loss 0.0019 it/s 11.60 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18000/24153 loss 0.0019 it/s 11.60 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18100/24153 loss 0.0019 it/s 11.60 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18200/24153 loss 0.0019 it/s 11.60 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18300/24153 loss 0.0019 it/s 11.60 lr 0.000009 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18400/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18500/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18600/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18700/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18800/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 18900/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19000/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19100/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19200/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19300/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19400/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19500/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19600/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19700/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19800/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 19900/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20000/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20100/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20200/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20300/24153 loss 0.0019 it/s 11.60 lr 0.000010 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20400/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20500/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20600/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20700/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20800/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 20900/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21000/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21100/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21200/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21300/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21400/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21500/24153 loss 0.0019 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21600/24153 loss 0.0018 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21700/24153 loss 0.0018 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21800/24153 loss 0.0018 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 21900/24153 loss 0.0018 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22000/24153 loss 0.0018 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22100/24153 loss 0.0018 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22200/24153 loss 0.0018 it/s 11.60 lr 0.000011 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22300/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22400/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22500/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22600/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22700/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22800/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 22900/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23000/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23100/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23200/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23300/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23400/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23500/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23600/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23700/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23800/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 23900/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 32768.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 24000/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 24100/24153 loss 0.0018 it/s 11.60 lr 0.000012 mem_gb 0.88 scale 65536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/var/lib/simon/agent_run_states/imet-2020-fgvc7-20250927-162858/train_b4_mem.py\", line 388, in <module>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    main()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/var/lib/simon/agent_run_states/imet-2020-fgvc7-20250927-162858/train_b4_mem.py\", line 360, in main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    val_idx, oof_probs, thr, f1 = train_one_fold(cfg, f, train_df, num_classes, img_ext, attr_to_idx)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/var/lib/simon/agent_run_states/imet-2020-fgvc7-20250927-162858/train_b4_mem.py\", line 231, in train_one_fold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    logits = eval_model(imgs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             ^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/module.py\", line 1562, in _call_impl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/timm/models/efficientnet.py\", line 268, in forward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    x = self.forward_features(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/timm/models/efficientnet.py\", line 256, in forward_features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    x = self.blocks(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/module.py\", line 1562, in _call_impl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/container.py\", line 219, in forward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            ^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/module.py\", line 1562, in _call_impl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/container.py\", line 219, in forward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            ^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/module.py\", line 1562, in _call_impl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/timm/models/_efficientnet_blocks.py\", line 288, in forward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    x = self.conv_dw(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/modules/module.py\", line 1562, in _call_impl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/timm/layers/conv2d_same.py\", line 51, in forward\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return conv2d_same(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/timm/layers/conv2d_same.py\", line 26, in conv2d_same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    x = pad_same(x, weight.shape[-2:], stride, dilation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/timm/layers/padding.py\", line 63, in pad_same\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    x = F.pad(x, (pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2), value=value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/app/.pip-target/torch/nn/functional.py\", line 4552, in pad\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    return torch._C._nn.pad(input, pad, mode, value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RuntimeError: !block->expandable_segment_ INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":2586, please report a bug to PyTorch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exit code: 1 | Elapsed 35.58 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done with fold-0 run (streaming).\n"
          ]
        }
      ]
    },
    {
      "id": "91f5e0d5-8203-40f6-8142-0446f79f5cda",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Patch train_b4_mem.py to disable grad checkpointing during eval/inference\n",
        "from pathlib import Path\n",
        "\n",
        "p = Path('train_b4_mem.py')\n",
        "txt = p.read_text()\n",
        "\n",
        "# Insert a small utility to disable ckpt\n",
        "if 'def _disable_ckpt(' not in txt:\n",
        "    insert_util = \"\\n\\ndef _disable_ckpt(m):\\n    if hasattr(m, 'set_grad_checkpointing'):\\n        try:\\n            m.set_grad_checkpointing(False)\\n        except Exception:\\n            pass\\n\"\n",
        "    # place after imports\n",
        "    imp_anchor = 'from timm.utils import ModelEmaV2'\n",
        "    txt = txt.replace(imp_anchor, imp_anchor + insert_util)\n",
        "\n",
        "# In validation: after picking eval_model, disable ckpt\n",
        "txt = txt.replace(\n",
        "    \"eval_model = ema.module if (ema is not None) else model\\n        all_probs=[]; all_tgts=[]\",\n",
        "    \"eval_model = ema.module if (ema is not None) else model\\n        _disable_ckpt(eval_model)\\n        all_probs=[]; all_tgts=[]\"\n",
        ")\n",
        "\n",
        "# In OOF extraction: after creating eval_model, disable ckpt\n",
        "txt = txt.replace(\n",
        "    \"eval_model = timm.create_model(cfg.model, pretrained=False, num_classes=num_classes).to(device).to(memory_format=torch.channels_last)\",\n",
        "    \"eval_model = timm.create_model(cfg.model, pretrained=False, num_classes=num_classes).to(device).to(memory_format=torch.channels_last)\\n        _disable_ckpt(eval_model)\"\n",
        ")\n",
        "\n",
        "# In infer_test: after creating model, disable ckpt\n",
        "txt = txt.replace(\n",
        "    \"model = timm.create_model(cfg.model, pretrained=False, num_classes=num_classes).to(device).to(memory_format=torch.channels_last)\",\n",
        "    \"model = timm.create_model(cfg.model, pretrained=False, num_classes=num_classes).to(device).to(memory_format=torch.channels_last)\\n        _disable_ckpt(model)\"\n",
        ")\n",
        "\n",
        "p.write_text(txt)\n",
        "print('Patched train_b4_mem.py: disabled grad checkpointing for eval/inference.')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched train_b4_mem.py: disabled grad checkpointing for eval/inference.\n"
          ]
        }
      ]
    },
    {
      "id": "3f72032a-8c04-4fbe-8586-346ac2426b9c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run stable trainer (train.py) for B4@448 fold0 with streaming logs (OOM-safe settings + step limits)\n",
        "import os, sys, time, shlex, subprocess\n",
        "\n",
        "def run_stream(cmd_list, env=None):\n",
        "    print('Running:', ' '.join(shlex.quote(x) for x in cmd_list), flush=True)\n",
        "    proc = subprocess.Popen(cmd_list, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, env=env)\n",
        "    t0 = time.time()\n",
        "    try:\n",
        "        for line in iter(proc.stdout.readline, ''):\n",
        "            if line == '' and proc.poll() is not None:\n",
        "                break\n",
        "            print(line.rstrip(), flush=True)\n",
        "    finally:\n",
        "        proc.stdout.close()\n",
        "        ret = proc.wait()\n",
        "        print(f'Exit code: {ret} | Elapsed {(time.time()-t0)/60:.2f} min', flush=True)\n",
        "    return ret\n",
        "\n",
        "env = os.environ.copy()\n",
        "env['PYTHONUNBUFFERED'] = '1'\n",
        "env['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n",
        "\n",
        "args = [\n",
        "    sys.executable, '-u', 'train.py',\n",
        "    '--model', 'tf_efficientnet_b4_ns',\n",
        "    '--img-size', '448',\n",
        "    '--epochs', '4',\n",
        "    '--batch-size', '8',\n",
        "    '--val-batch-size', '32',\n",
        "    '--num-workers', '4',\n",
        "    '--folds', '0',\n",
        "    '--out-dir', 'out_b4_trainpy_448_f0',\n",
        "    '--train-csv', 'train.csv',\n",
        "    '--labels-csv', 'labels.csv',\n",
        "    '--folds-csv', 'train_folds_top512.csv',\n",
        "    '--sample-sub', 'sample_submission.csv',\n",
        "    '--lr', '2e-4',\n",
        "    '--early-stop-patience', '2',\n",
        "    '--limit-train-steps', '2000',\n",
        "    '--limit-val-steps', '800',\n",
        "    '--pretrained',\n",
        "    '--use-ema'\n",
        "]\n",
        "ret = run_stream(args, env=env)\n",
        "print('Done: train.py B4@448 fold0')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: /usr/bin/python3.11 -u train.py --model tf_efficientnet_b4_ns --img-size 448 --epochs 4 --batch-size 8 --val-batch-size 32 --num-workers 4 --folds 0 --out-dir out_b4_trainpy_448_f0 --train-csv train.csv --labels-csv labels.csv --folds-csv train_folds_top512.csv --sample-sub sample_submission.csv --lr 2e-4 --early-stop-patience 2 --limit-train-steps 2000 --limit-val-steps 800 --pretrained --use-ema\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected image extension: .png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Fold 0 start ====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/var/lib/simon/agent_run_states/imet-2020-fgvc7-20250927-162858/train.py:220: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  scaler = torch.cuda.amp.GradScaler(enabled=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/var/lib/simon/agent_run_states/imet-2020-fgvc7-20250927-162858/train.py:249: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  with torch.cuda.amp.autocast(enabled=True):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 100/12076 loss 0.0014 elapsed 0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 200/12076 loss 0.0014 elapsed 0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 300/12076 loss 0.0014 elapsed 0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 400/12076 loss 0.0014 elapsed 0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 500/12076 loss 0.0014 elapsed 1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 600/12076 loss 0.0013 elapsed 1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 700/12076 loss 0.0013 elapsed 1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 800/12076 loss 0.0013 elapsed 1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 900/12076 loss 0.0013 elapsed 1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1000/12076 loss 0.0013 elapsed 1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1100/12076 loss 0.0013 elapsed 2.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1200/12076 loss 0.0012 elapsed 2.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1300/12076 loss 0.0012 elapsed 2.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1400/12076 loss 0.0012 elapsed 2.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1500/12076 loss 0.0012 elapsed 2.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1600/12076 loss 0.0012 elapsed 2.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1700/12076 loss 0.0012 elapsed 3.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1800/12076 loss 0.0012 elapsed 3.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 1900/12076 loss 0.0012 elapsed 3.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 iter 2000/12076 loss 0.0012 elapsed 3.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== VAL DIAG fold 0 epoch 1 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_size=24189 probs_shape=(24189, 3474) tgts_shape=(24189, 3474)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probs_range=[0.020055,0.517898]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tgt_pos_rate=0.00127183 mean_pos_per_img=4.418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thr=0.2 pred_pos_rate=0.04761503 mean_pred_per_img=165.415 empty_frac=0.000000 TP=84229 FP=3916985 FN=22646 f1@0.2=0.041006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 1 val micro-f1 0.23764 @ thr 0.380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 100/12076 loss 0.0010 elapsed 6.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 200/12076 loss 0.0010 elapsed 7.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 300/12076 loss 0.0010 elapsed 7.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 400/12076 loss 0.0009 elapsed 7.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 500/12076 loss 0.0009 elapsed 7.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 600/12076 loss 0.0010 elapsed 7.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 700/12076 loss 0.0010 elapsed 7.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 800/12076 loss 0.0009 elapsed 8.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 900/12076 loss 0.0009 elapsed 8.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1000/12076 loss 0.0009 elapsed 8.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1100/12076 loss 0.0009 elapsed 8.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1200/12076 loss 0.0009 elapsed 8.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1300/12076 loss 0.0009 elapsed 8.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1400/12076 loss 0.0009 elapsed 9.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1500/12076 loss 0.0009 elapsed 9.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1600/12076 loss 0.0009 elapsed 9.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1700/12076 loss 0.0009 elapsed 9.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1800/12076 loss 0.0009 elapsed 9.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 1900/12076 loss 0.0009 elapsed 9.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 iter 2000/12076 loss 0.0009 elapsed 10.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== VAL DIAG fold 0 epoch 2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_size=24189 probs_shape=(24189, 3474) tgts_shape=(24189, 3474)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probs_range=[0.018975,0.749775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tgt_pos_rate=0.00127183 mean_pos_per_img=4.418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thr=0.2 pred_pos_rate=0.04951517 mean_pred_per_img=172.016 empty_frac=0.000000 TP=91483 FP=4069405 FN=15392 f1@0.2=0.042872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 2 val micro-f1 0.36834 @ thr 0.410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 100/12076 loss 0.0009 elapsed 13.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 200/12076 loss 0.0009 elapsed 13.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 300/12076 loss 0.0009 elapsed 13.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 400/12076 loss 0.0009 elapsed 13.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 500/12076 loss 0.0009 elapsed 13.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 600/12076 loss 0.0009 elapsed 13.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 700/12076 loss 0.0009 elapsed 14.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 800/12076 loss 0.0009 elapsed 14.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 900/12076 loss 0.0009 elapsed 14.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1000/12076 loss 0.0009 elapsed 14.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1100/12076 loss 0.0009 elapsed 14.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1200/12076 loss 0.0009 elapsed 15.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1300/12076 loss 0.0009 elapsed 15.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1400/12076 loss 0.0009 elapsed 15.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1500/12076 loss 0.0009 elapsed 15.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1600/12076 loss 0.0009 elapsed 15.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1700/12076 loss 0.0009 elapsed 15.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1800/12076 loss 0.0009 elapsed 16.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 1900/12076 loss 0.0009 elapsed 16.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 0 epoch 3 iter 2000/12076 loss 0.0009 elapsed 16.3m\n"
          ]
        }
      ]
    },
    {
      "id": "33dcad12-1acf-4662-bc3e-2cbfe4bfce77",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fast OOF eval and threshold sweep for B4 final fix; regenerate submission.csv\n",
        "import numpy as np, pandas as pd, json, os, time\n",
        "from pathlib import Path\n",
        "\n",
        "def micro_f1_from_probs(probs, targets, thr=0.2):\n",
        "    preds = (probs >= thr).astype(np.uint8); t = targets.astype(np.uint8)\n",
        "    tp = np.logical_and(preds==1, t==1).sum(dtype=np.int64)\n",
        "    fp = np.logical_and(preds==1, t==0).sum(dtype=np.int64)\n",
        "    fn = np.logical_and(preds==0, t==1).sum(dtype=np.int64)\n",
        "    denom = 2*tp + fp + fn\n",
        "    return float((2*tp)/denom) if denom>0 else 0.0\n",
        "\n",
        "labels_df = pd.read_csv('labels.csv')\n",
        "attr_ids = sorted(labels_df['attribute_id'].unique().tolist())\n",
        "attr_to_idx = {a:i for i,a in enumerate(attr_ids)}\n",
        "idx_to_attr = np.array(attr_ids, dtype=np.int32)\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "num_classes = len(attr_ids)\n",
        "y_true = np.zeros((len(train_df), num_classes), dtype=np.uint8)\n",
        "for i, s in enumerate(train_df['attribute_ids'].fillna('').tolist()):\n",
        "    if s:\n",
        "        for a in map(int, s.split()):\n",
        "            j = attr_to_idx.get(a, None)\n",
        "            if j is not None: y_true[i, j] = 1\n",
        "\n",
        "out_dir = Path('out_b4_final_fix')\n",
        "oof = np.load(out_dir/'oof_probs.npy') if (out_dir/'oof_probs.npy').exists() else None\n",
        "test_probs = np.load(out_dir/'test_probs.npy') if (out_dir/'test_probs.npy').exists() else None\n",
        "assert oof is not None and test_probs is not None, 'Missing B4 artifacts'\n",
        "\n",
        "# Mask rows that have predictions (non-zero) in OOF\n",
        "has_pred = (oof.sum(axis=1) > 0)\n",
        "oof_sel = oof[has_pred]\n",
        "y_sel = y_true[has_pred]\n",
        "print(f'OOF selected rows: {has_pred.sum()} / {len(y_true)}', flush=True)\n",
        "\n",
        "thrs = np.arange(0.05, 0.951, 0.005)\n",
        "f1s = [micro_f1_from_probs(oof_sel, y_sel, thr=t) for t in thrs]\n",
        "best_idx = int(np.argmax(f1s)); best_thr = float(thrs[best_idx]); best_f1 = float(f1s[best_idx])\n",
        "print(f'OOF(masked) micro-f1 {best_f1:.5f} @ thr {best_thr:.3f}', flush=True)\n",
        "\n",
        "# Build submission at best_thr\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "ids = sub['id'].values\n",
        "rows = []\n",
        "for i in range(len(ids)):\n",
        "    p = test_probs[i]\n",
        "    pred_idx = np.where(p >= best_thr)[0].tolist()\n",
        "    if len(pred_idx) == 0: pred_idx = [int(np.argmax(p))]\n",
        "    pred_attr = [int(idx_to_attr[j]) for j in sorted(set(pred_idx))]\n",
        "    rows.append({'id': ids[i], 'attribute_ids': ' '.join(str(x) for x in pred_attr)})\n",
        "sub_df = pd.DataFrame(rows)\n",
        "sub_df.to_csv('submission.csv', index=False)\n",
        "print('Rewrote submission.csv using B4 OOF-calibrated threshold.', flush=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF selected rows: 24189 / 120801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF(masked) micro-f1 0.30970 @ thr 0.290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rewrote submission.csv using B4 OOF-calibrated threshold.\n"
          ]
        }
      ]
    },
    {
      "id": "c45fde90-190b-4fb1-82b1-d4135f854c9f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fast blend of available test_probs and write submission.csv with fixed thr\n",
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "dirs = [\n",
        "    'out_b3_384_top512',\n",
        "    'out_b3_448_top512',\n",
        "    'out_b3_384_card',\n",
        "    'out_convnext_tiny_384_top512',\n",
        "    'out_b4_final_fix',\n",
        "]\n",
        "probs_list = []\n",
        "for d in dirs:\n",
        "    p = Path(d)/'test_probs.npy'\n",
        "    if p.exists():\n",
        "        arr = np.load(p)\n",
        "        print(f'Loaded {p} shape={arr.shape}')\n",
        "        probs_list.append(arr)\n",
        "    else:\n",
        "        print(f'Skip missing {p}')\n",
        "assert len(probs_list) >= 2, 'Need at least two sets of test_probs to blend'\n",
        "probs = np.mean(probs_list, axis=0)\n",
        "print('Blended probs shape:', probs.shape, 'range:', float(probs.min()), float(probs.max()))\n",
        "\n",
        "labels_df = pd.read_csv('labels.csv')\n",
        "attr_ids = sorted(labels_df['attribute_id'].unique().tolist())\n",
        "idx_to_attr = np.array(attr_ids, dtype=np.int32)\n",
        "\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "ids = sub['id'].values\n",
        "\n",
        "thr = 0.34  # heuristic threshold for iMet with b3-type models\n",
        "rows = []\n",
        "for i in range(len(ids)):\n",
        "    p = probs[i]\n",
        "    pred_idx = np.where(p >= thr)[0].tolist()\n",
        "    if not pred_idx:\n",
        "        pred_idx = [int(np.argmax(p))]\n",
        "    pred_attr = [int(idx_to_attr[j]) for j in sorted(set(pred_idx))]\n",
        "    rows.append({'id': ids[i], 'attribute_ids': ' '.join(str(x) for x in pred_attr)})\n",
        "sub_df = pd.DataFrame(rows)\n",
        "sub_df.to_csv('submission.csv', index=False)\n",
        "print('Wrote blended submission.csv @ thr', thr)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded out_b3_384_top512/test_probs.npy shape=(21318, 3474)\nLoaded out_b3_448_top512/test_probs.npy shape=(21318, 3474)\nLoaded out_b3_384_card/test_probs.npy shape=(21318, 3474)\nLoaded out_convnext_tiny_384_top512/test_probs.npy shape=(21318, 3474)\nLoaded out_b4_final_fix/test_probs.npy shape=(21318, 3474)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blended probs shape: (21318, 3474) range: 0.0007429550169035792 0.9911518096923828\nWrote blended submission.csv @ thr 0.34\n"
          ]
        }
      ]
    },
    {
      "id": "2572ab8a-5a6d-434a-b4d8-51eef217317e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Last-minute post-process: weighted blend (exclude B4), tiered thresholds, group caps=1, max8, min1\n",
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# 1) Label mapping\n",
        "labels_df = pd.read_csv('labels.csv')\n",
        "attr_ids = sorted(labels_df['attribute_id'].unique().tolist())\n",
        "attr_to_idx = {a:i for i,a in enumerate(attr_ids)}\n",
        "idx_to_attr = np.array(attr_ids, dtype=np.int32)\n",
        "C = len(attr_ids)\n",
        "\n",
        "# 2) Class frequency from train.csv\n",
        "train_df = pd.read_csv('train.csv')\n",
        "counts = np.zeros(C, dtype=np.int32)\n",
        "for s in train_df['attribute_ids'].fillna(''):\n",
        "    if not s: continue\n",
        "    for a in map(int, s.split()):\n",
        "        j = attr_to_idx.get(a, None)\n",
        "        if j is not None: counts[j] += 1\n",
        "\n",
        "# 3) Per-class tier thresholds\n",
        "thr_vec = np.full(C, 0.36, dtype=np.float32)         # mid\n",
        "thr_vec[counts < 200] = 0.30                          # tail\n",
        "thr_vec[counts >= 1200] = 0.44                        # head\n",
        "\n",
        "# 4) Group caps (cap=1 per group)\n",
        "def canon_group(name: str):\n",
        "    n = str(name).lower()\n",
        "    g = n.split('::',1)[0].strip() if '::' in n else n.split(' - ',1)[0].strip()\n",
        "    aliases = {'nationality':'country'}\n",
        "    return aliases.get(g, g)\n",
        "\n",
        "labels_df['__group'] = labels_df['attribute_name'].apply(canon_group)\n",
        "cap1_groups = {'culture','country','region','dynasty','period','century','era','school','people','language','script','religion'}\n",
        "group_masks = {}\n",
        "for g in cap1_groups:\n",
        "    idxs = labels_df.loc[labels_df['__group']==g, 'attribute_id'].map(attr_to_idx).dropna().astype(int).values\n",
        "    if len(idxs)==0: continue\n",
        "    m = np.zeros(C, dtype=bool); m[idxs] = True\n",
        "    group_masks[g] = m\n",
        "group_items = [(g,m) for g,m in group_masks.items()]\n",
        "\n",
        "# 5) Load probs and blend with weights (exclude B4 via weight=0)\n",
        "paths_weights = [\n",
        "    ('out_b3_448_top512/test_probs.npy', 0.32),\n",
        "    ('out_b3_384_top512/test_probs.npy', 0.32),\n",
        "    ('out_b3_384_card/test_probs.npy', 0.22),\n",
        "    ('out_convnext_tiny_384_top512/test_probs.npy', 0.14),\n",
        "    ('out_b4_final_fix/test_probs.npy', 0.00),\n",
        "]\n",
        "probs, wsum = None, 0.0\n",
        "for pth, w in paths_weights:\n",
        "    p = Path(pth)\n",
        "    if not p.exists() or w<=0: continue\n",
        "    arr = np.load(p)\n",
        "    probs = arr*w if probs is None else probs + arr*w\n",
        "    wsum += w\n",
        "assert probs is not None and wsum>0, 'No probs loaded'\n",
        "probs /= wsum\n",
        "N, C2 = probs.shape\n",
        "assert C2==C, 'Class count mismatch'\n",
        "\n",
        "# 6) Post-process per image: thresholds, group caps, max 8, min 1\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "ids = sub['id'].values\n",
        "rows = []\n",
        "max_k = 8\n",
        "\n",
        "for i in range(N):\n",
        "    p = probs[i]\n",
        "    mask = (p >= thr_vec)\n",
        "\n",
        "    # cap=1 within each capped group\n",
        "    for g, gm in group_items:\n",
        "        sel = mask & gm\n",
        "        if sel.sum() > 1:\n",
        "            idxs = np.nonzero(sel)[0]\n",
        "            j_best = idxs[np.argmax(p[idxs])]\n",
        "            mask[idxs] = False\n",
        "            mask[j_best] = True\n",
        "\n",
        "    k = int(mask.sum())\n",
        "    if k == 0:\n",
        "        mask[int(np.argmax(p))] = True\n",
        "        k = 1\n",
        "\n",
        "    if k > max_k:\n",
        "        idxs = np.nonzero(mask)[0]\n",
        "        ord_idx = idxs[np.argsort(-p[idxs])[:max_k]]\n",
        "        new_mask = np.zeros_like(mask); new_mask[ord_idx] = True\n",
        "        mask = new_mask\n",
        "\n",
        "    pred_attr = [int(idx_to_attr[j]) for j in np.nonzero(mask)[0]]\n",
        "    rows.append({'id': ids[i], 'attribute_ids': ' '.join(map(str, pred_attr))})\n",
        "\n",
        "pd.DataFrame(rows).to_csv('submission.csv', index=False)\n",
        "print('submission.csv written: 4-model blend (B4=0), tiered thresholds, group caps=1, max8, min1')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written: 4-model blend (B4=0), tiered thresholds, group caps=1, max8, min1\n"
          ]
        }
      ]
    },
    {
      "id": "2f5f4375-131f-487e-b2d8-1b5780db228a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Variant: same 4-model blend with thresholds shifted +0.02 (head/mid/tail = 0.46/0.38/0.32)\n",
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "labels_df = pd.read_csv('labels.csv')\n",
        "attr_ids = sorted(labels_df['attribute_id'].unique().tolist())\n",
        "attr_to_idx = {a:i for i,a in enumerate(attr_ids)}\n",
        "idx_to_attr = np.array(attr_ids, dtype=np.int32)\n",
        "C = len(attr_ids)\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "counts = np.zeros(C, dtype=np.int32)\n",
        "for s in train_df['attribute_ids'].fillna(''):\n",
        "    if not s: continue\n",
        "    for a in map(int, s.split()):\n",
        "        j = attr_to_idx.get(a, None)\n",
        "        if j is not None: counts[j] += 1\n",
        "\n",
        "# Shifted thresholds\n",
        "thr_vec = np.full(C, 0.38, dtype=np.float32)  # mid +0.02\n",
        "thr_vec[counts < 200] = 0.32                   # tail +0.02\n",
        "thr_vec[counts >= 1200] = 0.46                 # head +0.02\n",
        "\n",
        "def canon_group(name: str):\n",
        "    n = str(name).lower()\n",
        "    g = n.split('::',1)[0].strip() if '::' in n else n.split(' - ',1)[0].strip()\n",
        "    aliases = {'nationality':'country'}\n",
        "    return aliases.get(g, g)\n",
        "\n",
        "labels_df['__group'] = labels_df['attribute_name'].apply(canon_group)\n",
        "cap1_groups = {'culture','country','region','dynasty','period','century','era','school','people','language','script','religion'}\n",
        "group_masks = {}\n",
        "for g in cap1_groups:\n",
        "    idxs = labels_df.loc[labels_df['__group']==g, 'attribute_id'].map(attr_to_idx).dropna().astype(int).values\n",
        "    if len(idxs)==0: continue\n",
        "    m = np.zeros(C, dtype=bool); m[idxs] = True\n",
        "    group_masks[g] = m\n",
        "group_items = [(g,m) for g,m in group_masks.items()]\n",
        "\n",
        "paths_weights = [\n",
        "    ('out_b3_448_top512/test_probs.npy', 0.32),\n",
        "    ('out_b3_384_top512/test_probs.npy', 0.32),\n",
        "    ('out_b3_384_card/test_probs.npy', 0.22),\n",
        "    ('out_convnext_tiny_384_top512/test_probs.npy', 0.14),\n",
        "    ('out_b4_final_fix/test_probs.npy', 0.00),\n",
        "]\n",
        "probs, wsum = None, 0.0\n",
        "for pth, w in paths_weights:\n",
        "    p = Path(pth)\n",
        "    if not p.exists() or w<=0: continue\n",
        "    arr = np.load(p)\n",
        "    probs = arr*w if probs is None else probs + arr*w\n",
        "    wsum += w\n",
        "assert probs is not None and wsum>0, 'No probs loaded'\n",
        "probs /= wsum\n",
        "N, C2 = probs.shape\n",
        "assert C2==C, 'Class count mismatch'\n",
        "\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "ids = sub['id'].values\n",
        "rows = []\n",
        "max_k = 8\n",
        "for i in range(N):\n",
        "    p = probs[i]\n",
        "    mask = (p >= thr_vec)\n",
        "    for g, gm in group_items:\n",
        "        sel = mask & gm\n",
        "        if sel.sum() > 1:\n",
        "            idxs = np.nonzero(sel)[0]\n",
        "            j_best = idxs[np.argmax(p[idxs])]\n",
        "            mask[idxs] = False\n",
        "            mask[j_best] = True\n",
        "    k = int(mask.sum())\n",
        "    if k == 0:\n",
        "        mask[int(np.argmax(p))] = True\n",
        "        k = 1\n",
        "    if k > max_k:\n",
        "        idxs = np.nonzero(mask)[0]\n",
        "        ord_idx = idxs[np.argsort(-p[idxs])[:max_k]]\n",
        "        new_mask = np.zeros_like(mask); new_mask[ord_idx] = True\n",
        "        mask = new_mask\n",
        "    pred_attr = [int(idx_to_attr[j]) for j in np.nonzero(mask)[0]]\n",
        "    rows.append({'id': ids[i], 'attribute_ids': ' '.join(map(str, pred_attr))})\n",
        "pd.DataFrame(rows).to_csv('submission.csv', index=False)\n",
        "print('submission.csv written: thresholds +0.02 shift (0.46/0.38/0.32), group caps=1, max8, min1')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written: thresholds +0.02 shift (0.46/0.38/0.32), group caps=1, max8, min1\n"
          ]
        }
      ]
    },
    {
      "id": "5a98f3f2-b321-42ee-99ab-cff3c3bde183",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Variant: thresholds shifted -0.02 (head/mid/tail = 0.42/0.34/0.28) for potential under-prediction\n",
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "labels_df = pd.read_csv('labels.csv')\n",
        "attr_ids = sorted(labels_df['attribute_id'].unique().tolist())\n",
        "attr_to_idx = {a:i for i,a in enumerate(attr_ids)}\n",
        "idx_to_attr = np.array(attr_ids, dtype=np.int32)\n",
        "C = len(attr_ids)\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "counts = np.zeros(C, dtype=np.int32)\n",
        "for s in train_df['attribute_ids'].fillna(''):\n",
        "    if not s: continue\n",
        "    for a in map(int, s.split()):\n",
        "        j = attr_to_idx.get(a, None)\n",
        "        if j is not None: counts[j] += 1\n",
        "\n",
        "# Shifted thresholds down\n",
        "thr_vec = np.full(C, 0.34, dtype=np.float32)  # mid -0.02\n",
        "thr_vec[counts < 200] = 0.28                   # tail -0.02\n",
        "thr_vec[counts >= 1200] = 0.42                 # head -0.02\n",
        "\n",
        "def canon_group(name: str):\n",
        "    n = str(name).lower()\n",
        "    g = n.split('::',1)[0].strip() if '::' in n else n.split(' - ',1)[0].strip()\n",
        "    aliases = {'nationality':'country'}\n",
        "    return aliases.get(g, g)\n",
        "\n",
        "labels_df['__group'] = labels_df['attribute_name'].apply(canon_group)\n",
        "cap1_groups = {'culture','country','region','dynasty','period','century','era','school','people','language','script','religion'}\n",
        "group_masks = {}\n",
        "for g in cap1_groups:\n",
        "    idxs = labels_df.loc[labels_df['__group']==g, 'attribute_id'].map(attr_to_idx).dropna().astype(int).values\n",
        "    if len(idxs)==0: continue\n",
        "    m = np.zeros(C, dtype=bool); m[idxs] = True\n",
        "    group_masks[g] = m\n",
        "group_items = [(g,m) for g,m in group_masks.items()]\n",
        "\n",
        "paths_weights = [\n",
        "    ('out_b3_448_top512/test_probs.npy', 0.32),\n",
        "    ('out_b3_384_top512/test_probs.npy', 0.32),\n",
        "    ('out_b3_384_card/test_probs.npy', 0.22),\n",
        "    ('out_convnext_tiny_384_top512/test_probs.npy', 0.14),\n",
        "    ('out_b4_final_fix/test_probs.npy', 0.00),\n",
        "]\n",
        "probs, wsum = None, 0.0\n",
        "for pth, w in paths_weights:\n",
        "    p = Path(pth)\n",
        "    if not p.exists() or w<=0: continue\n",
        "    arr = np.load(p)\n",
        "    probs = arr*w if probs is None else probs + arr*w\n",
        "    wsum += w\n",
        "assert probs is not None and wsum>0, 'No probs loaded'\n",
        "probs /= wsum\n",
        "N, C2 = probs.shape\n",
        "assert C2==C, 'Class count mismatch'\n",
        "\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "ids = sub['id'].values\n",
        "rows = []\n",
        "max_k = 8\n",
        "for i in range(N):\n",
        "    p = probs[i]\n",
        "    mask = (p >= thr_vec)\n",
        "    for g, gm in group_items:\n",
        "        sel = mask & gm\n",
        "        if sel.sum() > 1:\n",
        "            idxs = np.nonzero(sel)[0]\n",
        "            j_best = idxs[np.argmax(p[idxs])]\n",
        "            mask[idxs] = False\n",
        "            mask[j_best] = True\n",
        "    k = int(mask.sum())\n",
        "    if k == 0:\n",
        "        mask[int(np.argmax(p))] = True\n",
        "        k = 1\n",
        "    if k > max_k:\n",
        "        idxs = np.nonzero(mask)[0]\n",
        "        ord_idx = idxs[np.argsort(-p[idxs])[:max_k]]\n",
        "        new_mask = np.zeros_like(mask); new_mask[ord_idx] = True\n",
        "        mask = new_mask\n",
        "    pred_attr = [int(idx_to_attr[j]) for j in np.nonzero(mask)[0]]\n",
        "    rows.append({'id': ids[i], 'attribute_ids': ' '.join(map(str, pred_attr))})\n",
        "pd.DataFrame(rows).to_csv('submission.csv', index=False)\n",
        "print('submission.csv written: thresholds -0.02 shift (0.42/0.34/0.28), group caps=1, max8, min1')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written: thresholds -0.02 shift (0.42/0.34/0.28), group caps=1, max8, min1\n"
          ]
        }
      ]
    },
    {
      "id": "3284479f-b74e-40cd-b728-26c0564a863d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Variant: 4-model blend with logit temperature scaling (sharpen) and base thresholds 0.44/0.36/0.30\n",
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Config\n",
        "logit_scale = 1.15  # >1 sharpen, <1 smooth\n",
        "\n",
        "# 1) Label mapping\n",
        "labels_df = pd.read_csv('labels.csv')\n",
        "attr_ids = sorted(labels_df['attribute_id'].unique().tolist())\n",
        "attr_to_idx = {a:i for i,a in enumerate(attr_ids)}\n",
        "idx_to_attr = np.array(attr_ids, dtype=np.int32)\n",
        "C = len(attr_ids)\n",
        "\n",
        "# 2) Class frequency from train.csv\n",
        "train_df = pd.read_csv('train.csv')\n",
        "counts = np.zeros(C, dtype=np.int32)\n",
        "for s in train_df['attribute_ids'].fillna(''):\n",
        "    if not s: continue\n",
        "    for a in map(int, s.split()):\n",
        "        j = attr_to_idx.get(a, None)\n",
        "        if j is not None: counts[j] += 1\n",
        "\n",
        "# 3) Base per-class tier thresholds\n",
        "thr_vec = np.full(C, 0.36, dtype=np.float32)         # mid\n",
        "thr_vec[counts < 200] = 0.30                          # tail\n",
        "thr_vec[counts >= 1200] = 0.44                        # head\n",
        "\n",
        "# 4) Group caps (cap=1 per group)\n",
        "def canon_group(name: str):\n",
        "    n = str(name).lower()\n",
        "    g = n.split('::',1)[0].strip() if '::' in n else n.split(' - ',1)[0].strip()\n",
        "    aliases = {'nationality':'country'}\n",
        "    return aliases.get(g, g)\n",
        "\n",
        "labels_df['__group'] = labels_df['attribute_name'].apply(canon_group)\n",
        "cap1_groups = {'culture','country','region','dynasty','period','century','era','school','people','language','script','religion'}\n",
        "group_masks = {}\n",
        "for g in cap1_groups:\n",
        "    idxs = labels_df.loc[labels_df['__group']==g, 'attribute_id'].map(attr_to_idx).dropna().astype(int).values\n",
        "    if len(idxs)==0: continue\n",
        "    m = np.zeros(C, dtype=bool); m[idxs] = True\n",
        "    group_masks[g] = m\n",
        "group_items = [(g,m) for g,m in group_masks.items()]\n",
        "\n",
        "# 5) Load probs and blend with weights (exclude B4 via weight=0)\n",
        "paths_weights = [\n",
        "    ('out_b3_448_top512/test_probs.npy', 0.32),\n",
        "    ('out_b3_384_top512/test_probs.npy', 0.32),\n",
        "    ('out_b3_384_card/test_probs.npy', 0.22),\n",
        "    ('out_convnext_tiny_384_top512/test_probs.npy', 0.14),\n",
        "    ('out_b4_final_fix/test_probs.npy', 0.00),\n",
        "]\n",
        "probs, wsum = None, 0.0\n",
        "for pth, w in paths_weights:\n",
        "    p = Path(pth)\n",
        "    if not p.exists() or w<=0: continue\n",
        "    arr = np.load(p)\n",
        "    probs = arr*w if probs is None else probs + arr*w\n",
        "    wsum += w\n",
        "assert probs is not None and wsum>0, 'No probs loaded'\n",
        "probs /= wsum\n",
        "N, C2 = probs.shape\n",
        "assert C2==C, 'Class count mismatch'\n",
        "\n",
        "# 6) Logit temperature scaling (sharpen)\n",
        "eps = 1e-6\n",
        "probs = np.clip(probs, eps, 1.0-eps)\n",
        "logits = np.log(probs/(1.0-probs))\n",
        "probs_t = 1.0/(1.0 + np.exp(-logit_scale*logits))\n",
        "\n",
        "# 7) Post-process per image: thresholds, group caps, max 8, min 1\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "ids = sub['id'].values\n",
        "rows = []\n",
        "max_k = 8\n",
        "\n",
        "for i in range(N):\n",
        "    p = probs_t[i]\n",
        "    mask = (p >= thr_vec)\n",
        "\n",
        "    # cap=1 within each capped group\n",
        "    for g, gm in group_items:\n",
        "        sel = mask & gm\n",
        "        if sel.sum() > 1:\n",
        "            idxs = np.nonzero(sel)[0]\n",
        "            j_best = idxs[np.argmax(p[idxs])]\n",
        "            mask[idxs] = False\n",
        "            mask[j_best] = True\n",
        "\n",
        "    k = int(mask.sum())\n",
        "    if k == 0:\n",
        "        mask[int(np.argmax(p))] = True\n",
        "        k = 1\n",
        "\n",
        "    if k > max_k:\n",
        "        idxs = np.nonzero(mask)[0]\n",
        "        ord_idx = idxs[np.argsort(-p[idxs])[:max_k]]\n",
        "        new_mask = np.zeros_like(mask); new_mask[ord_idx] = True\n",
        "        mask = new_mask\n",
        "\n",
        "    pred_attr = [int(idx_to_attr[j]) for j in np.nonzero(mask)[0]]\n",
        "    rows.append({'id': ids[i], 'attribute_ids': ' '.join(map(str, pred_attr))})\n",
        "\n",
        "pd.DataFrame(rows).to_csv('submission.csv', index=False)\n",
        "print(f'submission.csv written: 4-model blend + logit_scale={logit_scale}, base thr tiers 0.44/0.36/0.30, caps=1, max8, min1')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written: 4-model blend + logit_scale=1.15, base thr tiers 0.44/0.36/0.30, caps=1, max8, min1\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}