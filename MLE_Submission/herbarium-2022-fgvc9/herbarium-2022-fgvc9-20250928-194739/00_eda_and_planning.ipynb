{
  "cells": [
    {
      "id": "51819123-4276-48f0-b6c8-21930446d65b",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Herbarium 2022 - FGVC9: Plan and Milestones\n",
        "\n",
        "Objective: WIN A MEDAL (macro F1 on LB).\n",
        "\n",
        "Milestone 0: Environment & Data Sanity\n",
        "- Verify GPU availability (nvidia-smi, torch cuda).\n",
        "- Inspect metadata: train/test sizes, class count (taxonID), label distribution skew, per-institution/site info.\n",
        "- Confirm image paths exist and are readable.\n",
        "\n",
        "Milestone 1: Validation Protocol\n",
        "- Stratified KFold by taxonID (e.g., 5 folds).\n",
        "- Deterministic seed handling, consistent folds cached.\n",
        "- Track macro-F1 OOF (primary) and accuracy.\n",
        "\n",
        "Milestone 2: Fast Baseline\n",
        "- Model: timm pretrained CNN (e.g., convnext_base/large or eva02 base) with mixed precision.\n",
        "- Image size 384 (warm-up at 224 for smoke tests), aug: RandAug/AutoAug + ColorJitter + Mixup/CutMix (light).\n",
        "- Loss: LabelSmoothingCrossEntropy or FocalLoss; try both (OOF-driven).\n",
        "- Optimizer: AdamW; OneCycle or cosine schedule; EMA weights.\n",
        "- Class weights or re-weighting (long tail) vs. sampling; validate.\n",
        "\n",
        "Milestone 3: Speed/Scale-up\n",
        "- Progressive resizing: 224 -> 384 -> 448 if time.\n",
        "- Use fp16, channels_last, torch.compile(optional).\n",
        "- Enable efficient dataloading: prefetch, pin_memory, num_workers, jpeg-turbo if available.\n",
        "\n",
        "Milestone 4: Error Analysis & Iteration\n",
        "- OOF error buckets: by family/genus, institution/source, size, orientation.\n",
        "- Try hierarchical soft targets (family/genus smoothing) if time.\n",
        "- Try stronger backbones (beit/beitv2, convnextv2, efficientnetv2).\n",
        "\n",
        "Milestone 5: Ensembling\n",
        "- Blend diverse seeds/models/resolutions by logits avg.\n",
        "- Calibrate if needed (temperature on OOF).\n",
        "\n",
        "Milestone 6: Submission\n",
        "- Generate test predictions and save submission.csv.\n",
        "- Verify shape and ids align with sample_submission.csv.\n",
        "\n",
        "Checkpoints for Expert Review\n",
        "- After Env+Data sanity (M0).\n",
        "- After baseline OOF ready (M2).\n",
        "- After any major iteration/ensemble (M4/M5).\n",
        "\n",
        "Next Cell (to add):\n",
        "- Environment checks, file listings, metadata inspection, class counts, and quick integrity assertions."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "6beff336-b9d9-43e5-b961-049f883253e2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, json, time, csv, sys, subprocess, itertools\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "t0 = time.time()\n",
        "print('=== GPU CHECK (nvidia-smi) ===', flush=True)\n",
        "subprocess.run(['bash','-lc','nvidia-smi || true'])\n",
        "\n",
        "print('\\n=== FILE LIST ===', flush=True)\n",
        "for p in sorted(os.listdir('.')):\n",
        "    if os.path.isdir(p):\n",
        "        n_dirs = sum(1 for _ in os.scandir(p) if _.is_dir())\n",
        "        n_files = sum(1 for _ in os.scandir(p) if _.is_file())\n",
        "        print(f'{p}/ -> {n_dirs} dirs, {n_files} files')\n",
        "    else:\n",
        "        print(p, os.path.getsize(p))\n",
        "\n",
        "def load_json(path):\n",
        "    with open(path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "print('\\n=== LOAD METADATA ===', flush=True)\n",
        "train_meta = load_json('train_metadata.json')\n",
        "test_meta = load_json('test_metadata.json')\n",
        "print('train type:', type(train_meta))\n",
        "if isinstance(train_meta, dict):\n",
        "    print('train keys:', list(train_meta.keys())[:10])\n",
        "else:\n",
        "    print('train len:', len(train_meta))\n",
        "print('test type:', type(test_meta))\n",
        "if isinstance(test_meta, dict):\n",
        "    print('test keys:', list(test_meta.keys())[:10])\n",
        "elif isinstance(test_meta, list):\n",
        "    print('test len:', len(test_meta))\n",
        "\n",
        "# Infer structures\n",
        "def info_dataset(meta, name):\n",
        "    if isinstance(meta, dict):\n",
        "        imgs = meta.get('images') or meta.get('data') or meta.get('items')\n",
        "        ann = meta.get('annotations')\n",
        "        cat = meta.get('categories')\n",
        "        if imgs is not None:\n",
        "            print(f'{name}: images={len(imgs)}')\n",
        "        else:\n",
        "            print(f'{name}: images UNKNOWN (no key)')\n",
        "        if ann is not None:\n",
        "            print(f'{name}: annotations={len(ann)}')\n",
        "        if cat is not None:\n",
        "            print(f'{name}: categories={len(cat)}')\n",
        "        return imgs, ann, cat\n",
        "    elif isinstance(meta, list):\n",
        "        print(f'{name}: list length={len(meta)}')\n",
        "        return meta, None, None\n",
        "    else:\n",
        "        print(f'{name}: type={type(meta)}')\n",
        "        return None, None, None\n",
        "\n",
        "train_imgs, train_ann, train_cat = info_dataset(train_meta, 'train')\n",
        "test_imgs, test_ann, test_cat = info_dataset(test_meta, 'test')\n",
        "\n",
        "# Peek at a few samples\n",
        "def peek(lst, n=2):\n",
        "    if not lst: return\n",
        "    for i, it in enumerate(itertools.islice(lst, n)):\n",
        "        if isinstance(it, dict):\n",
        "            print(f'sample[{i}] keys:', list(it.keys())[:20])\n",
        "        else:\n",
        "            print(f'sample[{i}] type:', type(it))\n",
        "\n",
        "print('\\ntrain images peek:')\n",
        "peek(train_imgs, 3)\n",
        "print('train annotations peek:')\n",
        "peek(train_ann, 3)\n",
        "print('train categories peek:')\n",
        "peek(train_cat, 3)\n",
        "print('test images/items peek:')\n",
        "peek(test_imgs, 3)\n",
        "\n",
        "# Try to locate labels and ids\n",
        "def guess_label_key(sample):\n",
        "    for k in ('taxonID','category_id','label','target','y','class_id','category'):\n",
        "        if k in sample:\n",
        "            return k\n",
        "    return None\n",
        "\n",
        "train_label_key = None\n",
        "train_id_key = None\n",
        "train_fname_key = None\n",
        "if train_imgs and isinstance(train_imgs, list) and len(train_imgs)>0 and isinstance(train_imgs[0], dict):\n",
        "    sample = train_imgs[0]\n",
        "    for k in ('image_id','id','_id','uid','record_id'):\n",
        "        if k in sample: train_id_key = k; break\n",
        "    for k in ('file_name','file','filepath','path','image_path','name'):\n",
        "        if k in sample: train_fname_key = k; break\n",
        "if train_ann and len(train_ann)>0 and isinstance(train_ann[0], dict):\n",
        "    train_label_key = guess_label_key(train_ann[0])\n",
        "elif train_imgs and len(train_imgs)>0 and isinstance(train_imgs[0], dict):\n",
        "    train_label_key = guess_label_key(train_imgs[0])\n",
        "\n",
        "print('train_id_key:', train_id_key, 'train_label_key:', train_label_key, 'train_fname_key:', train_fname_key)\n",
        "\n",
        "test_id_key = None\n",
        "test_fname_key = None\n",
        "if test_imgs and len(test_imgs)>0 and isinstance(test_imgs[0], dict):\n",
        "    for k in ('image_id','id','_id','uid','record_id'):\n",
        "        if k in test_imgs[0]: test_id_key = k; break\n",
        "    for k in ('file_name','file','filepath','path','image_path','name'):\n",
        "        if k in test_imgs[0]: test_fname_key = k; break\n",
        "print('test_id_key:', test_id_key, 'test_fname_key:', test_fname_key)\n",
        "\n",
        "# Class counts if possible\n",
        "cnt = None\n",
        "if train_ann and train_label_key:\n",
        "    cnt = Counter(a[train_label_key] for a in train_ann if train_label_key in a)\n",
        "    print('num classes from annotations:', len(cnt))\n",
        "    print('top5 classes by freq:', cnt.most_common(5))\n",
        "elif train_imgs and train_label_key:\n",
        "    cnt = Counter(i[train_label_key] for i in train_imgs if train_label_key in i)\n",
        "    print('num classes from images:', len(cnt))\n",
        "    print('top5 classes by freq:', cnt.most_common(5))\n",
        "\n",
        "print('\\n=== SAMPLE SUBMISSION ===', flush=True)\n",
        "with open('sample_submission.csv','r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "    rows = [next(reader) for _ in range(5)]\n",
        "print('header:', header)\n",
        "print('first rows:', rows)\n",
        "\n",
        "# Sanity: image paths exist? (we only check directory structure)\n",
        "def count_leaf_files(root):\n",
        "    total = 0\n",
        "    for dp, dn, fn in os.walk(root):\n",
        "        total += len(fn)\n",
        "    return total\n",
        "n_train_files = count_leaf_files('train_images') if os.path.exists('train_images') else -1\n",
        "n_test_files  = count_leaf_files('test_images') if os.path.exists('test_images') else -1\n",
        "print(f'train_images file count (recursive): {n_train_files}')\n",
        "print(f'test_images file count  (recursive): {n_test_files}')\n",
        "\n",
        "print('\\nDone. Elapsed: %.2fs' % (time.time()-t0), flush=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GPU CHECK (nvidia-smi) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 28 21:49:22 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     414MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n=== FILE LIST ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".00_eda_and_planning_kernel_state.json 183\n00_eda_and_planning.ipynb 54597\nagent_metadata/ -> 3 dirs, 9 files\ncheckpoints/ -> 0 dirs, 0 files\nconstraints.txt 51\ndescription.md 9057\ndocker_run.log 404262\nembeddings/ -> 0 dirs, 6 files\nrequirements.txt 2684\nsample_submission.csv 1629423\nsubmission.csv 2043720\ntask.txt 2372\ntest_images/ -> 175 dirs, 0 files\ntest_metadata.json 18686508\ntrain_images/ -> 156 dirs, 0 files\ntrain_metadata.json 590741595\n\n=== LOAD METADATA ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train type: <class 'dict'>\ntrain keys: ['annotations', 'categories', 'distances', 'genera', 'images', 'institutions', 'license']\ntest type: <class 'list'>\ntest len: 174052\ntrain: images=665720\ntrain: annotations=665720\ntrain: categories=15501\ntest: list length=174052\n\ntrain images peek:\nsample[0] keys: ['file_name', 'image_id', 'license']\nsample[1] keys: ['file_name', 'image_id', 'license']\nsample[2] keys: ['file_name', 'image_id', 'license']\ntrain annotations peek:\nsample[0] keys: ['category_id', 'genus_id', 'image_id', 'institution_id']\nsample[1] keys: ['category_id', 'genus_id', 'image_id', 'institution_id']\nsample[2] keys: ['category_id', 'genus_id', 'image_id', 'institution_id']\ntrain categories peek:\nsample[0] keys: ['authors', 'category_id', 'family', 'genus', 'scientificName', 'species']\nsample[1] keys: ['authors', 'category_id', 'family', 'genus', 'scientificName', 'species']\nsample[2] keys: ['authors', 'category_id', 'family', 'genus', 'scientificName', 'species']\ntest images/items peek:\nsample[0] keys: ['file_name', 'image_id', 'license']\nsample[1] keys: ['file_name', 'image_id', 'license']\nsample[2] keys: ['file_name', 'image_id', 'license']\ntrain_id_key: image_id train_label_key: category_id train_fname_key: file_name\ntest_id_key: image_id test_fname_key: file_name\nnum classes from annotations: 15501\ntop5 classes by freq: [(19, 64), (123, 64), (207, 64), (230, 64), (231, 64)]\n\n=== SAMPLE SUBMISSION ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "header: ['Id', 'Predicted']\nfirst rows: [['0', '42'], ['1', '42'], ['2', '42'], ['3', '42'], ['4', '42']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images file count (recursive): 665720\ntest_images file count  (recursive): 174052\n\nDone. Elapsed: 3.30s\n"
          ]
        }
      ]
    },
    {
      "id": "966f1470-1c65-4792-bdf2-167dda1ab578",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, subprocess, shutil, time\n",
        "t0=time.time()\n",
        "print('== Reset any prior torch stack ==', flush=True)\n",
        "for pkg in (\"torch\",\"torchvision\",\"torchaudio\"):\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg], check=False)\n",
        "\n",
        "for d in (\n",
        "    \"/app/.pip-target/torch\",\n",
        "    \"/app/.pip-target/torchvision\",\n",
        "    \"/app/.pip-target/torchaudio\",\n",
        "    \"/app/.pip-target/torch-2.4.1.dist-info\",\n",
        "    \"/app/.pip-target/torchvision-0.19.1.dist-info\",\n",
        "    \"/app/.pip-target/torchaudio-2.4.1.dist-info\",\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d); shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "def pip(*args):\n",
        "    print('> pip', ' '.join(args), flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "print('== Install PyTorch cu121 stack ==', flush=True)\n",
        "pip('install',\n",
        "    '--index-url','https://download.pytorch.org/whl/cu121',\n",
        "    '--extra-index-url','https://pypi.org/simple',\n",
        "    'torch==2.4.1','torchvision==0.19.1','torchaudio==2.4.1')\n",
        "\n",
        "open('constraints.txt','w').write('torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n')\n",
        "print('== Install non-torch deps under constraints ==', flush=True)\n",
        "pip('install','-c','constraints.txt',\n",
        "    'timm==1.0.9',\n",
        "    'open_clip_torch==2.24.0',\n",
        "    'faiss-cpu==1.8.0',\n",
        "    'pandas', 'numpy', 'scikit-learn', 'Pillow', 'tqdm',\n",
        "    '--upgrade-strategy','only-if-needed')\n",
        "\n",
        "import torch\n",
        "print('torch:', torch.__version__, 'cuda build:', getattr(torch.version,'cuda',None))\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f'Wrong CUDA build: {torch.version.cuda}'\n",
        "assert torch.cuda.is_available(), 'CUDA not available'\n",
        "print('GPU:', torch.cuda.get_device_name(0))\n",
        "print('Done installs in %.1fs' % (time.time()-t0), flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b01c01d8-4260-46db-b70b-c997133b04ff",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, json, time, math, sys, gc, hashlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import open_clip\n",
        "from tqdm import tqdm\n",
        "\n",
        "print('== Build train/test tables ==', flush=True)\n",
        "with open('train_metadata.json','r') as f:\n",
        "    tmeta = json.load(f)\n",
        "train_imgs = tmeta['images']\n",
        "train_anns = tmeta['annotations']\n",
        "img_by_id = {x['image_id']: x for x in train_imgs}\n",
        "\n",
        "rows = []\n",
        "for a in train_anns:\n",
        "    iid = a['image_id']\n",
        "    r = img_by_id[iid]\n",
        "    rows.append((iid, r['file_name'], a['category_id']))\n",
        "train_df = pd.DataFrame(rows, columns=['image_id','file_name','category_id'])\n",
        "train_df['path'] = 'train_images/' + train_df['file_name'].astype(str)\n",
        "print('train_df:', train_df.shape, 'unique classes:', train_df['category_id'].nunique())\n",
        "\n",
        "with open('test_metadata.json','r') as f:\n",
        "    test_meta = json.load(f)\n",
        "test_df = pd.DataFrame(test_meta)\n",
        "test_df = test_df[['image_id','file_name']].copy()\n",
        "test_df['path'] = 'test_images/' + test_df['file_name'].astype(str)\n",
        "print('test_df:', test_df.shape)\n",
        "\n",
        "# Build class frequency and maps\n",
        "cls_counts = train_df['category_id'].value_counts().sort_index()\n",
        "cat_ids = cls_counts.index.to_list()\n",
        "cat_id2idx = {cid:i for i,cid in enumerate(cat_ids)}\n",
        "idx2cat_id = {i:cid for cid,i in cat_id2idx.items()}\n",
        "train_df['y'] = train_df['category_id'].map(cat_id2idx).astype(int)\n",
        "num_classes = len(cat_ids)\n",
        "print('num_classes:', num_classes)\n",
        "\n",
        "os.makedirs('embeddings', exist_ok=True)\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, preprocess):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.preprocess = preprocess\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        p = self.df.at[i, 'path']\n",
        "        try:\n",
        "            img = Image.open(p).convert('RGB')\n",
        "        except Exception as e:\n",
        "            # fallback 1x1 black image on failure\n",
        "            img = Image.new('RGB', (224,224), (0,0,0))\n",
        "        return self.preprocess(img), i\n",
        "\n",
        "def extract_embeddings(df, model_name='ViT-B-32', pretrained='laion2b_s34b_b79k', bs=256, num_workers=8, out_path='embeddings/train_vitb32.npy'):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f'Loading open_clip model {model_name} / {pretrained}', flush=True)\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms(model_name, pretrained=pretrained, device=device)\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    ds = ImageDataset(df, preprocess)\n",
        "    dl = DataLoader(ds, batch_size=bs, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
        "    n = len(ds)\n",
        "    with torch.no_grad():\n",
        "        # probe dim\n",
        "        x0, _ = next(iter(dl))\n",
        "        x0 = x0.to(device, non_blocking=True)\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
        "            f0 = model.encode_image(x0)\n",
        "        d = f0.shape[-1]\n",
        "    feats = np.memmap(out_path + '.mmap', dtype='float32', mode='w+', shape=(n, d))\n",
        "    t0 = time.time()\n",
        "    seen = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, idx in tqdm(dl, total=math.ceil(n/bs), desc='emb', mininterval=2.0):\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
        "                fb = model.encode_image(xb)\n",
        "            fb = fb.float()\n",
        "            fb = torch.nn.functional.normalize(fb, p=2, dim=-1)\n",
        "            fb = fb.cpu().numpy()\n",
        "            feats[idx.numpy()] = fb\n",
        "            seen += xb.size(0)\n",
        "            if seen % (bs*10) == 0:\n",
        "                print(f'  wrote {seen}/{n}', flush=True)\n",
        "    feats.flush()\n",
        "    np.save(out_path, np.asarray(feats))\n",
        "    del feats\n",
        "    try: os.remove(out_path + '.mmap')\n",
        "    except: pass\n",
        "    print('Saved', out_path, 'elapsed %.1fs' % (time.time()-t0))\n",
        "\n",
        "def run_retrieval_kNN(train_emb_path, test_emb_path, k=50, out_csv='submission.csv'):\n",
        "    import faiss\n",
        "    print('Loading embeddings...', flush=True)\n",
        "    e_tr = np.load(train_emb_path).astype('float32')\n",
        "    e_te = np.load(test_emb_path).astype('float32')\n",
        "    # e_* already L2-normalized\n",
        "    print('train emb:', e_tr.shape, 'test emb:', e_te.shape)\n",
        "    index = faiss.IndexFlatIP(e_tr.shape[1])\n",
        "    index.add(e_tr)\n",
        "    print('Searching kNN...', flush=True)\n",
        "    sims, idxs = index.search(e_te, k)\n",
        "    # Map neighbor indices to labels\n",
        "    y_tr = train_df['y'].to_numpy()\n",
        "    # vote with similarity weights\n",
        "    num_classes = y_tr.max()+1\n",
        "    preds = np.empty((e_te.shape[0],), dtype=np.int32)\n",
        "    for i in tqdm(range(e_te.shape[0]), desc='vote', mininterval=2.0):\n",
        "        ids = idxs[i]\n",
        "        ws = sims[i]\n",
        "        labs = y_tr[ids]\n",
        "        # accumulate per-class score\n",
        "        scores = {}\n",
        "        for lab, w in zip(labs, ws):\n",
        "            scores[lab] = scores.get(lab, 0.0) + float(max(w, 0.0))\n",
        "        # pick argmax\n",
        "        if scores:\n",
        "            preds[i] = max(scores.items(), key=lambda x:x[1])[0]\n",
        "        else:\n",
        "            preds[i] = labs[0]\n",
        "    # map back to category_id\n",
        "    pred_cat = [idx2cat_id[int(p)] for p in preds]\n",
        "    # order by sample_submission Id (which uses sequential 0..N-1 mapping to test image_id order)\n",
        "    # sample_submission Id corresponds to row index in test_meta order\n",
        "    sub = pd.DataFrame({'Id': np.arange(len(test_df), dtype=np.int32), 'Predicted': pred_cat})\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv)\n",
        "\n",
        "print('== Retrieval baseline plan ready ==')\n",
        "print('Next steps:')\n",
        "print('1) extract_embeddings(train_df, model_name=\\'ViT-B-32\\', pretrained=\\'laion2b_s34b_b79k\\', bs=256, out_path=\\'embeddings/train_vitb32.npy\\')')\n",
        "print('2) extract_embeddings(test_df,  model_name=\\'ViT-B-32\\', pretrained=\\'laion2b_s34b_b79k\\', bs=256, out_path=\\'embeddings/test_vitb32.npy\\')')\n",
        "print('3) run_retrieval_kNN(\\'embeddings/train_vitb32.npy\\', \\'embeddings/test_vitb32.npy\\', k=50, out_csv=\\'submission.csv\\')')\n",
        "print('Smoke test first on a small subset before full run (e.g., head 20000).')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Build train/test tables ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df: (665720, 4) unique classes: 15501\ntest_df: (174052, 3)\nnum_classes: 15501\n== Retrieval baseline plan ready ==\nNext steps:\n1) extract_embeddings(train_df, model_name='ViT-B-32', pretrained='laion2b_s34b_b79k', bs=256, out_path='embeddings/train_vitb32.npy')\n2) extract_embeddings(test_df,  model_name='ViT-B-32', pretrained='laion2b_s34b_b79k', bs=256, out_path='embeddings/test_vitb32.npy')\n3) run_retrieval_kNN('embeddings/train_vitb32.npy', 'embeddings/test_vitb32.npy', k=50, out_csv='submission.csv')\nSmoke test first on a small subset before full run (e.g., head 20000).\n"
          ]
        }
      ]
    },
    {
      "id": "77bd21a8-b6c5-47eb-8dbf-19be793710cc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Smoke test: small subset embeddings and kNN vote\n",
        "import time, numpy as np, pandas as pd, os\n",
        "\n",
        "t0 = time.time()\n",
        "train_n = 5000\n",
        "test_n = 2000\n",
        "train_sub = train_df.head(train_n).copy()\n",
        "test_sub  = test_df.head(test_n).copy()\n",
        "print(f'Smoke subset sizes -> train: {len(train_sub)}, test: {len(test_sub)}', flush=True)\n",
        "\n",
        "os.makedirs('embeddings', exist_ok=True)\n",
        "tr_out = 'embeddings/train_vitb32_smoke.npy'\n",
        "te_out = 'embeddings/test_vitb32_smoke.npy'\n",
        "\n",
        "extract_embeddings(train_sub, model_name='ViT-B-32', pretrained='laion2b_s34b_b79k', bs=256, num_workers=8, out_path=tr_out)\n",
        "extract_embeddings(test_sub,  model_name='ViT-B-32', pretrained='laion2b_s34b_b79k', bs=256, num_workers=8, out_path=te_out)\n",
        "\n",
        "print('Embeddings saved (smoke). Loading back to verify...', flush=True)\n",
        "etr = np.load(tr_out)\n",
        "ete = np.load(te_out)\n",
        "print('Shapes -> train:', etr.shape, 'test:', ete.shape)\n",
        "\n",
        "# kNN on smoke to validate pipeline (no submission write for full test yet)\n",
        "def run_knn_smoke():\n",
        "    import faiss, numpy as np\n",
        "    idx = faiss.IndexFlatIP(etr.shape[1])\n",
        "    idx.add(etr.astype('float32'))\n",
        "    sims, inds = idx.search(ete.astype('float32'), 20)\n",
        "    y_tr = train_sub['y'].to_numpy()\n",
        "    preds = np.empty((ete.shape[0],), dtype=np.int32)\n",
        "    for i in range(ete.shape[0]):\n",
        "        labs = y_tr[inds[i]]\n",
        "        ws = sims[i]\n",
        "        scores = {}\n",
        "        for lab, w in zip(labs, ws):\n",
        "            if w > 0:\n",
        "                scores[lab] = scores.get(lab, 0.0) + float(w)\n",
        "        preds[i] = max(scores.items(), key=lambda x:x[1])[0] if scores else labs[0]\n",
        "    print('kNN smoke preds sample:', preds[:10])\n",
        "run_knn_smoke()\n",
        "\n",
        "print('Smoke test done. Elapsed: %.1fs' % (time.time()-t0))\n",
        "print('Next: run full extraction and kNN to produce submission.csv.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "117455a9-1591-453d-b5df-324484ba8236",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Full extraction and kNN submission\n",
        "import time, numpy as np\n",
        "\n",
        "t0 = time.time()\n",
        "train_out = 'embeddings/train_vitb32.npy'\n",
        "test_out  = 'embeddings/test_vitb32.npy'\n",
        "print('Starting full embedding extraction with OpenCLIP ViT-B/32...', flush=True)\n",
        "extract_embeddings(train_df, model_name='ViT-B-32', pretrained='laion2b_s34b_b79k', bs=256, num_workers=12, out_path=train_out)\n",
        "extract_embeddings(test_df,  model_name='ViT-B-32', pretrained='laion2b_s34b_b79k', bs=256, num_workers=12, out_path=test_out)\n",
        "print('Embeddings ready. Now running kNN and writing submission.csv ...', flush=True)\n",
        "run_retrieval_kNN(train_out, test_out, k=50, out_csv='submission.csv')\n",
        "print('All done in %.1f minutes' % ((time.time()-t0)/60.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7696939f-c485-4712-8516-2d82c48c64ea",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Prototype cosine classifier with class-prior debiasing (GPU, chunked)\n",
        "import time, numpy as np, pandas as pd, torch\n",
        "\n",
        "t0 = time.time()\n",
        "train_emb_path = 'embeddings/train_vitb32.npy'\n",
        "test_emb_path  = 'embeddings/test_vitb32.npy'\n",
        "print('Loading embeddings...', flush=True)\n",
        "E_tr = np.load(train_emb_path).astype('float32')  # (Ntr, D) L2-normalized\n",
        "E_te = np.load(test_emb_path).astype('float32')   # (Nte, D) L2-normalized\n",
        "print('Shapes:', E_tr.shape, E_te.shape, flush=True)\n",
        "\n",
        "# Build class prototypes (mean of normalized train embeddings per class)\n",
        "y_tr = train_df['y'].to_numpy()\n",
        "num_classes = y_tr.max() + 1\n",
        "D = E_tr.shape[1]\n",
        "P_sum = np.zeros((num_classes, D), dtype=np.float32)\n",
        "cnt = np.zeros((num_classes,), dtype=np.int64)\n",
        "for c in range(num_classes):\n",
        "    # slice indices per class in chunks to save RAM on boolean masks\n",
        "    idx = np.where(y_tr == c)[0]\n",
        "    if idx.size == 0:\n",
        "        continue\n",
        "    P_sum[c] = E_tr[idx].mean(axis=0)\n",
        "    cnt[c] = idx.size\n",
        "print('Prototype counts built. Non-empty classes:', int((cnt>0).sum()), flush=True)\n",
        "# L2-normalize prototypes\n",
        "P = P_sum / (np.linalg.norm(P_sum, axis=1, keepdims=True) + 1e-12)\n",
        "del P_sum\n",
        "\n",
        "# Class-prior debiasing: subtract alpha * log(pi_c) from logits\n",
        "alpha = 0.5\n",
        "pi = cnt / cnt.sum()\n",
        "log_pi = np.log(pi + 1e-12).astype('float32')\n",
        "\n",
        "# Move prototypes to GPU (fp16 for speed/memory)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "P_t = torch.from_numpy(P).to(device=device, dtype=torch.float16)\n",
        "log_pi_t = torch.from_numpy(log_pi).to(device=device, dtype=torch.float16)\n",
        "del P\n",
        "torch.cuda.empty_cache() if device=='cuda' else None\n",
        "\n",
        "# Chunked inference: logits = E_te_chunk @ P^T (cosine since both L2-normalized)\n",
        "bs = 4096\n",
        "Nte = E_te.shape[0]\n",
        "pred_idx = np.empty((Nte,), dtype=np.int32)\n",
        "start = 0\n",
        "loop_t0 = time.time()\n",
        "while start < Nte:\n",
        "    end = min(start + bs, Nte)\n",
        "    X = torch.from_numpy(E_te[start:end]).to(device=device, dtype=torch.float16, non_blocking=True)\n",
        "    # mm: (B,D) x (D,C)^T -> (B,C)\n",
        "    logits = X @ P_t.T  # cosine similarity\n",
        "    # debias\n",
        "    logits = logits - alpha * log_pi_t\n",
        "    # argmax per row\n",
        "    top1 = torch.argmax(logits, dim=1).to('cpu').numpy().astype(np.int32)\n",
        "    pred_idx[start:end] = top1\n",
        "    start = end\n",
        "    if (start // bs) % 10 == 0:\n",
        "        print(f'Processed {start}/{Nte} (elapsed {time.time()-loop_t0:.1f}s)', flush=True)\n",
        "del P_t, log_pi_t\n",
        "torch.cuda.empty_cache() if device=='cuda' else None\n",
        "\n",
        "# Map back to original category_id and write submission in test order\n",
        "pred_cat = [idx2cat_id[int(i)] for i in pred_idx]\n",
        "sub = pd.DataFrame({ 'Id': np.arange(len(test_df), dtype=np.int32), 'Predicted': pred_cat })\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv')\n",
        "print('Total elapsed: %.1f s' % (time.time()-t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "6a9a9e2d-6fb5-46a4-928f-d7efcee02a35",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Re-extract OpenCLIP embeddings with 2x TTA (orig + hflip), average and L2-normalize\n",
        "import time, math, numpy as np, torch, json\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, ImageOps, ImageFile\n",
        "import open_clip\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "class TTADataset(Dataset):\n",
        "    def __init__(self, df, preprocess):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.preprocess = preprocess\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        p = self.df.at[i, 'path']\n",
        "        try:\n",
        "            img = Image.open(p).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.new('RGB', (224,224), (0,0,0))\n",
        "        img_flip = ImageOps.mirror(img)\n",
        "        return self.preprocess(img), self.preprocess(img_flip), i\n",
        "\n",
        "def extract_embeddings_tta2(df, model_name='ViT-B-32', pretrained='laion2b_s34b_b79k', bs=256, num_workers=12, out_path='embeddings/train_vitb32_tta2.npy'):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f'Loading open_clip model {model_name} / {pretrained}', flush=True)\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms(model_name, pretrained=pretrained, device=device)\n",
        "    model.eval(); model = model.to(device)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    ds = TTADataset(df, preprocess)\n",
        "    dl = DataLoader(ds, batch_size=bs, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
        "    n = len(ds)\n",
        "    # probe dim\n",
        "    with torch.no_grad():\n",
        "        (x0a, x0b, _) = next(iter(dl))\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
        "            d = model.encode_image(x0a.to(device)).shape[-1]\n",
        "    feats = np.memmap(out_path + '.mmap', dtype='float32', mode='w+', shape=(n, d))\n",
        "    t0 = time.time(); seen = 0\n",
        "    with torch.no_grad():\n",
        "        for xa, xb, idx in DataLoader(ds, batch_size=bs, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True):\n",
        "            xa = xa.to(device, non_blocking=True); xb = xb.to(device, non_blocking=True)\n",
        "            with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
        "                fa = model.encode_image(xa)\n",
        "                fb = model.encode_image(xb)\n",
        "            fa = torch.nn.functional.normalize(fa.float(), p=2, dim=-1)\n",
        "            fb = torch.nn.functional.normalize(fb.float(), p=2, dim=-1)\n",
        "            f = (fa + fb) * 0.5\n",
        "            f = torch.nn.functional.normalize(f, p=2, dim=-1).cpu().numpy()\n",
        "            feats[idx.numpy()] = f\n",
        "            seen += xa.size(0)\n",
        "            if seen % (bs*10) == 0: print(f'  wrote {seen}/{n}', flush=True)\n",
        "    feats.flush(); np.save(out_path, np.asarray(feats)); del feats\n",
        "    try: import os; os.remove(out_path + '.mmap')\n",
        "    except: pass\n",
        "    print('Saved', out_path, 'elapsed %.1fs' % (time.time()-t0))\n",
        "\n",
        "print('Starting 2x TTA extraction for train/test (ViT-B/32)...', flush=True)\n",
        "t0 = time.time()\n",
        "extract_embeddings_tta2(train_df, out_path='embeddings/train_vitb32_tta2.npy')\n",
        "extract_embeddings_tta2(test_df,  out_path='embeddings/test_vitb32_tta2.npy')\n",
        "print('TTA embeddings done in %.1f min' % ((time.time()-t0)/60.0), flush=True)\n",
        "\n",
        "# Run prototype cosine with debias on TTA features\n",
        "import pandas as pd\n",
        "E_tr = np.load('embeddings/train_vitb32_tta2.npy').astype('float32')\n",
        "E_te = np.load('embeddings/test_vitb32_tta2.npy').astype('float32')\n",
        "y_tr = train_df['y'].to_numpy()\n",
        "num_classes = y_tr.max()+1; D = E_tr.shape[1]\n",
        "P_sum = np.zeros((num_classes, D), dtype=np.float32); cnt = np.zeros((num_classes,), dtype=np.int64)\n",
        "for c in range(num_classes):\n",
        "    idx = np.where(y_tr==c)[0]\n",
        "    if idx.size: P_sum[c] = E_tr[idx].mean(axis=0); cnt[c]=idx.size\n",
        "P = P_sum / (np.linalg.norm(P_sum, axis=1, keepdims=True) + 1e-12); del P_sum\n",
        "alpha = 0.5\n",
        "log_pi = np.log((cnt / cnt.sum()) + 1e-12).astype('float32')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "P_t = torch.from_numpy(P).to(device=device, dtype=torch.float16); del P\n",
        "log_pi_t = torch.from_numpy(log_pi).to(device=device, dtype=torch.float16)\n",
        "bs = 4096; Nte = E_te.shape[0]; pred_idx = np.empty((Nte,), dtype=np.int32)\n",
        "s=0; t1=time.time()\n",
        "while s < Nte:\n",
        "    e = min(s+bs, Nte)\n",
        "    X = torch.from_numpy(E_te[s:e]).to(device=device, dtype=torch.float16, non_blocking=True)\n",
        "    logits = X @ P_t.T\n",
        "    logits = logits - alpha * log_pi_t\n",
        "    pred_idx[s:e] = torch.argmax(logits, dim=1).to('cpu').numpy().astype(np.int32)\n",
        "    s = e\n",
        "    if (s//bs)%10==0: print(f'TTA infer {s}/{Nte} (elapsed {time.time()-t1:.1f}s)', flush=True)\n",
        "del P_t, log_pi_t; torch.cuda.empty_cache() if device=='cuda' else None\n",
        "pred_cat = [idx2cat_id[int(i)] for i in pred_idx]\n",
        "sub = pd.DataFrame({'Id': np.arange(len(test_df), dtype=np.int32), 'Predicted': pred_cat})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('submission.csv written (TTA prototypes)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "79c42f67-a933-40a9-9214-ed30705993a5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Linear probe on CLIP embeddings + prototype blend (fast, GPU, chunked)\n",
        "import os, time, math, numpy as np, pandas as pd, torch, torch.nn as nn\n",
        "\n",
        "def pick_emb(path_tta, path_base):\n",
        "    return path_tta if os.path.exists(path_tta) else path_base\n",
        "\n",
        "train_emb_path = pick_emb('embeddings/train_vitb32_tta2.npy','embeddings/train_vitb32.npy')\n",
        "test_emb_path  = pick_emb('embeddings/test_vitb32_tta2.npy', 'embeddings/test_vitb32.npy')\n",
        "print('Using embeddings:', train_emb_path, ' / ', test_emb_path, flush=True)\n",
        "\n",
        "# Load features\n",
        "E_tr = np.load(train_emb_path).astype('float32')\n",
        "E_te = np.load(test_emb_path).astype('float32')\n",
        "y_tr = train_df['y'].to_numpy()\n",
        "num_classes = int(y_tr.max()+1); D = E_tr.shape[1]\n",
        "print('Train feats:', E_tr.shape, 'Test feats:', E_te.shape, 'Classes:', num_classes, flush=True)\n",
        "\n",
        "# Class weights (inverse sqrt freq)\n",
        "freq = np.bincount(y_tr, minlength=num_classes).astype(np.float32)\n",
        "w = 1.0 / np.sqrt(freq + 1e-8)\n",
        "w = (w * (num_classes / w.sum())).astype('float32')\n",
        "\n",
        "# Dataset and loader over numpy arrays\n",
        "class FeatDS(torch.utils.data.Dataset):\n",
        "    def __init__(self, feats, labels):\n",
        "        self.X = feats; self.y = labels\n",
        "    def __len__(self): return self.X.shape[0]\n",
        "    def __getitem__(self, i):\n",
        "        return self.X[i], self.y[i]\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "train_ds = FeatDS(E_tr, y_tr.astype(np.int64))\n",
        "bs = 16384\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "# Model: linear classifier\n",
        "model = nn.Linear(D, num_classes, bias=True).to(device)\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.0)\n",
        "crit = nn.CrossEntropyLoss(weight=torch.from_numpy(w).to(device))\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
        "epochs = 2\n",
        "t0 = time.time()\n",
        "for ep in range(1, epochs+1):\n",
        "    model.train()\n",
        "    run_loss = 0.0; n_seen = 0\n",
        "    ep_t0 = time.time()\n",
        "    for xb, yb in train_dl:\n",
        "        xb = xb.to(device=device, dtype=torch.float16, non_blocking=True)\n",
        "        yb = yb.to(device=device, non_blocking=True)\n",
        "        optim.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(dtype=torch.float16, enabled=(device=='cuda')):\n",
        "            logits = model(xb)\n",
        "            loss = crit(logits, yb)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optim); scaler.update()\n",
        "        run_loss += loss.detach().float().item() * xb.size(0)\n",
        "        n_seen += xb.size(0)\n",
        "    print(f'Epoch {ep}/{epochs} - loss {(run_loss/max(1,n_seen)):.4f} - elapsed {time.time()-ep_t0:.1f}s', flush=True)\n",
        "print('Training done in %.1fs' % (time.time()-t0), flush=True)\n",
        "\n",
        "# Build prototypes for blend and log priors\n",
        "P_sum = np.zeros((num_classes, D), dtype=np.float32); cnt = freq.astype(np.int64)\n",
        "for c in range(num_classes):\n",
        "    idx = np.where(y_tr==c)[0]\n",
        "    if idx.size: P_sum[c] = E_tr[idx].mean(axis=0)\n",
        "P = P_sum / (np.linalg.norm(P_sum, axis=1, keepdims=True) + 1e-12); del P_sum\n",
        "alpha = 0.5\n",
        "log_pi = np.log((cnt / max(1, int(cnt.sum()))) + 1e-12).astype('float32')\n",
        "\n",
        "# Inference chunked with blend: 0.7*linear + 0.3*scaled_cosine\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    W_proto = torch.from_numpy(P).to(device=device, dtype=torch.float16)\n",
        "    log_pi_t = torch.from_numpy(log_pi).to(device=device, dtype=torch.float16)\n",
        "    blend_w_lin = 0.7\n",
        "    blend_w_proto = 0.3\n",
        "    proto_scale = 10.0\n",
        "    Nte = E_te.shape[0]; bs_inf = 2048\n",
        "    preds = np.empty((Nte,), dtype=np.int32)\n",
        "    s = 0; t1 = time.time();\n",
        "    while s < Nte:\n",
        "        e = min(s+bs_inf, Nte)\n",
        "        X = torch.from_numpy(E_te[s:e]).to(device=device, dtype=torch.float16, non_blocking=True)\n",
        "        with torch.cuda.amp.autocast(dtype=torch.float16, enabled=(device=='cuda')):\n",
        "            logit_lin = model(X)                              # (B,C)\n",
        "            logit_proto = (X @ W_proto.T) * proto_scale      # (B,C)\n",
        "            logits = blend_w_lin*logit_lin + blend_w_proto*logit_proto\n",
        "            logits = logits - alpha * log_pi_t               # debias\n",
        "        top1 = torch.argmax(logits, dim=1).to('cpu').numpy().astype(np.int32)\n",
        "        preds[s:e] = top1\n",
        "        s = e\n",
        "        if (s//bs_inf) % 10 == 0:\n",
        "            print(f'Infer {s}/{Nte} (elapsed {time.time()-t1:.1f}s)', flush=True)\n",
        "    del W_proto, log_pi_t\n",
        "    torch.cuda.empty_cache() if device=='cuda' else None\n",
        "\n",
        "# Map to category_id and write\n",
        "pred_cat = [idx2cat_id[int(i)] for i in preds]\n",
        "sub = pd.DataFrame({'Id': np.arange(len(test_df), dtype=np.int32), 'Predicted': pred_cat})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('submission.csv written (linear+proto blend)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "087d127f-cd77-40c9-9049-b8735e2c4fae",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ConvNeXtV2 training (speed-tuned) with LADE, EMA, AMP\n",
        "import os, time, math, json, random, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, ImageFile\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from timm.data import create_transform\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def seed_all(s=42):\n",
        "    random.seed(s); np.random.seed(s); torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
        "seed_all(42)\n",
        "\n",
        "os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')\n",
        "try: torch.set_float32_matmul_precision('medium')\n",
        "except: pass\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "# Config\n",
        "num_classes = int(train_df['y'].max()+1)\n",
        "img_size = 256  # reduced for throughput\n",
        "backbone_candidates = [\n",
        "    'convnextv2_small',                  # use default pretrained tag\n",
        "    'convnextv2_tiny',                   # fallback smaller\n",
        "    'convnextv2_base.fcmae_ft_in22k_in1k',  # known-good base weights\n",
        "]\n",
        "epochs = 6\n",
        "batch_size = 96     # try 96 first; if OOM, reduce to 80/72/64 manually\n",
        "accum_steps = 1     # no grad accumulation for faster steps\n",
        "num_workers = 16    # more workers for I/O\n",
        "lr = 3e-4\n",
        "weight_decay = 0.05\n",
        "ema_decay = 0.99985\n",
        "warmup_epochs = 1\n",
        "val_fold_index = 0\n",
        "ckpt_dir = Path('checkpoints'); ckpt_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Folds\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "folds = list(skf.split(train_df.index.values, train_df['y'].values))\n",
        "tr_idx, va_idx = folds[val_fold_index]\n",
        "train_idx = train_df.index.values[tr_idx]\n",
        "valid_idx = train_df.index.values[va_idx]\n",
        "print(f'Fold {val_fold_index}: train {len(train_idx)}, valid {len(valid_idx)}')\n",
        "\n",
        "# Transforms via timm (bicubic + light RandomErasing)\n",
        "mean = (0.485, 0.456, 0.406); std = (0.229, 0.224, 0.225)\n",
        "train_tfms = create_transform(\n",
        "    input_size=img_size, is_training=True,\n",
        "    scale=(0.9, 1.0), ratio=(0.8, 1.25), hflip=0.5,\n",
        "    interpolation='bicubic', mean=mean, std=std,\n",
        "    re_prob=0.25, re_mode='pixel'\n",
        ")\n",
        "valid_tfms = create_transform(\n",
        "    input_size=img_size, is_training=False,\n",
        "    interpolation='bicubic', mean=mean, std=std\n",
        ")\n",
        "\n",
        "class ImgDS(Dataset):\n",
        "    def __init__(self, df, indices, tfm):\n",
        "        self.df = df.loc[indices].reset_index(drop=True)\n",
        "        self.tfm = tfm\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        path = row['path']; y = int(row['y'])\n",
        "        try: img = Image.open(path).convert('RGB')\n",
        "        except: img = Image.new('RGB', (img_size, img_size), (0,0,0))\n",
        "        return self.tfm(img), y\n",
        "\n",
        "train_ds = ImgDS(train_df, train_idx, train_tfms)\n",
        "valid_ds = ImgDS(train_df, valid_idx, valid_tfms)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True, drop_last=True, prefetch_factor=6)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=max(1, batch_size*2), shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True, prefetch_factor=6)\n",
        "\n",
        "# LADE priors\n",
        "freq = train_df.loc[train_idx, 'y'].value_counts().reindex(range(num_classes), fill_value=0).values.astype(np.float32)\n",
        "prior = (freq + 1.0) / float(freq.sum() + num_classes)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "log_prior = torch.from_numpy(np.log(prior)).float().to(device)\n",
        "\n",
        "def create_model_with_fallback(cands, num_classes):\n",
        "    last_err = None\n",
        "    for name in cands:\n",
        "        try:\n",
        "            torch.cuda.empty_cache(); gc.collect()\n",
        "            print(f'Trying model: {name}', flush=True)\n",
        "            mdl = timm.create_model(name, pretrained=True, num_classes=num_classes)\n",
        "            mdl = mdl.to(device)\n",
        "            mdl = mdl.to(memory_format=torch.channels_last)\n",
        "            print(f'Loaded model: {name}', flush=True)\n",
        "            return mdl, name\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            print(f'OOM or error with {name}: {e}', flush=True)\n",
        "            try: del mdl\n",
        "            except: pass\n",
        "            torch.cuda.empty_cache(); gc.collect()\n",
        "    raise last_err\n",
        "\n",
        "model, model_name = create_model_with_fallback(backbone_candidates, num_classes)\n",
        "# EMA on CPU to save VRAM\n",
        "ema = ModelEmaV2(model, decay=ema_decay, device='cpu')\n",
        "\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, betas=(0.9, 0.999))\n",
        "updates_per_epoch = math.ceil(len(train_dl) / max(1, accum_steps))\n",
        "total_steps = epochs * updates_per_epoch\n",
        "warmup_steps = max(1, warmup_epochs * updates_per_epoch)\n",
        "\n",
        "def cosine_lr(step_it):\n",
        "    if step_it < warmup_steps:\n",
        "        return (step_it + 1) / max(1, warmup_steps)\n",
        "    t = (step_it - warmup_steps) / max(1, total_steps - warmup_steps)\n",
        "    return 0.5 * (1.0 + math.cos(math.pi * min(1.0, max(0.0, t))))\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=(device=='cuda'))\n",
        "\n",
        "best_f1 = -1.0\n",
        "best_path = ckpt_dir / f'cnv2x{img_size}_{model_name.replace(\".\", \"_\")}_fold{val_fold_index}_ema_best.pth'\n",
        "\n",
        "def validate(use_ema=True):\n",
        "    # Move EMA to device for eval to avoid swapping full state dicts repeatedly\n",
        "    mdl = model\n",
        "    if use_ema:\n",
        "        ema.module.to(device)\n",
        "        mdl = ema.module\n",
        "    mdl.eval()\n",
        "    preds = []; targets = []\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(device=='cuda')):\n",
        "        for xb, yb in valid_dl:\n",
        "            xb = xb.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            logits = mdl(xb)\n",
        "            pred = torch.argmax(logits, dim=1)\n",
        "            preds.append(pred.cpu().numpy()); targets.append(yb.cpu().numpy())\n",
        "    if use_ema:\n",
        "        ema.module.to('cpu')\n",
        "        torch.cuda.empty_cache() if device=='cuda' else None\n",
        "    preds = np.concatenate(preds); targets = np.concatenate(targets)\n",
        "    return f1_score(targets, preds, average='macro')\n",
        "\n",
        "micro_it = 0\n",
        "step_it = 0\n",
        "t_train0 = time.time()\n",
        "for ep in range(1, epochs+1):\n",
        "    model.train()\n",
        "    run_loss = 0.0; n_seen = 0\n",
        "    ep_t0 = time.time()\n",
        "    opt.zero_grad(set_to_none=True)\n",
        "    for xb, yb in train_dl:\n",
        "        xb = xb.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "        with torch.amp.autocast('cuda', enabled=(device=='cuda')):\n",
        "            logits = model(xb)\n",
        "            logits_adj = logits + log_prior.unsqueeze(0)\n",
        "            # Light label smoothing compatible with LADE\n",
        "            loss = F.cross_entropy(logits_adj, yb, label_smoothing=0.05) / max(1, accum_steps)\n",
        "        scaler.scale(loss).backward()\n",
        "        micro_it += 1\n",
        "        bs_now = xb.size(0)\n",
        "        run_loss += (loss.detach().float().item() * max(1, accum_steps)) * bs_now\n",
        "        n_seen += bs_now\n",
        "        if (micro_it % max(1, accum_steps)) == 0:\n",
        "            scaler.unscale_(opt)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            lr_scale = cosine_lr(step_it)\n",
        "            for pg in opt.param_groups: pg['lr'] = lr * lr_scale\n",
        "            scaler.step(opt); scaler.update()\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            if step_it >= warmup_steps:\n",
        "                ema.update(model)\n",
        "            step_it += 1\n",
        "            if step_it % 200 == 0:\n",
        "                print(f'ep {ep} step {step_it}/{updates_per_epoch} lr {opt.param_groups[0][\"lr\"]:.2e} loss {run_loss/max(1,n_seen):.4f}', flush=True)\n",
        "    ep_loss = run_loss / max(1, n_seen)\n",
        "    f1 = validate(use_ema=True)\n",
        "    print(f'Epoch {ep}/{epochs} - loss {ep_loss:.4f} - val macro-F1 {f1:.5f} - elapsed {time.time()-ep_t0:.1f}s', flush=True)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save({'model': ema.module.state_dict(), 'f1': f1, 'epoch': ep, 'cfg': {'model_name': model_name, 'img_size': img_size, 'fold': val_fold_index}}, best_path)\n",
        "        print(f'  Saved new best to {best_path} (F1={f1:.5f})', flush=True)\n",
        "\n",
        "print(f'Training complete in {(time.time()-t_train0)/60:.1f} min. Best F1={best_f1:.5f}')\n",
        "gc.collect();\n",
        "torch.cuda.empty_cache() if device=='cuda' else None"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/model_selection/_split.py:811: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: train 532576, valid 133144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying model: convnextv2_small\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOM or error with convnextv2_small: No pretrained weights exist for convnextv2_small. Use `pretrained=False` for random init.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying model: convnextv2_tiny\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model: convnextv2_tiny\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 200/5547 lr 1.08e-05 loss 9.7397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 400/5547 lr 2.16e-05 loss 9.6781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 600/5547 lr 3.24e-05 loss 9.6372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 800/5547 lr 4.33e-05 loss 9.5947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 1000/5547 lr 5.41e-05 loss 9.5180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 1200/5547 lr 6.49e-05 loss 9.4054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 1400/5547 lr 7.57e-05 loss 9.2762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 1600/5547 lr 8.65e-05 loss 9.1351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 1800/5547 lr 9.73e-05 loss 8.9870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 2000/5547 lr 1.08e-04 loss 8.8309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 2200/5547 lr 1.19e-04 loss 8.6729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 2400/5547 lr 1.30e-04 loss 8.5137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 2600/5547 lr 1.41e-04 loss 8.3527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 2800/5547 lr 1.51e-04 loss 8.1929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 3000/5547 lr 1.62e-04 loss 8.0331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 3200/5547 lr 1.73e-04 loss 7.8767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 3400/5547 lr 1.84e-04 loss 7.7235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 3600/5547 lr 1.95e-04 loss 7.5723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 3800/5547 lr 2.06e-04 loss 7.4259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 4000/5547 lr 2.16e-04 loss 7.2837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 4200/5547 lr 2.27e-04 loss 7.1480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 4400/5547 lr 2.38e-04 loss 7.0168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 4600/5547 lr 2.49e-04 loss 6.8910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 4800/5547 lr 2.60e-04 loss 6.7704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 5000/5547 lr 2.70e-04 loss 6.6569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 5200/5547 lr 2.81e-04 loss 6.5470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 1 step 5400/5547 lr 2.92e-04 loss 6.4421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6 - loss 6.3700 - val macro-F1 0.00000 - elapsed 3201.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved new best to checkpoints/cnv2x256_convnextv2_tiny_fold0_ema_best.pth (F1=0.00000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 5600/5547 lr 3.00e-04 loss 3.2664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 5800/5547 lr 3.00e-04 loss 3.2342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 6000/5547 lr 3.00e-04 loss 3.2308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 6200/5547 lr 3.00e-04 loss 3.2232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 6400/5547 lr 2.99e-04 loss 3.2170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 6600/5547 lr 2.99e-04 loss 3.1985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 6800/5547 lr 2.98e-04 loss 3.1831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 7000/5547 lr 2.98e-04 loss 3.1657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 7200/5547 lr 2.97e-04 loss 3.1496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 7400/5547 lr 2.97e-04 loss 3.1348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 7600/5547 lr 2.96e-04 loss 3.1172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 7800/5547 lr 2.95e-04 loss 3.1022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 8000/5547 lr 2.94e-04 loss 3.0888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 8200/5547 lr 2.93e-04 loss 3.0776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 8400/5547 lr 2.92e-04 loss 3.0636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 8600/5547 lr 2.91e-04 loss 3.0480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 8800/5547 lr 2.90e-04 loss 3.0339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 9000/5547 lr 2.89e-04 loss 3.0201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 9200/5547 lr 2.87e-04 loss 3.0059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 9400/5547 lr 2.86e-04 loss 2.9920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 9600/5547 lr 2.84e-04 loss 2.9784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 9800/5547 lr 2.83e-04 loss 2.9641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 10000/5547 lr 2.81e-04 loss 2.9515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 10200/5547 lr 2.80e-04 loss 2.9391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 10400/5547 lr 2.78e-04 loss 2.9271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 10600/5547 lr 2.76e-04 loss 2.9146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 10800/5547 lr 2.74e-04 loss 2.9033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 2 step 11000/5547 lr 2.72e-04 loss 2.8914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/6 - loss 2.8858 - val macro-F1 0.42962 - elapsed 3380.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved new best to checkpoints/cnv2x256_convnextv2_tiny_fold0_ema_best.pth (F1=0.42962)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 11200/5547 lr 2.70e-04 loss 2.0268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 11400/5547 lr 2.68e-04 loss 2.0375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 11600/5547 lr 2.66e-04 loss 2.0281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 11800/5547 lr 2.64e-04 loss 2.0296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 12000/5547 lr 2.62e-04 loss 2.0352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 12200/5547 lr 2.59e-04 loss 2.0404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 12400/5547 lr 2.57e-04 loss 2.0444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 12600/5547 lr 2.55e-04 loss 2.0471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 12800/5547 lr 2.52e-04 loss 2.0492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 13000/5547 lr 2.50e-04 loss 2.0494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 13200/5547 lr 2.47e-04 loss 2.0495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 13400/5547 lr 2.44e-04 loss 2.0510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 13600/5547 lr 2.42e-04 loss 2.0499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 13800/5547 lr 2.39e-04 loss 2.0495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 14000/5547 lr 2.36e-04 loss 2.0481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 14200/5547 lr 2.34e-04 loss 2.0470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 14400/5547 lr 2.31e-04 loss 2.0472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 14600/5547 lr 2.28e-04 loss 2.0459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 14800/5547 lr 2.25e-04 loss 2.0452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 15000/5547 lr 2.22e-04 loss 2.0433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 15200/5547 lr 2.19e-04 loss 2.0418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 15400/5547 lr 2.16e-04 loss 2.0396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 15600/5547 lr 2.13e-04 loss 2.0362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 15800/5547 lr 2.10e-04 loss 2.0339\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 16000/5547 lr 2.07e-04 loss 2.0312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 16200/5547 lr 2.03e-04 loss 2.0292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 16400/5547 lr 2.00e-04 loss 2.0256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 3 step 16600/5547 lr 1.97e-04 loss 2.0225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/6 - loss 2.0219 - val macro-F1 0.59279 - elapsed 3370.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved new best to checkpoints/cnv2x256_convnextv2_tiny_fold0_ema_best.pth (F1=0.59279)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 16800/5547 lr 1.94e-04 loss 1.4712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 17000/5547 lr 1.91e-04 loss 1.4626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 17200/5547 lr 1.87e-04 loss 1.4656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 17400/5547 lr 1.84e-04 loss 1.4697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 17600/5547 lr 1.81e-04 loss 1.4746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 17800/5547 lr 1.77e-04 loss 1.4782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 18000/5547 lr 1.74e-04 loss 1.4800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 18200/5547 lr 1.71e-04 loss 1.4825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 18400/5547 lr 1.67e-04 loss 1.4848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 18600/5547 lr 1.64e-04 loss 1.4835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 18800/5547 lr 1.60e-04 loss 1.4841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 19000/5547 lr 1.57e-04 loss 1.4851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 19200/5547 lr 1.54e-04 loss 1.4848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 19400/5547 lr 1.50e-04 loss 1.4832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 19600/5547 lr 1.47e-04 loss 1.4818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 19800/5547 lr 1.43e-04 loss 1.4815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 20000/5547 lr 1.40e-04 loss 1.4810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 20200/5547 lr 1.37e-04 loss 1.4807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 20400/5547 lr 1.33e-04 loss 1.4796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 20600/5547 lr 1.30e-04 loss 1.4780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 20800/5547 lr 1.27e-04 loss 1.4776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 21000/5547 lr 1.23e-04 loss 1.4768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 21200/5547 lr 1.20e-04 loss 1.4757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 21400/5547 lr 1.17e-04 loss 1.4747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 21600/5547 lr 1.13e-04 loss 1.4733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 21800/5547 lr 1.10e-04 loss 1.4720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 4 step 22000/5547 lr 1.07e-04 loss 1.4703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/6 - loss 1.4688 - val macro-F1 0.62790 - elapsed 3371.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved new best to checkpoints/cnv2x256_convnextv2_tiny_fold0_ema_best.pth (F1=0.62790)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 22200/5547 lr 1.03e-04 loss 1.0953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 22400/5547 lr 1.00e-04 loss 1.1133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 22600/5547 lr 9.71e-05 loss 1.1106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 22800/5547 lr 9.39e-05 loss 1.1133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 23000/5547 lr 9.08e-05 loss 1.1136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 23200/5547 lr 8.76e-05 loss 1.1134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 23400/5547 lr 8.46e-05 loss 1.1125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 23600/5547 lr 8.15e-05 loss 1.1127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 23800/5547 lr 7.85e-05 loss 1.1113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 24000/5547 lr 7.56e-05 loss 1.1121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 24200/5547 lr 7.26e-05 loss 1.1116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 24400/5547 lr 6.97e-05 loss 1.1109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 24600/5547 lr 6.69e-05 loss 1.1103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 24800/5547 lr 6.41e-05 loss 1.1097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 25000/5547 lr 6.13e-05 loss 1.1095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 25200/5547 lr 5.86e-05 loss 1.1088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 25400/5547 lr 5.59e-05 loss 1.1076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 25600/5547 lr 5.33e-05 loss 1.1064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 25800/5547 lr 5.07e-05 loss 1.1056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 26000/5547 lr 4.82e-05 loss 1.1051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 26200/5547 lr 4.57e-05 loss 1.1040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 26400/5547 lr 4.33e-05 loss 1.1031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 26600/5547 lr 4.10e-05 loss 1.1020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 26800/5547 lr 3.87e-05 loss 1.1012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 27000/5547 lr 3.64e-05 loss 1.1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 27200/5547 lr 3.42e-05 loss 1.0990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 27400/5547 lr 3.21e-05 loss 1.0980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 5 step 27600/5547 lr 3.00e-05 loss 1.0971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/6 - loss 1.0962 - val macro-F1 0.63557 - elapsed 3370.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved new best to checkpoints/cnv2x256_convnextv2_tiny_fold0_ema_best.pth (F1=0.63557)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 27800/5547 lr 2.80e-05 loss 0.9494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 28000/5547 lr 2.61e-05 loss 0.9461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 28200/5547 lr 2.42e-05 loss 0.9464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 28400/5547 lr 2.24e-05 loss 0.9447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 28600/5547 lr 2.06e-05 loss 0.9440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 28800/5547 lr 1.89e-05 loss 0.9443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 29000/5547 lr 1.73e-05 loss 0.9449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 29200/5547 lr 1.58e-05 loss 0.9453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 29400/5547 lr 1.43e-05 loss 0.9447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 29600/5547 lr 1.29e-05 loss 0.9444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 29800/5547 lr 1.15e-05 loss 0.9448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 30000/5547 lr 1.03e-05 loss 0.9444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 30200/5547 lr 9.05e-06 loss 0.9444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 30400/5547 lr 7.93e-06 loss 0.9439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 30600/5547 lr 6.87e-06 loss 0.9432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 30800/5547 lr 5.89e-06 loss 0.9427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 31000/5547 lr 4.99e-06 loss 0.9423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 31200/5547 lr 4.16e-06 loss 0.9420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 31400/5547 lr 3.40e-06 loss 0.9419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 31600/5547 lr 2.72e-06 loss 0.9418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 31800/5547 lr 2.11e-06 loss 0.9417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 32000/5547 lr 1.58e-06 loss 0.9412\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 32200/5547 lr 1.13e-06 loss 0.9408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 32400/5547 lr 7.50e-07 loss 0.9407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 32600/5547 lr 4.49e-07 loss 0.9406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 32800/5547 lr 2.24e-07 loss 0.9406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 33000/5547 lr 7.71e-08 loss 0.9402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep 6 step 33200/5547 lr 6.63e-09 loss 0.9402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/6 - loss 0.9401 - val macro-F1 0.63298 - elapsed 3370.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete in 334.5 min. Best F1=0.63557\n"
          ]
        }
      ]
    },
    {
      "id": "ddb88987-954f-43ae-a5a0-b790033b2012",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference: load EMA-best checkpoint and run 2x TTA on test, save logits and submission\n",
        "import time, glob, numpy as np, torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, ImageFile\n",
        "import timm, pandas as pd, os\n",
        "from timm.data import create_transform\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# Robust glob to match our saved pattern cnv2x{img_size}_{model_name}_fold0_ema_best.pth\n",
        "ckpts = sorted(glob.glob(str(ckpt_dir / 'cnv2x*_fold0_ema_best.pth')), key=lambda p: os.stat(p).st_mtime)\n",
        "best_ckpt = ckpts[-1] if ckpts else None\n",
        "print('Best checkpoint:', best_ckpt)\n",
        "assert best_ckpt is not None, 'No best checkpoint found.'\n",
        "\n",
        "# Load checkpoint and rebuild the exact model from cfg\n",
        "ckpt = torch.load(best_ckpt, map_location=device)\n",
        "cfg = ckpt.get('cfg', {})\n",
        "model_name_ckpt = cfg.get('model_name', 'convnextv2_base.fcmae_ft_in22k_in1k')\n",
        "img_size = int(cfg.get('img_size', 256))\n",
        "num_classes = int(train_df['y'].max()+1)\n",
        "model_inf = timm.create_model(model_name_ckpt, pretrained=False, num_classes=num_classes).to(device).to(memory_format=torch.channels_last)\n",
        "model_inf.load_state_dict(ckpt['model'], strict=True)\n",
        "model_inf.eval()\n",
        "\n",
        "# Test transforms (timm create_transform with bicubic, center crop)\n",
        "mean = (0.485, 0.456, 0.406); std = (0.229, 0.224, 0.225)\n",
        "test_tfms = create_transform(input_size=img_size, is_training=False, interpolation='bicubic', mean=mean, std=std)\n",
        "\n",
        "class TestDS(Dataset):\n",
        "    def __init__(self, df, tfm):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tfm = tfm\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        p = self.df.at[i, 'path']\n",
        "        try:\n",
        "            img = Image.open(p).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.new('RGB', (img_size, img_size), (0,0,0))\n",
        "        x = self.tfm(img)\n",
        "        return x, i\n",
        "\n",
        "test_ds = TestDS(test_df, test_tfms)\n",
        "bs_inf = 128\n",
        "num_workers = 10\n",
        "test_dl = DataLoader(test_ds, batch_size=bs_inf, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "# Inference with 2x TTA (orig + hflip), average logits; save logits fp16 and submission\n",
        "Nte = len(test_ds)\n",
        "logits_fp16 = np.memmap('logits_test_fp16.mmap', dtype='float16', mode='w+', shape=(Nte, num_classes))\n",
        "t0 = time.time(); seen = 0\n",
        "with torch.no_grad(), torch.amp.autocast('cuda', enabled=(device=='cuda')):\n",
        "    for xb, idx in test_dl:\n",
        "        xb = xb.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "        lo = model_inf(xb)\n",
        "        xf = torch.flip(xb, dims=[-1])\n",
        "        lf = model_inf(xf)\n",
        "        l = 0.5 * (lo + lf)\n",
        "        l = l.float()\n",
        "        logits_fp16[idx.numpy()] = l.cpu().numpy().astype('float16')\n",
        "        seen += xb.size(0)\n",
        "        if seen % (bs_inf*10) == 0:\n",
        "            print(f'Infer {seen}/{Nte} (elapsed {time.time()-t0:.1f}s)', flush=True)\n",
        "del logits_fp16\n",
        "np.save('logits_test_fp16.npy', np.memmap('logits_test_fp16.mmap', dtype='float16', mode='r', shape=(Nte, num_classes)))\n",
        "try: os.remove('logits_test_fp16.mmap')\n",
        "except: pass\n",
        "print('Saved logits_test_fp16.npy')\n",
        "\n",
        "# Build submission (argmax)\n",
        "logits = np.load('logits_test_fp16.npy').astype('float32')\n",
        "preds = logits.argmax(axis=1).astype('int32')\n",
        "pred_cat = [idx2cat_id[int(i)] for i in preds]\n",
        "sub = pd.DataFrame({'Id': np.arange(len(test_df), dtype=np.int32), 'Predicted': pred_cat})\n",
        "sub.to_csv('submission_classifier.csv', index=False)\n",
        "print('Wrote submission_classifier.csv')\n",
        "print('Inference total elapsed: %.1f s' % (time.time()-t0))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best checkpoint: checkpoints/cnv2x256_convnextv2_tiny_fold0_ema_best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2716/3147542851.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(best_ckpt, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 1280/174052 (elapsed 7.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 2560/174052 (elapsed 11.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 3840/174052 (elapsed 15.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 5120/174052 (elapsed 19.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 6400/174052 (elapsed 23.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 7680/174052 (elapsed 26.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 8960/174052 (elapsed 30.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 10240/174052 (elapsed 34.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 11520/174052 (elapsed 38.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 12800/174052 (elapsed 42.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 14080/174052 (elapsed 45.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 15360/174052 (elapsed 49.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 16640/174052 (elapsed 53.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 17920/174052 (elapsed 57.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 19200/174052 (elapsed 61.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 20480/174052 (elapsed 65.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 21760/174052 (elapsed 68.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 23040/174052 (elapsed 72.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 24320/174052 (elapsed 76.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 25600/174052 (elapsed 80.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 26880/174052 (elapsed 84.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 28160/174052 (elapsed 88.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 29440/174052 (elapsed 91.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 30720/174052 (elapsed 95.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 32000/174052 (elapsed 99.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 33280/174052 (elapsed 103.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 34560/174052 (elapsed 107.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 35840/174052 (elapsed 111.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 37120/174052 (elapsed 114.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 38400/174052 (elapsed 118.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 39680/174052 (elapsed 122.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 40960/174052 (elapsed 126.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 42240/174052 (elapsed 130.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 43520/174052 (elapsed 134.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 44800/174052 (elapsed 137.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 46080/174052 (elapsed 141.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 47360/174052 (elapsed 145.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 48640/174052 (elapsed 149.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 49920/174052 (elapsed 153.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 51200/174052 (elapsed 157.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 52480/174052 (elapsed 160.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 53760/174052 (elapsed 164.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 55040/174052 (elapsed 168.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 56320/174052 (elapsed 172.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 57600/174052 (elapsed 176.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 58880/174052 (elapsed 180.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 60160/174052 (elapsed 183.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 61440/174052 (elapsed 187.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 62720/174052 (elapsed 191.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 64000/174052 (elapsed 195.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 65280/174052 (elapsed 199.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 66560/174052 (elapsed 203.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 67840/174052 (elapsed 206.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 69120/174052 (elapsed 210.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 70400/174052 (elapsed 214.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 71680/174052 (elapsed 218.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 72960/174052 (elapsed 222.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 74240/174052 (elapsed 226.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 75520/174052 (elapsed 230.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 76800/174052 (elapsed 234.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 78080/174052 (elapsed 237.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 79360/174052 (elapsed 241.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 80640/174052 (elapsed 245.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 81920/174052 (elapsed 249.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 83200/174052 (elapsed 253.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 84480/174052 (elapsed 257.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 85760/174052 (elapsed 260.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 87040/174052 (elapsed 264.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 88320/174052 (elapsed 268.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 89600/174052 (elapsed 272.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 90880/174052 (elapsed 276.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 92160/174052 (elapsed 280.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 93440/174052 (elapsed 284.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 94720/174052 (elapsed 288.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 96000/174052 (elapsed 291.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 97280/174052 (elapsed 295.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 98560/174052 (elapsed 299.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 99840/174052 (elapsed 303.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 101120/174052 (elapsed 307.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 102400/174052 (elapsed 311.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 103680/174052 (elapsed 314.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 104960/174052 (elapsed 318.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 106240/174052 (elapsed 322.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 107520/174052 (elapsed 326.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 108800/174052 (elapsed 330.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 110080/174052 (elapsed 334.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 111360/174052 (elapsed 337.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 112640/174052 (elapsed 341.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 113920/174052 (elapsed 345.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 115200/174052 (elapsed 349.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 116480/174052 (elapsed 353.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 117760/174052 (elapsed 357.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 119040/174052 (elapsed 360.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 120320/174052 (elapsed 364.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 121600/174052 (elapsed 368.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 122880/174052 (elapsed 372.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 124160/174052 (elapsed 376.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 125440/174052 (elapsed 380.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 126720/174052 (elapsed 383.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 128000/174052 (elapsed 387.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 129280/174052 (elapsed 391.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 130560/174052 (elapsed 395.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 131840/174052 (elapsed 399.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 133120/174052 (elapsed 403.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 134400/174052 (elapsed 406.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 135680/174052 (elapsed 410.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 136960/174052 (elapsed 414.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 138240/174052 (elapsed 418.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 139520/174052 (elapsed 422.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 140800/174052 (elapsed 426.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 142080/174052 (elapsed 429.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 143360/174052 (elapsed 433.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 144640/174052 (elapsed 437.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 145920/174052 (elapsed 441.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 147200/174052 (elapsed 445.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 148480/174052 (elapsed 449.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 149760/174052 (elapsed 452.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 151040/174052 (elapsed 456.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 152320/174052 (elapsed 460.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 153600/174052 (elapsed 464.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 154880/174052 (elapsed 468.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 156160/174052 (elapsed 472.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 157440/174052 (elapsed 475.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 158720/174052 (elapsed 479.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 160000/174052 (elapsed 483.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 161280/174052 (elapsed 487.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 162560/174052 (elapsed 491.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 163840/174052 (elapsed 495.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 165120/174052 (elapsed 498.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 166400/174052 (elapsed 502.6s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 167680/174052 (elapsed 506.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 168960/174052 (elapsed 510.3s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 170240/174052 (elapsed 514.1s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 171520/174052 (elapsed 518.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer 172800/174052 (elapsed 521.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved logits_test_fp16.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_classifier.csv\nInference total elapsed: 554.6 s\n"
          ]
        }
      ]
    },
    {
      "id": "df016477-804b-4932-bc34-555e03ed4a40",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Proto logits (TTA embeddings) + optional blend with classifier logits\n",
        "import os, time, numpy as np, pandas as pd, torch\n",
        "\n",
        "def pick_emb(path_tta, path_base):\n",
        "    return path_tta if os.path.exists(path_tta) else path_base\n",
        "\n",
        "train_emb_path = pick_emb('embeddings/train_vitb32_tta2.npy','embeddings/train_vitb32.npy')\n",
        "test_emb_path  = pick_emb('embeddings/test_vitb32_tta2.npy', 'embeddings/test_vitb32.npy')\n",
        "print('Using embeddings:', train_emb_path, ' / ', test_emb_path, flush=True)\n",
        "\n",
        "# Load features and build prototypes\n",
        "E_tr = np.load(train_emb_path).astype('float32')\n",
        "E_te = np.load(test_emb_path).astype('float32')\n",
        "y_tr = train_df['y'].to_numpy()\n",
        "num_classes = int(y_tr.max()+1); D = E_tr.shape[1]\n",
        "freq = np.bincount(y_tr, minlength=num_classes).astype(np.float32)\n",
        "P_sum = np.zeros((num_classes, D), dtype=np.float32)\n",
        "for c in range(num_classes):\n",
        "    idx = np.where(y_tr==c)[0]\n",
        "    if idx.size: P_sum[c] = E_tr[idx].mean(axis=0)\n",
        "P = P_sum / (np.linalg.norm(P_sum, axis=1, keepdims=True) + 1e-12); del P_sum\n",
        "alpha = 0.5\n",
        "log_pi = np.log((freq / max(1, int(freq.sum()))) + 1e-12).astype('float32')\n",
        "proto_scale = 12.0\n",
        "\n",
        "# Compute proto logits for test (chunked, GPU if available)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "P_t = torch.from_numpy(P).to(device=device, dtype=torch.float16); del P\n",
        "log_pi_t = torch.from_numpy(log_pi).to(device=device, dtype=torch.float16)\n",
        "Nte = E_te.shape[0]; bs = 2048\n",
        "proto_mmap = np.memmap('proto_logits_fp16.mmap', dtype='float16', mode='w+', shape=(Nte, num_classes))\n",
        "t0 = time.time(); done = 0\n",
        "with torch.no_grad():\n",
        "    s = 0\n",
        "    while s < Nte:\n",
        "        e = min(s+bs, Nte)\n",
        "        X = torch.from_numpy(E_te[s:e]).to(device=device, dtype=torch.float16, non_blocking=True)\n",
        "        logits = (X @ P_t.T) * proto_scale\n",
        "        logits = logits - alpha * log_pi_t\n",
        "        proto_mmap[s:e] = logits.cpu().numpy().astype('float16')\n",
        "        s = e; done = s\n",
        "        if (done//bs) % 10 == 0:\n",
        "            print(f'proto logits {done}/{Nte} (elapsed {time.time()-t0:.1f}s)', flush=True)\n",
        "del P_t, log_pi_t\n",
        "proto_logits = np.memmap('proto_logits_fp16.mmap', dtype='float16', mode='r', shape=(Nte, num_classes))\n",
        "np.save('proto_logits_fp16.npy', proto_logits)\n",
        "try: os.remove('proto_logits_fp16.mmap')\n",
        "except: pass\n",
        "print('Saved proto_logits_fp16.npy')\n",
        "\n",
        "# Backup: write a proto-only submission for reference\n",
        "preds_proto = np.load('proto_logits_fp16.npy').astype('float32').argmax(axis=1).astype('int32')\n",
        "pred_cat_proto = [idx2cat_id[int(i)] for i in preds_proto]\n",
        "pd.DataFrame({'Id': np.arange(len(test_df), dtype=np.int32), 'Predicted': pred_cat_proto}).to_csv('submission_proto.csv', index=False)\n",
        "print('Wrote submission_proto.csv')\n",
        "\n",
        "# Optional blend: if classifier logits exist, blend 0.8 classifier + 0.2 proto and write submission_blend.csv\n",
        "if os.path.exists('logits_test_fp16.npy'):\n",
        "    clf_logits = np.load('logits_test_fp16.npy').astype('float32')\n",
        "    prt_logits = np.load('proto_logits_fp16.npy').astype('float32')\n",
        "    assert clf_logits.shape == prt_logits.shape, (clf_logits.shape, prt_logits.shape)\n",
        "    logits_blend = 0.8*clf_logits + 0.2*prt_logits\n",
        "    preds = logits_blend.argmax(axis=1).astype('int32')\n",
        "    pred_cat = [idx2cat_id[int(i)] for i in preds]\n",
        "    pd.DataFrame({'Id': np.arange(len(test_df), dtype=np.int32), 'Predicted': pred_cat}).to_csv('submission_blend.csv', index=False)\n",
        "    print('Wrote submission_blend.csv')\n",
        "else:\n",
        "    print('Classifier logits not found; blend skipped. Run Cell 10 later and re-run this section if needed.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using embeddings: embeddings/train_vitb32_tta2.npy  /  embeddings/test_vitb32_tta2.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proto logits 20480/174052 (elapsed 0.8s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proto logits 40960/174052 (elapsed 1.5s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proto logits 61440/174052 (elapsed 2.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proto logits 81920/174052 (elapsed 3.0s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proto logits 102400/174052 (elapsed 3.7s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proto logits 122880/174052 (elapsed 4.4s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proto logits 143360/174052 (elapsed 5.2s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proto logits 163840/174052 (elapsed 5.9s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved proto_logits_fp16.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_proto.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_blend.csv\n"
          ]
        }
      ]
    },
    {
      "id": "882d0f06-5b17-4674-8d4f-bd2f349538a5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Copy blended submission to submission.csv\n",
        "import pandas as pd, shutil, os\n",
        "src = 'submission_blend.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f\"{src} not found\"\n",
        "df = pd.read_csv(src)\n",
        "assert list(df.columns)==['Id','Predicted'], 'Invalid submission columns'\n",
        "df.to_csv(dst, index=False)\n",
        "print('Wrote', dst, 'rows:', len(df))\n",
        "print(df.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv rows: 174052\n   Id  Predicted\n0   0       9493\n1   1       5344\n2   2       3819\n3   3       2799\n4   4       6234\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}