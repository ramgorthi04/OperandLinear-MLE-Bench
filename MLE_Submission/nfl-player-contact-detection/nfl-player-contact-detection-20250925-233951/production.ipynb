{
  "cells": [
    {
      "id": "f5dfb753-b3a1-4f45-a626-dbdab35bccfd",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# PP blend r=4.0 and r=4.5 (0.5/0.5) with distance-aware caps (3/2/1) and thresholds optimized AFTER hysteresis per fold; fold-median thresholds; identical test chain; then G overwrite\n",
        "import time, numpy as np, pandas as pd, sys, subprocess\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "except Exception as e:\n",
        "    print('Installing xgboost...', e)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'xgboost==2.1.4'], check=True)\n",
        "    import xgboost as xgb\n",
        "print('xgboost version (pp-blend-r40-r45-cap321-thr-after-hyst):', getattr(xgb, '__version__', 'unknown'))\n",
        "\n",
        "def apply_hyst_per_pair(df_bin: pd.DataFrame) -> np.ndarray:\n",
        "    df_h = df_bin.sort_values(['game_play','p1','p2','step']).copy()\n",
        "    grp = df_h.groupby(['game_play','p1','p2'], sort=False)['pred_bin']\n",
        "    df_h['pred_hyst'] = grp.transform(lambda s: (s.rolling(3, center=True, min_periods=1).sum() >= 2).astype(int))\n",
        "    return df_h['pred_hyst'].to_numpy()\n",
        "\n",
        "def train_bag_radius(train_sup: pd.DataFrame, test_feats: pd.DataFrame, feat_cols, groups, y_all, seeds=(42,1337,2025)):\n",
        "    gkf = GroupKFold(n_splits=5)\n",
        "    ord_idx_tr = train_sup[['game_play','p1','p2','step']].sort_values(['game_play','p1','p2','step']).index.to_numpy()\n",
        "    ord_idx_te = test_feats[['game_play','p1','p2','step']].sort_values(['game_play','p1','p2','step']).index.to_numpy()\n",
        "    oof_s_list, test_s_list = [], []\n",
        "    for s in seeds:\n",
        "        print(f'  seed {s} ...', flush=True)\n",
        "        X_all = train_sup[feat_cols].astype(float).values\n",
        "        oof = np.full(len(train_sup), np.nan, float)\n",
        "        models = []\n",
        "        for fold, (tr_idx, va_idx) in enumerate(gkf.split(X_all, y_all, groups=groups)):\n",
        "            t1 = time.time()\n",
        "            X_tr, y_tr = X_all[tr_idx], y_all[tr_idx]\n",
        "            X_va, y_va = X_all[va_idx], y_all[va_idx]\n",
        "            neg = (y_tr == 0).sum(); posc = (y_tr == 1).sum()\n",
        "            spw = max(1.0, neg / max(1, posc))\n",
        "            dtrain = xgb.DMatrix(X_tr, label=y_tr); dvalid = xgb.DMatrix(X_va, label=y_va)\n",
        "            params = {'tree_method':'hist','device':'cuda','max_depth':7,'eta':0.05,'subsample':0.9,'colsample_bytree':0.8,\n",
        "                      'min_child_weight':10,'lambda':1.5,'alpha':0.1,'gamma':0.1,'objective':'binary:logistic','eval_metric':'logloss',\n",
        "                      'scale_pos_weight': float(spw), 'seed': int(s + fold)}\n",
        "            booster = xgb.train(params, dtrain, num_boost_round=3800, evals=[(dtrain,'train'),(dvalid,'valid')], early_stopping_rounds=200, verbose_eval=False)\n",
        "            best_it = int(getattr(booster, 'best_iteration', None) or booster.num_boosted_rounds() - 1)\n",
        "            oof[va_idx] = booster.predict(dvalid, iteration_range=(0, best_it + 1))\n",
        "            models.append((booster, best_it))\n",
        "            print(f'    fold {fold} done in {time.time()-t1:.1f}s; best_it={best_it}', flush=True)\n",
        "        # Smooth OOF in canonical order\n",
        "        df = train_sup[['game_play','p1','p2','step']].iloc[ord_idx_tr].copy()\n",
        "        df['oof'] = oof[ord_idx_tr]\n",
        "        df = df.sort_values(['game_play','p1','p2','step'])\n",
        "        grp = df.groupby(['game_play','p1','p2'], sort=False)\n",
        "        df['oof_smooth'] = grp['oof'].transform(lambda s_: s_.rolling(3, center=True, min_periods=1).max())\n",
        "        oof_s_list.append(df['oof_smooth'].to_numpy())\n",
        "        # Test preds and smoothing\n",
        "        Xt = test_feats[feat_cols].astype(float).values\n",
        "        dtest = xgb.DMatrix(Xt)\n",
        "        pt = np.zeros(len(test_feats), float)\n",
        "        for i, (booster, best_it) in enumerate(models):\n",
        "            t1 = time.time(); pt += booster.predict(dtest, iteration_range=(0, best_it + 1));\n",
        "            print(f'    test model {i} {time.time()-t1:.1f}s', flush=True)\n",
        "        pt /= max(1, len(models))\n",
        "        dt = test_feats[['game_play','p1','p2','step']].copy()\n",
        "        dt['prob'] = 0.0\n",
        "        dt.loc[ord_idx_te, 'prob'] = pt[ord_idx_te]\n",
        "        dt = dt.sort_values(['game_play','p1','p2','step'])\n",
        "        grp_t = dt.groupby(['game_play','p1','p2'], sort=False)\n",
        "        dt['prob_smooth'] = grp_t['prob'].transform(lambda s_: s_.rolling(3, center=True, min_periods=1).max())\n",
        "        test_s_list.append(dt['prob_smooth'].to_numpy())\n",
        "    oof_avg = np.mean(np.vstack(oof_s_list), axis=0)\n",
        "    test_avg = np.mean(np.vstack(test_s_list), axis=0)\n",
        "    keys_tr_sorted = train_sup[['game_play','p1','p2','step']].iloc[ord_idx_tr].copy().reset_index(drop=True)\n",
        "    keys_te_sorted = test_feats[['game_play','p1','p2','step']].iloc[ord_idx_te].copy().reset_index(drop=True)\n",
        "    return oof_avg, test_avg, keys_tr_sorted, keys_te_sorted\n",
        "\n",
        "def apply_distance_cap_smoothed(keys_df: pd.DataFrame, prob_smoothed: np.ndarray, dist_arr: np.ndarray, caps=(3,2,1), bins=(1.6, 2.4)) -> np.ndarray:\n",
        "    df = keys_df.copy().reset_index(drop=True)\n",
        "    df['prob'] = prob_smoothed\n",
        "    df['dist'] = dist_arr\n",
        "    df['row_id'] = np.arange(len(df))\n",
        "    long1 = df[['game_play','step','p1','prob','dist','row_id']].rename(columns={'p1':'player'})\n",
        "    long2 = df[['game_play','step','p2','prob','dist','row_id']].rename(columns={'p2':'player'})\n",
        "    dfl = pd.concat([long1, long2], ignore_index=True)\n",
        "    b0, b1 = bins\n",
        "    bin_idx = np.where(dfl['dist'].to_numpy() <= b0, 0, np.where(dfl['dist'].to_numpy() <= b1, 1, 2))\n",
        "    dfl['bin'] = bin_idx\n",
        "    dfl = dfl.sort_values(['game_play','step','player','bin','prob'], ascending=[True, True, True, True, False])\n",
        "    dfl['rank'] = dfl.groupby(['game_play','step','player','bin'], sort=False)['prob'].rank(method='first', ascending=False)\n",
        "    cap_map = {0: caps[0], 1: caps[1], 2: caps[2]}\n",
        "    dfl['cap'] = dfl['bin'].map(cap_map).astype(float)\n",
        "    keep_ids = set(dfl.loc[dfl['rank'] <= dfl['cap'], 'row_id'].tolist())\n",
        "    keep_mask = keys_df.index.to_series().reset_index(drop=True).isin(keep_ids).to_numpy()\n",
        "    prob_capped = prob_smoothed.copy()\n",
        "    prob_capped[~keep_mask] = 0.0\n",
        "    return prob_capped\n",
        "\n",
        "t0 = time.time()\n",
        "print('Loading r=4.0 and r=4.5 supervised dyn train and test features...')\n",
        "tr40 = pd.read_parquet('train_supervised_w5_helm_dyn_r40.parquet')\n",
        "te40 = pd.read_parquet('test_pairs_w5_helm_dyn_r40.parquet')\n",
        "tr45 = pd.read_parquet('train_supervised_w5_helm_dyn_r45.parquet')\n",
        "te45 = pd.read_parquet('test_pairs_w5_helm_dyn_r45.parquet')\n",
        "folds_df = pd.read_csv('folds_game_play.csv')\n",
        "tr40 = tr40.merge(folds_df, on='game_play', how='left')\n",
        "tr45 = tr45.merge(folds_df, on='game_play', how='left')\n",
        "assert tr40['fold'].notna().all() and tr45['fold'].notna().all()\n",
        "for df in (tr40, te40, tr45, te45):\n",
        "    if 'px_dist_norm_min' in df.columns: df['px_dist_norm_min'] = df['px_dist_norm_min'].fillna(1.0)\n",
        "    if 'views_both_present' in df.columns: df['views_both_present'] = df['views_both_present'].fillna(0).astype(float)\n",
        "\n",
        "drop_cols = {'contact','game_play','step','p1','p2','team1','team2','pos1','pos2','fold'}\n",
        "feat_cols40 = [c for c in tr40.columns if c not in drop_cols and pd.api.types.is_numeric_dtype(tr40[c])]\n",
        "feat_cols45 = [c for c in tr45.columns if c not in drop_cols and pd.api.types.is_numeric_dtype(tr45[c])]\n",
        "print('Using features r40:', len(feat_cols40), 'r45:', len(feat_cols45))\n",
        "\n",
        "# Train-bag for each radius\n",
        "groups40 = tr40['game_play'].values; y40 = tr40['contact'].astype(int).values\n",
        "groups45 = tr45['game_play'].values; y45 = tr45['contact'].astype(int).values\n",
        "\n",
        "print('Training r=4.0 ...')\n",
        "oof40, teprob40, keys40_tr, keys40_te = train_bag_radius(tr40, te40, feat_cols40, groups40, y40)\n",
        "print('Training r=4.5 ...')\n",
        "oof45, teprob45, keys45_tr, keys45_te = train_bag_radius(tr45, te45, feat_cols45, groups45, y45)\n",
        "\n",
        "# Align and blend OOF (0.5/0.5) on intersection of keys\n",
        "kcols = ['game_play','p1','p2','step']\n",
        "df_o40 = keys40_tr.copy(); df_o40['prob'] = oof40\n",
        "df_o45 = keys45_tr.copy(); df_o45['prob'] = oof45\n",
        "df_m = df_o40.merge(df_o45, on=kcols, how='inner', suffixes=('_40','_45'))\n",
        "oof_blend = 0.5 * df_m['prob_40'].to_numpy() + 0.5 * df_m['prob_45'].to_numpy()\n",
        "keys_blend_tr = df_m[kcols].reset_index(drop=True)\n",
        "\n",
        "# Gather y/same/fold/dist from r=4.5 (has wider coverage). Filter to blended keys.\n",
        "tr45_sorted = tr45.sort_values(kcols).reset_index(drop=True)\n",
        "df_meta = tr45_sorted[kcols + ['contact','same_team','fold','distance']].copy()\n",
        "df_meta = df_meta.merge(keys_blend_tr, on=kcols, how='right')\n",
        "y_sorted = df_meta['contact'].astype(int).to_numpy()\n",
        "same_sorted = df_meta['same_team'].fillna(0).astype(int).to_numpy() if 'same_team' in df_meta.columns else np.zeros(len(df_meta), np.int8)\n",
        "fold_sorted = df_meta['fold'].astype(int).to_numpy()\n",
        "dist_sorted = df_meta['distance'].astype(float).to_numpy()\n",
        "\n",
        "# Distance-aware cap on blended OOF\n",
        "oof_cap = apply_distance_cap_smoothed(keys_blend_tr, oof_blend, dist_sorted, caps=(3,2,1), bins=(1.6, 2.4))\n",
        "print('Applied distance-aware cap (3/2/1) to blended OOF. Kept nonzero:', int((oof_cap>0).sum()), 'of', len(oof_cap))\n",
        "\n",
        "# Optimize thresholds AFTER hysteresis per fold; grid 0.70-0.85\n",
        "thr_grid = np.round(np.linspace(0.70, 0.85, 16), 3)\n",
        "thr_best = []\n",
        "for k in sorted(np.unique(fold_sorted)):\n",
        "    m = (fold_sorted == k)\n",
        "    df_k = keys_blend_tr.loc[m, kcols].copy()\n",
        "    df_k['prob'] = oof_cap[m]\n",
        "    df_k['same'] = same_sorted[m]\n",
        "    y_k = y_sorted[m]\n",
        "    best_m, best_to, best_ts = -1.0, 0.78, 0.78\n",
        "    same_arr = df_k['same'].to_numpy()\n",
        "    prob_arr = df_k['prob'].to_numpy()\n",
        "    for to in thr_grid:\n",
        "        for ts in thr_grid:\n",
        "            thr_arr = np.where(same_arr == 1, ts, to)\n",
        "            pred_bin = (prob_arr >= thr_arr).astype(int)\n",
        "            df_tmp = df_k[kcols].copy()\n",
        "            df_tmp['pred_bin'] = pred_bin\n",
        "            pred_h = apply_hyst_per_pair(df_tmp)\n",
        "            mcc = matthews_corrcoef(y_k, pred_h)\n",
        "            if mcc > best_m:\n",
        "                best_m, best_to, best_ts = float(mcc), float(to), float(ts)\n",
        "    thr_best.append((best_to, best_ts))\n",
        "    print(f' Fold {k} best after-hyst MCC={best_m:.5f} thr_opp={best_to:.3f} thr_same={best_ts:.3f}')\n",
        "\n",
        "thr_best = np.array(thr_best, float)\n",
        "thr_opp_med = float(np.median(thr_best[:, 0]))\n",
        "thr_same_med = float(np.median(thr_best[:, 1]))\n",
        "print(f'Fold-median thresholds after hysteresis (blend r40/r45 cap3/2/1): thr_opp={thr_opp_med:.4f}, thr_same={thr_same_med:.4f}')\n",
        "\n",
        "# Test: align and blend 0.5/0.5, then smooth already done in train_bag, apply distance-aware caps, thresholds, hysteresis\n",
        "df_t40 = keys40_te.copy(); df_t40['prob'] = teprob40\n",
        "df_t45 = keys45_te.copy(); df_t45['prob'] = teprob45\n",
        "df_tm = df_t40.merge(df_t45, on=kcols, how='inner', suffixes=('_40','_45'))\n",
        "pt_blend = 0.5 * df_tm['prob_40'].to_numpy() + 0.5 * df_tm['prob_45'].to_numpy()\n",
        "keys_blend_te = df_tm[kcols].reset_index(drop=True)\n",
        "\n",
        "# Distance from r=4.5 test for caps\n",
        "te45_sorted = te45.sort_values(kcols).reset_index(drop=True)\n",
        "df_dist_t = te45_sorted[kcols + ['distance']].copy().merge(keys_blend_te, on=kcols, how='right')\n",
        "dist_t_sorted = df_dist_t['distance'].astype(float).to_numpy()\n",
        "pt_cap = apply_distance_cap_smoothed(keys_blend_te, pt_blend, dist_t_sorted, caps=(3,2,1), bins=(1.6, 2.4))\n",
        "print('Applied distance-aware caps (3/2/1) on test blend.')\n",
        "\n",
        "# same_team from r=4.5 test\n",
        "same_flag_test = te45.sort_values(kcols).reset_index(drop=True)[kcols + ['same_team']].copy().merge(keys_blend_te, on=kcols, how='right')\n",
        "same_arr_t = same_flag_test['same_team'].fillna(0).astype(int).to_numpy() if 'same_team' in same_flag_test.columns else np.zeros(len(keys_blend_te), int)\n",
        "thr_arr_t = np.where(same_arr_t == 1, thr_same_med, thr_opp_med)\n",
        "pred_bin_t = (pt_cap >= thr_arr_t).astype(int)\n",
        "df_tmp_t = keys_blend_te.copy()\n",
        "df_tmp_t['pred_bin'] = pred_bin_t\n",
        "pred_h_t = apply_hyst_per_pair(df_tmp_t)\n",
        "\n",
        "# Build submission with PP only (skip prior G overwrite)\n",
        "cid_sorted = (keys_blend_te['game_play'].astype(str) + '_' + keys_blend_te['step'].astype(str) + '_' + keys_blend_te['p1'].astype(str) + '_' + keys_blend_te['p2'].astype(str))\n",
        "pred_df_pp = pd.DataFrame({'contact_id': cid_sorted.values, 'contact_pp': pred_h_t.astype(int)})\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "sub = ss.merge(pred_df_pp, on='contact_id', how='left')\n",
        "sub['contact'] = sub['contact_pp'].fillna(0).astype(int)\n",
        "sub = sub.drop(columns=['contact_pp'])\n",
        "pp_ones = int(sub['contact'].sum())\n",
        "print('PP (blend r40/r45 + cap3/2/1 thr-after-hyst) ones:', pp_ones)\n",
        "\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv. Took {:.1f}s'.format(time.time()-t0))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgboost version (pp-blend-r40-r45-cap321-thr-after-hyst): 2.1.4\nLoading r=4.0 and r=4.5 supervised dyn train and test features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using features r40: 50 r45: 50\nTraining r=4.0 ...\n  seed 42 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 0 done in 36.7s; best_it=3253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 1 done in 40.3s; best_it=3632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 2 done in 37.7s; best_it=3326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 3 done in 38.9s; best_it=3446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 4 done in 37.6s; best_it=3468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 0 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 1 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 2 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 3 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 4 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 1337 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 0 done in 38.2s; best_it=3385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 1 done in 40.4s; best_it=3608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 2 done in 36.3s; best_it=3140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 3 done in 38.7s; best_it=3378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 4 done in 39.7s; best_it=3609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 0 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 1 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 2 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 3 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 4 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 2025 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 0 done in 39.2s; best_it=3453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 1 done in 38.7s; best_it=3408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 2 done in 37.8s; best_it=3284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 3 done in 41.0s; best_it=3573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 4 done in 37.5s; best_it=3388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 0 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 1 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 2 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 3 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 4 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training r=4.5 ...\n  seed 42 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 0 done in 46.6s; best_it=3688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 1 done in 45.1s; best_it=3754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 2 done in 43.3s; best_it=3466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 3 done in 40.9s; best_it=3177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 4 done in 44.9s; best_it=3799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 0 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 1 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 2 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 3 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 4 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 1337 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 0 done in 45.1s; best_it=3799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 1 done in 45.5s; best_it=3799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 2 done in 45.2s; best_it=3467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 3 done in 39.3s; best_it=2982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 4 done in 46.3s; best_it=3777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 0 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 1 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 2 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 3 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 4 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 2025 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 0 done in 44.7s; best_it=3798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 1 done in 45.4s; best_it=3796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 2 done in 45.9s; best_it=3519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 3 done in 44.1s; best_it=3358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    fold 4 done in 45.4s; best_it=3716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 0 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 1 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 2 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 3 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    test model 4 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied distance-aware cap (3/2/1) to blended OOF. Kept nonzero: 440775 of 634192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fold 0 best after-hyst MCC=0.71737 thr_opp=0.800 thr_same=0.820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fold 1 best after-hyst MCC=0.74015 thr_opp=0.840 thr_same=0.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fold 2 best after-hyst MCC=0.73547 thr_opp=0.840 thr_same=0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fold 3 best after-hyst MCC=0.73442 thr_opp=0.740 thr_same=0.740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fold 4 best after-hyst MCC=0.73501 thr_opp=0.810 thr_same=0.850\nFold-median thresholds after hysteresis (blend r40/r45 cap3/2/1): thr_opp=0.8100, thr_same=0.8200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied distance-aware caps (3/2/1) on test blend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PP (blend r40/r45 + cap3/2/1 thr-after-hyst) ones: 6428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv. Took 2226.8s\n"
          ]
        }
      ]
    },
    {
      "id": "6727faf1-8756-4eee-a5a9-753dfaccb257",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Single r=4.5 PP pipeline (bug-fixed caps) + Integrated G-head (patched); thresholds after hysteresis; OR combine; write submission.csv\n",
        "import os, time, sys, json, gc, math, itertools, warnings\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import xgboost as xgb\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "t0 = time.time()\n",
        "print('xgboost version (single-r45-pp+g, cap321-fix, thr-after-hyst):', xgb.__version__, flush=True)\n",
        "\n",
        "# -------------------- IO --------------------\n",
        "train_sup_fp = 'train_supervised_w5_helm_dyn_r45.parquet'\n",
        "test_sup_fp  = 'test_pairs_w5_helm_dyn_r45.parquet'\n",
        "folds_fp     = 'folds_game_play.csv'\n",
        "\n",
        "assert Path(train_sup_fp).exists() and Path(test_sup_fp).exists(), 'Supervised r45 parquet files missing.'\n",
        "folds_df = pd.read_csv(folds_fp)\n",
        "\n",
        "# -------------------- Load supervised (r=4.5) --------------------\n",
        "print('Loading r=4.5 supervised train/test...', flush=True)\n",
        "train_df = pd.read_parquet(train_sup_fp)\n",
        "test_df  = pd.read_parquet(test_sup_fp)\n",
        "\n",
        "# Expected columns keys: ['game_play','step','p1','p2','same_team','distance', ..., 'contact' in train]\n",
        "key_cols = ['game_play','step','p1','p2']\n",
        "for c in key_cols + ['same_team','distance']:\n",
        "    assert c in train_df.columns, f'missing {c} in train_df'\n",
        "    assert c in test_df.columns, f'missing {c} in test_df'\n",
        "assert 'contact' in train_df.columns\n",
        "\n",
        "# Merge folds on game_play\n",
        "train_df = train_df.merge(folds_df[['game_play','fold']], on='game_play', how='left')\n",
        "assert train_df['fold'].notnull().all(), 'fold assignment missing for some rows'\n",
        "\n",
        "# Features: drop keys/target/leak columns\n",
        "drop_cols = set(key_cols + ['contact','fold'])\n",
        "feat_cols = [c for c in train_df.columns if c not in drop_cols and train_df[c].dtype != 'O']\n",
        "meta_cols = key_cols + ['same_team','distance']\n",
        "meta_cols_merge = key_cols  # use only unique key for merges\n",
        "print(f'Using {len(feat_cols)} features', flush=True)\n",
        "\n",
        "# -------------------- Helpers --------------------\n",
        "def add_group_sort_index(df):\n",
        "    # canonical sort: do NOT include same_team in ordering\n",
        "    return df.sort_values(['game_play','p1','p2','step'], kind='mergesort').reset_index(drop=True)\n",
        "\n",
        "def roll_max_centered_by_group(df, prob_col, group_cols, win=3):\n",
        "    # transform preserves alignment; no index juggling\n",
        "    return df.groupby(group_cols, sort=False)[prob_col].transform(\n",
        "        lambda x: x.rolling(window=win, center=True, min_periods=1).max()\n",
        "    ).values\n",
        "\n",
        "def hysteresis_2of3_sorted(pred_bin: np.ndarray, df_sorted: pd.DataFrame, group_cols: list) -> np.ndarray:\n",
        "    assert isinstance(df_sorted.index, pd.RangeIndex)\n",
        "    arr = pred_bin.astype(np.uint8)\n",
        "    gvals = df_sorted[group_cols].to_numpy()\n",
        "\n",
        "    new_group = np.zeros(len(df_sorted), dtype=bool)\n",
        "    new_group[1:] = (gvals[1:] != gvals[:-1]).any(axis=1)\n",
        "    end_group = np.zeros(len(df_sorted), dtype=bool)\n",
        "    end_group[:-1] = new_group[1:]\n",
        "    end_group[-1] = True\n",
        "\n",
        "    prev = np.r_[arr[0], arr[:-1]]\n",
        "    prev[new_group] = arr[new_group]\n",
        "    nxt = np.r_[arr[1:], arr[-1]]\n",
        "    nxt[end_group] = arr[end_group]\n",
        "\n",
        "    out = (arr + prev + nxt >= 2).astype(np.uint8)\n",
        "    return out\n",
        "\n",
        "def mcc_fast(y_true, y_pred):\n",
        "    return matthews_corrcoef(y_true, y_pred)\n",
        "\n",
        "def apply_dual_threshold(proba, same_team, thr_opp, thr_same):\n",
        "    thr = np.where(same_team.astype(np.int8)==1, thr_same, thr_opp)\n",
        "    return (proba >= thr).astype(np.uint8)\n",
        "\n",
        "def distance_bin_from_val(d):\n",
        "    if d <= 1.6: return 0\n",
        "    if d <= 2.4: return 1\n",
        "    return 2\n",
        "\n",
        "def apply_distance_caps_bugfixed(df_keys_meta, prob_smoothed):\n",
        "    n = len(df_keys_meta)\n",
        "    assert n == len(prob_smoothed)\n",
        "    df = df_keys_meta.copy().reset_index(drop=True)\n",
        "    df['prob_s'] = prob_smoothed.astype(np.float64)\n",
        "    df['bin'] = df['distance'].apply(distance_bin_from_val).astype(np.int8)\n",
        "    df['idx'] = np.arange(len(df), dtype=np.int64)\n",
        "    a = df[['game_play','step','p1','bin','prob_s','idx']].rename(columns={'p1':'player'})\n",
        "    b = df[['game_play','step','p2','bin','prob_s','idx']].rename(columns={'p2':'player'})\n",
        "    long = pd.concat([a,b], axis=0, ignore_index=True)\n",
        "    cap_map = {0:3, 1:2, 2:1}\n",
        "    long['cap'] = long['bin'].map(cap_map).astype(np.int8)\n",
        "    long['rank'] = long.groupby(['game_play','step','player','bin'], sort=False)['prob_s'].rank(method='first', ascending=False)\n",
        "    keep_long = long[long['rank'] <= long['cap']]\n",
        "    keep_ids = set(keep_long['idx'].values.tolist())\n",
        "    keep_mask = np.isin(np.arange(len(df)), list(keep_ids))\n",
        "    return keep_mask\n",
        "\n",
        "def train_xgb_pp(X_train, y_train, X_valid, y_valid, params):\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
        "    booster = xgb.train(params=params, dtrain=dtrain, num_boost_round=20000, evals=[(dvalid,'valid')],\n",
        "                        early_stopping_rounds=400, verbose_eval=False)\n",
        "    return booster\n",
        "\n",
        "def train_xgb_g(X_train, y_train, X_valid, y_valid, params):\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
        "    booster = xgb.train(params=params, dtrain=dtrain, num_boost_round=6000, evals=[(dvalid,'valid')],\n",
        "                        early_stopping_rounds=200, verbose_eval=False)\n",
        "    return booster\n",
        "\n",
        "def predict_xgb(booster, X):\n",
        "    return booster.predict(xgb.DMatrix(X), iteration_range=(0, booster.best_iteration+1))\n",
        "\n",
        "# -------------------- PP model: 3-seed bagging, OOF/test --------------------\n",
        "seeds = [42, 1337, 2025]\n",
        "groups = train_df['game_play'].values\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "oof_pred_accum = np.zeros((len(train_df),), dtype=np.float64)\n",
        "test_pred_accum = np.zeros((len(test_df),), dtype=np.float64)\n",
        "\n",
        "# compute scale_pos_weight (cap for stability)\n",
        "pos = float(train_df['contact'].sum())\n",
        "neg = float(len(train_df) - pos)\n",
        "spw = max(1.0, neg / max(1.0, pos))\n",
        "spw = min(spw, 5.0)\n",
        "print(f'scale_pos_weight={spw:.2f} (neg={neg:.0f}, pos={pos:.0f})', flush=True)\n",
        "\n",
        "params_base = {\n",
        "    'objective':'binary:logistic',\n",
        "    'eval_metric':'logloss',\n",
        "    'tree_method':'gpu_hist',\n",
        "    'max_depth':7,\n",
        "    'eta':0.05,\n",
        "    'subsample':0.8,\n",
        "    'colsample_bytree':0.8,\n",
        "    'min_child_weight':10,\n",
        "    'lambda':1.0,\n",
        "    'scale_pos_weight': spw,\n",
        "}\n",
        "\n",
        "print('Training PP r=4.5 single model (3 seeds)...', flush=True)\n",
        "for sd in seeds:\n",
        "    params = params_base.copy()\n",
        "    params['seed'] = sd\n",
        "    fold_idx = 0\n",
        "    for tr_idx, va_idx in gkf.split(train_df, train_df['contact'].values, groups):\n",
        "        t1 = time.time()\n",
        "        X_tr = train_df.iloc[tr_idx][feat_cols].values\n",
        "        y_tr = train_df.iloc[tr_idx]['contact'].values.astype(np.float32)\n",
        "        X_va = train_df.iloc[va_idx][feat_cols].values\n",
        "        y_va = train_df.iloc[va_idx]['contact'].values.astype(np.float32)\n",
        "        bst = train_xgb_pp(X_tr, y_tr, X_va, y_va, params)\n",
        "        oof_pred_accum[va_idx] += predict_xgb(bst, X_va)\n",
        "        test_pred_accum += predict_xgb(bst, test_df[feat_cols].values)\n",
        "        dt = time.time()-t1\n",
        "        print(f'  seed {sd} fold {fold_idx} done in {dt:.1f}s; best_it={bst.best_iteration}', flush=True)\n",
        "        del bst; gc.collect()\n",
        "        fold_idx += 1\n",
        "\n",
        "oof_pred = oof_pred_accum / len(seeds)\n",
        "test_pred = test_pred_accum / (len(seeds)*5)\n",
        "print('PP bagging complete.', flush=True)\n",
        "\n",
        "# -------------------- Roll-max smoothing (centered w=3) --------------------\n",
        "train_meta = train_df[key_cols + ['same_team','distance']].copy().reset_index(drop=True)\n",
        "test_meta  = test_df[key_cols + ['same_team','distance']].copy().reset_index(drop=True)\n",
        "\n",
        "train_meta['proba'] = oof_pred\n",
        "test_meta['proba']  = test_pred\n",
        "\n",
        "train_meta = add_group_sort_index(train_meta)\n",
        "test_meta  = add_group_sort_index(test_meta)\n",
        "\n",
        "train_meta['proba_s'] = roll_max_centered_by_group(train_meta, 'proba', ['game_play','p1','p2'], win=3)\n",
        "test_meta['proba_s']  = roll_max_centered_by_group(test_meta,  'proba', ['game_play','p1','p2'], win=3)\n",
        "\n",
        "# -------------------- Distance-aware caps (3/2/1) with bug-fixed mask --------------------\n",
        "keep_mask_train = apply_distance_caps_bugfixed(train_meta[key_cols + ['same_team','distance']], train_meta['proba_s'].values)\n",
        "keep_mask_test  = apply_distance_caps_bugfixed(test_meta[key_cols + ['same_team','distance']],  test_meta['proba_s'].values)\n",
        "print(f'Applied distance-aware caps. Train kept_nonzero: {keep_mask_train.sum()} of {len(keep_mask_train)}', flush=True)\n",
        "print(f'Applied distance-aware caps. Test  kept_nonzero: {keep_mask_test.sum()} of {len(keep_mask_test)}', flush=True)\n",
        "\n",
        "train_meta['proba_sc'] = np.where(keep_mask_train, train_meta['proba_s'].values, 0.0)\n",
        "test_meta['proba_sc']  = np.where(keep_mask_test,  test_meta['proba_s'].values,  0.0)\n",
        "\n",
        "# Bring back to original train/test row order via deterministic key merge (keys only, not same_team)\n",
        "orig_train = train_df[key_cols + ['same_team','distance','contact','fold']].reset_index(drop=True).copy()\n",
        "tmp = train_meta.reset_index(drop=True).copy()\n",
        "m_train = orig_train.merge(tmp[meta_cols_merge + ['proba_sc']], on=meta_cols_merge, how='left', validate='one_to_one')\n",
        "assert m_train['proba_sc'].notnull().all(), 'alignment failure in train_meta'\n",
        "\n",
        "orig_test = test_df[key_cols + ['same_team','distance']].reset_index(drop=True).copy()\n",
        "tmp2 = test_meta.reset_index(drop=True).copy()\n",
        "m_test = orig_test.merge(tmp2[meta_cols_merge + ['proba_sc']], on=meta_cols_merge, how='left', validate='one_to_one')\n",
        "assert m_test['proba_sc'].notnull().all(), 'alignment failure in test_meta'\n",
        "\n",
        "# Quantiles sanity per fold (after smoothing+caps)\n",
        "for f in sorted(train_df['fold'].unique()):\n",
        "    m = (train_df['fold'].values == f)\n",
        "    q = np.quantile(m_train.loc[m, 'proba_sc'].values, [0, 0.5, 0.9, 0.99])\n",
        "    print(f'PP fold {f} proba_sc quantiles:', q, flush=True)\n",
        "\n",
        "# -------------------- Threshold optimization AFTER hysteresis (per-fold), then fold-median --------------------\n",
        "thr_grid = np.round(np.arange(0.60, 0.921, 0.02), 3)\n",
        "sort_cols_pp = ['game_play','p1','p2','step']\n",
        "best_by_fold = []\n",
        "for f in sorted(train_df['fold'].unique()):\n",
        "    mask_f = (train_df['fold'].values == f)\n",
        "    df_f = m_train.loc[mask_f, ['game_play','p1','p2','step','same_team','distance','proba_sc','contact']].copy()\n",
        "    df_f = df_f.sort_values(sort_cols_pp).reset_index(drop=True)\n",
        "    assert isinstance(df_f.index, pd.RangeIndex)\n",
        "    y = df_f['contact'].astype(int).values\n",
        "    best_mcc = -1.0; best_thr = (0.80, 0.80)\n",
        "    for thr_opp in thr_grid:\n",
        "        for thr_same in thr_grid:\n",
        "            pred_bin = apply_dual_threshold(df_f['proba_sc'].values, df_f['same_team'].values, thr_opp, thr_same)\n",
        "            pred_hyst = hysteresis_2of3_sorted(pred_bin, df_f, ['game_play','p1','p2'])\n",
        "            mcc = mcc_fast(y, pred_hyst)\n",
        "            if mcc > best_mcc:\n",
        "                best_mcc = mcc; best_thr = (thr_opp, thr_same)\n",
        "    print(f' Fold {f} best after-hyst MCC={best_mcc:.5f} thr_opp={best_thr[0]:.3f} thr_same={best_thr[1]:.3f}', flush=True)\n",
        "    best_by_fold.append((f, best_mcc, best_thr[0], best_thr[1]))\n",
        "\n",
        "thr_opp_med = float(np.median([t[2] for t in best_by_fold]))\n",
        "thr_same_med = float(np.median([t[3] for t in best_by_fold]))\n",
        "print(f'Fold-median thresholds after hysteresis (PP r45): thr_opp={thr_opp_med:.4f}, thr_same={thr_same_med:.4f}', flush=True)\n",
        "\n",
        "# Apply to test: sort -> threshold -> hysteresis -> restore original order\n",
        "m_test_sorted = m_test.copy()\n",
        "m_test_sorted['_orig_idx'] = np.arange(len(m_test_sorted))\n",
        "m_test_sorted = m_test_sorted.sort_values(sort_cols_pp).reset_index(drop=True)\n",
        "assert isinstance(m_test_sorted.index, pd.RangeIndex)\n",
        "# Apply a small test-only threshold offset\n",
        "pp_thr_offset = -0.02\n",
        "thr_opp_med_t = max(0.0, thr_opp_med - pp_thr_offset)\n",
        "thr_same_med_t = max(0.0, thr_same_med - pp_thr_offset)\n",
        "pp_test_bin_sorted = apply_dual_threshold(m_test_sorted['proba_sc'].values, m_test_sorted['same_team'].values, thr_opp_med_t, thr_same_med_t)\n",
        "pp_test_bin_sorted = hysteresis_2of3_sorted(pp_test_bin_sorted, m_test_sorted, ['game_play','p1','p2'])\n",
        "pp_test_bin = np.zeros((len(m_test),), dtype=np.uint8)\n",
        "pp_test_bin[m_test_sorted['_orig_idx'].values] = pp_test_bin_sorted\n",
        "\n",
        "# Build canonical PP contact_id and in-sample PP count\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "ss_set = set(ss['contact_id'].astype(str))\n",
        "p1i = m_test['p1'].astype(int).to_numpy()\n",
        "p2i = m_test['p2'].astype(int).to_numpy()\n",
        "stepi = m_test['step'].astype(int).to_numpy()\n",
        "pmin = np.minimum(p1i, p2i)\n",
        "pmax = np.maximum(p1i, p2i)\n",
        "cid_pp = (m_test['game_play'].astype(str) + '_' + stepi.astype(str) + '_' + pmin.astype(str) + '_' + pmax.astype(str)).astype(str)\n",
        "pp_in_mask = cid_pp.isin(ss_set).to_numpy()\n",
        "pp_pos = int(pp_test_bin.sum())\n",
        "pp_pos_in = int((pp_test_bin.astype(bool) & pp_in_mask).sum())\n",
        "print(f'PP positives after full chain: {pp_pos} (in-sample: {pp_pos_in})', flush=True)\n",
        "\n",
        "# -------------------- G-head (integrated, PATCHED) --------------------\n",
        "print('Training G-head (per-player) ...', flush=True)\n",
        "train_trk = pd.read_csv('train_player_tracking.csv')\n",
        "test_trk  = pd.read_csv('test_player_tracking.csv')\n",
        "labels = pd.read_csv('train_labels.csv')\n",
        "\n",
        "# Normalize position column names if present\n",
        "rename_map = {}\n",
        "if 'x_position' in train_trk.columns and 'y_position' in train_trk.columns:\n",
        "    rename_map.update({'x_position':'x','y_position':'y'})\n",
        "train_trk = train_trk.rename(columns=rename_map)\n",
        "test_trk  = test_trk.rename(columns=rename_map)\n",
        "\n",
        "# Minimal per-player features from tracking (select available)\n",
        "base_cols = ['game_play','step','nfl_player_id']\n",
        "cand_cols = ['x','y','speed','acceleration','o','dir']\n",
        "avail = [c for c in cand_cols if c in train_trk.columns]\n",
        "use_cols = base_cols + avail\n",
        "train_trk = train_trk[use_cols].copy()\n",
        "test_trk  = test_trk[[c for c in use_cols if c in test_trk.columns]].copy()\n",
        "\n",
        "# unify dtype for ids\n",
        "train_trk['nfl_player_id'] = train_trk['nfl_player_id'].astype(str)\n",
        "test_trk['nfl_player_id'] = test_trk['nfl_player_id'].astype(str)\n",
        "\n",
        "def add_player_feats(df):\n",
        "    df = df.sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "    for col in [c for c in ['x','y','speed','acceleration'] if c in df.columns]:\n",
        "        df[f'd_{col}'] = df.groupby(['game_play','nfl_player_id'])[col].diff().fillna(0.0)\n",
        "    if 'acceleration' in df.columns:\n",
        "        df['jerk'] = df.groupby(['game_play','nfl_player_id'])['acceleration'].diff().fillna(0.0)\n",
        "    if 'speed' in df.columns:\n",
        "        df['speed_drop_3'] = df['speed'] - df.groupby(['game_play','nfl_player_id'])['speed'].shift(3).fillna(df['speed'])\n",
        "        # rolling extrema (w=3) fast lifts\n",
        "        df['speed_min_3'] = df.groupby(['game_play','nfl_player_id'])['speed'].rolling(3, min_periods=1).min().reset_index(level=[0,1], drop=True)\n",
        "        df['speed_max_3'] = df.groupby(['game_play','nfl_player_id'])['speed'].rolling(3, min_periods=1).max().reset_index(level=[0,1], drop=True)\n",
        "    if 'acceleration' in df.columns:\n",
        "        df['accel_r3_min'] = df.groupby(['game_play','nfl_player_id'])['acceleration'].rolling(3, min_periods=1).min().reset_index(level=[0,1], drop=True)\n",
        "    if 'o' in df.columns:\n",
        "        df['d_o'] = df.groupby(['game_play','nfl_player_id'])['o'].diff().fillna(0.0)\n",
        "        df['d_o'] = (df['d_o'] + 180) % 360 - 180\n",
        "    if 'dir' in df.columns:\n",
        "        df['d_dir'] = df.groupby(['game_play','nfl_player_id'])['dir'].diff().fillna(0.0)\n",
        "        df['d_dir'] = (df['d_dir'] + 180) % 360 - 180\n",
        "    df['time_since_snap'] = df.groupby('game_play')['step'].transform(lambda s: s - s.min())\n",
        "    return df\n",
        "\n",
        "train_trk = add_player_feats(train_trk)\n",
        "test_trk  = add_player_feats(test_trk)\n",
        "\n",
        "# 1) Build opponent proximity from r=4.5 PP pair tables (feature only)\n",
        "def build_opp_prox_feats(df_pairs, dist_thr=3.5):\n",
        "    use = df_pairs.loc[df_pairs['same_team']==0, ['game_play','step','p1','p2','distance','approaching_flag','rel_speed']].copy()\n",
        "    a = use[['game_play','step','p1','distance','approaching_flag','rel_speed']].rename(columns={'p1':'nfl_player_id'})\n",
        "    b = use[['game_play','step','p2','distance','approaching_flag','rel_speed']].rename(columns={'p2':'nfl_player_id'})\n",
        "    long = pd.concat([a,b], ignore_index=True)\n",
        "    agg = long.groupby(['game_play','step','nfl_player_id'], as_index=False).agg(\n",
        "        min_opp_dist=('distance','min'),\n",
        "        has_approaching=('approaching_flag','max'),\n",
        "        max_rel_speed=('rel_speed','max')\n",
        "    )\n",
        "    agg['close_opp'] = (agg['min_opp_dist'] <= dist_thr).astype(np.int8)\n",
        "    agg['approaching_fast'] = ((agg['has_approaching']==1) | (agg['max_rel_speed'] >= 1.5)).astype(np.int8)\n",
        "    return agg\n",
        "\n",
        "prox_train = build_opp_prox_feats(train_df, dist_thr=3.5)\n",
        "prox_test  = build_opp_prox_feats(test_df,  dist_thr=3.5)\n",
        "prox_train['nfl_player_id'] = prox_train['nfl_player_id'].astype(str)\n",
        "prox_test['nfl_player_id']  = prox_test['nfl_player_id'].astype(str)\n",
        "\n",
        "train_trk = train_trk.merge(prox_train, on=['game_play','step','nfl_player_id'], how='left')\n",
        "test_trk  = test_trk.merge(prox_test,  on=['game_play','step','nfl_player_id'], how='left')\n",
        "for c in ['min_opp_dist','close_opp','approaching_fast','has_approaching','max_rel_speed']:\n",
        "    fill = 99.0 if c=='min_opp_dist' else 0\n",
        "    train_trk[c] = train_trk[c].fillna(fill)\n",
        "    test_trk[c]  = test_trk[c].fillna(fill)\n",
        "\n",
        "# Quick extra features\n",
        "train_trk['time_since_snap_sq'] = train_trk['time_since_snap']**2\n",
        "test_trk['time_since_snap_sq']  = test_trk['time_since_snap']**2\n",
        "train_trk = train_trk.sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "test_trk  = test_trk.sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "train_trk['min_opp_dist_lag'] = train_trk.groupby(['game_play','nfl_player_id'])['min_opp_dist'].shift(1)\n",
        "test_trk['min_opp_dist_lag']  = test_trk.groupby(['game_play','nfl_player_id'])['min_opp_dist'].shift(1)\n",
        "train_trk['min_opp_dist_lag'] = train_trk['min_opp_dist_lag'].fillna(train_trk['min_opp_dist'])\n",
        "test_trk['min_opp_dist_lag']  = test_trk['min_opp_dist_lag'].fillna(test_trk['min_opp_dist'])\n",
        "\n",
        "# Additional high-signal features (per expert advice)\n",
        "train_trk['d_min_opp_dist'] = np.clip(train_trk['min_opp_dist'] - train_trk['min_opp_dist_lag'], -2.0, 2.0)\n",
        "test_trk['d_min_opp_dist']  = np.clip(test_trk['min_opp_dist'] - test_trk['min_opp_dist_lag'], -2.0, 2.0)\n",
        "if 'speed_min_3' in train_trk.columns and 'speed_max_3' in train_trk.columns:\n",
        "    train_trk['speed_range_3'] = train_trk['speed_max_3'] - train_trk['speed_min_3']\n",
        "    test_trk['speed_range_3']  = test_trk['speed_max_3'] - test_trk['speed_min_3']\n",
        "train_trk['decel_and_close'] = (((train_trk.get('acceleration', pd.Series(0)).astype(float) <= -0.4) & (train_trk['min_opp_dist'].astype(float) <= 3.5)).astype(np.int8))\n",
        "test_trk['decel_and_close']  = (((test_trk.get('acceleration', pd.Series(0)).astype(float) <= -0.4) & (test_trk['min_opp_dist'].astype(float) <= 3.5)).astype(np.int8))\n",
        "\n",
        "# Build G labels from contact_id pattern: GP1_GP2_STEP_PLAYER_G (NO \u00b11 expansion)\n",
        "labels_g = labels[labels['contact_id'].str.endswith('_G')].copy()\n",
        "parts = labels_g['contact_id'].str.split('_')\n",
        "labels_g['game_play'] = parts.str[0] + '_' + parts.str[1]\n",
        "labels_g['step'] = parts.str[2].astype(int)\n",
        "labels_g['player'] = parts.str[3]\n",
        "labels_g = labels_g[['game_play','step','player','contact']].copy()\n",
        "\n",
        "train_trk['player'] = train_trk['nfl_player_id'].astype(str)\n",
        "train_g = train_trk.merge(labels_g, on=['game_play','step','player'], how='left')\n",
        "train_g['contact'] = train_g['contact'].fillna(0).astype(int)\n",
        "\n",
        "# G folds by game_play\n",
        "gp_g = train_g['game_play'].values\n",
        "gkf_g = GroupKFold(n_splits=5)\n",
        "g_feat_drop = set(['game_play','step','nfl_player_id','player','contact'])\n",
        "g_feat_cols = [c for c in train_g.columns if c not in g_feat_drop and train_g[c].dtype != 'O']\n",
        "for _c in ['time_since_snap_sq','min_opp_dist_lag']:\n",
        "    if _c not in g_feat_cols and _c in train_g.columns:\n",
        "        g_feat_cols.append(_c)\n",
        "print(f'G-head features: {len(g_feat_cols)}', flush=True)\n",
        "\n",
        "g_oof_accum = np.zeros((len(train_g),), dtype=np.float64)\n",
        "g_test_accum = np.zeros((len(test_trk),), dtype=np.float64)\n",
        "\n",
        "for sd in seeds:\n",
        "    fi = 0\n",
        "    for tr_idx, va_idx in gkf_g.split(train_g, train_g['contact'].values, gp_g):\n",
        "        X_tr = train_g.iloc[tr_idx][g_feat_cols].values\n",
        "        y_tr = train_g.iloc[tr_idx]['contact'].values.astype(np.float32)\n",
        "        X_va = train_g.iloc[va_idx][g_feat_cols].values\n",
        "        y_va = train_g.iloc[va_idx]['contact'].values.astype(np.float32)\n",
        "        # per-fold SPW with clip and stronger regularization\n",
        "        posc = float((y_tr==1).sum()); negc = float(len(y_tr)-posc)\n",
        "        spw_g = min(max(1.0, negc / max(1.0, posc)), 5.0)\n",
        "        params_g = {\n",
        "            'objective':'binary:logistic',\n",
        "            'eval_metric':'logloss',\n",
        "            'tree_method':'gpu_hist',\n",
        "            'max_depth':6,\n",
        "            'eta':0.04,\n",
        "            'subsample':0.8,\n",
        "            'colsample_bytree':0.75,\n",
        "            'min_child_weight':20,\n",
        "            'lambda':2.5,\n",
        "            'alpha':0.3,\n",
        "            'max_delta_step':1,\n",
        "            'scale_pos_weight': spw_g,\n",
        "            'seed': int(sd)\n",
        "        }\n",
        "        bst = train_xgb_g(X_tr, y_tr, X_va, y_va, params_g)\n",
        "        g_oof_accum[va_idx] += predict_xgb(bst, X_va)\n",
        "        g_test_accum += predict_xgb(bst, test_trk[g_feat_cols].values)\n",
        "        print(f'  G seed {sd} fold {fi} best_it={bst.best_iteration}', flush=True)\n",
        "        del bst; gc.collect(); fi += 1\n",
        "\n",
        "g_oof = g_oof_accum / len(seeds)\n",
        "g_test = g_test_accum / (len(seeds)*5)\n",
        "\n",
        "# Post-proc for G (patched order):\n",
        "# 1) Build meta with proba_raw\n",
        "train_g_meta = train_trk[['game_play','step','nfl_player_id','speed','acceleration','speed_drop_3','time_since_snap','close_opp']].copy().reset_index(drop=True)\n",
        "test_g_meta  = test_trk[['game_play','step','nfl_player_id','speed','acceleration','speed_drop_3','time_since_snap','close_opp']].copy().reset_index(drop=True)\n",
        "train_g_meta['proba_raw'] = g_oof\n",
        "test_g_meta['proba_raw']  = g_test\n",
        "\n",
        "# 2) Kinematic-first gate on raw probabilities (relaxed thresholds)\n",
        "def kinematic_gate(df):\n",
        "    speed = df['speed'] if 'speed' in df.columns else pd.Series(1.0, index=df.index)\n",
        "    accel = df['acceleration'] if 'acceleration' in df.columns else pd.Series(0.0, index=df.index)\n",
        "    sdrop = df['speed_drop_3'] if 'speed_drop_3' in df.columns else pd.Series(0.0, index=df.index)\n",
        "    tss = df['time_since_snap'] if 'time_since_snap' in df.columns else pd.Series(0, index=df.index)\n",
        "    gate = ((speed <= 1.6) | (accel <= -0.3) | (sdrop <= -0.3)) & (tss >= 2)\n",
        "    return gate.values\n",
        "\n",
        "train_gate = kinematic_gate(train_g_meta)\n",
        "test_gate  = kinematic_gate(test_g_meta)\n",
        "print('G gate train True:', int(train_gate.sum()), 'of', len(train_gate), flush=True)\n",
        "print('G gate test  True:', int(test_gate.sum()),  'of', len(test_gate),  flush=True)\n",
        "train_g_meta['proba_raw'] = np.where(train_gate, train_g_meta['proba_raw'].values, 0.0)\n",
        "test_g_meta['proba_raw']  = np.where(test_gate,  test_g_meta['proba_raw'].values,  0.0)\n",
        "print('Nonzero proba_raw after gate (train/test):', int((train_g_meta['proba_raw']>0).sum()), int((test_g_meta['proba_raw']>0).sum()), flush=True)\n",
        "if (train_g_meta['proba_raw']>0).any():\n",
        "    print('Train proba_raw gated quantiles:', np.quantile(train_g_meta.loc[train_g_meta['proba_raw']>0,'proba_raw'].values, [0.9,0.95,0.99,0.999]), flush=True)\n",
        "if (test_g_meta['proba_raw']>0).any():\n",
        "    print('Test proba_raw gated quantiles:', np.quantile(test_g_meta.loc[test_g_meta['proba_raw']>0,'proba_raw'].values, [0.9,0.95,0.99,0.999]), flush=True)\n",
        "\n",
        "# 3) Cap top-k per (game_play, step) on RAW proba (alignment-safe, no reordering)\n",
        "def cap_topk_rank_inplace(df: pd.DataFrame, proba_col: str, k: int = 1, min_prob: float = 0.0) -> np.ndarray:\n",
        "    ranks = df.groupby(['game_play','step'], sort=False)[proba_col].rank(method='first', ascending=False)\n",
        "    keep = (ranks <= k) & (df[proba_col] >= min_prob)\n",
        "    out = np.where(keep.values, df[proba_col].values, 0.0).astype(np.float64)\n",
        "    # Assert cap holds\n",
        "    cnt = df.assign(_nz=(out>0).astype(int)).groupby(['game_play','step'], sort=False)['_nz'].sum().max()\n",
        "    assert int(cnt) <= k, f'Cap violation: found {int(cnt)} > k={k} per step'\n",
        "    return out\n",
        "\n",
        "k_cap = 2\n",
        "min_prob_cap = 0.0\n",
        "train_g_meta['proba_gc'] = cap_topk_rank_inplace(train_g_meta, 'proba_raw', k=k_cap, min_prob=min_prob_cap)\n",
        "test_g_meta['proba_gc']  = cap_topk_rank_inplace(test_g_meta,  'proba_raw', k=k_cap, min_prob=min_prob_cap)\n",
        "print('Test G candidates after cap (proba_gc>0):', int((test_g_meta['proba_gc']>0).sum()), flush=True)\n",
        "\n",
        "# 4) Light smoothing AFTER cap (w=3)\n",
        "def roll_max_centered_by_group_player(df, prob_col, win=3):\n",
        "    return df.groupby(['game_play','nfl_player_id'], sort=False)[prob_col].transform(\n",
        "        lambda x: x.rolling(win, center=True, min_periods=1).max()\n",
        "    ).values\n",
        "\n",
        "train_g_meta = train_g_meta.sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "test_g_meta  = test_g_meta.sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "train_g_meta['proba_gcs'] = roll_max_centered_by_group_player(train_g_meta, 'proba_gc', win=3)\n",
        "test_g_meta['proba_gcs']  = roll_max_centered_by_group_player(test_g_meta,  'proba_gc', win=3)\n",
        "if (train_g_meta['proba_gcs']>0).any():\n",
        "    print('Train proba_gcs gated quantiles:', np.quantile(train_g_meta.loc[train_g_meta['proba_gcs']>0,'proba_gcs'].values, [0.9,0.95,0.99]), flush=True)\n",
        "if (test_g_meta['proba_gcs']>0).any():\n",
        "    print('Test proba_gcs gated quantiles:', np.quantile(test_g_meta.loc[test_g_meta['proba_gcs']>0,'proba_gcs'].values, [0.9,0.95,0.99]), flush=True)\n",
        "\n",
        "# attach labels to train_g_meta for thresholding\n",
        "train_g_meta = train_g_meta.merge(train_g[['game_play','step','nfl_player_id','contact']], on=['game_play','step','nfl_player_id'], how='left', validate='one_to_one')\n",
        "train_g_meta['contact'] = train_g_meta['contact'].fillna(0).astype(int)\n",
        "\n",
        "# Threshold search grid and RATE-based guardrail per fold\n",
        "thr_grid_g = np.round(np.arange(0.42, 0.905, 0.005), 3)\n",
        "best_thr_g = []\n",
        "for f in sorted(np.unique(train_df['fold'].values)):\n",
        "    gps_fold = set(train_df.loc[train_df['fold']==f, 'game_play'].unique().tolist())\n",
        "    idx = train_g_meta['game_play'].isin(gps_fold).values\n",
        "    df_f = train_g_meta.loc[idx].copy()\n",
        "    df_f = df_f.sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "    assert isinstance(df_f.index, pd.RangeIndex)\n",
        "    y = df_f['contact'].values.astype(int)\n",
        "    fold_size = len(df_f)\n",
        "    cap_rate = 0.0125\n",
        "    cap_pos = int(np.floor(cap_rate * fold_size))\n",
        "    nz = int((df_f['proba_gcs']>0).sum())\n",
        "    print(f' G Fold {f}: fold_size={fold_size} cap_pos={cap_pos} nz={nz}', flush=True)\n",
        "    best_mcc=-1.0; best_thr=None; best_pos=None\n",
        "    for thr in thr_grid_g:\n",
        "        pred = (df_f['proba_gcs'].values >= thr).astype(np.uint8)\n",
        "        pred_h = hysteresis_2of3_sorted(pred, df_f, ['game_play','nfl_player_id'])\n",
        "        num_pos = int(pred_h.sum())\n",
        "        if num_pos > cap_pos:\n",
        "            continue\n",
        "        mcc = mcc_fast(y, pred_h)\n",
        "        if mcc > best_mcc:\n",
        "            best_mcc = mcc; best_thr = float(thr); best_pos = num_pos\n",
        "    if best_thr is None:\n",
        "        # fallback: choose highest thr with <= cap_pos; if none, use 0.98\n",
        "        fallback_thr = None; fallback_pos = None\n",
        "        for thr in thr_grid_g[::-1]:\n",
        "            pred = (df_f['proba_gcs'].values >= thr).astype(np.uint8)\n",
        "            pred_h = hysteresis_2of3_sorted(pred, df_f, ['game_play','nfl_player_id'])\n",
        "            num_pos = int(pred_h.sum())\n",
        "            if num_pos <= cap_pos:\n",
        "                fallback_thr = float(thr); fallback_pos = int(num_pos); break\n",
        "        if fallback_thr is None:\n",
        "            fallback_thr = 0.98; fallback_pos = -1\n",
        "        best_thr = fallback_thr; best_pos = fallback_pos\n",
        "    cap_flag = 'CAP95' if (best_pos is not None and cap_pos > 0 and best_pos >= 0.95*cap_pos) else ''\n",
        "    print(f' G Fold {f} best after-hyst thr={best_thr:.3f} pos={best_pos} (cap={cap_pos}) {cap_flag}', flush=True)\n",
        "    best_thr_g.append(best_thr)\n",
        "\n",
        "thr_g_med = float(np.median(best_thr_g))\n",
        "print(f'G fold-median threshold after hysteresis: thr_g={thr_g_med:.4f}', flush=True)\n",
        "\n",
        "# Apply to test G: optional test-side threshold scan to hit target G=1.5k-1.8k with combined<=8.8k (in-sample counts)\n",
        "test_g_meta_sorted = test_g_meta.copy()\n",
        "test_g_meta_sorted['_orig_idx'] = np.arange(len(test_g_meta_sorted))\n",
        "test_g_meta_sorted = test_g_meta_sorted.sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "assert isinstance(test_g_meta_sorted.index, pd.RangeIndex)\n",
        "thr_test = float(thr_g_med)\n",
        "target_lo, target_hi = 1500, 1800\n",
        "# Build canonical G contact_id for original-order meta and in-sample mask\n",
        "stepi_go = test_g_meta['step'].astype(int).to_numpy()\n",
        "pidi_go = test_g_meta['nfl_player_id'].astype(int).to_numpy()\n",
        "cid_g_orig = (test_g_meta['game_play'].astype(str) + '_' + stepi_go.astype(str) + '_' + pidi_go.astype(str) + '_G').astype(str)\n",
        "g_in_mask_orig = cid_g_orig.isin(ss_set).to_numpy()\n",
        "for thr in thr_grid_g[::-1]:  # high -> low\n",
        "    pred_sorted = (test_g_meta_sorted['proba_gcs'].values >= thr).astype(np.uint8)\n",
        "    pred_sorted = hysteresis_2of3_sorted(pred_sorted, test_g_meta_sorted, ['game_play','nfl_player_id'])\n",
        "    tmp = np.zeros((len(test_g_meta_sorted),), dtype=np.uint8)\n",
        "    tmp[test_g_meta_sorted['_orig_idx'].values] = pred_sorted\n",
        "    g_cnt = int(tmp.sum())\n",
        "    g_cnt_in = int((tmp.astype(bool) & g_in_mask_orig).sum())\n",
        "    combined_cnt_in = int(pp_pos_in + g_cnt_in)\n",
        "    if (g_cnt_in >= target_lo) and (g_cnt_in <= target_hi) and (combined_cnt_in <= 8800):\n",
        "        thr_test = float(thr)\n",
        "        print(f'Override test thr_g to {thr_test:.3f} for G_in={g_cnt_in} and combined_in={combined_cnt_in}', flush=True)\n",
        "        break\n",
        "\n",
        "# Final apply to test with chosen thr_test\n",
        "g_test_bin_sorted = (test_g_meta_sorted['proba_gcs'].values >= thr_test).astype(np.uint8)\n",
        "g_test_bin_sorted = hysteresis_2of3_sorted(g_test_bin_sorted, test_g_meta_sorted, ['game_play','nfl_player_id'])\n",
        "g_test_bin = np.zeros((len(test_g_meta),), dtype=np.uint8)\n",
        "g_test_bin[test_g_meta_sorted['_orig_idx'].values] = g_test_bin_sorted\n",
        "g_pos = int(g_test_bin.sum())\n",
        "g_pos_in = int((g_test_bin.astype(bool) & g_in_mask_orig).sum())\n",
        "print(f'G positives after full chain (gated+cap): {g_pos} (in-sample: {g_pos_in})', flush=True)\n",
        "\n",
        "# -------------------- Build submission: OR combine PP and G with canonical IDs --------------------\n",
        "# PP rows (canonical p_min/p_max)\n",
        "sub_pp = pd.DataFrame({'contact_id': cid_pp.astype(str), 'contact': pp_test_bin.astype(int)})\n",
        "# G rows (canonical)\n",
        "stepi_g = test_g_meta['step'].astype(int).to_numpy()\n",
        "pidi_g = test_g_meta['nfl_player_id'].astype(int).to_numpy()\n",
        "cid_g = (test_g_meta['game_play'].astype(str) + '_' + stepi_g.astype(str) + '_' + pidi_g.astype(str) + '_G').astype(str)\n",
        "sub_g = pd.DataFrame({'contact_id': cid_g.astype(str), 'contact': g_test_bin.astype(int)})\n",
        "sub_g = sub_g[sub_g['contact'] > 0]\n",
        "\n",
        "# Combine via OR, align to sample\n",
        "sub = pd.concat([sub_pp, sub_g], ignore_index=True).groupby('contact_id', as_index=False)['contact'].max()\n",
        "pp_in = int(sub.loc[sub['contact_id'].isin(ss_set) & (~sub['contact_id'].str.endswith('_G')), 'contact'].sum())\n",
        "g_in = int(sub.loc[sub['contact_id'].isin(ss_set) & (sub['contact_id'].str.endswith('_G')), 'contact'].sum())\n",
        "print(f'Final counts BEFORE merge (in-sample): PP={pp_in}, G={g_in}, combined={pp_in+g_in}', flush=True)\n",
        "sub = ss[['contact_id']].merge(sub, on='contact_id', how='left')\n",
        "sub['contact'] = sub['contact'].fillna(0).astype(int)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv', flush=True)\n",
        "print(f'Total time: {time.time()-t0:.1f}s', flush=True)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgboost version (single-r45-pp+g, cap321-fix, thr-after-hyst): 2.1.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading r=4.5 supervised train/test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 50 features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scale_pos_weight=5.00 (neg=696815, pos=48809)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training PP r=4.5 single model (3 seeds)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 42 fold 0 done in 36.3s; best_it=2533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 42 fold 1 done in 32.2s; best_it=2289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 42 fold 2 done in 29.1s; best_it=2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 42 fold 3 done in 28.0s; best_it=1951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 42 fold 4 done in 33.1s; best_it=2406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 1337 fold 0 done in 36.0s; best_it=2510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 1337 fold 1 done in 30.4s; best_it=2119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 1337 fold 2 done in 28.9s; best_it=1987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 1337 fold 3 done in 24.1s; best_it=1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 1337 fold 4 done in 35.5s; best_it=2568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 2025 fold 0 done in 35.4s; best_it=2420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 2025 fold 1 done in 36.4s; best_it=2600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 2025 fold 2 done in 29.1s; best_it=2017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 2025 fold 3 done in 26.2s; best_it=1725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  seed 2025 fold 4 done in 32.2s; best_it=2283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PP bagging complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied distance-aware caps. Train kept_nonzero: 461184 of 745624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied distance-aware caps. Test  kept_nonzero: 196178 of 319769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PP fold 0 proba_sc quantiles: [0.00000000e+00 1.57871132e-05 3.99024809e-01 9.90915716e-01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PP fold 1 proba_sc quantiles: [0.00000000e+00 2.37228955e-05 4.50268100e-01 9.92166954e-01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PP fold 2 proba_sc quantiles: [0.00000000e+00 1.83392870e-05 4.15545891e-01 9.92218574e-01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PP fold 3 proba_sc quantiles: [0.00000000e+00 1.80452072e-05 4.30632964e-01 9.91201311e-01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PP fold 4 proba_sc quantiles: [0.00000000e+00 2.60238642e-05 4.86056199e-01 9.92451434e-01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fold 0 best after-hyst MCC=0.71530 thr_opp=0.720 thr_same=0.780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fold 1 best after-hyst MCC=0.74015 thr_opp=0.760 thr_same=0.700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fold 2 best after-hyst MCC=0.73827 thr_opp=0.780 thr_same=0.620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fold 3 best after-hyst MCC=0.73629 thr_opp=0.660 thr_same=0.600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fold 4 best after-hyst MCC=0.73990 thr_opp=0.740 thr_same=0.800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold-median thresholds after hysteresis (PP r45): thr_opp=0.7400, thr_same=0.7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PP positives after full chain: 6371 (in-sample: 6345)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training G-head (per-player) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G-head features: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 42 fold 0 best_it=974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 42 fold 1 best_it=1686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 42 fold 2 best_it=798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 42 fold 3 best_it=1319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 42 fold 4 best_it=1258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 1337 fold 0 best_it=1150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 1337 fold 1 best_it=2075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 1337 fold 2 best_it=769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 1337 fold 3 best_it=1488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 1337 fold 4 best_it=995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 2025 fold 0 best_it=1012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 2025 fold 1 best_it=1933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 2025 fold 2 best_it=656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 2025 fold 3 best_it=1430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G seed 2025 fold 4 best_it=1169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G gate train True: 972034 of 1225299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G gate test  True: 104903 of 127754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nonzero proba_raw after gate (train/test): 972034 104903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train proba_raw gated quantiles: [0.01858482 0.11650438 0.61017988 0.90421667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test proba_raw gated quantiles: [0.1420511  0.31259542 0.694529   0.92223667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test G candidates after cap (proba_gc>0): 11471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train proba_gcs gated quantiles: [0.43306754 0.67890182 0.90120914]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test proba_gcs gated quantiles: [0.55948352 0.7268164  0.91980044]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G Fold 0: fold_size=240966 cap_pos=3012 nz=31437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G Fold 0 best after-hyst thr=0.465 pos=2986 (cap=3012) CAP95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G Fold 1: fold_size=246994 cap_pos=3087 nz=31778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G Fold 1 best after-hyst thr=0.420 pos=3048 (cap=3087) CAP95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G Fold 2: fold_size=233992 cap_pos=2924 nz=30571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G Fold 2 best after-hyst thr=0.515 pos=2846 (cap=2924) CAP95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G Fold 3: fold_size=237314 cap_pos=2966 nz=30801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G Fold 3 best after-hyst thr=0.540 pos=2858 (cap=2966) CAP95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G Fold 4: fold_size=266033 cap_pos=3325 nz=34428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G Fold 4 best after-hyst thr=0.515 pos=2520 (cap=3325) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G fold-median threshold after hysteresis: thr_g=0.5150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Override test thr_g to 0.475 for G_in=1507 and combined_in=7852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G positives after full chain (gated+cap): 2323 (in-sample: 1507)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final counts BEFORE merge (in-sample): PP=6345, G=1507, combined=7852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total time: 677.9s\n"
          ]
        }
      ]
    },
    {
      "id": "e4c786e3-f097-4fc2-8165-70a2752bc9b3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Debug: Inspect columns of r=4.5 supervised parquet files to fix key column names\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "train_sup_fp = 'train_supervised_w5_helm_dyn_r45.parquet'\n",
        "test_sup_fp  = 'test_pairs_w5_helm_dyn_r45.parquet'\n",
        "print('Exist:', Path(train_sup_fp).exists(), Path(test_sup_fp).exists())\n",
        "train_df_head = pd.read_parquet(train_sup_fp)\n",
        "test_df_head = pd.read_parquet(test_sup_fp)\n",
        "print('train columns:', list(train_df_head.columns))\n",
        "print('test  columns:', list(test_df_head.columns))\n",
        "print('head train:')\n",
        "print(train_df_head.head(3))\n",
        "print('head test:')\n",
        "print(test_df_head.head(3))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exist: True True\ntrain columns: ['game_play', 'step', 'p1', 'p2', 'contact', 'distance', 'rel_dx', 'rel_dy', 'speed1', 'speed2', 'accel1', 'accel2', 'closing', 'abs_closing', 'abs_d_heading', 'same_team', 'team1', 'team2', 'pos1', 'pos2', 'dist_min_p5', 'dist_mean_p5', 'dist_max_p5', 'dist_std_p5', 'abs_close_min_p5', 'abs_close_mean_p5', 'abs_close_max_p5', 'abs_close_std_p5', 'cnt_dist_lt15_p5', 'cnt_dist_lt20_p5', 'cnt_dist_lt25_p5', 'dist_delta_p5', 'px_dist_norm_min', 'views_both_present', 'approaching_flag', 'ttc_raw', 'ttc_clip', 'ttc_log', 'inv_ttc', 'd_dist_1', 'd_dist_2', 'd_dist_5', 'd_close_1', 'd_absclose_1', 'd_speed1_1', 'd_speed2_1', 'd_accel1_1', 'd_accel2_1', 'rm3_d_dist_1', 'rm3_d_close_1', 'rel_speed', 'abs_rel_speed', 'rel_accel', 'abs_rel_accel', 'jerk1', 'jerk2', 'd_px_norm_1', 'cnt_px_lt006_p3', 'cnt_px_lt008_p3']\ntest  columns: ['game_play', 'step', 'p1', 'p2', 'distance', 'rel_dx', 'rel_dy', 'speed1', 'speed2', 'accel1', 'accel2', 'closing', 'abs_closing', 'abs_d_heading', 'same_team', 'team1', 'team2', 'pos1', 'pos2', 'dist_min_p5', 'dist_mean_p5', 'dist_max_p5', 'dist_std_p5', 'abs_close_min_p5', 'abs_close_mean_p5', 'abs_close_max_p5', 'abs_close_std_p5', 'cnt_dist_lt15_p5', 'cnt_dist_lt20_p5', 'cnt_dist_lt25_p5', 'dist_delta_p5', 'px_dist_norm_min', 'views_both_present', 'approaching_flag', 'ttc_raw', 'ttc_clip', 'ttc_log', 'inv_ttc', 'd_dist_1', 'd_dist_2', 'd_dist_5', 'd_close_1', 'd_absclose_1', 'd_speed1_1', 'd_speed2_1', 'd_accel1_1', 'd_accel2_1', 'rm3_d_dist_1', 'rm3_d_close_1', 'rel_speed', 'abs_rel_speed', 'rel_accel', 'abs_rel_accel', 'jerk1', 'jerk2', 'd_px_norm_1', 'cnt_px_lt006_p3', 'cnt_px_lt008_p3']\nhead train:\n      game_play  step     p1     p2  contact  distance  rel_dx  rel_dy  \\\n0  58168_003392     0  38590  41944        0  2.948525   -1.67    2.43   \n1  58168_003392     0  38590  47944        0  2.196110   -1.77   -1.30   \n2  58168_003392     0  38590  44822        0  1.833712   -0.80   -1.65   \n\n   speed1  speed2  ...  rm3_d_close_1  rel_speed  abs_rel_speed  rel_accel  \\\n0    0.68    0.52  ...       0.165135      -0.16           0.16      -0.22   \n1    0.20    0.52  ...      -0.209869       0.32           0.32      -1.04   \n2    0.52    1.41  ...       0.302586       0.89           0.89       1.86   \n\n   abs_rel_accel  jerk1 jerk2 d_px_norm_1 cnt_px_lt006_p3 cnt_px_lt008_p3  \n0           0.22   0.34 -0.14   -0.126781             0.0             0.0  \n1           1.04   1.16 -0.79   -0.000736             0.0             0.0  \n2           1.86   0.12  0.70    0.217862             0.0             0.0  \n\n[3 rows x 59 columns]\nhead test:\n      game_play  step     p1     p2  distance  rel_dx  rel_dy  speed1  speed2  \\\n0  58187_001341  -148  34452  38696  1.926058    1.01    1.64    0.22    0.05   \n1  58187_001341  -147  34452  38696  1.941958    1.04    1.64    0.18    0.38   \n2  58187_001341  -146  34452  38696  1.966571   -1.07   -1.65    0.46    0.18   \n\n   accel1  ...  rm3_d_close_1  rel_speed  abs_rel_speed  rel_accel  \\\n0    0.71  ...       0.000000      -0.17           0.17       0.21   \n1    0.53  ...       0.253579       0.20           0.20       1.06   \n2    1.31  ...       0.127683      -0.28           0.28      -0.78   \n\n   abs_rel_accel jerk1 jerk2 d_px_norm_1 cnt_px_lt006_p3  cnt_px_lt008_p3  \n0           0.21  0.00  0.00         0.0             0.0              0.0  \n1           1.06 -0.18  0.67         0.0             0.0              0.0  \n2           0.78  0.78 -1.06         0.0             0.0              0.0  \n\n[3 rows x 58 columns]\n"
          ]
        }
      ]
    },
    {
      "id": "bf9587df-b294-467c-970d-83fa2f0a21e8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Integrate fresh G-head (fast) and OR-combine with existing PP (from submission.csv non-G rows); write improved submission.csv\n",
        "import time, gc, numpy as np, pandas as pd, xgboost as xgb\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "t0 = time.time()\n",
        "print('G-head quick integration start...', flush=True)\n",
        "\n",
        "# 1) Load tracking and labels\n",
        "train_trk = pd.read_csv('train_player_tracking.csv')\n",
        "test_trk  = pd.read_csv('test_player_tracking.csv')\n",
        "labels = pd.read_csv('train_labels.csv')\n",
        "\n",
        "rename_map = {}\n",
        "if 'x_position' in train_trk.columns and 'y_position' in train_trk.columns:\n",
        "    rename_map.update({'x_position':'x','y_position':'y'})\n",
        "train_trk = train_trk.rename(columns=rename_map)\n",
        "test_trk  = test_trk.rename(columns=rename_map)\n",
        "\n",
        "base_cols = ['game_play','step','nfl_player_id']\n",
        "cand_cols = ['x','y','speed','acceleration']\n",
        "avail = [c for c in cand_cols if c in train_trk.columns]\n",
        "use_cols = base_cols + avail\n",
        "train_trk = train_trk[use_cols].copy()\n",
        "test_trk  = test_trk[[c for c in use_cols if c in test_trk.columns]].copy()\n",
        "\n",
        "def add_player_feats(df):\n",
        "    df = df.sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "    for col in [c for c in ['x','y','speed','acceleration'] if c in df.columns]:\n",
        "        df[f'd_{col}'] = df.groupby(['game_play','nfl_player_id'])[col].diff().fillna(0.0)\n",
        "    if 'acceleration' in df.columns:\n",
        "        df['jerk'] = df.groupby(['game_play','nfl_player_id'])['acceleration'].diff().fillna(0.0)\n",
        "    for col in [c for c in ['speed','acceleration'] if c in df.columns]:\n",
        "        df[f'{col}_r3_max'] = df.groupby(['game_play','nfl_player_id'])[col].rolling(3, min_periods=1).max().reset_index(level=[0,1], drop=True)\n",
        "        df[f'{col}_r5_min'] = df.groupby(['game_play','nfl_player_id'])[col].rolling(5, min_periods=1).min().reset_index(level=[0,1], drop=True)\n",
        "    if 'speed' in df.columns:\n",
        "        df['speed_drop_3'] = df['speed'] - df.groupby(['game_play','nfl_player_id'])['speed'].shift(3).fillna(df['speed'])\n",
        "    return df\n",
        "\n",
        "train_trk = add_player_feats(train_trk)\n",
        "test_trk  = add_player_feats(test_trk)\n",
        "\n",
        "# Build G labels\n",
        "labels_g = labels[labels['contact_id'].str.endswith('_G')].copy()\n",
        "parts = labels_g['contact_id'].str.split('_')\n",
        "labels_g['game_play'] = parts.str[0] + '_' + parts.str[1]\n",
        "labels_g['step'] = parts.str[2].astype(int)\n",
        "labels_g['player'] = parts.str[3]\n",
        "labels_g = labels_g[['game_play','step','player','contact']].copy()\n",
        "\n",
        "train_trk['player'] = train_trk['nfl_player_id'].astype(str)\n",
        "g_lab = labels_g.copy()\n",
        "g_lab_p1 = g_lab.copy(); g_lab_p1['step'] = g_lab_p1['step'] + 1\n",
        "g_lab_m1 = g_lab.copy(); g_lab_m1['step'] = g_lab_m1['step'] - 1\n",
        "g_lab_all = pd.concat([g_lab, g_lab_p1, g_lab_m1], ignore_index=True).drop_duplicates(['game_play','step','player'])\n",
        "g_lab_all['contact'] = 1\n",
        "\n",
        "train_g = train_trk.merge(g_lab_all, on=['game_play','step','player'], how='left')\n",
        "train_g['contact'] = train_g['contact'].fillna(0).astype(int)\n",
        "\n",
        "# 2) Train a fast G-head (1 seed, 5 folds) on GPU\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "groups_g = train_g['game_play'].values\n",
        "g_feat_drop = {'game_play','step','nfl_player_id','player','contact'}\n",
        "g_feat_cols = [c for c in train_g.columns if c not in g_feat_drop and train_g[c].dtype != 'O']\n",
        "print('G-head features:', len(g_feat_cols), flush=True)\n",
        "\n",
        "def train_xgb_fast(X_tr, y_tr, X_va, y_va, seed=42):\n",
        "    dtr = xgb.DMatrix(X_tr, label=y_tr); dva = xgb.DMatrix(X_va, label=y_va)\n",
        "    neg = float((y_tr==0).sum()); pos = float((y_tr==1).sum()); spw = max(1.0, neg/max(1.0,pos))\n",
        "    params = {\n",
        "        'objective':'binary:logistic', 'eval_metric':'logloss', 'tree_method':'gpu_hist',\n",
        "        'max_depth':7, 'eta':0.06, 'subsample':0.9, 'colsample_bytree':0.8, 'min_child_weight':10, 'lambda':1.2,\n",
        "        'scale_pos_weight': spw, 'seed': int(seed)\n",
        "    }\n",
        "    bst = xgb.train(params, dtr, num_boost_round=4000, evals=[(dva,'valid')], early_stopping_rounds=200, verbose_eval=False)\n",
        "    return bst\n",
        "\n",
        "oof = np.zeros(len(train_g), float); pt = np.zeros(len(test_trk), float)\n",
        "seed = 42; fi=0\n",
        "Xt = xgb.DMatrix(test_trk[g_feat_cols].values) if len(test_trk) else None\n",
        "for tr_idx, va_idx in gkf.split(train_g, train_g['contact'].values, groups_g):\n",
        "    X_tr = train_g.iloc[tr_idx][g_feat_cols].values; y_tr = train_g.iloc[tr_idx]['contact'].values.astype(np.float32)\n",
        "    X_va = train_g.iloc[va_idx][g_feat_cols].values; y_va = train_g.iloc[va_idx]['contact'].values.astype(np.float32)\n",
        "    t1=time.time(); bst = train_xgb_fast(X_tr, y_tr, X_va, y_va, seed=seed)\n",
        "    oof[va_idx] = bst.predict(xgb.DMatrix(X_va), iteration_range=(0, bst.best_iteration+1))\n",
        "    if Xt is not None: pt += bst.predict(Xt, iteration_range=(0, bst.best_iteration+1))\n",
        "    print(f'  G fast fold {fi} best_it={bst.best_iteration} in {time.time()-t1:.1f}s', flush=True)\n",
        "    del bst; gc.collect(); fi+=1\n",
        "pt = pt / 5.0\n",
        "\n",
        "# 3) Post-proc: rolling max w=5, per-fold threshold after hysteresis, median to test\n",
        "def roll_max_centered_by_group_player(df, prob_col, win=5):\n",
        "    return df.groupby(['game_play','nfl_player_id'], sort=False)[prob_col].apply(lambda x: x.rolling(win, center=True, min_periods=1).max()).reset_index(level=[0,1], drop=True).values\n",
        "\n",
        "def hysteresis_2of3_sorted(pred_bin: np.ndarray, df_sorted: pd.DataFrame, group_cols: list) -> np.ndarray:\n",
        "    assert isinstance(df_sorted.index, pd.RangeIndex)\n",
        "    arr = pred_bin.astype(np.uint8); gvals = df_sorted[group_cols].to_numpy()\n",
        "    new_group = np.zeros(len(df_sorted), dtype=bool); new_group[1:] = (gvals[1:] != gvals[:-1]).any(axis=1)\n",
        "    end_group = np.zeros(len(df_sorted), dtype=bool); end_group[:-1] = new_group[1:]; end_group[-1] = True\n",
        "    prev = np.r_[arr[0], arr[:-1]]; prev[new_group] = arr[new_group]\n",
        "    nxt = np.r_[arr[1:], arr[-1]]; nxt[end_group] = arr[end_group]\n",
        "    return (arr + prev + nxt >= 2).astype(np.uint8)\n",
        "\n",
        "train_g_meta = train_trk[['game_play','step','nfl_player_id']].copy().reset_index(drop=True)\n",
        "test_g_meta  = test_trk[['game_play','step','nfl_player_id']].copy().reset_index(drop=True)\n",
        "train_g_meta['proba'] = oof; test_g_meta['proba'] = pt\n",
        "train_g_meta = train_g_meta.sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "test_g_meta  = test_g_meta.sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "train_g_meta['proba_s'] = roll_max_centered_by_group_player(train_g_meta, 'proba', win=5)\n",
        "test_g_meta['proba_s']  = roll_max_centered_by_group_player(test_g_meta,  'proba', win=5)\n",
        "\n",
        "# Attach labels for thresholding by folds from PP folds\n",
        "folds_df = pd.read_csv('folds_game_play.csv')\n",
        "gp2fold = dict(zip(folds_df['game_play'], folds_df['game_play'].astype(str).map(lambda x: folds_df.loc[folds_df['game_play']==x,'fold'].values[0]) if False else folds_df['fold']))\n",
        "train_g_meta['fold'] = train_g_meta['game_play'].map(gp2fold).astype(int)\n",
        "train_g_meta = train_g_meta.merge(train_g[['game_play','step','nfl_player_id','contact']], on=['game_play','step','nfl_player_id'], how='left', validate='one_to_one')\n",
        "train_g_meta['contact'] = train_g_meta['contact'].fillna(0).astype(int)\n",
        "\n",
        "thr_grid = np.round(np.arange(0.60, 0.921, 0.02), 3)\n",
        "best_thr_g = []\n",
        "for f in sorted(train_g_meta['fold'].unique()):\n",
        "    df_f = train_g_meta.loc[train_g_meta['fold']==f].sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "    y = df_f['contact'].values.astype(int)\n",
        "    best_m=-1.0; best_t=0.78\n",
        "    for t in thr_grid:\n",
        "        pred = (df_f['proba_s'].values >= t).astype(np.uint8)\n",
        "        pred_h = hysteresis_2of3_sorted(pred, df_f, ['game_play','nfl_player_id'])\n",
        "        # Simple MCC\n",
        "        tp = ((y==1)&(pred_h==1)).sum(); tn=((y==0)&(pred_h==0)).sum(); fp=((y==0)&(pred_h==1)).sum(); fn=((y==1)&(pred_h==0)).sum()\n",
        "        denom = max(1.0, float(((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5))\n",
        "        mcc = (tp*tn - fp*fn)/denom\n",
        "        if mcc > best_m: best_m=mcc; best_t=float(t)\n",
        "    print(f' G-fast Fold {f} best MCC={best_m:.5f} thr={best_t:.3f}', flush=True)\n",
        "    best_thr_g.append(best_t)\n",
        "thr_g_med = float(np.median(best_thr_g))\n",
        "print(f'G-fast fold-median thr={thr_g_med:.4f}', flush=True)\n",
        "\n",
        "# Apply to test G and build G rows\n",
        "tst = test_g_meta.copy(); tst['_idx']=np.arange(len(tst))\n",
        "tst = tst.sort_values(['game_play','nfl_player_id','step']).reset_index(drop=True)\n",
        "g_bin_sorted = (tst['proba_s'].values >= thr_g_med).astype(np.uint8)\n",
        "g_bin_sorted = hysteresis_2of3_sorted(g_bin_sorted, tst, ['game_play','nfl_player_id'])\n",
        "g_bin = np.zeros(len(test_g_meta), np.uint8); g_bin[tst['_idx'].values]=g_bin_sorted\n",
        "g_rows = test_g_meta[['game_play','step','nfl_player_id']].copy()\n",
        "g_rows['contact'] = g_bin.astype(int)\n",
        "g_rows = g_rows[g_rows['contact']>0].copy()\n",
        "g_rows['contact_id'] = g_rows['game_play'] + '_' + g_rows['step'].astype(str) + '_' + g_rows['nfl_player_id'].astype(str) + '_G'\n",
        "sub_g = g_rows[['contact_id','contact']].copy()\n",
        "g_pos = int(sub_g['contact'].sum())\n",
        "print('G-fast positives:', g_pos, flush=True)\n",
        "\n",
        "# 4) OR-combine with existing PP predictions (from current submission.csv non-G rows)\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "cur = pd.read_csv('submission.csv')\n",
        "pp_only = cur[~cur['contact_id'].str.endswith('_G')].copy()\n",
        "pp_only = pp_only.rename(columns={'contact':'pp_contact'})\n",
        "sub = ss[['contact_id']].merge(pp_only, on='contact_id', how='left')\n",
        "sub['pp_contact'] = sub['pp_contact'].fillna(0).astype(int)\n",
        "if len(sub_g):\n",
        "    sub = sub.merge(sub_g.rename(columns={'contact':'g_contact'}), on='contact_id', how='left')\n",
        "    sub['g_contact'] = sub['g_contact'].fillna(0).astype(int)\n",
        "    sub['contact'] = np.maximum(sub['pp_contact'], sub['g_contact']).astype(int)\n",
        "else:\n",
        "    sub['contact'] = sub['pp_contact']\n",
        "sub = sub[['contact_id','contact']]\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved improved submission.csv (PP OR G-fast). Total time {:.1f}s'.format(time.time()-t0), flush=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G-head quick integration start...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G-head features: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G fast fold 0 best_it=535 in 4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G fast fold 1 best_it=682 in 5.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G fast fold 2 best_it=619 in 4.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G fast fold 3 best_it=509 in 4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  G fast fold 4 best_it=379 in 3.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G-fast Fold 0 best MCC=7637962530.00000 thr=0.660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G-fast Fold 1 best MCC=9144683812.00000 thr=0.680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G-fast Fold 2 best MCC=8056316466.00000 thr=0.660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G-fast Fold 3 best MCC=7984390436.00000 thr=0.640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " G-fast Fold 4 best MCC=9738054776.00000 thr=0.640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G-fast fold-median thr=0.6600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G-fast positives: 38345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved improved submission.csv (PP OR G-fast). Total time 33.8s\n"
          ]
        }
      ]
    },
    {
      "id": "26687919-b903-4cb0-8598-e40ba3d1c33e",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan: Patch G-head per expert advice (do NOT execute yet)\n",
        "\n",
        "We received expert guidance that explains the G-head blow-up and how to fix it. Next steps (implementation to be done in Cell 1 in upcoming edits; do not run until PP Cell 0 finishes):\n",
        "\n",
        "- Replace cap_topk_per_step with a groupby-rank mask that never reorders rows:\n",
        "  - Rank within (game_play, step) descending by proba; keep_mask = (rank <= k) & (proba >= min_prob); set others to 0.0.\n",
        "  - Enforce assertion: per-(game_play, step), number of proba>0 must be <= k.\n",
        "\n",
        "- Post-proc order: Gate -> CAP (k=1\u20132 on raw proba) -> Threshold -> Hysteresis (2-of-3). Reduce smoothing:\n",
        "  - If smoothing is used, apply roll-max AFTER cap with a short window (w=3).\n",
        "\n",
        "- Calibrate/regularize the G model:\n",
        "  - Clip scale_pos_weight to <= 5 per fold.\n",
        "  - Stronger regularization: lambda ~2\u20133, alpha ~0.2\u20130.5, min_child_weight ~20, max_depth ~6, subsample ~0.8, colsample_bytree ~0.7\u20130.8, eta ~0.03\u20130.05; optional max_delta_step=1.\n",
        "  - Keep eval_metric='logloss'.\n",
        "\n",
        "- Gate kinematic-first (proximity as feature, not hard gate):\n",
        "  - Start with conservative gate_extra = (speed <= 0.8) OR (acceleration <= -0.8) OR (speed_drop_3 <= -0.8) AND time_since_snap >= 2. Optionally AND proximity close_opp for precision.\n",
        "\n",
        "- Labels:\n",
        "  - Remove \u00b11 expansion initially; use exact frame. Reintroduce limited expansion only with kinematic confirmation if needed.\n",
        "\n",
        "- Threshold search and guardrail:\n",
        "  - Keep per-fold grid AFTER hysteresis; accept only thresholds with <=500 positives (or ~0.3% of fold size).\n",
        "  - Fallback: choose highest threshold that satisfies the cap; if none, use a very high constant (e.g., 0.98), not 0.94.\n",
        "  - Optionally initialize from high-quantile (99\u201399.9th) and sweep a narrow band.\n",
        "\n",
        "- Diagnostics to add before re-running:\n",
        "  - Print stagewise counts (raw -> gate -> cap -> smooth -> hysteresis -> threshold) train/test.\n",
        "  - Quantiles/histograms for proba_s and proba_gc per fold.\n",
        "  - Assert per-(game_play, step) cap holds (<=k).\n",
        "  - Verify contact_id format for G: <game_play>_<step>_<nfl_player_id>_G.\n",
        "\n",
        "Targets:\n",
        "- Test G candidates (proba_gc>0): ~4\u20136k.\n",
        "- Final G positives after hysteresis: ~1.8k\u20132.2k.\n",
        "\n",
        "Execution plan:\n",
        "1) When Cell 0 completes, modify Cell 1 to: implement safe cap, change order (cap before smoothing), tighten gate (kinematic-first), clip spw and add regularization, remove \u00b11 labels.\n",
        "2) Add diagnostics prints and assertions to stop runs if caps fail.\n",
        "3) Execute Cell 1; verify counts and distributions; iterate thresholds.\n",
        "4) If G still high: raise min_prob (e.g., 0.997), tighten gate; if low: relax min_prob (e.g., 0.99).\n",
        "\n",
        "We will not execute Cell 1 until these patches are coded. Cell 0 continues to run for a clean PP-only baseline."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "ffebc4c5-6ee2-4500-86d6-affa189af0a4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Snapshot current Cell 1 submission: save combined and extract G rows for hedge blend\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "src = Path('submission.csv')\n",
        "assert src.exists(), 'submission.csv not found; run Cell 1 first.'\n",
        "sub = pd.read_csv(src)\n",
        "\n",
        "# Save full combined from Cell 1\n",
        "sub.to_csv('submission_cell1_pp_r45_plus_g.csv', index=False)\n",
        "print('Saved snapshot:', 'submission_cell1_pp_r45_plus_g.csv', 'rows=', len(sub))\n",
        "\n",
        "# Extract G rows only\n",
        "is_g = sub['contact_id'].str.endswith('_G')\n",
        "g_rows = sub.loc[is_g, ['contact_id','contact']].copy()\n",
        "g_rows.to_csv('g_rows_from_cell1.csv', index=False)\n",
        "print('Saved G rows:', 'g_rows_from_cell1.csv', 'G positives=', int(g_rows['contact'].sum()), 'rows=', len(g_rows))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved snapshot: submission_cell1_pp_r45_plus_g.csv rows= 463243\nSaved G rows: g_rows_from_cell1.csv G positives= 1507 rows= 40282\n"
          ]
        }
      ]
    },
    {
      "id": "ac084ca6-3b6f-4711-ab9b-bac642201562",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Combine PP-only (from Cell 0 PP-blend file) with saved G rows (from Cell 1 snapshot) and write hedge submission (do NOT overwrite submission.csv)\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "pp_file = Path('submission_ppblend_plus_g.csv')  # use PP-blend file; will strip G rows\n",
        "g_file = Path('g_rows_from_cell1.csv')\n",
        "ss_file = Path('sample_submission.csv')\n",
        "assert pp_file.exists(), 'PP-blend file not found: submission_ppblend_plus_g.csv'\n",
        "assert g_file.exists(), 'g_rows_from_cell1.csv not found. Re-run Cell 5 snapshot after Cell 1.'\n",
        "\n",
        "pp_sub_full = pd.read_csv(pp_file)\n",
        "ss = pd.read_csv(ss_file)\n",
        "\n",
        "# Strip G rows to get PP-only from the blend\n",
        "pp_sub = pp_sub_full[~pp_sub_full['contact_id'].str.endswith('_G')].copy()\n",
        "pp_sub = pp_sub.rename(columns={'contact':'pp_contact'})\n",
        "\n",
        "g_rows = pd.read_csv(g_file)\n",
        "g_rows = g_rows.rename(columns={'contact':'g_contact'})\n",
        "\n",
        "# OR-combine on sample_submission universe\n",
        "sub = ss[['contact_id']].merge(pp_sub, on='contact_id', how='left')\n",
        "sub['pp_contact'] = sub['pp_contact'].fillna(0).astype(int)\n",
        "sub = sub.merge(g_rows, on='contact_id', how='left')\n",
        "sub['g_contact'] = sub['g_contact'].fillna(0).astype(int)\n",
        "sub['contact'] = (sub['pp_contact'] | sub['g_contact']).astype(int)\n",
        "sub = sub[['contact_id','contact']]\n",
        "\n",
        "combined_pos = int(sub['contact'].sum())\n",
        "pp_pos = int(pp_sub['pp_contact'].sum())\n",
        "g_pos = int(g_rows['g_contact'].sum())\n",
        "print('Hedge components -> PP:', pp_pos, 'G:', g_pos, 'combined:', combined_pos)\n",
        "\n",
        "# Save hedge output only (do NOT overwrite submission.csv here)\n",
        "sub.to_csv('submission_hedge_ppblend_plus_freshG.csv', index=False)\n",
        "print('Saved submission_hedge_ppblend_plus_freshG.csv')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hedge components -> PP: 6428 G: 1507 combined: 7935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_hedge_ppblend_plus_freshG.csv\n"
          ]
        }
      ]
    },
    {
      "id": "a2bd213f-8674-47bd-a64a-f359235edbbd",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspect snapshot submission from Cell 1 and, if valid, set it as current submission.csv\n",
        "import pandas as pd, shutil, os\n",
        "from pathlib import Path\n",
        "\n",
        "snap_fp = Path('submission_cell1_pp_r45_plus_g.csv')\n",
        "assert snap_fp.exists(), 'snapshot file missing: submission_cell1_pp_r45_plus_g.csv'\n",
        "sub = pd.read_csv(snap_fp)\n",
        "is_g = sub['contact_id'].str.endswith('_G')\n",
        "pp_pos = int(sub.loc[~is_g, 'contact'].sum())\n",
        "g_pos = int(sub.loc[is_g, 'contact'].sum())\n",
        "combined = int(sub['contact'].sum())\n",
        "print('Snapshot counts -> PP:', pp_pos, 'G:', g_pos, 'combined:', combined)\n",
        "\n",
        "# If looks like the strong run (target ~PP 6601, G 1854, combined ~8455), overwrite submission.csv with snapshot\n",
        "if (pp_pos >= 6400 and pp_pos <= 6800) and (g_pos >= 1700 and g_pos <= 2000) and (combined <= 9000):\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Set submission.csv from snapshot (Cell 1 PP+G).')\n",
        "else:\n",
        "    print('Snapshot not in expected range. Keeping current submission.csv.')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Snapshot counts -> PP: 6571 G: 1250 combined: 7821\nSnapshot not in expected range. Keeping current submission.csv.\n"
          ]
        }
      ]
    },
    {
      "id": "a3b964b4-0193-44db-a208-879a9c89ae16",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Normalize contact_id in snapshot to canonical schema and rebuild submission.csv\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "snap_fp = Path('submission_cell1_pp_r45_plus_g.csv')\n",
        "ss_fp = Path('sample_submission.csv')\n",
        "assert snap_fp.exists() and ss_fp.exists(), 'Required files missing.'\n",
        "snap = pd.read_csv(snap_fp)\n",
        "ss = pd.read_csv(ss_fp)\n",
        "\n",
        "def normalize_cid(cid: str) -> str:\n",
        "    parts = cid.split('_')\n",
        "    if cid.endswith('_G'):\n",
        "        gp = parts[0] + '_' + parts[1]\n",
        "        step = int(parts[2])\n",
        "        pid = int(parts[3])\n",
        "        return f'{gp}_{step}_{pid}_G'\n",
        "    else:\n",
        "        gp = parts[0] + '_' + parts[1]\n",
        "        step = int(parts[2])\n",
        "        p1, p2 = int(parts[3]), int(parts[4])\n",
        "        if p1 <= p2:\n",
        "            pmin, pmax = p1, p2\n",
        "        else:\n",
        "            pmin, pmax = p2, p1\n",
        "        return f'{gp}_{step}_{pmin}_{pmax}'\n",
        "\n",
        "# Normalize IDs and collapse duplicates\n",
        "snap['contact_id'] = snap['contact_id'].astype(str).apply(normalize_cid)\n",
        "snap = snap.groupby('contact_id', as_index=False)['contact'].max()\n",
        "\n",
        "# Align to sample and fill missing as 0\n",
        "sub = ss[['contact_id']].merge(snap, on='contact_id', how='left')\n",
        "sub['contact'] = sub['contact'].fillna(0).astype(int)\n",
        "\n",
        "# Report in-sample counts\n",
        "is_g = sub['contact_id'].str.endswith('_G')\n",
        "pp_pos = int(sub.loc[~is_g, 'contact'].sum())\n",
        "g_pos = int(sub.loc[is_g, 'contact'].sum())\n",
        "combined = int(sub['contact'].sum())\n",
        "print('Normalized snapshot counts -> PP:', pp_pos, 'G:', g_pos, 'combined:', combined)\n",
        "\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved normalized submission.csv')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized snapshot counts -> PP: 6571 G: 1171 combined: 7742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved normalized submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "d6e15bc4-3fef-46c3-8d05-ba1f1ac04e9b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set submission.csv to hedge file\n",
        "import pandas as pd, os\n",
        "hedge_fp = 'submission_hedge_ppblend_plus_freshG.csv'\n",
        "sub = pd.read_csv(hedge_fp)\n",
        "is_g = sub['contact_id'].str.endswith('_G')\n",
        "pp_pos = int(sub.loc[~is_g, 'contact'].sum()); g_pos = int(sub.loc[is_g, 'contact'].sum()); combined = int(sub['contact'].sum())\n",
        "print('Hedge counts -> PP:', pp_pos, 'G:', g_pos, 'combined:', combined)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('submission.csv overwritten from hedge file')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hedge counts -> PP: 6428 G: 1507 combined: 7935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv overwritten from hedge file\n"
          ]
        }
      ]
    },
    {
      "id": "d1680f31-2982-4cfd-897e-0cbdfee66282",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build a precision-tilted hedge: cap G to k=1 per (game_play, step) on hedge file and write submission.csv\n",
        "import pandas as pd\n",
        "\n",
        "hedge_fp = 'submission_hedge_ppblend_plus_freshG.csv'\n",
        "sub = pd.read_csv(hedge_fp)\n",
        "\n",
        "# Split PP and G\n",
        "is_g = sub['contact_id'].str.endswith('_G')\n",
        "pp = sub.loc[~is_g].copy()\n",
        "g = sub.loc[is_g].copy()\n",
        "\n",
        "# Parse game_play and step from G contact_id: <game_play>_<step>_<player>_G\n",
        "parts = g['contact_id'].str.split('_')\n",
        "g['game_play'] = parts.str[0] + '_' + parts.str[1]\n",
        "g['step'] = parts.str[2].astype(int)\n",
        "\n",
        "# For each (game_play, step), keep at most 1 G positive (k=1), preferring any positive; if multiple, keep first arbitrarily\n",
        "g_pos = g[g['contact'] == 1].copy()\n",
        "g_pos = g_pos.sort_values(['game_play','step']).drop_duplicates(['game_play','step'], keep='first')\n",
        "\n",
        "# Recombine PP with capped G\n",
        "sub_k1 = pd.concat([pp[['contact_id','contact']], g_pos[['contact_id','contact']]], ignore_index=True)\n",
        "sub_k1 = sub_k1.groupby('contact_id', as_index=False)['contact'].max()\n",
        "\n",
        "# Report counts\n",
        "is_g_k1 = sub_k1['contact_id'].str.endswith('_G')\n",
        "pp_pos = int(sub_k1.loc[~is_g_k1, 'contact'].sum())\n",
        "g_pos_cnt = int(sub_k1.loc[is_g_k1, 'contact'].sum())\n",
        "combined = int(sub_k1['contact'].sum())\n",
        "print('Precision-hedge counts -> PP:', pp_pos, 'G(k=1):', g_pos_cnt, 'combined:', combined)\n",
        "\n",
        "# Save as submission.csv\n",
        "sub_k1.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (hedge with G k=1 cap)')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision-hedge counts -> PP: 6428 G(k=1): 781 combined: 7209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (hedge with G k=1 cap)\n"
          ]
        }
      ]
    },
    {
      "id": "3fdeb0d3-7d33-4617-a655-0a8a303f1c01",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build PP-only submission from blend file (strip G rows) and align to sample_submission\n",
        "import pandas as pd\n",
        "ppblend_fp = 'submission_ppblend_plus_g.csv'\n",
        "ss_fp = 'sample_submission.csv'\n",
        "ppsub_full = pd.read_csv(ppblend_fp)\n",
        "ss = pd.read_csv(ss_fp)\n",
        "# Keep PP rows only and align\n",
        "pp_only = ppsub_full[~ppsub_full['contact_id'].str.endswith('_G')].copy()\n",
        "pp_only = pp_only.rename(columns={'contact':'pp_contact'})\n",
        "sub = ss[['contact_id']].merge(pp_only, on='contact_id', how='left')\n",
        "sub['contact'] = sub['pp_contact'].fillna(0).astype(int)\n",
        "sub = sub[['contact_id','contact']]\n",
        "pp_pos = int(sub['contact'].sum())\n",
        "print('PP-only submission positives:', pp_pos)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (PP-only from blend)')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PP-only submission positives: 6428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (PP-only from blend)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}