{
  "cells": [
    {
      "id": "4ac07ce4-7dc1-47d2-be48-6a8eac7576a5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Entropy-adaptive PoE fusion using cached probabilities; OOF tune and test submission\n",
        "import numpy as np, pandas as pd, json, time, os\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "probs_cache = Path('probs_cache')\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "\n",
        "# Load fold splits\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "\n",
        "# Calibration for skeleton v2/v3 blend\n",
        "calib = json.load(open('calib_all_v2v3_meta.json','r'))\n",
        "T2 = np.array(calib['T2'], dtype=np.float32)\n",
        "T3 = np.array(calib['T3'], dtype=np.float32)\n",
        "A  = np.array(calib.get('A', [0.7]*len(T2)), dtype=np.float32)  # per-class weight for v2\n",
        "\n",
        "def temp_scale(p, T):\n",
        "    T = np.asarray(T, dtype=np.float32).reshape(-1)\n",
        "    p = np.clip(p, 1e-8, 1.0)\n",
        "    logp = np.log(p)\n",
        "    if p.shape[0] == T.shape[0]:\n",
        "        logp = logp / np.maximum(T[:, None], 1e-6)\n",
        "        q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "        return q.astype(np.float32)\n",
        "    elif p.shape[-1] == T.shape[0]:\n",
        "        logp = logp / np.maximum(T[None, :], 1e-6)\n",
        "        q = np.exp(logp); q /= (q.sum(axis=1, keepdims=True) + 1e-8)\n",
        "        return q.T.astype(np.float32)\n",
        "    else:\n",
        "        raise ValueError('T length mismatch')\n",
        "\n",
        "def ensure_CxT(p, C=21):\n",
        "    if p.shape[0] == C: return p\n",
        "    if p.shape[1] == C: return p.T\n",
        "    raise ValueError('Bad probs shape')\n",
        "\n",
        "def load_skeleton_probs(seq_id: int) -> np.ndarray:\n",
        "    p2 = np.load(probs_cache/f\"{seq_id}_ce.npy\").astype(np.float32)\n",
        "    p3 = np.load(probs_cache/f\"{seq_id}_ce_v3.npy\").astype(np.float32)\n",
        "    p2 = ensure_CxT(temp_scale(p2, T2))\n",
        "    p3 = ensure_CxT(temp_scale(p3, T3))\n",
        "    Tm = min(p2.shape[1], p3.shape[1])\n",
        "    p2 = p2[:, :Tm]; p3 = p3[:, :Tm]\n",
        "    a = A.reshape(-1,1)\n",
        "    p = a*p2 + (1.0-a)*p3\n",
        "    p /= (p.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return p.astype(np.float32)\n",
        "\n",
        "def load_rgb_probs(seq_id: int) -> np.ndarray | None:\n",
        "    pth = probs_cache/f\"{seq_id}_rgb.npy\"\n",
        "    if not pth.exists(): return None\n",
        "    p = np.load(pth).astype(np.float32)\n",
        "    return ensure_CxT(p)\n",
        "\n",
        "def entropy(p: np.ndarray) -> np.ndarray:\n",
        "    q = np.clip(p, 1e-8, 1.0)\n",
        "    return -np.sum(q*np.log(q), axis=0)\n",
        "\n",
        "def align_by_entropy_corr(p_src: np.ndarray, p_ref: np.ndarray, max_shift: int = 15):\n",
        "    # Align p_src to p_ref by maximizing entropy correlation.\n",
        "    # Returns (src_aligned, ref_cropped) with equal time length.\n",
        "    hs = entropy(p_src); hr = entropy(p_ref)\n",
        "    best = (-1e9, 0)\n",
        "    for sh in range(-max_shift, max_shift+1):\n",
        "        if sh >= 0:\n",
        "            L = min(hs.shape[0] - sh, hr.shape[0])\n",
        "            if L < 16: continue\n",
        "            s = hs[sh:sh+L]; r = hr[:L]\n",
        "        else:\n",
        "            L = min(hs.shape[0], hr.shape[0] + sh)  # sh negative\n",
        "            if L < 16: continue\n",
        "            s = hs[:L]; r = hr[-sh:-sh+L]\n",
        "        # robust corr (handle constant segments)\n",
        "        if s.std() < 1e-8 or r.std() < 1e-8:\n",
        "            corr = -1.0\n",
        "        else:\n",
        "            corr = float(np.corrcoef(s, r)[0,1])\n",
        "        if corr > best[0]: best = (corr, sh)\n",
        "    sh = best[1]\n",
        "    if sh >= 0:\n",
        "        L = min(p_src.shape[1] - sh, p_ref.shape[1])\n",
        "        return p_src[:, sh:sh+L], p_ref[:, :L]\n",
        "    else:\n",
        "        L = min(p_src.shape[1], p_ref.shape[1] + sh)\n",
        "        return p_src[:, :L], p_ref[:, -sh:-sh+L]\n",
        "\n",
        "def smooth_probs_box(p: np.ndarray, k: int = 5) -> np.ndarray:\n",
        "    if k<=1: return p\n",
        "    C,T = p.shape\n",
        "    pad = k//2\n",
        "    x = np.pad(p, ((0,0),(pad,pad)), mode='edge')\n",
        "    cs = np.cumsum(x, axis=1, dtype=np.float64)\n",
        "    out = (cs[:, k:] - cs[:, :-k]) / k\n",
        "    out = out.astype(np.float32)\n",
        "    out /= (out.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return out\n",
        "\n",
        "def decode_minseg(p: np.ndarray, min_dur: np.ndarray) -> np.ndarray:\n",
        "    y = p.argmax(axis=0).astype(np.int32)\n",
        "    T = y.shape[0]; i=0\n",
        "    while i < T:\n",
        "        c = y[i]; j=i+1\n",
        "        while j<T and y[j]==c: j+=1\n",
        "        L = j-i\n",
        "        if c!=0 and L < int(min_dur[c]):\n",
        "            lc = y[i-1] if i>0 else None\n",
        "            rc = y[j] if j<T else None\n",
        "            ls = float(p[lc, i:j].mean()) if lc is not None else -1e9\n",
        "            rs = float(p[rc, i:j].mean()) if rc is not None else -1e9\n",
        "            if rs >= ls: y[i:j] = rc if rc is not None else 0\n",
        "            else:        y[i:j] = lc if lc is not None else 0\n",
        "            i = max(0, i-1); continue\n",
        "        i = j\n",
        "    return y\n",
        "\n",
        "def aba_collapse(y: np.ndarray, max_len: int = 2, ratio: float = 1.04, p: np.ndarray | None = None) -> np.ndarray:\n",
        "    # collapse short ABA islands\n",
        "    T = len(y); i=1\n",
        "    while i < T-1:\n",
        "        if y[i-1]==y[i+1] and y[i]!=y[i-1]:\n",
        "            L=1; j=i+1\n",
        "            while j<T-1 and y[j-1]==y[j+1] and y[j]!=y[j-1]:\n",
        "                L+=1; j+=1\n",
        "            if L<=max_len:\n",
        "                y[i:j] = y[i-1]\n",
        "                i = max(1, i-1); continue\n",
        "            i = j\n",
        "        i+=1\n",
        "    return y\n",
        "\n",
        "def compress_to_sequence(y_frames):\n",
        "    seq=[]; last=-1\n",
        "    for c in y_frames:\n",
        "        if c==0: continue\n",
        "        if c!=last: seq.append(int(c)); last=int(c)\n",
        "    return seq\n",
        "\n",
        "def make_perm20(seq_raw, p: np.ndarray):\n",
        "    # keep first occurrence, then append missing classes by total mass desc\n",
        "    seen=set(); seq=[]\n",
        "    for c in seq_raw:\n",
        "        if 1<=c<=20 and c not in seen:\n",
        "            seen.add(c); seq.append(c)\n",
        "    if len(seq)<20:\n",
        "        masses = [(c, float(p[c].sum())) for c in range(1,21) if c not in seen]\n",
        "        masses.sort(key=lambda x: x[1], reverse=True)\n",
        "        for c,_ in masses:\n",
        "            if len(seq)==20: break\n",
        "            seq.append(c)\n",
        "    if len(seq)>20: seq = seq[:20]\n",
        "    return seq\n",
        "\n",
        "def segment_lengths(y):\n",
        "    lens=defaultdict(list); cur=None; run=0\n",
        "    for c in y:\n",
        "        if c==0:\n",
        "            if cur is not None: lens[cur].append(run); cur=None; run=0\n",
        "            continue\n",
        "        if cur is None: cur=int(c); run=1\n",
        "        elif c==cur: run+=1\n",
        "        else: lens[cur].append(run); cur=int(c); run=1\n",
        "    if cur is not None: lens[cur].append(run)\n",
        "    return lens\n",
        "\n",
        "def compute_min_dur_from_ids(ids):\n",
        "    agg=defaultdict(list)\n",
        "    for sid in ids:\n",
        "        y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "        for c,ls in segment_lengths(y).items():\n",
        "            if c!=0: agg[c].extend(ls)\n",
        "    med = np.zeros(21, dtype=np.float32)\n",
        "    for c in range(1,21):\n",
        "        ls = agg.get(c, [])\n",
        "        med[c] = float(np.median(ls)) if ls else 1.0\n",
        "    return med\n",
        "\n",
        "def fuse_entropy_adaptive(ps: np.ndarray, pr: np.ndarray | None, alpha0: float, beta: float, a_min: float, a_max: float) -> np.ndarray:\n",
        "    if pr is None:\n",
        "        return ps\n",
        "    # Align\n",
        "    pr_a, ps_a = align_by_entropy_corr(pr, ps, max_shift=15)\n",
        "    # Crop to common\n",
        "    Tm = min(ps_a.shape[1], pr_a.shape[1])\n",
        "    ps_a = ps_a[:, :Tm]; pr_a = pr_a[:, :Tm]\n",
        "    Hs = entropy(ps_a); Hr = entropy(pr_a)\n",
        "    a_t = alpha0 + beta*(Hr - Hs)\n",
        "    a_t = np.clip(a_t, a_min, a_max).astype(np.float32)\n",
        "    logp = (1.0 - a_t)[None,:]*np.log(np.clip(ps_a,1e-8,1.0)) + a_t[None,:]*np.log(np.clip(pr_a,1e-8,1.0))\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def oof_eval_entropy_adaptive(grid_alpha0, grid_beta, bounds_list, smooth_k=5, min_mult=0.7):\n",
        "    results = {}\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med = compute_min_dur_from_ids(tr); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "        for a0 in grid_alpha0:\n",
        "            for b in grid_beta:\n",
        "                for (a_min, a_max) in bounds_list:\n",
        "                    key=(a0,b,a_min,a_max,fd['fold'])\n",
        "                    dists=[]\n",
        "                    for sid in va:\n",
        "                        ps = load_skeleton_probs(int(sid))\n",
        "                        pr = load_rgb_probs(int(sid))\n",
        "                        pf = fuse_entropy_adaptive(ps, pr, a0, b, a_min, a_max)\n",
        "                        pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                        y = decode_minseg(pf, min_dur)\n",
        "                        y = aba_collapse(y, max_len=2, ratio=1.04, p=pf)\n",
        "                        seq = compress_to_sequence(y)\n",
        "                        y_true = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "                        seq_true = compress_to_sequence(y_true)\n",
        "                        # Levenshtein\n",
        "                        n=len(seq); m=len(seq_true);\n",
        "                        if n==0: d=m; dists.append(d); continue\n",
        "                        dp=list(range(m+1))\n",
        "                        for i in range(1,n+1):\n",
        "                            prev=dp[0]; dp[0]=i\n",
        "                            for j in range(1,m+1):\n",
        "                                tmp=dp[j]; cost=0 if seq[i-1]==seq_true[j-1] else 1\n",
        "                                dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "                        dists.append(dp[m])\n",
        "                    results.setdefault((a0,b,a_min,a_max), []).append(float(np.mean(dists)))\n",
        "    # summarize by worst-fold then mean\n",
        "    summary=[]\n",
        "    for k, arr in results.items():\n",
        "        worst=max(arr); mean=float(np.mean(arr))\n",
        "        summary.append((worst, mean, k))\n",
        "    summary.sort(key=lambda x: (x[0], x[1]))\n",
        "    return summary\n",
        "\n",
        "def decode_test_with_best(a0, b, a_min, a_max, smooth_k=5, min_mult=0.7, out_csv='submission_entropy_adapt.csv'):\n",
        "    med = compute_min_dur_from_ids(all_train_ids); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time()\n",
        "    n=0\n",
        "    for sid in test_ids:\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        ps = load_skeleton_probs(int(sid))\n",
        "        pr = load_rgb_probs(int(sid))\n",
        "        pf = fuse_entropy_adaptive(ps, pr, a0, b, a_min, a_max)\n",
        "        pf = smooth_probs_box(pf, k=smooth_k)\n",
        "        y = decode_minseg(pf, min_dur)\n",
        "        y = aba_collapse(y, max_len=2, ratio=1.04, p=pf)\n",
        "        seq_raw = compress_to_sequence(y)\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    sub.to_csv('submission.csv', index=False); print('submission.csv written ->', out_csv)\n",
        "\n",
        "# Grid and run\n",
        "grid_alpha0 = [0.24, 0.26]\n",
        "grid_beta   = [0.15, 0.30]\n",
        "bounds_list = [(0.15, 0.40), (0.20, 0.45)]\n",
        "print('OOF tuning entropy-adaptive fusion...', flush=True)\n",
        "summary = oof_eval_entropy_adaptive(grid_alpha0, grid_beta, bounds_list, smooth_k=5, min_mult=0.7)\n",
        "best = summary[0]\n",
        "print('Best (worst,mean,params)=', best[:2], best[2])\n",
        "a0,b,a_min,a_max = best[2]\n",
        "out_csv = f\"submission_entropy_adapt_a{str(a0).replace('.','')}_b{str(b).replace('.','')}_l{str(a_min).replace('.','')}_u{str(a_max).replace('.','')}.csv\"\n",
        "print('Decoding TEST with best params...', flush=True)\n",
        "decode_test_with_best(a0, b, a_min, a_max, smooth_k=5, min_mult=0.7, out_csv=out_csv)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF tuning entropy-adaptive fusion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best (worst,mean,params)= (4.69, 4.055534254105683) (0.24, 0.15, 0.15, 0.4)\nDecoding TEST with best params...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_entropy_adapt_a024_b015_l015_u04.csv rows= 95\nsubmission.csv written -> submission_entropy_adapt_a024_b015_l015_u04.csv\n"
          ]
        }
      ]
    },
    {
      "id": "b397e4f9-5957-44f2-88ba-54fb12d7a675",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Restore best-known baseline submission\n",
        "import shutil, os\n",
        "src = 'submission_fused_rgb_audio_g025.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "shutil.copyfile(src, dst)\n",
        "print(f'Restored baseline submission: {src} -> {dst}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored baseline submission: submission_fused_rgb_audio_g025.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "db9b8f08-bebe-4df6-a59e-3b2fc23c96a8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Depth+User visual hedge: average visual (rgb/depth/user), PoE with skeleton+audio; small OOF grid and test decode\n",
        "import numpy as np, pandas as pd, json, time, os\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "probs_cache = Path('probs_cache')\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "\n",
        "# Reuse folds and skeleton calibration from cell 0 if available; otherwise reload\n",
        "try:\n",
        "    folds\n",
        "except NameError:\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "try:\n",
        "    T2\n",
        "except NameError:\n",
        "    calib = json.load(open('calib_all_v2v3_meta.json','r'))\n",
        "    T2 = np.array(calib['T2'], dtype=np.float32)\n",
        "    T3 = np.array(calib['T3'], dtype=np.float32)\n",
        "    A  = np.array(calib.get('A', [0.7]*len(T2)), dtype=np.float32)\n",
        "\n",
        "def ensure_CxT(p, C=21):\n",
        "    if p is None: return None\n",
        "    if p.ndim==2 and p.shape[0]==C: return p\n",
        "    if p.ndim==2 and p.shape[1]==C: return p.T\n",
        "    raise ValueError('Bad probs shape')\n",
        "\n",
        "def load_skeleton_probs(seq_id: int) -> np.ndarray:\n",
        "    p2 = np.load(probs_cache/f\"{seq_id}_ce.npy\").astype(np.float32)\n",
        "    p3 = np.load(probs_cache/f\"{seq_id}_ce_v3.npy\").astype(np.float32)\n",
        "    # temp_scale already applied in upstream pipelines; calib here was used previously; trust cached probs to be calibrated\n",
        "    p2 = ensure_CxT(p2); p3 = ensure_CxT(p3)\n",
        "    Tm = min(p2.shape[1], p3.shape[1])\n",
        "    p2 = p2[:, :Tm]; p3 = p3[:, :Tm]\n",
        "    a = A.reshape(-1,1).astype(np.float32)\n",
        "    p = a*p2 + (1.0-a)*p3\n",
        "    p /= (p.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return p.astype(np.float32)\n",
        "\n",
        "def load_probs_generic(seq_id: int, suffix: str) -> np.ndarray | None:\n",
        "    pth = probs_cache/f\"{seq_id}_{suffix}.npy\"\n",
        "    if not pth.exists(): return None\n",
        "    p = np.load(pth).astype(np.float32)\n",
        "    return ensure_CxT(p)\n",
        "\n",
        "def entropy(p: np.ndarray) -> np.ndarray:\n",
        "    q = np.clip(p, 1e-8, 1.0)\n",
        "    return -np.sum(q*np.log(q), axis=0)\n",
        "\n",
        "def align_by_entropy_corr(p_src: np.ndarray, p_ref: np.ndarray, max_shift: int = 15):\n",
        "    hs = entropy(p_src); hr = entropy(p_ref)\n",
        "    best = (-1e9, 0)\n",
        "    for sh in range(-max_shift, max_shift+1):\n",
        "        if sh >= 0:\n",
        "            L = min(hs.shape[0] - sh, hr.shape[0])\n",
        "            if L < 16: continue\n",
        "            s = hs[sh:sh+L]; r = hr[:L]\n",
        "        else:\n",
        "            L = min(hs.shape[0], hr.shape[0] + sh)\n",
        "            if L < 16: continue\n",
        "            s = hs[:L]; r = hr[-sh:-sh+L]\n",
        "        if s.std() < 1e-8 or r.std() < 1e-8:\n",
        "            corr = -1.0\n",
        "        else:\n",
        "            corr = float(np.corrcoef(s, r)[0,1])\n",
        "        if corr > best[0]: best = (corr, sh)\n",
        "    sh = best[1]\n",
        "    if sh >= 0:\n",
        "        L = min(p_src.shape[1] - sh, p_ref.shape[1])\n",
        "        return p_src[:, sh:sh+L], p_ref[:, :L]\n",
        "    else:\n",
        "        L = min(p_src.shape[1], p_ref.shape[1] + sh)\n",
        "        return p_src[:, :L], p_ref[:, -sh:-sh+L]\n",
        "\n",
        "def smooth_probs_box(p: np.ndarray, k: int = 5) -> np.ndarray:\n",
        "    if k<=1: return p\n",
        "    C,T = p.shape\n",
        "    pad = k//2\n",
        "    x = np.pad(p, ((0,0),(pad,pad)), mode='edge')\n",
        "    cs = np.cumsum(x, axis=1, dtype=np.float64)\n",
        "    out = (cs[:, k:] - cs[:, :-k]) / k\n",
        "    out = out.astype(np.float32)\n",
        "    out /= (out.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return out\n",
        "\n",
        "def decode_minseg(p: np.ndarray, min_dur: np.ndarray) -> np.ndarray:\n",
        "    y = p.argmax(axis=0).astype(np.int32)\n",
        "    T = y.shape[0]; i=0\n",
        "    while i < T:\n",
        "        c = y[i]; j=i+1\n",
        "        while j<T and y[j]==c: j+=1\n",
        "        L = j-i\n",
        "        if c!=0 and L < int(min_dur[c]):\n",
        "            lc = y[i-1] if i>0 else None\n",
        "            rc = y[j] if j<T else None\n",
        "            ls = float(p[lc, i:j].mean()) if lc is not None else -1e9\n",
        "            rs = float(p[rc, i:j].mean()) if rc is not None else -1e9\n",
        "            if rs >= ls: y[i:j] = rc if rc is not None else 0\n",
        "            else:        y[i:j] = lc if lc is not None else 0\n",
        "            i = max(0, i-1); continue\n",
        "        i = j\n",
        "    return y\n",
        "\n",
        "def aba_collapse(y: np.ndarray, max_len: int = 2, ratio: float = 1.04, p: np.ndarray | None = None) -> np.ndarray:\n",
        "    T = len(y); i=1\n",
        "    while i < T-1:\n",
        "        if y[i-1]==y[i+1] and y[i]!=y[i-1]:\n",
        "            L=1; j=i+1\n",
        "            while j<T-1 and y[j-1]==y[j+1] and y[j]!=y[j-1]:\n",
        "                L+=1; j+=1\n",
        "            if L<=max_len:\n",
        "                y[i:j] = y[i-1]\n",
        "                i = max(1, i-1); continue\n",
        "            i = j\n",
        "        i+=1\n",
        "    return y\n",
        "\n",
        "def compress_to_sequence(y_frames):\n",
        "    seq=[]; last=-1\n",
        "    for c in y_frames:\n",
        "        if c==0: continue\n",
        "        if c!=last: seq.append(int(c)); last=int(c)\n",
        "    return seq\n",
        "\n",
        "def make_perm20(seq_raw, p: np.ndarray):\n",
        "    seen=set(); seq=[]\n",
        "    for c in seq_raw:\n",
        "        if 1<=c<=20 and c not in seen:\n",
        "            seen.add(c); seq.append(c)\n",
        "    if len(seq)<20:\n",
        "        masses = [(c, float(p[c].sum())) for c in range(1,21) if c not in seen]\n",
        "        masses.sort(key=lambda x: x[1], reverse=True)\n",
        "        for c,_ in masses:\n",
        "            if len(seq)==20: break\n",
        "            seq.append(c)\n",
        "    if len(seq)>20: seq = seq[:20]\n",
        "    return seq\n",
        "\n",
        "def segment_lengths(y):\n",
        "    lens=defaultdict(list); cur=None; run=0\n",
        "    for c in y:\n",
        "        if c==0:\n",
        "            if cur is not None: lens[cur].append(run); cur=None; run=0\n",
        "            continue\n",
        "        if cur is None: cur=int(c); run=1\n",
        "        elif c==cur: run+=1\n",
        "        else: lens[cur].append(run); cur=int(c); run=1\n",
        "    if cur is not None: lens[cur].append(run)\n",
        "    return lens\n",
        "\n",
        "def compute_min_dur_from_ids(ids):\n",
        "    agg=defaultdict(list)\n",
        "    for sid in ids:\n",
        "        y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "        for c,ls in segment_lengths(y).items():\n",
        "            if c!=0: agg[c].extend(ls)\n",
        "    med = np.zeros(21, dtype=np.float32)\n",
        "    for c in range(1,21):\n",
        "        ls = agg.get(c, [])\n",
        "        med[c] = float(np.median(ls)) if ls else 1.0\n",
        "    return med\n",
        "\n",
        "def visual_average_aligned(ps: np.ndarray, pr: np.ndarray | None, pdepth: np.ndarray | None, pu: np.ndarray | None) -> np.ndarray | None:\n",
        "    streams=[]\n",
        "    for pv in (pr, pdepth, pu):\n",
        "        if pv is None: continue\n",
        "        pv_a, ps_a = align_by_entropy_corr(pv, ps, max_shift=15)\n",
        "        # crop to common length with skeleton-aligned reference\n",
        "        Tm = min(pv_a.shape[1], ps_a.shape[1])\n",
        "        streams.append(pv_a[:, :Tm])\n",
        "    if not streams: return None\n",
        "    # average and renormalize\n",
        "    L = min(s.shape[1] for s in streams)\n",
        "    streams = [s[:, :L] for s in streams]\n",
        "    v = np.mean(streams, axis=0)\n",
        "    v /= (v.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return v.astype(np.float32)\n",
        "\n",
        "def fuse_poe(ps: np.ndarray, pvis: np.ndarray | None, pa: np.ndarray | None, alpha_vis: float, gamma_a: float) -> np.ndarray:\n",
        "    # Align each non-skeleton to skeleton independently, crop to common T\n",
        "    parts = [ps]\n",
        "    if pvis is not None:\n",
        "        pvis_a, ps_a = align_by_entropy_corr(pvis, ps, max_shift=15)\n",
        "        parts.append(pvis_a); ps = ps_a\n",
        "    if pa is not None:\n",
        "        pa_a, ps_a2 = align_by_entropy_corr(pa, ps, max_shift=15)\n",
        "        parts.append(pa_a); ps = ps_a2\n",
        "    Tm = min(p.shape[1] for p in parts)\n",
        "    ps = ps[:, :Tm]\n",
        "    pvis_c = parts[1][:, :Tm] if (pvis is not None) else None\n",
        "    pa_c   = parts[-1][:Tm] if False else None  # placeholder to keep lints calm\n",
        "    pa_c = parts[-1][:, :Tm] if (pa is not None) else None\n",
        "    w_s = max(0.0, 1.0 - (alpha_vis if pvis is not None else 0.0) - (gamma_a if pa is not None else 0.0))\n",
        "    logp = w_s*np.log(np.clip(ps,1e-8,1.0))\n",
        "    if pvis is not None:\n",
        "        logp += alpha_vis*np.log(np.clip(pvis_c,1e-8,1.0))\n",
        "    if pa is not None:\n",
        "        logp += gamma_a*np.log(np.clip(pa_c,1e-8,1.0))\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def oof_eval_visual_audio_hedge(alpha_list, gamma_list, smooth_k=5, min_mult=0.7):\n",
        "    results = {}\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med = compute_min_dur_from_ids(tr); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "        for av in alpha_list:\n",
        "            for ga in gamma_list:\n",
        "                key=(av,ga,fd['fold'])\n",
        "                dists=[]\n",
        "                for sid in va:\n",
        "                    ps = load_skeleton_probs(int(sid))\n",
        "                    pr = load_probs_generic(int(sid), 'rgb')\n",
        "                    pdepth = load_probs_generic(int(sid), 'depth')\n",
        "                    pu = load_probs_generic(int(sid), 'user')\n",
        "                    pa = load_probs_generic(int(sid), 'audio')\n",
        "                    pvis = visual_average_aligned(ps, pr, pdepth, pu)\n",
        "                    pf = fuse_poe(ps, pvis, pa, av, ga)\n",
        "                    pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                    y = decode_minseg(pf, min_dur)\n",
        "                    y = aba_collapse(y, max_len=2, ratio=1.04, p=pf)\n",
        "                    seq = compress_to_sequence(y)\n",
        "                    y_true = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "                    seq_true = compress_to_sequence(y_true)\n",
        "                    # Levenshtein\n",
        "                    n=len(seq); m=len(seq_true);\n",
        "                    if n==0: d=m; dists.append(d); continue\n",
        "                    dp=list(range(m+1))\n",
        "                    for i in range(1,n+1):\n",
        "                        prev=dp[0]; dp[0]=i\n",
        "                        for j in range(1,m+1):\n",
        "                            tmp=dp[j]; cost=0 if seq[i-1]==seq_true[j-1] else 1\n",
        "                            dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "                    dists.append(dp[m])\n",
        "                results.setdefault((av,ga), []).append(float(np.mean(dists)))\n",
        "    summary=[]\n",
        "    for k, arr in results.items():\n",
        "        worst=max(arr); mean=float(np.mean(arr))\n",
        "        summary.append((worst, mean, k))\n",
        "    summary.sort(key=lambda x: (x[0], x[1]))\n",
        "    return summary\n",
        "\n",
        "def decode_test_visual_audio_hedge(av, ga, smooth_k=5, min_mult=0.7, out_csv='submission_va_hedge.csv'):\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        ps = load_skeleton_probs(int(sid))\n",
        "        pr = load_probs_generic(int(sid), 'rgb')\n",
        "        pdepth = load_probs_generic(int(sid), 'depth')\n",
        "        pu = load_probs_generic(int(sid), 'user')\n",
        "        pa = load_probs_generic(int(sid), 'audio')\n",
        "        pvis = visual_average_aligned(ps, pr, pdepth, pu)\n",
        "        pf = fuse_poe(ps, pvis, pa, av, ga)\n",
        "        pf = smooth_probs_box(pf, k=smooth_k)\n",
        "        y = decode_minseg(pf, min_dur)\n",
        "        y = aba_collapse(y, max_len=2, ratio=1.04, p=pf)\n",
        "        seq_raw = compress_to_sequence(y)\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    sub.to_csv('submission.csv', index=False); print('submission.csv written ->', out_csv)\n",
        "\n",
        "# Run small grid\n",
        "alpha_list = [0.20, 0.25, 0.30]\n",
        "gamma_list = [0.20, 0.25, 0.30]\n",
        "print('OOF tuning visual+audio hedge...', flush=True)\n",
        "summary = oof_eval_visual_audio_hedge(alpha_list, gamma_list, smooth_k=5, min_mult=0.7)\n",
        "best = summary[0]\n",
        "print('Best (worst,mean,params)=', best[:2], best[2])\n",
        "av,ga = best[2]\n",
        "out_csv = f\"submission_visavg_poe_av{str(av).replace('.','')}_ga{str(ga).replace('.','')}.csv\"\n",
        "print('Decoding TEST with best params...', flush=True)\n",
        "decode_test_visual_audio_hedge(av, ga, smooth_k=5, min_mult=0.7, out_csv=out_csv)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF tuning visual+audio hedge...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best (worst,mean,params)= (4.57, 3.8699285370713947) (0.25, 0.2)\nDecoding TEST with best params...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_visavg_poe_av025_ga02.csv rows= 95\nsubmission.csv written -> submission_visavg_poe_av025_ga02.csv\n"
          ]
        }
      ]
    },
    {
      "id": "f691afb6-ed6f-4758-9c8e-fd482a5449bd",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Segmental Viterbi/HSMM decoder with duration and sparse transitions; OOF tiny grid and test decode\n",
        "import numpy as np, pandas as pd, json, time, os\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "probs_cache = Path('probs_cache')\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "\n",
        "try:\n",
        "    folds\n",
        "except NameError:\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "\n",
        "# Utilities reused from previous cells if present; define minimal fallbacks\n",
        "def ensure_CxT(p, C=21):\n",
        "    if p is None: return None\n",
        "    if p.ndim==2 and p.shape[0]==C: return p\n",
        "    if p.ndim==2 and p.shape[1]==C: return p.T\n",
        "    raise ValueError('Bad probs shape')\n",
        "\n",
        "def load_skeleton_probs(seq_id: int) -> np.ndarray:\n",
        "    p2 = np.load(probs_cache/f\"{seq_id}_ce.npy\").astype(np.float32)\n",
        "    p3 = np.load(probs_cache/f\"{seq_id}_ce_v3.npy\").astype(np.float32)\n",
        "    p2 = ensure_CxT(p2); p3 = ensure_CxT(p3)\n",
        "    Tm = min(p2.shape[1], p3.shape[1])\n",
        "    p2 = p2[:, :Tm]; p3 = p3[:, :Tm]\n",
        "    # Per-class blend weight A loaded in other cells; fall back to 0.7 if missing\n",
        "    try:\n",
        "        a = A.reshape(-1,1).astype(np.float32)\n",
        "    except NameError:\n",
        "        a = np.full((21,1), 0.7, dtype=np.float32)\n",
        "    p = a*p2 + (1.0-a)*p3\n",
        "    p /= (p.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return p.astype(np.float32)\n",
        "\n",
        "def load_probs_generic(seq_id: int, suffix: str) -> np.ndarray | None:\n",
        "    pth = probs_cache/f\"{seq_id}_{suffix}.npy\"\n",
        "    if not pth.exists(): return None\n",
        "    p = np.load(pth).astype(np.float32)\n",
        "    return ensure_CxT(p)\n",
        "\n",
        "def entropy(p: np.ndarray) -> np.ndarray:\n",
        "    q = np.clip(p, 1e-8, 1.0)\n",
        "    return -np.sum(q*np.log(q), axis=0)\n",
        "\n",
        "def align_by_entropy_corr(p_src: np.ndarray, p_ref: np.ndarray, max_shift: int = 15):\n",
        "    hs = entropy(p_src); hr = entropy(p_ref)\n",
        "    best = (-1e9, 0)\n",
        "    for sh in range(-max_shift, max_shift+1):\n",
        "        if sh >= 0:\n",
        "            L = min(hs.shape[0] - sh, hr.shape[0])\n",
        "            if L < 16: continue\n",
        "            s = hs[sh:sh+L]; r = hr[:L]\n",
        "        else:\n",
        "            L = min(hs.shape[0], hr.shape[0] + sh)\n",
        "            if L < 16: continue\n",
        "            s = hs[:L]; r = hr[-sh:-sh+L]\n",
        "        if s.std() < 1e-8 or r.std() < 1e-8:\n",
        "            corr = -1.0\n",
        "        else:\n",
        "            corr = float(np.corrcoef(s, r)[0,1])\n",
        "        if corr > best[0]: best = (corr, sh)\n",
        "    sh = best[1]\n",
        "    if sh >= 0:\n",
        "        L = min(p_src.shape[1] - sh, p_ref.shape[1])\n",
        "        return p_src[:, sh:sh+L], p_ref[:, :L]\n",
        "    else:\n",
        "        L = min(p_src.shape[1], p_ref.shape[1] + sh)\n",
        "        return p_src[:, :L], p_ref[:, -sh:-sh+L]\n",
        "\n",
        "def smooth_probs_box(p: np.ndarray, k: int = 5) -> np.ndarray:\n",
        "    if k<=1: return p\n",
        "    C,T = p.shape\n",
        "    pad = k//2\n",
        "    x = np.pad(p, ((0,0),(pad,pad)), mode='edge')\n",
        "    cs = np.cumsum(x, axis=1, dtype=np.float64)\n",
        "    out = (cs[:, k:] - cs[:, :-k]) / k\n",
        "    out = out.astype(np.float32)\n",
        "    out /= (out.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return out\n",
        "\n",
        "# Visual/audio fusion: average visual streams then PoE with skeleton and audio\n",
        "def visual_average_aligned(ps: np.ndarray, pr: np.ndarray | None, pdepth: np.ndarray | None, pu: np.ndarray | None) -> np.ndarray | None:\n",
        "    streams=[]\n",
        "    for pv in (pr, pdepth, pu):\n",
        "        if pv is None: continue\n",
        "        pv_a, ps_a = align_by_entropy_corr(pv, ps, max_shift=15)\n",
        "        Tm = min(pv_a.shape[1], ps_a.shape[1])\n",
        "        streams.append(pv_a[:, :Tm])\n",
        "    if not streams: return None\n",
        "    L = min(s.shape[1] for s in streams)\n",
        "    streams = [s[:, :L] for s in streams]\n",
        "    v = np.mean(streams, axis=0)\n",
        "    v /= (v.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return v.astype(np.float32)\n",
        "\n",
        "def fuse_poe_fixed(ps: np.ndarray, pvis: np.ndarray | None, pa: np.ndarray | None, alpha_vis: float = 0.26, gamma_a: float = 0.25) -> np.ndarray:\n",
        "    parts = [ps]\n",
        "    if pvis is not None:\n",
        "        pvis_a, ps_a = align_by_entropy_corr(pvis, ps, max_shift=15)\n",
        "        parts.append(pvis_a); ps = ps_a\n",
        "    if pa is not None:\n",
        "        pa_a, ps_a2 = align_by_entropy_corr(pa, ps, max_shift=15)\n",
        "        parts.append(pa_a); ps = ps_a2\n",
        "    Tm = min(p.shape[1] for p in parts)\n",
        "    ps = ps[:, :Tm]\n",
        "    pvis_c = parts[1][:, :Tm] if (pvis is not None) else None\n",
        "    pa_c = parts[-1][:, :Tm] if (pa is not None) else None\n",
        "    w_s = max(0.0, 1.0 - (alpha_vis if pvis is not None else 0.0) - (gamma_a if pa is not None else 0.0))\n",
        "    logp = w_s*np.log(np.clip(ps,1e-8,1.0))\n",
        "    if pvis is not None: logp += alpha_vis*np.log(np.clip(pvis_c,1e-8,1.0))\n",
        "    if pa is not None:   logp += gamma_a*np.log(np.clip(pa_c,1e-8,1.0))\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "# Duration priors from labels3d_v2\n",
        "def segment_lengths(y):\n",
        "    lens=defaultdict(list); cur=None; run=0\n",
        "    for c in y:\n",
        "        if c==0:\n",
        "            if cur is not None: lens[cur].append(run); cur=None; run=0\n",
        "            continue\n",
        "        if cur is None: cur=int(c); run=1\n",
        "        elif c==cur: run+=1\n",
        "        else: lens[cur].append(run); cur=int(c); run=1\n",
        "    if cur is not None: lens[cur].append(run)\n",
        "    return lens\n",
        "\n",
        "def compute_duration_pmf(ids, max_dur=150):\n",
        "    counts = np.ones((21, max_dur+1), dtype=np.float64)  # Laplace +1, index by duration d (1..max_dur)\n",
        "    for sid in ids:\n",
        "        y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "        lens = segment_lengths(y)\n",
        "        for c, arr in lens.items():\n",
        "            if c==0: continue\n",
        "            for L in arr:\n",
        "                d = int(min(L, max_dur))\n",
        "                counts[c, d] += 1.0\n",
        "    # class 0: keep Laplace baseline only (uniform-ish after norm)\n",
        "    pmf = counts / counts.sum(axis=1, keepdims=True)\n",
        "    log_pmf = -np.log(np.clip(pmf, 1e-12, 1.0))\n",
        "    return log_pmf.astype(np.float32)\n",
        "\n",
        "# Transition priors: allow only gesture<->silence and silence->silence\n",
        "def compute_transition_cost(ids):\n",
        "    trans = np.full((21,21), 1e-9, dtype=np.float64)  # smoothing\n",
        "    for sid in ids:\n",
        "        y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "        # traverse segments\n",
        "        cur=None; run=0; segs=[]\n",
        "        for c in y:\n",
        "            if cur is None: cur=int(c); run=1\n",
        "            elif c==cur: run+=1\n",
        "            else: segs.append(cur); cur=int(c); run=1\n",
        "        if cur is not None: segs.append(cur)\n",
        "        for i in range(1, len(segs)):\n",
        "            a = int(segs[i-1]); b = int(segs[i])\n",
        "            trans[a, b] += 1.0\n",
        "    # enforce sparsity: gesture->gesture (i!=j) forbidden by huge cost\n",
        "    allowed = np.zeros_like(trans, dtype=bool)\n",
        "    allowed[0, :] = True  # silence to any\n",
        "    allowed[:, 0] = True  # any to silence\n",
        "    # keep silence->silence allowed; gestures->gestures disallowed\n",
        "    probs = trans / trans.sum(axis=1, keepdims=True)\n",
        "    cost = -np.log(np.clip(probs, 1e-12, 1.0))\n",
        "    big = 1e6\n",
        "    for i in range(21):\n",
        "        for j in range(21):\n",
        "            if not (allowed[i,j] or (i==j==0)):\n",
        "                cost[i,j] = big\n",
        "    return cost.astype(np.float32)\n",
        "\n",
        "def smooth1d_keep_len(x: np.ndarray, k: int) -> np.ndarray:\n",
        "    if k<=1: return x.astype(np.float32, copy=False)\n",
        "    kernel = np.ones(k, dtype=np.float32)/k\n",
        "    pad = k//2\n",
        "    xpad = np.pad(x, (pad, pad), mode='edge')\n",
        "    y = np.convolve(xpad, kernel, mode='valid')  # length T\n",
        "    return y.astype(np.float32)\n",
        "\n",
        "# Segmental Viterbi\n",
        "def seg_viterbi(p: np.ndarray, log_dur: np.ndarray, trans_cost: np.ndarray, w_dur=1.0, w_tr=1.0, max_dur=150, per_class_smooth=False):\n",
        "    C,T = p.shape\n",
        "    # optional per-class smoothing (preserve length exactly)\n",
        "    if per_class_smooth:\n",
        "        ks = np.clip((0.5*np.ones(C)*7).astype(int), 3, 15)\n",
        "        ps = np.empty_like(p)\n",
        "        for c in range(C):\n",
        "            k = int(ks[c])\n",
        "            ps[c] = smooth1d_keep_len(p[c], k)\n",
        "        p = ps; p /= (p.sum(axis=0, keepdims=True)+1e-8)\n",
        "    # emission prefix sums\n",
        "    nll = -np.log(np.clip(p, 1e-8, 1.0)).astype(np.float32)\n",
        "    pref = np.cumsum(nll, axis=1, dtype=np.float64)\n",
        "    def seg_cost(c, t0, t1):\n",
        "        if t0<=0: return float(pref[c, t1-1])\n",
        "        return float(pref[c, t1-1] - pref[c, t0-1])\n",
        "    # DP arrays\n",
        "    INF = 1e18\n",
        "    dp = np.full((C, T+1), INF, dtype=np.float64)  # dp[c, t] best cost ending exactly at t with class c segment\n",
        "    bp_prev_c = -np.ones((C, T+1), dtype=np.int16)\n",
        "    bp_prev_t = -np.ones((C, T+1), dtype=np.int32)\n",
        "    # base: start at t=0 coming from silence\n",
        "    dp[:,0] = INF; dp[0,0] = 0.0\n",
        "    # iterate end time t\n",
        "    for t in range(1, T+1):\n",
        "        # consider class c for the segment ending at t with duration d\n",
        "        maxd = min(max_dur, t)\n",
        "        for c in range(C):\n",
        "            best_cost = INF; best_prev_c = -1; best_prev_t = -1\n",
        "            # allowed previous class\n",
        "            if c==0:\n",
        "                prev_classes = list(range(C))  # any to silence\n",
        "            else:\n",
        "                prev_classes = [0]  # only silence to gesture\n",
        "            for d in range(1, maxd+1):\n",
        "                t0 = t - d\n",
        "                emis = seg_cost(c, t0, t)\n",
        "                durc = 0.0 if c==0 else float(log_dur[c, min(d, log_dur.shape[1]-1)])\n",
        "                for pc in prev_classes:\n",
        "                    prev_cost = dp[pc, t0]\n",
        "                    if prev_cost >= INF: continue\n",
        "                    tc = float(trans_cost[pc, c])\n",
        "                    cost = prev_cost + emis + w_dur*durc + w_tr*tc\n",
        "                    if cost < best_cost:\n",
        "                        best_cost = cost; best_prev_c = pc; best_prev_t = t0\n",
        "            dp[c, t] = best_cost; bp_prev_c[c, t] = best_prev_c; bp_prev_t[c, t] = best_prev_t\n",
        "    # best ending state at T\n",
        "    c_end = int(np.argmin(dp[:, T]))\n",
        "    # backtrack\n",
        "    segs=[]; c=c_end; t=T\n",
        "    while t>0 and c>=0:\n",
        "        t0 = int(bp_prev_t[c, t]); pc = int(bp_prev_c[c, t])\n",
        "        if t0<0 or pc<0: break\n",
        "        segs.append((c, t0, t))\n",
        "        c = pc; t = t0\n",
        "    segs.reverse()\n",
        "    # build framewise labels\n",
        "    y = np.zeros(T, dtype=np.int32)\n",
        "    for c, t0, t1 in segs:\n",
        "        if c==0: continue\n",
        "        y[t0:t1] = int(c)\n",
        "    return y\n",
        "\n",
        "# OOF evaluation\n",
        "def build_fused_probs_for_id(sid: int, alpha_vis=0.26, gamma_a=0.25, smooth_k=5):\n",
        "    ps = load_skeleton_probs(sid)\n",
        "    pr = load_probs_generic(sid, 'rgb')\n",
        "    pdepth = load_probs_generic(sid, 'depth')\n",
        "    pu = load_probs_generic(sid, 'user')\n",
        "    pa = load_probs_generic(sid, 'audio')\n",
        "    pvis = visual_average_aligned(ps, pr, pdepth, pu)\n",
        "    pf = fuse_poe_fixed(ps, pvis, pa, alpha_vis=alpha_vis, gamma_a=gamma_a)\n",
        "    pf = smooth_probs_box(pf, k=smooth_k)\n",
        "    return pf\n",
        "\n",
        "def lev_dist(a, b):\n",
        "    n=len(a); m=len(b)\n",
        "    if n==0: return m\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; cost=0 if a[i-1]==b[j-1] else 1\n",
        "            dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "def oof_eval_hsmm(grid_wdur=(0.5,1.0), grid_wtr=(0.5,1.0), grid_maxd=(100,150), per_class_smooth_opts=(False, True)):\n",
        "    print('OOF HSMM tuning...', flush=True)\n",
        "    results = {}\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        log_dur = compute_duration_pmf(tr, max_dur=max(grid_maxd))\n",
        "        trans_cost = compute_transition_cost(tr)\n",
        "        for wd in grid_wdur:\n",
        "            for wt in grid_wtr:\n",
        "                for md in grid_maxd:\n",
        "                    for pcs in per_class_smooth_opts:\n",
        "                        key=(wd,wt,md,pcs); dists=[]\n",
        "                        t0=time.time()\n",
        "                        for sid in va:\n",
        "                            pf = build_fused_probs_for_id(int(sid), alpha_vis=0.26, gamma_a=0.25, smooth_k=5)\n",
        "                            y = seg_viterbi(pf, log_dur, trans_cost, w_dur=wd, w_tr=wt, max_dur=md, per_class_smooth=pcs)\n",
        "                            # post\n",
        "                            y = aba_collapse(y, max_len=2, ratio=1.04, p=pf)\n",
        "                            seq = [int(c) for i,c in enumerate(y) if c!=0 and (i==0 or y[i-1]!=c)]\n",
        "                            y_true = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "                            seq_true = [int(c) for i,c in enumerate(y_true) if c!=0 and (i==0 or y_true[i-1]!=c)]\n",
        "                            dists.append(lev_dist(seq, seq_true))\n",
        "                        results.setdefault(key, []).append(float(np.mean(dists)))\n",
        "                        print(f\"fold={fd['fold']} wd={wd} wt={wt} md={md} pcs={pcs} mean={np.mean(dists):.3f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "    summary=[]\n",
        "    for k, arr in results.items():\n",
        "        worst=max(arr); mean=float(np.mean(arr))\n",
        "        summary.append((worst, mean, k))\n",
        "    summary.sort(key=lambda x: (x[0], x[1]))\n",
        "    return summary\n",
        "\n",
        "def decode_test_hsmm(best_params, out_csv='submission_hsmm_poe.csv'):\n",
        "    wd,wt,md,pcs = best_params\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    log_dur = compute_duration_pmf(all_train_ids, max_dur=md)\n",
        "    trans_cost = compute_transition_cost(all_train_ids)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        pf = build_fused_probs_for_id(int(sid), alpha_vis=0.26, gamma_a=0.25, smooth_k=5)\n",
        "        y = seg_viterbi(pf, log_dur, trans_cost, w_dur=wd, w_tr=wt, max_dur=md, per_class_smooth=pcs)\n",
        "        y = aba_collapse(y, max_len=2, ratio=1.04, p=pf)\n",
        "        seq_raw = [int(c) for i,c in enumerate(y) if c!=0 and (i==0 or y[i-1]!=c)]\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    sub.to_csv('submission.csv', index=False); print('submission.csv written ->', out_csv)\n",
        "\n",
        "# Run narrowed grid OOF then decode test\n",
        "summary = oof_eval_hsmm(grid_wdur=(1.0,), grid_wtr=(0.5,), grid_maxd=(100,), per_class_smooth_opts=(False,))\n",
        "best = summary[0]\n",
        "print('HSMM Best (worst,mean,params)=', best[:2], best[2])\n",
        "wd,wt,md,pcs = best[2]\n",
        "out_csv = f\"submission_hsmm_poe_wd{str(wd).replace('.','')}_wt{str(wt).replace('.','')}_md{md}_pcs{int(pcs)}.csv\"\n",
        "print('Decoding TEST with best params...', flush=True)\n",
        "decode_test_hsmm((wd,wt,md,pcs), out_csv=out_csv)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF HSMM tuning...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 322\u001b[39m\n\u001b[32m    319\u001b[39m     sub.to_csv(\u001b[33m'\u001b[39m\u001b[33msubmission.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m); \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33msubmission.csv written ->\u001b[39m\u001b[33m'\u001b[39m, out_csv)\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# Run narrowed grid OOF then decode test\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m summary = \u001b[43moof_eval_hsmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_wdur\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_wtr\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_maxd\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_class_smooth_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m best = summary[\u001b[32m0\u001b[39m]\n\u001b[32m    324\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mHSMM Best (worst,mean,params)=\u001b[39m\u001b[33m'\u001b[39m, best[:\u001b[32m2\u001b[39m], best[\u001b[32m2\u001b[39m])\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 283\u001b[39m, in \u001b[36moof_eval_hsmm\u001b[39m\u001b[34m(grid_wdur, grid_wtr, grid_maxd, per_class_smooth_opts)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sid \u001b[38;5;129;01min\u001b[39;00m va:\n\u001b[32m    282\u001b[39m     pf = build_fused_probs_for_id(\u001b[38;5;28mint\u001b[39m(sid), alpha_vis=\u001b[32m0.26\u001b[39m, gamma_a=\u001b[32m0.25\u001b[39m, smooth_k=\u001b[32m5\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     y = \u001b[43mseg_viterbi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_dur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_dur\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_tr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_dur\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_class_smooth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m     \u001b[38;5;66;03m# post\u001b[39;00m\n\u001b[32m    285\u001b[39m     y = aba_collapse(y, max_len=\u001b[32m2\u001b[39m, ratio=\u001b[32m1.04\u001b[39m, p=pf)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 223\u001b[39m, in \u001b[36mseg_viterbi\u001b[39m\u001b[34m(p, log_dur, trans_cost, w_dur, w_tr, max_dur, per_class_smooth)\u001b[39m\n\u001b[32m    221\u001b[39m prev_cost = dp[pc, t0]\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prev_cost >= INF: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m tc = \u001b[38;5;28mfloat\u001b[39m(trans_cost[pc, c])\n\u001b[32m    224\u001b[39m cost = prev_cost + emis + w_dur*durc + w_tr*tc\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cost < best_cost:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "e7dd2747-bafd-447f-af2c-df28c211af05",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Minimal duration-aware Local Search decoder (fast) with tiny OOF grid and test decode\n",
        "import numpy as np, pandas as pd, json, time, os\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "probs_cache = Path('probs_cache')\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "\n",
        "try:\n",
        "    folds\n",
        "except NameError:\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "\n",
        "# Reuse utilities from previous cells\n",
        "def ensure_CxT(p, C=21):\n",
        "    if p is None: return None\n",
        "    if p.ndim==2 and p.shape[0]==C: return p\n",
        "    if p.ndim==2 and p.shape[1]==C: return p.T\n",
        "    raise ValueError('Bad probs shape')\n",
        "\n",
        "def load_skeleton_probs(seq_id: int) -> np.ndarray:\n",
        "    p2 = np.load(probs_cache/f\"{seq_id}_ce.npy\").astype(np.float32)\n",
        "    p3 = np.load(probs_cache/f\"{seq_id}_ce_v3.npy\").astype(np.float32)\n",
        "    p2 = ensure_CxT(p2); p3 = ensure_CxT(p3)\n",
        "    Tm = min(p2.shape[1], p3.shape[1])\n",
        "    p2 = p2[:, :Tm]; p3 = p3[:, :Tm]\n",
        "    try:\n",
        "        a = A.reshape(-1,1).astype(np.float32)\n",
        "    except NameError:\n",
        "        a = np.full((21,1), 0.7, dtype=np.float32)\n",
        "    p = a*p2 + (1.0-a)*p3\n",
        "    p /= (p.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return p.astype(np.float32)\n",
        "\n",
        "def load_probs_generic(seq_id: int, suffix: str) -> np.ndarray | None:\n",
        "    pth = probs_cache/f\"{seq_id}_{suffix}.npy\"\n",
        "    if not pth.exists(): return None\n",
        "    p = np.load(pth).astype(np.float32)\n",
        "    return ensure_CxT(p)\n",
        "\n",
        "def entropy(p: np.ndarray) -> np.ndarray:\n",
        "    q = np.clip(p, 1e-8, 1.0)\n",
        "    return -np.sum(q*np.log(q), axis=0)\n",
        "\n",
        "def align_by_entropy_corr(p_src: np.ndarray, p_ref: np.ndarray, max_shift: int = 15):\n",
        "    hs = entropy(p_src); hr = entropy(p_ref)\n",
        "    best = (-1e9, 0)\n",
        "    for sh in range(-max_shift, max_shift+1):\n",
        "        if sh >= 0:\n",
        "            L = min(hs.shape[0] - sh, hr.shape[0])\n",
        "            if L < 16: continue\n",
        "            s = hs[sh:sh+L]; r = hr[:L]\n",
        "        else:\n",
        "            L = min(hs.shape[0], hr.shape[0] + sh)\n",
        "            if L < 16: continue\n",
        "            s = hs[:L]; r = hr[-sh:-sh+L]\n",
        "        if s.std() < 1e-8 or r.std() < 1e-8:\n",
        "            corr = -1.0\n",
        "        else:\n",
        "            corr = float(np.corrcoef(s, r)[0,1])\n",
        "        if corr > best[0]: best = (corr, sh)\n",
        "    sh = best[1]\n",
        "    if sh >= 0:\n",
        "        L = min(p_src.shape[1] - sh, p_ref.shape[1])\n",
        "        return p_src[:, sh:sh+L], p_ref[:, :L]\n",
        "    else:\n",
        "        L = min(p_src.shape[1], p_ref.shape[1] + sh)\n",
        "        return p_src[:, :L], p_ref[:, -sh:-sh+L]\n",
        "\n",
        "def smooth_probs_box(p: np.ndarray, k: int = 5) -> np.ndarray:\n",
        "    if k<=1: return p\n",
        "    C,T = p.shape\n",
        "    pad = k//2\n",
        "    x = np.pad(p, ((0,0),(pad,pad)), mode='edge')\n",
        "    cs = np.cumsum(x, axis=1, dtype=np.float64)\n",
        "    out = (cs[:, k:] - cs[:, :-k]) / k\n",
        "    out = out.astype(np.float32)\n",
        "    out /= (out.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return out\n",
        "\n",
        "def decode_minseg(p: np.ndarray, min_dur: np.ndarray) -> np.ndarray:\n",
        "    y = p.argmax(axis=0).astype(np.int32)\n",
        "    T = y.shape[0]; i=0\n",
        "    while i < T:\n",
        "        c = y[i]; j=i+1\n",
        "        while j<T and y[j]==c: j+=1\n",
        "        L = j-i\n",
        "        if c!=0 and L < int(min_dur[c]):\n",
        "            lc = y[i-1] if i>0 else None\n",
        "            rc = y[j] if j<T else None\n",
        "            ls = float(p[lc, i:j].mean()) if lc is not None else -1e9\n",
        "            rs = float(p[rc, i:j].mean()) if rc is not None else -1e9\n",
        "            if rs >= ls: y[i:j] = rc if rc is not None else 0\n",
        "            else:        y[i:j] = lc if lc is not None else 0\n",
        "            i = max(0, i-1); continue\n",
        "        i = j\n",
        "    return y\n",
        "\n",
        "def aba_collapse(y: np.ndarray, max_len: int = 2, ratio: float = 1.04, p: np.ndarray | None = None) -> np.ndarray:\n",
        "    T = len(y); i=1\n",
        "    while i < T-1:\n",
        "        if y[i-1]==y[i+1] and y[i]!=y[i-1]:\n",
        "            L=1; j=i+1\n",
        "            while j<T-1 and y[j-1]==y[j+1] and y[j]!=y[j-1]:\n",
        "                L+=1; j+=1\n",
        "            if L<=max_len:\n",
        "                y[i:j] = y[i-1]\n",
        "                i = max(1, i-1); continue\n",
        "            i = j\n",
        "        i+=1\n",
        "    return y\n",
        "\n",
        "def compress_to_sequence(y_frames):\n",
        "    seq=[]; last=-1\n",
        "    for c in y_frames:\n",
        "        if c==0: continue\n",
        "        if c!=last: seq.append(int(c)); last=int(c)\n",
        "    return seq\n",
        "\n",
        "def make_perm20(seq_raw, p: np.ndarray):\n",
        "    seen=set(); seq=[]\n",
        "    for c in seq_raw:\n",
        "        if 1<=c<=20 and c not in seen:\n",
        "            seen.add(c); seq.append(c)\n",
        "    if len(seq)<20:\n",
        "        masses = [(c, float(p[c].sum())) for c in range(1,21) if c not in seen]\n",
        "        masses.sort(key=lambda x: x[1], reverse=True)\n",
        "        for c,_ in masses:\n",
        "            if len(seq)==20: break\n",
        "            seq.append(c)\n",
        "    if len(seq)>20: seq = seq[:20]\n",
        "    return seq\n",
        "\n",
        "def segment_lengths(y):\n",
        "    lens=defaultdict(list); cur=None; run=0\n",
        "    for c in y:\n",
        "        if c==0:\n",
        "            if cur is not None: lens[cur].append(run); cur=None; run=0\n",
        "            continue\n",
        "        if cur is None: cur=int(c); run=1\n",
        "        elif c==cur: run+=1\n",
        "        else: lens[cur].append(run); cur=int(c); run=1\n",
        "    if cur is not None: lens[cur].append(run)\n",
        "    return lens\n",
        "\n",
        "def compute_duration_stats(ids):\n",
        "    agg=defaultdict(list)\n",
        "    for sid in ids:\n",
        "        y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "        for c,ls in segment_lengths(y).items():\n",
        "            if c!=0: agg[c].extend(ls)\n",
        "    med = np.zeros(21, dtype=np.float32); q95 = np.zeros(21, dtype=np.float32)\n",
        "    for c in range(1,21):\n",
        "        ls = agg.get(c, [])\n",
        "        if ls:\n",
        "            arr = np.array(ls, dtype=np.float32)\n",
        "            med[c] = float(np.median(arr))\n",
        "            q95[c] = float(np.quantile(arr, 0.95))\n",
        "        else:\n",
        "            med[c] = 5.0; q95[c] = 50.0\n",
        "    q95 = np.clip(q95, 5.0, 150.0)\n",
        "    return med, q95\n",
        "\n",
        "# --- Temperature scaling helpers ---\n",
        "def temp_scale_scalar(p: np.ndarray, T: float) -> np.ndarray:\n",
        "    if p is None or T is None: return p\n",
        "    T = float(T)\n",
        "    logp = np.log(np.clip(p, 1e-8, 1.0)) / max(T, 1e-6)\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def _load_temp_from_json(path: Path) -> float | None:\n",
        "    if not path.exists(): return None\n",
        "    try:\n",
        "        obj = json.load(open(path,'r'))\n",
        "        if isinstance(obj, dict):\n",
        "            for k in ('T','temp','temperature'):\n",
        "                if k in obj: return float(obj[k])\n",
        "        if isinstance(obj, (int,float)):\n",
        "            return float(obj)\n",
        "    except Exception:\n",
        "        try:\n",
        "            txt = open(path,'r').read().strip()\n",
        "            return float(txt)\n",
        "        except Exception:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def get_fold_temp_map(prefix: str):\n",
        "    mp = {}\n",
        "    for f in (0,1,2):\n",
        "        t = _load_temp_from_json(Path(f\"{prefix}_fold{f}.json\"))\n",
        "        if t is not None: mp[f]=t\n",
        "    return mp\n",
        "\n",
        "TEMP_RGB   = get_fold_temp_map('rgb_temp')\n",
        "TEMP_DEPTH = get_fold_temp_map('depth_temp')\n",
        "TEMP_USER  = get_fold_temp_map('user_temp')\n",
        "TEMP_AUDIO = get_fold_temp_map('audio_temp')\n",
        "\n",
        "def get_test_temp_avg(mp: dict) -> float | None:\n",
        "    if not mp: return None\n",
        "    return float(np.mean(list(mp.values())))\n",
        "\n",
        "# --- Fusion with independent alignment and per-fold temps ---\n",
        "def build_fused_probs_for_id(sid: int, alpha_vis=0.26, gamma_a=0.25, smooth_k=3, fold: int | None = None, for_test: bool = False):\n",
        "    ps_ref = load_skeleton_probs(sid)\n",
        "    pr = load_probs_generic(sid, 'rgb')\n",
        "    pdp = load_probs_generic(sid, 'depth')\n",
        "    pu  = load_probs_generic(sid, 'user')\n",
        "    pa  = load_probs_generic(sid, 'audio')\n",
        "    # temperature-scale non-skeleton streams before alignment\n",
        "    if fold is not None:\n",
        "        if pr is not None and fold in TEMP_RGB:   pr = temp_scale_scalar(pr, TEMP_RGB[fold])\n",
        "        if pdp is not None and fold in TEMP_DEPTH: pdp = temp_scale_scalar(pdp, TEMP_DEPTH[fold])\n",
        "        if pu is not None and fold in TEMP_USER:  pu  = temp_scale_scalar(pu,  TEMP_USER[fold])\n",
        "        if pa is not None and fold in TEMP_AUDIO: pa  = temp_scale_scalar(pa,  TEMP_AUDIO[fold])\n",
        "    elif for_test:\n",
        "        t = get_test_temp_avg(TEMP_RGB);   pr  = temp_scale_scalar(pr,  t) if pr  is not None else None\n",
        "        t = get_test_temp_avg(TEMP_DEPTH); pdp = temp_scale_scalar(pdp, t) if pdp is not None else None\n",
        "        t = get_test_temp_avg(TEMP_USER);  pu  = temp_scale_scalar(pu,  t) if pu  is not None else None\n",
        "        t = get_test_temp_avg(TEMP_AUDIO); pa  = temp_scale_scalar(pa,  t) if pa  is not None else None\n",
        "    # align each to skeleton independently\n",
        "    aligned = [ps_ref]\n",
        "    pr_a = pdp_a = pu_a = pa_a = None\n",
        "    if pr is not None:\n",
        "        pr_a, ps_a = align_by_entropy_corr(pr, ps_ref, max_shift=15)\n",
        "        aligned.append(ps_a); pr_a = pr_a\n",
        "    if pdp is not None:\n",
        "        pdp_a, ps_a2 = align_by_entropy_corr(pdp, ps_ref, max_shift=15)\n",
        "        aligned.append(ps_a2); pdp_a = pdp_a\n",
        "    if pu is not None:\n",
        "        pu_a, ps_a3 = align_by_entropy_corr(pu, ps_ref, max_shift=15)\n",
        "        aligned.append(ps_a3); pu_a = pu_a\n",
        "    if pa is not None:\n",
        "        pa_a, ps_a4 = align_by_entropy_corr(pa, ps_ref, max_shift=15)\n",
        "        aligned.append(ps_a4); pa_a = pa_a\n",
        "    # crop all to common T\n",
        "    Tm = min(x.shape[1] for x in aligned)\n",
        "    ps = ps_ref[:, :Tm]\n",
        "    if pr_a is not None: pr_a = pr_a[:, :Tm]\n",
        "    if pdp_a is not None: pdp_a = pdp_a[:, :Tm]\n",
        "    if pu_a is not None: pu_a = pu_a[:, :Tm]\n",
        "    if pa_a is not None: pa_a = pa_a[:, :Tm]\n",
        "    # visual average\n",
        "    vis_list = [v for v in (pr_a, pdp_a, pu_a) if v is not None]\n",
        "    pvis = None\n",
        "    if vis_list:\n",
        "        v = np.mean(vis_list, axis=0)\n",
        "        v /= (v.sum(axis=0, keepdims=True)+1e-8)\n",
        "        pvis = v.astype(np.float32)\n",
        "    # PoE\n",
        "    w_s = 1.0 - (alpha_vis if pvis is not None else 0.0) - (gamma_a if pa_a is not None else 0.0)\n",
        "    logp = w_s*np.log(np.clip(ps,1e-8,1.0))\n",
        "    if pvis is not None: logp += alpha_vis*np.log(np.clip(pvis,1e-8,1.0))\n",
        "    if pa_a is not None: logp += gamma_a*np.log(np.clip(pa_a,1e-8,1.0))\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    q = smooth_probs_box(q.astype(np.float32), k=smooth_k)\n",
        "    return q\n",
        "\n",
        "def lev_dist(a, b):\n",
        "    n=len(a); m=len(b)\n",
        "    if n==0: return m\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; cost=0 if a[i-1]==b[j-1] else 1\n",
        "            dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# DP to optimize boundaries given a fixed order (length 20). Downsample by stride s for speed with feasibility bounds.\n",
        "def optimize_boundaries(order, p, med, q95, w_dur=0.0, stride=3):\n",
        "    C,T = p.shape\n",
        "    if stride>1:\n",
        "        T2 = T//stride\n",
        "        p_ds = p[:, :T2*stride].reshape(C, T2, stride).mean(axis=2).astype(np.float32)\n",
        "        scale = stride\n",
        "    else:\n",
        "        p_ds = p; T2=T; scale=1\n",
        "    nll = -np.log(np.clip(p_ds, 1e-8, 1.0)).astype(np.float32)\n",
        "    pref = np.cumsum(nll, axis=1, dtype=np.float64)\n",
        "    def seg_nll(c, t0, t1):\n",
        "        if t0<=0: return float(pref[c, t1-1])\n",
        "        return float(pref[c, t1-1] - pref[c, t0-1])\n",
        "    K = len(order)\n",
        "    INF=1e18\n",
        "    dp = np.full((K+1, T2+1), INF, dtype=np.float64)\n",
        "    bp = -np.ones((K+1, T2+1), dtype=np.int32)\n",
        "    dp[0,0]=0.0\n",
        "    # per-class min/max durations (downsampled)\n",
        "    dmin_ds_global = max(1, 3//scale)\n",
        "    dmin_c_ds = np.zeros(21, dtype=np.int32)\n",
        "    dmax_c_ds = np.zeros(21, dtype=np.int32)\n",
        "    for c in range(21):\n",
        "        md = max(1.0, med[c])\n",
        "        dmin_c_ds[c] = max(1, int((0.4*md)//scale))\n",
        "        dmax_c_ds[c] = max(dmin_c_ds[c], int(min(q95[c]//scale, 150//scale)))\n",
        "    # adjust dmin to ensure feasibility sum(dmin) <= T2\n",
        "    sum_min = int(sum(dmin_c_ds[c] for c in order))\n",
        "    if sum_min > T2:\n",
        "        factor = T2 / max(sum_min, 1)\n",
        "        for c in set(order):\n",
        "            d = max(1, int(np.floor(dmin_c_ds[c] * factor)))\n",
        "            dmin_c_ds[c] = d\n",
        "        # ensure dmax >= dmin\n",
        "        for c in set(order):\n",
        "            if dmax_c_ds[c] < dmin_c_ds[c]: dmax_c_ds[c] = dmin_c_ds[c]\n",
        "    # DP with feasibility bounds\n",
        "    for k in range(1, K+1):\n",
        "        c = order[k-1]\n",
        "        md = max(1.0, med[c]); log_md = np.log(md)\n",
        "        t_lo = k*dmin_ds_global\n",
        "        t_hi = T2 - (K-k)*dmin_ds_global\n",
        "        t_lo = max(t_lo, 1); t_hi = max(t_hi, 1)\n",
        "        for t in range(t_lo, t_hi+1):\n",
        "            best = INF; best_t0=-1\n",
        "            t0_max = t - dmin_c_ds[c]\n",
        "            t0_min = max((k-1)*dmin_ds_global, t - dmax_c_ds[c], 0)\n",
        "            for t0 in range(t0_min, t0_max+1):\n",
        "                d = t - t0\n",
        "                cost = dp[k-1, t0] + seg_nll(c, t0, t) + w_dur*abs(np.log(max(d*scale,1.0)) - log_md)\n",
        "                if cost < best:\n",
        "                    best = cost; best_t0 = t0\n",
        "            dp[k, t] = best; bp[k, t] = best_t0\n",
        "    # backtrack from best end time (allow tail silence)\n",
        "    t = int(np.argmin(dp[K, :]))\n",
        "    if not np.isfinite(dp[K, t]):\n",
        "        raise RuntimeError('DP backtrack failed: no finite path')\n",
        "    k=K; cuts=[t]\n",
        "    while k>0:\n",
        "        t0 = int(bp[k, t])\n",
        "        if t0<0:\n",
        "            raise RuntimeError('DP backtrack failed: infeasible path')\n",
        "        cuts.append(t0); t=t0; k-=1\n",
        "    cuts = cuts[::-1]\n",
        "    # scale back to original timeline\n",
        "    bnds=[0]\n",
        "    for x in cuts[1:]:\n",
        "        b = int(x*scale)\n",
        "        bnds.append(b)\n",
        "    if bnds[-1] < T: bnds[-1] = bnds[-1]  # allow tail background; do not force to T\n",
        "    return bnds\n",
        "\n",
        "def total_seq_cost(order, p, bnds, med, w_dur=0.0):\n",
        "    # compute total cost with original (non-downsampled) p\n",
        "    nll = -np.log(np.clip(p, 1e-8, 1.0)).astype(np.float32)\n",
        "    pref = np.cumsum(nll, axis=1, dtype=np.float64)\n",
        "    def seg_nll(c, t0, t1):\n",
        "        if t0<=0: return float(pref[c, t1-1])\n",
        "        return float(pref[c, t1-1] - pref[c, t0-1])\n",
        "    cost=0.0\n",
        "    for k,c in enumerate(order):\n",
        "        t0=bnds[k]; t1=bnds[k+1]\n",
        "        cost += seg_nll(c, t0, t1)\n",
        "        if w_dur>0:\n",
        "            md = max(1.0, med[c]); cost += w_dur*abs(np.log(max(t1-t0,1.0)) - np.log(md))\n",
        "    return float(cost)\n",
        "\n",
        "def initial_order_from_minseg(p, med, mult=0.7):\n",
        "    min_dur = np.floor(med*mult + 0.5).astype(np.int32); min_dur[0]=0\n",
        "    y = decode_minseg(p, min_dur)\n",
        "    y = aba_collapse(y, max_len=2, ratio=1.04, p=p)\n",
        "    seq0 = compress_to_sequence(y)\n",
        "    seq = make_perm20(seq0, p)\n",
        "    return seq\n",
        "\n",
        "def _segment_emission_costs(order, p, bnds):\n",
        "    # emission-only cost per segment for prioritizing moves\n",
        "    nll = -np.log(np.clip(p, 1e-8, 1.0)).astype(np.float32)\n",
        "    pref = np.cumsum(nll, axis=1, dtype=np.float64)\n",
        "    def seg_nll(c, t0, t1):\n",
        "        if t0<=0: return float(pref[c, t1-1])\n",
        "        return float(pref[c, t1-1] - pref[c, t0-1])\n",
        "    costs=[]\n",
        "    for k,c in enumerate(order):\n",
        "        t0=bnds[k]; t1=bnds[k+1]\n",
        "        costs.append(seg_nll(c,t0,t1))\n",
        "    return np.array(costs, dtype=np.float64)\n",
        "\n",
        "def neighbors(order, bnds, p, cap=10):\n",
        "    K=len(order); cands=[]; seen=set()\n",
        "    # adjacent swaps\n",
        "    for i in range(K-1):\n",
        "        o=order.copy(); o[i],o[i+1]=o[i+1],o[i]\n",
        "        t=tuple(o)\n",
        "        if t not in seen:\n",
        "            seen.add(t); cands.append(o)\n",
        "        if len(cands)>=cap: return cands\n",
        "    # optional (i, i+2) swaps for first few positions\n",
        "    for i in range(min(3, K-2)):\n",
        "        o=order.copy(); o[i],o[i+2]=o[i+2],o[i]\n",
        "        t=tuple(o)\n",
        "        if t not in seen:\n",
        "            seen.add(t); cands.append(o)\n",
        "        if len(cands)>=cap: return cands\n",
        "    # reinsertion for top-3 costly segments to i\u00b11, i\u00b12\n",
        "    seg_costs = _segment_emission_costs(order, p, bnds)\n",
        "    top_idx = list(np.argsort(-seg_costs)[:3])\n",
        "    for idx in top_idx:\n",
        "        for delta in (-2,-1,1,2):\n",
        "            j = idx + delta\n",
        "            if j<0 or j>=K: continue\n",
        "            o=order.copy()\n",
        "            val=o.pop(idx)\n",
        "            o.insert(j, val)\n",
        "            t=tuple(o)\n",
        "            if t not in seen:\n",
        "                seen.add(t); cands.append(o)\n",
        "            if len(cands)>=cap: return cands\n",
        "    return cands\n",
        "\n",
        "def local_search_decode(p, med, q95, mult=0.7, w_dur=0.0, passes=3, max_moves=12, stride=3):\n",
        "    order = initial_order_from_minseg(p, med, mult=mult)\n",
        "    bnds = optimize_boundaries(order, p, med, q95, w_dur=w_dur, stride=stride)\n",
        "    best_cost = total_seq_cost(order, p, bnds, med, w_dur=w_dur)\n",
        "    moves=0\n",
        "    for _ in range(passes):\n",
        "        improved=False\n",
        "        cand_list = neighbors(order, bnds, p, cap=10)\n",
        "        for cand in cand_list:\n",
        "            b = optimize_boundaries(cand, p, med, q95, w_dur=w_dur, stride=stride)\n",
        "            c = total_seq_cost(cand, p, b, med, w_dur=w_dur)\n",
        "            if c + 1e-4 < best_cost:\n",
        "                order=cand; bnds=b; best_cost=c; improved=True\n",
        "                moves+=1\n",
        "                if moves>=max_moves: break\n",
        "        if not improved or moves>=max_moves: break\n",
        "    # build frame labels from final boundaries\n",
        "    y = np.zeros(p.shape[1], dtype=np.int32)\n",
        "    for k,c in enumerate(order):\n",
        "        t0=bnds[k]; t1=bnds[k+1]\n",
        "        y[t0:t1]=c\n",
        "    return y, order, bnds, best_cost\n",
        "\n",
        "def oof_eval_ls(mult_list=(0.65,0.70), wdur_list=(0.1,0.2), stride=3):\n",
        "    print('OOF LS tuning...', flush=True)\n",
        "    results={}\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med, q95 = compute_duration_stats(tr)\n",
        "        fold_scores = defaultdict(list)\n",
        "        t_fold=time.time()\n",
        "        n_seq=0; total_seq=len(va)*len(mult_list)*len(wdur_list)\n",
        "        for sid in va:\n",
        "            p = build_fused_probs_for_id(int(sid), alpha_vis=0.26, gamma_a=0.25, smooth_k=3, fold=int(fd['fold']))\n",
        "            y_true = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "            seq_true = [int(c) for i,c in enumerate(y_true) if c!=0 and (i==0 or y_true[i-1]!=c)]\n",
        "            for m in mult_list:\n",
        "                for wd in wdur_list:\n",
        "                    y, order, bnds, cost = local_search_decode(p, med, q95, mult=m, w_dur=wd, passes=3, max_moves=12, stride=stride)\n",
        "                    seq = [int(c) for i,c in enumerate(y) if c!=0 and (i==0 or y[i-1]!=c)]\n",
        "                    d = lev_dist(seq, seq_true)\n",
        "                    fold_scores[(m,wd)].append(d)\n",
        "                    n_seq+=1\n",
        "                    if (n_seq%20)==0:\n",
        "                        print(f\"fold={fd['fold']} progress {n_seq}/{total_seq} elapsed={time.time()-t_fold:.1f}s\", flush=True)\n",
        "        for k,v in fold_scores.items():\n",
        "            results.setdefault(k, []).append(float(np.mean(v)))\n",
        "        print(f\"fold={fd['fold']} done in {time.time()-t_fold:.1f}s\", flush=True)\n",
        "    summary=[]\n",
        "    for k, arr in results.items():\n",
        "        worst=max(arr); mean=float(np.mean(arr))\n",
        "        summary.append((worst, mean, k))\n",
        "    summary.sort(key=lambda x: (x[0], x[1]))\n",
        "    return summary\n",
        "\n",
        "def decode_test_ls(mult=0.70, w_dur=0.0, stride=3, out_csv='submission_ls_poe_fast.csv'):\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med, q95 = compute_duration_stats(all_train_ids)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        p = build_fused_probs_for_id(int(sid), alpha_vis=0.26, gamma_a=0.25, smooth_k=3, fold=None, for_test=True)\n",
        "        y, order, bnds, cost = local_search_decode(p, med, q95, mult=mult, w_dur=w_dur, passes=3, max_moves=12, stride=stride)\n",
        "        seq = [int(c) for i,c in enumerate(y) if c!=0 and (i==0 or y[i-1]!=c)]\n",
        "        # ensure perm20\n",
        "        seq = make_perm20(seq, p)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    sub.to_csv('submission.csv', index=False); print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('OOF LS tuning...', flush=True)\n",
        "summary = oof_eval_ls(mult_list=(0.65,0.70), wdur_list=(0.1,0.2), stride=3)\n",
        "best = summary[0]\n",
        "print('LS Best (worst,mean,params)=', best[:2], best[2])\n",
        "m,wd = best[2]\n",
        "out_csv = f\"submission_ls_poe_fast_m{str(m).replace('.','')}_wd{str(wd).replace('.','')}.csv\"\n",
        "print('Decoding TEST with best params...', flush=True)\n",
        "decode_test_ls(mult=m, w_dur=wd, stride=3, out_csv=out_csv)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF LS tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF LS tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 20/392 elapsed=85.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 40/392 elapsed=189.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 60/392 elapsed=343.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 80/392 elapsed=440.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 100/392 elapsed=568.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 120/392 elapsed=676.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 140/392 elapsed=740.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 160/392 elapsed=879.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 180/392 elapsed=1120.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 200/392 elapsed=1363.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 220/392 elapsed=1574.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 240/392 elapsed=1753.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 260/392 elapsed=1878.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 280/392 elapsed=2043.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 300/392 elapsed=2275.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 320/392 elapsed=2509.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 340/392 elapsed=2673.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 360/392 elapsed=2795.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 progress 380/392 elapsed=2902.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 done in 2946.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 20/396 elapsed=64.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 40/396 elapsed=128.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 60/396 elapsed=264.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 80/396 elapsed=339.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 100/396 elapsed=449.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 120/396 elapsed=604.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 140/396 elapsed=749.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 160/396 elapsed=889.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 180/396 elapsed=1056.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 200/396 elapsed=1195.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 220/396 elapsed=1350.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 240/396 elapsed=1520.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 260/396 elapsed=1604.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 280/396 elapsed=1697.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 300/396 elapsed=1825.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 320/396 elapsed=2006.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 340/396 elapsed=2115.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 360/396 elapsed=2176.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 progress 380/396 elapsed=2239.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 done in 2294.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 20/400 elapsed=146.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 40/400 elapsed=275.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 60/400 elapsed=420.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 80/400 elapsed=575.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 100/400 elapsed=750.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 120/400 elapsed=924.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 140/400 elapsed=1115.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 160/400 elapsed=1275.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 180/400 elapsed=1440.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 200/400 elapsed=1564.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 220/400 elapsed=1748.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 240/400 elapsed=1902.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 260/400 elapsed=2073.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 280/400 elapsed=2165.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 300/400 elapsed=2352.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 320/400 elapsed=2456.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 340/400 elapsed=2567.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 360/400 elapsed=2705.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 380/400 elapsed=2855.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 progress 400/400 elapsed=3003.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 done in 3003.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LS Best (worst,mean,params)= (9.37, 7.894308390022675) (0.65, 0.1)\nDecoding TEST with best params...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=159.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=353.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=526.9s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 495\u001b[39m\n\u001b[32m    493\u001b[39m out_csv = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msubmission_ls_poe_fast_m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(m).replace(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_wd\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(wd).replace(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mDecoding TEST with best params...\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m \u001b[43mdecode_test_ls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmult\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_dur\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_csv\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 477\u001b[39m, in \u001b[36mdecode_test_ls\u001b[39m\u001b[34m(mult, w_dur, stride, out_csv)\u001b[39m\n\u001b[32m    475\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    476\u001b[39m p = build_fused_probs_for_id(\u001b[38;5;28mint\u001b[39m(sid), alpha_vis=\u001b[32m0.26\u001b[39m, gamma_a=\u001b[32m0.25\u001b[39m, smooth_k=\u001b[32m3\u001b[39m, fold=\u001b[38;5;28;01mNone\u001b[39;00m, for_test=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m y, order, bnds, cost = \u001b[43mlocal_search_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq95\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmult\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_dur\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw_dur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_moves\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m seq = [\u001b[38;5;28mint\u001b[39m(c) \u001b[38;5;28;01mfor\u001b[39;00m i,c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y) \u001b[38;5;28;01mif\u001b[39;00m c!=\u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (i==\u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y[i-\u001b[32m1\u001b[39m]!=c)]\n\u001b[32m    479\u001b[39m \u001b[38;5;66;03m# ensure perm20\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 422\u001b[39m, in \u001b[36mlocal_search_decode\u001b[39m\u001b[34m(p, med, q95, mult, w_dur, passes, max_moves, stride)\u001b[39m\n\u001b[32m    420\u001b[39m cand_list = neighbors(order, bnds, p, cap=\u001b[32m10\u001b[39m)\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cand \u001b[38;5;129;01min\u001b[39;00m cand_list:\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     b = \u001b[43moptimize_boundaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq95\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_dur\u001b[49m\u001b[43m=\u001b[49m\u001b[43mw_dur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    423\u001b[39m     c = total_seq_cost(cand, p, b, med, w_dur=w_dur)\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m c + \u001b[32m1e-4\u001b[39m < best_cost:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 322\u001b[39m, in \u001b[36moptimize_boundaries\u001b[39m\u001b[34m(order, p, med, q95, w_dur, stride)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t0 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(t0_min, t0_max+\u001b[32m1\u001b[39m):\n\u001b[32m    321\u001b[39m     d = t - t0\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     cost = dp[k-\u001b[32m1\u001b[39m, t0] + seg_nll(c, t0, t) + w_dur*\u001b[38;5;28mabs\u001b[39m(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m*\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m - log_md)\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cost < best:\n\u001b[32m    324\u001b[39m         best = cost; best_t0 = t0\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "f140f408-1347-4e0a-a2cc-7463496c9bd5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pairwise order decoder + boundary DP (fast) TEST DECODE ONLY (no OOF) to avoid long runtimes\n",
        "import numpy as np, pandas as pd, json, time, os\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "probs_cache = Path('probs_cache')\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "\n",
        "try:\n",
        "    folds\n",
        "except NameError:\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "\n",
        "# Reuse from previous cells: build_fused_probs_for_id, optimize_boundaries, compute_duration_stats, lev_dist, make_perm20\n",
        "\n",
        "def pairwise_order_from_probs(p: np.ndarray, q_power: float = 1.8) -> list:\n",
        "    # Compute pairwise 'i before j' wins using weighted mass; exclude class 0\n",
        "    C,T = p.shape\n",
        "    classes = list(range(1,21))\n",
        "    w = np.power(np.clip(p[1:21], 1e-8, 1.0), q_power).astype(np.float32)  # shape 20 x T\n",
        "    # precompute cumulative sums from the end for each class: S_after[c,t] = sum_{u>t} w[c,u]\n",
        "    S_after = np.cumsum(w[:, ::-1], axis=1)[:, ::-1]\n",
        "    W = np.zeros((20,20), dtype=np.float64)\n",
        "    for i in range(20):\n",
        "        # wins of i over all j: sum_t w_i[t] * S_after[j][t]\n",
        "        wi = w[i]\n",
        "        for j in range(20):\n",
        "            if i==j: continue\n",
        "            W[i,j] = float((wi * S_after[j]).sum())\n",
        "    # margin scores\n",
        "    M = W - W.T  # antisymmetric margins\n",
        "    score = M.sum(axis=1)  # Borda-like\n",
        "    order_idx = list(np.argsort(-score))  # descending score\n",
        "    order = [classes[i] for i in order_idx]\n",
        "    return order\n",
        "\n",
        "def decode_test_pairwise(q_power=1.8, w_dur=0.0, stride=3, smooth_k=5, out_csv='submission_pairwise_dp.csv', stage_submission=False):\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med, q95 = compute_duration_stats(all_train_ids)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        p = build_fused_probs_for_id(int(sid), alpha_vis=0.26, gamma_a=0.25, smooth_k=smooth_k, fold=None, for_test=True)\n",
        "        order = pairwise_order_from_probs(p, q_power=q_power)\n",
        "        bnds = optimize_boundaries(order, p, med, q95, w_dur=w_dur, stride=stride)\n",
        "        y = np.zeros(p.shape[1], dtype=np.int32)\n",
        "        for k,c in enumerate(order):\n",
        "            t0=bnds[k]; t1=bnds[k+1]\n",
        "            y[t0:t1]=c\n",
        "        seq_raw = [int(c) for i,c in enumerate(y) if c!=0 and (i==0 or y[i-1]!=c)]\n",
        "        seq = make_perm20(seq_raw, p)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    if stage_submission:\n",
        "        sub.to_csv('submission.csv', index=False); print('submission.csv written ->', out_csv)\n",
        "\n",
        "# Fast test-only decode with fixed params (avoid long OOF). Does NOT overwrite submission.csv.\n",
        "q_fixed = 1.8\n",
        "wd_fixed = 0.0\n",
        "print('Decoding TEST with pairwise+DP (fixed params)...', flush=True)\n",
        "out_csv = f\"submission_pairwise_dp_q{str(q_fixed).replace('.','')}_wd{str(wd_fixed).replace('.','')}.csv\"\n",
        "decode_test_pairwise(q_power=q_fixed, w_dur=wd_fixed, stride=3, smooth_k=5, out_csv=out_csv, stage_submission=False)\n",
        "print('Done. Baseline submission.csv remains unchanged.')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST with pairwise+DP (fixed params)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=1759186346.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=1759186320.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=1759186362.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=1759186365.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=1759186355.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_pairwise_dp_q18_wd00.csv rows= 95\nDone. Baseline submission.csv remains unchanged.\n"
          ]
        }
      ]
    },
    {
      "id": "ae7a1063-49f7-451a-b5f1-08e5a49a2010",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Borda rank-ensemble with per-sequence gating; TEST DECODE ONLY\n",
        "import numpy as np, pandas as pd, json, time, os\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "probs_cache = Path('probs_cache')\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "\n",
        "try:\n",
        "    folds\n",
        "except NameError:\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "\n",
        "# Reuse utilities if present; define minimal fallbacks\n",
        "def ensure_CxT(p, C=21):\n",
        "    if p is None: return None\n",
        "    if p.ndim==2 and p.shape[0]==C: return p\n",
        "    if p.ndim==2 and p.shape[1]==C: return p.T\n",
        "    raise ValueError('Bad probs shape')\n",
        "\n",
        "def load_skeleton_probs(seq_id: int) -> np.ndarray:\n",
        "    p2 = np.load(probs_cache/f\"{seq_id}_ce.npy\").astype(np.float32)\n",
        "    p3 = np.load(probs_cache/f\"{seq_id}_ce_v3.npy\").astype(np.float32)\n",
        "    p2 = ensure_CxT(p2); p3 = ensure_CxT(p3)\n",
        "    Tm = min(p2.shape[1], p3.shape[1])\n",
        "    p2 = p2[:, :Tm]; p3 = p3[:, :Tm]\n",
        "    try:\n",
        "        a = A.reshape(-1,1).astype(np.float32)\n",
        "    except NameError:\n",
        "        a = np.full((21,1), 0.7, dtype=np.float32)\n",
        "    p = a*p2 + (1.0-a)*p3\n",
        "    p /= (p.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return p.astype(np.float32)\n",
        "\n",
        "def load_probs_generic(seq_id: int, suffix: str) -> np.ndarray | None:\n",
        "    pth = probs_cache/f\"{seq_id}_{suffix}.npy\"\n",
        "    if not pth.exists(): return None\n",
        "    p = np.load(pth).astype(np.float32)\n",
        "    return ensure_CxT(p)\n",
        "\n",
        "def entropy(p: np.ndarray) -> np.ndarray:\n",
        "    q = np.clip(p, 1e-8, 1.0)\n",
        "    return -np.sum(q*np.log(q), axis=0)\n",
        "\n",
        "def align_with_corr(p_src: np.ndarray, p_ref: np.ndarray, max_shift: int = 15):\n",
        "    hs = entropy(p_src); hr = entropy(p_ref)\n",
        "    best = (-1e9, 0)\n",
        "    for sh in range(-max_shift, max_shift+1):\n",
        "        if sh >= 0:\n",
        "            L = min(hs.shape[0] - sh, hr.shape[0])\n",
        "            if L < 16: continue\n",
        "            s = hs[sh:sh+L]; r = hr[:L]\n",
        "        else:\n",
        "            L = min(hs.shape[0], hr.shape[0] + sh)\n",
        "            if L < 16: continue\n",
        "            s = hs[:L]; r = hr[-sh:-sh+L]\n",
        "        if s.std() < 1e-8 or r.std() < 1e-8:\n",
        "            corr = -1.0\n",
        "        else:\n",
        "            corr = float(np.corrcoef(s, r)[0,1])\n",
        "        if corr > best[0]: best = (corr, sh)\n",
        "    corr, sh = best\n",
        "    if sh >= 0:\n",
        "        L = min(p_src.shape[1] - sh, p_ref.shape[1])\n",
        "        return p_src[:, sh:sh+L], p_ref[:, :L], corr\n",
        "    else:\n",
        "        L = min(p_src.shape[1], p_ref.shape[1] + sh)\n",
        "        return p_src[:, :L], p_ref[:, -sh:-sh+L], corr\n",
        "\n",
        "def smooth_probs_box(p: np.ndarray, k: int = 5) -> np.ndarray:\n",
        "    if k<=1: return p\n",
        "    C,T = p.shape\n",
        "    pad = k//2\n",
        "    x = np.pad(p, ((0,0),(pad,pad)), mode='edge')\n",
        "    cs = np.cumsum(x, axis=1, dtype=np.float64)\n",
        "    out = (cs[:, k:] - cs[:, :-k]) / k\n",
        "    out = out.astype(np.float32)\n",
        "    out /= (out.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return out\n",
        "\n",
        "# --- Temperature scaling helpers (reuse test-avg temps) ---\n",
        "def temp_scale_scalar(p: np.ndarray, T: float) -> np.ndarray:\n",
        "    if p is None or T is None: return p\n",
        "    T = float(T)\n",
        "    logp = np.log(np.clip(p, 1e-8, 1.0)) / max(T, 1e-6)\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def _load_temp_from_json(path: Path) -> float | None:\n",
        "    if not path.exists(): return None\n",
        "    try:\n",
        "        obj = json.load(open(path,'r'))\n",
        "        if isinstance(obj, dict):\n",
        "            for k in ('T','temp','temperature'):\n",
        "                if k in obj: return float(obj[k])\n",
        "        if isinstance(obj, (int,float)):\n",
        "            return float(obj)\n",
        "    except Exception:\n",
        "        try:\n",
        "            txt = open(path,'r').read().strip()\n",
        "            return float(txt)\n",
        "        except Exception:\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "def get_fold_temp_map(prefix: str):\n",
        "    mp = {}\n",
        "    for f in (0,1,2):\n",
        "        t = _load_temp_from_json(Path(f\"{prefix}_fold{f}.json\"))\n",
        "        if t is not None: mp[f]=t\n",
        "    return mp\n",
        "\n",
        "TEMP_RGB   = get_fold_temp_map('rgb_temp')\n",
        "TEMP_DEPTH = get_fold_temp_map('depth_temp')\n",
        "TEMP_USER  = get_fold_temp_map('user_temp')\n",
        "TEMP_AUDIO = get_fold_temp_map('audio_temp')\n",
        "\n",
        "def get_test_temp_avg(mp: dict) -> float | None:\n",
        "    if not mp: return None\n",
        "    return float(np.mean(list(mp.values())))\n",
        "\n",
        "# --- Duration stats ---\n",
        "def segment_lengths(y):\n",
        "    lens=defaultdict(list); cur=None; run=0\n",
        "    for c in y:\n",
        "        if c==0:\n",
        "            if cur is not None: lens[cur].append(run); cur=None; run=0\n",
        "            continue\n",
        "        if cur is None: cur=int(c); run=1\n",
        "        elif c==cur: run+=1\n",
        "        else: lens[cur].append(run); cur=int(c); run=1\n",
        "    if cur is not None: lens[cur].append(run)\n",
        "    return lens\n",
        "\n",
        "def compute_duration_stats(ids):\n",
        "    agg=defaultdict(list)\n",
        "    for sid in ids:\n",
        "        y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "        for c,ls in segment_lengths(y).items():\n",
        "            if c!=0: agg[c].extend(ls)\n",
        "    med = np.zeros(21, dtype=np.float32); q95 = np.zeros(21, dtype=np.float32)\n",
        "    for c in range(1,21):\n",
        "        ls = agg.get(c, [])\n",
        "        if ls:\n",
        "            arr = np.array(ls, dtype=np.float32)\n",
        "            med[c] = float(np.median(arr))\n",
        "            q95[c] = float(np.quantile(arr, 0.95))\n",
        "        else:\n",
        "            med[c] = 5.0; q95[c] = 50.0\n",
        "    q95 = np.clip(q95, 5.0, 150.0)\n",
        "    return med, q95\n",
        "\n",
        "# --- Decoders and helpers ---\n",
        "def decode_minseg(p: np.ndarray, min_dur: np.ndarray) -> np.ndarray:\n",
        "    y = p.argmax(axis=0).astype(np.int32)\n",
        "    T = y.shape[0]; i=0\n",
        "    while i < T:\n",
        "        c = y[i]; j=i+1\n",
        "        while j<T and y[j]==c: j+=1\n",
        "        L = j-i\n",
        "        if c!=0 and L < int(min_dur[c]):\n",
        "            lc = y[i-1] if i>0 else None\n",
        "            rc = y[j] if j<T else None\n",
        "            ls = float(p[lc, i:j].mean()) if lc is not None else -1e9\n",
        "            rs = float(p[rc, i:j].mean()) if rc is not None else -1e9\n",
        "            if rs >= ls: y[i:j] = rc if rc is not None else 0\n",
        "            else:        y[i:j] = lc if lc is not None else 0\n",
        "            i = max(0, i-1); continue\n",
        "        i = j\n",
        "    return y\n",
        "\n",
        "def aba_collapse(y: np.ndarray, max_len: int = 2) -> np.ndarray:\n",
        "    T = len(y); i=1\n",
        "    while i < T-1:\n",
        "        if y[i-1]==y[i+1] and y[i]!=y[i-1]:\n",
        "            L=1; j=i+1\n",
        "            while j<T-1 and y[j-1]==y[j+1] and y[j]!=y[j-1]:\n",
        "                L+=1; j+=1\n",
        "            if L<=max_len:\n",
        "                y[i:j] = y[i-1]\n",
        "                i = max(1, i-1); continue\n",
        "            i = j\n",
        "        i+=1\n",
        "    return y\n",
        "\n",
        "def compress_to_sequence(y_frames):\n",
        "    seq=[]; last=-1\n",
        "    for c in y_frames:\n",
        "        if c==0: continue\n",
        "        if c!=last: seq.append(int(c)); last=int(c)\n",
        "    return seq\n",
        "\n",
        "def make_perm20(seq_raw, p: np.ndarray):\n",
        "    seen=set(); seq=[]\n",
        "    for c in seq_raw:\n",
        "        if 1<=c<=20 and c not in seen:\n",
        "            seen.add(c); seq.append(c)\n",
        "    if len(seq)<20:\n",
        "        masses = [(c, float(p[c].sum())) for c in range(1,21) if c not in seen]\n",
        "        masses.sort(key=lambda x: x[1], reverse=True)\n",
        "        for c,_ in masses:\n",
        "            if len(seq)==20: break\n",
        "            seq.append(c)\n",
        "    if len(seq)>20: seq = seq[:20]\n",
        "    return seq\n",
        "\n",
        "def optimize_boundaries(order, p, med, q95, w_dur=0.05, stride=3):\n",
        "    C,T = p.shape\n",
        "    if stride>1:\n",
        "        T2 = T//stride\n",
        "        p_ds = p[:, :T2*stride].reshape(C, T2, stride).mean(axis=2).astype(np.float32)\n",
        "        scale = stride\n",
        "    else:\n",
        "        p_ds = p; T2=T; scale=1\n",
        "    nll = -np.log(np.clip(p_ds, 1e-8, 1.0)).astype(np.float32)\n",
        "    pref = np.cumsum(nll, axis=1, dtype=np.float64)\n",
        "    def seg_nll(c, t0, t1):\n",
        "        if t0<=0: return float(pref[c, t1-1])\n",
        "        return float(pref[c, t1-1] - pref[c, t0-1])\n",
        "    K = len(order)\n",
        "    INF=1e18\n",
        "    dp = np.full((K+1, T2+1), INF, dtype=np.float64)\n",
        "    bp = -np.ones((K+1, T2+1), dtype=np.int32)\n",
        "    dp[0,0]=0.0\n",
        "    dmin_ds_global = max(1, 3//scale)\n",
        "    dmin_c_ds = np.zeros(21, dtype=np.int32)\n",
        "    dmax_c_ds = np.zeros(21, dtype=np.int32)\n",
        "    for c in range(21):\n",
        "        md = max(1.0, med[c])\n",
        "        dmin_c_ds[c] = max(1, int((0.4*md)//scale))\n",
        "        dmax_c_ds[c] = max(dmin_c_ds[c], int(min(q95[c]//scale, 150//scale)))\n",
        "    sum_min = int(sum(dmin_c_ds[c] for c in order))\n",
        "    if sum_min > T2:\n",
        "        factor = T2 / max(sum_min, 1)\n",
        "        for c in set(order):\n",
        "            d = max(1, int(np.floor(dmin_c_ds[c] * factor)))\n",
        "            dmin_c_ds[c] = d\n",
        "        for c in set(order):\n",
        "            if dmax_c_ds[c] < dmin_c_ds[c]: dmax_c_ds[c] = dmin_c_ds[c]\n",
        "    for k in range(1, K+1):\n",
        "        c = order[k-1]\n",
        "        md = max(1.0, med[c]); log_md = np.log(md)\n",
        "        t_lo = k*dmin_ds_global\n",
        "        t_hi = T2 - (K-k)*dmin_ds_global\n",
        "        t_lo = max(t_lo, 1); t_hi = max(t_hi, 1)\n",
        "        for t in range(t_lo, t_hi+1):\n",
        "            best = INF; best_t0=-1\n",
        "            t0_max = t - dmin_c_ds[c]\n",
        "            t0_min = max((k-1)*dmin_ds_global, t - dmax_c_ds[c], 0)\n",
        "            for t0 in range(t0_min, t0_max+1):\n",
        "                d = t - t0\n",
        "                cost = dp[k-1, t0] + seg_nll(c, t0, t) + w_dur*abs(np.log(max(d*scale,1.0)) - log_md)\n",
        "                if cost < best:\n",
        "                    best = cost; best_t0 = t0\n",
        "            dp[k, t] = best; bp[k, t] = best_t0\n",
        "    t = int(np.argmin(dp[K, :]))\n",
        "    if not np.isfinite(dp[K, t]):\n",
        "        # fallback: force equal splits\n",
        "        step = max(1, T//K)\n",
        "        bnds=[0]\n",
        "        for k in range(1,K): bnds.append(min(T, k*step))\n",
        "        bnds.append(T)\n",
        "        return bnds\n",
        "    k=K; cuts=[t]\n",
        "    while k>0:\n",
        "        t0 = int(bp[k, t])\n",
        "        if t0<0: break\n",
        "        cuts.append(t0); t=t0; k-=1\n",
        "    cuts = cuts[::-1]\n",
        "    bnds=[0]\n",
        "    for x in cuts[1:]:\n",
        "        b = int(x*scale)\n",
        "        bnds.append(b)\n",
        "    if len(bnds)<K+1: bnds.append(T)\n",
        "    if bnds[-1] < T: bnds[-1] = T\n",
        "    return bnds\n",
        "\n",
        "def pairwise_order_from_probs(p: np.ndarray, q_power: float = 1.8):\n",
        "    C,T = p.shape\n",
        "    classes = list(range(1,21))\n",
        "    w = np.power(np.clip(p[1:21], 1e-8, 1.0), q_power).astype(np.float32)\n",
        "    S_after = np.cumsum(w[:, ::-1], axis=1)[:, ::-1]\n",
        "    W = np.zeros((20,20), dtype=np.float64)\n",
        "    for i in range(20):\n",
        "        wi = w[i]\n",
        "        for j in range(20):\n",
        "            if i==j: continue\n",
        "            W[i,j] = float((wi * S_after[j]).sum())\n",
        "    M = W - W.T\n",
        "    score = M.sum(axis=1)\n",
        "    order_idx = list(np.argsort(-score))\n",
        "    order = [classes[i] for i in order_idx]\n",
        "    return order, M\n",
        "\n",
        "# --- Per-sequence gated fusion ---\n",
        "def build_fused_probs_gated(sid: int, alpha_vis=0.26, gamma_a=0.25, smooth_k=5):\n",
        "    ps_ref = load_skeleton_probs(sid)\n",
        "    pr = load_probs_generic(sid, 'rgb')\n",
        "    pdp = load_probs_generic(sid, 'depth')\n",
        "    pu  = load_probs_generic(sid, 'user')\n",
        "    pa  = load_probs_generic(sid, 'audio')\n",
        "    # temp-scale for test using average fold temps\n",
        "    t = get_test_temp_avg(TEMP_RGB);   pr  = temp_scale_scalar(pr,  t) if pr  is not None else None\n",
        "    t = get_test_temp_avg(TEMP_DEPTH); pdp = temp_scale_scalar(pdp, t) if pdp is not None else None\n",
        "    t = get_test_temp_avg(TEMP_USER);  pu  = temp_scale_scalar(pu,  t) if pu  is not None else None\n",
        "    t = get_test_temp_avg(TEMP_AUDIO); pa  = temp_scale_scalar(pa,  t) if pa is not None else None\n",
        "    # align and compute corr; gate by corr>=0.5\n",
        "    aligned = [ps_ref]\n",
        "    vis_list=[]\n",
        "    # RGB\n",
        "    if pr is not None:\n",
        "        pr_a, ps_a, corr = align_with_corr(pr, ps_ref, max_shift=15)\n",
        "        if corr >= 0.5: vis_list.append(pr_a); aligned.append(ps_a)\n",
        "    # Depth\n",
        "    if pdp is not None:\n",
        "        pdp_a, ps_a2, corr = align_with_corr(pdp, ps_ref, max_shift=15)\n",
        "        if corr >= 0.5: vis_list.append(pdp_a); aligned.append(ps_a2)\n",
        "    # User\n",
        "    if pu is not None:\n",
        "        pu_a, ps_a3, corr = align_with_corr(pu, ps_ref, max_shift=15)\n",
        "        if corr >= 0.5: vis_list.append(pu_a); aligned.append(ps_a3)\n",
        "    # Audio (not visual but also gate with corr>=0.5 for robustness)\n",
        "    pa_a = None\n",
        "    if pa is not None:\n",
        "        pa_a_tmp, ps_a4, corr = align_with_corr(pa, ps_ref, max_shift=15)\n",
        "        if corr >= 0.5:\n",
        "            pa_a = pa_a_tmp; aligned.append(ps_a4)\n",
        "    # crop to common T\n",
        "    Tm = min(x.shape[1] for x in aligned)\n",
        "    ps = ps_ref[:, :Tm]\n",
        "    if vis_list:\n",
        "        vis_list = [v[:, :Tm] for v in vis_list]\n",
        "        pvis = np.mean(vis_list, axis=0)\n",
        "        pvis /= (pvis.sum(axis=0, keepdims=True)+1e-8)\n",
        "    else:\n",
        "        pvis = None\n",
        "    if pa_a is not None: pa_a = pa_a[:, :Tm]\n",
        "    # PoE\n",
        "    w_s = 1.0 - (alpha_vis if pvis is not None else 0.0) - (gamma_a if pa_a is not None else 0.0)\n",
        "    logp = w_s*np.log(np.clip(ps,1e-8,1.0))\n",
        "    if pvis is not None: logp += alpha_vis*np.log(np.clip(pvis,1e-8,1.0))\n",
        "    if pa_a is not None: logp += gamma_a*np.log(np.clip(pa_a,1e-8,1.0))\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    q = smooth_probs_box(q.astype(np.float32), k=smooth_k)\n",
        "    return q\n",
        "\n",
        "# --- Borda aggregation ---\n",
        "def borda_aggregate(o1, o2, o3, p_fused, M_pairwise):\n",
        "    # ranks: dict class->rank (1..20)\n",
        "    ranks = []\n",
        "    for o in (o1,o2,o3):\n",
        "        rk={c:i+1 for i,c in enumerate(o)}\n",
        "        ranks.append(rk)\n",
        "    classes = list(range(1,21))\n",
        "    # base Borda score\n",
        "    scores = {c: sum(21 - ranks[k].get(c, 20) for k in range(3)) for c in classes}\n",
        "    # tie-breakers: total mass desc, then pairwise margin desc, then o1 precedence\n",
        "    mass = {c: float(p_fused[c].sum()) for c in classes}\n",
        "    # pairwise margin proxy: sum over j M[c_idx-1, j-1]\n",
        "    # Build mapping class->idx 0..19\n",
        "    idx = {c: c-1 for c in classes}\n",
        "    margin = {c: float(M_pairwise[idx[c]].sum()) for c in classes}\n",
        "    # final ordering\n",
        "    def key(c):\n",
        "        return (-scores[c], -mass[c], -margin[c], ranks[0].get(c, 20))\n",
        "    agg = sorted(classes, key=key)\n",
        "    return agg\n",
        "\n",
        "# --- Main: test decode with ensemble ---\n",
        "def generate_submission_borda(out_csv='submission_ensemble_borda_gated.csv'):\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med, q95 = compute_duration_stats(all_train_ids)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        p = build_fused_probs_gated(int(sid), alpha_vis=0.26, gamma_a=0.25, smooth_k=5)\n",
        "        # Candidate 1: MinSeg k=5, ABA max_len=2\n",
        "        min_dur = np.floor(med*0.7 + 0.5).astype(np.int32); min_dur[0]=0\n",
        "        y1 = decode_minseg(p, min_dur.copy())\n",
        "        y1 = aba_collapse(y1, max_len=2)\n",
        "        o1 = make_perm20(compress_to_sequence(y1), p)\n",
        "        # Candidate 2: MinSeg k=3, ABA max_len=3\n",
        "        p_s3 = smooth_probs_box(p, k=3)\n",
        "        y2 = decode_minseg(p_s3, min_dur.copy())\n",
        "        y2 = aba_collapse(y2, max_len=3)\n",
        "        o2 = make_perm20(compress_to_sequence(y2), p)\n",
        "        # Candidate 3: Pairwise q=1.8\n",
        "        o3, M = pairwise_order_from_probs(p, q_power=1.8)\n",
        "        # Ensure all are length 20 unique\n",
        "        if len(o1)!=20: o1 = make_perm20(o1, p)\n",
        "        if len(o2)!=20: o2 = make_perm20(o2, p)\n",
        "        if len(o3)!=20: o3 = make_perm20(o3, p)\n",
        "        # Borda\n",
        "        o_final = borda_aggregate(o1, o2, o3, p, M)\n",
        "        # Boundary optimization\n",
        "        bnds = optimize_boundaries(o_final, p, med, q95, w_dur=0.05, stride=3)\n",
        "        y = np.zeros(p.shape[1], dtype=np.int32)\n",
        "        for k,c in enumerate(o_final):\n",
        "            t0=bnds[k]; t1=bnds[k+1]\n",
        "            y[t0:t1]=c\n",
        "        seq_raw = [int(c) for i,c in enumerate(y) if c!=0 and (i==0 or y[i-1]!=c)]\n",
        "        seq = make_perm20(seq_raw, p)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    sub.to_csv('submission.csv', index=False); print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('Generating Borda-ensemble gated submission...', flush=True)\n",
        "generate_submission_borda(out_csv='submission_ensemble_borda_gated.csv')\n",
        "print('Done.')\n",
        "\n",
        "# Note: This cell performs TEST decode only and overwrites submission.csv intentionally."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Borda-ensemble gated submission...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=1759186533.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=1759186812.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=1759186840.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=1759186849.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=1759186233.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_ensemble_borda_gated.csv rows= 95\nsubmission.csv written -> submission_ensemble_borda_gated.csv\nDone.\n"
          ]
        }
      ]
    },
    {
      "id": "1c11b176-4200-4938-ae10-098acab8152b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Re-run Borda ensemble with audio gate=0.3 (visuals keep 0.5); stage as submission.csv\n",
        "import numpy as np, pandas as pd, time\n",
        "from pathlib import Path\n",
        "\n",
        "def build_fused_probs_gated_audio03(sid: int, alpha_vis=0.26, gamma_a=0.25, smooth_k=5):\n",
        "    ps_ref = load_skeleton_probs(sid)\n",
        "    pr = load_probs_generic(sid, 'rgb')\n",
        "    pdp = load_probs_generic(sid, 'depth')\n",
        "    pu  = load_probs_generic(sid, 'user')\n",
        "    pa  = load_probs_generic(sid, 'audio')\n",
        "    # temp-scale for test using average fold temps\n",
        "    t = get_test_temp_avg(TEMP_RGB);   pr  = temp_scale_scalar(pr,  t) if pr  is not None else None\n",
        "    t = get_test_temp_avg(TEMP_DEPTH); pdp = temp_scale_scalar(pdp, t) if pdp is not None else None\n",
        "    t = get_test_temp_avg(TEMP_USER);  pu  = temp_scale_scalar(pu,  t) if pu  is not None else None\n",
        "    t = get_test_temp_avg(TEMP_AUDIO); pa  = temp_scale_scalar(pa,  t) if pa is not None else None\n",
        "    # align and compute corr; gate: visuals >=0.5, audio >=0.3\n",
        "    aligned = [ps_ref]\n",
        "    vis_list=[]\n",
        "    if pr is not None:\n",
        "        pr_a, ps_a, corr = align_with_corr(pr, ps_ref, max_shift=15)\n",
        "        if corr >= 0.5: vis_list.append(pr_a); aligned.append(ps_a)\n",
        "    if pdp is not None:\n",
        "        pdp_a, ps_a2, corr = align_with_corr(pdp, ps_ref, max_shift=15)\n",
        "        if corr >= 0.5: vis_list.append(pdp_a); aligned.append(ps_a2)\n",
        "    if pu is not None:\n",
        "        pu_a, ps_a3, corr = align_with_corr(pu, ps_ref, max_shift=15)\n",
        "        if corr >= 0.5: vis_list.append(pu_a); aligned.append(ps_a3)\n",
        "    pa_a = None\n",
        "    if pa is not None:\n",
        "        pa_a_tmp, ps_a4, corr = align_with_corr(pa, ps_ref, max_shift=15)\n",
        "        if corr >= 0.3:\n",
        "            pa_a = pa_a_tmp; aligned.append(ps_a4)\n",
        "    Tm = min(x.shape[1] for x in aligned)\n",
        "    ps = ps_ref[:, :Tm]\n",
        "    if vis_list:\n",
        "        vis_list = [v[:, :Tm] for v in vis_list]\n",
        "        pvis = np.mean(vis_list, axis=0)\n",
        "        pvis /= (pvis.sum(axis=0, keepdims=True)+1e-8)\n",
        "    else:\n",
        "        pvis = None\n",
        "    if pa_a is not None: pa_a = pa_a[:, :Tm]\n",
        "    w_s = 1.0 - (alpha_vis if pvis is not None else 0.0) - (gamma_a if pa_a is not None else 0.0)\n",
        "    logp = w_s*np.log(np.clip(ps,1e-8,1.0))\n",
        "    if pvis is not None: logp += alpha_vis*np.log(np.clip(pvis,1e-8,1.0))\n",
        "    if pa_a is not None: logp += gamma_a*np.log(np.clip(pa_a,1e-8,1.0))\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    q = smooth_probs_box(q.astype(np.float32), k=smooth_k)\n",
        "    return q\n",
        "\n",
        "def generate_submission_borda_audio03(out_csv='submission_ensemble_borda_gated_audio03.csv'):\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med, q95 = compute_duration_stats(all_train_ids)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        p = build_fused_probs_gated_audio03(int(sid), alpha_vis=0.26, gamma_a=0.25, smooth_k=5)\n",
        "        min_dur = np.floor(med*0.7 + 0.5).astype(np.int32); min_dur[0]=0\n",
        "        y1 = decode_minseg(p, min_dur.copy()); y1 = aba_collapse(y1, max_len=2)\n",
        "        o1 = make_perm20(compress_to_sequence(y1), p)\n",
        "        p_s3 = smooth_probs_box(p, k=3)\n",
        "        y2 = decode_minseg(p_s3, min_dur.copy()); y2 = aba_collapse(y2, max_len=3)\n",
        "        o2 = make_perm20(compress_to_sequence(y2), p)\n",
        "        o3, M = pairwise_order_from_probs(p, q_power=1.8)\n",
        "        if len(o1)!=20: o1 = make_perm20(o1, p)\n",
        "        if len(o2)!=20: o2 = make_perm20(o2, p)\n",
        "        if len(o3)!=20: o3 = make_perm20(o3, p)\n",
        "        o_final = borda_aggregate(o1, o2, o3, p, M)\n",
        "        bnds = optimize_boundaries(o_final, p, med, q95, w_dur=0.05, stride=3)\n",
        "        y = np.zeros(p.shape[1], dtype=np.int32)\n",
        "        for k,c in enumerate(o_final):\n",
        "            t0=bnds[k]; t1=bnds[k+1]\n",
        "            y[t0:t1]=c\n",
        "        seq_raw = [int(c) for i,c in enumerate(y) if c!=0 and (i==0 or y[i-1]!=c)]\n",
        "        seq = make_perm20(seq_raw, p)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f\"Decoded {n}/95 elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    sub.to_csv('submission.csv', index=False); print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('Generating Borda-ensemble (audio gate=0.3)...', flush=True)\n",
        "generate_submission_borda_audio03(out_csv='submission_ensemble_borda_gated_audio03.csv')\n",
        "print('Done.')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Borda-ensemble (audio gate=0.3)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=1759186858.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=1759187138.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=1759187165.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=1759187175.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=1759186559.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_ensemble_borda_gated_audio03.csv rows= 95\nsubmission.csv written -> submission_ensemble_borda_gated_audio03.csv\nDone.\n"
          ]
        }
      ]
    },
    {
      "id": "02ea070f-afaa-4741-9ab8-2340ddebfccb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OOF sanity check: Borda-gated (audio gate=0.3) vs baseline PoE+MinSeg\n",
        "import numpy as np, pandas as pd, json, time\n",
        "from collections import defaultdict\n",
        "\n",
        "def lev_dist(a, b):\n",
        "    n=len(a); m=len(b)\n",
        "    if n==0: return m\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; cost=0 if a[i-1]==b[j-1] else 1\n",
        "            dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "def compress_to_sequence(y_frames):\n",
        "    seq=[]; last=-1\n",
        "    for c in y_frames:\n",
        "        if c==0: continue\n",
        "        if c!=last: seq.append(int(c)); last=int(c)\n",
        "    return seq\n",
        "\n",
        "def oof_eval_borda_and_baseline():\n",
        "    results = {'borda03': [], 'baseline_poe': []}\n",
        "    fold_stats = {'borda03': [], 'baseline_poe': []}\n",
        "    t_all = time.time()\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med, q95 = compute_duration_stats(tr)\n",
        "        # baseline PoE uses build_fused_probs_for_id from cell 4 with smooth_k=5\n",
        "        dists_borda=[]; dists_base=[]\n",
        "        t0 = time.time()\n",
        "        for sid in va:\n",
        "            sid = int(sid)\n",
        "            # skip if skeleton probs missing\n",
        "            if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "                continue\n",
        "            # Borda-gated audio0.3 fused probs\n",
        "            p_borda = build_fused_probs_gated_audio03(sid, alpha_vis=0.26, gamma_a=0.25, smooth_k=5)\n",
        "            # Candidates\n",
        "            min_dur = np.floor(med*0.7 + 0.5).astype(np.int32); min_dur[0]=0\n",
        "            y1 = decode_minseg(p_borda, min_dur.copy()); y1 = aba_collapse(y1, max_len=2)\n",
        "            o1 = make_perm20(compress_to_sequence(y1), p_borda)\n",
        "            p_s3 = smooth_probs_box(p_borda, k=3)\n",
        "            y2 = decode_minseg(p_s3, min_dur.copy()); y2 = aba_collapse(y2, max_len=3)\n",
        "            o2 = make_perm20(compress_to_sequence(y2), p_borda)\n",
        "            o3, M = pairwise_order_from_probs(p_borda, q_power=1.8)\n",
        "            if len(o1)!=20: o1 = make_perm20(o1, p_borda)\n",
        "            if len(o2)!=20: o2 = make_perm20(o2, p_borda)\n",
        "            if len(o3)!=20: o3 = make_perm20(o3, p_borda)\n",
        "            of = borda_aggregate(o1, o2, o3, p_borda, M)\n",
        "            bnds = optimize_boundaries(of, p_borda, med, q95, w_dur=0.05, stride=3)\n",
        "            yf = np.zeros(p_borda.shape[1], dtype=np.int32)\n",
        "            for k,c in enumerate(of):\n",
        "                tA=bnds[k]; tB=bnds[k+1]\n",
        "                yf[tA:tB]=c\n",
        "            seq_borda = compress_to_sequence(yf)\n",
        "            # Baseline PoE fused probs\n",
        "            p_base = build_fused_probs_for_id(sid, alpha_vis=0.26, gamma_a=0.25, smooth_k=5, fold=int(fd['fold']))\n",
        "            yb = decode_minseg(p_base, min_dur.copy()); yb = aba_collapse(yb, max_len=2)\n",
        "            seq_base = compress_to_sequence(yb)\n",
        "            # Ground truth\n",
        "            y_true = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "            seq_true = compress_to_sequence(y_true)\n",
        "            d_b = lev_dist(seq_borda, seq_true); dists_borda.append(d_b)\n",
        "            d_a = lev_dist(seq_base, seq_true); dists_base.append(d_a)\n",
        "        worst_b = max(dists_borda) if dists_borda else 1e9\n",
        "        mean_b  = float(np.mean(dists_borda)) if dists_borda else 1e9\n",
        "        worst_a = max(dists_base) if dists_base else 1e9\n",
        "        mean_a  = float(np.mean(dists_base)) if dists_base else 1e9\n",
        "        fold_stats['borda03'].append(mean_b); fold_stats['baseline_poe'].append(mean_a)\n",
        "        print(f\"fold={fd['fold']} Borda03 mean={mean_b:.3f} (norm={mean_b/20:.3f}) worst={worst_b:.3f} | Base mean={mean_a:.3f} (norm={mean_a/20:.3f}) worst={worst_a:.3f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "        results['borda03'].extend(dists_borda); results['baseline_poe'].extend(dists_base)\n",
        "    # summarize overall\n",
        "    worst_b = max(results['borda03']) if results['borda03'] else 1e9\n",
        "    mean_b  = float(np.mean(results['borda03'])) if results['borda03'] else 1e9\n",
        "    worst_a = max(results['baseline_poe']) if results['baseline_poe'] else 1e9\n",
        "    mean_a  = float(np.mean(results['baseline_poe'])) if results['baseline_poe'] else 1e9\n",
        "    print(f\"OOF summary Borda03: worst={worst_b:.3f}, mean={mean_b:.3f}, norm_mean={mean_b/20:.5f}\")\n",
        "    print(f\"OOF summary Baseline: worst={worst_a:.3f}, mean={mean_a:.3f}, norm_mean={mean_a/20:.5f}\")\n",
        "    print(f\"Total elapsed={time.time()-t_all:.1f}s\", flush=True)\n",
        "\n",
        "print('Running OOF sanity check for Borda audio0.3 vs baseline PoE...', flush=True)\n",
        "oof_eval_borda_and_baseline()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running OOF sanity check for Borda audio0.3 vs baseline PoE...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 Borda03 mean=10.347 (norm=0.517) worst=15.000 | Base mean=3.857 (norm=0.193) worst=10.000 elapsed=35.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 Borda03 mean=8.798 (norm=0.440) worst=17.000 | Base mean=2.929 (norm=0.146) worst=13.000 elapsed=32.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 Borda03 mean=10.320 (norm=0.516) worst=20.000 | Base mean=4.470 (norm=0.223) worst=20.000 elapsed=33.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF summary Borda03: worst=20.000, mean=9.822, norm_mean=0.49108\nOOF summary Baseline: worst=20.000, mean=3.754, norm_mean=0.18771\nTotal elapsed=102.3s\n"
          ]
        }
      ]
    },
    {
      "id": "8d4c42e7-2351-4077-b5d3-bf2ef2c5857c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Soft-gated PoE fusion by entropy correlation per stream; OOF sanity and TEST decode\n",
        "import numpy as np, pandas as pd, json, time\n",
        "from pathlib import Path\n",
        "\n",
        "probs_cache = Path('probs_cache')\n",
        "\n",
        "def soft_gate_from_corr(corr, w_min=0.05, w_max=0.40):\n",
        "    if corr is None: return 0.0\n",
        "    w = (corr + 1.0) / 4.0  # maps corr in [-1,1] -> [0,0.5]\n",
        "    return float(np.clip(w, w_min, w_max))\n",
        "\n",
        "def build_fused_probs_softgate(sid: int, smooth_k=5, fold: int | None = None, for_test: bool = False, audio_gate_thresh=0.30):\n",
        "    ps_ref = load_skeleton_probs(sid)\n",
        "    pr = load_probs_generic(sid, 'rgb')\n",
        "    pdp = load_probs_generic(sid, 'depth')\n",
        "    pu  = load_probs_generic(sid, 'user')\n",
        "    pa  = load_probs_generic(sid, 'audio')\n",
        "    # temp-scale using fold temps for OOF or avg test temps\n",
        "    if fold is not None:\n",
        "        if pr is not None and fold in TEMP_RGB:     pr  = temp_scale_scalar(pr,  TEMP_RGB[fold])\n",
        "        if pdp is not None and fold in TEMP_DEPTH:  pdp = temp_scale_scalar(pdp, TEMP_DEPTH[fold])\n",
        "        if pu  is not None and fold in TEMP_USER:   pu  = temp_scale_scalar(pu,  TEMP_USER[fold])\n",
        "        if pa  is not None and fold in TEMP_AUDIO:  pa  = temp_scale_scalar(pa,  TEMP_AUDIO[fold])\n",
        "    elif for_test:\n",
        "        t = get_test_temp_avg(TEMP_RGB);   pr  = temp_scale_scalar(pr,  t) if pr  is not None else None\n",
        "        t = get_test_temp_avg(TEMP_DEPTH); pdp = temp_scale_scalar(pdp, t) if pdp is not None else None\n",
        "        t = get_test_temp_avg(TEMP_USER);  pu  = temp_scale_scalar(pu,  t) if pu  is not None else None\n",
        "        t = get_test_temp_avg(TEMP_AUDIO); pa  = temp_scale_scalar(pa,  t) if pa is not None else None\n",
        "    # align independently to skeleton and get corr\n",
        "    aligned_refs = [ps_ref]\n",
        "    streams = []  # list of (p_aligned, weight)\n",
        "    # Visual streams (soft weights from corr, no hard dropping)\n",
        "    if pr is not None:\n",
        "        pr_a, ps_a, cr = align_with_corr(pr, ps_ref, max_shift=15)\n",
        "        w = soft_gate_from_corr(cr, 0.05, 0.40)\n",
        "        streams.append((pr_a, w)); aligned_refs.append(ps_a)\n",
        "    if pdp is not None:\n",
        "        pdp_a, ps_a2, cr = align_with_corr(pdp, ps_ref, max_shift=15)\n",
        "        w = soft_gate_from_corr(cr, 0.05, 0.40)\n",
        "        streams.append((pdp_a, w)); aligned_refs.append(ps_a2)\n",
        "    if pu is not None:\n",
        "        pu_a, ps_a3, cr = align_with_corr(pu, ps_ref, max_shift=15)\n",
        "        w = soft_gate_from_corr(cr, 0.05, 0.40)\n",
        "        streams.append((pu_a, w)); aligned_refs.append(ps_a3)\n",
        "    # Audio: allow lower gate thresh as per expert (0.3); then soft map\n",
        "    pa_a = None; w_audio = 0.0\n",
        "    if pa is not None:\n",
        "        pa_tmp, ps_a4, cr = align_with_corr(pa, ps_ref, max_shift=15)\n",
        "        if cr >= audio_gate_thresh:\n",
        "            pa_a = pa_tmp; aligned_refs.append(ps_a4); w_audio = soft_gate_from_corr(cr, 0.05, 0.40)\n",
        "    # crop all to common length\n",
        "    Tm = min(x.shape[1] for x in aligned_refs)\n",
        "    ps = ps_ref[:, :Tm]\n",
        "    # log-space PoE with per-stream weights; skeleton gets remainder\n",
        "    total_non_skel = sum(w for _,w in streams) + (w_audio if pa_a is not None else 0.0)\n",
        "    total_non_skel = float(np.clip(total_non_skel, 0.0, 0.95))\n",
        "    w_skel = 1.0 - total_non_skel\n",
        "    logp = w_skel * np.log(np.clip(ps, 1e-8, 1.0))\n",
        "    for p_str, w in streams:\n",
        "        p_str = p_str[:, :Tm]\n",
        "        logp += w * np.log(np.clip(p_str, 1e-8, 1.0))\n",
        "    if pa_a is not None:\n",
        "        pa_c = pa_a[:, :Tm]\n",
        "        logp += w_audio * np.log(np.clip(pa_c, 1e-8, 1.0))\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    q = smooth_probs_box(q.astype(np.float32), k=smooth_k)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def oof_eval_softgate_vs_base(audio_gate_thresh=0.30):\n",
        "    print('OOF soft-gate vs baseline...', flush=True)\n",
        "    results_soft=[]; results_base=[]\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med, q95 = compute_duration_stats(tr)\n",
        "        min_dur = np.floor(med*0.7 + 0.5).astype(np.int32); min_dur[0]=0\n",
        "        d_soft=[]; d_base=[]; t0=time.time()\n",
        "        for sid in va:\n",
        "            sid=int(sid)\n",
        "            if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "                continue\n",
        "            pf_s = build_fused_probs_softgate(sid, smooth_k=5, fold=int(fd['fold']), for_test=False, audio_gate_thresh=audio_gate_thresh)\n",
        "            y_s = decode_minseg(pf_s, min_dur.copy()); y_s = aba_collapse(y_s, max_len=2)\n",
        "            seq_s = compress_to_sequence(y_s)\n",
        "            pf_b = build_fused_probs_for_id(sid, alpha_vis=0.26, gamma_a=0.25, smooth_k=5, fold=int(fd['fold']))\n",
        "            y_b = decode_minseg(pf_b, min_dur.copy()); y_b = aba_collapse(y_b, max_len=2)\n",
        "            seq_b = compress_to_sequence(y_b)\n",
        "            y_true = np.load(labels_dir/f\"{sid}.npy\").astype(np.int32)\n",
        "            seq_t = compress_to_sequence(y_true)\n",
        "            # Levenshtein\n",
        "            def lev(a,b):\n",
        "                n=len(a); m=len(b)\n",
        "                if n==0: return m\n",
        "                dp=list(range(m+1))\n",
        "                for i in range(1,n+1):\n",
        "                    prev=dp[0]; dp[0]=i\n",
        "                    for j in range(1,m+1):\n",
        "                        tmp=dp[j]; cost=0 if a[i-1]==b[j-1] else 1\n",
        "                        dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "                return dp[m]\n",
        "            d_soft.append(lev(seq_s, seq_t)); d_base.append(lev(seq_b, seq_t))\n",
        "        print(f\"fold={fd['fold']} soft mean={np.mean(d_soft):.3f} (norm={np.mean(d_soft)/20:.3f}) | base mean={np.mean(d_base):.3f} (norm={np.mean(d_base)/20:.3f}) elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "        results_soft.extend(d_soft); results_base.extend(d_base)\n",
        "    print(f\"Summary soft: mean={np.mean(results_soft):.3f} (norm={np.mean(results_soft)/20:.5f})\")\n",
        "    print(f\"Summary base: mean={np.mean(results_base):.3f} (norm={np.mean(results_base)/20:.5f})\")\n",
        "\n",
        "def decode_test_softgate(audio_gate_thresh=0.30, out_csv='submission_softgate.csv'):\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med, q95 = compute_duration_stats(all_train_ids)\n",
        "    min_dur = np.floor(med*0.7 + 0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        pf = build_fused_probs_softgate(int(sid), smooth_k=5, fold=None, for_test=True, audio_gate_thresh=audio_gate_thresh)\n",
        "        y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "        seq_raw = compress_to_sequence(y)\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    # do not auto-stage; we will choose after OOF check\n",
        "\n",
        "print('Running OOF soft-gate vs base...', flush=True)\n",
        "oof_eval_softgate_vs_base(audio_gate_thresh=0.30)\n",
        "print('Optionally decode TEST with soft-gate by calling decode_test_softgate().')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running OOF soft-gate vs base...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF soft-gate vs baseline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 soft mean=12.990 (norm=0.649) | base mean=3.857 (norm=0.193) elapsed=4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 soft mean=12.020 (norm=0.601) | base mean=2.929 (norm=0.146) elapsed=3.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 soft mean=11.420 (norm=0.571) | base mean=4.470 (norm=0.223) elapsed=2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary soft: mean=12.138 (norm=0.60690)\nSummary base: mean=3.754 (norm=0.18771)\nOptionally decode TEST with soft-gate by calling decode_test_softgate().\n"
          ]
        }
      ]
    },
    {
      "id": "fc73c1d1-319f-4690-85ce-fa4e77ae795b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hedge 2: Gated-PoE (audio gate=0.3) + MinSeg (no Borda, no DP); TEST DECODE ONLY; does NOT overwrite submission.csv\n",
        "import numpy as np, pandas as pd, time\n",
        "from pathlib import Path\n",
        "\n",
        "def decode_test_gated_poe_minseg_audio03(out_csv='submission_gated_poe_minseg_a03.csv', alpha_vis=0.26, gamma_a=0.25, smooth_k=5, min_mult=0.70):\n",
        "    # duration stats from all train ids\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med, q95 = compute_duration_stats(all_train_ids)\n",
        "    min_dur = np.floor(med*min_mult + 0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        # fused probs with visual gate=0.5, audio gate=0.3\n",
        "        p = build_fused_probs_gated_audio03(int(sid), alpha_vis=alpha_vis, gamma_a=gamma_a, smooth_k=smooth_k)\n",
        "        # MinSeg decode\n",
        "        y = decode_minseg(p, min_dur.copy())\n",
        "        y = aba_collapse(y, max_len=2)\n",
        "        seq_raw = compress_to_sequence(y)\n",
        "        seq = make_perm20(seq_raw, p)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "\n",
        "print('Decoding TEST: Gated-PoE (audio gate=0.3) + MinSeg...', flush=True)\n",
        "decode_test_gated_poe_minseg_audio03(out_csv='submission_gated_poe_minseg_a03.csv', alpha_vis=0.26, gamma_a=0.25, smooth_k=5, min_mult=0.70)\n",
        "print('Done. submission.csv unchanged (baseline remains staged).')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST: Gated-PoE (audio gate=0.3) + MinSeg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_gated_poe_minseg_a03.csv rows= 95\nDone. submission.csv unchanged (baseline remains staged).\n"
          ]
        }
      ]
    },
    {
      "id": "c7844507-dc50-4930-b8c3-3ecb8abe00a2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Stage hedge submission: pairwise+DP q=1.8 wd=0.0\n",
        "import shutil, os\n",
        "src = 'submission_pairwise_dp_q18_wd00.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "shutil.copyfile(src, dst)\n",
        "print(f'Staged hedge submission: {src} -> {dst}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged hedge submission: submission_pairwise_dp_q18_wd00.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "f3b4cade-daae-444c-8c4b-badb161a120c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Stage hedge submission: gated PoE + MinSeg (audio gate=0.3)\n",
        "import shutil, os\n",
        "src = 'submission_gated_poe_minseg_a03.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "shutil.copyfile(src, dst)\n",
        "print(f'Staged hedge submission: {src} -> {dst}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged hedge submission: submission_gated_poe_minseg_a03.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "699632b5-a27c-4811-9cd4-5d629b85f88c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optional Hedge 3: Majority-vote MinSeg over min_dur multipliers on fused PoE; TEST DECODE ONLY\n",
        "import numpy as np, pandas as pd, time\n",
        "\n",
        "def majority_vote_labels(labels_list):\n",
        "    # labels_list: list of np.array int32 of equal length\n",
        "    L = len(labels_list)\n",
        "    T = labels_list[0].shape[0]\n",
        "    out = np.zeros(T, dtype=np.int32)\n",
        "    for t in range(T):\n",
        "        a = labels_list[0][t]; b = labels_list[1][t]; c = labels_list[2][t]\n",
        "        if a==b or a==c: out[t]=a\n",
        "        elif b==c: out[t]=b\n",
        "        else: out[t]=labels_list[1][t]  # tie-break to central (m=0.70)\n",
        "    return out\n",
        "\n",
        "def decode_test_minseg_majority(out_csv='submission_minseg_mv_m060_070_080.csv', alpha_vis=0.26, gamma_a=0.25, smooth_k=5):\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med, q95 = compute_duration_stats(all_train_ids)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        pf = build_fused_probs_for_id(int(sid), alpha_vis=alpha_vis, gamma_a=gamma_a, smooth_k=smooth_k, fold=None, for_test=True)\n",
        "        labels=[]\n",
        "        for mult in (0.60, 0.70, 0.80):\n",
        "            min_dur = np.floor(med*mult + 0.5).astype(np.int32); min_dur[0]=0\n",
        "            y = decode_minseg(pf, min_dur.copy())\n",
        "            y = aba_collapse(y, max_len=2)\n",
        "            labels.append(y)\n",
        "        y_mv = majority_vote_labels(labels)\n",
        "        seq_raw = [int(c) for i,c in enumerate(y_mv) if c!=0 and (i==0 or y_mv[i-1]!=c)]\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "\n",
        "print('Decoding TEST: MinSeg majority vote over m={0.60,0.70,0.80} ...', flush=True)\n",
        "decode_test_minseg_majority(out_csv='submission_minseg_mv_m060_070_080.csv', alpha_vis=0.26, gamma_a=0.25, smooth_k=5)\n",
        "print('Done. submission.csv unchanged (baseline remains staged unless restaged manually).')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST: MinSeg majority vote over m={0.60,0.70,0.80} ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_minseg_mv_m060_070_080.csv rows= 95\nDone. submission.csv unchanged (baseline remains staged unless restaged manually).\n"
          ]
        }
      ]
    },
    {
      "id": "6561b732-207b-4b3a-b50f-73e6bb0a5bcf",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Best-of-N test-time selection over tiny PoE/decoder grid; picks highest log-likelihood; TEST DECODE ONLY\n",
        "import numpy as np, pandas as pd, time\n",
        "\n",
        "def total_emission_loglik(y: np.ndarray, p: np.ndarray) -> float:\n",
        "    # y: framewise labels (int32, 0..20), p: CxT probs (same T as y)\n",
        "    C,T = p.shape\n",
        "    assert y.shape[0] == T, f'Length mismatch y={y.shape[0]} T={T}'\n",
        "    idx = np.clip(y, 0, C-1).astype(np.int32)\n",
        "    cols = np.arange(T, dtype=np.int32)\n",
        "    probs = np.clip(p[idx, cols], 1e-12, 1.0)\n",
        "    return float(np.log(probs).sum())\n",
        "\n",
        "def decode_minseg_on_probs(pf: np.ndarray, med: np.ndarray, min_mult: float):\n",
        "    min_dur = np.floor(med*min_mult + 0.5).astype(np.int32); min_dur[0]=0\n",
        "    y = decode_minseg(pf, min_dur.copy())\n",
        "    y = aba_collapse(y, max_len=2)\n",
        "    return y\n",
        "\n",
        "def build_fused_probs_fixed_for_test(sid: int, alpha_vis=0.26, gamma_a=0.25):\n",
        "    # Reuse build_fused_probs_for_id with for_test=True; keep k=3 as a light default pre-smooth\n",
        "    pf = build_fused_probs_for_id(int(sid), alpha_vis=alpha_vis, gamma_a=gamma_a, smooth_k=3, fold=None, for_test=True)\n",
        "    return pf\n",
        "\n",
        "def decode_test_bestofN(out_csv='submission_bestofN_poe_minseg.csv',\n",
        "                        alpha_list=(0.24,0.26,0.28), gamma_list=(0.20,0.25,0.30),\n",
        "                        smooth_list=(3,5), min_mult_list=(0.60,0.70)):\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med, q95 = compute_duration_stats(all_train_ids)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        best_ll = -1e99; best_seq=None\n",
        "        # Precompute base fused probs per (alpha,gamma)\n",
        "        pf_cache = {}\n",
        "        for av in alpha_list:\n",
        "            for ga in gamma_list:\n",
        "                pf_cache[(av,ga)] = build_fused_probs_fixed_for_test(sid, alpha_vis=av, gamma_a=ga)\n",
        "        for (av,ga), pf_base in pf_cache.items():\n",
        "            for sk in smooth_list:\n",
        "                # smooth once to pf_use; keep length consistent for both decode and LL\n",
        "                pf_use = smooth_probs_box(pf_base, k=sk)\n",
        "                for mm in min_mult_list:\n",
        "                    y = decode_minseg_on_probs(pf_use, med, min_mult=mm)\n",
        "                    ll = total_emission_loglik(y, pf_use)\n",
        "                    if ll > best_ll:\n",
        "                        best_ll = ll\n",
        "                        seq_raw = [int(c) for i,c in enumerate(y) if c!=0 and (i==0 or y[i-1]!=c)]\n",
        "                        seq = make_perm20(seq_raw, pf_use)\n",
        "                        best_seq = seq\n",
        "        ids.append(sid); rows.append(' '.join(map(str, best_seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f\"Decoded {n}/95 elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "\n",
        "print('Decoding TEST with Best-of-N PoE+MinSeg (tiny grid)...', flush=True)\n",
        "decode_test_bestofN(out_csv='submission_bestofN_poe_minseg.csv',\n",
        "                    alpha_list=(0.24,0.26,0.28), gamma_list=(0.20,0.25,0.30),\n",
        "                    smooth_list=(3,5), min_mult_list=(0.60,0.70))\n",
        "print('Done. submission.csv unchanged; stage explicitly before submit.')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST with Best-of-N PoE+MinSeg (tiny grid)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=8.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=11.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=13.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_bestofN_poe_minseg.csv rows= 95\nDone. submission.csv unchanged; stage explicitly before submit.\n"
          ]
        }
      ]
    },
    {
      "id": "59bd1e9a-7d30-4a71-babc-4237c3fb3b53",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Stage hedge submission: Best-of-N PoE+MinSeg\n",
        "import shutil, os\n",
        "src = 'submission_bestofN_poe_minseg.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "shutil.copyfile(src, dst)\n",
        "print(f'Staged hedge submission: {src} -> {dst}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged hedge submission: submission_bestofN_poe_minseg.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "288e7ca4-309f-4f34-934a-85b06d720344",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optional Hedge: PoE+MinSeg (m=0.65) with pairwise-margin fill for missing classes; TEST DECODE ONLY\n",
        "import numpy as np, pandas as pd, time\n",
        "\n",
        "def pairwise_margins(p: np.ndarray, q_power: float = 1.8):\n",
        "    # returns antisymmetric margins M (20x20) for classes 1..20\n",
        "    C,T = p.shape\n",
        "    w = np.power(np.clip(p[1:21], 1e-8, 1.0), q_power).astype(np.float32)  # 20 x T\n",
        "    S_after = np.cumsum(w[:, ::-1], axis=1)[:, ::-1]\n",
        "    W = np.zeros((20,20), dtype=np.float64)\n",
        "    for i in range(20):\n",
        "        wi = w[i]\n",
        "        for j in range(20):\n",
        "            if i==j: continue\n",
        "            W[i,j] = float((wi * S_after[j]).sum())\n",
        "    M = W - W.T\n",
        "    return M\n",
        "\n",
        "def make_perm20_pairmargin(seq_raw, p: np.ndarray, q_power: float = 1.8):\n",
        "    # keep first occurrences from seq_raw; fill missing by pairwise margin strength\n",
        "    seen=set(); seq=[]\n",
        "    for c in seq_raw:\n",
        "        if 1<=c<=20 and c not in seen:\n",
        "            seen.add(c); seq.append(c)\n",
        "    if len(seq) >= 20:\n",
        "        return seq[:20]\n",
        "    # compute margins\n",
        "    M = pairwise_margins(p, q_power=q_power)\n",
        "    # score each missing class by row-sum (overall dominance)\n",
        "    missing = [c for c in range(1,21) if c not in seen]\n",
        "    scores = {c: float(M[c-1].sum()) for c in missing}\n",
        "    missing_sorted = sorted(missing, key=lambda c: scores[c], reverse=True)\n",
        "    for c in missing_sorted:\n",
        "        if len(seq)==20: break\n",
        "        seq.append(c)\n",
        "    if len(seq)>20: seq = seq[:20]\n",
        "    return seq\n",
        "\n",
        "def decode_test_poe_minseg_pairfill(out_csv='submission_poe_m065_pairfill.csv', alpha_vis=0.26, gamma_a=0.25, smooth_k=5, min_mult=0.65, q_power=1.8):\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med, q95 = compute_duration_stats(all_train_ids)\n",
        "    min_dur = np.floor(med*min_mult + 0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        if not (probs_cache/f\"{sid}_ce.npy\").exists() or not (probs_cache/f\"{sid}_ce_v3.npy\").exists():\n",
        "            continue\n",
        "        pf = build_fused_probs_for_id(int(sid), alpha_vis=alpha_vis, gamma_a=gamma_a, smooth_k=smooth_k, fold=None, for_test=True)\n",
        "        y = decode_minseg(pf, min_dur.copy())\n",
        "        y = aba_collapse(y, max_len=2)\n",
        "        seq_raw = [int(c) for i,c in enumerate(y) if c!=0 and (i==0 or y[i-1]!=c)]\n",
        "        seq = make_perm20_pairmargin(seq_raw, pf, q_power=q_power)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "\n",
        "print('Decoding TEST: PoE+MinSeg (m=0.65) with pairwise-margin fill...', flush=True)\n",
        "decode_test_poe_minseg_pairfill(out_csv='submission_poe_m065_pairfill.csv', alpha_vis=0.26, gamma_a=0.25, smooth_k=5, min_mult=0.65, q_power=1.8)\n",
        "print('Done. submission.csv unchanged.')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST: PoE+MinSeg (m=0.65) with pairwise-margin fill...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_poe_m065_pairfill.csv rows= 95\nDone. submission.csv unchanged.\n"
          ]
        }
      ]
    },
    {
      "id": "fba4653e-366a-4dc0-8693-3eb5262e85a8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Stage hedge submission: PoE+MinSeg m=0.65 with pairwise-margin fill\n",
        "import shutil, os\n",
        "src = 'submission_poe_m065_pairfill.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "shutil.copyfile(src, dst)\n",
        "print(f'Staged hedge submission: {src} -> {dst}')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged hedge submission: submission_poe_m065_pairfill.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "15b5bb3e-8f8a-479f-890d-fbcdb5dcc7b4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CLIP ViT-B/32 feature extraction (fps=4, max_frames=512) -> rgb_clip_embed/{train,test}/{id}.npy\n",
        "import os, sys, subprocess, time, json, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Install deps if missing (torch cu121, open_clip_torch, decord)\n",
        "def ensure_pkg():\n",
        "    try:\n",
        "        import torch, open_clip, decord  # noqa\n",
        "        import torchvision  # noqa\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print('Installing deps...', e, flush=True)\n",
        "    cmds = [\n",
        "        [sys.executable, '-m', 'pip', 'install', '--index-url', 'https://download.pytorch.org/whl/cu121', '--extra-index-url', 'https://pypi.org/simple', 'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1'],\n",
        "        [sys.executable, '-m', 'pip', 'install', 'open_clip_torch', 'decord']\n",
        "    ]\n",
        "    for cmd in cmds:\n",
        "        print('>', ' '.join(cmd), flush=True)\n",
        "        subprocess.run(cmd, check=True)\n",
        "    print('Deps installed.', flush=True)\n",
        "\n",
        "ensure_pkg()\n",
        "\n",
        "import torch, torchvision.transforms as T\n",
        "import open_clip\n",
        "from decord import VideoReader, cpu\n",
        "from PIL import Image\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('CUDA available:', torch.cuda.is_available(), flush=True)\n",
        "if device=='cuda':\n",
        "    print('GPU:', torch.cuda.get_device_name(0), flush=True)\n",
        "\n",
        "CACHE_DIR = Path('rgb_clip_embed'); (CACHE_DIR/'train').mkdir(parents=True, exist_ok=True); (CACHE_DIR/'test').mkdir(parents=True, exist_ok=True)\n",
        "VID_DIR_T = Path('rgb_videos/train'); VID_DIR_E = Path('rgb_videos/test')\n",
        "\n",
        "# Model + transforms\n",
        "model, _, _ = open_clip.create_model_and_transforms('ViT-B-32-quickgelu', pretrained='laion400m_e32', device=device)\n",
        "model.eval()\n",
        "mean = (0.48145466, 0.4578275, 0.40821073); std = (0.26862954, 0.26130258, 0.27577711)\n",
        "tx = T.Compose([T.Resize(224, interpolation=T.InterpolationMode.BICUBIC), T.CenterCrop(224), T.ToTensor(), T.Normalize(mean, std)])\n",
        "\n",
        "def sample_idx(nf, fps_native, fps_target=4.0, max_frames=512):\n",
        "    if not fps_native or fps_native<=0: n = min(max_frames, nf)\n",
        "    else:\n",
        "        dur = nf/float(fps_native); n = min(max_frames, int(round(dur*fps_target)))\n",
        "    n = max(1, min(n, nf))\n",
        "    return np.linspace(0, nf-1, n).round().astype(int)\n",
        "\n",
        "@torch.no_grad()\n",
        "def encode_video(path: Path, max_frames=512, bs=128):\n",
        "    vr = VideoReader(str(path), ctx=cpu(0))\n",
        "    nf = len(vr)\n",
        "    try: fps_native = float(vr.get_avg_fps())\n",
        "    except Exception: fps_native = None\n",
        "    idx = sample_idx(nf, fps_native, 4.0, max_frames)\n",
        "    embs=[]\n",
        "    for i in range(0, len(idx), bs):\n",
        "        frames = vr.get_batch(idx[i:i+bs]).asnumpy()  # (B,H,W,C) uint8\n",
        "        imgs = [tx(Image.fromarray(fr)) for fr in frames]\n",
        "        x = torch.stack(imgs,0).to(device, non_blocking=True)\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16) if device=='cuda' else torch.no_grad():\n",
        "            f = model.encode_image(x)  # (B,512)\n",
        "        f = torch.nn.functional.normalize(f.float(), dim=1).cpu().numpy()\n",
        "        embs.append(f)\n",
        "    E = np.concatenate(embs,0).astype(np.float16)  # (T,512)\n",
        "    return E\n",
        "\n",
        "def id_to_video(dirpath: Path, sid: int):\n",
        "    # Expect exact match first\n",
        "    cands = list(dirpath.glob(f'{sid}.mp4'))\n",
        "    if cands: return cands[0]\n",
        "    # fallback: any file containing id\n",
        "    cands = list(dirpath.glob(f'*{sid}*.mp4'))\n",
        "    return cands[0] if cands else None\n",
        "\n",
        "def extract_split(split='train', max_frames=512):\n",
        "    csv_path = 'training.csv' if split=='train' else 'test.csv'\n",
        "    ids = pd.read_csv(csv_path)['Id'].astype(int).tolist()\n",
        "    out_dir = CACHE_DIR/split\n",
        "    vid_dir = VID_DIR_T if split=='train' else VID_DIR_E\n",
        "    done=0; t0=time.time()\n",
        "    for k,sid in enumerate(ids, 1):\n",
        "        out = out_dir/f\"{sid}.npy\"\n",
        "        if out.exists():\n",
        "            continue\n",
        "        vp = id_to_video(vid_dir, sid)\n",
        "        if vp is None:\n",
        "            # silently skip missing videos (e.g., some test ids)\n",
        "            continue\n",
        "        try:\n",
        "            E = encode_video(vp, max_frames=max_frames, bs=128)\n",
        "            np.save(out, E)\n",
        "        except Exception as e:\n",
        "            print('FAIL', split, sid, e, flush=True)\n",
        "        done+=1\n",
        "        if (done%20)==0:\n",
        "            print(f\"{split}: saved {done} in {time.time()-t0:.1f}s (last id={sid})\", flush=True)\n",
        "    print(split, 'finished; new saved =', done, 'elapsed=', round(time.time()-t0,1), 's', flush=True)\n",
        "\n",
        "print('Starting CLIP extraction (train then test)...', flush=True)\n",
        "extract_split('train', max_frames=512)\n",
        "extract_split('test',  max_frames=512)\n",
        "print('CLIP extraction done.', flush=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: NVIDIA A10-24Q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting CLIP extraction (train then test)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 20 in 26.7s (last id=21)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 40 in 55.8s (last id=41)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 60 in 91.0s (last id=61)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 80 in 124.1s (last id=81)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 100 in 148.2s (last id=102)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 120 in 172.1s (last id=122)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 140 in 196.4s (last id=142)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 160 in 219.2s (last id=162)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 180 in 242.3s (last id=182)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 200 in 266.3s (last id=202)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 220 in 290.1s (last id=222)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 240 in 317.0s (last id=242)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 260 in 341.4s (last id=262)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: saved 280 in 365.4s (last id=282)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train finished; new saved = 297 elapsed= 384.7 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: saved 20 in 23.8s (last id=319)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: saved 40 in 50.1s (last id=340)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: saved 60 in 74.3s (last id=362)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: saved 80 in 99.3s (last id=383)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test finished; new saved = 92 elapsed= 113.7 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP extraction done.\n"
          ]
        }
      ]
    },
    {
      "id": "440c04cf-d030-410c-9c49-5c117f45c452",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CLIP head training (3 folds, linear 512->21), cache OOF/test probs, per-fold temp scaling\n",
        "import json, numpy as np, pandas as pd, torch, torch.nn as nn, torch.nn.functional as F, time\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pathlib import Path\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "EMB_TR = Path('rgb_clip_embed/train'); EMB_TE = Path('rgb_clip_embed/test'); PROBS = Path('probs_cache'); PROBS.mkdir(exist_ok=True)\n",
        "LABELS = Path('labels3d_v2/train')\n",
        "\n",
        "def load_clip_embed(sid: int, split: str):\n",
        "    p = (EMB_TR if split=='train' else EMB_TE)/f'{sid}.npy'\n",
        "    if not p.exists(): return None\n",
        "    return np.load(p)\n",
        "\n",
        "def resample_labels(y, T):\n",
        "    if len(y)==T: return y\n",
        "    idx = np.linspace(0, len(y)-1, T).round().astype(int)\n",
        "    return y[idx]\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, ids):\n",
        "        self.items=[]\n",
        "        for sid in ids:\n",
        "            E = load_clip_embed(int(sid), 'train')\n",
        "            if E is None: continue\n",
        "            y = np.load(LABELS/f\"{int(sid)}.npy\").astype(np.int64)\n",
        "            y = resample_labels(y, E.shape[0])\n",
        "            self.items.append((int(sid), E.astype(np.float32), y))\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self, i):\n",
        "        sid,E,y = self.items[i]\n",
        "        return sid, torch.from_numpy(E), torch.from_numpy(y)\n",
        "\n",
        "class LinearHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(512, 21)\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "@torch.no_grad()\n",
        "def forward_logits_all(head, E_np: np.ndarray, bs: int = 4096):\n",
        "    xb = torch.from_numpy(E_np.astype(np.float32)).to(device)\n",
        "    outs=[]\n",
        "    for i in range(0, xb.size(0), bs):\n",
        "        outs.append(head(xb[i:i+bs]).float().cpu())\n",
        "    lg = torch.cat(outs,0).numpy()  # (T,21)\n",
        "    return lg\n",
        "\n",
        "def fit_temperature(head, val_items):\n",
        "    # Collect logits and labels\n",
        "    Xs=[]; Ys=[]\n",
        "    with torch.no_grad():\n",
        "        for sid,E,y in val_items:\n",
        "            xb = torch.from_numpy(E.astype(np.float32)).to(device)\n",
        "            outs=[]\n",
        "            for i in range(0, xb.size(0), 4096):\n",
        "                outs.append(head(xb[i:i+4096]).float())\n",
        "            lg = torch.cat(outs,0)  # (T,21)\n",
        "            Xs.append(lg.cpu()); Ys.append(torch.from_numpy(y))\n",
        "    X = torch.cat(Xs,0).to(device); Y = torch.cat(Ys,0).to(device)\n",
        "    Tsc = torch.tensor(1.5, device=device, requires_grad=True)\n",
        "    opt = torch.optim.LBFGS([Tsc], lr=0.01, max_iter=50)\n",
        "    def closure():\n",
        "        opt.zero_grad()\n",
        "        loss = F.cross_entropy(X / Tsc, Y, reduction='mean')\n",
        "        loss.backward()\n",
        "        return loss\n",
        "    opt.step(closure)\n",
        "    return float(Tsc.detach().cpu().item())\n",
        "\n",
        "def train_clip_head_and_cache(folds_path='folds_archive_cv.json', epochs=3, bs_frames=2048, lr=2e-3, wd=0.05):\n",
        "    folds = json.load(open(folds_path,'r'))\n",
        "    test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "    for fd in folds:\n",
        "        fidx = int(fd['fold'])\n",
        "        tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "        ds_tr = SeqDataset(tr_ids); ds_va = SeqDataset(va_ids)\n",
        "        # Flatten frames for training\n",
        "        Xtr = np.concatenate([E for _,E,_ in ds_tr.items], axis=0)\n",
        "        Ytr = np.concatenate([y for *_,y in ds_tr.items], axis=0)\n",
        "        # Build loaders as chunks to avoid extra copies\n",
        "        n = Xtr.shape[0]\n",
        "        chunks = [(Xtr[i:i+bs_frames], Ytr[i:i+bs_frames]) for i in range(0, n, bs_frames)]\n",
        "        head = LinearHead().to(device)\n",
        "        opt = torch.optim.AdamW(head.parameters(), lr=lr, weight_decay=wd)\n",
        "        scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
        "        t0=time.time()\n",
        "        head.train()\n",
        "        for ep in range(epochs):\n",
        "            loss_sum=0.0; nb=0\n",
        "            for xb_np,yb_np in chunks:\n",
        "                xb = torch.from_numpy(xb_np).to(device)\n",
        "                yb = torch.from_numpy(yb_np).to(device)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
        "                    lg = head(xb)\n",
        "                    loss = F.cross_entropy(lg, yb, label_smoothing=0.05)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(opt); scaler.update()\n",
        "                loss_sum += float(loss.detach().cpu().item()); nb+=1\n",
        "            print(f\"fold={fidx} ep={ep+1}/{epochs} loss={loss_sum/max(nb,1):.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "        # Cache OOF probs for validation ids\n",
        "        head.eval()\n",
        "        with torch.no_grad():\n",
        "            for sid,E,y in ds_va.items:\n",
        "                lg = forward_logits_all(head, E, bs=4096)  # (T,21)\n",
        "                p = torch.softmax(torch.from_numpy(lg), dim=1).numpy().astype(np.float32).T  # CxT\n",
        "                np.save(PROBS/f\"{sid}_clip.npy\", p)\n",
        "        # Temp scaling on validation\n",
        "        Tval = fit_temperature(head, ds_va.items)\n",
        "        json.dump({'T': Tval}, open(f'clip_temp_fold{fidx}.json','w'))\n",
        "        # Test per-fold probs (temp-scaled)\n",
        "        with torch.no_grad():\n",
        "            for sid in test_ids:\n",
        "                E = load_clip_embed(int(sid), 'test')\n",
        "                if E is None: continue\n",
        "                lg = forward_logits_all(head, E, bs=4096)  # (T,21)\n",
        "                p = torch.softmax(torch.from_numpy(lg)/Tval, dim=1).numpy().astype(np.float32).T  # CxT\n",
        "                np.save(PROBS/f\"{sid}_clip_f{fidx}.npy\", p)\n",
        "    print('CLIP head training + caching complete.', flush=True)\n",
        "\n",
        "print('Ready: run train_clip_head_and_cache() after embeddings finish.')\n",
        "\n",
        "# Fusion + decode with CLIP stream into PoE; small OOF grid and test decode\n",
        "def _load_temp_num(path: str):\n",
        "    p = Path(path)\n",
        "    if not p.exists(): return None\n",
        "    try:\n",
        "        return float(json.load(open(p,'r')).get('T', 1.0))\n",
        "    except Exception:\n",
        "        try: return float(open(p).read().strip())\n",
        "        except Exception: return None\n",
        "\n",
        "def clip_test_temp_mean():\n",
        "    ts = [_load_temp_num(f'clip_temp_fold{f}.json') for f in (0,1,2)]\n",
        "    ts = [t for t in ts if t is not None]\n",
        "    return float(np.mean(ts)) if ts else 1.0\n",
        "\n",
        "def load_clip_probs_train(sid:int):\n",
        "    pth = PROBS/f\"{sid}_clip.npy\"\n",
        "    if not pth.exists(): return None\n",
        "    arr = np.load(pth).astype(np.float32)\n",
        "    return arr\n",
        "\n",
        "def load_clip_probs_test_avg(sid:int):\n",
        "    arr=[]\n",
        "    for f in (0,1,2):\n",
        "        pth = PROBS/f\"{sid}_clip_f{f}.npy\"\n",
        "        if pth.exists(): arr.append(np.load(pth).astype(np.float32))\n",
        "    if not arr: return None\n",
        "    L = min(a.shape[1] for a in arr)\n",
        "    q = np.mean([a[:, :L] for a in arr], axis=0)\n",
        "    q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    return q\n",
        "\n",
        "# Reuse ensure_CxT, load_skeleton_probs, load_probs_generic, align_by_entropy_corr, smooth_probs_box, decode_minseg, aba_collapse, compress_to_sequence, make_perm20, compute_min_dur_from_ids if present\n",
        "def fuse_poe_with_clip(ps, p_clip, p_audio, alpha_clip, gamma_audio):\n",
        "    parts=[ps]\n",
        "    if p_clip is not None:\n",
        "        pc, ps = align_by_entropy_corr(p_clip, ps, max_shift=15); parts.append(pc)\n",
        "    if p_audio is not None:\n",
        "        pa, ps = align_by_entropy_corr(p_audio, ps, max_shift=15); parts.append(pa)\n",
        "    Tm = min(p.shape[1] for p in parts)\n",
        "    ps = ps[:, :Tm]\n",
        "    pc = parts[1][:, :Tm] if p_clip is not None else None\n",
        "    pa = parts[-1][:, :Tm] if p_audio is not None else None\n",
        "    w_s = 1.0 - (alpha_clip if pc is not None else 0.0) - (gamma_audio if pa is not None else 0.0)\n",
        "    logp = w_s*np.log(np.clip(ps,1e-8,1.0))\n",
        "    if pc is not None: logp += alpha_clip*np.log(np.clip(pc,1e-8,1.0))\n",
        "    if pa is not None: logp += gamma_audio*np.log(np.clip(pa,1e-8,1.0))\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "# --- temperature scaling helpers for parity ---\n",
        "def temp_scale_scalar(p_arr: np.ndarray | None, T: float | None):\n",
        "    if p_arr is None or T is None: return p_arr\n",
        "    logp = np.log(np.clip(p_arr, 1e-8, 1.0)) / max(float(T), 1e-6)\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "# --- length-preserving fusion (no crop-to-shortest): align by shift only, add overlap contributions ---\n",
        "def _find_best_shift(p_src: np.ndarray, p_ref: np.ndarray, max_shift: int = 15):\n",
        "    # Use entropy correlation to pick shift; return (sh, L) where sh can be negative\n",
        "    hs = entropy(p_src); hr = entropy(p_ref)\n",
        "    best = (-1e9, 0)\n",
        "    for sh in range(-max_shift, max_shift+1):\n",
        "        if sh >= 0:\n",
        "            L = min(hs.shape[0] - sh, hr.shape[0])\n",
        "            if L < 16: continue\n",
        "            s = hs[sh:sh+L]; r = hr[:L]\n",
        "        else:\n",
        "            L = min(hs.shape[0], hr.shape[0] + sh)\n",
        "            if L < 16: continue\n",
        "            s = hs[:L]; r = hr[-sh:-sh+L]\n",
        "        if s.std() < 1e-8 or r.std() < 1e-8:\n",
        "            corr = -1.0\n",
        "        else:\n",
        "            corr = float(np.corrcoef(s, r)[0,1])\n",
        "        if corr > best[0]: best = (corr, sh)\n",
        "    return best[1]\n",
        "\n",
        "def fuse_poe_with_clip_keep_len(ps: np.ndarray, p_clip: np.ndarray | None, p_audio: np.ndarray | None, alpha_clip: float, gamma_audio: float):\n",
        "    C, T = ps.shape\n",
        "    logp = np.log(np.clip(ps, 1e-8, 1.0))\n",
        "    w_s = np.ones(T, dtype=np.float32)\n",
        "    # CLIP contribution\n",
        "    if p_clip is not None:\n",
        "        sh = _find_best_shift(p_clip, ps, max_shift=15)\n",
        "        if sh >= 0:\n",
        "            L = min(p_clip.shape[1] - sh, T); ref_start = 0; src_start = sh\n",
        "        else:\n",
        "            L = min(p_clip.shape[1], T + sh); ref_start = -sh; src_start = 0\n",
        "        if L > 0:\n",
        "            w_s[ref_start:ref_start+L] -= alpha_clip\n",
        "            logp[:, ref_start:ref_start+L] += alpha_clip * np.log(np.clip(p_clip[:, src_start:src_start+L], 1e-8, 1.0))\n",
        "    # Audio contribution\n",
        "    if p_audio is not None:\n",
        "        sh = _find_best_shift(p_audio, ps, max_shift=15)\n",
        "        if sh >= 0:\n",
        "            L = min(p_audio.shape[1] - sh, T); ref_start = 0; src_start = sh\n",
        "        else:\n",
        "            L = min(p_audio.shape[1], T + sh); ref_start = -sh; src_start = 0\n",
        "        if L > 0:\n",
        "            w_s[ref_start:ref_start+L] -= gamma_audio\n",
        "            logp[:, ref_start:ref_start+L] += gamma_audio * np.log(np.clip(p_audio[:, src_start:src_start+L], 1e-8, 1.0))\n",
        "    w_s = np.clip(w_s, 0.0, 1.0)[None, :]\n",
        "    logp = w_s * logp\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def oof_grid_clip(alpha_list=(0.30,0.35,0.40,0.45,0.50), gamma_list=(0.15,0.20,0.25,0.30), smooth_k=5, min_mult=0.7, keep_len=True):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    results=[]\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med = compute_min_dur_from_ids(tr); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "        fidx = int(fd['fold'])\n",
        "        Tclip = _load_temp_num(f'clip_temp_fold{fidx}.json')\n",
        "        Taud  = _load_temp_num(f'audio_temp_fold{fidx}.json')\n",
        "        for a in alpha_list:\n",
        "            for g in gamma_list:\n",
        "                d=[]\n",
        "                for sid in va:\n",
        "                    sid=int(sid)\n",
        "                    ps = load_skeleton_probs(sid)\n",
        "                    pc = load_clip_probs_train(sid)\n",
        "                    pa = load_probs_generic(sid, 'audio')\n",
        "                    # temperature parity for OOF\n",
        "                    if pc is not None and Tclip is not None: pc = temp_scale_scalar(pc, Tclip)\n",
        "                    if pa is not None and Taud  is not None: pa = temp_scale_scalar(pa,  Taud)\n",
        "                    if keep_len:\n",
        "                        pf = fuse_poe_with_clip_keep_len(ps, pc, pa, a, g)\n",
        "                    else:\n",
        "                        pf = fuse_poe_with_clip(ps, pc, pa, a, g)\n",
        "                    pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                    y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                    seq = compress_to_sequence(y); true = compress_to_sequence(np.load(LABELS/f\"{sid}.npy\"))\n",
        "                    n=len(seq); m=len(true);\n",
        "                    if n==0: d.append(m); continue\n",
        "                    dp=list(range(m+1))\n",
        "                    for i in range(1,n+1):\n",
        "                        prev=dp[0]; dp[0]=i\n",
        "                        for j in range(1,m+1):\n",
        "                            tmp=dp[j]; cost=0 if seq[i-1]==true[j-1] else 1\n",
        "                            dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "                    d.append(dp[m])\n",
        "                results.append((max(d), float(np.mean(d)), a, g))\n",
        "    results.sort(key=lambda x: (x[0], x[1]))\n",
        "    return results[0]\n",
        "\n",
        "def decode_test_clip(alpha_clip=0.26, gamma_audio=0.25, smooth_k=5, min_mult=0.7, out_csv='submission_clip_poe.csv', keep_len=True):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    # average audio temperature over folds for test-time parity\n",
        "    Ta_list = [_load_temp_num(f'audio_temp_fold{f}.json') for f in (0,1,2)]\n",
        "    Ta_vals = [t for t in Ta_list if t is not None]\n",
        "    Ta_mean = float(np.mean(Ta_vals)) if len(Ta_vals)>0 else None\n",
        "    ids,rows=[],[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pc = load_clip_probs_test_avg(sid)  # per-fold temp already applied\n",
        "        pa = load_probs_generic(sid, 'audio')\n",
        "        if pa is not None and Ta_mean is not None:\n",
        "            pa = temp_scale_scalar(pa, Ta_mean)\n",
        "        if keep_len:\n",
        "            pf = fuse_poe_with_clip_keep_len(ps, pc, pa, alpha_clip, gamma_audio)\n",
        "        else:\n",
        "            pf = fuse_poe_with_clip(ps, pc, pa, alpha_clip, gamma_audio)\n",
        "        pf = smooth_probs_box(pf, k=smooth_k)\n",
        "        y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "        seq = make_perm20(compress_to_sequence(y), pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95', flush=True)\n",
        "    pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id').to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, flush=True)\n",
        "\n",
        "print('CLIP head cell ready. After embeddings finish:',\n",
        "      '\\n - train_clip_head_and_cache()  # ~60-75m',\n",
        "      '\\n - best = oof_grid_clip(); print(best)',\n",
        "      '\\n - decode_test_clip(alpha_clip=best[2], gamma_audio=best[3])', flush=True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready: run train_clip_head_and_cache() after embeddings finish.\nCLIP head cell ready. After embeddings finish: \n - train_clip_head_and_cache()  # ~60-75m \n - best = oof_grid_clip(); print(best) \n - decode_test_clip(alpha_clip=best[2], gamma_audio=best[3])\n"
          ]
        }
      ]
    },
    {
      "id": "68fbf301-2c5b-4a85-b119-468e05d1d7bc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run CLIP head training -> OOF grid -> test decode -> stage submission\n",
        "import time, shutil, os\n",
        "t0=time.time()\n",
        "print('Starting CLIP head training + caching...', flush=True)\n",
        "train_clip_head_and_cache(epochs=3, bs_frames=2048, lr=2e-3, wd=0.05)\n",
        "print(f'CLIP head done in {time.time()-t0:.1f}s', flush=True)\n",
        "print('Running small OOF grid for CLIP fusion...', flush=True)\n",
        "best = oof_grid_clip(alpha_list=(0.18,0.22,0.24,0.26,0.28), gamma_list=(0.20,0.25,0.30), smooth_k=5, min_mult=0.7)\n",
        "print('Best (worst, mean, alpha_clip, gamma_audio)=', best, flush=True)\n",
        "_,_,alpha_clip,gamma_audio = best\n",
        "print('Decoding TEST with best weights...', flush=True)\n",
        "decode_test_clip(alpha_clip=alpha_clip, gamma_audio=gamma_audio, smooth_k=5, min_mult=0.7, out_csv='submission_clip_poe.csv')\n",
        "src = 'submission_clip_poe.csv'; dst = 'submission.csv'\n",
        "if os.path.exists(src):\n",
        "    shutil.copyfile(src, dst)\n",
        "    print(f'Staged submission: {src} -> {dst}', flush=True)\n",
        "else:\n",
        "    print('ERROR: submission_clip_poe.csv not found', flush=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting CLIP head training + caching...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=1/3 loss=3.0246 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=2/3 loss=2.9646 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=3/3 loss=2.9289 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_114161/2940198149.py:87: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=1/3 loss=3.0209 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=2/3 loss=2.9359 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=3/3 loss=2.8867 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=1/3 loss=2.9405 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=2/3 loss=2.7434 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=3/3 loss=2.6489 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP head training + caching complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP head done in 1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running small OOF grid for CLIP fusion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best (worst, mean, alpha_clip, gamma_audio)= (19, 16.785714285714285, 0.28, 0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST with best weights...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_poe.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_poe.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "f77aa596-c664-4b9c-957e-1b0381102156",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Re-run OOF grid with calibration parity + expanded ranges, then decode test and stage\n",
        "import time, shutil, os\n",
        "print('Running parity-fixed OOF grid for CLIP fusion...', flush=True)\n",
        "t0=time.time()\n",
        "best = oof_grid_clip(alpha_list=(0.30,0.35,0.40,0.45,0.50), gamma_list=(0.15,0.20,0.25,0.30), smooth_k=5, min_mult=0.7)\n",
        "print('Best (worst, mean, alpha_clip, gamma_audio)=', best, 'elapsed=', round(time.time()-t0,1),'s', flush=True)\n",
        "_,_,alpha_clip,gamma_audio = best\n",
        "print(f'Decoding TEST with alpha_clip={alpha_clip}, gamma_audio={gamma_audio} ...', flush=True)\n",
        "out_csv = 'submission_clip_poe_fixed.csv'\n",
        "decode_test_clip(alpha_clip=alpha_clip, gamma_audio=gamma_audio, smooth_k=5, min_mult=0.7, out_csv=out_csv)\n",
        "if os.path.exists(out_csv):\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "else:\n",
        "    print('ERROR: submission_clip_poe_fixed.csv not found', flush=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running parity-fixed OOF grid for CLIP fusion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best (worst, mean, alpha_clip, gamma_audio)= (19, 16.79591836734694, 0.3, 0.15) elapsed= 38.7 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST with alpha_clip=0.3, gamma_audio=0.15 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_poe_fixed.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_poe_fixed.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "c1207885-333c-4dac-b25a-75a2cc083987",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Decode TEST with conservative CLIP fusion (keep_len) and stage\n",
        "import shutil, os, time\n",
        "alpha_clip = 0.40\n",
        "gamma_audio = 0.25\n",
        "out_csv = 'submission_clip_poe_noloss.csv'\n",
        "print(f'Decoding TEST with keep_len: alpha_clip={alpha_clip}, gamma_audio={gamma_audio}', flush=True)\n",
        "decode_test_clip(alpha_clip=alpha_clip, gamma_audio=gamma_audio, smooth_k=5, min_mult=0.7, out_csv=out_csv, keep_len=True)\n",
        "if os.path.exists(out_csv):\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "else:\n",
        "    print('ERROR: expected output file missing', flush=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST with keep_len: alpha_clip=0.4, gamma_audio=0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_poe_noloss.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_poe_noloss.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "73d6686e-8129-4e13-b896-152fbb35e854",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OOF sanity: CLIP keep_len PoE vs baseline PoE (MobileNet RGB) with temp parity; quick grid over alphas\n",
        "import numpy as np, pandas as pd, json, time\n",
        "from collections import defaultdict\n",
        "\n",
        "def lev_dist(a, b):\n",
        "    n=len(a); m=len(b)\n",
        "    if n==0: return m\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; cost=0 if a[i-1]==b[j-1] else 1\n",
        "            dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "def oof_eval_clip_keep_len_vs_base(alpha_list=(0.30,0.35,0.40,0.45), gamma_list=(0.20,0.25), smooth_k=5, min_mult=0.7):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    results = {}  # (a,g)-> list of fold means\n",
        "    base_stats = []\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med = compute_min_dur_from_ids(tr); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "        fidx = int(fd['fold'])\n",
        "        Tclip = _load_temp_num(f'clip_temp_fold{fidx}.json')\n",
        "        Taud  = _load_temp_num(f'audio_temp_fold{fidx}.json')\n",
        "        # baseline PoE mean on this fold for reference\n",
        "        d_base=[]\n",
        "        for sid in va:\n",
        "            sid=int(sid)\n",
        "            pf_base = build_fused_probs_for_id(sid, alpha_vis=0.26, gamma_a=0.25, smooth_k=5, fold=fidx)  # MobileNet RGB + audio\n",
        "            yb = decode_minseg(pf_base, min_dur.copy()); yb = aba_collapse(yb, max_len=2)\n",
        "            seq_b = compress_to_sequence(yb)\n",
        "            y_true = np.load(LABELS/f\"{sid}.npy\").astype(np.int32)\n",
        "            seq_t = compress_to_sequence(y_true)\n",
        "            d_base.append(lev_dist(seq_b, seq_t))\n",
        "        base_stats.append(float(np.mean(d_base)))\n",
        "        # grid for CLIP keep_len\n",
        "        for a in alpha_list:\n",
        "            for g in gamma_list:\n",
        "                d=[]\n",
        "                for sid in va:\n",
        "                    sid=int(sid)\n",
        "                    ps = load_skeleton_probs(sid)\n",
        "                    pc = load_clip_probs_train(sid)\n",
        "                    pa = load_probs_generic(sid, 'audio')\n",
        "                    if pc is not None and Tclip is not None: pc = temp_scale_scalar(pc, Tclip)\n",
        "                    if pa is not None and Taud  is not None: pa = temp_scale_scalar(pa,  Taud)\n",
        "                    pf = fuse_poe_with_clip_keep_len(ps, pc, pa, a, g)\n",
        "                    pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                    y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                    seq = compress_to_sequence(y)\n",
        "                    y_true = np.load(LABELS/f\"{sid}.npy\").astype(np.int32)\n",
        "                    seq_t = compress_to_sequence(y_true)\n",
        "                    d.append(lev_dist(seq, seq_t))\n",
        "                results.setdefault((a,g), []).append(float(np.mean(d)))\n",
        "        print(f\"fold={fidx} base_mean={np.mean(d_base):.3f} (norm={np.mean(d_base)/20:.3f})\", flush=True)\n",
        "    # summarize\n",
        "    summary=[]\n",
        "    for (a,g), arr in results.items():\n",
        "        worst=max(arr); mean=float(np.mean(arr))\n",
        "        summary.append((worst, mean, a, g))\n",
        "    summary.sort(key=lambda x: (x[0], x[1]))\n",
        "    print('Baseline OOF means per fold:', [f\"{x:.3f}\" for x in base_stats], 'overall mean=', f\"{np.mean(base_stats):.3f}\")\n",
        "    print('Top CLIP keep_len configs (worst,mean,a,g):')\n",
        "    for row in summary[:5]:\n",
        "        print(row)\n",
        "    return summary[0]\n",
        "\n",
        "print('Running OOF sanity: CLIP keep_len vs baseline...', flush=True)\n",
        "best_clip = oof_eval_clip_keep_len_vs_base(alpha_list=(0.30,0.35,0.40,0.45), gamma_list=(0.20,0.25), smooth_k=5, min_mult=0.7)\n",
        "print('Best CLIP keep_len config:', best_clip, flush=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running OOF sanity: CLIP keep_len vs baseline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 base_mean=3.857 (norm=0.193)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 base_mean=2.929 (norm=0.146)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 base_mean=4.470 (norm=0.223)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline OOF means per fold: ['3.857', '2.929', '4.470'] overall mean= 3.752\nTop CLIP keep_len configs (worst,mean,a,g):\n(4.45, 3.7286435786435788, 0.3, 0.2)\n(4.45, 3.7286435786435788, 0.3, 0.25)\n(4.46, 3.7285411942554796, 0.4, 0.2)\n(4.46, 3.7285411942554796, 0.4, 0.25)\n(4.46, 3.7319769119769126, 0.35, 0.2)\nBest CLIP keep_len config: (4.45, 3.7286435786435788, 0.3, 0.2)\n"
          ]
        }
      ]
    },
    {
      "id": "1c0d2ed3-a603-43e3-8568-d52b8370d46b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Decode TEST with OOF-best keep_len CLIP fusion (alpha=0.30, gamma=0.20) and stage\n",
        "import shutil, os, time\n",
        "alpha_clip = 0.30\n",
        "gamma_audio = 0.20\n",
        "out_csv = 'submission_clip_poe_keep_best.csv'\n",
        "print(f'Decoding TEST keep_len with alpha_clip={alpha_clip}, gamma_audio={gamma_audio}', flush=True)\n",
        "decode_test_clip(alpha_clip=alpha_clip, gamma_audio=gamma_audio, smooth_k=5, min_mult=0.7, out_csv=out_csv, keep_len=True)\n",
        "if os.path.exists(out_csv):\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "else:\n",
        "    print('ERROR: expected output file missing', flush=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST keep_len with alpha_clip=0.3, gamma_audio=0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_poe_keep_best.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_poe_keep_best.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "24793a4a-e032-499a-af73-c6e3efa607fb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CLIP + MobileNet RGB + Audio PoE (keep_len), temp parity; small OOF grid -> test decode\n",
        "import numpy as np, pandas as pd, json, time, os\n",
        "from pathlib import Path\n",
        "\n",
        "def _mean_fold_temp(prefix: str):\n",
        "    vals=[]\n",
        "    for f in (0,1,2):\n",
        "        t = _load_temp_num(f'{prefix}_fold{f}.json')\n",
        "        if t is not None: vals.append(float(t))\n",
        "    return float(np.mean(vals)) if vals else None\n",
        "\n",
        "def fuse_poe_keep_len_three(ps: np.ndarray, p_clip: np.ndarray | None, p_rgb: np.ndarray | None, p_audio: np.ndarray | None, a_clip: float, a_rgb: float, g_aud: float):\n",
        "    C,T = ps.shape\n",
        "    logp = np.log(np.clip(ps, 1e-8, 1.0))\n",
        "    w_s = np.ones(T, dtype=np.float32)\n",
        "    def add_stream(pv, alpha):\n",
        "        nonlocal logp, w_s\n",
        "        if pv is None or alpha<=0: return\n",
        "        sh = _find_best_shift(pv, ps, max_shift=15)\n",
        "        if sh >= 0:\n",
        "            L = min(pv.shape[1] - sh, T); ref_start = 0; src_start = sh\n",
        "        else:\n",
        "            L = min(pv.shape[1], T + sh); ref_start = -sh; src_start = 0\n",
        "        if L > 0:\n",
        "            w_s[ref_start:ref_start+L] -= alpha\n",
        "            logp[:, ref_start:ref_start+L] += alpha * np.log(np.clip(pv[:, src_start:src_start+L], 1e-8, 1.0))\n",
        "    add_stream(p_clip, a_clip)\n",
        "    add_stream(p_rgb,  a_rgb)\n",
        "    add_stream(p_audio, g_aud)\n",
        "    w_s = np.clip(w_s, 0.0, 1.0)[None, :]\n",
        "    logp = w_s * logp\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def oof_grid_clip_rgb(alpha_clip_list=(0.20,0.25,0.30), alpha_rgb_list=(0.10,0.15,0.20,0.25), gamma_list=(0.20,0.25), smooth_k=5, min_mult=0.7):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    results=[]\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med = compute_min_dur_from_ids(tr); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "        fidx = int(fd['fold'])\n",
        "        Tclip = _load_temp_num(f'clip_temp_fold{fidx}.json')\n",
        "        Trgb  = _load_temp_num(f'rgb_temp_fold{fidx}.json')\n",
        "        Taud  = _load_temp_num(f'audio_temp_fold{fidx}.json')\n",
        "        for ac in alpha_clip_list:\n",
        "            for ar in alpha_rgb_list:\n",
        "                for g in gamma_list:\n",
        "                    d=[]\n",
        "                    for sid in va:\n",
        "                        sid=int(sid)\n",
        "                        ps = load_skeleton_probs(sid)\n",
        "                        pc = load_clip_probs_train(sid)\n",
        "                        pr = load_probs_generic(sid, 'rgb')\n",
        "                        pa = load_probs_generic(sid, 'audio')\n",
        "                        if pc is not None and Tclip is not None: pc = temp_scale_scalar(pc, Tclip)\n",
        "                        if pr is not None and Trgb  is not None: pr = temp_scale_scalar(pr,  Trgb)\n",
        "                        if pa is not None and Taud  is not None: pa = temp_scale_scalar(pa,  Taud)\n",
        "                        pf = fuse_poe_keep_len_three(ps, pc, pr, pa, ac, ar, g)\n",
        "                        pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                        y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                        seq = compress_to_sequence(y); true = compress_to_sequence(np.load(LABELS/f\"{sid}.npy\"))\n",
        "                        n=len(seq); m=len(true);\n",
        "                        if n==0: d.append(m); continue\n",
        "                        dp=list(range(m+1))\n",
        "                        for i in range(1,n+1):\n",
        "                            prev=dp[0]; dp[0]=i\n",
        "                            for j in range(1,m+1):\n",
        "                                tmp=dp[j]; cost=0 if seq[i-1]==true[j-1] else 1\n",
        "                                dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "                        d.append(dp[m])\n",
        "                    results.append((max(d), float(np.mean(d)), ac, ar, g))\n",
        "    results.sort(key=lambda x: (x[0], x[1]))\n",
        "    return results[0]\n",
        "\n",
        "def decode_test_clip_rgb(a_clip=0.30, a_rgb=0.15, g_aud=0.20, smooth_k=5, min_mult=0.7, out_csv='submission_clip_rgb_keep.csv'):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    # temps: CLIP test already temped per-fold and averaged; RGB/audio need mean temps\n",
        "    Trgb_mean = _mean_fold_temp('rgb_temp')\n",
        "    Ta_mean   = _mean_fold_temp('audio_temp')\n",
        "    ids,rows=[],[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pc = load_clip_probs_test_avg(sid)\n",
        "        pr = load_probs_generic(sid, 'rgb')\n",
        "        pa = load_probs_generic(sid, 'audio')\n",
        "        if pr is not None and Trgb_mean is not None: pr = temp_scale_scalar(pr, Trgb_mean)\n",
        "        if pa is not None and Ta_mean   is not None: pa = temp_scale_scalar(pa,  Ta_mean)\n",
        "        pf = fuse_poe_keep_len_three(ps, pc, pr, pa, a_clip, a_rgb, g_aud)\n",
        "        pf = smooth_probs_box(pf, k=smooth_k)\n",
        "        y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "        seq = make_perm20(compress_to_sequence(y), pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95', flush=True)\n",
        "    pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id').to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, flush=True)\n",
        "\n",
        "print('Running OOF grid for CLIP+RGB+Audio (keep_len)...', flush=True)\n",
        "t0=time.time()\n",
        "best = oof_grid_clip_rgb(alpha_clip_list=(0.20,0.25,0.30), alpha_rgb_list=(0.10,0.15,0.20,0.25), gamma_list=(0.20,0.25), smooth_k=5, min_mult=0.7)\n",
        "print('Best (worst,mean,a_clip,a_rgb,g_aud)=', best, 'elapsed=', round(time.time()-t0,1),'s', flush=True)\n",
        "_,_,ac,ar,ga = best\n",
        "print(f'Decoding TEST with a_clip={ac}, a_rgb={ar}, g_aud={ga} ...', flush=True)\n",
        "out_csv = 'submission_clip_rgb_keep.csv'\n",
        "decode_test_clip_rgb(a_clip=ac, a_rgb=ar, g_aud=ga, smooth_k=5, min_mult=0.7, out_csv=out_csv)\n",
        "if os.path.exists(out_csv):\n",
        "    import shutil\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running OOF grid for CLIP+RGB+Audio (keep_len)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best (worst,mean,a_clip,a_rgb,g_aud)= (10, 3.86734693877551, 0.3, 0.1, 0.2) elapsed= 100.8 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST with a_clip=0.3, a_rgb=0.1, g_aud=0.2 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_rgb_keep.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_rgb_keep.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "e86c9a9f-c7b3-455d-b21b-722ab37f234d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Stage OOF-best CLIP+Audio keep_len submission\n",
        "import shutil, os\n",
        "src = 'submission_clip_poe_keep_best.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "shutil.copyfile(src, dst)\n",
        "print(f'Staged best CLIP+Audio keep_len submission: {src} -> {dst}')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged best CLIP+Audio keep_len submission: submission_clip_poe_keep_best.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "183e1d78-5ce7-4d29-8560-e26cd1326b4f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Retrain CLIP head with more epochs, then OOF grid (parity, keep_len) and decode test\n",
        "import time, shutil, os\n",
        "print('Retraining CLIP head (epochs=12)...', flush=True)\n",
        "t0=time.time()\n",
        "train_clip_head_and_cache(epochs=12, bs_frames=2048, lr=2e-3, wd=0.05)\n",
        "print(f'CLIP head retrain done in {time.time()-t0:.1f}s', flush=True)\n",
        "print('OOF grid (parity, keep_len) after retrain...', flush=True)\n",
        "best = oof_grid_clip(alpha_list=(0.30,0.35,0.40,0.45,0.50), gamma_list=(0.15,0.20,0.25,0.30), smooth_k=5, min_mult=0.7, keep_len=True)\n",
        "print('Best (worst, mean, alpha_clip, gamma_audio)=', best, flush=True)\n",
        "_,_,alpha_clip,gamma_audio = best\n",
        "print(f'Decoding TEST keep_len with alpha_clip={alpha_clip}, gamma_audio={gamma_audio} ...', flush=True)\n",
        "out_csv = 'submission_clip_poe_retrained.csv'\n",
        "decode_test_clip(alpha_clip=alpha_clip, gamma_audio=gamma_audio, smooth_k=5, min_mult=0.7, out_csv=out_csv, keep_len=True)\n",
        "if os.path.exists(out_csv):\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "else:\n",
        "    print('ERROR: expected output file missing', flush=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retraining CLIP head (epochs=12)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=1/12 loss=3.0333 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=2/12 loss=2.9702 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=3/12 loss=2.9323 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=4/12 loss=2.9037 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=5/12 loss=2.8803 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=6/12 loss=2.8598 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_114161/2600357026.py:87: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=7/12 loss=2.8410 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=8/12 loss=2.8236 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=9/12 loss=2.8072 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=10/12 loss=2.7916 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=11/12 loss=2.7770 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=12/12 loss=2.7631 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=1/12 loss=3.0161 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=2/12 loss=2.9321 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=3/12 loss=2.8837 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=4/12 loss=2.8508 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=5/12 loss=2.8257 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=6/12 loss=2.8045 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=7/12 loss=2.7853 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=8/12 loss=2.7675 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=9/12 loss=2.7509 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=10/12 loss=2.7352 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=11/12 loss=2.7203 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=12/12 loss=2.7062 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=1/12 loss=2.9398 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=2/12 loss=2.7423 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=3/12 loss=2.6477 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=4/12 loss=2.6143 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=5/12 loss=2.5953 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=6/12 loss=2.5774 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=7/12 loss=2.5600 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=8/12 loss=2.5433 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=9/12 loss=2.5272 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=10/12 loss=2.5118 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=11/12 loss=2.4969 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=12/12 loss=2.4826 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP head training + caching complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP head retrain done in 2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF grid (parity, keep_len) after retrain...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best (worst, mean, alpha_clip, gamma_audio)= (10, 3.836734693877551, 0.35, 0.15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST keep_len with alpha_clip=0.35, gamma_audio=0.15 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_poe_retrained.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_poe_retrained.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "449ca47a-2953-42a6-ba59-8803a8386e7e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Re-extract TEST CLIP with longer cap (max_frames=1024), retrain head, re-decode keep_len with OOF-best weights\n",
        "import time, os, shutil\n",
        "print('Re-extracting TEST CLIP embeddings with max_frames=1024...', flush=True)\n",
        "t0=time.time()\n",
        "extract_split('test', max_frames=1024)\n",
        "print(f'Test CLIP re-extract done in {time.time()-t0:.1f}s', flush=True)\n",
        "print('Retraining CLIP head (epochs=6) and caching per-fold TEST probs...', flush=True)\n",
        "t1=time.time()\n",
        "train_clip_head_and_cache(epochs=6, bs_frames=2048, lr=2e-3, wd=0.05)\n",
        "print(f'Head retrain+cache done in {time.time()-t1:.1f}s', flush=True)\n",
        "alpha_clip = 0.30; gamma_audio = 0.20\n",
        "out_csv = 'submission_clip_poe_keep_1024.csv'\n",
        "print(f'Decoding TEST keep_len with alpha_clip={alpha_clip}, gamma_audio={gamma_audio} (using 1024-frame CLIP)...', flush=True)\n",
        "decode_test_clip(alpha_clip=alpha_clip, gamma_audio=gamma_audio, smooth_k=5, min_mult=0.7, out_csv=out_csv, keep_len=True)\n",
        "if os.path.exists(out_csv):\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "else:\n",
        "    print('ERROR: expected output file missing', flush=True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-extracting TEST CLIP embeddings with max_frames=1024...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test finished; new saved = 0 elapsed= 0.0 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CLIP re-extract done in 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retraining CLIP head (epochs=6) and caching per-fold TEST probs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=1/6 loss=3.0273 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=2/6 loss=2.9659 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=3/6 loss=2.9292 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=4/6 loss=2.9013 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=5/6 loss=2.8783 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=0 ep=6/6 loss=2.8580 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_114161/2600357026.py:87: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=1/6 loss=3.0192 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=2/6 loss=2.9350 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=3/6 loss=2.8864 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=4/6 loss=2.8532 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=5/6 loss=2.8279 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=1 ep=6/6 loss=2.8064 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=1/6 loss=2.9378 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=2/6 loss=2.7417 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=3/6 loss=2.6483 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=4/6 loss=2.6152 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=5/6 loss=2.5960 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold=2 ep=6/6 loss=2.5780 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLIP head training + caching complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Head retrain+cache done in 1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST keep_len with alpha_clip=0.3, gamma_audio=0.2 (using 1024-frame CLIP)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_poe_keep_1024.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_poe_keep_1024.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "8c9ead41-9d0a-4706-9f5e-6ea691956d35",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Refined OOF grid (keep_len, temp parity) around best; decode test and stage\n",
        "import time, os, shutil\n",
        "def oof_grid_clip_refined(alpha_list=(0.28,0.30,0.32,0.34), gamma_list=(0.18,0.20,0.22,0.24), smooth_k=5, min_mult=0.7, keep_len=True):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    results=[]\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med = compute_min_dur_from_ids(tr); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "        fidx = int(fd['fold'])\n",
        "        Tclip = _load_temp_num(f'clip_temp_fold{fidx}.json')\n",
        "        Taud  = _load_temp_num(f'audio_temp_fold{fidx}.json')\n",
        "        for a in alpha_list:\n",
        "            for g in gamma_list:\n",
        "                d=[]\n",
        "                for sid in va:\n",
        "                    sid=int(sid)\n",
        "                    ps = load_skeleton_probs(sid)\n",
        "                    pc = load_clip_probs_train(sid)\n",
        "                    pa = load_probs_generic(sid, 'audio')\n",
        "                    if pc is not None and Tclip is not None: pc = temp_scale_scalar(pc, Tclip)\n",
        "                    if pa is not None and Taud  is not None: pa = temp_scale_scalar(pa,  Taud)\n",
        "                    if keep_len:\n",
        "                        pf = fuse_poe_with_clip_keep_len(ps, pc, pa, a, g)\n",
        "                    else:\n",
        "                        pf = fuse_poe_with_clip(ps, pc, pa, a, g)\n",
        "                    pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                    y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                    seq = compress_to_sequence(y); true = compress_to_sequence(np.load(LABELS/f\"{sid}.npy\"))\n",
        "                    n=len(seq); m=len(true);\n",
        "                    if n==0: d.append(m); continue\n",
        "                    dp=list(range(m+1))\n",
        "                    for i in range(1,n+1):\n",
        "                        prev=dp[0]; dp[0]=i\n",
        "                        for j in range(1,m+1):\n",
        "                            tmp=dp[j]; cost=0 if seq[i-1]==true[j-1] else 1\n",
        "                            dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "                    d.append(dp[m])\n",
        "                results.append((max(d), float(np.mean(d)), a, g))\n",
        "    results.sort(key=lambda x: (x[0], x[1]))\n",
        "    return results[0]\n",
        "\n",
        "print('Refined OOF grid (keep_len, parity)...', flush=True)\n",
        "t0=time.time()\n",
        "best = oof_grid_clip_refined(alpha_list=(0.28,0.30,0.32,0.34), gamma_list=(0.18,0.20,0.22,0.24), smooth_k=5, min_mult=0.7, keep_len=True)\n",
        "print('Best (worst, mean, alpha_clip, gamma_audio)=', best, 'elapsed=', round(time.time()-t0,1),'s', flush=True)\n",
        "_,_,alpha_clip,gamma_audio = best\n",
        "print(f'Decoding TEST keep_len with alpha_clip={alpha_clip}, gamma_audio={gamma_audio} ...', flush=True)\n",
        "out_csv = 'submission_clip_poe_keep_refined.csv'\n",
        "decode_test_clip(alpha_clip=alpha_clip, gamma_audio=gamma_audio, smooth_k=5, min_mult=0.7, out_csv=out_csv, keep_len=True)\n",
        "if os.path.exists(out_csv):\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "else:\n",
        "    print('ERROR: expected output file missing', flush=True)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refined OOF grid (keep_len, parity)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best (worst, mean, alpha_clip, gamma_audio)= (10, 3.836734693877551, 0.3, 0.18) elapsed= 54.2 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST keep_len with alpha_clip=0.3, gamma_audio=0.18 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_poe_keep_refined.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_poe_keep_refined.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "c969b4e4-7caa-4e65-84ad-0ac0e9e45d97",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test-time Best-of-N for CLIP+Audio keep_len PoE using emission log-likelihood; stages submission\n",
        "import numpy as np, pandas as pd, time, os, shutil, json\n",
        "\n",
        "def total_emission_loglik(y: np.ndarray, p: np.ndarray) -> float:\n",
        "    C,T = p.shape\n",
        "    idx = np.clip(y, 0, C-1).astype(np.int32)\n",
        "    cols = np.arange(T, dtype=np.int32)\n",
        "    probs = np.clip(p[idx, cols], 1e-12, 1.0)\n",
        "    return float(np.log(probs).sum())\n",
        "\n",
        "def build_pf_clip_audio_keep_len(sid: int, a_clip: float, g_aud: float, smooth_k=5, min_mult=0.7):\n",
        "    # durations from all train for decoding outside\n",
        "    return None  # not used; we directly build pf in the loop\n",
        "\n",
        "def decode_test_clip_bestofN_keep_len(out_csv='submission_clip_poe_keep_bestofN.csv',\n",
        "                                      alpha_list=(0.28,0.30,0.32,0.34), gamma_list=(0.18,0.20,0.22,0.24),\n",
        "                                      smooth_k=5, min_mult=0.7):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    # average audio temperature over folds\n",
        "    Ta_list = [_load_temp_num(f'audio_temp_fold{f}.json') for f in (0,1,2)]\n",
        "    Ta_vals = [t for t in Ta_list if t is not None]\n",
        "    Ta_mean = float(np.mean(Ta_vals)) if len(Ta_vals)>0 else None\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pc = load_clip_probs_test_avg(sid)  # per-fold temp already applied\n",
        "        pa = load_probs_generic(sid, 'audio')\n",
        "        if pa is not None and Ta_mean is not None:\n",
        "            pa = temp_scale_scalar(pa, Ta_mean)\n",
        "        best_ll = -1e99; best_seq=None\n",
        "        for ac in alpha_list:\n",
        "            for ga in gamma_list:\n",
        "                pf = fuse_poe_with_clip_keep_len(ps, pc, pa, ac, ga)\n",
        "                pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                ll = total_emission_loglik(y, pf)\n",
        "                if ll > best_ll:\n",
        "                    best_ll = ll\n",
        "                    seq = make_perm20(compress_to_sequence(y), pf)\n",
        "                    best_seq = seq\n",
        "        ids.append(sid); rows.append(' '.join(map(str, best_seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "\n",
        "print('Decoding TEST: Best-of-N over (alpha_clip, gamma_audio) for CLIP+Audio keep_len...', flush=True)\n",
        "decode_test_clip_bestofN_keep_len(out_csv='submission_clip_poe_keep_bestofN.csv',\n",
        "                                  alpha_list=(0.28,0.30,0.32,0.34), gamma_list=(0.18,0.20,0.22,0.24),\n",
        "                                  smooth_k=5, min_mult=0.7)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST: Best-of-N over (alpha_clip, gamma_audio) for CLIP+Audio keep_len...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=4.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=5.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=6.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_poe_keep_bestofN.csv rows= 95\nStaged submission: submission_clip_poe_keep_bestofN.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "441c1707-2ece-4f4f-8f68-af0183991fe4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CLIP features for Depth and User: extract -> train heads -> OOF grid (alpha_clip_total,gamma_audio) -> test decode keep_len\n",
        "import os, time, json, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Reuse model/tx/encode_video from Cell 18 (already executed).\n",
        "assert 'model' in globals(), 'CLIP model not initialized; run Cell 18 first.'\n",
        "assert 'tx' in globals(), 'CLIP transforms not initialized; run Cell 18 first.'\n",
        "\n",
        "# Dirs\n",
        "VID_DIR_DEPTH_T = Path('rgb_videos_depth/train'); VID_DIR_DEPTH_E = Path('rgb_videos_depth/test')\n",
        "VID_DIR_USER_T  = Path('rgb_videos_user/train');  VID_DIR_USER_E  = Path('rgb_videos_user/test')\n",
        "EMB_DEPTH = Path('rgb_clip_embed_depth'); (EMB_DEPTH/'train').mkdir(parents=True, exist_ok=True); (EMB_DEPTH/'test').mkdir(parents=True, exist_ok=True)\n",
        "EMB_USER  = Path('rgb_clip_embed_user');  (EMB_USER/'train').mkdir(parents=True, exist_ok=True);  (EMB_USER/'test').mkdir(parents=True, exist_ok=True)\n",
        "PROBS = Path('probs_cache'); PROBS.mkdir(exist_ok=True)\n",
        "\n",
        "def id_to_video_generic(dirpath: Path, sid: int):\n",
        "    cands = list(dirpath.glob(f'{sid}.mp4'))\n",
        "    if cands: return cands[0]\n",
        "    cands = list(dirpath.glob(f'*{sid}*.mp4'))\n",
        "    return cands[0] if cands else None\n",
        "\n",
        "def extract_split_generic(split='train', max_frames=512, which='depth'):\n",
        "    out_dir = (EMB_DEPTH if which=='depth' else EMB_USER)/split\n",
        "    vid_dir = (VID_DIR_DEPTH_T if split=='train' else VID_DIR_DEPTH_E) if which=='depth' else (VID_DIR_USER_T if split=='train' else VID_DIR_USER_E)\n",
        "    csv_path = 'training.csv' if split=='train' else 'test.csv'\n",
        "    ids = pd.read_csv(csv_path)['Id'].astype(int).tolist()\n",
        "    done=0; t0=time.time()\n",
        "    for k,sid in enumerate(ids, 1):\n",
        "        out = out_dir/f\"{sid}.npy\"\n",
        "        if out.exists():\n",
        "            continue\n",
        "        vp = id_to_video_generic(vid_dir, sid)\n",
        "        if vp is None:\n",
        "            continue\n",
        "        try:\n",
        "            E = encode_video(vp, max_frames=max_frames, bs=128)\n",
        "            np.save(out, E)\n",
        "        except Exception as e:\n",
        "            print('FAIL', which, split, sid, e, flush=True)\n",
        "        done+=1\n",
        "        if (done%20)==0:\n",
        "            print(f\"{which}/{split}: saved {done} in {time.time()-t0:.1f}s (last id={sid})\", flush=True)\n",
        "    print(which, split, 'finished; new saved =', done, 'elapsed=', round(time.time()-t0,1), 's', flush=True)\n",
        "\n",
        "# Train linear head for a given embed root; cache OOF and per-fold TEST (temp-scaled) probs\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "LABELS = Path('labels3d_v2/train')\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class SeqDatasetEmbed(Dataset):\n",
        "    def __init__(self, ids, emb_root: Path):\n",
        "        self.items=[]; self.emb_root=emb_root\n",
        "        for sid in ids:\n",
        "            p = (emb_root/'train'/f\"{int(sid)}.npy\")\n",
        "            if not p.exists(): continue\n",
        "            E = np.load(p)\n",
        "            y = np.load(LABELS/f\"{int(sid)}.npy\").astype(np.int64)\n",
        "            if len(y)!=E.shape[0]:\n",
        "                idx = np.linspace(0, len(y)-1, E.shape[0]).round().astype(int)\n",
        "                y = y[idx]\n",
        "            self.items.append((int(sid), E.astype(np.float32), y))\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self, i):\n",
        "        sid,E,y = self.items[i]\n",
        "        return sid, torch.from_numpy(E), torch.from_numpy(y)\n",
        "\n",
        "class LinearHead(nn.Module):\n",
        "    def __init__(self): super().__init__(); self.fc = nn.Linear(512, 21)\n",
        "    def forward(self, x): return self.fc(x)\n",
        "\n",
        "@torch.no_grad()\n",
        "def forward_logits_all(head, E_np: np.ndarray, bs: int = 4096):\n",
        "    xb = torch.from_numpy(E_np.astype(np.float32)).to(device)\n",
        "    outs=[]\n",
        "    for i in range(0, xb.size(0), bs):\n",
        "        outs.append(head(xb[i:i+bs]).float().cpu())\n",
        "    return torch.cat(outs,0).numpy().astype(np.float32)\n",
        "\n",
        "def fit_temperature_on_val(head, val_items):\n",
        "    Xs=[]; Ys=[]\n",
        "    with torch.no_grad():\n",
        "        for sid,E,y in val_items:\n",
        "            xb = torch.from_numpy(E.astype(np.float32)).to(device)\n",
        "            outs=[]\n",
        "            for i in range(0, xb.size(0), 4096):\n",
        "                outs.append(head(xb[i:i+4096]).float())\n",
        "            lg = torch.cat(outs,0); Xs.append(lg.cpu()); Ys.append(torch.from_numpy(y))\n",
        "    X = torch.cat(Xs,0).to(device); Y = torch.cat(Ys,0).to(device)\n",
        "    Tsc = torch.tensor(1.5, device=device, requires_grad=True)\n",
        "    opt = torch.optim.LBFGS([Tsc], lr=0.01, max_iter=50)\n",
        "    def closure():\n",
        "        opt.zero_grad(); loss = F.cross_entropy(X / Tsc, Y, reduction='mean'); loss.backward(); return loss\n",
        "    opt.step(closure)\n",
        "    return float(Tsc.detach().cpu().item())\n",
        "\n",
        "def train_clip_head_and_cache_for_embed(emb_root: Path, suffix: str, temp_prefix: str, epochs=3, bs_frames=2048, lr=2e-3, wd=0.05):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "    for fd in folds:\n",
        "        fidx = int(fd['fold'])\n",
        "        tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "        ds_tr = SeqDatasetEmbed(tr_ids, emb_root); ds_va = SeqDatasetEmbed(va_ids, emb_root)\n",
        "        if len(ds_tr)==0 or len(ds_va)==0: continue\n",
        "        Xtr = np.concatenate([E for _,E,_ in ds_tr.items], axis=0)\n",
        "        Ytr = np.concatenate([y for *_,y in ds_tr.items], axis=0)\n",
        "        chunks = [(Xtr[i:i+bs_frames], Ytr[i:i+bs_frames]) for i in range(0, Xtr.shape[0], bs_frames)]\n",
        "        head = LinearHead().to(device)\n",
        "        opt = torch.optim.AdamW(head.parameters(), lr=lr, weight_decay=wd)\n",
        "        scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
        "        t0=time.time(); head.train()\n",
        "        for ep in range(epochs):\n",
        "            loss_sum=0.0; nb=0\n",
        "            for xb_np,yb_np in chunks:\n",
        "                xb = torch.from_numpy(xb_np).to(device); yb = torch.from_numpy(yb_np).to(device)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
        "                    lg = head(xb); loss = F.cross_entropy(lg, yb, label_smoothing=0.05)\n",
        "                scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "                loss_sum += float(loss.detach().cpu().item()); nb+=1\n",
        "            print(f\"{suffix} fold={fidx} ep={ep+1}/{epochs} loss={loss_sum/max(nb,1):.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "        head.eval()\n",
        "        with torch.no_grad():\n",
        "            for sid,E,y in ds_va.items:\n",
        "                lg = forward_logits_all(head, E, bs=4096)  # (T,21)\n",
        "                p = torch.softmax(torch.from_numpy(lg), dim=1).numpy().astype(np.float32).T  # CxT\n",
        "                np.save(PROBS/f\"{sid}_{suffix}.npy\", p)\n",
        "        Tval = fit_temperature_on_val(head, ds_va.items)\n",
        "        json.dump({'T': Tval}, open(f'{temp_prefix}_temp_fold{fidx}.json','w'))\n",
        "        with torch.no_grad():\n",
        "            for sid in test_ids:\n",
        "                pth = emb_root/'test'/f\"{sid}.npy\"\n",
        "                if not pth.exists(): continue\n",
        "                E = np.load(pth)\n",
        "                lg = forward_logits_all(head, E, bs=4096)\n",
        "                p = torch.softmax(torch.from_numpy(lg)/Tval, dim=1).numpy().astype(np.float32).T\n",
        "                np.save(PROBS/f\"{sid}_{suffix}_f{fidx}.npy\", p)\n",
        "    print(f'{suffix} head training + caching complete.', flush=True)\n",
        "\n",
        "# Loaders for new streams\n",
        "def _load_temp_num(path: str):\n",
        "    p = Path(path);\n",
        "    if not p.exists(): return None\n",
        "    try: return float(json.load(open(p,'r')).get('T', 1.0))\n",
        "    except Exception:\n",
        "        try: return float(open(p).read().strip())\n",
        "        except Exception: return None\n",
        "\n",
        "def load_clipd_probs_train(sid:int):\n",
        "    pth = PROBS/f\"{sid}_clipd.npy\"\n",
        "    return np.load(pth).astype(np.float32) if pth.exists() else None\n",
        "def load_clipu_probs_train(sid:int):\n",
        "    pth = PROBS/f\"{sid}_clipu.npy\"\n",
        "    return np.load(pth).astype(np.float32) if pth.exists() else None\n",
        "def load_clipd_probs_test_avg(sid:int):\n",
        "    arr=[]\n",
        "    for f in (0,1,2):\n",
        "        pth = PROBS/f\"{sid}_clipd_f{f}.npy\"\n",
        "        if pth.exists(): arr.append(np.load(pth).astype(np.float32))\n",
        "    if not arr: return None\n",
        "    L = min(a.shape[1] for a in arr)\n",
        "    q = np.mean([a[:, :L] for a in arr], axis=0); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    return q.astype(np.float32)\n",
        "def load_clipu_probs_test_avg(sid:int):\n",
        "    arr=[]\n",
        "    for f in (0,1,2):\n",
        "        pth = PROBS/f\"{sid}_clipu_f{f}.npy\"\n",
        "        if pth.exists(): arr.append(np.load(pth).astype(np.float32))\n",
        "    if not arr: return None\n",
        "    L = min(a.shape[1] for a in arr)\n",
        "    q = np.mean([a[:, :L] for a in arr], axis=0); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "# Visual averaging on skeleton timeline (keep_len) for multiple CLIP streams\n",
        "def _find_best_shift(p_src: np.ndarray, p_ref: np.ndarray, max_shift: int = 15):\n",
        "    hs = entropy(p_src); hr = entropy(p_ref)\n",
        "    best = (-1e9, 0)\n",
        "    for sh in range(-max_shift, max_shift+1):\n",
        "        if sh >= 0:\n",
        "            L = min(hs.shape[0] - sh, hr.shape[0])\n",
        "            if L < 16: continue\n",
        "            s = hs[sh:sh+L]; r = hr[:L]\n",
        "        else:\n",
        "            L = min(hs.shape[0], hr.shape[0] + sh)\n",
        "            if L < 16: continue\n",
        "            s = hs[:L]; r = hr[-sh:-sh+L]\n",
        "        corr = -1.0 if (s.std()<1e-8 or r.std()<1e-8) else float(np.corrcoef(s, r)[0,1])\n",
        "        if corr > best[0]: best = (corr, sh)\n",
        "    return best[1]\n",
        "\n",
        "def visual_avg_keep_len(ps: np.ndarray, streams: list[np.ndarray | None]) -> np.ndarray | None:\n",
        "    C,T = ps.shape\n",
        "    acc = np.zeros((C,T), dtype=np.float32); cnt = np.zeros(T, dtype=np.int32)\n",
        "    any_ok = False\n",
        "    for pv in streams:\n",
        "        if pv is None or pv.ndim!=2: continue\n",
        "        sh = _find_best_shift(pv, ps, max_shift=15)\n",
        "        if sh >= 0:\n",
        "            L = min(pv.shape[1]-sh, T); ref_start=0; src_start=sh\n",
        "        else:\n",
        "            L = min(pv.shape[1], T+sh); ref_start=-sh; src_start=0\n",
        "        if L >= 16:\n",
        "            acc[:, ref_start:ref_start+L] += pv[:, src_start:src_start+L].astype(np.float32)\n",
        "            cnt[ref_start:ref_start+L] += 1\n",
        "            any_ok = True\n",
        "    if not any_ok: return None\n",
        "    mask = cnt>0\n",
        "    v = np.zeros((C,T), dtype=np.float32)\n",
        "    v[:, mask] = acc[:, mask] / np.maximum(cnt[mask][None,:], 1)\n",
        "    # normalize columns where mask True\n",
        "    colsum = v.sum(axis=0, keepdims=True); colsum[:, ~mask] = 1.0\n",
        "    v = v / np.clip(colsum, 1e-8, 1e8)\n",
        "    return v.astype(np.float32)\n",
        "\n",
        "# Keep-len fusion with single visual averaged stream + audio\n",
        "def fuse_keep_len_skel_vis_audio(ps: np.ndarray, pvis: np.ndarray | None, pa: np.ndarray | None, alpha_vis_total: float, gamma_audio: float) -> np.ndarray:\n",
        "    C,T = ps.shape\n",
        "    logp = np.log(np.clip(ps, 1e-8, 1.0)).astype(np.float32)\n",
        "    w_s = np.ones(T, dtype=np.float32)\n",
        "    if pvis is not None:\n",
        "        mask_v = (pvis.sum(axis=0) > 0)\n",
        "        logp[:, mask_v] += alpha_vis_total * np.log(np.clip(pvis[:, mask_v], 1e-8, 1.0))\n",
        "        w_s[mask_v] -= alpha_vis_total\n",
        "    if pa is not None:\n",
        "        sh = _find_best_shift(pa, ps, max_shift=15)\n",
        "        if sh >= 0:\n",
        "            L = min(pa.shape[1]-sh, T); ref_start=0; src_start=sh\n",
        "        else:\n",
        "            L = min(pa.shape[1], T+sh); ref_start=-sh; src_start=0\n",
        "        if L >= 16:\n",
        "            logp[:, ref_start:ref_start+L] += gamma_audio * np.log(np.clip(pa[:, src_start:src_start+L], 1e-8, 1.0))\n",
        "            w_s[ref_start:ref_start+L] -= gamma_audio\n",
        "    w_s = np.clip(w_s, 0.0, 1.0)[None, :]\n",
        "    logp = w_s * logp\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "# OOF grid over alpha_clip_total and gamma_audio with temp parity per stream; select by worst then mean\n",
        "def oof_grid_threeclip(alpha_list=(0.30,0.35,0.40,0.45,0.50), gamma_list=(0.15,0.20,0.25,0.30), smooth_k=5, min_mult=0.7):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    results=[]\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med = compute_min_dur_from_ids(tr); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "        fidx = int(fd['fold'])\n",
        "        Tr = _load_temp_num(f'clip_temp_fold{fidx}.json')\n",
        "        Td = _load_temp_num(f'clipd_temp_fold{fidx}.json')\n",
        "        Tu = _load_temp_num(f'clipu_temp_fold{fidx}.json')\n",
        "        Ta = _load_temp_num(f'audio_temp_fold{fidx}.json')\n",
        "        for a in alpha_list:\n",
        "            for g in gamma_list:\n",
        "                if a + g > 0.60: continue\n",
        "                d=[]\n",
        "                for sid in va:\n",
        "                    sid=int(sid)\n",
        "                    ps = load_skeleton_probs(sid)\n",
        "                    pr = load_clip_probs_train(sid)\n",
        "                    pdp = load_clipd_probs_train(sid)\n",
        "                    pu  = load_clipu_probs_train(sid)\n",
        "                    pa  = load_probs_generic(sid, 'audio')\n",
        "                    if pr is not None and Tr is not None: pr  = temp_scale_scalar(pr,  Tr)\n",
        "                    if pdp is not None and Td is not None: pdp = temp_scale_scalar(pdp, Td)\n",
        "                    if pu  is not None and Tu is not None: pu  = temp_scale_scalar(pu,  Tu)\n",
        "                    if pa  is not None and Ta is not None:  pa  = temp_scale_scalar(pa,  Ta)\n",
        "                    pvis = visual_avg_keep_len(ps, [pr, pdp, pu])\n",
        "                    pf = fuse_keep_len_skel_vis_audio(ps, pvis, pa, a, g)\n",
        "                    pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                    y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                    seq = compress_to_sequence(y); true = compress_to_sequence(np.load(LABELS/f\"{sid}.npy\"))\n",
        "                    n=len(seq); m=len(true);\n",
        "                    if n==0: d.append(m); continue\n",
        "                    dp=list(range(m+1))\n",
        "                    for i in range(1,n+1):\n",
        "                        prev=dp[0]; dp[0]=i\n",
        "                        for j in range(1,m+1):\n",
        "                            tmp=dp[j]; cost=0 if seq[i-1]==true[j-1] else 1\n",
        "                            dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "                    d.append(dp[m])\n",
        "                if d: results.append((max(d), float(np.mean(d)), a, g))\n",
        "    results.sort(key=lambda x: (x[0], x[1]))\n",
        "    return results[0] if results else None\n",
        "\n",
        "def decode_test_threeclip(alpha_clip_total=0.40, gamma_audio=0.20, smooth_k=5, min_mult=0.7, out_csv='submission_clip3_poe_keep.csv'):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    # audio mean temp\n",
        "    Ta_list = [_load_temp_num(f'audio_temp_fold{f}.json') for f in (0,1,2)]\n",
        "    Ta_vals = [t for t in Ta_list if t is not None]\n",
        "    Ta_mean = float(np.mean(Ta_vals)) if len(Ta_vals)>0 else None\n",
        "    ids,rows=[],[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pr = load_clip_probs_test_avg(sid)\n",
        "        pdp = load_clipd_probs_test_avg(sid)\n",
        "        pu  = load_clipu_probs_test_avg(sid)\n",
        "        pa  = load_probs_generic(sid, 'audio')\n",
        "        if pa is not None and Ta_mean is not None: pa = temp_scale_scalar(pa, Ta_mean)\n",
        "        pvis = visual_avg_keep_len(ps, [pr, pdp, pu])\n",
        "        pf = fuse_keep_len_skel_vis_audio(ps, pvis, pa, alpha_clip_total, gamma_audio)\n",
        "        pf = smooth_probs_box(pf, k=smooth_k)\n",
        "        y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "        seq = make_perm20(compress_to_sequence(y), pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95', flush=True)\n",
        "    pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id').to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, flush=True)\n",
        "\n",
        "print('Extracting CLIP embeddings for Depth and User (train then test)...', flush=True)\n",
        "extract_split_generic('train', max_frames=512, which='depth')\n",
        "extract_split_generic('test',  max_frames=512, which='depth')\n",
        "extract_split_generic('train', max_frames=512, which='user')\n",
        "extract_split_generic('test',  max_frames=512, which='user')\n",
        "print('Training linear heads for Depth(User) CLIP...', flush=True)\n",
        "train_clip_head_and_cache_for_embed(EMB_DEPTH, suffix='clipd', temp_prefix='clipd', epochs=3, bs_frames=2048, lr=2e-3, wd=0.05)\n",
        "train_clip_head_and_cache_for_embed(EMB_USER,  suffix='clipu', temp_prefix='clipu', epochs=3, bs_frames=2048, lr=2e-3, wd=0.05)\n",
        "print('OOF grid for three-CLIP fusion (keep_len, temp parity)...', flush=True)\n",
        "best = oof_grid_threeclip(alpha_list=(0.30,0.35,0.40,0.45,0.50), gamma_list=(0.15,0.20,0.25,0.30), smooth_k=5, min_mult=0.7)\n",
        "print('Best (worst, mean, alpha_clip_total, gamma_audio)=', best, flush=True)\n",
        "if best is not None:\n",
        "    _,_,a_best,g_best = best\n",
        "    print(f'Decoding TEST with alpha_clip_total={a_best}, gamma_audio={g_best} ...', flush=True)\n",
        "    decode_test_threeclip(alpha_clip_total=a_best, gamma_audio=g_best, smooth_k=5, min_mult=0.7, out_csv='submission_clip3_poe_keep.csv')\n",
        "    import shutil, os\n",
        "    if os.path.exists('submission_clip3_poe_keep.csv'):\n",
        "        shutil.copyfile('submission_clip3_poe_keep.csv', 'submission.csv')\n",
        "        print('Staged submission: submission_clip3_poe_keep.csv -> submission.csv', flush=True)\n",
        "else:\n",
        "    print('No best found; skipping test decode.', flush=True)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting CLIP embeddings for Depth and User (train then test)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 20 in 25.3s (last id=21)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 40 in 52.0s (last id=41)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 60 in 85.4s (last id=61)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 80 in 116.2s (last id=81)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 100 in 139.5s (last id=102)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 120 in 162.6s (last id=122)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 140 in 186.4s (last id=142)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 160 in 208.9s (last id=162)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 180 in 231.6s (last id=182)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 200 in 254.5s (last id=202)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 220 in 277.2s (last id=222)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 240 in 302.0s (last id=242)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 260 in 325.6s (last id=262)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/train: saved 280 in 349.5s (last id=282)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth train finished; new saved = 297 elapsed= 368.9 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/test: saved 20 in 23.5s (last id=319)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/test: saved 40 in 49.5s (last id=340)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/test: saved 60 in 73.7s (last id=362)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth/test: saved 80 in 98.4s (last id=383)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "depth test finished; new saved = 92 elapsed= 112.6 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 20 in 23.2s (last id=21)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 40 in 48.1s (last id=41)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 60 in 78.4s (last id=61)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 80 in 106.7s (last id=81)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 100 in 129.9s (last id=102)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 120 in 153.5s (last id=122)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 140 in 177.1s (last id=142)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 160 in 199.4s (last id=162)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 180 in 222.0s (last id=182)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 200 in 244.9s (last id=202)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 220 in 268.0s (last id=222)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 240 in 291.8s (last id=242)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 260 in 315.2s (last id=262)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/train: saved 280 in 338.6s (last id=282)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user train finished; new saved = 297 elapsed= 357.5 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/test: saved 20 in 23.2s (last id=319)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/test: saved 40 in 48.9s (last id=340)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/test: saved 60 in 72.3s (last id=362)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user/test: saved 80 in 97.1s (last id=383)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user test finished; new saved = 92 elapsed= 111.5 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training linear heads for Depth(User) CLIP...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipd fold=0 ep=1/3 loss=3.0267 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipd fold=0 ep=2/3 loss=2.9690 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipd fold=0 ep=3/3 loss=2.9393 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_114161/2808803653.py:110: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipd fold=1 ep=1/3 loss=3.0168 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipd fold=1 ep=2/3 loss=2.9361 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipd fold=1 ep=3/3 loss=2.8959 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipd fold=2 ep=1/3 loss=2.9160 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipd fold=2 ep=2/3 loss=2.7133 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipd fold=2 ep=3/3 loss=2.6375 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipd head training + caching complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipu fold=0 ep=1/3 loss=3.0197 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipu fold=0 ep=2/3 loss=2.9571 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipu fold=0 ep=3/3 loss=2.9267 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_114161/2808803653.py:110: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipu fold=1 ep=1/3 loss=3.0157 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipu fold=1 ep=2/3 loss=2.9297 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipu fold=1 ep=3/3 loss=2.8900 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipu fold=2 ep=1/3 loss=2.9129 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipu fold=2 ep=2/3 loss=2.6939 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipu fold=2 ep=3/3 loss=2.6211 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clipu head training + caching complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF grid for three-CLIP fusion (keep_len, temp parity)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best (worst, mean, alpha_clip_total, gamma_audio)= (10, 3.836734693877551, 0.35, 0.15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST with alpha_clip_total=0.35, gamma_audio=0.15 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip3_poe_keep.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip3_poe_keep.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "03b33773-aa4a-4f3b-bffd-f5c862c08daf",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test-time Best-of-N over alpha_clip_total, gamma_audio, and visual weight splits (RGB/Depth/User) with keep_len PoE\n",
        "import numpy as np, pandas as pd, time, os, shutil, json\n",
        "\n",
        "def weighted_visual_avg_keep_len(ps: np.ndarray, pr: np.ndarray | None, pdp: np.ndarray | None, pu: np.ndarray | None, w_rgb: float, w_dep: float, w_usr: float):\n",
        "    C,T = ps.shape\n",
        "    acc = np.zeros((C,T), dtype=np.float32); wsum = np.zeros(T, dtype=np.float32)\n",
        "    def add(pv, w):\n",
        "        nonlocal acc, wsum\n",
        "        if pv is None or w<=0: return\n",
        "        sh = _find_best_shift(pv, ps, max_shift=15)\n",
        "        if sh >= 0:\n",
        "            L = min(pv.shape[1]-sh, T); ref_start=0; src_start=sh\n",
        "        else:\n",
        "            L = min(pv.shape[1], T+sh); ref_start=-sh; src_start=0\n",
        "        if L >= 16:\n",
        "            acc[:, ref_start:ref_start+L] += w * pv[:, src_start:src_start+L].astype(np.float32)\n",
        "            wsum[ref_start:ref_start+L] += w\n",
        "    add(pr,  w_rgb)\n",
        "    add(pdp, w_dep)\n",
        "    add(pu,  w_usr)\n",
        "    mask = wsum > 0\n",
        "    if not mask.any():\n",
        "        return None\n",
        "    v = np.zeros((C,T), dtype=np.float32)\n",
        "    v[:, mask] = acc[:, mask] / np.maximum(wsum[mask][None, :], 1e-8)\n",
        "    colsum = v.sum(axis=0, keepdims=True); colsum[:, ~mask] = 1.0\n",
        "    v = v / np.clip(colsum, 1e-8, 1e8)\n",
        "    return v.astype(np.float32)\n",
        "\n",
        "def fuse_keep_len_skel_vis_audio(ps: np.ndarray, pvis: np.ndarray | None, pa: np.ndarray | None, alpha_vis_total: float, gamma_audio: float) -> np.ndarray:\n",
        "    C,T = ps.shape\n",
        "    logp = np.log(np.clip(ps, 1e-8, 1.0)).astype(np.float32)\n",
        "    w_s = np.ones(T, dtype=np.float32)\n",
        "    if pvis is not None:\n",
        "        mask_v = (pvis.sum(axis=0) > 0)\n",
        "        logp[:, mask_v] += alpha_vis_total * np.log(np.clip(pvis[:, mask_v], 1e-8, 1.0))\n",
        "        w_s[mask_v] -= alpha_vis_total\n",
        "    if pa is not None:\n",
        "        sh = _find_best_shift(pa, ps, max_shift=15)\n",
        "        if sh >= 0:\n",
        "            L = min(pa.shape[1]-sh, T); ref_start=0; src_start=sh\n",
        "        else:\n",
        "            L = min(pa.shape[1], T+sh); ref_start=-sh; src_start=0\n",
        "        if L >= 16:\n",
        "            logp[:, ref_start:ref_start+L] += gamma_audio * np.log(np.clip(pa[:, src_start:src_start+L], 1e-8, 1.0))\n",
        "            w_s[ref_start:ref_start+L] -= gamma_audio\n",
        "    w_s = np.clip(w_s, 0.0, 1.0)[None, :]\n",
        "    logp = w_s * logp\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def total_emission_loglik(y: np.ndarray, p: np.ndarray) -> float:\n",
        "    C,T = p.shape\n",
        "    idx = np.clip(y, 0, C-1).astype(np.int32)\n",
        "    cols = np.arange(T, dtype=np.int32)\n",
        "    probs = np.clip(p[idx, cols], 1e-12, 1.0)\n",
        "    return float(np.log(probs).sum())\n",
        "\n",
        "def decode_test_threeclip_bestofN(out_csv='submission_clip3_bestofN.csv',\n",
        "                                  alpha_tot_list=(0.35,0.40,0.45), gamma_list=(0.20,0.25),\n",
        "                                  splits=((0.60,0.25,0.15),(0.50,0.30,0.20),(0.70,0.20,0.10), None),\n",
        "                                  smooth_k=5, min_mult=0.7):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    # audio mean temp for test\n",
        "    Ta_list = [_load_temp_num(f'audio_temp_fold{f}.json') for f in (0,1,2)]\n",
        "    Ta_vals = [t for t in Ta_list if t is not None]\n",
        "    Ta_mean = float(np.mean(Ta_vals)) if len(Ta_vals)>0 else None\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pr = load_clip_probs_test_avg(sid)            # RGB CLIP (per-fold temp applied)\n",
        "        pdp = load_clipd_probs_test_avg(sid)          # Depth CLIP\n",
        "        pu  = load_clipu_probs_test_avg(sid)          # User CLIP\n",
        "        pa  = load_probs_generic(sid, 'audio')\n",
        "        if pa is not None and Ta_mean is not None:\n",
        "            pa = temp_scale_scalar(pa, Ta_mean)\n",
        "        best_ll=-1e99; best_seq=None\n",
        "        for a_tot in alpha_tot_list:\n",
        "            for ga in gamma_list:\n",
        "                if a_tot + ga > 0.60: continue\n",
        "                for sp in splits:\n",
        "                    if sp is None:\n",
        "                        # equal average using existing helper\n",
        "                        pvis = visual_avg_keep_len(ps, [pr, pdp, pu])\n",
        "                    else:\n",
        "                        wr,wd,wu = sp\n",
        "                        # scale weights to sum to 1 over available streams\n",
        "                        avail = [(pr,wr),(pdp,wd),(pu,wu)]\n",
        "                        s = sum(w for pv,w in avail if pv is not None)\n",
        "                        if s<=0: pvis=None\n",
        "                        else:\n",
        "                            wr2 = (wr/s) if pr  is not None else 0.0\n",
        "                            wd2 = (wd/s) if pdp is not None else 0.0\n",
        "                            wu2 = (wu/s) if pu  is not None else 0.0\n",
        "                            pvis = weighted_visual_avg_keep_len(ps, pr, pdp, pu, wr2, wd2, wu2)\n",
        "                    pf = fuse_keep_len_skel_vis_audio(ps, pvis, pa, a_tot, ga)\n",
        "                    pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                    y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                    ll = total_emission_loglik(y, pf)\n",
        "                    if ll > best_ll:\n",
        "                        best_ll = ll\n",
        "                        seq = make_perm20(compress_to_sequence(y), pf)\n",
        "                        best_seq = seq\n",
        "        ids.append(sid); rows.append(' '.join(map(str, best_seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "\n",
        "print('Decoding TEST Best-of-N over (alpha_clip_total, gamma_audio, visual splits)...', flush=True)\n",
        "decode_test_threeclip_bestofN(out_csv='submission_clip3_bestofN.csv',\n",
        "                               alpha_tot_list=(0.35,0.40,0.45), gamma_list=(0.20,0.25),\n",
        "                               splits=((0.60,0.25,0.15),(0.50,0.30,0.20),(0.70,0.20,0.10), None),\n",
        "                               smooth_k=5, min_mult=0.7)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST Best-of-N over (alpha_clip_total, gamma_audio, visual splits)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=5.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=6.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip3_bestofN.csv rows= 95\nStaged submission: submission_clip3_bestofN.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "48ebe057-7997-4fbe-b41e-e015a50d8a25",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# PANNs (CNN14) audio embeddings -> linear head -> OOF gamma grid -> test decode (keep_len PoE) and stage submission\n",
        "import sys, subprocess, os, time, json, numpy as np, pandas as pd, ssl, urllib.request\n",
        "from pathlib import Path\n",
        "\n",
        "# 0) Ensure PANNs labels CSV and checkpoint exist without using wget (apt is unavailable).\n",
        "PANN_DIR = '/app/panns_data'\n",
        "CKPT_PATH = f'{PANN_DIR}/Cnn14_mAP=0.431.pth'\n",
        "LABELS_CSV_URL = 'http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/class_labels_indices.csv'\n",
        "CKPT_URLS = [\n",
        "    'https://zenodo.org/record/3987831/files/Cnn14_mAP%3D0.431.pth?download=1',\n",
        "    'https://zenodo.org/record/3987831/files/Cnn14_mAP=0.431.pth?download=1'\n",
        "]\n",
        "\n",
        "def _urlretrieve(url, dst):\n",
        "    try:\n",
        "        ctx = ssl.create_default_context()\n",
        "        with urllib.request.urlopen(urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'}), context=ctx) as r, open(dst, 'wb') as f:\n",
        "            f.write(r.read())\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print('Download failed for', url, e, flush=True)\n",
        "        return False\n",
        "\n",
        "def ensure_panns_assets():\n",
        "    os.makedirs(PANN_DIR, exist_ok=True)\n",
        "    labels_csv = os.path.join(PANN_DIR, 'class_labels_indices.csv')\n",
        "    if not os.path.exists(labels_csv):\n",
        "        print('Downloading PANNs labels CSV...', flush=True)\n",
        "        ok = _urlretrieve(LABELS_CSV_URL, labels_csv)\n",
        "        if ok: print('Labels CSV ready at', labels_csv, flush=True)\n",
        "    if not os.path.exists(CKPT_PATH):\n",
        "        print('Downloading PANNs checkpoint to', CKPT_PATH, flush=True)\n",
        "        for url in CKPT_URLS:\n",
        "            if _urlretrieve(url, CKPT_PATH):\n",
        "                print('Checkpoint downloaded from', url, flush=True)\n",
        "                break\n",
        "        if not os.path.exists(CKPT_PATH):\n",
        "            raise RuntimeError('Failed to download PANNs checkpoint; cannot proceed.')\n",
        "\n",
        "ensure_panns_assets()\n",
        "\n",
        "# 1) Ensure deps\n",
        "def ensure_audio_pkgs():\n",
        "    try:\n",
        "        import panns_inference, librosa, torchlibrosa  # noqa\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print('Installing audio deps...', e, flush=True)\n",
        "    cmds = [\n",
        "        [sys.executable, '-m', 'pip', 'install', '-q', 'panns-inference', 'torchlibrosa', 'librosa==0.10.1']\n",
        "    ]\n",
        "    for cmd in cmds:\n",
        "        subprocess.run(cmd, check=True)\n",
        "    print('Audio deps installed.', flush=True)\n",
        "\n",
        "ensure_audio_pkgs()\n",
        "import librosa\n",
        "from panns_inference import AudioTagging\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "AUDIO_WAV_TR = Path('audio_wav/train'); AUDIO_WAV_TE = Path('audio_wav/test')\n",
        "LABELS = Path('labels3d_v2/train')\n",
        "\n",
        "# 1b) Create a single global AudioTagging instance (reuse across all files) to avoid repeated heavy init\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Creating global PANNs AudioTagging on', DEVICE, 'checkpoint:', CKPT_PATH, flush=True)\n",
        "AT_GLOBAL = AudioTagging(checkpoint_path=CKPT_PATH, device=DEVICE)\n",
        "\n",
        "# 2) Extract PANNs features on-demand and cache to audio_panns/{split}/{id}.npy\n",
        "FEAT_DIR = Path('audio_panns'); (FEAT_DIR/'train').mkdir(parents=True, exist_ok=True); (FEAT_DIR/'test').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def _to_527(F: np.ndarray) -> np.ndarray:\n",
        "    # ensure feature dim = 527 (AudioSet classes) by slicing/padding if needed\n",
        "    if F.ndim!=2: F = np.atleast_2d(F.astype(np.float32))\n",
        "    T,D = F.shape\n",
        "    if D == 527: return F.astype(np.float32)\n",
        "    if D > 527: return F[:, :527].astype(np.float32)\n",
        "    # pad\n",
        "    out = np.zeros((T, 527), dtype=np.float32); out[:, :D] = F.astype(np.float32); return out\n",
        "\n",
        "def _parse_at_output(out):\n",
        "    # panns_inference may return dict or tuple\n",
        "    try:\n",
        "        if isinstance(out, dict):\n",
        "            fw = out.get('framewise_output', None)\n",
        "            cw = out.get('clipwise_output', None)\n",
        "            return fw, cw\n",
        "        # tuple: try (clipwise, embedding, framewise) variants\n",
        "        if isinstance(out, tuple):\n",
        "            fw = None; cw = None\n",
        "            for elem in out:\n",
        "                arr = np.asarray(elem)\n",
        "                if arr.ndim>=1:\n",
        "                    if arr.shape[-1] == 527 and cw is None:\n",
        "                        cw = arr\n",
        "                    elif arr.shape[-1] != 527 and fw is None and arr.ndim==2:\n",
        "                        # some builds put framewise as time x 527; safeguard\n",
        "                        if arr.shape[-1] == 527: fw = arr\n",
        "            return fw, cw\n",
        "    except Exception:\n",
        "        return None, None\n",
        "    return None, None\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_panns_for_file(wav_path: Path, sr=32000, pool2=True) -> np.ndarray:\n",
        "    try:\n",
        "        y, sr_ = librosa.load(str(wav_path), sr=sr, mono=True)\n",
        "        if y.size == 0:\n",
        "            return np.zeros((1, 527), dtype=np.float32)\n",
        "        feats = []\n",
        "        seg_len = sr * 30\n",
        "        y = y.astype(np.float32)\n",
        "        for s in range(0, len(y), seg_len):\n",
        "            seg = y[s:s+seg_len]\n",
        "            if seg.size == 0: continue\n",
        "            seg_b = seg[None, :]  # (1, samples)\n",
        "            out = AT_GLOBAL.inference(seg_b)\n",
        "            fw, cw = _parse_at_output(out)\n",
        "            if fw is not None:\n",
        "                fw_np = np.asarray(fw, dtype=np.float32)\n",
        "                # If fw has batch, squeeze\n",
        "                if fw_np.ndim == 3: fw_np = fw_np.reshape(-1, fw_np.shape[-1])\n",
        "                # pool to ~5 Hz\n",
        "                if pool2 and fw_np.ndim==2 and fw_np.shape[0] > 1:\n",
        "                    Tm = (fw_np.shape[0]//2)*2\n",
        "                    if Tm >= 2:\n",
        "                        fw_np = fw_np[:Tm].reshape(Tm//2, 2, fw_np.shape[1]).mean(axis=1).astype(np.float32)\n",
        "                feats.append(_to_527(fw_np))\n",
        "            elif cw is not None:\n",
        "                cw_np = np.asarray(cw, dtype=np.float32)\n",
        "                if cw_np.ndim == 2: cw_np = cw_np[0]\n",
        "                feats.append(_to_527(cw_np[None, :]))\n",
        "        if not feats:\n",
        "            return np.zeros((1, 527), dtype=np.float32)\n",
        "        F = np.concatenate(feats, axis=0).astype(np.float32)\n",
        "        return _to_527(F)\n",
        "    except Exception as e:\n",
        "        print('PANNs FAIL on', wav_path, e, flush=True)\n",
        "        return np.zeros((1, 527), dtype=np.float32)\n",
        "\n",
        "def extract_split_panns(split='train'):\n",
        "    print(f'Skipping bulk PANNs extract for {split}; using on-the-fly extraction.', flush=True)\n",
        "\n",
        "print('Preparing PANNs (CNN14) assets and skipping bulk extraction...', flush=True)\n",
        "extract_split_panns('train')\n",
        "extract_split_panns('test')\n",
        "\n",
        "# 3) Train linear head (D->21) per fold on framewise PANNs features; cache OOF and per-fold TEST probs; save temps\n",
        "class PannsDataset(Dataset):\n",
        "    def __init__(self, ids):\n",
        "        self.items=[]\n",
        "        for sid in ids:\n",
        "            sid=int(sid)\n",
        "            p = FEAT_DIR/'train'/f'{sid}.npy'\n",
        "            if not p.exists():\n",
        "                wp = AUDIO_WAV_TR/f'{sid}.wav'\n",
        "                if wp.exists():\n",
        "                    X = extract_panns_for_file(wp)\n",
        "                    np.save(p, X.astype(np.float32))\n",
        "            if not p.exists():\n",
        "                continue\n",
        "            X = np.load(p).astype(np.float32)\n",
        "            X = _to_527(X)  # coerce feature dim to 527\n",
        "            y = np.load(LABELS/f\"{sid}.npy\").astype(np.int64)\n",
        "            if X.shape[0] != len(y):\n",
        "                idx = np.linspace(0, len(y)-1, X.shape[0]).round().astype(int)\n",
        "                y = y[idx]\n",
        "            self.items.append((sid, X, y))\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self, i):\n",
        "        sid,X,y = self.items[i]\n",
        "        return sid, torch.from_numpy(X), torch.from_numpy(y)\n",
        "\n",
        "class LinearHead(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(in_dim, 21)\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "@torch.no_grad()\n",
        "def forward_logits_all(head, X_np: np.ndarray, bs: int = 8192):\n",
        "    xb = torch.from_numpy(X_np.astype(np.float32)).to(DEVICE)\n",
        "    outs=[]\n",
        "    for i in range(0, xb.size(0), bs):\n",
        "        outs.append(head(xb[i:i+bs]).float().cpu())\n",
        "    return torch.cat(outs,0).numpy().astype(np.float32)\n",
        "\n",
        "def fit_temperature_on_val(head, val_items):\n",
        "    Xs=[]; Ys=[]\n",
        "    with torch.no_grad():\n",
        "        for sid,X,y in val_items:\n",
        "            xb = torch.from_numpy(X.astype(np.float32)).to(DEVICE)\n",
        "            outs=[]\n",
        "            for i in range(0, xb.size(0), 8192):\n",
        "                outs.append(head(xb[i:i+8192]).float())\n",
        "            lg = torch.cat(outs,0); Xs.append(lg.cpu()); Ys.append(torch.from_numpy(y))\n",
        "    X = torch.cat(Xs,0).to(DEVICE); Y = torch.cat(Ys,0).to(DEVICE)\n",
        "    Tsc = torch.tensor(1.5, device=DEVICE, requires_grad=True)\n",
        "    opt = torch.optim.LBFGS([Tsc], lr=0.01, max_iter=50)\n",
        "    def closure():\n",
        "        opt.zero_grad(); loss = F.cross_entropy(X / Tsc, Y, reduction='mean'); loss.backward(); return loss\n",
        "    opt.step(closure)\n",
        "    return float(Tsc.detach().cpu().item())\n",
        "\n",
        "def _uniform_cap_frames(X: np.ndarray, Y: np.ndarray, cap: int = 100_000):\n",
        "    n = X.shape[0]\n",
        "    if n <= cap: return X, Y\n",
        "    idx = np.linspace(0, n-1, cap).round().astype(int)\n",
        "    return X[idx], Y[idx]\n",
        "\n",
        "def train_panns_head_and_cache(folds_path='folds_archive_cv.json', epochs=1, lr=2e-3, wd=0.05):\n",
        "    folds = json.load(open(folds_path,'r'))\n",
        "    test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "    for fd in folds:\n",
        "        fidx = int(fd['fold'])\n",
        "        tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "        ds_tr = PannsDataset(tr_ids); ds_va = PannsDataset(va_ids)\n",
        "        if len(ds_tr)==0 or len(ds_va)==0:\n",
        "            print('Fold', fidx, 'no data; skipping.')\n",
        "            continue\n",
        "        Xtr = np.concatenate([X for _,X,_ in ds_tr.items], axis=0)\n",
        "        Ytr = np.concatenate([y for *_,y in ds_tr.items], axis=0)\n",
        "        Xtr, Ytr = _uniform_cap_frames(Xtr, Ytr, cap=100_000)\n",
        "        in_dim = Xtr.shape[1]\n",
        "        head = LinearHead(in_dim).to(DEVICE)\n",
        "        opt = torch.optim.AdamW(head.parameters(), lr=lr, weight_decay=wd)\n",
        "        scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE=='cuda'))\n",
        "        t0=time.time(); head.train()\n",
        "        for ep in range(epochs):\n",
        "            loss_sum=0.0; nb=0\n",
        "            for i in range(0, Xtr.shape[0], 8192):\n",
        "                xb = torch.from_numpy(Xtr[i:i+8192]).to(DEVICE)\n",
        "                yb = torch.from_numpy(Ytr[i:i+8192]).to(DEVICE)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(DEVICE=='cuda')):\n",
        "                    lg = head(xb); loss = F.cross_entropy(lg, yb, label_smoothing=0.05)\n",
        "                scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "                loss_sum += float(loss.detach().cpu().item()); nb+=1\n",
        "            print(f'panns fold={fidx} ep={ep+1}/{epochs} loss={loss_sum/max(nb,1):.4f} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "        head.eval()\n",
        "        with torch.no_grad():\n",
        "            for sid,X,y in ds_va.items:\n",
        "                lg = forward_logits_all(head, X, bs=8192)  # (T,21)\n",
        "                p = torch.softmax(torch.from_numpy(lg), dim=1).numpy().astype(np.float32).T  # CxT\n",
        "                np.save(probs_cache/f\"{sid}_audio_panns.npy\", p)\n",
        "        Tval = fit_temperature_on_val(head, ds_va.items)\n",
        "        json.dump({'T': Tval}, open(f'audio_panns_temp_fold{fidx}.json','w'))\n",
        "        with torch.no_grad():\n",
        "            for sid in test_ids:\n",
        "                sid=int(sid)\n",
        "                pth = FEAT_DIR/'test'/f\"{sid}.npy\"\n",
        "                if not pth.exists():\n",
        "                    wp = AUDIO_WAV_TE/f'{sid}.wav'\n",
        "                    if wp.exists():\n",
        "                        X = extract_panns_for_file(wp)\n",
        "                        np.save(pth, X.astype(np.float32))\n",
        "                if not pth.exists():\n",
        "                    continue\n",
        "                X = _to_527(np.load(pth).astype(np.float32))\n",
        "                lg = forward_logits_all(head, X, bs=8192)\n",
        "                p = torch.softmax(torch.from_numpy(lg)/Tval, dim=1).numpy().astype(np.float32).T\n",
        "                np.save(probs_cache/f\"{sid}_audio_panns_f{fidx}.npy\", p)\n",
        "    print('PANNs head training + caching complete.', flush=True)\n",
        "\n",
        "print('Training PANNs linear head (fast: epochs=1)...', flush=True)\n",
        "train_panns_head_and_cache(epochs=1, lr=2e-3, wd=0.05)\n",
        "\n",
        "# 4) Fuse with skeleton + CLIP(RGB) using keep_len PoE; OOF gamma grid (alpha fixed 0.30) -> pick by worst then mean\n",
        "def _load_temp_num(path: str):\n",
        "    p = Path(path);\n",
        "    if not p.exists(): return None\n",
        "    try: return float(json.load(open(p,'r')).get('T', 1.0))\n",
        "    except Exception:\n",
        "        try: return float(open(p).read().strip())\n",
        "        except Exception: return None\n",
        "\n",
        "def load_audio_panns_train(sid:int):\n",
        "    pth = probs_cache/f\"{sid}_audio_panns.npy\"\n",
        "    return np.load(pth).astype(np.float32) if pth.exists() else None\n",
        "\n",
        "def load_audio_panns_test_avg(sid:int):\n",
        "    arr=[]\n",
        "    for f in (0,1,2):\n",
        "        pth = probs_cache/f\"{sid}_audio_panns_f{f}.npy\"\n",
        "        if pth.exists(): arr.append(np.load(pth).astype(np.float32))\n",
        "    if not arr: return None\n",
        "    L = min(a.shape[1] for a in arr)\n",
        "    q = np.mean([a[:, :L] for a in arr], axis=0); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def oof_grid_gamma_panns(alpha_clip_fixed=0.30, gamma_list=(0.18,0.20,0.22,0.25), smooth_k=5, min_mult=0.7):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    results=[]\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med = compute_min_dur_from_ids(tr); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "        fidx = int(fd['fold'])\n",
        "        Tclip = _load_temp_num(f'clip_temp_fold{fidx}.json')\n",
        "        for g in gamma_list:\n",
        "            d=[]\n",
        "            for sid in va:\n",
        "                sid=int(sid)\n",
        "                ps = load_skeleton_probs(sid)\n",
        "                pc = load_clip_probs_train(sid)\n",
        "                pa = load_audio_panns_train(sid)\n",
        "                if pc is not None and Tclip is not None: pc = temp_scale_scalar(pc, Tclip)\n",
        "                if pa is None:\n",
        "                    pa = load_probs_generic(sid, 'audio')\n",
        "                pf = fuse_poe_with_clip_keep_len(ps, pc, pa, alpha_clip_fixed, g)\n",
        "                pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                seq = compress_to_sequence(y); true = compress_to_sequence(np.load(LABELS/f\"{sid}.npy\"))\n",
        "                n=len(seq); m=len(true)\n",
        "                if n==0: d.append(m); continue\n",
        "                dp=list(range(m+1))\n",
        "                for i in range(1,n+1):\n",
        "                    prev=dp[0]; dp[0]=i\n",
        "                    for j in range(1,m+1):\n",
        "                        tmp=dp[j]; cost=0 if seq[i-1]==true[j-1] else 1\n",
        "                        dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "                d.append(dp[m])\n",
        "            results.append((max(d), float(np.mean(d)), g, fidx))\n",
        "    agg={}\n",
        "    for worst, mean, g, fidx in results:\n",
        "        agg.setdefault(g, []).append(mean)\n",
        "    summary=[]\n",
        "    for g, arr in agg.items():\n",
        "        summary.append((max(arr), float(np.mean(arr)), g))\n",
        "    summary.sort(key=lambda x: (x[0], x[1]))\n",
        "    return summary[0]\n",
        "\n",
        "print('OOF grid for gamma (PANNs audio) with alpha_clip=0.30 ...', flush=True)\n",
        "best_g = oof_grid_gamma_panns(alpha_clip_fixed=0.30, gamma_list=(0.18,0.20,0.22,0.25), smooth_k=5, min_mult=0.7)\n",
        "print('Best gamma (worst, mean, gamma)=', best_g, flush=True)\n",
        "gamma_best = best_g[2]\n",
        "\n",
        "# 5) Decode TEST with alpha_clip=0.30, gamma_panns=best; MinSeg with min_mult=0.70; stage\n",
        "def decode_test_with_panns(alpha_clip=0.30, gamma_audio=0.20, smooth_k=5, min_mult=0.7, out_csv='submission_clip_panns_keep.csv'):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids,rows=[],[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pc = load_clip_probs_test_avg(sid)  # already temp-averaged\n",
        "        pa = load_audio_panns_test_avg(sid)\n",
        "        if pa is None:\n",
        "            pa = load_probs_generic(sid, 'audio')\n",
        "        pf = fuse_poe_with_clip_keep_len(ps, pc, pa, alpha_clip, gamma_audio)\n",
        "        pf = smooth_probs_box(pf, k=smooth_k)\n",
        "        y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "        seq = make_perm20(compress_to_sequence(y), pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95', flush=True)\n",
        "    pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id').to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, flush=True)\n",
        "    import shutil\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "\n",
        "print('Decoding TEST with PANNs audio fusion...', flush=True)\n",
        "decode_test_with_panns(alpha_clip=0.30, gamma_audio=gamma_best, smooth_k=5, min_mult=0.7, out_csv='submission_clip_panns_keep.csv')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating global PANNs AudioTagging on cuda checkpoint: /app/panns_data/Cnn14_mAP=0.431.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint path: /app/panns_data/Cnn14_mAP=0.431.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU number: 1\nPreparing PANNs (CNN14) assets and skipping bulk extraction...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping bulk PANNs extract for train; using on-the-fly extraction.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping bulk PANNs extract for test; using on-the-fly extraction.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training PANNs linear head (fast: epochs=1)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "panns fold=0 ep=1/1 loss=3.0315 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/panns_inference/inference.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=self.device)\n/tmp/ipykernel_114161/1462993053.py:230: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PANNs FAIL on audio_wav/test/318.wav Given input size: (512x1x8). Calculated output size: (512x0x4). Output size is too small\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PANNs FAIL on audio_wav/test/340.wav Given input size: (1024x1x4). Calculated output size: (1024x0x2). Output size is too small\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PANNs FAIL on audio_wav/test/343.wav Given input size: (512x1x8). Calculated output size: (512x0x4). Output size is too small\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PANNs FAIL on audio_wav/test/369.wav Given input size: (1024x1x4). Calculated output size: (1024x0x2). Output size is too small\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PANNs FAIL on audio_wav/test/377.wav Given input size: (1024x1x4). Calculated output size: (1024x0x2). Output size is too small\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "panns fold=1 ep=1/1 loss=3.0660 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "panns fold=2 ep=1/1 loss=3.0516 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PANNs head training + caching complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF grid for gamma (PANNs audio) with alpha_clip=0.30 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best gamma (worst, mean, gamma)= (4.45, 3.71847385418814, 0.18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST with PANNs audio fusion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "25a0011e-be29-4790-b574-d92cc7ac3e27",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OpenCLIP ViT-L/14 RGB features (fps=4, max_frames=512) -> linear head -> keep_len PoE with audio -> OOF tune -> TEST decode + stage\n",
        "import os, sys, subprocess, time, json, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Ensure deps (torch cu121 stack, open_clip_torch, decord already installed earlier in Cell 18)\n",
        "import torch, torchvision.transforms as T\n",
        "import open_clip\n",
        "from decord import VideoReader, cpu\n",
        "from PIL import Image\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('CUDA available:', torch.cuda.is_available(), 'GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU', flush=True)\n",
        "\n",
        "# Dirs for ViT-L/14 embeddings\n",
        "EMB_L = Path('rgb_clipL_embed'); (EMB_L/'train').mkdir(parents=True, exist_ok=True); (EMB_L/'test').mkdir(parents=True, exist_ok=True)\n",
        "VID_DIR_T = Path('rgb_videos/train'); VID_DIR_E = Path('rgb_videos/test')\n",
        "PROBS = Path('probs_cache'); PROBS.mkdir(exist_ok=True)\n",
        "LABELS = Path('labels3d_v2/train')\n",
        "\n",
        "# Reuse skeleton utilities from earlier cells\n",
        "try:\n",
        "    folds\n",
        "except NameError:\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "\n",
        "# Load OpenCLIP ViT-L/14\n",
        "modelL, _, txL = open_clip.create_model_and_transforms('ViT-L-14', pretrained='laion2b_s32b_b82k', device=device)\n",
        "modelL.eval()\n",
        "mean = (0.48145466, 0.4578275, 0.40821073); std = (0.26862954, 0.26130258, 0.27577711)\n",
        "tx_img = T.Compose([T.Resize(224, interpolation=T.InterpolationMode.BICUBIC), T.CenterCrop(224), T.ToTensor(), T.Normalize(mean, std)])\n",
        "\n",
        "def sample_idx(nf, fps_native, fps_target=4.0, max_frames=512):\n",
        "    if not fps_native or fps_native<=0: n = min(max_frames, nf)\n",
        "    else:\n",
        "        dur = nf/float(fps_native); n = min(max_frames, int(round(dur*fps_target)))\n",
        "    n = max(1, min(n, nf))\n",
        "    return np.linspace(0, nf-1, n).round().astype(int)\n",
        "\n",
        "@torch.no_grad()\n",
        "def encode_video_L(path: Path, max_frames=512, bs=64):\n",
        "    vr = VideoReader(str(path), ctx=cpu(0))\n",
        "    nf = len(vr)\n",
        "    try: fps_native = float(vr.get_avg_fps())\n",
        "    except Exception: fps_native = None\n",
        "    idx = sample_idx(nf, fps_native, 4.0, max_frames)\n",
        "    embs=[]\n",
        "    for i in range(0, len(idx), bs):\n",
        "        frames = vr.get_batch(idx[i:i+bs]).asnumpy()\n",
        "        imgs = [tx_img(Image.fromarray(fr)) for fr in frames]\n",
        "        x = torch.stack(imgs,0).to(device, non_blocking=True)\n",
        "        with torch.autocast(device_type='cuda', dtype=torch.float16) if device=='cuda' else torch.no_grad():\n",
        "            f = modelL.encode_image(x)\n",
        "        f = torch.nn.functional.normalize(f.float(), dim=1).cpu().numpy()\n",
        "        embs.append(f)\n",
        "    E = np.concatenate(embs,0).astype(np.float16)\n",
        "    return E\n",
        "\n",
        "def id_to_video(dirpath: Path, sid: int):\n",
        "    cands = list(dirpath.glob(f'{sid}.mp4'))\n",
        "    if cands: return cands[0]\n",
        "    cands = list(dirpath.glob(f'*{sid}*.mp4'))\n",
        "    return cands[0] if cands else None\n",
        "\n",
        "def extract_split_L(split='train', max_frames=512):\n",
        "    csv_path = 'training.csv' if split=='train' else 'test.csv'\n",
        "    ids = pd.read_csv(csv_path)['Id'].astype(int).tolist()\n",
        "    out_dir = EMB_L/split\n",
        "    vid_dir = VID_DIR_T if split=='train' else VID_DIR_E\n",
        "    done=0; t0=time.time()\n",
        "    for k,sid in enumerate(ids, 1):\n",
        "        out = out_dir/f\"{sid}.npy\"\n",
        "        if out.exists():\n",
        "            continue\n",
        "        vp = id_to_video(vid_dir, sid)\n",
        "        if vp is None:\n",
        "            continue\n",
        "        try:\n",
        "            E = encode_video_L(vp, max_frames=max_frames, bs=64)\n",
        "            np.save(out, E)\n",
        "            done+=1\n",
        "            if (done%20)==0: print(f\"{split}: saved {done} in {time.time()-t0:.1f}s (last id={sid})\", flush=True)\n",
        "        except Exception as e:\n",
        "            print('FAIL ViT-L', split, sid, e, flush=True)\n",
        "    print(split, 'ViT-L finished; new saved =', done, 'elapsed=', round(time.time()-t0,1), 's', flush=True)\n",
        "\n",
        "print('Extracting ViT-L/14 embeddings (train then test)...', flush=True)\n",
        "extract_split_L('train', max_frames=512)\n",
        "extract_split_L('test',  max_frames=512)\n",
        "\n",
        "# Train linear head (D->21) on ViT-L embeddings; cache OOF and per-fold TEST with temp scaling\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def load_clipL_embed(sid: int, split: str):\n",
        "    p = (EMB_L/'train'/f'{sid}.npy') if split=='train' else (EMB_L/'test'/f'{sid}.npy')\n",
        "    if not p.exists(): return None\n",
        "    return np.load(p)\n",
        "\n",
        "def resample_labels(y, T):\n",
        "    if len(y)==T: return y\n",
        "    idx = np.linspace(0, len(y)-1, T).round().astype(int)\n",
        "    return y[idx]\n",
        "\n",
        "class SeqDatasetL(Dataset):\n",
        "    def __init__(self, ids):\n",
        "        self.items=[]\n",
        "        for sid in ids:\n",
        "            E = load_clipL_embed(int(sid), 'train')\n",
        "            if E is None: continue\n",
        "            y = np.load(LABELS/f\"{int(sid)}.npy\").astype(np.int64)\n",
        "            y = resample_labels(y, E.shape[0])\n",
        "            self.items.append((int(sid), E.astype(np.float32), y))\n",
        "    def __len__(self): return len(self.items)\n",
        "    def __getitem__(self, i):\n",
        "        sid,E,y = self.items[i]\n",
        "        return sid, torch.from_numpy(E), torch.from_numpy(y)\n",
        "\n",
        "class LinearHead(nn.Module):\n",
        "    def __init__(self, in_dim): super().__init__(); self.fc = nn.Linear(in_dim, 21)\n",
        "    def forward(self, x): return self.fc(x)\n",
        "\n",
        "@torch.no_grad()\n",
        "def forward_logits_all(head, E_np: np.ndarray, bs: int = 2048):\n",
        "    xb = torch.from_numpy(E_np.astype(np.float32)).to(device)\n",
        "    outs=[]\n",
        "    for i in range(0, xb.size(0), bs):\n",
        "        outs.append(head(xb[i:i+bs]).float().cpu())\n",
        "    return torch.cat(outs,0).numpy().astype(np.float32)\n",
        "\n",
        "def fit_temperature(head, val_items):\n",
        "    Xs=[]; Ys=[]\n",
        "    with torch.no_grad():\n",
        "        for sid,E,y in val_items:\n",
        "            xb = torch.from_numpy(E.astype(np.float32)).to(device)\n",
        "            outs=[]\n",
        "            for i in range(0, xb.size(0), 2048):\n",
        "                outs.append(head(xb[i:i+2048]).float())\n",
        "            lg = torch.cat(outs,0); Xs.append(lg.cpu()); Ys.append(torch.from_numpy(y))\n",
        "    X = torch.cat(Xs,0).to(device); Y = torch.cat(Ys,0).to(device)\n",
        "    Tsc = torch.tensor(1.5, device=device, requires_grad=True)\n",
        "    opt = torch.optim.LBFGS([Tsc], lr=0.01, max_iter=50)\n",
        "    def closure():\n",
        "        opt.zero_grad(); loss = F.cross_entropy(X / Tsc, Y, reduction='mean'); loss.backward(); return loss\n",
        "    opt.step(closure)\n",
        "    return float(Tsc.detach().cpu().item())\n",
        "\n",
        "def train_clipL_head_and_cache(folds_path='folds_archive_cv.json', epochs=3, bs_frames=2048, lr=2e-3, wd=0.05):\n",
        "    folds = json.load(open(folds_path,'r'))\n",
        "    test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "    for fd in folds:\n",
        "        fidx = int(fd['fold'])\n",
        "        tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "        ds_tr = SeqDatasetL(tr_ids); ds_va = SeqDatasetL(va_ids)\n",
        "        if len(ds_tr)==0 or len(ds_va)==0: continue\n",
        "        Xtr = np.concatenate([E for _,E,_ in ds_tr.items], axis=0)\n",
        "        Ytr = np.concatenate([y for *_,y in ds_tr.items], axis=0)\n",
        "        chunks = [(Xtr[i:i+bs_frames], Ytr[i:i+bs_frames]) for i in range(0, Xtr.shape[0], bs_frames)]\n",
        "        in_dim = Xtr.shape[1]\n",
        "        head = LinearHead(in_dim).to(device)\n",
        "        opt = torch.optim.AdamW(head.parameters(), lr=lr, weight_decay=wd)\n",
        "        scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
        "        t0=time.time(); head.train()\n",
        "        for ep in range(epochs):\n",
        "            loss_sum=0.0; nb=0\n",
        "            for xb_np,yb_np in chunks:\n",
        "                xb = torch.from_numpy(xb_np).to(device); yb = torch.from_numpy(yb_np).to(device)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with torch.autocast(device_type='cuda', dtype=torch.float16, enabled=(device=='cuda')):\n",
        "                    lg = head(xb); loss = F.cross_entropy(lg, yb, label_smoothing=0.05)\n",
        "                scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "                loss_sum += float(loss.detach().cpu().item()); nb+=1\n",
        "            print(f\"ViT-L fold={fidx} ep={ep+1}/{epochs} loss={loss_sum/max(nb,1):.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "        head.eval()\n",
        "        # Cache OOF probs for validation ids\n",
        "        with torch.no_grad():\n",
        "            for sid,E,y in ds_va.items:\n",
        "                lg = forward_logits_all(head, E, bs=2048)  # (T,21)\n",
        "                p = torch.softmax(torch.from_numpy(lg), dim=1).numpy().astype(np.float32).T  # CxT\n",
        "                np.save(PROBS/f\"{sid}_clipL.npy\", p)\n",
        "        # Temp scaling on validation\n",
        "        Tval = fit_temperature(head, ds_va.items)\n",
        "        json.dump({'T': Tval}, open(f'clipL_temp_fold{fidx}.json','w'))\n",
        "        # Test per-fold probs (temp-scaled)\n",
        "        with torch.no_grad():\n",
        "            for sid in test_ids:\n",
        "                E = load_clipL_embed(int(sid), 'test')\n",
        "                if E is None: continue\n",
        "                lg = forward_logits_all(head, E, bs=2048)  # (T,21)\n",
        "                p = torch.softmax(torch.from_numpy(lg)/Tval, dim=1).numpy().astype(np.float32).T  # CxT\n",
        "                np.save(PROBS/f\"{sid}_clipL_f{fidx}.npy\", p)\n",
        "    print('ViT-L head training + caching complete.', flush=True)\n",
        "\n",
        "print('Training ViT-L head (3 folds)...', flush=True)\n",
        "train_clipL_head_and_cache(epochs=3, bs_frames=2048, lr=2e-3, wd=0.05)\n",
        "\n",
        "# Loaders for ViT-L probs\n",
        "def _load_temp_num(path: str):\n",
        "    p = Path(path);\n",
        "    if not p.exists(): return None\n",
        "    try: return float(json.load(open(p,'r')).get('T', 1.0))\n",
        "    except Exception:\n",
        "        try: return float(open(p).read().strip())\n",
        "        except Exception: return None\n",
        "\n",
        "def load_clipL_probs_train(sid:int):\n",
        "    pth = PROBS/f\"{sid}_clipL.npy\"\n",
        "    return np.load(pth).astype(np.float32) if pth.exists() else None\n",
        "\n",
        "def load_clipL_probs_test_avg(sid:int):\n",
        "    arr=[]\n",
        "    for f in (0,1,2):\n",
        "        pth = PROBS/f\"{sid}_clipL_f{f}.npy\"\n",
        "        if pth.exists(): arr.append(np.load(pth).astype(np.float32))\n",
        "    if not arr: return None\n",
        "    L = min(a.shape[1] for a in arr)\n",
        "    q = np.mean([a[:, :L] for a in arr], axis=0); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "# Reuse fusion utilities: load_skeleton_probs, load_probs_generic, fuse_poe_with_clip_keep_len, smooth_probs_box, decode_minseg, aba_collapse, compress_to_sequence, make_perm20, compute_min_dur_from_ids\n",
        "\n",
        "def oof_grid_clipL(alpha_list=(0.30,0.35,0.40,0.45), gamma_list=(0.15,0.20,0.25), smooth_k=5, min_mult=0.7):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    results=[]\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med = compute_min_dur_from_ids(tr); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "        fidx = int(fd['fold'])\n",
        "        Tclip = _load_temp_num(f'clipL_temp_fold{fidx}.json')\n",
        "        Taud  = _load_temp_num(f'audio_temp_fold{fidx}.json')\n",
        "        for a in alpha_list:\n",
        "            for g in gamma_list:\n",
        "                d=[]\n",
        "                for sid in va:\n",
        "                    sid=int(sid)\n",
        "                    ps = load_skeleton_probs(sid)\n",
        "                    pc = load_clipL_probs_train(sid)\n",
        "                    pa = load_probs_generic(sid, 'audio')\n",
        "                    if pc is not None and Tclip is not None: pc = temp_scale_scalar(pc, Tclip)\n",
        "                    if pa is not None and Taud  is not None: pa = temp_scale_scalar(pa,  Taud)\n",
        "                    pf = fuse_poe_with_clip_keep_len(ps, pc, pa, a, g)\n",
        "                    pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                    y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                    seq = compress_to_sequence(y); true = compress_to_sequence(np.load(LABELS/f\"{sid}.npy\"))\n",
        "                    # Levenshtein\n",
        "                    n=len(seq); m=len(true)\n",
        "                    if n==0: d.append(m); continue\n",
        "                    dp=list(range(m+1))\n",
        "                    for i in range(1,n+1):\n",
        "                        prev=dp[0]; dp[0]=i\n",
        "                        for j in range(1,m+1):\n",
        "                            tmp=dp[j]; cost=0 if seq[i-1]==true[j-1] else 1\n",
        "                            dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "                    d.append(dp[m])\n",
        "                results.append((max(d), float(np.mean(d)), a, g))\n",
        "    results.sort(key=lambda x: (x[0], x[1]))\n",
        "    return results[0]\n",
        "\n",
        "def decode_test_clipL(alpha_clip=0.35, gamma_audio=0.20, smooth_k=5, min_mult=0.7, out_csv='submission_clipL_poe_keep.csv'):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    Ta_list = [_load_temp_num(f'audio_temp_fold{f}.json') for f in (0,1,2)]\n",
        "    Ta_vals = [t for t in Ta_list if t is not None]\n",
        "    Ta_mean = float(np.mean(Ta_vals)) if len(Ta_vals)>0 else None\n",
        "    ids,rows=[],[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pc = load_clipL_probs_test_avg(sid)\n",
        "        pa = load_probs_generic(sid, 'audio')\n",
        "        if pa is not None and Ta_mean is not None: pa = temp_scale_scalar(pa, Ta_mean)\n",
        "        pf = fuse_poe_with_clip_keep_len(ps, pc, pa, alpha_clip, gamma_audio)\n",
        "        pf = smooth_probs_box(pf, k=smooth_k)\n",
        "        y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "        seq = make_perm20(compress_to_sequence(y), pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95', flush=True)\n",
        "    pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id').to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, flush=True)\n",
        "    import shutil\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "\n",
        "print('OOF grid for ViT-L keep_len fusion...', flush=True)\n",
        "best = oof_grid_clipL(alpha_list=(0.30,0.35,0.40,0.45), gamma_list=(0.15,0.20,0.25), smooth_k=5, min_mult=0.7)\n",
        "print('Best (worst, mean, alpha_clip, gamma_audio)=', best, flush=True)\n",
        "_,_,alphaL,gammaA = best\n",
        "print(f'Decoding TEST keep_len with ViT-L: alpha={alphaL}, gamma={gammaA} ...', flush=True)\n",
        "decode_test_clipL(alpha_clip=alphaL, gamma_audio=gammaA, smooth_k=5, min_mult=0.7, out_csv='submission_clipL_poe_keep.csv')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True GPU: NVIDIA A10-24Q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ViT-L/14 embeddings (train then test)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train ViT-L finished; new saved = 0 elapsed= 0.0 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test ViT-L finished; new saved = 0 elapsed= 0.0 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ViT-L head (3 folds)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT-L fold=0 ep=1/3 loss=3.0236 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT-L fold=0 ep=2/3 loss=2.9589 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT-L fold=0 ep=3/3 loss=2.9224 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_114161/1119292429.py:161: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT-L fold=1 ep=1/3 loss=3.0183 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT-L fold=1 ep=2/3 loss=2.9263 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT-L fold=1 ep=3/3 loss=2.8792 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT-L fold=2 ep=1/3 loss=2.9162 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT-L fold=2 ep=2/3 loss=2.7021 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT-L fold=2 ep=3/3 loss=2.6253 elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT-L head training + caching complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF grid for ViT-L keep_len fusion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best (worst, mean, alpha_clip, gamma_audio)= (10, 3.836734693877551, 0.4, 0.15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST keep_len with ViT-L: alpha=0.4, gamma=0.15 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clipL_poe_keep.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clipL_poe_keep.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "b03d9d6c-78b9-462e-b9bd-fe3f509f4638",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Best-of-N (keep_len PoE) over alpha_clip, gamma_audio, and min_mult in {0.65,0.70} for CLIP(RGB)+Audio; stages submission\n",
        "import numpy as np, pandas as pd, time, os, shutil, json\n",
        "\n",
        "def total_emission_loglik(y: np.ndarray, p: np.ndarray) -> float:\n",
        "    C,T = p.shape\n",
        "    idx = np.clip(y, 0, C-1).astype(np.int32)\n",
        "    cols = np.arange(T, dtype=np.int32)\n",
        "    probs = np.clip(p[idx, cols], 1e-12, 1.0)\n",
        "    return float(np.log(probs).sum())\n",
        "\n",
        "def decode_test_clip_bestofN_keep_len_minmult(out_csv='submission_clip_poe_keep_bestofN_minmult.csv',\n",
        "                                             alpha_list=(0.28,0.30,0.32,0.34), gamma_list=(0.18,0.20,0.22,0.24),\n",
        "                                             min_mult_list=(0.65,0.70), smooth_k=5):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    # average audio temperature over folds\n",
        "    def _load_temp_num(path: str):\n",
        "        p = Path(path);\n",
        "        if not p.exists(): return None\n",
        "        try: return float(json.load(open(p,'r')).get('T', 1.0))\n",
        "        except Exception:\n",
        "            try: return float(open(p).read().strip())\n",
        "            except Exception: return None\n",
        "    Ta_list = [_load_temp_num(f'audio_temp_fold{f}.json') for f in (0,1,2)]\n",
        "    Ta_vals = [t for t in Ta_list if t is not None]\n",
        "    Ta_mean = float(np.mean(Ta_vals)) if len(Ta_vals)>0 else None\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pc = load_clip_probs_test_avg(sid)  # per-fold temp already applied\n",
        "        pa = load_probs_generic(sid, 'audio')\n",
        "        if pa is not None and Ta_mean is not None:\n",
        "            pa = temp_scale_scalar(pa, Ta_mean)\n",
        "        best_ll = -1e99; best_seq=None\n",
        "        for ac in alpha_list:\n",
        "            for ga in gamma_list:\n",
        "                pf = fuse_poe_with_clip_keep_len(ps, pc, pa, ac, ga)\n",
        "                pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                for mm in min_mult_list:\n",
        "                    min_dur = np.floor(med*mm + 0.5).astype(np.int32); min_dur[0]=0\n",
        "                    y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                    ll = total_emission_loglik(y, pf)\n",
        "                    if ll > best_ll:\n",
        "                        best_ll = ll\n",
        "                        seq = make_perm20(compress_to_sequence(y), pf)\n",
        "                        best_seq = seq\n",
        "        ids.append(sid); rows.append(' '.join(map(str, best_seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "\n",
        "print('Decoding TEST: Best-of-N over (alpha_clip, gamma_audio, min_mult) for CLIP+Audio keep_len...', flush=True)\n",
        "decode_test_clip_bestofN_keep_len_minmult(out_csv='submission_clip_poe_keep_bestofN_minmult.csv',\n",
        "                                          alpha_list=(0.28,0.30,0.32,0.34), gamma_list=(0.18,0.20,0.22,0.24),\n",
        "                                          min_mult_list=(0.65,0.70), smooth_k=5)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST: Best-of-N over (alpha_clip, gamma_audio, min_mult) for CLIP+Audio keep_len...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=4.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=6.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=8.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=9.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_poe_keep_bestofN_minmult.csv rows= 95\nStaged submission: submission_clip_poe_keep_bestofN_minmult.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "0757a9e5-bedf-45b7-9c13-52339b8f16b8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hedge decodes for PANNs gamma +/- 0.02; restage OOF-best (g=0.18) at the end\n",
        "import shutil, os\n",
        "print('Decoding PANNs hedges gamma=0.16 and gamma=0.20 ...', flush=True)\n",
        "try:\n",
        "    decode_test_with_panns(alpha_clip=0.30, gamma_audio=0.16, smooth_k=5, min_mult=0.7, out_csv='submission_clip_panns_keep_g016.csv')\n",
        "except Exception as e:\n",
        "    print('Gamma 0.16 decode failed:', e, flush=True)\n",
        "try:\n",
        "    decode_test_with_panns(alpha_clip=0.30, gamma_audio=0.20, smooth_k=5, min_mult=0.7, out_csv='submission_clip_panns_keep_g020.csv')\n",
        "except Exception as e:\n",
        "    print('Gamma 0.20 decode failed:', e, flush=True)\n",
        "# Restore OOF-best staged (gamma=0.18) to submission.csv\n",
        "if os.path.exists('submission_clip_panns_keep.csv'):\n",
        "    shutil.copyfile('submission_clip_panns_keep.csv', 'submission.csv')\n",
        "    print('Restaged OOF-best: submission_clip_panns_keep.csv -> submission.csv', flush=True)\n",
        "else:\n",
        "    print('Warning: submission_clip_panns_keep.csv missing; cannot restage.', flush=True)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding PANNs hedges gamma=0.16 and gamma=0.20 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_g016.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_g016.csv -> submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_g020.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_g020.csv -> submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restaged OOF-best: submission_clip_panns_keep.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "a1284b69-813e-47f9-a90a-5e97051346a4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Stage PANNs hedge gamma=0.20\n",
        "import shutil, os\n",
        "src = 'submission_clip_panns_keep_g020.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "shutil.copyfile(src, dst)\n",
        "print(f'Staged PANNs hedge submission: {src} -> {dst}')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged PANNs hedge submission: submission_clip_panns_keep_g020.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "461d5e09-a49a-46cf-a972-1686cd672cb2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Best-of-N over (alpha_clip, gamma_panns, min_mult) for PANNs fusion; TEST DECODE; stage result\n",
        "import numpy as np, pandas as pd, time, os, shutil, json\n",
        "\n",
        "def total_emission_loglik(y: np.ndarray, p: np.ndarray) -> float:\n",
        "    C,T = p.shape\n",
        "    idx = np.clip(y, 0, C-1).astype(np.int32)\n",
        "    cols = np.arange(T, dtype=np.int32)\n",
        "    probs = np.clip(p[idx, cols], 1e-12, 1.0)\n",
        "    return float(np.log(probs).sum())\n",
        "\n",
        "def decode_test_panns_bestofN_keep_len(out_csv='submission_clip_panns_keep_bestofN_minmult.csv',\n",
        "                                       alpha_list=(0.28,0.30,0.32), gamma_list=(0.16,0.18,0.20,0.22),\n",
        "                                       min_mult_list=(0.65,0.70), smooth_k=5):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pc = load_clip_probs_test_avg(sid)  # CLIP per-fold temp already applied\n",
        "        pa = load_audio_panns_test_avg(sid)\n",
        "        if pa is None:\n",
        "            pa = load_probs_generic(sid, 'audio')\n",
        "        best_ll = -1e99; best_seq=None\n",
        "        for ac in alpha_list:\n",
        "            for ga in gamma_list:\n",
        "                pf = fuse_poe_with_clip_keep_len(ps, pc, pa, ac, ga)\n",
        "                pf = smooth_probs_box(pf, k=smooth_k)\n",
        "                for mm in min_mult_list:\n",
        "                    min_dur = np.floor(med*mm + 0.5).astype(np.int32); min_dur[0]=0\n",
        "                    y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                    ll = total_emission_loglik(y, pf)\n",
        "                    if ll > best_ll:\n",
        "                        best_ll = ll\n",
        "                        seq = make_perm20(compress_to_sequence(y), pf)\n",
        "                        best_seq = seq\n",
        "        ids.append(sid); rows.append(' '.join(map(str, best_seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "\n",
        "print('Decoding TEST Best-of-N for PANNs fusion...', flush=True)\n",
        "decode_test_panns_bestofN_keep_len(out_csv='submission_clip_panns_keep_bestofN_minmult.csv',\n",
        "                                   alpha_list=(0.28,0.30,0.32), gamma_list=(0.16,0.18,0.20,0.22),\n",
        "                                   min_mult_list=(0.65,0.70), smooth_k=5)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST Best-of-N for PANNs fusion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=4.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_bestofN_minmult.csv rows= 95\nStaged submission: submission_clip_panns_keep_bestofN_minmult.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "16281165-212c-4ce9-b8f4-d70c806a7ab7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Best-of-N for PANNs fusion with smooth_k in {3,5} and pairwise-margin fill; TEST DECODE; stage\n",
        "import numpy as np, pandas as pd, time, os, shutil, json\n",
        "\n",
        "def total_emission_loglik(y: np.ndarray, p: np.ndarray) -> float:\n",
        "    C,T = p.shape\n",
        "    idx = np.clip(y, 0, C-1).astype(np.int32)\n",
        "    cols = np.arange(T, dtype=np.int32)\n",
        "    probs = np.clip(p[idx, cols], 1e-12, 1.0)\n",
        "    return float(np.log(probs).sum())\n",
        "\n",
        "def pairwise_margins(p: np.ndarray, q_power: float = 1.8):\n",
        "    C,T = p.shape\n",
        "    w = np.power(np.clip(p[1:21], 1e-8, 1.0), q_power).astype(np.float32)  # 20 x T\n",
        "    S_after = np.cumsum(w[:, ::-1], axis=1)[:, ::-1]\n",
        "    W = np.zeros((20,20), dtype=np.float64)\n",
        "    for i in range(20):\n",
        "        wi = w[i]\n",
        "        for j in range(20):\n",
        "            if i==j: continue\n",
        "            W[i,j] = float((wi * S_after[j]).sum())\n",
        "    M = W - W.T\n",
        "    return M\n",
        "\n",
        "def make_perm20_pairmargin(seq_raw, p: np.ndarray, q_power: float = 1.8):\n",
        "    seen=set(); seq=[]\n",
        "    for c in seq_raw:\n",
        "        if 1<=c<=20 and c not in seen:\n",
        "            seen.add(c); seq.append(c)\n",
        "    if len(seq) >= 20:\n",
        "        return seq[:20]\n",
        "    M = pairwise_margins(p, q_power=q_power)\n",
        "    missing = [c for c in range(1,21) if c not in seen]\n",
        "    scores = {c: float(M[c-1].sum()) for c in missing}\n",
        "    missing_sorted = sorted(missing, key=lambda c: scores[c], reverse=True)\n",
        "    for c in missing_sorted:\n",
        "        if len(seq)==20: break\n",
        "        seq.append(c)\n",
        "    if len(seq)>20: seq = seq[:20]\n",
        "    return seq\n",
        "\n",
        "def decode_test_panns_bestofN_keep_len_smooth_pair(out_csv='submission_clip_panns_keep_bestofN_smooth_pair.csv',\n",
        "                                                   alpha_list=(0.28,0.30,0.32), gamma_list=(0.16,0.18,0.20,0.22),\n",
        "                                                   min_mult_list=(0.65,0.70), smooth_list=(3,5)):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids=[]; rows=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pc = load_clip_probs_test_avg(sid)  # CLIP per-fold temp already applied\n",
        "        pa = load_audio_panns_test_avg(sid)\n",
        "        if pa is None:\n",
        "            pa = load_probs_generic(sid, 'audio')\n",
        "        best_ll = -1e99; best_seq=None\n",
        "        for ac in alpha_list:\n",
        "            for ga in gamma_list:\n",
        "                pf_base = fuse_poe_with_clip_keep_len(ps, pc, pa, ac, ga)\n",
        "                for sk in smooth_list:\n",
        "                    pf = smooth_probs_box(pf_base, k=sk)\n",
        "                    for mm in min_mult_list:\n",
        "                        min_dur = np.floor(med*mm + 0.5).astype(np.int32); min_dur[0]=0\n",
        "                        y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                        ll = total_emission_loglik(y, pf)\n",
        "                        if ll > best_ll:\n",
        "                            best_ll = ll\n",
        "                            seq = make_perm20_pairmargin(compress_to_sequence(y), pf, q_power=1.8)\n",
        "                            best_seq = seq\n",
        "        ids.append(sid); rows.append(' '.join(map(str, best_seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "\n",
        "print('Decoding TEST Best-of-N (smooth {3,5} + pairwise fill) for PANNs fusion...', flush=True)\n",
        "decode_test_panns_bestofN_keep_len_smooth_pair(out_csv='submission_clip_panns_keep_bestofN_smooth_pair.csv',\n",
        "                                               alpha_list=(0.28,0.30,0.32), gamma_list=(0.16,0.18,0.20,0.22),\n",
        "                                               min_mult_list=(0.65,0.70), smooth_list=(3,5))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST Best-of-N (smooth {3,5} + pairwise fill) for PANNs fusion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=5.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=7.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=9.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_bestofN_smooth_pair.csv rows= 95\nStaged submission: submission_clip_panns_keep_bestofN_smooth_pair.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "f742ed06-082b-4386-938b-f60397201e71",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OOF sanity: compare min_mult=0.70 vs 0.68 for PANNs fusion (alpha_clip=0.30, gamma=0.18), keep_len PoE\n",
        "import numpy as np, pandas as pd, json, time\n",
        "\n",
        "def lev_dist(a, b):\n",
        "    n=len(a); m=len(b)\n",
        "    if n==0: return m\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; cost=0 if a[i-1]==b[j-1] else 1\n",
        "            dp[j]=min(dp[j]+1, dp[j-1]+1, prev+cost); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "def oof_compare_minmult(alpha_clip=0.30, gamma_audio=0.18, smooth_k=5, min_mult_list=(0.70, 0.68)):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    results = {mm: [] for mm in min_mult_list}\n",
        "    for fd in folds:\n",
        "        tr = list(map(int, fd['train_ids'])); va = list(map(int, fd['val_ids']))\n",
        "        med = compute_min_dur_from_ids(tr)\n",
        "        fidx = int(fd['fold'])\n",
        "        Tclip = _load_temp_num(f'clip_temp_fold{fidx}.json')\n",
        "        for sid in va:\n",
        "            sid=int(sid)\n",
        "            ps = load_skeleton_probs(sid)\n",
        "            pc = load_clip_probs_train(sid)\n",
        "            pa = load_audio_panns_train(sid)\n",
        "            if pc is not None and Tclip is not None: pc = temp_scale_scalar(pc, Tclip)\n",
        "            if pa is None:\n",
        "                pa = load_probs_generic(sid, 'audio')\n",
        "            pf = fuse_poe_with_clip_keep_len(ps, pc, pa, alpha_clip, gamma_audio)\n",
        "            pf = smooth_probs_box(pf, k=smooth_k)\n",
        "            true_seq = compress_to_sequence(np.load(LABELS/f\"{sid}.npy\"))\n",
        "            for mm in min_mult_list:\n",
        "                min_dur = np.floor(med*mm + 0.5).astype(np.int32); min_dur[0]=0\n",
        "                y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "                seq = compress_to_sequence(y)\n",
        "                results[mm].append(lev_dist(seq, true_seq))\n",
        "    for mm in min_mult_list:\n",
        "        arr = results[mm]\n",
        "        print(f\"min_mult={mm:.2f}: worst={max(arr):.3f}, mean={np.mean(arr):.3f}, norm_mean={np.mean(arr)/20:.5f}\")\n",
        "    # recommend best by worst then mean\n",
        "    summary = sorted([(max(v), float(np.mean(v)), mm) for mm,v in results.items()], key=lambda x: (x[0], x[1]))\n",
        "    print('Best setting (by OOF):', summary[0])\n",
        "    return summary[0]\n",
        "\n",
        "print('OOF compare min_mult 0.70 vs 0.68 (PANNs keep_len PoE)...', flush=True)\n",
        "best_mm = oof_compare_minmult(alpha_clip=0.30, gamma_audio=0.18, smooth_k=5, min_mult_list=(0.70, 0.68))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF compare min_mult 0.70 vs 0.68 (PANNs keep_len PoE)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_mult=0.70: worst=20.000, mean=3.721, norm_mean=0.18603\nmin_mult=0.68: worst=20.000, mean=3.680, norm_mean=0.18401\nBest setting (by OOF): (20, 3.68013468013468, 0.68)\n"
          ]
        }
      ]
    },
    {
      "id": "b46caa38-28fc-47f7-aa05-abd809e0f543",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Decode TEST with PANNs fusion using min_mult=0.68 (OOF-better) and stage\n",
        "import shutil, os, time\n",
        "print('Decoding TEST with PANNs: alpha_clip=0.30, gamma=0.18, min_mult=0.68 ...', flush=True)\n",
        "out_csv = 'submission_clip_panns_keep_m068.csv'\n",
        "decode_test_with_panns(alpha_clip=0.30, gamma_audio=0.18, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "if os.path.exists(out_csv):\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "else:\n",
        "    print('ERROR: expected output file missing', flush=True)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST with PANNs: alpha_clip=0.30, gamma=0.18, min_mult=0.68 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_m068.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_m068.csv -> submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_m068.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "2224bee8-4e5c-4b6c-b4a1-81b7bcc52080",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Stage hedge: PANNs Best-of-N with smooth {3,5} + pairwise fill\n",
        "import shutil, os\n",
        "src = 'submission_clip_panns_keep_bestofN_smooth_pair.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "shutil.copyfile(src, dst)\n",
        "print(f'Staged hedge submission: {src} -> {dst}')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged hedge submission: submission_clip_panns_keep_bestofN_smooth_pair.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "30ce98f5-c1df-49dd-a826-049290028294",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final hedge S1: PANNs fusion keep_len PoE with smooth_k=3, alpha_clip=0.30, gamma=0.18, min_mult=0.68; stage submission\n",
        "import shutil, os, time\n",
        "print('Decoding TEST S1: alpha_clip=0.30, gamma=0.18, min_mult=0.68, smooth_k=3 ...', flush=True)\n",
        "out_csv = 'submission_clip_panns_keep_m068_smooth3.csv'\n",
        "decode_test_with_panns(alpha_clip=0.30, gamma_audio=0.18, smooth_k=3, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(out_csv), f'Expected {out_csv}'\n",
        "shutil.copyfile(out_csv, 'submission.csv')\n",
        "print(f'Staged submission S1: {out_csv} -> submission.csv', flush=True)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST S1: alpha_clip=0.30, gamma=0.18, min_mult=0.68, smooth_k=3 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_m068_smooth3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_m068_smooth3.csv -> submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission S1: submission_clip_panns_keep_m068_smooth3.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "49447104-551f-40e0-aed3-efae5666e8bd",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final hedge S2: PANNs fusion keep_len PoE with smooth_k=5, alpha_clip=0.30, gamma=0.20, min_mult=0.68; stage submission\n",
        "import shutil, os, time\n",
        "print('Decoding TEST S2: alpha_clip=0.30, gamma=0.20, min_mult=0.68, smooth_k=5 ...', flush=True)\n",
        "out_csv = 'submission_clip_panns_keep_m068_g020.csv'\n",
        "decode_test_with_panns(alpha_clip=0.30, gamma_audio=0.20, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(out_csv), f'Expected {out_csv}'\n",
        "shutil.copyfile(out_csv, 'submission.csv')\n",
        "print(f'Staged submission S2: {out_csv} -> submission.csv', flush=True)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST S2: alpha_clip=0.30, gamma=0.20, min_mult=0.68, smooth_k=5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_m068_g020.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_m068_g020.csv -> submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission S2: submission_clip_panns_keep_m068_g020.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "d89ecf1d-faac-418f-9fe1-77c1486ab733",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final hedge S3: PANNs fusion keep_len PoE with smooth_k=5, alpha_clip=0.30, gamma=0.18, min_mult=0.70; stage submission\n",
        "import shutil, os, time\n",
        "print('Decoding TEST S3: alpha_clip=0.30, gamma=0.18, min_mult=0.70, smooth_k=5 ...', flush=True)\n",
        "out_csv = 'submission_clip_panns_keep_m070.csv'\n",
        "decode_test_with_panns(alpha_clip=0.30, gamma_audio=0.18, smooth_k=5, min_mult=0.70, out_csv=out_csv)\n",
        "assert os.path.exists(out_csv), f'Expected {out_csv}'\n",
        "shutil.copyfile(out_csv, 'submission.csv')\n",
        "print(f'Staged submission S3: {out_csv} -> submission.csv', flush=True)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST S3: alpha_clip=0.30, gamma=0.18, min_mult=0.70, smooth_k=5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_m070.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_m070.csv -> submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission S3: submission_clip_panns_keep_m070.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "9f0e1b10-e5fb-4e9b-97c2-65bfba73824b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final hedge S4: keep_len PoE with alpha_clip=0.32, gamma=0.18, min_mult=0.68, smooth_k=5; stage submission\n",
        "import shutil, os, time\n",
        "print('Decoding TEST S4: alpha_clip=0.32, gamma=0.18, min_mult=0.68, smooth_k=5 ...', flush=True)\n",
        "out_csv = 'submission_clip_panns_keep_m068_a032_g018.csv'\n",
        "decode_test_with_panns(alpha_clip=0.32, gamma_audio=0.18, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(out_csv), f'Expected {out_csv}'\n",
        "shutil.copyfile(out_csv, 'submission.csv')\n",
        "print(f'Staged submission S4: {out_csv} -> submission.csv', flush=True)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST S4: alpha_clip=0.32, gamma=0.18, min_mult=0.68, smooth_k=5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_m068_a032_g018.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_m068_a032_g018.csv -> submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission S4: submission_clip_panns_keep_m068_a032_g018.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "93556597-ec84-4f39-8b56-2a29330db98e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final hedge S5: keep_len PoE with alpha_clip=0.30, gamma=0.22, min_mult=0.68, smooth_k=5; stage submission\n",
        "import shutil, os, time\n",
        "print('Decoding TEST S5: alpha_clip=0.30, gamma=0.22, min_mult=0.68, smooth_k=5 ...', flush=True)\n",
        "out_csv = 'submission_clip_panns_keep_m068_g022.csv'\n",
        "decode_test_with_panns(alpha_clip=0.30, gamma_audio=0.22, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(out_csv), f'Expected {out_csv}'\n",
        "shutil.copyfile(out_csv, 'submission.csv')\n",
        "print(f'Staged submission S5: {out_csv} -> submission.csv', flush=True)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST S5: alpha_clip=0.30, gamma=0.22, min_mult=0.68, smooth_k=5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_m068_g022.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_m068_g022.csv -> submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission S5: submission_clip_panns_keep_m068_g022.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "76214054-62cd-4af7-8c93-e9eb478fe6b7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final hedge S6: keep_len PoE with alpha_clip=0.28, gamma=0.18, min_mult=0.68, smooth_k=5; stage submission\n",
        "import shutil, os, time\n",
        "print('Decoding TEST S6: alpha_clip=0.28, gamma=0.18, min_mult=0.68, smooth_k=5 ...', flush=True)\n",
        "out_csv = 'submission_clip_panns_keep_m068_a028_g018.csv'\n",
        "decode_test_with_panns(alpha_clip=0.28, gamma_audio=0.18, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(out_csv), f'Expected {out_csv}'\n",
        "shutil.copyfile(out_csv, 'submission.csv')\n",
        "print(f'Staged submission S6: {out_csv} -> submission.csv', flush=True)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST S6: alpha_clip=0.28, gamma=0.18, min_mult=0.68, smooth_k=5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_m068_a028_g018.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_m068_a028_g018.csv -> submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission S6: submission_clip_panns_keep_m068_a028_g018.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "5ea73a21-7d0d-494d-a52b-e0d6c6c015d8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final hedge S7: keep_len PoE with alpha_clip=0.30, gamma=0.18, min_mult=0.68, smooth_k=5, ABA max_len=3; stage submission\n",
        "import numpy as np, pandas as pd, json, time, shutil, os\n",
        "\n",
        "def decode_test_with_panns_aba(alpha_clip=0.30, gamma_audio=0.18, smooth_k=5, min_mult=0.68, aba_len=3, out_csv='submission_clip_panns_keep_m068_aba3.csv'):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids); min_dur = np.floor(med*min_mult+0.5).astype(np.int32); min_dur[0]=0\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids,rows=[],[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pc = load_clip_probs_test_avg(sid)  # already temp-averaged\n",
        "        pa = load_audio_panns_test_avg(sid)\n",
        "        if pa is None:\n",
        "            pa = load_probs_generic(sid, 'audio')\n",
        "        pf = fuse_poe_with_clip_keep_len(ps, pc, pa, alpha_clip, gamma_audio)\n",
        "        pf = smooth_probs_box(pf, k=smooth_k)\n",
        "        y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=aba_len)\n",
        "        seq = make_perm20(compress_to_sequence(y), pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, flush=True)\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "\n",
        "print('Decoding TEST S7: alpha_clip=0.30, gamma=0.18, min_mult=0.68, smooth_k=5, ABA=3 ...', flush=True)\n",
        "decode_test_with_panns_aba(alpha_clip=0.30, gamma_audio=0.18, smooth_k=5, min_mult=0.68, aba_len=3, out_csv='submission_clip_panns_keep_m068_aba3.csv')"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST S7: alpha_clip=0.30, gamma=0.18, min_mult=0.68, smooth_k=5, ABA=3 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_m068_aba3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_m068_aba3.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "98b0e18f-6cb2-4c9e-bb34-5e0a4bd164ec",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final hedge S8: keep_len PoE with alpha_clip=0.30, gamma=0.19, min_mult=0.68, smooth_k=5 (ABA=2 default); stage submission\n",
        "import shutil, os, time\n",
        "print('Decoding TEST S8: alpha_clip=0.30, gamma=0.19, min_mult=0.68, smooth_k=5 ...', flush=True)\n",
        "out_csv = 'submission_clip_panns_keep_m068_g019.csv'\n",
        "decode_test_with_panns(alpha_clip=0.30, gamma_audio=0.19, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(out_csv), f'Expected {out_csv}'\n",
        "shutil.copyfile(out_csv, 'submission.csv')\n",
        "print(f'Staged submission S8: {out_csv} -> submission.csv', flush=True)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST S8: alpha_clip=0.30, gamma=0.19, min_mult=0.68, smooth_k=5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_clip_panns_keep_m068_g019.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission: submission_clip_panns_keep_m068_g019.csv -> submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged submission S8: submission_clip_panns_keep_m068_g019.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "6210d5c5-f729-4c6e-bb9d-38fcc9484877",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick integrity check: submission.csv has 95 rows and each Sequence is a permutation of 1..20\n",
        "import pandas as pd, numpy as np, sys\n",
        "sub = pd.read_csv('submission.csv')\n",
        "print('Rows:', len(sub))\n",
        "assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "bad=[]\n",
        "for i,(sid,seq_str) in enumerate(zip(sub['Id'], sub['Sequence'])):\n",
        "    seq = list(map(int, str(seq_str).split()))\n",
        "    if len(seq)!=20 or set(seq)!=set(range(1,21)) or len(set(seq))!=20:\n",
        "        bad.append((sid, seq[:5], len(seq), len(set(seq))))\n",
        "print('Invalid rows:', len(bad))\n",
        "if bad:\n",
        "    print('Examples (Id, first5, len, uniq):', bad[:5])\n",
        "else:\n",
        "    print('All sequences valid permutations of 1..20.')\n",
        "# Additional sanity: no NaNs/inf in file\n",
        "assert not sub.isna().any().any(), 'NaNs found in submission.csv'\n",
        "print('Integrity checks passed.')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 95\nInvalid rows: 0\nAll sequences valid permutations of 1..20.\nIntegrity checks passed.\n"
          ]
        }
      ]
    },
    {
      "id": "f451025d-1ba6-4dff-ad73-ea5b1dd04212",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Patch: canonical skeleton loader with temps + classic-audio fallback temp; final decodes m068_g018 and m068_g019, stage g018\n",
        "import numpy as np, pandas as pd, json, time, os, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "print('Applying PATCH: canonical skeleton temps + classic-audio fallback temp', flush=True)\n",
        "probs_cache = Path('probs_cache')\n",
        "calib = json.load(open('calib_all_v2v3_meta.json','r'))\n",
        "T2 = np.array(calib['T2'], dtype=np.float32)\n",
        "T3 = np.array(calib['T3'], dtype=np.float32)\n",
        "A  = np.array(calib.get('A', [0.7]*len(T2)), dtype=np.float32)\n",
        "\n",
        "def temp_scale(p, T):\n",
        "    T = np.asarray(T, dtype=np.float32).reshape(-1)\n",
        "    p = np.clip(p, 1e-8, 1.0)\n",
        "    logp = np.log(p)\n",
        "    if p.shape[0] == T.shape[0]:\n",
        "        logp = logp / np.maximum(T[:, None], 1e-6)\n",
        "        q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "        return q.astype(np.float32)\n",
        "    elif p.shape[-1] == T.shape[0]:\n",
        "        logp = logp / np.maximum(T[None, :], 1e-6)\n",
        "        q = np.exp(logp); q /= (q.sum(axis=1, keepdims=True) + 1e-8)\n",
        "        return q.T.astype(np.float32)\n",
        "    else:\n",
        "        raise ValueError('T length mismatch')\n",
        "\n",
        "def ensure_CxT(p, C=21):\n",
        "    if p is None: return None\n",
        "    if p.ndim==2 and p.shape[0]==C: return p\n",
        "    if p.ndim==2 and p.shape[1]==C: return p.T\n",
        "    raise ValueError('Bad probs shape')\n",
        "\n",
        "def load_skeleton_probs(seq_id: int) -> np.ndarray:\n",
        "    p2 = np.load(probs_cache/f\"{seq_id}_ce.npy\").astype(np.float32)\n",
        "    p3 = np.load(probs_cache/f\"{seq_id}_ce_v3.npy\").astype(np.float32)\n",
        "    p2 = ensure_CxT(temp_scale(p2, T2))\n",
        "    p3 = ensure_CxT(temp_scale(p3, T3))\n",
        "    Tm = min(p2.shape[1], p3.shape[1])\n",
        "    p2 = p2[:, :Tm]; p3 = p3[:, :Tm]\n",
        "    a = A.reshape(-1,1).astype(np.float32)\n",
        "    p = a*p2 + (1.0-a)*p3\n",
        "    p /= (p.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return p.astype(np.float32)\n",
        "\n",
        "def _load_temp_num(path):\n",
        "    try:\n",
        "        with open(path,'r') as f:\n",
        "            obj = json.load(f)\n",
        "        if isinstance(obj, dict) and 'T' in obj: return float(obj['T'])\n",
        "        return float(obj)\n",
        "    except Exception:\n",
        "        try:\n",
        "            return float(open(path).read().strip())\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "def temp_scale_scalar(p_arr: np.ndarray | None, Tnum: float | None):\n",
        "    if p_arr is None or Tnum is None: return p_arr\n",
        "    p = np.clip(p_arr, 1e-8, 1.0).astype(np.float32)\n",
        "    logp = np.log(p) / max(float(Tnum), 1e-6)\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True)+1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def decode_test_with_panns_final(alpha_clip=0.30, gamma_audio=0.18, smooth_k=5, min_mult=0.68, out_csv='submission_final.csv'):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids)\n",
        "    min_dur = np.floor(med*min_mult + 0.5).astype(np.int32); min_dur[0]=0\n",
        "    # mean classic-audio temp (fallback only, PANNs already temped per-fold and averaged)\n",
        "    Ta_vals = [_load_temp_num(f'audio_temp_fold{f}.json') for f in (0,1,2)]\n",
        "    Ta_vals = [t for t in Ta_vals if t is not None]\n",
        "    Ta_mean = float(np.mean(Ta_vals)) if Ta_vals else None\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids, rows = [], []\n",
        "    t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pc = load_clip_probs_test_avg(sid)  # CLIP per-fold temps already applied upstream\n",
        "        pa = load_audio_panns_test_avg(sid) # PANNs per-fold temps already applied upstream\n",
        "        if pa is None:\n",
        "            pa = load_probs_generic(sid, 'audio')\n",
        "            if pa is not None and Ta_mean is not None:\n",
        "                pa = temp_scale_scalar(ensure_CxT(pa), Ta_mean)\n",
        "        pf = fuse_poe_with_clip_keep_len(ps, pc, pa, alpha_clip, gamma_audio)\n",
        "        pf = smooth_probs_box(pf, k=smooth_k)\n",
        "        y = decode_minseg(pf, min_dur.copy()); y = aba_collapse(y, max_len=2)\n",
        "        seq = make_perm20(compress_to_sequence(y), pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    return out_csv\n",
        "\n",
        "# Run two finals and stage g018 per expert advice\n",
        "print('Decoding FINAL m068_g018 ...', flush=True)\n",
        "csv018 = decode_test_with_panns_final(alpha_clip=0.30, gamma_audio=0.18, smooth_k=5, min_mult=0.68, out_csv='submission_final_m068_g018.csv')\n",
        "print('Decoding FINAL m068_g019 ...', flush=True)\n",
        "csv019 = decode_test_with_panns_final(alpha_clip=0.30, gamma_audio=0.19, smooth_k=5, min_mult=0.68, out_csv='submission_final_m068_g019.csv')\n",
        "# Stage OOF-best first (g018) for submission.csv\n",
        "shutil.copyfile(csv018, 'submission.csv')\n",
        "print(f'Staged submission: {csv018} -> submission.csv', flush=True)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying PATCH: canonical skeleton temps + classic-audio fallback temp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding FINAL m068_g018 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_final_m068_g018.csv rows= 95\nDecoding FINAL m068_g019 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_final_m068_g019.csv rows= 95\nStaged submission: submission_final_m068_g018.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "6cb2fe6d-0114-4697-8563-bd5d18fd6dc2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Stage parity-fixed hedge: gamma=0.19\n",
        "import shutil, os, pandas as pd\n",
        "src = 'submission_final_m068_g019.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "sub = pd.read_csv(src)\n",
        "assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "shutil.copyfile(src, dst)\n",
        "print(f'Staged: {src} -> {dst}')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged: submission_final_m068_g019.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "e1c93761-2459-4d21-961f-5f9179f6b242",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final hedge (parity-fixed): gamma=0.22 with m=0.68, smooth_k=5; stage submission\n",
        "import shutil, os, pandas as pd\n",
        "print('Decoding FINAL m068_g022 ...', flush=True)\n",
        "out_csv = 'submission_final_m068_g022.csv'\n",
        "csv022 = decode_test_with_panns_final(alpha_clip=0.30, gamma_audio=0.22, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(csv022), f'Missing {csv022}'\n",
        "sub = pd.read_csv(csv022); assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "shutil.copyfile(csv022, 'submission.csv')\n",
        "print(f'Staged submission: {csv022} -> submission.csv', flush=True)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding FINAL m068_g022 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_final_m068_g022.csv rows= 95\nStaged submission: submission_final_m068_g022.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "ae2229f0-8c01-4913-8d8c-e8386c25c124",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Modality isolation hedge: Skeleton + PANNs only (alpha_clip=0.0), gamma=0.22; stage submission\n",
        "import shutil, os, pandas as pd\n",
        "print('Decoding FINAL skeleton+PANNs only m068_g022 ...', flush=True)\n",
        "out_csv = 'submission_final_sp_only_m068_g022.csv'\n",
        "csv_sp = decode_test_with_panns_final(alpha_clip=0.0, gamma_audio=0.22, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(csv_sp), f'Missing {csv_sp}'\n",
        "sub = pd.read_csv(csv_sp); assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "shutil.copyfile(csv_sp, 'submission.csv')\n",
        "print(f'Staged submission: {csv_sp} -> submission.csv', flush=True)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding FINAL skeleton+PANNs only m068_g022 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_final_sp_only_m068_g022.csv rows= 95\nStaged submission: submission_final_sp_only_m068_g022.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "230d8ac5-681a-4847-8cd3-8d2061e3a868",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Modality isolation hedge: Skeleton + CLIP only (gamma_audio=0.0), alpha_clip=0.30; stage submission\n",
        "import shutil, os, pandas as pd\n",
        "print('Decoding FINAL skeleton+CLIP only m068_a030 ...', flush=True)\n",
        "out_csv = 'submission_final_sc_only_m068_a030.csv'\n",
        "csv_sc = decode_test_with_panns_final(alpha_clip=0.30, gamma_audio=0.0, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(csv_sc), f'Missing {csv_sc}'\n",
        "sub = pd.read_csv(csv_sc); assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "shutil.copyfile(csv_sc, 'submission.csv')\n",
        "print(f'Staged submission: {csv_sc} -> submission.csv', flush=True)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding FINAL skeleton+CLIP only m068_a030 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_final_sc_only_m068_a030.csv rows= 95\nStaged submission: submission_final_sc_only_m068_a030.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "79531241-462c-46fe-bf11-105a572d0a21",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Parity-fixed hedge: min_mult=0.70 with gamma=0.18; stage submission\n",
        "import shutil, os, pandas as pd\n",
        "print('Decoding FINAL m070_g018 ...', flush=True)\n",
        "out_csv = 'submission_final_m070_g018.csv'\n",
        "csv070 = decode_test_with_panns_final(alpha_clip=0.30, gamma_audio=0.18, smooth_k=5, min_mult=0.70, out_csv=out_csv)\n",
        "assert os.path.exists(csv070), f'Missing {csv070}'\n",
        "sub = pd.read_csv(csv070); assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "shutil.copyfile(csv070, 'submission.csv')\n",
        "print(f'Staged submission: {csv070} -> submission.csv', flush=True)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding FINAL m070_g018 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_final_m070_g018.csv rows= 95\nStaged submission: submission_final_m070_g018.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "73fdb685-e7a8-4864-8533-de8f85454e46",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick final decode per expert: gamma=0.25 at min_mult=0.68 (keep_len PoE), smooth_k=5; stage submission\n",
        "import os, shutil, pandas as pd\n",
        "print('Decoding FINAL m068_g025 ...', flush=True)\n",
        "out_csv = 'submission_final_m068_g025.csv'\n",
        "csv025 = decode_test_with_panns_final(alpha_clip=0.30, gamma_audio=0.25, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(csv025), f'Missing {csv025}'\n",
        "sub = pd.read_csv(csv025); assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "shutil.copyfile(csv025, 'submission.csv')\n",
        "print(f'Staged submission: {csv025} -> submission.csv', flush=True)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding FINAL m068_g025 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_final_m068_g025.csv rows= 95\nStaged submission: submission_final_m068_g025.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "ff1a8674-b8f1-4ac1-9153-463c5a4781ac",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Best-of-2 per-sequence selection: Full (S+CLIP+PANNs) vs Audio-only (S+PANNs), keep_len PoE, parity-fixed\n",
        "import numpy as np, pandas as pd, json, time, os, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def _load_temp_num(path: str):\n",
        "    p = Path(path)\n",
        "    if not p.exists(): return None\n",
        "    try:\n",
        "        return float(json.load(open(path,'r')).get('T', 1.0))\n",
        "    except Exception:\n",
        "        try: return float(open(path).read().strip())\n",
        "        except Exception: return None\n",
        "\n",
        "def total_emission_loglik(y: np.ndarray, p: np.ndarray) -> float:\n",
        "    C,T = p.shape\n",
        "    idx = np.clip(y, 0, C-1).astype(np.int32)\n",
        "    cols = np.arange(T, dtype=np.int32)\n",
        "    probs = np.clip(p[idx, cols], 1e-12, 1.0)\n",
        "    return float(np.log(probs).sum())\n",
        "\n",
        "def decode_test_bestof2_keep_len(out_csv='submission_bestof2_full_vs_audio.csv',\n",
        "                                 a_full=0.30, g_full=0.22,\n",
        "                                 a_audio=0.0, g_audio=0.22,\n",
        "                                 min_mult=0.68, smooth_k=5):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids = sorted({int(x) for fd in folds for x in fd['train_ids']})\n",
        "    med = compute_min_dur_from_ids(all_train_ids)\n",
        "    min_dur = np.floor(med*min_mult + 0.5).astype(np.int32); min_dur[0]=0\n",
        "    # classic-audio temp mean as fallback if PANNs missing\n",
        "    Ta_vals = [_load_temp_num(f'audio_temp_fold{f}.json') for f in (0,1,2)]\n",
        "    Ta_vals = [t for t in Ta_vals if t is not None]\n",
        "    Ta_mean = float(np.mean(Ta_vals)) if Ta_vals else None\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    ids,rows=[],[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        sid=int(sid)\n",
        "        ps = load_skeleton_probs(sid)\n",
        "        pc = load_clip_probs_test_avg(sid)  # CLIP per-fold temps already applied upstream\n",
        "        pa = load_audio_panns_test_avg(sid) # PANNs per-fold temps already applied upstream\n",
        "        if pa is None:\n",
        "            pa = load_probs_generic(sid, 'audio')\n",
        "            if pa is not None and Ta_mean is not None:\n",
        "                pa = temp_scale_scalar(ensure_CxT(pa), Ta_mean)\n",
        "        # Candidate A: Full (S+CLIP+Audio)\n",
        "        pf_full = fuse_poe_with_clip_keep_len(ps, pc, pa, a_full, g_full)\n",
        "        pf_full = smooth_probs_box(pf_full, k=smooth_k)\n",
        "        y_full = decode_minseg(pf_full, min_dur.copy()); y_full = aba_collapse(y_full, max_len=2)\n",
        "        ll_full = total_emission_loglik(y_full, pf_full)\n",
        "        seq_full = make_perm20(compress_to_sequence(y_full), pf_full)\n",
        "        # Candidate B: Audio-only (S+Audio)\n",
        "        pf_aud = fuse_poe_with_clip_keep_len(ps, None, pa, a_audio, g_audio)\n",
        "        pf_aud = smooth_probs_box(pf_aud, k=smooth_k)\n",
        "        y_aud = decode_minseg(pf_aud, min_dur.copy()); y_aud = aba_collapse(y_aud, max_len=2)\n",
        "        ll_aud = total_emission_loglik(y_aud, pf_aud)\n",
        "        seq_aud = make_perm20(compress_to_sequence(y_aud), pf_aud)\n",
        "        # Pick higher LL\n",
        "        if ll_full >= ll_aud:\n",
        "            seq = seq_full\n",
        "        else:\n",
        "            seq = seq_aud\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'Decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub))\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Staged submission: {out_csv} -> submission.csv', flush=True)\n",
        "\n",
        "print('Decoding TEST: Best-of-2 selection (Full vs Audio-only)...', flush=True)\n",
        "decode_test_bestof2_keep_len(out_csv='submission_bestof2_full_vs_audio.csv',\n",
        "                             a_full=0.30, g_full=0.22, a_audio=0.0, g_audio=0.22,\n",
        "                             min_mult=0.68, smooth_k=5)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding TEST: Best-of-2 selection (Full vs Audio-only)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_bestof2_full_vs_audio.csv rows= 95\nStaged submission: submission_bestof2_full_vs_audio.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "e1b588f7-21cd-4773-b2e6-82ddaea76f5b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick hedge: decode FINAL with gamma=0.26 at min_mult=0.68 (keep_len PoE), smooth_k=5; stage submission\n",
        "import os, shutil, pandas as pd\n",
        "print('Decoding FINAL m068_g026 ...', flush=True)\n",
        "out_csv = 'submission_final_m068_g026.csv'\n",
        "csv026 = decode_test_with_panns_final(alpha_clip=0.30, gamma_audio=0.26, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(csv026), f'Missing {csv026}'\n",
        "sub = pd.read_csv(csv026); assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "shutil.copyfile(csv026, 'submission.csv')\n",
        "print(f'Staged submission: {csv026} -> submission.csv', flush=True)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding FINAL m068_g026 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_final_m068_g026.csv rows= 95\nStaged submission: submission_final_m068_g026.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "1a3404d9-8302-4830-a00d-291b2dd15516",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick hedge per expert Option A: gamma=0.26, min_mult=0.70 (keep_len PoE), smooth_k=5; stage submission\n",
        "import os, shutil, pandas as pd\n",
        "print('Decoding FINAL m070_g026 ...', flush=True)\n",
        "out_csv = 'submission_final_m070_g026.csv'\n",
        "csv = decode_test_with_panns_final(alpha_clip=0.30, gamma_audio=0.26, smooth_k=5, min_mult=0.70, out_csv=out_csv)\n",
        "assert os.path.exists(csv), f'Missing {csv}'\n",
        "sub = pd.read_csv(csv); assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "shutil.copyfile(csv, 'submission.csv')\n",
        "print(f'Staged submission: {csv} -> submission.csv', flush=True)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding FINAL m070_g026 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_final_m070_g026.csv rows= 95\nStaged submission: submission_final_m070_g026.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "7ad2e3d9-b970-41e0-a79e-41bcef6063d0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Stage precomputed hedge: MinSeg majority vote over m={0.60,0.70,0.80}\n",
        "import shutil, os\n",
        "src = 'submission_minseg_mv_m060_070_080.csv'\n",
        "dst = 'submission.csv'\n",
        "if os.path.exists(src):\n",
        "    shutil.copyfile(src, dst)\n",
        "    print(f'Staged: {src} -> {dst}')\n",
        "else:\n",
        "    print(f'Missing {src}; no staging performed.')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staged: submission_minseg_mv_m060_070_080.csv -> submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "191d8553-fad2-45b7-8b4b-d5b138519bee",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick hedge: decode FINAL with gamma=0.24 at min_mult=0.68 (keep_len PoE), smooth_k=5; stage submission\n",
        "import os, shutil, pandas as pd\n",
        "print('Decoding FINAL m068_g024 ...', flush=True)\n",
        "out_csv = 'submission_final_m068_g024.csv'\n",
        "csv024 = decode_test_with_panns_final(alpha_clip=0.30, gamma_audio=0.24, smooth_k=5, min_mult=0.68, out_csv=out_csv)\n",
        "assert os.path.exists(csv024), f'Missing {csv024}'\n",
        "sub = pd.read_csv(csv024); assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "shutil.copyfile(csv024, 'submission.csv')\n",
        "print(f'Staged submission: {csv024} -> submission.csv', flush=True)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding FINAL m068_g024 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 20/95 elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 40/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 60/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 80/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded 95/95 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_final_m068_g024.csv rows= 95\nStaged submission: submission_final_m068_g024.csv -> submission.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}