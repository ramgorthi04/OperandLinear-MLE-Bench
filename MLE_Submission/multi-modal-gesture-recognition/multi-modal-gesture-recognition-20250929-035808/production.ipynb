{
  "cells": [
    {
      "id": "dd61bde4-1000-4bf4-940b-a35bb51108f5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build 3-fold Grouped CV by source archive (leave-one-tar-out) and save folds\n",
        "import os, io, tarfile, zipfile, json, sys, time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "print('=== Building archive-grouped CV folds (training1/2/3) ===', flush=True)\n",
        "CWD = Path('.')\n",
        "TRAIN_TARS = [CWD/'training1.tar.gz', CWD/'training2.tar.gz', CWD/'training3.tar.gz']\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "train_ids = set(train_df['Id'].astype(int).tolist())\n",
        "\n",
        "def tar_members_ids(tarpath: Path):\n",
        "    ids = set()\n",
        "    with tarfile.open(tarpath, 'r:*') as tf:\n",
        "        for m in tf:\n",
        "            if not m.isreg():\n",
        "                continue\n",
        "            nm = m.name.lstrip('./')\n",
        "            if nm.endswith('.zip') and nm.startswith('Sample') and len(nm) >= len('Sample00001.zip'):\n",
        "                try:\n",
        "                    sid = int(nm[6:11])\n",
        "                    if sid in train_ids:\n",
        "                        ids.add(sid)\n",
        "                except Exception:\n",
        "                    pass\n",
        "    return ids\n",
        "\n",
        "groups = {}  # id -> group (1,2,3)\n",
        "tar_id_sets = []\n",
        "for gi, tp in enumerate(TRAIN_TARS, start=1):\n",
        "    if not tp.exists():\n",
        "        print(f'WARNING: missing {tp}', flush=True)\n",
        "        tar_id_sets.append(set());\n",
        "        continue\n",
        "    s = tar_members_ids(tp); tar_id_sets.append(s)\n",
        "    for sid in s:\n",
        "        groups[sid] = gi\n",
        "\n",
        "# Sanity: all training ids should appear in one of the tars\n",
        "miss = sorted([sid for sid in train_ids if sid not in groups])\n",
        "if miss:\n",
        "    print(f'WARNING: {len(miss)} training Ids not found in any training*.tar.gz e.g., {miss[:10]}', flush=True)\n",
        "\n",
        "# Build 3 folds: each fold validates on one tar, trains on the other two\n",
        "folds = []\n",
        "for holdout_idx in range(3):\n",
        "    val_ids = sorted(tar_id_sets[holdout_idx])\n",
        "    tr_ids = sorted(set().union(*[tar_id_sets[j] for j in range(3) if j != holdout_idx]))\n",
        "    folds.append({'fold': holdout_idx, 'train_ids': tr_ids, 'val_ids': val_ids})\n",
        "\n",
        "# Save id->tar map and folds\n",
        "pd.DataFrame({'Id': list(groups.keys()), 'archive_group': [groups[i] for i in groups.keys()]}).to_csv('id_to_archive.csv', index=False)\n",
        "with open('folds_archive_cv.json', 'w') as f:\n",
        "    json.dump(folds, f)\n",
        "\n",
        "# Print summary\n",
        "print('Fold sizes:')\n",
        "for f in folds:\n",
        "    print(f\"  fold={f['fold']} train={len(f['train_ids'])} val={len(f['val_ids'])}\")\n",
        "cover = set().union(*tar_id_sets) if tar_id_sets else set()\n",
        "print(f'Total train_ids={len(train_ids)}; covered_by_tars={len(cover)}; unmatched={len(train_ids-cover)}')\n",
        "print('Saved: id_to_archive.csv, folds_archive_cv.json', flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "623bf650-2cff-4a9f-af48-5dcd629572b2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Grouped-CV OOF eval + probs caching + small grid over decoder/blend (per expert plan)\n",
        "import os, json, time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA:', torch.cuda.is_available(), flush=True)\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "\n",
        "# Load folds and training sequences\n",
        "folds = json.load(open('folds_archive_cv.json', 'r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p); X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    # compute per-class median frame durations using ONLY the provided training ids (no leakage)\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum())\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "\n",
        "# Minimal model defs for loading checkpoints\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []\n",
        "        dil = 1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h\n",
        "            h = blk(h)\n",
        "            h = h + res\n",
        "        logits = self.head(h)\n",
        "        return logits.transpose(1,2)\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.3, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x)\n",
        "        h = self.gn1(h)\n",
        "        h = F.relu(h, inplace=True)\n",
        "        h = self.drop(h)\n",
        "        h = self.conv2(h)\n",
        "        h = self.gn2(h)\n",
        "        h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class Stage(nn.Module):\n",
        "    def __init__(self, in_ch, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(in_ch, ch, 1)\n",
        "        blocks = []\n",
        "        dil = 1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(ch, dil, drop=drop))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(ch, 21, 1)\n",
        "    def forward(self, x):\n",
        "        h = self.inp(x)\n",
        "        for b in self.blocks:\n",
        "            h = b(h)\n",
        "        return self.head(h)\n",
        "\n",
        "class MSTCNPP(nn.Module):\n",
        "    def __init__(self, d_in, stages=4, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Conv1d(d_in, d_in, 1)\n",
        "        self.stages = nn.ModuleList()\n",
        "        self.stages.append(Stage(d_in, ch=ch, layers=layers, drop=drop))\n",
        "        for _ in range(stages-1):\n",
        "            self.stages.append(Stage(21, ch=ch, layers=layers, drop=drop))\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        x = self.input_proj(x)\n",
        "        logits_list = []\n",
        "        prev = self.stages[0](x)\n",
        "        logits_list.append(prev.transpose(1,2))\n",
        "        for s in range(1, len(self.stages)):\n",
        "            probs = prev.softmax(dim=1)\n",
        "            prev = self.stages[s](probs)\n",
        "            logits_list.append(prev.transpose(1,2))\n",
        "        return logits_list\n",
        "\n",
        "def load_models():\n",
        "    ce_paths=[\"model_ce_tcn_s0.pth\",\"model_ce_tcn_s1.pth\",\"model_ce_tcn_s2.pth\"]\n",
        "    ms_path=\"model_mstcnpp_s2.pth\"\n",
        "    for p in ce_paths+[ms_path]:\n",
        "        assert Path(p).exists(), f\"Missing {p}\"\n",
        "    ce_models=[]\n",
        "    for p in ce_paths:\n",
        "        m = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device))\n",
        "        m.eval()\n",
        "        ce_models.append(m)\n",
        "    ms = MSTCNPP(d_in=D_in, stages=4, ch=128, layers=10, drop=0.3).to(device)\n",
        "    ms.load_state_dict(torch.load(ms_path, map_location=device))\n",
        "    ms.eval()\n",
        "    return ce_models, ms\n",
        "\n",
        "def time_warp_probs(p_t_c: torch.Tensor, factor: float) -> torch.Tensor:\n",
        "    T, C = p_t_c.shape\n",
        "    tgt_len = max(1, int(round(T*factor)))\n",
        "    x = p_t_c.T.unsqueeze(0)\n",
        "    y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False)\n",
        "    y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T\n",
        "    y2 = y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    return y2\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        ps = time_warp_probs(p_t_c, s)\n",
        "        acc = ps if acc is None else (acc + ps)\n",
        "    out = acc / float(len(factors))\n",
        "    out = out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    return out\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    # ensure SAME-length output even for even kernels\n",
        "    k = max(1, int(k))\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    pad = (k-1)//2\n",
        "    y = F.conv1d(x, w, padding=pad)\n",
        "    y = y.view(-1)\n",
        "    T = p_t.shape[0]\n",
        "    if y.shape[0] < T:\n",
        "        y = F.pad(y, (0, T - y.shape[0]))\n",
        "    elif y.shape[0] > T:\n",
        "        y = y[:T]\n",
        "    return y\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w)\n",
        "    b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]\n",
        "    s = seg.sum() + 1e-8\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def decode_peaks(p_t_c: torch.Tensor, med_k: dict, gamma: float = 1.0, pool_k=13, temp=0.9):\n",
        "    # refined peak-time decoder with per-fold duration priors (no leakage) and gamma scaling\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp))\n",
        "        p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    T, C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    ks = [13]*C\n",
        "    for c in range(C):\n",
        "        if c==0:\n",
        "            scores[:,c] = p_s[:,c]\n",
        "            ks[c] = 13\n",
        "            continue\n",
        "        base_k = med_k.get(c, 13)\n",
        "        k = int(np.clip(round(gamma * base_k), 9, 25))\n",
        "        if k % 2 == 0:\n",
        "            k = min(25, k + 1)  # force odd to keep same length\n",
        "        ks[c] = k\n",
        "        scores[:,c] = duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        k = ks[c]\n",
        "        w_com = max(5, k//3)\n",
        "        radius = max(10, k//2)\n",
        "        s = scores[:,c]\n",
        "        t_star = int(torch.argmax(s).item())\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=w_com)\n",
        "        t_idx = int(round(t_ref))\n",
        "        t_idx = min(max(t_idx,0), T-1)\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        pooled_at_ref = p_s[t_idx, c].item()\n",
        "        peaks.append([c, t_ref, float(scores[t_idx,c].item()), float(local_mean), float(pooled_at_ref)])\n",
        "    # sort by time then by score then local mean then pooled prob\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3], -x[4]))\n",
        "    # enforce minimum separation >=2 frames and strictly increasing timestamps\n",
        "    last_t = -1e9\n",
        "    for i in range(len(peaks)):\n",
        "        if peaks[i][1] <= last_t:\n",
        "            peaks[i][1] = last_t + 2.0\n",
        "        last_t = min(peaks[i][1], float(T-1))\n",
        "    return [int(c) for c,_,_,_,_ in peaks]\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "def cache_probs_for_id(sid:int, ce_models, ms_model):\n",
        "    # cache CE-avg and MS probs (without TTA), to speed grid sweeps\n",
        "    ce_out=probs_cache/f\"{sid}_ce.npy\"; ms_out=probs_cache/f\"{sid}_ms.npy\"\n",
        "    if ce_out.exists() and ms_out.exists():\n",
        "        return\n",
        "    X=load_feat(sid,'train',1800); xb=torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        # CE avg\n",
        "        ce_sum=None\n",
        "        for m in ce_models:\n",
        "            p=m(xb)[0].softmax(dim=-1)\n",
        "            ce_sum = p if ce_sum is None else (ce_sum + p)\n",
        "        ce = (ce_sum/len(ce_models)).cpu().numpy()\n",
        "        # MS last stage\n",
        "        p_ms = ms_model(xb)[-1][0].softmax(dim=-1).cpu().numpy()\n",
        "    np.save(ce_out, ce); np.save(ms_out, p_ms)\n",
        "\n",
        "def load_cached_probs(sid:int):\n",
        "    ce=np.load(probs_cache/f\"{sid}_ce.npy\"); ms=np.load(probs_cache/f\"{sid}_ms.npy\")\n",
        "    return torch.from_numpy(ce).to(device), torch.from_numpy(ms).to(device)\n",
        "\n",
        "# Global TTA factors (wider) used consistently in CV and test-time\n",
        "TTA_FACTORS = (0.85, 0.9, 1.0, 1.1, 1.15)\n",
        "\n",
        "def blend_probs(ce_torch: torch.Tensor, ms_torch: torch.Tensor, w_ce=0.9, temp_ms: float = 1.0):\n",
        "    # geometric mean in prob-space via log domain, with optional MS temperature\n",
        "    if temp_ms!=1.0:\n",
        "        ms_torch = (ms_torch ** (1.0/temp_ms)); ms_torch = ms_torch/(ms_torch.sum(dim=-1,keepdim=True)+1e-8)\n",
        "    log_ce = torch.log(ce_torch+1e-8); log_ms=torch.log(ms_torch+1e-8)\n",
        "    comb = torch.exp(w_ce*log_ce + (1.0-w_ce)*log_ms)\n",
        "    return comb/(comb.sum(dim=-1,keepdim=True)+1e-8)\n",
        "\n",
        "print('Loading models...', flush=True)\n",
        "ce_models, ms_model = load_models()\n",
        "\n",
        "# Pre-cache val probs for all folds\n",
        "t0=time.time()\n",
        "for f in folds:\n",
        "    vids = f['val_ids']\n",
        "    print(f\"[Cache] fold={f['fold']} val_ids={len(vids)}\", flush=True)\n",
        "    for i, sid in enumerate(vids, 1):\n",
        "        cache_probs_for_id(int(sid), ce_models, ms_model)\n",
        "        if (i%25)==0 or i==len(vids):\n",
        "            print(f\"  cached {i}/{len(vids)} (elapsed {time.time()-t0:.1f}s)\", flush=True)\n",
        "\n",
        "# Small grid over decoder and blend settings WITH per-fold priors and gamma scale\n",
        "pool_ks=[11,13,15]; temps=[0.90,0.95,1.00]; w_ces=[0.95]; gammas=[0.90,0.95,0.975,1.00,1.025,1.05,1.10]\n",
        "\n",
        "# cache med_k per fold to avoid recomputation\n",
        "med_cache = {}  # fold_idx -> med_k dict\n",
        "\n",
        "def eval_setting_on_fold(fold, use_ms: bool, pool_k:int, temp:float, gamma: float, w_ce:float=0.95, temp_ms:float=1.0):\n",
        "    fold_idx = fold['fold']\n",
        "    if fold_idx not in med_cache:\n",
        "        med_cache[fold_idx] = compute_class_median_durations_for_ids(fold['train_ids'])\n",
        "    med_k = med_cache[fold_idx]\n",
        "    vids = fold['val_ids']; tot=0; cnt=0\n",
        "    for sid in vids:\n",
        "        ce, ms = load_cached_probs(int(sid))\n",
        "        probs = ce if not use_ms else blend_probs(ce, ms, w_ce=w_ce, temp_ms=temp_ms)\n",
        "        probs = apply_tta_timewarp(probs, factors=TTA_FACTORS)\n",
        "        seq = decode_peaks(probs, med_k=med_k, gamma=gamma, pool_k=pool_k, temp=temp)\n",
        "        tot += levenshtein(seq, id2seq[int(sid)]); cnt += 1\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "def sweep(use_ms: bool):\n",
        "    results=[]\n",
        "    for pool_k in pool_ks:\n",
        "        for temp in temps:\n",
        "            for gamma in gammas:\n",
        "                if use_ms:\n",
        "                    for w_ce in w_ces:\n",
        "                        per_fold=[]\n",
        "                        for f in folds:\n",
        "                            lev = eval_setting_on_fold(f, True, pool_k, temp, gamma=gamma, w_ce=w_ce, temp_ms=0.95)\n",
        "                            per_fold.append(lev)\n",
        "                        results.append((np.mean(per_fold), np.max(per_fold), {'pool_k':pool_k,'temp':temp,'gamma':gamma,'w_ce':w_ce,'use_ms':True}))\n",
        "                else:\n",
        "                    per_fold=[]\n",
        "                    for f in folds:\n",
        "                        lev = eval_setting_on_fold(f, False, pool_k, temp, gamma=gamma)\n",
        "                        per_fold.append(lev)\n",
        "                    results.append((np.mean(per_fold), np.max(per_fold), {'pool_k':pool_k,'temp':temp,'gamma':gamma,'use_ms':False}))\n",
        "    results.sort(key=lambda x: (x[1], x[0]))  # prioritize worst-fold, then mean\n",
        "    return results\n",
        "\n",
        "print('Sweeping CE-only...', flush=True)\n",
        "res_ce = sweep(False)\n",
        "print('Top CE-only (mean, worst, cfg):')\n",
        "for r in res_ce[:5]:\n",
        "    print(r)\n",
        "\n",
        "print('Sweeping CE+MS (geom, CE-heavy)...', flush=True)\n",
        "res_ms = sweep(True)\n",
        "print('Top CE+MS (mean, worst, cfg):')\n",
        "for r in res_ms[:5]:\n",
        "    print(r)\n",
        "\n",
        "# Save sweep results\n",
        "pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res_ce]).to_csv('cv_sweep_ce.csv', index=False)\n",
        "pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res_ms]).to_csv('cv_sweep_ce_ms.csv', index=False)\n",
        "print('Saved cv_sweep_ce.csv and cv_sweep_ce_ms.csv', flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "343c0940-90cc-495b-a419-ba726e3644f9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build submissions: primary (CE+MS geom, CE-heavy) and backup (CE-only) using grouped-CV tuned settings\n",
        "import pandas as pd, numpy as np, time, torch, torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "\n",
        "def load_feat_test(sample_id: int, max_T=1800):\n",
        "    p = (feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p); X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "# Read best configs (sorted by worst then mean earlier)\n",
        "cfg_ce = pd.read_csv('cv_sweep_ce.csv').sort_values(['worst','mean']).iloc[0].to_dict()\n",
        "cfg_ms = pd.read_csv('cv_sweep_ce_ms.csv').sort_values(['worst','mean']).iloc[0].to_dict()\n",
        "print('Chosen CE-only cfg:', cfg_ce)\n",
        "print('Chosen CE+MS cfg:', cfg_ms)\n",
        "\n",
        "# Compute test-time priors from ALL training ids (non-leaky), and extract gammas\n",
        "train_ids_all = pd.read_csv('training.csv')['Id'].astype(int).tolist()\n",
        "med_k_test = compute_class_median_durations_for_ids(train_ids_all)\n",
        "gamma_ce = float(cfg_ce.get('gamma', 1.0))\n",
        "gamma_ms = float(cfg_ms.get('gamma', 1.0))\n",
        "\n",
        "# Ensure models available from previous cell; otherwise load\n",
        "try:\n",
        "    ce_models, ms_model\n",
        "except NameError:\n",
        "    ce_models, ms_model = load_models()\n",
        "\n",
        "def ensemble_ce_probs_from_models(xb, ce_models):\n",
        "    with torch.no_grad():\n",
        "        acc=None\n",
        "        for m in ce_models:\n",
        "            p = m(xb)[0].softmax(dim=-1)\n",
        "            acc = p if acc is None else (acc + p)\n",
        "        probs = acc/len(ce_models)\n",
        "        return probs/(probs.sum(dim=-1,keepdim=True)+1e-8)\n",
        "\n",
        "def blend_probs_geom(ce_prob: torch.Tensor, ms_prob: torch.Tensor, w_ce=0.9, temp_ms=0.95):\n",
        "    if temp_ms!=1.0:\n",
        "        ms_prob = (ms_prob ** (1.0/temp_ms)); ms_prob = ms_prob/(ms_prob.sum(dim=-1,keepdim=True)+1e-8)\n",
        "    log_ce = torch.log(ce_prob+1e-8); log_ms=torch.log(ms_prob+1e-8)\n",
        "    comb = torch.exp(w_ce*log_ce + (1.0-w_ce)*log_ms)\n",
        "    return comb/(comb.sum(dim=-1,keepdim=True)+1e-8)\n",
        "\n",
        "# Consistent wider TTA factors with CV\n",
        "TTA_FACTORS = (0.85, 0.9, 1.0, 1.1, 1.15)\n",
        "\n",
        "# Backup submission: CE-only\n",
        "rows_ce=[]; t0=time.time()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    X = load_feat_test(int(sid), 1800)\n",
        "    xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "    ce_prob = ensemble_ce_probs_from_models(xb, ce_models)\n",
        "    probs = apply_tta_timewarp(ce_prob, factors=TTA_FACTORS)\n",
        "    seq = decode_peaks(probs, med_k=med_k_test, gamma=gamma_ce, pool_k=int(cfg_ce['pool_k']), temp=float(cfg_ce['temp']))\n",
        "    rows_ce.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if (i%10)==0 or i==len(test_ids):\n",
        "        print(f\"  [infer CE-only] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub_ce = pd.DataFrame(rows_ce, columns=['Id','Sequence'])\n",
        "assert len(sub_ce)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub_ce.Sequence), 'CE-only submission format invalid'\n",
        "sub_ce.to_csv('submission_backup_ce_only.csv', index=False)\n",
        "print('Wrote submission_backup_ce_only.csv; head:\\n', sub_ce.head())\n",
        "\n",
        "# Primary submission: CE+MS geometric mean, CE-heavy\n",
        "rows_ms=[]; t0=time.time()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    X = load_feat_test(int(sid), 1800)\n",
        "    xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        ce_prob = ensemble_ce_probs_from_models(xb, ce_models)\n",
        "        ms_prob = ms_model(xb)[-1][0].softmax(dim=-1)\n",
        "    probs = blend_probs_geom(ce_prob, ms_prob, w_ce=float(cfg_ms.get('w_ce', 0.95)), temp_ms=0.95)\n",
        "    probs = apply_tta_timewarp(probs, factors=TTA_FACTORS)\n",
        "    seq = decode_peaks(probs, med_k=med_k_test, gamma=gamma_ms, pool_k=int(cfg_ms['pool_k']), temp=float(cfg_ms['temp']))\n",
        "    rows_ms.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if (i%10)==0 or i==len(test_ids):\n",
        "        print(f\"  [infer CE+MS] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub_ms = pd.DataFrame(rows_ms, columns=['Id','Sequence'])\n",
        "assert len(sub_ms)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub_ms.Sequence), 'CE+MS submission format invalid'\n",
        "sub_ms.to_csv('submission_primary_ce_ms.csv', index=False)\n",
        "sub_ms.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission_primary_ce_ms.csv and submission.csv; head:\\n', sub_ms.head())\n",
        "print('Done building submissions.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "e0e63345-3b60-4da7-883a-dbeab8bd6eff",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fallback: use CE-only backup submission as final submission.csv\n",
        "import pandas as pd, shutil, os\n",
        "src = 'submission_backup_ce_only.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), 'Missing CE-only backup submission file'\n",
        "shutil.copyfile(src, dst)\n",
        "df = pd.read_csv(dst).head()\n",
        "print('submission.csv head (CE-only backup):\\n', df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "9c5fab5b-ed84-4c4f-a090-a86d4e25693e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspect features3d_v2 to decide if we can append cheap scalars (scale_ema diffs, hand curvature)\n",
        "import numpy as np, json, random\n",
        "from pathlib import Path\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "paths = sorted(feat_tr_dir.glob('*.npz'))\n",
        "assert len(paths)==297, f'Expected 297 train npz, got {len(paths)}'\n",
        "p = paths[0]\n",
        "d = np.load(p)\n",
        "print('Keys:', list(d.keys()))\n",
        "X = d['X']\n",
        "print('Shape X:', X.shape, 'dtype:', X.dtype)\n",
        "if 'meta' in d.files:\n",
        "    try:\n",
        "        meta = json.loads(d['meta'].tobytes().decode('utf-8')) if hasattr(d['meta'], 'tobytes') else d['meta'].item()\n",
        "        print('Meta example:', str(meta)[:200])\n",
        "    except Exception as e:\n",
        "        print('Meta parse failed:', e)\n",
        "\n",
        "# Peek several samples to estimate typical T and D\n",
        "Ds = []; Ts = []\n",
        "for q in random.sample(paths, k=min(5, len(paths))):\n",
        "    Xq = np.load(q)['X']\n",
        "    Ts.append(Xq.shape[0]); Ds.append(Xq.shape[1])\n",
        "print('Sampled T range:', (min(Ts), max(Ts)), 'D unique:', sorted(set(Ds)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "267ad90e-b7ff-49f9-8cff-455dae0f1911",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Robust primary submission: CE+MS with per-sample fallback to CE-only to avoid hangs (now with priors + gamma)\n",
        "import pandas as pd, numpy as np, time, torch, os\n",
        "from pathlib import Path\n",
        "\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "\n",
        "def load_feat_test(sample_id: int, max_T=1800):\n",
        "    d = np.load((feat_te_dir/f\"{sample_id}.npz\")); X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "# Load best configs\n",
        "cfg_ce = pd.read_csv('cv_sweep_ce.csv').sort_values(['worst','mean']).iloc[0].to_dict()\n",
        "cfg_ms = pd.read_csv('cv_sweep_ce_ms.csv').sort_values(['worst','mean']).iloc[0].to_dict()\n",
        "w_ce = float(cfg_ms.get('w_ce', 0.95)); pool_k_ms = int(cfg_ms['pool_k']); temp_msdec = float(cfg_ms['temp'])\n",
        "pool_k_ce = int(cfg_ce['pool_k']); temp_cedec = float(cfg_ce['temp'])\n",
        "gamma_ce = float(cfg_ce.get('gamma', 1.0)); gamma_ms = float(cfg_ms.get('gamma', 1.0))\n",
        "print('Using cfg CE:', cfg_ce, '\\nUsing cfg CE+MS:', cfg_ms, flush=True)\n",
        "\n",
        "# Compute non-leaky test-time priors from ALL training ids once\n",
        "train_ids_all = pd.read_csv('training.csv')['Id'].astype(int).tolist()\n",
        "med_k_test = compute_class_median_durations_for_ids(train_ids_all)\n",
        "\n",
        "try:\n",
        "    ce_models, ms_model\n",
        "except NameError:\n",
        "    ce_models, ms_model = load_models()\n",
        "\n",
        "def ensemble_ce_probs_from_models(xb, ce_models):\n",
        "    with torch.no_grad():\n",
        "        acc=None\n",
        "        for m in ce_models:\n",
        "            p = m(xb)[0].softmax(dim=-1)\n",
        "            acc = p if acc is None else (acc + p)\n",
        "        probs = acc/len(ce_models)\n",
        "        return probs/(probs.sum(dim=-1,keepdim=True)+1e-8)\n",
        "\n",
        "def blend_probs_geom(ce_prob: torch.Tensor, ms_prob: torch.Tensor, w_ce=0.95, temp_ms=0.95):\n",
        "    if temp_ms!=1.0:\n",
        "        ms_prob = (ms_prob ** (1.0/temp_ms)); ms_prob = ms_prob/(ms_prob.sum(dim=-1,keepdim=True)+1e-8)\n",
        "    log_ce = torch.log(ce_prob+1e-8); log_ms=torch.log(ms_prob+1e-8)\n",
        "    comb = torch.exp(w_ce*log_ce + (1.0-w_ce)*log_ms)\n",
        "    return comb/(comb.sum(dim=-1,keepdim=True)+1e-8)\n",
        "\n",
        "rows=[]; t0=time.time(); failures=0\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    X = load_feat_test(int(sid), 1800)\n",
        "    xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        ce_prob = ensemble_ce_probs_from_models(xb, ce_models)\n",
        "        use_ms = True\n",
        "        try:\n",
        "            ms_prob = ms_model(xb)[-1][0].softmax(dim=-1)\n",
        "        except Exception as e:\n",
        "            use_ms = False; failures += 1\n",
        "    if use_ms:\n",
        "        probs = blend_probs_geom(ce_prob, ms_prob, w_ce=w_ce, temp_ms=0.95)\n",
        "        probs = apply_tta_timewarp(probs, factors=(0.9,1.0,1.1))\n",
        "        seq = decode_peaks(probs, med_k=med_k_test, gamma=gamma_ms, pool_k=pool_k_ms, temp=temp_msdec)\n",
        "    else:\n",
        "        probs = apply_tta_timewarp(ce_prob, factors=(0.9,1.0,1.1))\n",
        "        seq = decode_peaks(probs, med_k=med_k_test, gamma=gamma_ce, pool_k=pool_k_ce, temp=temp_cedec)\n",
        "    rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if (i%10)==0 or i==len(test_ids):\n",
        "        print(f\"  [robust CE+MS] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m fails={failures}\", flush=True)\n",
        "\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "sub.to_csv('submission_primary_ce_ms_fallback.csv', index=False)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission_primary_ce_ms_fallback.csv and submission.csv; head:\\n', sub.head(), flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "2b825261-fad5-447a-a26a-3a6b98eee6e7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train CE-only DilatedTCN per fold under grouped CV (expert spec)\n",
        "import os, json, math, time, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "assert torch.cuda.is_available(), 'GPU required for timely training'\n",
        "torch.backends.cudnn.benchmark = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "\n",
        "# Model per expert spec\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, 1)\n",
        "        blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for b in self.blocks:\n",
        "            h = b(h)\n",
        "        out = self.head(h)\n",
        "        return out.transpose(1,2)  # B,T,C\n",
        "\n",
        "# EMA helper\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[n] = p.detach().clone()\n",
        "    @torch.no_grad()\n",
        "    def update(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[n].mul_(self.decay).add_(p.detach(), alpha=1.0 - self.decay)\n",
        "    def apply_to(self, model):\n",
        "        self.backup = {}\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.backup[n] = p.detach().clone()\n",
        "                p.data.copy_(self.shadow[n].data)\n",
        "    def restore(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                p.data.copy_(self.backup[n].data)\n",
        "\n",
        "# Data utils\n",
        "def load_feat_full(sample_id: int):\n",
        "    d = np.load((feat_tr_dir/f\"{sample_id}.npz\"))\n",
        "    X = d['X'].astype(np.float32)  # full length, no truncation\n",
        "    return X\n",
        "def load_labels(sample_id: int):\n",
        "    y = np.load(lab_tr_dir/f\"{sample_id}.npy\").astype(np.int64)\n",
        "    return y\n",
        "\n",
        "def compute_fold_scaler(id_list):\n",
        "    # Running mean/var across frames for numerical stability\n",
        "    n = 0\n",
        "    mean = None\n",
        "    M2 = None\n",
        "    for sid in id_list:\n",
        "        X = load_feat_full(int(sid))\n",
        "        n_i = X.shape[0]\n",
        "        if mean is None:\n",
        "            mean = X.mean(axis=0)\n",
        "            M2 = ((X - mean)**2).sum(axis=0)\n",
        "            n = n_i\n",
        "        else:\n",
        "            # combine two sets\n",
        "            mean_i = X.mean(axis=0)\n",
        "            n_new = n + n_i\n",
        "            delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new))\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new))\n",
        "            n = n_new\n",
        "    var = M2 / max(1, (n - 1))\n",
        "    std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def compute_class_weights(train_ids):\n",
        "    # per-frame frequency over 21 classes (0..20); cap class 0 weight\n",
        "    counts = np.zeros(21, dtype=np.int64)\n",
        "    for sid in train_ids:\n",
        "        y = load_labels(int(sid))\n",
        "        vals, cnts = np.unique(y, return_counts=True)\n",
        "        for v, c in zip(vals, cnts):\n",
        "            if 0 <= v <= 20:\n",
        "                counts[v] += int(c)\n",
        "    freq = counts / max(1, counts.sum())\n",
        "    w = 1.0 / np.sqrt(np.clip(freq, 1e-12, None))\n",
        "    w = w / w.mean()\n",
        "    w0_cap = 0.7 * w.mean()\n",
        "    w[0] = min(w[0], w0_cap)\n",
        "    return torch.tensor(w, dtype=torch.float32, device=device)\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, ids, mean, std, train=True, crop_min=1600, crop_max=1800, time_masks=(3,5), mask_len=(5,15), noise_std=0.01, seed=42):\n",
        "        self.ids = list(ids)\n",
        "        self.mean = torch.from_numpy(mean).float()\n",
        "        self.std = torch.from_numpy(std).float()\n",
        "        self.train = train\n",
        "        self.crop_min = crop_min\n",
        "        self.crop_max = crop_max\n",
        "        self.tmask_lo, self.tmask_hi = time_masks\n",
        "        self.mlen_lo, self.mlen_hi = mask_len\n",
        "        self.noise_std = noise_std\n",
        "        self.rng = random.Random(seed)\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "    def _rand_crop(self, X, y):\n",
        "        T = X.shape[0]\n",
        "        if not self.train:\n",
        "            return X, y\n",
        "        tgt = self.rng.randint(self.crop_min, self.crop_max)\n",
        "        if T <= tgt:\n",
        "            return X, y\n",
        "        start = self.rng.randint(0, T - tgt)\n",
        "        end = start + tgt\n",
        "        return X[start:end], y[start:end]\n",
        "    def _time_mask(self, X):\n",
        "        if not self.train:\n",
        "            return X\n",
        "        T = X.shape[0]\n",
        "        m = self.rng.randint(self.tmask_lo, self.tmask_hi)\n",
        "        for _ in range(m):\n",
        "            L = self.rng.randint(self.mlen_lo, self.mlen_hi)\n",
        "            if T <= L: continue\n",
        "            s = self.rng.randint(0, T - L)\n",
        "            e = s + L\n",
        "            seg_mean = X[max(0, s-5):min(T, e+5)].mean(axis=0, keepdims=True)\n",
        "            X[s:e] = seg_mean\n",
        "        return X\n",
        "    def __getitem__(self, idx):\n",
        "        sid = int(self.ids[idx])\n",
        "        X = load_feat_full(sid)\n",
        "        y = load_labels(sid)\n",
        "        X, y = self._rand_crop(X, y)\n",
        "        # standardize\n",
        "        X = (torch.from_numpy(X).float() - self.mean) / (self.std + 1e-6)\n",
        "        if self.train:\n",
        "            if self.noise_std > 0:\n",
        "                X = X + torch.randn_like(X) * self.noise_std\n",
        "            # time mask in numpy for speed then back\n",
        "            X_np = X.numpy()\n",
        "            X_np = self._time_mask(X_np)\n",
        "            X = torch.from_numpy(X_np).float()\n",
        "        y = torch.from_numpy(y).long()\n",
        "        return X, y\n",
        "\n",
        "def collate_pad(batch):\n",
        "    # pad to max T in batch for efficient training; return CPU tensors\n",
        "    xs, ys = zip(*batch)\n",
        "    T_max = max(x.shape[0] for x in xs)\n",
        "    D = xs[0].shape[1]\n",
        "    xb = torch.zeros((len(xs), T_max, D), dtype=torch.float32)\n",
        "    yb = torch.full((len(xs), T_max), -100, dtype=torch.long)\n",
        "    for i, (x, y) in enumerate(zip(xs, ys)):\n",
        "        T = x.shape[0]\n",
        "        xb[i, :T] = x\n",
        "        yb[i, :T] = y\n",
        "    return xb, yb  # keep on CPU; DataLoader pin_memory will handle page-locking\n",
        "\n",
        "def cosine_with_warmup(step, total_steps, warmup_steps, base_lr, min_lr):\n",
        "    if step < warmup_steps:\n",
        "        return base_lr * (step / max(1, warmup_steps))\n",
        "    t = (step - warmup_steps) / max(1, (total_steps - warmup_steps))\n",
        "    return min_lr + 0.5 * (base_lr - min_lr) * (1 + math.cos(math.pi * t))\n",
        "\n",
        "def train_fold(fold_idx, train_ids, val_ids, epochs=50, batch_size=8, accum_steps=1, base_lr=3e-3, min_lr=3e-5, wd=0.01, label_smooth=0.05):\n",
        "    print(f\"=== Train fold {fold_idx}: train_n={len(train_ids)} val_n={len(val_ids)} ===\", flush=True)\n",
        "    # compute scaler and class weights on train only\n",
        "    mean, std = compute_fold_scaler(train_ids)\n",
        "    class_w = compute_class_weights(train_ids)\n",
        "    D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "    model = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "    ema = EMA(model, decay=0.999)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=wd, betas=(0.9, 0.999))\n",
        "    # datasets\n",
        "    tr_ds = SeqDataset(train_ids, mean, std, train=True, crop_min=1600, crop_max=4096, time_masks=(3,5), mask_len=(5,15), noise_std=0.01, seed=fold_idx+123)\n",
        "    va_ds = SeqDataset(val_ids, mean, std, train=False, seed=fold_idx+777)\n",
        "    # num_workers=0; keep pin_memory True to speed H2D copies; tensors stay on CPU in collate_pad\n",
        "    tr_ld = DataLoader(tr_ds, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0, collate_fn=collate_pad, pin_memory=True)\n",
        "    va_ld = DataLoader(va_ds, batch_size=1, shuffle=False, drop_last=False, num_workers=0, collate_fn=collate_pad, pin_memory=True)\n",
        "    # schedule\n",
        "    steps_per_epoch = max(1, len(tr_ld))\n",
        "    total_steps = steps_per_epoch * epochs\n",
        "    warmup_steps = 5 * steps_per_epoch  # 5 epochs warmup\n",
        "    crit = nn.CrossEntropyLoss(weight=class_w, label_smoothing=label_smooth, ignore_index=-100)\n",
        "    best_val = float('inf'); best_path = f\"model_ce_fold{fold_idx}.pth\"; patience=5; bad=0\n",
        "    t0=time.time()\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        tr_loss = 0.0; seen = 0; t_ep=time.time()\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        for step, (xb, yb) in enumerate(tr_ld):\n",
        "            # move batch to GPU\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            bs, T, D = xb.shape; C = 21\n",
        "            lr = cosine_with_warmup((ep-1)*steps_per_epoch + step, total_steps, warmup_steps, base_lr, min_lr)\n",
        "            for pg in opt.param_groups: pg['lr'] = lr\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                logits = model(xb)  # B,T,C\n",
        "                loss = crit(logits.reshape(-1, C), yb.reshape(-1))\n",
        "            # backward + step with AMP\n",
        "            scaler.scale(loss / accum_steps).backward()\n",
        "            if ((step + 1) % accum_steps) == 0:\n",
        "                scaler.unscale_(opt)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                ema.update(model)\n",
        "            tr_loss += loss.item() * bs\n",
        "            seen += bs\n",
        "            if (step+1) % 50 == 0 or (step+1)==steps_per_epoch:\n",
        "                print(f\"  ep{ep} step {step+1}/{steps_per_epoch} lr={lr:.2e} loss={tr_loss/max(1,seen):.4f} elapsed={(time.time()-t_ep):.1f}s\", flush=True)\n",
        "        # validate with EMA weights\n",
        "        model.eval(); ema.apply_to(model)\n",
        "        val_loss = 0.0; vseen=0\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda'):\n",
        "            for xb, yb in va_ld:\n",
        "                xb = xb.to(device, non_blocking=True)\n",
        "                yb = yb.to(device, non_blocking=True)\n",
        "                bs, T, D = xb.shape; C = 21\n",
        "                logits = model(xb)\n",
        "                loss = crit(logits.reshape(-1, C), yb.reshape(-1))\n",
        "                val_loss += loss.item()\n",
        "                vseen += 1\n",
        "        ema.restore(model)\n",
        "        val_loss = val_loss / max(1, vseen)\n",
        "        print(f\"[Fold {fold_idx}] Epoch {ep} train_loss={tr_loss/max(1,seen):.4f} val_loss={val_loss:.4f} epoch_time={(time.time()-t_ep):.1f}s total={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "        # early stopping on val CE; save EMA weights at best\n",
        "        if val_loss < best_val - 1e-4:\n",
        "            best_val = val_loss; bad = 0\n",
        "            ema.apply_to(model); torch.save(model.state_dict(), best_path); ema.restore(model)\n",
        "            print(f\"  Saved best to {best_path}\", flush=True)\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience:\n",
        "                print(f\"  Early stop at epoch {ep}\", flush=True)\n",
        "                break\n",
        "        # free cache\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "    print(f\"Fold {fold_idx} done. Best val CE={best_val:.4f}. Model -> {best_path}\")\n",
        "\n",
        "# Kick off training sequentially across folds (force retrain, overwrite existing checkpoints)\n",
        "for f in folds:\n",
        "    fold_idx = int(f['fold'])\n",
        "    outp = Path(f\"model_ce_fold{fold_idx}.pth\")\n",
        "    if outp.exists():\n",
        "        print(f\"[Overwrite] Removing existing {outp} to retrain with fixed loss/EMA...\")\n",
        "        try:\n",
        "            outp.unlink()\n",
        "        except Exception as e:\n",
        "            print(f\"  Warning: could not delete {outp}: {e}\")\n",
        "    train_ids = f['train_ids']\n",
        "    val_ids = f['val_ids']\n",
        "    train_fold(fold_idx, train_ids, val_ids, epochs=50, batch_size=8, accum_steps=1, base_lr=3e-3, min_lr=3e-5, wd=0.01, label_smooth=0.05)\n",
        "    # After each fold, flush CUDA\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "print('All folds processed.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "519f0364-1116-4df5-b3d3-3b2323caf099",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OOF eval and test inference using newly trained per-fold CE models (DilatedTCN 128x12, EMA checkpoints)\n",
        "import os, json, time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA:', torch.cuda.is_available(), flush=True)\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def load_feat(split, sid:int):\n",
        "    d = np.load((feat_tr_dir if split=='train' else feat_te_dir)/f\"{sid}.npz\");\n",
        "    return d['X'].astype(np.float32)\n",
        "\n",
        "def compute_fold_scaler(id_list):\n",
        "    n = 0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = load_feat('train', int(sid))\n",
        "        n_i = X.shape[0]\n",
        "        if mean is None:\n",
        "            mean = X.mean(axis=0);\n",
        "            M2 = ((X - mean)**2).sum(axis=0);\n",
        "            n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0);\n",
        "            n_new = n + n_i; delta = mean_i - mean;\n",
        "            mean = mean + delta * (n_i / max(1, n_new));\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new));\n",
        "            n = n_new\n",
        "    var = M2 / max(1, (n - 1)); std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "\n",
        "# Model def matching training\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__();\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h);\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True);\n",
        "        return x + h\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__();\n",
        "        self.inp = nn.Conv1d(d_in, channels, 1)\n",
        "        blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3));\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2);\n",
        "        h = self.inp(x);\n",
        "        for b in self.blocks: h = b(h);\n",
        "        out = self.head(h);\n",
        "        return out.transpose(1,2)\n",
        "\n",
        "def time_warp_probs(p_t_c: torch.Tensor, factor: float) -> torch.Tensor:\n",
        "    T, C = p_t_c.shape; tgt_len = max(1, int(round(T*factor)));\n",
        "    x = p_t_c.T.unsqueeze(0);\n",
        "    y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False);\n",
        "    y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T;\n",
        "    return y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        ps = time_warp_probs(p_t_c, s);\n",
        "        acc = ps if acc is None else (acc + ps)\n",
        "    out = acc / float(len(factors))\n",
        "    return out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2);\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k = max(1, int(k)); x = p_t.view(1,1,-1);\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "    pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1);\n",
        "    T = p_t.shape[0];\n",
        "    if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]))\n",
        "    elif y.shape[0] > T: y = y[:T]\n",
        "    return y\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T = p.shape[0]; a = max(0, t_star - w); b = min(T-1, t_star + w);\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype);\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8;\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def decode_peaks(p_t_c: torch.Tensor, med_k: dict, gamma: float = 1.0, pool_k=13, temp=0.95):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k); T, C = p_s.shape;\n",
        "    scores = torch.empty_like(p_s); ks=[13]*C\n",
        "    for c in range(C):\n",
        "        if c==0: scores[:,c]=p_s[:,c]; ks[c]=13; continue\n",
        "        base_k = med_k.get(c, 13); k = int(np.clip(round(gamma * base_k), 9, 25));\n",
        "        if k % 2 == 0: k = min(25, k + 1); ks[c]=k;\n",
        "        scores[:,c] = duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks=[]\n",
        "    for c in range(1,21):\n",
        "        k=ks[c]; w_com = max(5, k//3); radius = max(10, k//2); s=scores[:,c];\n",
        "        t_star = int(torch.argmax(s).item()); t_ref = refine_com(p_s[:,c], t_star, w=w_com);\n",
        "        t_idx = int(round(max(0, min(t_ref, T-1))));\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item();\n",
        "        pooled_at_ref = p_s[t_idx, c].item();\n",
        "        peaks.append([c, t_ref, float(scores[t_idx,c].item()), float(local_mean), float(pooled_at_ref)])\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3], -x[4]));\n",
        "    last_t = -1e9\n",
        "    for i in range(len(peaks)):\n",
        "        if peaks[i][1] <= last_t: peaks[i][1] = last_t + 2.0;\n",
        "        last_t = min(peaks[i][1], float(T-1))\n",
        "    return [int(c) for c,_,_,_,_ in peaks]\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# OOF: per-fold model on its own val_ids only; probs cached\n",
        "def cache_fold_val_probs(fold):\n",
        "    fold_idx = int(fold['fold'])\n",
        "    ckpt = Path(f\"model_ce_fold{fold_idx}.pth\");\n",
        "    assert ckpt.exists(), f\"Missing {ckpt}; train fold models first\"\n",
        "    D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "    model = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device)); model.eval()\n",
        "    mean,std = compute_fold_scaler(fold['train_ids'])\n",
        "    mean_t = torch.from_numpy(mean).float().to(device); std_t = torch.from_numpy(std).float().to(device)\n",
        "    vids = fold['val_ids']\n",
        "    t0=time.time()\n",
        "    for i, sid in enumerate(vids, 1):\n",
        "        sid=int(sid); outp = probs_cache/f\"{sid}_ce_new.npy\"\n",
        "        if outp.exists():\n",
        "            if (i%25)==0 or i==len(vids):\n",
        "                print(f\"  [fold {fold_idx}] cached {i}/{len(vids)} elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "            continue\n",
        "        X = load_feat('train', sid); xb = torch.from_numpy(X).float().to(device);\n",
        "        xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0)\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "            probs = model(xb)[0].softmax(dim=-1);\n",
        "            probs = apply_tta_timewarp(probs, factors=(0.9,1.0,1.1))\n",
        "        np.save(outp, probs.cpu().numpy())\n",
        "        if (i%25)==0 or i==len(vids):\n",
        "            print(f\"  [fold {fold_idx}] cached {i}/{len(vids)} elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "def load_cached_prob_new(sid:int):\n",
        "    return torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new.npy\")).to(device)\n",
        "\n",
        "print('Caching OOF probs per fold (new CE models)...', flush=True)\n",
        "for f in folds: cache_fold_val_probs(f)\n",
        "\n",
        "# Small grid over decoder settings (CE-only); per-fold priors, select by worst-fold then mean\n",
        "pool_ks=[11,13,15]; temps=[0.90,0.95,1.00]; gammas=[0.90,0.95,0.975,1.00,1.025,1.05]\n",
        "med_cache={}\n",
        "def eval_cfg_on_fold(fold, pool_k, temp, gamma):\n",
        "    fi = int(fold['fold'])\n",
        "    if fi not in med_cache: med_cache[fi] = compute_class_median_durations_for_ids(fold['train_ids'])\n",
        "    med_k = med_cache[fi]\n",
        "    vids = fold['val_ids']; tot=0; cnt=0\n",
        "    for sid in vids:\n",
        "        p = load_cached_prob_new(int(sid));\n",
        "        seq = decode_peaks(p, med_k=med_k, gamma=gamma, pool_k=pool_k, temp=temp);\n",
        "        tot += levenshtein(seq, id2seq[int(sid)]); cnt += 1\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "res=[]\n",
        "for pool_k in pool_ks:\n",
        "    for temp in temps:\n",
        "        for gamma in gammas:\n",
        "            per_fold=[]\n",
        "            for f in folds:\n",
        "                lev = eval_cfg_on_fold(f, pool_k, temp, gamma); per_fold.append(lev)\n",
        "            res.append((np.mean(per_fold), np.max(per_fold), {'pool_k':pool_k, 'temp':temp, 'gamma':gamma}))\n",
        "res.sort(key=lambda x: (x[1], x[0]))\n",
        "print('Top CE-only (new models):')\n",
        "for r in res[:5]: print(r)\n",
        "pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res]).to_csv('cv_sweep_ce_new.csv', index=False)\n",
        "print('Saved cv_sweep_ce_new.csv', flush=True)\n",
        "\n",
        "# Test-time inference: ensemble 3 fold models; standardize per-model with its own scaler, then average probs\n",
        "print('Building CE-only test submission with new models...', flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "cfg_best = pd.read_csv('cv_sweep_ce_new.csv').sort_values(['worst','mean']).iloc[0].to_dict() if Path('cv_sweep_ce_new.csv').exists() else {'pool_k':13,'temp':0.95,'gamma':1.0}\n",
        "pool_k=int(cfg_best['pool_k']); temp=float(cfg_best['temp']); gamma=float(cfg_best.get('gamma',1.0))\n",
        "med_k_test = compute_class_median_durations_for_ids(pd.read_csv('training.csv')['Id'].astype(int).tolist())\n",
        "\n",
        "# preload models and their scalers\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "models=[]; scalers=[]\n",
        "for fi in range(3):\n",
        "    ckpt = Path(f\"model_ce_fold{fi}.pth\");\n",
        "    if not ckpt.exists():\n",
        "        print(f\"WARNING: missing {ckpt}; skipping in ensemble\")\n",
        "        continue\n",
        "    m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "    m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval(); models.append(m)\n",
        "    mean,std = compute_fold_scaler(folds[fi]['train_ids']);\n",
        "    scalers.append((torch.from_numpy(mean).float().to(device), torch.from_numpy(std).float().to(device)))\n",
        "assert len(models)>0, 'No CE fold models available'\n",
        "\n",
        "rows=[]; t0=time.time()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    X = load_feat('test', int(sid));\n",
        "    acc=None\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "        for m, (mean_t, std_t) in zip(models, scalers):\n",
        "            xb = torch.from_numpy(X).float().to(device);\n",
        "            xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0);\n",
        "            p = m(xb)[0].softmax(dim=-1);\n",
        "            p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1));\n",
        "            acc = p if acc is None else (acc + p)\n",
        "        probs = acc / float(len(models)); probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    seq = decode_peaks(probs, med_k=med_k_test, gamma=gamma, pool_k=pool_k, temp=temp)\n",
        "    rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if (i%10)==0 or i==len(test_ids):\n",
        "        print(f\"  [infer CE-new] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "sub.to_csv('submission_primary_ce_new.csv', index=False);\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission_primary_ce_new.csv and submission.csv; head:\\n', sub.head(), flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c29f0b79-3803-4cdc-a381-1f8cab3cea81",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train a second CE seed per fold (to ensemble 6 models total)\n",
        "import os, json, math, time, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA available:', torch.cuda.is_available(), flush=True)\n",
        "assert torch.cuda.is_available(), 'GPU required for timely training'\n",
        "torch.backends.cudnn.benchmark = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, 1)\n",
        "        blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for b in self.blocks:\n",
        "            h = b(h)\n",
        "        out = self.head(h)\n",
        "        return out.transpose(1,2)\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.decay = decay\n",
        "        self.shadow = {n: p.detach().clone() for n,p in model.named_parameters() if p.requires_grad}\n",
        "    @torch.no_grad()\n",
        "    def update(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[n].mul_(self.decay).add_(p.detach(), alpha=1.0 - self.decay)\n",
        "    def apply_to(self, model):\n",
        "        self.backup = {}\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.backup[n] = p.detach().clone()\n",
        "                p.data.copy_(self.shadow[n].data)\n",
        "    def restore(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                p.data.copy_(self.backup[n].data)\n",
        "\n",
        "def load_feat_full(sample_id: int):\n",
        "    d = np.load((feat_tr_dir/f\"{sample_id}.npz\"))\n",
        "    return d['X'].astype(np.float32)\n",
        "def load_labels(sample_id: int):\n",
        "    return np.load(lab_tr_dir/f\"{sample_id}.npy\").astype(np.int64)\n",
        "\n",
        "def compute_fold_scaler(id_list):\n",
        "    n = 0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = load_feat_full(int(sid))\n",
        "        n_i = X.shape[0]\n",
        "        if mean is None:\n",
        "            mean = X.mean(axis=0)\n",
        "            M2 = ((X - mean)**2).sum(axis=0)\n",
        "            n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0)\n",
        "            n_new = n + n_i\n",
        "            delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new))\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new))\n",
        "            n = n_new\n",
        "    var = M2 / max(1, (n - 1))\n",
        "    std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def compute_class_weights(train_ids):\n",
        "    counts = np.zeros(21, dtype=np.int64)\n",
        "    for sid in train_ids:\n",
        "        y = load_labels(int(sid))\n",
        "        vals, cnts = np.unique(y, return_counts=True)\n",
        "        for v, c in zip(vals, cnts):\n",
        "            if 0 <= v <= 20:\n",
        "                counts[v] += int(c)\n",
        "    freq = counts / max(1, counts.sum())\n",
        "    w = 1.0 / np.sqrt(np.clip(freq, 1e-12, None))\n",
        "    w = w / w.mean()\n",
        "    w0_cap = 0.7 * w.mean()\n",
        "    w[0] = min(w[0], w0_cap)\n",
        "    return torch.tensor(w, dtype=torch.float32, device=device)\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, ids, mean, std, train=True, crop_min=1600, crop_max=4096, time_masks=(3,5), mask_len=(5,15), noise_std=0.01, seed=777):\n",
        "        self.ids = list(ids)\n",
        "        self.mean = torch.from_numpy(mean).float()\n",
        "        self.std = torch.from_numpy(std).float()\n",
        "        self.train = train\n",
        "        self.crop_min = crop_min\n",
        "        self.crop_max = crop_max\n",
        "        self.tmask_lo, self.tmask_hi = time_masks\n",
        "        self.mlen_lo, self.mlen_hi = mask_len\n",
        "        self.noise_std = noise_std\n",
        "        self.rng = random.Random(seed)\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "    def _rand_crop(self, X, y):\n",
        "        T = X.shape[0]\n",
        "        if not self.train:\n",
        "            return X, y\n",
        "        tgt = self.rng.randint(self.crop_min, self.crop_max)\n",
        "        if T <= tgt:\n",
        "            return X, y\n",
        "        start = self.rng.randint(0, T - tgt)\n",
        "        end = start + tgt\n",
        "        return X[start:end], y[start:end]\n",
        "    def _time_mask(self, X):\n",
        "        if not self.train:\n",
        "            return X\n",
        "        T = X.shape[0]\n",
        "        m = self.rng.randint(self.tmask_lo, self.tmask_hi)\n",
        "        for _ in range(m):\n",
        "            L = self.rng.randint(self.mlen_lo, self.mlen_hi)\n",
        "            if T <= L: continue\n",
        "            s = self.rng.randint(0, T - L)\n",
        "            e = s + L\n",
        "            seg_mean = X[max(0, s-5):min(T, e+5)].mean(axis=0, keepdims=True)\n",
        "            X[s:e] = seg_mean\n",
        "        return X      \n",
        "    def __getitem__(self, idx):\n",
        "        sid = int(self.ids[idx])\n",
        "        X = load_feat_full(sid)\n",
        "        y = load_labels(sid)\n",
        "        X, y = self._rand_crop(X, y)\n",
        "        X = (torch.from_numpy(X).float() - self.mean) / (self.std + 1e-6)\n",
        "        if self.train:\n",
        "            if self.noise_std > 0:\n",
        "                X = X + torch.randn_like(X) * self.noise_std\n",
        "            X_np = X.numpy(); X_np = self._time_mask(X_np); X = torch.from_numpy(X_np).float()\n",
        "        y = torch.from_numpy(y).long()\n",
        "        return X, y\n",
        "\n",
        "def collate_pad(batch):\n",
        "    xs, ys = zip(*batch)\n",
        "    T_max = max(x.shape[0] for x in xs)\n",
        "    D = xs[0].shape[1]\n",
        "    xb = torch.zeros((len(xs), T_max, D), dtype=torch.float32)\n",
        "    yb = torch.full((len(xs), T_max), -100, dtype=torch.long)\n",
        "    for i, (x, y) in enumerate(zip(xs, ys)):\n",
        "        T = x.shape[0]\n",
        "        xb[i, :T] = x\n",
        "        yb[i, :T] = y\n",
        "    return xb, yb\n",
        "\n",
        "def cosine_with_warmup(step, total_steps, warmup_steps, base_lr, min_lr):\n",
        "    if step < warmup_steps:\n",
        "        return base_lr * (step / max(1, warmup_steps))\n",
        "    t = (step - warmup_steps) / max(1, (total_steps - warmup_steps))\n",
        "    return min_lr + 0.5 * (base_lr - min_lr) * (1 + math.cos(math.pi * t))\n",
        "\n",
        "def train_fold_seed(fold_idx, train_ids, val_ids, out_name, ds_seed, epochs=50, batch_size=8, accum_steps=1, base_lr=3e-3, min_lr=3e-5, wd=0.01, label_smooth=0.05):\n",
        "    print(f\"=== Train fold {fold_idx} (seed2): train_n={len(train_ids)} val_n={len(val_ids)} ===\", flush=True)\n",
        "    mean, std = compute_fold_scaler(train_ids)\n",
        "    class_w = compute_class_weights(train_ids)\n",
        "    D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "    model = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "    torch.manual_seed(1337 + fold_idx*11)\n",
        "    np.random.seed(4242 + fold_idx*17)\n",
        "    random.seed(9001 + fold_idx*23)\n",
        "    ema = EMA(model, decay=0.999)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=wd, betas=(0.9, 0.999))\n",
        "    tr_ds = SeqDataset(train_ids, mean, std, train=True, crop_min=1600, crop_max=4096, time_masks=(3,5), mask_len=(5,15), noise_std=0.01, seed=ds_seed)\n",
        "    va_ds = SeqDataset(val_ids, mean, std, train=False, seed=ds_seed+777)\n",
        "    tr_ld = DataLoader(tr_ds, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0, collate_fn=collate_pad, pin_memory=True)\n",
        "    va_ld = DataLoader(va_ds, batch_size=1, shuffle=False, drop_last=False, num_workers=0, collate_fn=collate_pad, pin_memory=True)\n",
        "    steps_per_epoch = max(1, len(tr_ld))\n",
        "    total_steps = steps_per_epoch * epochs\n",
        "    warmup_steps = 5 * steps_per_epoch\n",
        "    crit = nn.CrossEntropyLoss(weight=class_w, label_smoothing=label_smooth, ignore_index=-100)\n",
        "    best_val = float('inf'); patience=5; bad=0\n",
        "    t0=time.time()\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train(); tr_loss=0.0; seen=0; t_ep=time.time()\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        for step, (xb, yb) in enumerate(tr_ld):\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            bs, T, D = xb.shape; C = 21\n",
        "            lr = cosine_with_warmup((ep-1)*steps_per_epoch + step, total_steps, warmup_steps, base_lr, min_lr)\n",
        "            for pg in opt.param_groups: pg['lr'] = lr\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                logits = model(xb)\n",
        "                loss = crit(logits.reshape(-1, C), yb.reshape(-1))\n",
        "            scaler.scale(loss / accum_steps).backward()\n",
        "            if ((step + 1) % accum_steps) == 0:\n",
        "                scaler.unscale_(opt)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                ema.update(model)\n",
        "            tr_loss += loss.item() * bs; seen += bs\n",
        "            if (step+1) % 50 == 0 or (step+1)==steps_per_epoch:\n",
        "                print(f\"  ep{ep} step {step+1}/{steps_per_epoch} lr={lr:.2e} loss={tr_loss/max(1,seen):.4f} elapsed={(time.time()-t_ep):.1f}s\", flush=True)\n",
        "        model.eval(); ema.apply_to(model)\n",
        "        val_loss = 0.0; vseen=0\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda'):\n",
        "            for xb, yb in va_ld:\n",
        "                xb = xb.to(device, non_blocking=True)\n",
        "                yb = yb.to(device, non_blocking=True)\n",
        "                bs, T, D = xb.shape; C = 21\n",
        "                logits = model(xb)\n",
        "                loss = crit(logits.reshape(-1, C), yb.reshape(-1))\n",
        "                val_loss += loss.item(); vseen += 1\n",
        "        ema.restore(model)\n",
        "        val_loss = val_loss / max(1, vseen)\n",
        "        print(f\"[Fold {fold_idx} seed2] Epoch {ep} train_loss={tr_loss/max(1,seen):.4f} val_loss={val_loss:.4f} epoch_time={(time.time()-t_ep):.1f}s total={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "        if val_loss < best_val - 1e-4:\n",
        "            best_val = val_loss; bad = 0\n",
        "            ema.apply_to(model); torch.save(model.state_dict(), out_name); ema.restore(model)\n",
        "            print(f\"  Saved best to {out_name}\", flush=True)\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience:\n",
        "                print(f\"  Early stop at epoch {ep}\", flush=True)\n",
        "                break\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "    print(f\"Fold {fold_idx} seed2 done. Best val CE={best_val:.4f}. Model -> {out_name}\")\n",
        "\n",
        "# Kick off training for seed2 across folds (separate ckpts)\n",
        "for f in folds:\n",
        "    fold_idx = int(f['fold'])\n",
        "    outp = Path(f\"model_ce_fold{fold_idx}_s1.pth\")\n",
        "    if outp.exists():\n",
        "        print(f\"[Overwrite] Removing existing {outp} to retrain seed2...\")\n",
        "        try:\n",
        "            outp.unlink()\n",
        "        except Exception as e:\n",
        "            print(f\"  Warning: could not delete {outp}: {e}\")\n",
        "    train_ids = f['train_ids']; val_ids = f['val_ids']\n",
        "    train_fold_seed(fold_idx, train_ids, val_ids, out_name=str(outp), ds_seed=2025 + fold_idx)\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "print('All folds (seed2) processed.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train fold 0 (seed2): train_n=199 val_n=98 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep1 step 24/24 lr=5.75e-04 loss=4.3221 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 1 train_loss=4.3221 val_loss=6.2157 epoch_time=2.5s total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep2 step 24/24 lr=1.18e-03 loss=2.8240 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 2 train_loss=2.8240 val_loss=5.7264 epoch_time=2.5s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep3 step 24/24 lr=1.78e-03 loss=2.3179 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 3 train_loss=2.3179 val_loss=5.2618 epoch_time=2.5s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep4 step 24/24 lr=2.37e-03 loss=1.9468 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 4 train_loss=1.9468 val_loss=4.8661 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep5 step 24/24 lr=2.98e-03 loss=1.7240 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 5 train_loss=1.7240 val_loss=4.5117 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep6 step 24/24 lr=3.00e-03 loss=1.5131 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 6 train_loss=1.5131 val_loss=4.2118 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep7 step 24/24 lr=2.99e-03 loss=1.4153 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 7 train_loss=1.4153 val_loss=3.9526 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep8 step 24/24 lr=2.97e-03 loss=1.3417 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 8 train_loss=1.3417 val_loss=3.7161 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep9 step 24/24 lr=2.94e-03 loss=1.2169 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 9 train_loss=1.2169 val_loss=3.5032 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep10 step 24/24 lr=2.91e-03 loss=1.1507 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 10 train_loss=1.1507 val_loss=3.3038 epoch_time=2.5s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep11 step 24/24 lr=2.87e-03 loss=1.1207 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 11 train_loss=1.1207 val_loss=3.1110 epoch_time=2.5s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep12 step 24/24 lr=2.83e-03 loss=1.0550 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 12 train_loss=1.0550 val_loss=2.9316 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep13 step 24/24 lr=2.78e-03 loss=1.0209 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 13 train_loss=1.0209 val_loss=2.7620 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep14 step 24/24 lr=2.72e-03 loss=0.9766 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 14 train_loss=0.9766 val_loss=2.6160 epoch_time=2.5s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep15 step 24/24 lr=2.66e-03 loss=0.9401 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 15 train_loss=0.9401 val_loss=2.4818 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep16 step 24/24 lr=2.59e-03 loss=0.9050 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 16 train_loss=0.9050 val_loss=2.3671 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep17 step 24/24 lr=2.51e-03 loss=0.8736 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 17 train_loss=0.8736 val_loss=2.2670 epoch_time=2.7s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep18 step 24/24 lr=2.43e-03 loss=0.8713 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 18 train_loss=0.8713 val_loss=2.1798 epoch_time=2.5s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep19 step 24/24 lr=2.35e-03 loss=0.8294 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 19 train_loss=0.8294 val_loss=2.1096 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep20 step 24/24 lr=2.26e-03 loss=0.7967 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 20 train_loss=0.7967 val_loss=2.0478 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep21 step 24/24 lr=2.17e-03 loss=0.7826 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 21 train_loss=0.7826 val_loss=1.9985 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep22 step 24/24 lr=2.08e-03 loss=0.7625 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 22 train_loss=0.7625 val_loss=1.9569 epoch_time=2.5s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep23 step 24/24 lr=1.98e-03 loss=0.7373 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 23 train_loss=0.7373 val_loss=1.9235 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep24 step 24/24 lr=1.88e-03 loss=0.7117 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 24 train_loss=0.7117 val_loss=1.8980 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep25 step 24/24 lr=1.78e-03 loss=0.7009 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 25 train_loss=0.7009 val_loss=1.8763 epoch_time=2.5s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep26 step 24/24 lr=1.67e-03 loss=0.6892 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 26 train_loss=0.6892 val_loss=1.8591 epoch_time=2.5s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep27 step 24/24 lr=1.57e-03 loss=0.6678 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 27 train_loss=0.6678 val_loss=1.8447 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep28 step 24/24 lr=1.47e-03 loss=0.6478 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 28 train_loss=0.6478 val_loss=1.8344 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep29 step 24/24 lr=1.36e-03 loss=0.6241 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 29 train_loss=0.6241 val_loss=1.8267 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep30 step 24/24 lr=1.26e-03 loss=0.6188 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 30 train_loss=0.6188 val_loss=1.8212 epoch_time=2.5s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep31 step 24/24 lr=1.16e-03 loss=0.5915 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 31 train_loss=0.5915 val_loss=1.8176 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep32 step 24/24 lr=1.06e-03 loss=0.5972 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 32 train_loss=0.5972 val_loss=1.8155 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep33 step 24/24 lr=9.63e-04 loss=0.5906 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 33 train_loss=0.5906 val_loss=1.8142 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep34 step 24/24 lr=8.68e-04 loss=0.5678 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 34 train_loss=0.5678 val_loss=1.8143 epoch_time=2.5s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep35 step 24/24 lr=7.76e-04 loss=0.5636 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 35 train_loss=0.5636 val_loss=1.8147 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep36 step 24/24 lr=6.88e-04 loss=0.5569 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 36 train_loss=0.5569 val_loss=1.8160 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep37 step 24/24 lr=6.04e-04 loss=0.5511 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 37 train_loss=0.5511 val_loss=1.8176 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep38 step 24/24 lr=5.25e-04 loss=0.5469 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 seed2] Epoch 38 train_loss=0.5469 val_loss=1.8196 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Early stop at epoch 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 seed2 done. Best val CE=1.8142. Model -> model_ce_fold0_s1.pth\n=== Train fold 1 (seed2): train_n=198 val_n=99 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep1 step 24/24 lr=5.75e-04 loss=3.9077 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 1 train_loss=3.9077 val_loss=5.2814 epoch_time=2.6s total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep2 step 24/24 lr=1.18e-03 loss=2.8003 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 2 train_loss=2.8003 val_loss=4.9305 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep3 step 24/24 lr=1.78e-03 loss=2.2498 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 3 train_loss=2.2498 val_loss=4.6204 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep4 step 24/24 lr=2.37e-03 loss=1.9123 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 4 train_loss=1.9123 val_loss=4.3503 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep5 step 24/24 lr=2.98e-03 loss=1.6704 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 5 train_loss=1.6704 val_loss=4.1068 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep6 step 24/24 lr=3.00e-03 loss=1.5400 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 6 train_loss=1.5400 val_loss=3.8875 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep7 step 24/24 lr=2.99e-03 loss=1.4024 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 7 train_loss=1.4024 val_loss=3.6800 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep8 step 24/24 lr=2.97e-03 loss=1.2832 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 8 train_loss=1.2832 val_loss=3.4860 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep9 step 24/24 lr=2.94e-03 loss=1.1876 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 9 train_loss=1.1876 val_loss=3.3066 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep10 step 24/24 lr=2.91e-03 loss=1.1518 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 10 train_loss=1.1518 val_loss=3.1377 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep11 step 24/24 lr=2.87e-03 loss=1.0971 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 11 train_loss=1.0971 val_loss=2.9767 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep12 step 24/24 lr=2.83e-03 loss=1.0612 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 12 train_loss=1.0612 val_loss=2.8215 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep13 step 24/24 lr=2.78e-03 loss=0.9910 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 13 train_loss=0.9910 val_loss=2.6735 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep14 step 24/24 lr=2.72e-03 loss=0.9458 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 14 train_loss=0.9458 val_loss=2.5356 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep15 step 24/24 lr=2.66e-03 loss=0.9101 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 15 train_loss=0.9101 val_loss=2.4055 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep16 step 24/24 lr=2.59e-03 loss=0.9061 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 16 train_loss=0.9061 val_loss=2.2882 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep17 step 24/24 lr=2.51e-03 loss=0.8579 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 17 train_loss=0.8579 val_loss=2.1844 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep18 step 24/24 lr=2.43e-03 loss=0.8282 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 18 train_loss=0.8282 val_loss=2.0938 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep19 step 24/24 lr=2.35e-03 loss=0.7876 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 19 train_loss=0.7876 val_loss=2.0142 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep20 step 24/24 lr=2.26e-03 loss=0.7652 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 20 train_loss=0.7652 val_loss=1.9467 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep21 step 24/24 lr=2.17e-03 loss=0.7394 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 21 train_loss=0.7394 val_loss=1.8890 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep22 step 24/24 lr=2.08e-03 loss=0.7280 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 22 train_loss=0.7280 val_loss=1.8421 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep23 step 24/24 lr=1.98e-03 loss=0.6970 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 23 train_loss=0.6970 val_loss=1.8015 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep24 step 24/24 lr=1.88e-03 loss=0.6924 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 24 train_loss=0.6924 val_loss=1.7707 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep25 step 24/24 lr=1.78e-03 loss=0.6732 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 25 train_loss=0.6732 val_loss=1.7410 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep26 step 24/24 lr=1.67e-03 loss=0.6516 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 26 train_loss=0.6516 val_loss=1.7182 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep27 step 24/24 lr=1.57e-03 loss=0.6381 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 27 train_loss=0.6381 val_loss=1.6990 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep28 step 24/24 lr=1.47e-03 loss=0.6306 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 28 train_loss=0.6306 val_loss=1.6817 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep29 step 24/24 lr=1.36e-03 loss=0.6193 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 29 train_loss=0.6193 val_loss=1.6671 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep30 step 24/24 lr=1.26e-03 loss=0.5898 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 30 train_loss=0.5898 val_loss=1.6563 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep31 step 24/24 lr=1.16e-03 loss=0.5777 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 31 train_loss=0.5777 val_loss=1.6457 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep32 step 24/24 lr=1.06e-03 loss=0.5711 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 32 train_loss=0.5711 val_loss=1.6367 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep33 step 24/24 lr=9.63e-04 loss=0.5587 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 33 train_loss=0.5587 val_loss=1.6292 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep34 step 24/24 lr=8.68e-04 loss=0.5544 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 34 train_loss=0.5544 val_loss=1.6226 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep35 step 24/24 lr=7.76e-04 loss=0.5470 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 35 train_loss=0.5470 val_loss=1.6170 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep36 step 24/24 lr=6.88e-04 loss=0.5391 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 36 train_loss=0.5391 val_loss=1.6129 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep37 step 24/24 lr=6.04e-04 loss=0.5350 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 37 train_loss=0.5350 val_loss=1.6095 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep38 step 24/24 lr=5.25e-04 loss=0.5304 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 38 train_loss=0.5304 val_loss=1.6067 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep39 step 24/24 lr=4.50e-04 loss=0.5255 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 39 train_loss=0.5255 val_loss=1.6041 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep40 step 24/24 lr=3.80e-04 loss=0.5228 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 40 train_loss=0.5228 val_loss=1.6020 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep41 step 24/24 lr=3.16e-04 loss=0.5208 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 41 train_loss=0.5208 val_loss=1.6006 epoch_time=2.8s total=1.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep42 step 24/24 lr=2.58e-04 loss=0.5162 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 42 train_loss=0.5162 val_loss=1.5994 epoch_time=2.6s total=1.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep43 step 24/24 lr=2.06e-04 loss=0.5152 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 43 train_loss=0.5152 val_loss=1.5983 epoch_time=2.8s total=2.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep44 step 24/24 lr=1.60e-04 loss=0.5116 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 44 train_loss=0.5116 val_loss=1.5979 epoch_time=2.6s total=2.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep45 step 24/24 lr=1.21e-04 loss=0.5112 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 45 train_loss=0.5112 val_loss=1.5975 epoch_time=2.6s total=2.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep46 step 24/24 lr=8.87e-05 loss=0.5105 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 46 train_loss=0.5105 val_loss=1.5972 epoch_time=2.7s total=2.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep47 step 24/24 lr=6.34e-05 loss=0.5094 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 47 train_loss=0.5094 val_loss=1.5969 epoch_time=2.6s total=2.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep48 step 24/24 lr=4.51e-05 loss=0.5087 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 48 train_loss=0.5087 val_loss=1.5971 epoch_time=2.6s total=2.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep49 step 24/24 lr=3.39e-05 loss=0.5096 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 49 train_loss=0.5096 val_loss=1.5973 epoch_time=2.6s total=2.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep50 step 24/24 lr=3.00e-05 loss=0.5039 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 seed2] Epoch 50 train_loss=0.5039 val_loss=1.5978 epoch_time=2.6s total=2.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 seed2 done. Best val CE=1.5969. Model -> model_ce_fold1_s1.pth\n=== Train fold 2 (seed2): train_n=197 val_n=100 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep1 step 24/24 lr=5.75e-04 loss=3.8870 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 1 train_loss=3.8870 val_loss=5.2328 epoch_time=2.6s total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep2 step 24/24 lr=1.18e-03 loss=2.5170 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 2 train_loss=2.5170 val_loss=4.9687 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep3 step 24/24 lr=1.78e-03 loss=1.8888 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 3 train_loss=1.8888 val_loss=4.7228 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep4 step 24/24 lr=2.37e-03 loss=1.5874 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 4 train_loss=1.5874 val_loss=4.5057 epoch_time=2.7s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep5 step 24/24 lr=2.98e-03 loss=1.4474 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 5 train_loss=1.4474 val_loss=4.3084 epoch_time=2.7s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep6 step 24/24 lr=3.00e-03 loss=1.3688 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 6 train_loss=1.3688 val_loss=4.1181 epoch_time=2.7s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep7 step 24/24 lr=2.99e-03 loss=1.2299 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 7 train_loss=1.2299 val_loss=3.9397 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep8 step 24/24 lr=2.97e-03 loss=1.1676 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 8 train_loss=1.1676 val_loss=3.7722 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep9 step 24/24 lr=2.94e-03 loss=1.0639 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 9 train_loss=1.0639 val_loss=3.6144 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep10 step 24/24 lr=2.91e-03 loss=1.0345 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 10 train_loss=1.0345 val_loss=3.4615 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep11 step 24/24 lr=2.87e-03 loss=1.0037 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 11 train_loss=1.0037 val_loss=3.3071 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep12 step 24/24 lr=2.83e-03 loss=0.9477 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 12 train_loss=0.9477 val_loss=3.1638 epoch_time=2.7s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep13 step 24/24 lr=2.78e-03 loss=0.9207 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 13 train_loss=0.9207 val_loss=3.0243 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep14 step 24/24 lr=2.72e-03 loss=0.8855 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 14 train_loss=0.8855 val_loss=2.8873 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep15 step 24/24 lr=2.66e-03 loss=0.8457 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 15 train_loss=0.8457 val_loss=2.7586 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep16 step 24/24 lr=2.59e-03 loss=0.8414 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 16 train_loss=0.8414 val_loss=2.6417 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep17 step 24/24 lr=2.51e-03 loss=0.8094 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 17 train_loss=0.8094 val_loss=2.5342 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep18 step 24/24 lr=2.43e-03 loss=0.7856 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 18 train_loss=0.7856 val_loss=2.4377 epoch_time=2.7s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep19 step 24/24 lr=2.35e-03 loss=0.8012 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 19 train_loss=0.8012 val_loss=2.3527 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep20 step 24/24 lr=2.26e-03 loss=0.7446 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 20 train_loss=0.7446 val_loss=2.2797 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep21 step 24/24 lr=2.17e-03 loss=0.7158 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 21 train_loss=0.7158 val_loss=2.2169 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep22 step 24/24 lr=2.08e-03 loss=0.7068 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 22 train_loss=0.7068 val_loss=2.1629 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep23 step 24/24 lr=1.98e-03 loss=0.6889 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 23 train_loss=0.6889 val_loss=2.1184 epoch_time=2.7s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep24 step 24/24 lr=1.88e-03 loss=0.6853 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 24 train_loss=0.6853 val_loss=2.0802 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep25 step 24/24 lr=1.78e-03 loss=0.6654 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 25 train_loss=0.6654 val_loss=2.0507 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep26 step 24/24 lr=1.67e-03 loss=0.6536 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 26 train_loss=0.6536 val_loss=2.0244 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep27 step 24/24 lr=1.57e-03 loss=0.6499 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 27 train_loss=0.6499 val_loss=2.0041 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep28 step 24/24 lr=1.47e-03 loss=0.6342 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 28 train_loss=0.6342 val_loss=1.9867 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep29 step 24/24 lr=1.36e-03 loss=0.6140 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 29 train_loss=0.6140 val_loss=1.9741 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep30 step 24/24 lr=1.26e-03 loss=0.6084 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 30 train_loss=0.6084 val_loss=1.9643 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep31 step 24/24 lr=1.16e-03 loss=0.5988 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 31 train_loss=0.5988 val_loss=1.9577 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep32 step 24/24 lr=1.06e-03 loss=0.5895 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 32 train_loss=0.5895 val_loss=1.9521 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep33 step 24/24 lr=9.63e-04 loss=0.5922 elapsed=2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 33 train_loss=0.5922 val_loss=1.9484 epoch_time=2.8s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep34 step 24/24 lr=8.68e-04 loss=0.5791 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 34 train_loss=0.5791 val_loss=1.9461 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep35 step 24/24 lr=7.76e-04 loss=0.5776 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 35 train_loss=0.5776 val_loss=1.9459 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best to model_ce_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep36 step 24/24 lr=6.88e-04 loss=0.5689 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 36 train_loss=0.5689 val_loss=1.9461 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep37 step 24/24 lr=6.04e-04 loss=0.5641 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 37 train_loss=0.5641 val_loss=1.9471 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep38 step 24/24 lr=5.25e-04 loss=0.5647 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 38 train_loss=0.5647 val_loss=1.9496 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep39 step 24/24 lr=4.50e-04 loss=0.5580 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 39 train_loss=0.5580 val_loss=1.9522 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep40 step 24/24 lr=3.80e-04 loss=0.5526 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 seed2] Epoch 40 train_loss=0.5526 val_loss=1.9557 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Early stop at epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 seed2 done. Best val CE=1.9459. Model -> model_ce_fold2_s1.pth\nAll folds (seed2) processed.\n"
          ]
        }
      ]
    },
    {
      "id": "b70e5ced-81fb-49ee-9ced-a43a6df2c99b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build 6-model CE ensemble: cache OOF for seed2, average OOF per fold, sweep decoder, infer test, write submission\n",
        "import os, json, time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA:', torch.cuda.is_available(), flush=True)\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def load_feat(split, sid:int):\n",
        "    d = np.load((feat_tr_dir if split=='train' else feat_te_dir)/f\"{sid}.npz\");\n",
        "    return d['X'].astype(np.float32)\n",
        "\n",
        "def compute_fold_scaler(id_list):\n",
        "    n = 0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = load_feat('train', int(sid)); n_i = X.shape[0]\n",
        "        if mean is None:\n",
        "            mean = X.mean(axis=0); M2 = ((X - mean)**2).sum(axis=0); n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0); n_new = n + n_i; delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new))\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new)); n = n_new\n",
        "    var = M2 / max(1, (n - 1)); std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__();\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch); self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1); self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h);\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True);\n",
        "        return x + h\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__();\n",
        "        self.inp = nn.Conv1d(d_in, channels, 1); blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3));\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks); self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2); h = self.inp(x);\n",
        "        for b in self.blocks: h = b(h);\n",
        "        out = self.head(h); return out.transpose(1,2)\n",
        "\n",
        "def time_warp_probs(p_t_c: torch.Tensor, factor: float) -> torch.Tensor:\n",
        "    T, C = p_t_c.shape; tgt_len = max(1, int(round(T*factor)));\n",
        "    x = p_t_c.T.unsqueeze(0);\n",
        "    y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False);\n",
        "    y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T;\n",
        "    return y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        ps = time_warp_probs(p_t_c, s);\n",
        "        acc = ps if acc is None else (acc + ps)\n",
        "    out = acc / float(len(factors))\n",
        "    return out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2);\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k = max(1, int(k)); x = p_t.view(1,1,-1);\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "    pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1);\n",
        "    T = p_t.shape[0]\n",
        "    if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]))\n",
        "    elif y.shape[0] > T: y = y[:T]\n",
        "    return y\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T = p.shape[0]; a = max(0, t_star - w); b = min(T-1, t_star + w);\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype);\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8;\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def decode_peaks(p_t_c: torch.Tensor, med_k: dict, gamma: float = 1.0, pool_k=13, temp=0.9):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k); T, C = p_s.shape;\n",
        "    scores = torch.empty_like(p_s); ks=[13]*C\n",
        "    for c in range(C):\n",
        "        if c==0: scores[:,c]=p_s[:,c]; ks[c]=13; continue\n",
        "        base_k = med_k.get(c, 13); k = int(np.clip(round(gamma * base_k), 9, 25));\n",
        "        if k % 2 == 0: k = min(25, k + 1); ks[c]=k;\n",
        "        scores[:,c] = duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks=[]\n",
        "    for c in range(1,21):\n",
        "        k=ks[c]; w_com = max(5, k//3); radius = max(10, k//2); s=scores[:,c];\n",
        "        t_star = int(torch.argmax(s).item()); t_ref = refine_com(p_s[:,c], t_star, w=w_com);\n",
        "        t_idx = int(round(max(0, min(t_ref, T-1))));\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item();\n",
        "        pooled_at_ref = p_s[t_idx, c].item();\n",
        "        peaks.append([c, t_ref, float(scores[t_idx,c].item()), float(local_mean), float(pooled_at_ref)])\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3], -x[4]));\n",
        "    last_t = -1e9\n",
        "    for i in range(len(peaks)):\n",
        "        if peaks[i][1] <= last_t: peaks[i][1] = last_t + 2.0;\n",
        "        last_t = min(peaks[i][1], float(T-1))\n",
        "    return [int(c) for c,_,_,_,_ in peaks]\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# 1) Cache OOF for seed2: per-fold model on its own val_ids, TTA=(0.9,1.0,1.1); save as {sid}_ce_new_s1.npy\n",
        "def cache_fold_val_probs_seed2(fold):\n",
        "    fold_idx = int(fold['fold'])\n",
        "    ckpt = Path(f\"model_ce_fold{fold_idx}_s1.pth\");\n",
        "    assert ckpt.exists(), f\"Missing {ckpt}; train seed2 models first\"\n",
        "    D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "    model = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device)); model.eval()\n",
        "    mean,std = compute_fold_scaler(fold['train_ids'])\n",
        "    mean_t = torch.from_numpy(mean).float().to(device); std_t = torch.from_numpy(std).float().to(device)\n",
        "    vids = fold['val_ids']; t0=time.time()\n",
        "    for i, sid in enumerate(vids, 1):\n",
        "        sid=int(sid); outp = probs_cache/f\"{sid}_ce_new_s1.npy\"\n",
        "        if outp.exists():\n",
        "            if (i%25)==0 or i==len(vids):\n",
        "                print(f\"  [fold {fold_idx} s1] cached {i}/{len(vids)} elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "            continue\n",
        "        X = load_feat('train', sid); xb = torch.from_numpy(X).float().to(device);\n",
        "        xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0)\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "            probs = model(xb)[0].softmax(dim=-1);\n",
        "            probs = apply_tta_timewarp(probs, factors=(0.9,1.0,1.1))\n",
        "        np.save(outp, probs.cpu().numpy())\n",
        "        if (i%25)==0 or i==len(vids):\n",
        "            print(f\"  [fold {fold_idx} s1] cached {i}/{len(vids)} elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "def load_cached_prob_seed(sid:int, seed:int):\n",
        "    if seed==0:\n",
        "        return torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new.npy\")).to(device)\n",
        "    else:\n",
        "        return torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new_s1.npy\")).to(device)\n",
        "\n",
        "print('Caching OOF probs for seed2...', flush=True)\n",
        "for f in folds: cache_fold_val_probs_seed2(f)\n",
        "\n",
        "# 2) Sweep decoder on averaged OOF (seed0+seed1) with per-fold priors; select by worst-fold then mean\n",
        "pool_ks=[11,13,15]; temps=[0.90,0.95,1.00]; gammas=[0.90,0.95,0.975,1.00,1.025,1.05]\n",
        "med_cache={}\n",
        "def eval_cfg_on_fold_avg(fold, pool_k, temp, gamma):\n",
        "    fi = int(fold['fold'])\n",
        "    if fi not in med_cache: med_cache[fi] = compute_class_median_durations_for_ids(fold['train_ids'])\n",
        "    med_k = med_cache[fi]\n",
        "    vids = fold['val_ids']; tot=0; cnt=0\n",
        "    for sid in vids:\n",
        "        p0 = load_cached_prob_seed(int(sid), 0); p1 = load_cached_prob_seed(int(sid), 1);\n",
        "        p = (p0 + p1) * 0.5; p = p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        seq = decode_peaks(p, med_k=med_k, gamma=gamma, pool_k=pool_k, temp=temp)\n",
        "        tot += levenshtein(seq, id2seq[int(sid)]); cnt += 1\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "res=[]\n",
        "for pool_k in pool_ks:\n",
        "    for temp in temps:\n",
        "        for gamma in gammas:\n",
        "            per_fold=[]\n",
        "            for f in folds:\n",
        "                lev = eval_cfg_on_fold_avg(f, pool_k, temp, gamma); per_fold.append(lev)\n",
        "            res.append((np.mean(per_fold), np.max(per_fold), {'pool_k':pool_k, 'temp':temp, 'gamma':gamma}))\n",
        "res.sort(key=lambda x: (x[1], x[0]))\n",
        "print('Top CE-only 6x (avg OOF):')\n",
        "for r in res[:5]: print(r)\n",
        "pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res]).to_csv('cv_sweep_ce_6x.csv', index=False)\n",
        "print('Saved cv_sweep_ce_6x.csv', flush=True)\n",
        "\n",
        "# 3) Test inference: load all 6 CE models; per-model standardize with its fold scaler; TTA=(0.9,1.0,1.1); average probs; decode with best cfg\n",
        "print('Building CE 6-model ensemble test submission...', flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "cfg_best = pd.read_csv('cv_sweep_ce_6x.csv').sort_values(['worst','mean']).iloc[0].to_dict() if Path('cv_sweep_ce_6x.csv').exists() else {'pool_k':13,'temp':0.95,'gamma':1.0}\n",
        "pool_k=int(cfg_best['pool_k']); temp=float(cfg_best['temp']); gamma=float(cfg_best.get('gamma',1.0))\n",
        "med_k_test = compute_class_median_durations_for_ids(pd.read_csv('training.csv')['Id'].astype(int).tolist())\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "models=[]; scalers=[]\n",
        "for fi in range(3):\n",
        "    for s in (0,1):\n",
        "        ckpt = Path(f\"model_ce_fold{fi}{'_s1' if s==1 else ''}.pth\");\n",
        "        if not ckpt.exists():\n",
        "            print(f\"WARNING: missing {ckpt}; skipping\")\n",
        "            continue\n",
        "        m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "        m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval(); models.append(m)\n",
        "        mean,std = compute_class_median_durations_for_ids([]), None  # placeholder to keep scope\n",
        "    # per-fold scaler computed once and reused for both seeds\n",
        "for fi in range(3):\n",
        "    mean,std = compute_fold_scaler(folds[fi]['train_ids'])\n",
        "    scalers.append((torch.from_numpy(mean).float().to(device), torch.from_numpy(std).float().to(device)))\n",
        "\n",
        "rows=[]; t0=time.time()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    X = load_feat('test', int(sid));\n",
        "    acc=None\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "        mi = 0\n",
        "        for fi in range(3):\n",
        "            mean_t, std_t = scalers[fi]\n",
        "            for s in (0,1):\n",
        "                ckpt = Path(f\"model_ce_fold{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                if not ckpt.exists():\n",
        "                    continue\n",
        "                # lazy load per model to keep VRAM low\n",
        "                m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                xb = torch.from_numpy(X).float().to(device);\n",
        "                xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0);\n",
        "                p = m(xb)[0].softmax(dim=-1);\n",
        "                p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1));\n",
        "                acc = p if acc is None else (acc + p)\n",
        "                del m\n",
        "        probs = acc / float(6); probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    seq = decode_peaks(probs, med_k=med_k_test, gamma=gamma, pool_k=pool_k, temp=temp)\n",
        "    rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if (i%10)==0 or i==len(test_ids):\n",
        "        print(f\"  [infer CE-6x] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "sub.to_csv('submission_primary_ce_6x.csv', index=False);\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission_primary_ce_6x.csv and submission.csv; head:\\n', sub.head(), flush=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching OOF probs for seed2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/2445870380.py:154: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(ckpt, map_location=device)); model.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 s1] cached 25/98 elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 s1] cached 50/98 elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 s1] cached 75/98 elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 s1] cached 98/98 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 s1] cached 25/99 elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 s1] cached 50/99 elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 s1] cached 75/99 elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 s1] cached 99/99 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 s1] cached 25/100 elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 s1] cached 50/100 elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 s1] cached 75/100 elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 s1] cached 100/100 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top CE-only 6x (avg OOF):\n(4.469703841132413, 5.1, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.95})\n(4.469703841132413, 5.1, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.975})\n(4.469703841132413, 5.1, {'pool_k': 11, 'temp': 0.9, 'gamma': 1.0})\n(4.469703841132413, 5.1, {'pool_k': 11, 'temp': 0.9, 'gamma': 1.025})\n(4.469703841132413, 5.1, {'pool_k': 11, 'temp': 0.9, 'gamma': 1.05})\nSaved cv_sweep_ce_6x.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building CE 6-model ensemble test submission...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/2445870380.py:227: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval(); models.append(m)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/2445870380.py:248: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x] 30/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x] 40/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x] 50/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x] 60/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x] 70/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x] 80/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x] 90/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x] 95/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_6x.csv and submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 7 1...\n1  301  10 12 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 3 1...\n2  302  1 17 16 12 5 19 7 13 20 18 11 3 4 6 15 8 14 10...\n3  303  13 4 12 1 10 14 5 19 15 20 17 11 16 8 18 7 3 6...\n4  304  8 1 12 14 18 13 9 7 2 11 3 20 19 5 10 6 15 17 ...\n"
          ]
        }
      ]
    },
    {
      "id": "b8763d5b-81e9-4159-a4db-d47d8b256bc2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Improved decoder + re-sweep on averaged OOF (6x CE) + rebuild submission (no retrain)\n",
        "import os, json, time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA:', torch.cuda.is_available(), flush=True)\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "probs_cache = Path('probs_cache')\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def load_feat(split, sid:int):\n",
        "    d = np.load((feat_tr_dir if split=='train' else feat_te_dir)/f\"{sid}.npz\");\n",
        "    return d['X'].astype(np.float32)\n",
        "\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "\n",
        "def time_warp_probs(p_t_c: torch.Tensor, factor: float) -> torch.Tensor:\n",
        "    T, C = p_t_c.shape; tgt_len = max(1, int(round(T*factor)));\n",
        "    x = p_t_c.T.unsqueeze(0);\n",
        "    y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False);\n",
        "    y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T;\n",
        "    return y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        ps = time_warp_probs(p_t_c, s);\n",
        "        acc = ps if acc is None else (acc + ps)\n",
        "    out = acc / float(len(factors))\n",
        "    return out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2);\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k = max(1, int(k)); x = p_t.view(1,1,-1);\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "    pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1);\n",
        "    T = p_t.shape[0]\n",
        "    if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]))\n",
        "    elif y.shape[0] > T: y = y[:T]\n",
        "    return y\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# Improved decoder pieces\n",
        "def topk_candidates_per_class(p_s: torch.Tensor, scores: torch.Tensor, c: int, k_c: int, temp: float, K: int = 3):\n",
        "    # return up to K candidate (time_refined, score_tuple) for class c\n",
        "    T = p_s.shape[0]\n",
        "    s = scores[:, c]\n",
        "    vals, idxs = torch.topk(s, k=min(K, T))\n",
        "    cand = []\n",
        "    w_com = max(5, k_c//3); radius = max(10, k_c//2)\n",
        "    for v, t_star in zip(vals.tolist(), idxs.tolist()):\n",
        "        t_ref = refine_com(p_s[:,c], int(t_star), w=w_com)\n",
        "        t_idx = int(round(max(0, min(t_ref, T-1))))\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        pooled_at_ref = p_s[t_idx, c].item()\n",
        "        cand.append((t_ref, float(v), float(local_mean), float(pooled_at_ref)))\n",
        "    # sort by refined time, then score desc, then local stats desc\n",
        "    cand.sort(key=lambda x: (x[0], -x[1], -x[2], -x[3]))\n",
        "    return cand\n",
        "\n",
        "def decode_peaks_improved(p_t_c: torch.Tensor, med_k: dict, gamma: float = 1.0, pool_k=13, temp=0.9, min_sep=2, K=3, k_delta=4):\n",
        "    # temperature calibration\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    # base smoothing\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k); T, C = p_s.shape\n",
        "    # compute per-class kernel k_c and multi-scale duration integrals\n",
        "    scores = torch.zeros_like(p_s)\n",
        "    ks = [13]*C\n",
        "    for c in range(C):\n",
        "        if c == 0:\n",
        "            scores[:, c] = p_s[:, c]; ks[c]=13; continue\n",
        "        base_k = med_k.get(c, 13)\n",
        "        k_c = int(np.clip(round(gamma * base_k), 9, 25))\n",
        "        if k_c % 2 == 0: k_c = min(25, k_c + 1)\n",
        "        ks[c] = k_c\n",
        "        # multi-scale\n",
        "        ks_multi = sorted(set([int(np.clip(k_c - k_delta, 9, 25)), k_c, int(np.clip(k_c + k_delta, 9, 25))]))\n",
        "        ks_multi = [k if (k % 2)==1 else min(25, k+1) for k in ks_multi]\n",
        "        acc=None\n",
        "        for k in ks_multi:\n",
        "            di = duration_integral_single(p_s[:, c], k=k).unsqueeze(1)\n",
        "            acc = di if acc is None else (acc + di)\n",
        "        scores[:, c] = (acc / float(len(ks_multi))).squeeze(1)\n",
        "    # build candidate list per class\n",
        "    all_cand = []\n",
        "    for c in range(1,21):\n",
        "        cand = topk_candidates_per_class(p_s, scores, c, ks[c], temp=temp, K=K)\n",
        "        if len(cand)==0:\n",
        "            all_cand.append((c, 0.0, -1e9, -1e9, -1e9))\n",
        "        else:\n",
        "            # pick best candidate per class after monotonic assignment below; store all\n",
        "            for (t_ref, v, lm, pr) in cand:\n",
        "                all_cand.append((c, t_ref, v, lm, pr))\n",
        "    # monotonic assignment: one slot per class, increasing times with min separation\n",
        "    # greedy: sort by time, then score desc; enforce separation\n",
        "    all_cand.sort(key=lambda x: (x[1], -x[2], -x[3], -x[4]))\n",
        "    chosen = {}  # class -> (t_ref, scores)\n",
        "    last_t = -1e9\n",
        "    for c, t_ref, v, lm, pr in all_cand:\n",
        "        if c in chosen:\n",
        "            continue\n",
        "        if t_ref <= last_t + float(min_sep):\n",
        "            # shift forward minimally\n",
        "            t_ref = last_t + float(min_sep)\n",
        "        last_t = min(t_ref, float(T-1))\n",
        "        chosen[c] = (last_t, v, lm, pr)\n",
        "        if len(chosen)==20:\n",
        "            break\n",
        "    # ensure all classes present (fallback times spaced if missing)\n",
        "    if len(chosen) < 20:\n",
        "        missing = [c for c in range(1,21) if c not in chosen]\n",
        "        t = max(last_t, 0.0)\n",
        "        for c in missing:\n",
        "            t = min(t + float(min_sep), float(T-1))\n",
        "            chosen[c] = (t, -1e9, -1e9, -1e9)\n",
        "    # sort by time to produce final sequence\n",
        "    seq = [c for c,_ in sorted(chosen.items(), key=lambda kv: kv[1][0])]\n",
        "    return seq\n",
        "\n",
        "# Per-sample gamma scaling based on length ratio\n",
        "def gamma_with_length(gamma_cv: float, T: int, med_k: dict):\n",
        "    L_est = float(sum(med_k.get(c,13) for c in range(1,21)))\n",
        "    if L_est <= 0:\n",
        "        return gamma_cv\n",
        "    ratio = float(T) / L_est\n",
        "    gamma_s = float(np.clip(ratio, 0.85, 1.15))\n",
        "    return float(gamma_cv * gamma_s)\n",
        "\n",
        "# Load averaged OOF (seed0+seed1) for each fold's val ids\n",
        "def load_oof_avg_for_id(sid:int):\n",
        "    p0 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new.npy\")).to(device)\n",
        "    p1 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new_s1.npy\")).to(device)\n",
        "    p = (p0 + p1) * 0.5\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "# Sweep over improved decoder params on OOF avg\n",
        "pool_ks=[11,13,15]; temps=[0.90,0.95,1.00]; gammas=[0.90,0.95,0.975,1.00,1.025,1.05]; seps=[2,3,4]\n",
        "print('Sweeping improved decoder on averaged OOF...', flush=True)\n",
        "med_cache={}\n",
        "def eval_cfg_on_fold_improved(fold, pool_k, temp, gamma, sep):\n",
        "    fi = int(fold['fold'])\n",
        "    if fi not in med_cache: med_cache[fi] = compute_class_median_durations_for_ids(fold['train_ids'])\n",
        "    med_k = med_cache[fi]\n",
        "    vids = fold['val_ids']; tot=0; cnt=0\n",
        "    for sid in vids:\n",
        "        sid = int(sid)\n",
        "        p = load_oof_avg_for_id(sid)\n",
        "        T = p.shape[0]\n",
        "        gamma_eff = gamma_with_length(gamma, T, med_k)\n",
        "        seq = decode_peaks_improved(p, med_k=med_k, gamma=gamma_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "        tot += levenshtein(seq, id2seq[sid]); cnt += 1\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "res=[]\n",
        "for pool_k in pool_ks:\n",
        "    for temp in temps:\n",
        "        for gamma in gammas:\n",
        "            for sep in seps:\n",
        "                per_fold=[]\n",
        "                for f in folds:\n",
        "                    lev = eval_cfg_on_fold_improved(f, pool_k, temp, gamma, sep); per_fold.append(lev)\n",
        "                res.append((np.mean(per_fold), np.max(per_fold), {'pool_k':pool_k, 'temp':temp, 'gamma':gamma, 'sep':sep}))\n",
        "res.sort(key=lambda x: (x[1], x[0]))\n",
        "print('Top improved decoder (mean, worst, cfg):')\n",
        "for r in res[:5]: print(r)\n",
        "pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res]).to_csv('cv_sweep_ce_6x_improved.csv', index=False)\n",
        "print('Saved cv_sweep_ce_6x_improved.csv', flush=True)\n",
        "\n",
        "# Test-time: load 6 CE models lazily, standardize per-fold, TTA=(0.9,1.0,1.1), improved decoder with gamma length scaling\n",
        "print('Building CE 6-model ensemble test submission (improved decoder)...', flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "cfg_best = pd.read_csv('cv_sweep_ce_6x_improved.csv').sort_values(['worst','mean']).iloc[0].to_dict() if Path('cv_sweep_ce_6x_improved.csv').exists() else {'pool_k':13,'temp':0.95,'gamma':1.0,'sep':2}\n",
        "pool_k=int(cfg_best['pool_k']); temp=float(cfg_best['temp']); gamma=float(cfg_best.get('gamma',1.0)); sep=int(cfg_best.get('sep',2))\n",
        "med_k_train_all = compute_class_median_durations_for_ids(pd.read_csv('training.csv')['Id'].astype(int).tolist())\n",
        "\n",
        "def compute_fold_scaler(id_list):\n",
        "    n = 0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = load_feat('train', int(sid)); n_i = X.shape[0]\n",
        "        if mean is None:\n",
        "            mean = X.mean(axis=0); M2 = ((X - mean)**2).sum(axis=0); n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0); n_new = n + n_i; delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new))\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new)); n = n_new\n",
        "    var = M2 / max(1, (n - 1)); std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "def load_fold_scalers():\n",
        "    scalers=[]\n",
        "    for fi in range(3):\n",
        "        mean,std = compute_fold_scaler(folds[fi]['train_ids'])\n",
        "        scalers.append((torch.from_numpy(mean).float().to(device), torch.from_numpy(std).float().to(device)))\n",
        "    return scalers\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__();\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch); self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1); self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h);\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True);\n",
        "        return x + h\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__();\n",
        "        self.inp = nn.Conv1d(d_in, channels, 1); blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3));\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks); self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2); h = self.inp(x);\n",
        "        for b in self.blocks: h = b(h);\n",
        "        out = self.head(h); return out.transpose(1,2)\n",
        "\n",
        "scalers = load_fold_scalers()\n",
        "rows=[]; t0=time.time()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    X = load_feat('test', int(sid));\n",
        "    T = X.shape[0]\n",
        "    acc=None\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "        for fi in range(3):\n",
        "            mean_t, std_t = scalers[fi]\n",
        "            for s in (0,1):\n",
        "                ckpt = Path(f\"model_ce_fold{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                if not ckpt.exists():\n",
        "                    continue\n",
        "                m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                xb = torch.from_numpy(X).float().to(device);\n",
        "                xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0);\n",
        "                p = m(xb)[0].softmax(dim=-1);\n",
        "                p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1));\n",
        "                acc = p if acc is None else (acc + p)\n",
        "                del m\n",
        "        probs = acc / float(6); probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    gamma_eff = gamma_with_length(gamma, T, med_k_train_all)\n",
        "    seq = decode_peaks_improved(probs, med_k=med_k_train_all, gamma=gamma_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "    rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if (i%10)==0 or i==len(test_ids):\n",
        "        print(f\"  [infer CE-6x improved] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "sub.to_csv('submission_primary_ce_6x_v2.csv', index=False)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission_primary_ce_6x_v2.csv and submission.csv; head:\\n', sub.head(), flush=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweeping improved decoder on averaged OOF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top improved decoder (mean, worst, cfg):\n(4.4864048649762935, 5.15, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.9, 'sep': 2})\n(4.4864048649762935, 5.15, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.9, 'sep': 3})\n(4.4864048649762935, 5.15, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.9, 'sep': 4})\n(4.4864048649762935, 5.15, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.95, 'sep': 2})\n(4.4864048649762935, 5.15, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.95, 'sep': 3})\nSaved cv_sweep_ce_6x_improved.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building CE 6-model ensemble test submission (improved decoder)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/1527191474.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x improved] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x improved] 20/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x improved] 30/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x improved] 40/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x improved] 50/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x improved] 60/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x improved] 70/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x improved] 80/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x improved] 90/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x improved] 95/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_6x_v2.csv and submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 7 1...\n1  301  10 12 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 3 1...\n2  302  1 17 16 12 5 19 7 13 20 18 11 3 4 6 15 8 14 10...\n3  303  13 4 12 1 10 14 5 19 15 20 17 11 16 8 18 7 3 6...\n4  304  8 1 12 14 18 13 9 7 2 11 3 20 19 5 10 6 15 17 ...\n"
          ]
        }
      ]
    },
    {
      "id": "ddcdd496-d27f-4df4-b70f-ac81ddd7250b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Decoder sanity checks: (A) OOF debug on a few samples, (B) Oracle one-hot GT probs test\n",
        "import json, numpy as np, pandas as pd, torch, torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "probs_cache = Path('probs_cache')\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "# Reuse helpers from earlier cells if present; otherwise minimal fallbacks\n",
        "def load_oof_avg_for_id(sid:int):\n",
        "    p0 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new.npy\")).to(device)\n",
        "    p1 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new_s1.npy\")).to(device)\n",
        "    p = (p0 + p1) * 0.5\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    lab_tr_dir = Path('labels3d_v2')/'train'\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "\n",
        "# If decode_peaks_improved/gamma_with_length not in globals (e.g., fresh kernel), import from Cell 10 context by redefining minimal versions\n",
        "if 'decode_peaks_improved' not in globals():\n",
        "    # Minimal dependencies\n",
        "    def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "        x = p_t_c.unsqueeze(0).transpose(1,2); y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "        return y.transpose(1,2).squeeze(0)\n",
        "    def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "        k = max(1, int(k)); x = p_t.view(1,1,-1); w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "        pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1); T = p_t.shape[0]\n",
        "        if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]));\n",
        "        elif y.shape[0] > T: y = y[:T];\n",
        "        return y\n",
        "    def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "        T = p.shape[0]; a=max(0,t_star-w); b=min(T-1,t_star+w); idx=torch.arange(a,b+1, device=p.device, dtype=p.dtype);\n",
        "        seg=p[a:b+1]; s=seg.sum()+1e-8; return float(((idx*seg).sum()/s).item())\n",
        "    def topk_candidates_per_class(p_s: torch.Tensor, scores: torch.Tensor, c: int, k_c: int, temp: float, K: int = 3):\n",
        "        T = p_s.shape[0]; s = scores[:, c]; vals, idxs = torch.topk(s, k=min(K, T));\n",
        "        cand=[]; w_com=max(5,k_c//3); radius=max(10,k_c//2)\n",
        "        for v, t_star in zip(vals.tolist(), idxs.tolist()):\n",
        "            t_ref = refine_com(p_s[:,c], int(t_star), w=w_com); t_idx=int(round(max(0, min(t_ref, T-1))));\n",
        "            local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item(); pooled_at_ref = p_s[t_idx, c].item();\n",
        "            cand.append((t_ref, float(v), float(local_mean), float(pooled_at_ref)))\n",
        "        cand.sort(key=lambda x: (x[0], -x[1], -x[2], -x[3])); return cand\n",
        "    def decode_peaks_improved(p_t_c: torch.Tensor, med_k: dict, gamma: float = 1.0, pool_k=13, temp=0.9, min_sep=2, K=3, k_delta=4):\n",
        "        if temp != 1.0:\n",
        "            p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        p_s = avg_pool_probs(p_t_c, k=pool_k); T, C = p_s.shape; scores = torch.zeros_like(p_s); ks=[13]*C\n",
        "        for c in range(C):\n",
        "            if c==0: scores[:,c]=p_s[:,c]; ks[c]=13; continue\n",
        "            base_k = med_k.get(c, 13); k_c = int(np.clip(round(gamma*base_k), 9, 25));\n",
        "            if k_c % 2 == 0: k_c = min(25, k_c + 1); ks[c]=k_c\n",
        "            ks_multi = sorted(set([int(np.clip(k_c - k_delta, 9, 25)), k_c, int(np.clip(k_c + k_delta, 9, 25))]));\n",
        "            ks_multi = [k if (k % 2)==1 else min(25, k+1) for k in ks_multi]; acc=None\n",
        "            for k in ks_multi:\n",
        "                di = duration_integral_single(p_s[:, c], k=k).unsqueeze(1); acc = di if acc is None else (acc + di)\n",
        "            scores[:, c] = (acc / float(len(ks_multi))).squeeze(1)\n",
        "        all_cand=[]\n",
        "        for c in range(1,21):\n",
        "            cand = topk_candidates_per_class(p_s, scores, c, ks[c], temp=temp, K=K)\n",
        "            if len(cand)==0: all_cand.append((c, 0.0, -1e9, -1e9, -1e9))\n",
        "            else:\n",
        "                for (t_ref, v, lm, pr) in cand: all_cand.append((c, t_ref, v, lm, pr))\n",
        "        all_cand.sort(key=lambda x: (x[1], -x[2], -x[3], -x[4])); chosen={}; last_t=-1e9\n",
        "        for c, t_ref, v, lm, pr in all_cand:\n",
        "            if c in chosen: continue\n",
        "            if t_ref <= last_t + 2.0: t_ref = last_t + 2.0\n",
        "            last_t = min(t_ref, float(T-1)); chosen[c]=(last_t, v, lm, pr)\n",
        "            if len(chosen)==20: break\n",
        "        if len(chosen) < 20:\n",
        "            missing = [c for c in range(1,21) if c not in chosen]; t = max(last_t, 0.0)\n",
        "            for c in missing: t = min(t + 2.0, float(T-1)); chosen[c]=(t,-1e9,-1e9,-1e9)\n",
        "        seq = [c for c,_ in sorted(chosen.items(), key=lambda kv: kv[1][0])]; return seq\n",
        "    def gamma_with_length(gamma_cv: float, T: int, med_k: dict):\n",
        "        L_est = float(sum(med_k.get(c,13) for c in range(1,21)));\n",
        "        if L_est <= 0: return gamma_cv\n",
        "        ratio = float(T) / L_est; gamma_s = float(np.clip(ratio, 0.85, 1.15)); return float(gamma_cv * gamma_s)\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# Load best improved-decoder cfg if available\n",
        "cfg_path = Path('cv_sweep_ce_6x_improved.csv')\n",
        "if cfg_path.exists():\n",
        "    cfg_best = pd.read_csv(cfg_path).sort_values(['worst','mean']).iloc[0].to_dict()\n",
        "    pool_k=int(cfg_best['pool_k']); temp=float(cfg_best['temp']); gamma=float(cfg_best.get('gamma',1.0)); sep=int(cfg_best.get('sep',2))\n",
        "else:\n",
        "    pool_k, temp, gamma, sep = 13, 0.95, 1.0, 2\n",
        "\n",
        "# (A) OOF debug on 6 samples from fold 0\n",
        "f0 = folds[0]\n",
        "med_k_f0 = compute_class_median_durations_for_ids(f0['train_ids'])\n",
        "print('--- OOF debug (fold 0) ---', flush=True)\n",
        "for sid in list(f0['val_ids'])[:6]:\n",
        "    p = load_oof_avg_for_id(int(sid))\n",
        "    T = p.shape[0]\n",
        "    gamma_eff = gamma_with_length(gamma, T, med_k_f0)\n",
        "    seq = decode_peaks_improved(p, med_k=med_k_f0, gamma=gamma_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "    gt = id2seq[int(sid)]\n",
        "    ld = levenshtein(seq, gt)\n",
        "    uniq = len(set(seq))\n",
        "    print(f\"sid={sid} T={T} LD={ld} uniq={uniq} seq[:5]={seq[:5]} ...\", flush=True)\n",
        "\n",
        "# (B) Oracle test: construct near one-hot GT probs and ensure decoder recovers GT (LD\u22480)\n",
        "print('--- Oracle decoder test ---', flush=True)\n",
        "def build_oracle_probs(T:int, gt_seq, med_k):\n",
        "    # place Gaussian-like peaks for each class at cumulative centers spaced by med_k\n",
        "    C=21; p = torch.full((T,C), 1e-8, device=device, dtype=torch.float32);\n",
        "    centers=[]; t=0\n",
        "    for c in gt_seq:\n",
        "        k = int(np.clip(med_k.get(c,13), 9, 25));\n",
        "        t = min(t + max(3, k//2), T-1); centers.append(t); t = min(t + max(3, k//2), T-1)\n",
        "    if len(centers)>0 and centers[-1] < T-1:\n",
        "        # spread remaining\n",
        "        pass\n",
        "    for c, t0 in zip(gt_seq, centers):\n",
        "        width = 3\n",
        "        for dt in range(-3*width, 3*width+1):\n",
        "            tt = int(np.clip(t0+dt, 0, T-1))\n",
        "            p[tt, c] = max(p[tt, c].item(), float(np.exp(-0.5*(dt/width)**2)))\n",
        "    p = p / (p.sum(dim=-1, keepdim=True) + 1e-8);\n",
        "    return p\n",
        "\n",
        "tested = 0\n",
        "for sid in list(f0['val_ids'])[:6]:\n",
        "    gt = id2seq[int(sid)]\n",
        "    # estimate a T similar to OOF probs for this sid\n",
        "    p_oof = load_oof_avg_for_id(int(sid)); T = p_oof.shape[0]\n",
        "    p_oracle = build_oracle_probs(T, gt, med_k_f0)\n",
        "    gamma_eff = gamma_with_length(gamma, T, med_k_f0)\n",
        "    seq_or = decode_peaks_improved(p_oracle, med_k=med_k_f0, gamma=gamma_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "    ld_or = levenshtein(seq_or, gt)\n",
        "    print(f\"sid={sid} ORACLE LD={ld_or} uniq={len(set(seq_or))} seq[:5]={seq_or[:5]} ...\", flush=True)\n",
        "    tested += 1\n",
        "    if tested>=4: break\n",
        "print('Decoder sanity checks done.', flush=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- OOF debug (fold 0) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sid=1 T=1254 LD=0 uniq=20 seq[:5]=[2, 14, 20, 6, 7] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sid=3 T=1117 LD=2 uniq=20 seq[:5]=[12, 3, 17, 18, 14] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sid=4 T=1336 LD=0 uniq=20 seq[:5]=[13, 1, 8, 18, 7] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sid=5 T=1334 LD=0 uniq=20 seq[:5]=[10, 4, 7, 13, 19] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sid=6 T=1202 LD=0 uniq=20 seq[:5]=[14, 15, 10, 16, 11] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sid=7 T=1124 LD=2 uniq=20 seq[:5]=[19, 10, 11, 12, 9] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Oracle decoder test ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sid=1 ORACLE LD=0 uniq=20 seq[:5]=[2, 14, 20, 6, 7] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sid=3 ORACLE LD=0 uniq=20 seq[:5]=[12, 3, 18, 14, 16] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sid=4 ORACLE LD=0 uniq=20 seq[:5]=[13, 1, 8, 18, 7] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sid=5 ORACLE LD=0 uniq=20 seq[:5]=[10, 4, 7, 13, 19] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder sanity checks done.\n"
          ]
        }
      ]
    },
    {
      "id": "22666ab3-2e80-4279-93c4-409baf36aeee",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train CE+TC DilatedTCN per fold (3 folds) with 2 seeds, per expert recipe\n",
        "import os, json, math, time, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA available:', torch.cuda.is_available(), flush=True)\n",
        "assert torch.cuda.is_available(), 'GPU required for timely training'\n",
        "torch.backends.cudnn.benchmark = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)  # FIXED: conv2(h) not conv2(x)\n",
        "        return x + h\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, 1)\n",
        "        blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for b in self.blocks:\n",
        "            h = b(h)\n",
        "        out = self.head(h)\n",
        "        return out.transpose(1,2)  # B,T,C\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.decay = decay\n",
        "        self.shadow = {n: p.detach().clone() for n,p in model.named_parameters() if p.requires_grad}\n",
        "    @torch.no_grad()\n",
        "    def update(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[n].mul_(self.decay).add_(p.detach(), alpha=1.0 - self.decay)\n",
        "    def apply_to(self, model):\n",
        "        self.backup = {}\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.backup[n] = p.detach().clone()\n",
        "                p.data.copy_(self.shadow[n].data)\n",
        "    def restore(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                p.data.copy_(self.backup[n].data)\n",
        "\n",
        "def load_feat_full(sample_id: int):\n",
        "    d = np.load((feat_tr_dir/f\"{sample_id}.npz\"))\n",
        "    return d['X'].astype(np.float32)\n",
        "def load_labels(sample_id: int):\n",
        "    return np.load(lab_tr_dir/f\"{sample_id}.npy\").astype(np.int64)\n",
        "\n",
        "def compute_fold_scaler(id_list):\n",
        "    n = 0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = load_feat_full(int(sid))\n",
        "        n_i = X.shape[0]\n",
        "        if mean is None:\n",
        "            mean = X.mean(axis=0)\n",
        "            M2 = ((X - mean)**2).sum(axis=0)\n",
        "            n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0)\n",
        "            n_new = n + n_i\n",
        "            delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new))\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new))\n",
        "            n = n_new\n",
        "    var = M2 / max(1, (n - 1))\n",
        "    std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def compute_class_weights(train_ids):\n",
        "    counts = np.zeros(21, dtype=np.int64)\n",
        "    for sid in train_ids:\n",
        "        y = load_labels(int(sid))\n",
        "        vals, cnts = np.unique(y, return_counts=True)\n",
        "        for v, c in zip(vals, cnts):\n",
        "            if 0 <= v <= 20:\n",
        "                counts[v] += int(c)\n",
        "    freq = counts / max(1, counts.sum())\n",
        "    w = 1.0 / np.sqrt(np.clip(freq, 1e-12, None))\n",
        "    w = w / w.mean()\n",
        "    w0_cap = 0.7 * w.mean()\n",
        "    w[0] = min(w[0], w0_cap)\n",
        "    return torch.tensor(w, dtype=torch.float32, device=device)\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, ids, mean, std, train=True, crop_min=1600, crop_max=4096, time_masks=(3,5), mask_len=(5,15), noise_std=0.01, seed=42):\n",
        "        self.ids = list(ids)\n",
        "        self.mean = torch.from_numpy(mean).float()\n",
        "        self.std = torch.from_numpy(std).float()\n",
        "        self.train = train\n",
        "        self.crop_min = crop_min\n",
        "        self.crop_max = crop_max\n",
        "        self.tmask_lo, self.tmask_hi = time_masks\n",
        "        self.mlen_lo, self.mlen_hi = mask_len\n",
        "        self.noise_std = noise_std\n",
        "        self.rng = random.Random(seed)\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "    def _rand_crop(self, X, y):\n",
        "        T = X.shape[0]\n",
        "        if not self.train:\n",
        "            return X, y\n",
        "        tgt = self.rng.randint(self.crop_min, self.crop_max)\n",
        "        if T <= tgt:\n",
        "            return X, y\n",
        "        start = self.rng.randint(0, T - tgt)\n",
        "        end = start + tgt\n",
        "        return X[start:end], y[start:end]\n",
        "    def _time_mask(self, X):\n",
        "        if not self.train:\n",
        "            return X\n",
        "        T = X.shape[0]\n",
        "        m = self.rng.randint(self.tmask_lo, self.tmask_hi)\n",
        "        for _ in range(m):\n",
        "            L = self.rng.randint(self.mlen_lo, self.mlen_hi)\n",
        "            if T <= L: continue\n",
        "            s = self.rng.randint(0, T - L)\n",
        "            e = s + L\n",
        "            seg_mean = X[max(0, s-5):min(T, e+5)].mean(axis=0, keepdims=True)\n",
        "            X[s:e] = seg_mean\n",
        "        return X\n",
        "    def __getitem__(self, idx):\n",
        "        sid = int(self.ids[idx])\n",
        "        X = load_feat_full(sid)\n",
        "        y = load_labels(sid)\n",
        "        X, y = self._rand_crop(X, y)\n",
        "        X = (torch.from_numpy(X).float() - self.mean) / (self.std + 1e-6)\n",
        "        if self.train:\n",
        "            if self.noise_std > 0:\n",
        "                X = X + torch.randn_like(X) * self.noise_std\n",
        "            X_np = X.numpy(); X_np = self._time_mask(X_np); X = torch.from_numpy(X_np).float()\n",
        "        y = torch.from_numpy(y).long()\n",
        "        return X, y\n",
        "\n",
        "def collate_pad(batch):\n",
        "    xs, ys = zip(*batch)\n",
        "    T_max = max(x.shape[0] for x in xs)\n",
        "    D = xs[0].shape[1]\n",
        "    xb = torch.zeros((len(xs), T_max, D), dtype=torch.float32)\n",
        "    yb = torch.full((len(xs), T_max), -100, dtype=torch.long)\n",
        "    for i, (x, y) in enumerate(zip(xs, ys)):\n",
        "        T = x.shape[0]\n",
        "        xb[i, :T] = x\n",
        "        yb[i, :T] = y\n",
        "    return xb, yb\n",
        "\n",
        "def cosine_with_warmup(step, total_steps, warmup_steps, base_lr, min_lr):\n",
        "    if step < warmup_steps:\n",
        "        return base_lr * (step / max(1, warmup_steps))\n",
        "    t = (step - warmup_steps) / max(1, (total_steps - warmup_steps))\n",
        "    return min_lr + 0.5 * (base_lr - min_lr) * (1 + math.cos(math.pi * t))\n",
        "\n",
        "# Temporal Consistency (TC) loss per expert recipe\n",
        "def tc_loss_kld_adjacent(logits: torch.Tensor, y: torch.Tensor, k2: bool = True):\n",
        "    # logits: [B,T,C], y: [B,T] with -100 pad\n",
        "    B,T,C = logits.shape\n",
        "    log_probs = F.log_softmax(logits, dim=-1)\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    total = 0.0\n",
        "    denom = 0.0\n",
        "    for k in (1, 2) if k2 else (1,):\n",
        "        y_t   = y[:, k:]\n",
        "        y_tm  = y[:, :-k]\n",
        "        m = (y_t != -100) & (y_tm != -100) & (y_t == y_tm) & (y_t != 0)\n",
        "        if not m.any():\n",
        "            continue\n",
        "        lp = log_probs[:, k:, :]               # teacher at t-1 (or t-2) as stop-grad on probs\n",
        "        p_prev = probs[:, :-k, :].detach()\n",
        "        kl = F.kl_div(lp, p_prev, reduction='none').sum(dim=-1)  # [B,T-k]\n",
        "        # mask and mean\n",
        "        kl = torch.where(m, kl, torch.zeros_like(kl))\n",
        "        total = total + kl.sum() * (1.0 if k==1 else 0.5)\n",
        "        denom = denom + m.sum() * (1.0 if k==1 else 0.5)\n",
        "    if denom == 0:\n",
        "        return logits.new_tensor(0.0)\n",
        "    return total / denom\n",
        "\n",
        "def train_fold_tc(fold_idx, train_ids, val_ids, out_name, ds_seed, epochs=40, batch_size=8, accum_steps=1, base_lr=3e-3, min_lr=3e-5, wd=0.01, label_smooth=0.05, lambda_tc=0.20, tc_warmup_epochs=5, k2=True):\n",
        "    print(f\"=== Train CE+TC fold {fold_idx} ({out_name}) : train_n={len(train_ids)} val_n={len(val_ids)} ===\", flush=True)\n",
        "    # scaler and class weights from train only\n",
        "    mean, std = compute_fold_scaler(train_ids)\n",
        "    class_w = compute_class_weights(train_ids)\n",
        "    D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "    model = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "    # seeds\n",
        "    torch.manual_seed(1337 + ds_seed)\n",
        "    np.random.seed(4242 + ds_seed)\n",
        "    random.seed(9001 + ds_seed)\n",
        "    ema = EMA(model, decay=0.999)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=wd, betas=(0.9, 0.999))\n",
        "    tr_ds = SeqDataset(train_ids, mean, std, train=True, crop_min=1600, crop_max=4096, time_masks=(3,5), mask_len=(5,15), noise_std=0.01, seed=ds_seed)\n",
        "    va_ds = SeqDataset(val_ids, mean, std, train=False, seed=ds_seed+777)\n",
        "    tr_ld = DataLoader(tr_ds, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0, collate_fn=collate_pad, pin_memory=True)\n",
        "    va_ld = DataLoader(va_ds, batch_size=1, shuffle=False, drop_last=False, num_workers=0, collate_fn=collate_pad, pin_memory=True)\n",
        "    steps_per_epoch = max(1, len(tr_ld))\n",
        "    total_steps = steps_per_epoch * epochs\n",
        "    warmup_steps = 5 * steps_per_epoch\n",
        "    ce_crit = nn.CrossEntropyLoss(weight=class_w, label_smoothing=label_smooth, ignore_index=-100)\n",
        "    best_val = float('inf'); patience=6; bad=0\n",
        "    t0=time.time()\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train(); tr_loss=0.0; tr_ce=0.0; tr_tc=0.0; seen=0; t_ep=time.time()\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        # TC lambda schedule: linear warmup over first tc_warmup_epochs\n",
        "        lam_tc = float(lambda_tc * min(1.0, ep / max(1, tc_warmup_epochs)))\n",
        "        for step, (xb, yb) in enumerate(tr_ld):\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            bs, T, D = xb.shape; C = 21\n",
        "            lr = cosine_with_warmup((ep-1)*steps_per_epoch + step, total_steps, warmup_steps, base_lr, min_lr)\n",
        "            for pg in opt.param_groups: pg['lr'] = lr\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                logits = model(xb)  # B,T,C\n",
        "                loss_ce = ce_crit(logits.reshape(-1, C), yb.reshape(-1))\n",
        "                loss_tc = tc_loss_kld_adjacent(logits, yb, k2=k2)\n",
        "                loss = loss_ce + lam_tc * loss_tc\n",
        "            scaler.scale(loss / accum_steps).backward()\n",
        "            if ((step + 1) % accum_steps) == 0:\n",
        "                scaler.unscale_(opt)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                scaler.step(opt)\n",
        "                scaler.update()\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                ema.update(model)\n",
        "            tr_loss += loss.item() * bs; tr_ce += loss_ce.item() * bs; tr_tc += (loss_tc.item() if torch.is_tensor(loss_tc) else float(loss_tc)) * bs; seen += bs\n",
        "            if (step+1) % 50 == 0 or (step+1)==steps_per_epoch:\n",
        "                print(f\"  ep{ep} step {step+1}/{steps_per_epoch} lr={lr:.2e} loss={tr_loss/max(1,seen):.4f} ce={tr_ce/max(1,seen):.4f} tc={tr_tc/max(1,seen):.4f} lam_tc={lam_tc:.3f} elapsed={(time.time()-t_ep):.1f}s\", flush=True)\n",
        "        # validate CE only (selection by CE), with EMA weights\n",
        "        model.eval(); ema.apply_to(model)\n",
        "        val_loss = 0.0; vseen=0\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda'):\n",
        "            for xb, yb in va_ld:\n",
        "                xb = xb.to(device, non_blocking=True)\n",
        "                yb = yb.to(device, non_blocking=True)\n",
        "                bs, T, D = xb.shape; C = 21\n",
        "                logits = model(xb)\n",
        "                loss = ce_crit(logits.reshape(-1, C), yb.reshape(-1))\n",
        "                val_loss += loss.item(); vseen += 1\n",
        "        ema.restore(model)\n",
        "        val_loss = val_loss / max(1, vseen)\n",
        "        print(f\"[Fold {fold_idx} CE+TC] Epoch {ep} train_loss={tr_loss/max(1,seen):.4f} train_ce={tr_ce/max(1,seen):.4f} train_tc={tr_tc/max(1,seen):.4f} val_ce={val_loss:.4f} epoch_time={(time.time()-t_ep):.1f}s total={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "        if val_loss < best_val - 1e-4:\n",
        "            best_val = val_loss; bad = 0\n",
        "            ema.apply_to(model); torch.save(model.state_dict(), out_name); ema.restore(model)\n",
        "            print(f\"  Saved best EMA weights to {out_name}\", flush=True)\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience:\n",
        "                print(f\"  Early stop at epoch {ep}\", flush=True)\n",
        "                break\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "    print(f\"Fold {fold_idx} CE+TC done. Best val CE={best_val:.4f}. Model -> {out_name}\")\n",
        "\n",
        "# Kick off CE+TC training across folds for two seeds (6 models); overwrite existing\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "for f in folds:\n",
        "    fi = int(f['fold'])\n",
        "    for seed_idx, suf in enumerate(['', '_s1']):\n",
        "        outp = Path(f\"model_tc_fold{fi}{suf}.pth\")\n",
        "        if outp.exists():\n",
        "            print(f\"[Overwrite] Removing existing {outp} to retrain CE+TC...\")\n",
        "            try: outp.unlink()\n",
        "            except Exception as e: print(f\"  Warning: could not delete {outp}: {e}\")\n",
        "        ds_seed = (2026 + fi*17 + (seed_idx*101))\n",
        "        train_fold_tc(fi, f['train_ids'], f['val_ids'], out_name=str(outp), ds_seed=ds_seed,\n",
        "                      epochs=40, batch_size=8, accum_steps=1, base_lr=3e-3, min_lr=3e-5, wd=0.01,\n",
        "                      label_smooth=0.05, lambda_tc=0.20, tc_warmup_epochs=5, k2=True)\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "print('All folds CE+TC processed.')\n",
        "\n",
        "# Note: After training, run a new cell to cache OOF for TC models (e.g., *_tc.npy), sweep decoder per expert grid,\n",
        "# and evaluate CE6, TC6, and CE6+TC6 blends by worst-fold then mean. Then build test submission with winning blend."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overwrite] Removing existing model_tc_fold0.pth to retrain CE+TC...\n=== Train CE+TC fold 0 (model_tc_fold0.pth) : train_n=199 val_n=98 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep1 step 24/24 lr=5.75e-04 loss=3.9350 ce=3.9207 tc=0.3569 lam_tc=0.040 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 1 train_loss=3.9350 train_ce=3.9207 train_tc=0.3569 val_ce=5.3257 epoch_time=2.6s total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep2 step 24/24 lr=1.18e-03 loss=2.7930 ce=2.7810 tc=0.1497 lam_tc=0.080 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 2 train_loss=2.7930 train_ce=2.7810 train_tc=0.1497 val_ce=4.9782 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep3 step 24/24 lr=1.78e-03 loss=2.2651 ce=2.2429 tc=0.1858 lam_tc=0.120 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 3 train_loss=2.2651 train_ce=2.2429 train_tc=0.1858 val_ce=4.6737 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep4 step 24/24 lr=2.37e-03 loss=1.9310 ce=1.9038 tc=0.1695 lam_tc=0.160 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 4 train_loss=1.9310 train_ce=1.9038 train_tc=0.1695 val_ce=4.4008 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep5 step 24/24 lr=2.98e-03 loss=1.7373 ce=1.7036 tc=0.1685 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 5 train_loss=1.7373 train_ce=1.7036 train_tc=0.1685 val_ce=4.1559 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep6 step 24/24 lr=2.99e-03 loss=1.5848 ce=1.5518 tc=0.1649 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 6 train_loss=1.5848 train_ce=1.5518 train_tc=0.1649 val_ce=3.9378 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep7 step 24/24 lr=2.98e-03 loss=1.4690 ce=1.4355 tc=0.1676 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 7 train_loss=1.4690 train_ce=1.4355 train_tc=0.1676 val_ce=3.7348 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep8 step 24/24 lr=2.95e-03 loss=1.3563 ce=1.3230 tc=0.1664 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 8 train_loss=1.3563 train_ce=1.3230 train_tc=0.1664 val_ce=3.5482 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep9 step 24/24 lr=2.91e-03 loss=1.2685 ce=1.2361 tc=0.1623 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 9 train_loss=1.2685 train_ce=1.2361 train_tc=0.1623 val_ce=3.3744 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep10 step 24/24 lr=2.86e-03 loss=1.2104 ce=1.1782 tc=0.1613 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 10 train_loss=1.2104 train_ce=1.1782 train_tc=0.1613 val_ce=3.2159 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep11 step 24/24 lr=2.79e-03 loss=1.1379 ce=1.1060 tc=0.1592 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 11 train_loss=1.1379 train_ce=1.1060 train_tc=0.1592 val_ce=3.0619 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep12 step 24/24 lr=2.72e-03 loss=1.0917 ce=1.0604 tc=0.1569 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 12 train_loss=1.0917 train_ce=1.0604 train_tc=0.1569 val_ce=2.9203 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep13 step 24/24 lr=2.64e-03 loss=1.0351 ce=1.0046 tc=0.1524 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 13 train_loss=1.0351 train_ce=1.0046 train_tc=0.1524 val_ce=2.7923 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep14 step 24/24 lr=2.55e-03 loss=1.0103 ce=0.9796 tc=0.1532 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 14 train_loss=1.0103 train_ce=0.9796 train_tc=0.1532 val_ce=2.6708 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep15 step 24/24 lr=2.45e-03 loss=0.9630 ce=0.9329 tc=0.1508 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 15 train_loss=0.9630 train_ce=0.9329 train_tc=0.1508 val_ce=2.5664 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep16 step 24/24 lr=2.34e-03 loss=0.9566 ce=0.9265 tc=0.1504 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 16 train_loss=0.9566 train_ce=0.9265 train_tc=0.1504 val_ce=2.4710 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep17 step 24/24 lr=2.22e-03 loss=0.9205 ce=0.8911 tc=0.1472 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 17 train_loss=0.9205 train_ce=0.8911 train_tc=0.1472 val_ce=2.3796 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep18 step 24/24 lr=2.10e-03 loss=0.8901 ce=0.8607 tc=0.1469 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 18 train_loss=0.8901 train_ce=0.8607 train_tc=0.1469 val_ce=2.3002 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep19 step 24/24 lr=1.98e-03 loss=0.8483 ce=0.8206 tc=0.1385 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 19 train_loss=0.8483 train_ce=0.8206 train_tc=0.1385 val_ce=2.2321 epoch_time=2.7s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep20 step 24/24 lr=1.85e-03 loss=0.8149 ce=0.7873 tc=0.1379 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 20 train_loss=0.8149 train_ce=0.7873 train_tc=0.1379 val_ce=2.1724 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep21 step 24/24 lr=1.72e-03 loss=0.7991 ce=0.7713 tc=0.1389 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 21 train_loss=0.7991 train_ce=0.7713 train_tc=0.1389 val_ce=2.1227 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep22 step 24/24 lr=1.59e-03 loss=0.7909 ce=0.7643 tc=0.1328 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 22 train_loss=0.7909 train_ce=0.7643 train_tc=0.1328 val_ce=2.0823 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep23 step 24/24 lr=1.45e-03 loss=0.7500 ce=0.7240 tc=0.1302 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 23 train_loss=0.7500 train_ce=0.7240 train_tc=0.1302 val_ce=2.0464 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep24 step 24/24 lr=1.32e-03 loss=0.7347 ce=0.7087 tc=0.1296 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 24 train_loss=0.7347 train_ce=0.7087 train_tc=0.1296 val_ce=2.0159 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep25 step 24/24 lr=1.19e-03 loss=0.7090 ce=0.6840 tc=0.1249 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 25 train_loss=0.7090 train_ce=0.6840 train_tc=0.1249 val_ce=1.9906 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep26 step 24/24 lr=1.06e-03 loss=0.6850 ce=0.6600 tc=0.1250 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 26 train_loss=0.6850 train_ce=0.6600 train_tc=0.1250 val_ce=1.9692 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep27 step 24/24 lr=9.36e-04 loss=0.6684 ce=0.6440 tc=0.1221 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 27 train_loss=0.6684 train_ce=0.6440 train_tc=0.1221 val_ce=1.9528 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep28 step 24/24 lr=8.16e-04 loss=0.6517 ce=0.6279 tc=0.1192 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 28 train_loss=0.6517 train_ce=0.6279 train_tc=0.1192 val_ce=1.9378 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep29 step 24/24 lr=7.02e-04 loss=0.6446 ce=0.6213 tc=0.1162 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 29 train_loss=0.6446 train_ce=0.6213 train_tc=0.1162 val_ce=1.9273 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep30 step 24/24 lr=5.93e-04 loss=0.6285 ce=0.6055 tc=0.1148 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 30 train_loss=0.6285 train_ce=0.6055 train_tc=0.1148 val_ce=1.9170 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep31 step 24/24 lr=4.93e-04 loss=0.6169 ce=0.5941 tc=0.1142 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 31 train_loss=0.6169 train_ce=0.5941 train_tc=0.1142 val_ce=1.9077 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep32 step 24/24 lr=4.00e-04 loss=0.6098 ce=0.5873 tc=0.1124 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 32 train_loss=0.6098 train_ce=0.5873 train_tc=0.1124 val_ce=1.9005 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep33 step 24/24 lr=3.17e-04 loss=0.6021 ce=0.5791 tc=0.1151 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 33 train_loss=0.6021 train_ce=0.5791 train_tc=0.1151 val_ce=1.8949 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep34 step 24/24 lr=2.43e-04 loss=0.5989 ce=0.5766 tc=0.1114 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 34 train_loss=0.5989 train_ce=0.5766 train_tc=0.1114 val_ce=1.8906 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep35 step 24/24 lr=1.79e-04 loss=0.5921 ce=0.5696 tc=0.1124 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 35 train_loss=0.5921 train_ce=0.5696 train_tc=0.1124 val_ce=1.8864 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep36 step 24/24 lr=1.27e-04 loss=0.5928 ce=0.5704 tc=0.1120 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 36 train_loss=0.5928 train_ce=0.5704 train_tc=0.1120 val_ce=1.8836 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep37 step 24/24 lr=8.50e-05 loss=0.5753 ce=0.5530 tc=0.1112 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 37 train_loss=0.5753 train_ce=0.5530 train_tc=0.1112 val_ce=1.8805 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep38 step 24/24 lr=5.49e-05 loss=0.5814 ce=0.5592 tc=0.1109 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 38 train_loss=0.5814 train_ce=0.5592 train_tc=0.1109 val_ce=1.8785 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep39 step 24/24 lr=3.65e-05 loss=0.5808 ce=0.5587 tc=0.1107 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 39 train_loss=0.5808 train_ce=0.5587 train_tc=0.1107 val_ce=1.8768 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep40 step 24/24 lr=3.00e-05 loss=0.5837 ce=0.5615 tc=0.1110 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 40 train_loss=0.5837 train_ce=0.5615 train_tc=0.1110 val_ce=1.8752 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 CE+TC done. Best val CE=1.8752. Model -> model_tc_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overwrite] Removing existing model_tc_fold0_s1.pth to retrain CE+TC...\n=== Train CE+TC fold 0 (model_tc_fold0_s1.pth) : train_n=199 val_n=98 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep1 step 24/24 lr=5.75e-04 loss=3.7025 ce=3.6898 tc=0.3187 lam_tc=0.040 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 1 train_loss=3.7025 train_ce=3.6898 train_tc=0.3187 val_ce=4.5695 epoch_time=2.6s total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep2 step 24/24 lr=1.18e-03 loss=2.8007 ce=2.7891 tc=0.1454 lam_tc=0.080 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 2 train_loss=2.8007 train_ce=2.7891 train_tc=0.1454 val_ce=4.3268 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep3 step 24/24 lr=1.78e-03 loss=2.2440 ce=2.2205 tc=0.1964 lam_tc=0.120 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 3 train_loss=2.2440 train_ce=2.2205 train_tc=0.1964 val_ce=4.1102 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep4 step 24/24 lr=2.37e-03 loss=1.9379 ce=1.9092 tc=0.1791 lam_tc=0.160 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 4 train_loss=1.9379 train_ce=1.9092 train_tc=0.1791 val_ce=3.9078 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep5 step 24/24 lr=2.98e-03 loss=1.7458 ce=1.7128 tc=0.1652 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 5 train_loss=1.7458 train_ce=1.7128 train_tc=0.1652 val_ce=3.7177 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep6 step 24/24 lr=2.99e-03 loss=1.5985 ce=1.5659 tc=0.1634 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 6 train_loss=1.5985 train_ce=1.5659 train_tc=0.1634 val_ce=3.5396 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep7 step 24/24 lr=2.98e-03 loss=1.4352 ce=1.4026 tc=0.1630 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 7 train_loss=1.4352 train_ce=1.4026 train_tc=0.1630 val_ce=3.3738 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep8 step 24/24 lr=2.95e-03 loss=1.3400 ce=1.3077 tc=0.1612 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 8 train_loss=1.3400 train_ce=1.3077 train_tc=0.1612 val_ce=3.2169 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep9 step 24/24 lr=2.91e-03 loss=1.2601 ce=1.2278 tc=0.1612 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 9 train_loss=1.2601 train_ce=1.2278 train_tc=0.1612 val_ce=3.0677 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep10 step 24/24 lr=2.86e-03 loss=1.1701 ce=1.1379 tc=0.1610 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 10 train_loss=1.1701 train_ce=1.1379 train_tc=0.1610 val_ce=2.9254 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep11 step 24/24 lr=2.79e-03 loss=1.1371 ce=1.1048 tc=0.1616 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 11 train_loss=1.1371 train_ce=1.1048 train_tc=0.1616 val_ce=2.7857 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep12 step 24/24 lr=2.72e-03 loss=1.0844 ce=1.0527 tc=0.1582 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 12 train_loss=1.0844 train_ce=1.0527 train_tc=0.1582 val_ce=2.6531 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep13 step 24/24 lr=2.64e-03 loss=1.0257 ce=0.9951 tc=0.1531 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 13 train_loss=1.0257 train_ce=0.9951 train_tc=0.1531 val_ce=2.5299 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep14 step 24/24 lr=2.55e-03 loss=0.9756 ce=0.9446 tc=0.1546 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 14 train_loss=0.9756 train_ce=0.9446 train_tc=0.1546 val_ce=2.4171 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep15 step 24/24 lr=2.45e-03 loss=0.9556 ce=0.9256 tc=0.1502 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 15 train_loss=0.9556 train_ce=0.9256 train_tc=0.1502 val_ce=2.3140 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep16 step 24/24 lr=2.34e-03 loss=0.9315 ce=0.9020 tc=0.1477 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 16 train_loss=0.9315 train_ce=0.9020 train_tc=0.1477 val_ce=2.2204 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep17 step 24/24 lr=2.22e-03 loss=0.8971 ce=0.8678 tc=0.1462 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 17 train_loss=0.8971 train_ce=0.8678 train_tc=0.1462 val_ce=2.1414 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep18 step 24/24 lr=2.10e-03 loss=0.8643 ce=0.8353 tc=0.1447 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 18 train_loss=0.8643 train_ce=0.8353 train_tc=0.1447 val_ce=2.0739 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep19 step 24/24 lr=1.98e-03 loss=0.8457 ce=0.8176 tc=0.1404 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 19 train_loss=0.8457 train_ce=0.8176 train_tc=0.1404 val_ce=2.0168 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep20 step 24/24 lr=1.85e-03 loss=0.7980 ce=0.7707 tc=0.1364 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 20 train_loss=0.7980 train_ce=0.7707 train_tc=0.1364 val_ce=1.9679 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep21 step 24/24 lr=1.72e-03 loss=0.7803 ce=0.7530 tc=0.1367 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 21 train_loss=0.7803 train_ce=0.7530 train_tc=0.1367 val_ce=1.9296 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep22 step 24/24 lr=1.59e-03 loss=0.7586 ce=0.7314 tc=0.1358 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 22 train_loss=0.7586 train_ce=0.7314 train_tc=0.1358 val_ce=1.8976 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep23 step 24/24 lr=1.45e-03 loss=0.7495 ce=0.7231 tc=0.1323 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 23 train_loss=0.7495 train_ce=0.7231 train_tc=0.1323 val_ce=1.8722 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep24 step 24/24 lr=1.32e-03 loss=0.7231 ce=0.6972 tc=0.1295 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 24 train_loss=0.7231 train_ce=0.6972 train_tc=0.1295 val_ce=1.8511 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep25 step 24/24 lr=1.19e-03 loss=0.7002 ce=0.6750 tc=0.1262 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 25 train_loss=0.7002 train_ce=0.6750 train_tc=0.1262 val_ce=1.8350 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep26 step 24/24 lr=1.06e-03 loss=0.6851 ce=0.6595 tc=0.1280 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 26 train_loss=0.6851 train_ce=0.6595 train_tc=0.1280 val_ce=1.8219 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep27 step 24/24 lr=9.36e-04 loss=0.6663 ce=0.6412 tc=0.1253 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 27 train_loss=0.6663 train_ce=0.6412 train_tc=0.1253 val_ce=1.8119 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep28 step 24/24 lr=8.16e-04 loss=0.6518 ce=0.6275 tc=0.1216 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 28 train_loss=0.6518 train_ce=0.6275 train_tc=0.1216 val_ce=1.8036 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep29 step 24/24 lr=7.02e-04 loss=0.6272 ce=0.6034 tc=0.1188 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 29 train_loss=0.6272 train_ce=0.6034 train_tc=0.1188 val_ce=1.7981 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep30 step 24/24 lr=5.93e-04 loss=0.6205 ce=0.5972 tc=0.1163 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 30 train_loss=0.6205 train_ce=0.5972 train_tc=0.1163 val_ce=1.7931 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep31 step 24/24 lr=4.93e-04 loss=0.6090 ce=0.5861 tc=0.1143 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 31 train_loss=0.6090 train_ce=0.5861 train_tc=0.1143 val_ce=1.7908 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep32 step 24/24 lr=4.00e-04 loss=0.6026 ce=0.5800 tc=0.1131 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 32 train_loss=0.6026 train_ce=0.5800 train_tc=0.1131 val_ce=1.7885 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep33 step 24/24 lr=3.17e-04 loss=0.5972 ce=0.5747 tc=0.1129 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 33 train_loss=0.5972 train_ce=0.5747 train_tc=0.1129 val_ce=1.7877 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep34 step 24/24 lr=2.43e-04 loss=0.5903 ce=0.5676 tc=0.1132 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 34 train_loss=0.5903 train_ce=0.5676 train_tc=0.1132 val_ce=1.7872 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep35 step 24/24 lr=1.79e-04 loss=0.5861 ce=0.5639 tc=0.1110 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 35 train_loss=0.5861 train_ce=0.5639 train_tc=0.1110 val_ce=1.7879 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep36 step 24/24 lr=1.27e-04 loss=0.5849 ce=0.5625 tc=0.1124 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 36 train_loss=0.5849 train_ce=0.5625 train_tc=0.1124 val_ce=1.7888 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep37 step 24/24 lr=8.50e-05 loss=0.5834 ce=0.5610 tc=0.1119 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 37 train_loss=0.5834 train_ce=0.5610 train_tc=0.1119 val_ce=1.7900 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep38 step 24/24 lr=5.49e-05 loss=0.5797 ce=0.5575 tc=0.1112 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 38 train_loss=0.5797 train_ce=0.5575 train_tc=0.1112 val_ce=1.7915 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep39 step 24/24 lr=3.65e-05 loss=0.5774 ce=0.5552 tc=0.1107 lam_tc=0.200 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 39 train_loss=0.5774 train_ce=0.5552 train_tc=0.1107 val_ce=1.7931 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep40 step 24/24 lr=3.00e-05 loss=0.5786 ce=0.5565 tc=0.1106 lam_tc=0.200 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 0 CE+TC] Epoch 40 train_loss=0.5786 train_ce=0.5565 train_tc=0.1106 val_ce=1.7949 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Early stop at epoch 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 CE+TC done. Best val CE=1.7872. Model -> model_tc_fold0_s1.pth\n[Overwrite] Removing existing model_tc_fold1.pth to retrain CE+TC...\n=== Train CE+TC fold 1 (model_tc_fold1.pth) : train_n=198 val_n=99 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep1 step 24/24 lr=5.75e-04 loss=3.5919 ce=3.5765 tc=0.3857 lam_tc=0.040 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 1 train_loss=3.5919 train_ce=3.5765 train_tc=0.3857 val_ce=4.1792 epoch_time=2.7s total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep2 step 24/24 lr=1.18e-03 loss=2.7753 ce=2.7640 tc=0.1407 lam_tc=0.080 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 2 train_loss=2.7753 train_ce=2.7640 train_tc=0.1407 val_ce=4.0270 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep3 step 24/24 lr=1.78e-03 loss=2.2952 ce=2.2729 tc=0.1860 lam_tc=0.120 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 3 train_loss=2.2952 train_ce=2.2729 train_tc=0.1860 val_ce=3.8824 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep4 step 24/24 lr=2.37e-03 loss=1.9529 ce=1.9270 tc=0.1618 lam_tc=0.160 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 4 train_loss=1.9529 train_ce=1.9270 train_tc=0.1618 val_ce=3.7427 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep5 step 24/24 lr=2.98e-03 loss=1.7241 ce=1.6908 tc=0.1664 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 5 train_loss=1.7241 train_ce=1.6908 train_tc=0.1664 val_ce=3.6085 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep6 step 24/24 lr=2.99e-03 loss=1.6000 ce=1.5691 tc=0.1546 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 6 train_loss=1.6000 train_ce=1.5691 train_tc=0.1546 val_ce=3.4716 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep7 step 24/24 lr=2.98e-03 loss=1.4187 ce=1.3877 tc=0.1550 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 7 train_loss=1.4187 train_ce=1.3877 train_tc=0.1550 val_ce=3.3391 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep8 step 24/24 lr=2.95e-03 loss=1.3717 ce=1.3402 tc=0.1574 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 8 train_loss=1.3717 train_ce=1.3402 train_tc=0.1574 val_ce=3.2108 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep9 step 24/24 lr=2.91e-03 loss=1.2399 ce=1.2091 tc=0.1539 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 9 train_loss=1.2399 train_ce=1.2091 train_tc=0.1539 val_ce=3.0847 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep10 step 24/24 lr=2.86e-03 loss=1.1589 ce=1.1281 tc=0.1539 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 10 train_loss=1.1589 train_ce=1.1281 train_tc=0.1539 val_ce=2.9672 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep11 step 24/24 lr=2.79e-03 loss=1.1200 ce=1.0897 tc=0.1517 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 11 train_loss=1.1200 train_ce=1.0897 train_tc=0.1517 val_ce=2.8537 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep12 step 24/24 lr=2.72e-03 loss=1.0875 ce=1.0558 tc=0.1582 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 12 train_loss=1.0875 train_ce=1.0558 train_tc=0.1582 val_ce=2.7424 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep13 step 24/24 lr=2.64e-03 loss=1.0249 ce=0.9948 tc=0.1506 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 13 train_loss=1.0249 train_ce=0.9948 train_tc=0.1506 val_ce=2.6326 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep14 step 24/24 lr=2.55e-03 loss=1.0262 ce=0.9965 tc=0.1483 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 14 train_loss=1.0262 train_ce=0.9965 train_tc=0.1483 val_ce=2.5269 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep15 step 24/24 lr=2.45e-03 loss=0.9462 ce=0.9167 tc=0.1477 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 15 train_loss=0.9462 train_ce=0.9167 train_tc=0.1477 val_ce=2.4259 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep16 step 24/24 lr=2.34e-03 loss=0.9184 ce=0.8886 tc=0.1492 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 16 train_loss=0.9184 train_ce=0.8886 train_tc=0.1492 val_ce=2.3313 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep17 step 24/24 lr=2.22e-03 loss=0.8926 ce=0.8631 tc=0.1471 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 17 train_loss=0.8926 train_ce=0.8631 train_tc=0.1471 val_ce=2.2442 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep18 step 24/24 lr=2.10e-03 loss=0.8593 ce=0.8310 tc=0.1414 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 18 train_loss=0.8593 train_ce=0.8310 train_tc=0.1414 val_ce=2.1644 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep19 step 24/24 lr=1.98e-03 loss=0.8175 ce=0.7892 tc=0.1416 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 19 train_loss=0.8175 train_ce=0.7892 train_tc=0.1416 val_ce=2.0957 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep20 step 24/24 lr=1.85e-03 loss=0.7829 ce=0.7554 tc=0.1375 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 20 train_loss=0.7829 train_ce=0.7554 train_tc=0.1375 val_ce=2.0328 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep21 step 24/24 lr=1.72e-03 loss=0.7671 ce=0.7398 tc=0.1366 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 21 train_loss=0.7671 train_ce=0.7398 train_tc=0.1366 val_ce=1.9737 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep22 step 24/24 lr=1.59e-03 loss=0.7578 ce=0.7311 tc=0.1337 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 22 train_loss=0.7578 train_ce=0.7311 train_tc=0.1337 val_ce=1.9254 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep23 step 24/24 lr=1.45e-03 loss=0.7246 ce=0.6986 tc=0.1298 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 23 train_loss=0.7246 train_ce=0.6986 train_tc=0.1298 val_ce=1.8839 epoch_time=2.7s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep24 step 24/24 lr=1.32e-03 loss=0.7037 ce=0.6783 tc=0.1271 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 24 train_loss=0.7037 train_ce=0.6783 train_tc=0.1271 val_ce=1.8473 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep25 step 24/24 lr=1.19e-03 loss=0.6860 ce=0.6605 tc=0.1277 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 25 train_loss=0.6860 train_ce=0.6605 train_tc=0.1277 val_ce=1.8161 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep26 step 24/24 lr=1.06e-03 loss=0.6691 ce=0.6448 tc=0.1216 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 26 train_loss=0.6691 train_ce=0.6448 train_tc=0.1216 val_ce=1.7888 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep27 step 24/24 lr=9.36e-04 loss=0.6447 ce=0.6205 tc=0.1211 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 27 train_loss=0.6447 train_ce=0.6205 train_tc=0.1211 val_ce=1.7651 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep28 step 24/24 lr=8.16e-04 loss=0.6321 ce=0.6086 tc=0.1176 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 28 train_loss=0.6321 train_ce=0.6086 train_tc=0.1176 val_ce=1.7447 epoch_time=2.7s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep29 step 24/24 lr=7.02e-04 loss=0.6231 ce=0.5998 tc=0.1168 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 29 train_loss=0.6231 train_ce=0.5998 train_tc=0.1168 val_ce=1.7278 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep30 step 24/24 lr=5.93e-04 loss=0.6099 ce=0.5873 tc=0.1133 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 30 train_loss=0.6099 train_ce=0.5873 train_tc=0.1133 val_ce=1.7127 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep31 step 24/24 lr=4.93e-04 loss=0.6016 ce=0.5792 tc=0.1117 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 31 train_loss=0.6016 train_ce=0.5792 train_tc=0.1117 val_ce=1.7007 epoch_time=2.7s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep32 step 24/24 lr=4.00e-04 loss=0.5928 ce=0.5709 tc=0.1097 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 32 train_loss=0.5928 train_ce=0.5709 train_tc=0.1097 val_ce=1.6899 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep33 step 24/24 lr=3.17e-04 loss=0.5878 ce=0.5656 tc=0.1110 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 33 train_loss=0.5878 train_ce=0.5656 train_tc=0.1110 val_ce=1.6806 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep34 step 24/24 lr=2.43e-04 loss=0.5801 ce=0.5586 tc=0.1076 lam_tc=0.200 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 34 train_loss=0.5801 train_ce=0.5586 train_tc=0.1076 val_ce=1.6719 epoch_time=2.8s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep35 step 24/24 lr=1.79e-04 loss=0.5785 ce=0.5568 tc=0.1086 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 35 train_loss=0.5785 train_ce=0.5568 train_tc=0.1086 val_ce=1.6655 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep36 step 24/24 lr=1.27e-04 loss=0.5743 ce=0.5529 tc=0.1066 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 36 train_loss=0.5743 train_ce=0.5529 train_tc=0.1066 val_ce=1.6592 epoch_time=2.7s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep37 step 24/24 lr=8.50e-05 loss=0.5697 ce=0.5481 tc=0.1080 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 37 train_loss=0.5697 train_ce=0.5481 train_tc=0.1080 val_ce=1.6539 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep38 step 24/24 lr=5.49e-05 loss=0.5688 ce=0.5473 tc=0.1078 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 38 train_loss=0.5688 train_ce=0.5473 train_tc=0.1078 val_ce=1.6496 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep39 step 24/24 lr=3.65e-05 loss=0.5634 ce=0.5420 tc=0.1066 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 39 train_loss=0.5634 train_ce=0.5420 train_tc=0.1066 val_ce=1.6458 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep40 step 24/24 lr=3.00e-05 loss=0.5694 ce=0.5478 tc=0.1078 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 40 train_loss=0.5694 train_ce=0.5478 train_tc=0.1078 val_ce=1.6429 epoch_time=2.7s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 CE+TC done. Best val CE=1.6429. Model -> model_tc_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overwrite] Removing existing model_tc_fold1_s1.pth to retrain CE+TC...\n=== Train CE+TC fold 1 (model_tc_fold1_s1.pth) : train_n=198 val_n=99 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep1 step 24/24 lr=5.75e-04 loss=3.8114 ce=3.7953 tc=0.4031 lam_tc=0.040 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 1 train_loss=3.8114 train_ce=3.7953 train_tc=0.4031 val_ce=4.9977 epoch_time=2.8s total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep2 step 24/24 lr=1.18e-03 loss=2.7553 ce=2.7420 tc=0.1670 lam_tc=0.080 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 2 train_loss=2.7553 train_ce=2.7420 train_tc=0.1670 val_ce=4.7065 epoch_time=2.7s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep3 step 24/24 lr=1.78e-03 loss=2.2091 ce=2.1853 tc=0.1977 lam_tc=0.120 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 3 train_loss=2.2091 train_ce=2.1853 train_tc=0.1977 val_ce=4.4427 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep4 step 24/24 lr=2.37e-03 loss=1.8804 ce=1.8527 tc=0.1729 lam_tc=0.160 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 4 train_loss=1.8804 train_ce=1.8527 train_tc=0.1729 val_ce=4.2070 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep5 step 24/24 lr=2.98e-03 loss=1.6864 ce=1.6538 tc=0.1626 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 5 train_loss=1.6864 train_ce=1.6538 train_tc=0.1626 val_ce=3.9838 epoch_time=2.7s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep6 step 24/24 lr=2.99e-03 loss=1.5026 ce=1.4698 tc=0.1641 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 6 train_loss=1.5026 train_ce=1.4698 train_tc=0.1641 val_ce=3.7846 epoch_time=2.7s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep7 step 24/24 lr=2.98e-03 loss=1.4211 ce=1.3889 tc=0.1610 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 7 train_loss=1.4211 train_ce=1.3889 train_tc=0.1610 val_ce=3.5973 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep8 step 24/24 lr=2.95e-03 loss=1.3094 ce=1.2776 tc=0.1590 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 8 train_loss=1.3094 train_ce=1.2776 train_tc=0.1590 val_ce=3.4217 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep9 step 24/24 lr=2.91e-03 loss=1.1847 ce=1.1529 tc=0.1592 lam_tc=0.200 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 9 train_loss=1.1847 train_ce=1.1529 train_tc=0.1592 val_ce=3.2517 epoch_time=2.8s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep10 step 24/24 lr=2.86e-03 loss=1.1721 ce=1.1405 tc=0.1585 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 10 train_loss=1.1721 train_ce=1.1405 train_tc=0.1585 val_ce=3.0890 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep11 step 24/24 lr=2.79e-03 loss=1.1005 ce=1.0697 tc=0.1540 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 11 train_loss=1.1005 train_ce=1.0697 train_tc=0.1540 val_ce=2.9297 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep12 step 24/24 lr=2.72e-03 loss=1.0367 ce=1.0057 tc=0.1553 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 12 train_loss=1.0367 train_ce=1.0057 train_tc=0.1553 val_ce=2.7795 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep13 step 24/24 lr=2.64e-03 loss=1.0210 ce=0.9899 tc=0.1555 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 13 train_loss=1.0210 train_ce=0.9899 train_tc=0.1555 val_ce=2.6370 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep14 step 24/24 lr=2.55e-03 loss=0.9800 ce=0.9494 tc=0.1534 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 14 train_loss=0.9800 train_ce=0.9494 train_tc=0.1534 val_ce=2.5012 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep15 step 24/24 lr=2.45e-03 loss=0.9419 ce=0.9121 tc=0.1490 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 15 train_loss=0.9419 train_ce=0.9121 train_tc=0.1490 val_ce=2.3811 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep16 step 24/24 lr=2.34e-03 loss=0.8777 ce=0.8490 tc=0.1434 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 16 train_loss=0.8777 train_ce=0.8490 train_tc=0.1434 val_ce=2.2748 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep17 step 24/24 lr=2.22e-03 loss=0.8549 ce=0.8255 tc=0.1472 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 17 train_loss=0.8549 train_ce=0.8255 train_tc=0.1472 val_ce=2.1836 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep18 step 24/24 lr=2.10e-03 loss=0.8460 ce=0.8174 tc=0.1428 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 18 train_loss=0.8460 train_ce=0.8174 train_tc=0.1428 val_ce=2.1052 epoch_time=2.7s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep19 step 24/24 lr=1.98e-03 loss=0.8057 ce=0.7774 tc=0.1417 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 19 train_loss=0.8057 train_ce=0.7774 train_tc=0.1417 val_ce=2.0359 epoch_time=2.7s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep20 step 24/24 lr=1.85e-03 loss=0.7885 ce=0.7603 tc=0.1412 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 20 train_loss=0.7885 train_ce=0.7603 train_tc=0.1412 val_ce=1.9767 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep21 step 24/24 lr=1.72e-03 loss=0.7531 ce=0.7249 tc=0.1409 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 21 train_loss=0.7531 train_ce=0.7249 train_tc=0.1409 val_ce=1.9265 epoch_time=2.7s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep22 step 24/24 lr=1.59e-03 loss=0.7395 ce=0.7127 tc=0.1338 lam_tc=0.200 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 22 train_loss=0.7395 train_ce=0.7127 train_tc=0.1338 val_ce=1.8865 epoch_time=2.7s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep23 step 24/24 lr=1.45e-03 loss=0.7183 ce=0.6923 tc=0.1299 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 23 train_loss=0.7183 train_ce=0.6923 train_tc=0.1299 val_ce=1.8506 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep24 step 24/24 lr=1.32e-03 loss=0.6901 ce=0.6647 tc=0.1274 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 24 train_loss=0.6901 train_ce=0.6647 train_tc=0.1274 val_ce=1.8205 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep25 step 24/24 lr=1.19e-03 loss=0.6714 ce=0.6461 tc=0.1262 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 25 train_loss=0.6714 train_ce=0.6461 train_tc=0.1262 val_ce=1.7941 epoch_time=2.7s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep26 step 24/24 lr=1.06e-03 loss=0.6590 ce=0.6344 tc=0.1227 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 26 train_loss=0.6590 train_ce=0.6344 train_tc=0.1227 val_ce=1.7718 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep27 step 24/24 lr=9.36e-04 loss=0.6372 ce=0.6136 tc=0.1178 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 27 train_loss=0.6372 train_ce=0.6136 train_tc=0.1178 val_ce=1.7532 epoch_time=2.7s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep28 step 24/24 lr=8.16e-04 loss=0.6238 ce=0.6004 tc=0.1169 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 28 train_loss=0.6238 train_ce=0.6004 train_tc=0.1169 val_ce=1.7382 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep29 step 24/24 lr=7.02e-04 loss=0.6125 ce=0.5899 tc=0.1128 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 29 train_loss=0.6125 train_ce=0.5899 train_tc=0.1128 val_ce=1.7255 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep30 step 24/24 lr=5.93e-04 loss=0.6031 ce=0.5803 tc=0.1141 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 30 train_loss=0.6031 train_ce=0.5803 train_tc=0.1141 val_ce=1.7143 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep31 step 24/24 lr=4.93e-04 loss=0.5919 ce=0.5696 tc=0.1120 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 31 train_loss=0.5919 train_ce=0.5696 train_tc=0.1120 val_ce=1.7044 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep32 step 24/24 lr=4.00e-04 loss=0.5872 ce=0.5649 tc=0.1111 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 32 train_loss=0.5872 train_ce=0.5649 train_tc=0.1111 val_ce=1.6958 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep33 step 24/24 lr=3.17e-04 loss=0.5822 ce=0.5600 tc=0.1108 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 33 train_loss=0.5822 train_ce=0.5600 train_tc=0.1108 val_ce=1.6887 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep34 step 24/24 lr=2.43e-04 loss=0.5771 ce=0.5554 tc=0.1082 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 34 train_loss=0.5771 train_ce=0.5554 train_tc=0.1082 val_ce=1.6831 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep35 step 24/24 lr=1.79e-04 loss=0.5746 ce=0.5529 tc=0.1083 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 35 train_loss=0.5746 train_ce=0.5529 train_tc=0.1083 val_ce=1.6774 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep36 step 24/24 lr=1.27e-04 loss=0.5679 ce=0.5462 tc=0.1083 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 36 train_loss=0.5679 train_ce=0.5462 train_tc=0.1083 val_ce=1.6734 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep37 step 24/24 lr=8.50e-05 loss=0.5673 ce=0.5460 tc=0.1066 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 37 train_loss=0.5673 train_ce=0.5460 train_tc=0.1066 val_ce=1.6699 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep38 step 24/24 lr=5.49e-05 loss=0.5657 ce=0.5443 tc=0.1071 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 38 train_loss=0.5657 train_ce=0.5443 train_tc=0.1071 val_ce=1.6668 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep39 step 24/24 lr=3.65e-05 loss=0.5648 ce=0.5434 tc=0.1069 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 39 train_loss=0.5648 train_ce=0.5434 train_tc=0.1069 val_ce=1.6641 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep40 step 24/24 lr=3.00e-05 loss=0.5640 ce=0.5426 tc=0.1069 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1 CE+TC] Epoch 40 train_loss=0.5640 train_ce=0.5426 train_tc=0.1069 val_ce=1.6620 epoch_time=2.7s total=1.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 CE+TC done. Best val CE=1.6620. Model -> model_tc_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overwrite] Removing existing model_tc_fold2.pth to retrain CE+TC...\n=== Train CE+TC fold 2 (model_tc_fold2.pth) : train_n=197 val_n=100 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep1 step 24/24 lr=5.75e-04 loss=4.0675 ce=4.0550 tc=0.3125 lam_tc=0.040 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 1 train_loss=4.0675 train_ce=4.0550 train_tc=0.3125 val_ce=5.8243 epoch_time=2.6s total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep2 step 24/24 lr=1.18e-03 loss=2.5841 ce=2.5703 tc=0.1729 lam_tc=0.080 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 2 train_loss=2.5841 train_ce=2.5703 train_tc=0.1729 val_ce=5.4341 epoch_time=2.7s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep3 step 24/24 lr=1.78e-03 loss=1.9524 ce=1.9289 tc=0.1962 lam_tc=0.120 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 3 train_loss=1.9524 train_ce=1.9289 train_tc=0.1962 val_ce=5.0584 epoch_time=2.7s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep4 step 24/24 lr=2.37e-03 loss=1.6531 ce=1.6272 tc=0.1621 lam_tc=0.160 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 4 train_loss=1.6531 train_ce=1.6272 train_tc=0.1621 val_ce=4.7337 epoch_time=2.7s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep5 step 24/24 lr=2.98e-03 loss=1.4799 ce=1.4499 tc=0.1501 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 5 train_loss=1.4799 train_ce=1.4499 train_tc=0.1501 val_ce=4.4515 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep6 step 24/24 lr=2.99e-03 loss=1.4004 ce=1.3724 tc=0.1402 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 6 train_loss=1.4004 train_ce=1.3724 train_tc=0.1402 val_ce=4.2113 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep7 step 24/24 lr=2.98e-03 loss=1.2729 ce=1.2456 tc=0.1362 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 7 train_loss=1.2729 train_ce=1.2456 train_tc=0.1362 val_ce=3.9995 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep8 step 24/24 lr=2.95e-03 loss=1.1903 ce=1.1633 tc=0.1346 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 8 train_loss=1.1903 train_ce=1.1633 train_tc=0.1346 val_ce=3.8108 epoch_time=2.7s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep9 step 24/24 lr=2.91e-03 loss=1.1078 ce=1.0819 tc=0.1299 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 9 train_loss=1.1078 train_ce=1.0819 train_tc=0.1299 val_ce=3.6409 epoch_time=2.6s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep10 step 24/24 lr=2.86e-03 loss=1.0870 ce=1.0605 tc=0.1323 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 10 train_loss=1.0870 train_ce=1.0605 train_tc=0.1323 val_ce=3.4872 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep11 step 24/24 lr=2.79e-03 loss=1.0115 ce=0.9867 tc=0.1240 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 11 train_loss=1.0115 train_ce=0.9867 train_tc=0.1240 val_ce=3.3463 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep12 step 24/24 lr=2.72e-03 loss=0.9753 ce=0.9500 tc=0.1263 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 12 train_loss=0.9753 train_ce=0.9500 train_tc=0.1263 val_ce=3.2150 epoch_time=2.7s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep13 step 24/24 lr=2.64e-03 loss=0.9226 ce=0.8982 tc=0.1218 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 13 train_loss=0.9226 train_ce=0.8982 train_tc=0.1218 val_ce=3.0910 epoch_time=2.7s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep14 step 24/24 lr=2.55e-03 loss=0.9064 ce=0.8825 tc=0.1196 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 14 train_loss=0.9064 train_ce=0.8825 train_tc=0.1196 val_ce=2.9718 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep15 step 24/24 lr=2.45e-03 loss=0.8839 ce=0.8607 tc=0.1162 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 15 train_loss=0.8839 train_ce=0.8607 train_tc=0.1162 val_ce=2.8623 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep16 step 24/24 lr=2.34e-03 loss=0.8551 ce=0.8329 tc=0.1108 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 16 train_loss=0.8551 train_ce=0.8329 train_tc=0.1108 val_ce=2.7611 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep17 step 24/24 lr=2.22e-03 loss=0.8550 ce=0.8332 tc=0.1090 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 17 train_loss=0.8550 train_ce=0.8332 train_tc=0.1090 val_ce=2.6680 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep18 step 24/24 lr=2.10e-03 loss=0.8056 ce=0.7846 tc=0.1051 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 18 train_loss=0.8056 train_ce=0.7846 train_tc=0.1051 val_ce=2.5876 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep19 step 24/24 lr=1.98e-03 loss=0.7853 ce=0.7647 tc=0.1032 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 19 train_loss=0.7853 train_ce=0.7647 train_tc=0.1032 val_ce=2.5160 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep20 step 24/24 lr=1.85e-03 loss=0.7638 ce=0.7432 tc=0.1034 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 20 train_loss=0.7638 train_ce=0.7432 train_tc=0.1034 val_ce=2.4513 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep21 step 24/24 lr=1.72e-03 loss=0.7360 ce=0.7164 tc=0.0983 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 21 train_loss=0.7360 train_ce=0.7164 train_tc=0.0983 val_ce=2.3960 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep22 step 24/24 lr=1.59e-03 loss=0.7179 ce=0.6988 tc=0.0956 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 22 train_loss=0.7179 train_ce=0.6988 train_tc=0.0956 val_ce=2.3508 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep23 step 24/24 lr=1.45e-03 loss=0.7122 ce=0.6936 tc=0.0930 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 23 train_loss=0.7122 train_ce=0.6936 train_tc=0.0930 val_ce=2.3139 epoch_time=2.7s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep24 step 24/24 lr=1.32e-03 loss=0.6764 ce=0.6587 tc=0.0885 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 24 train_loss=0.6764 train_ce=0.6587 train_tc=0.0885 val_ce=2.2810 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep25 step 24/24 lr=1.19e-03 loss=0.6758 ce=0.6578 tc=0.0901 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 25 train_loss=0.6758 train_ce=0.6578 train_tc=0.0901 val_ce=2.2533 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep26 step 24/24 lr=1.06e-03 loss=0.6653 ce=0.6479 tc=0.0868 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 26 train_loss=0.6653 train_ce=0.6479 train_tc=0.0868 val_ce=2.2303 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep27 step 24/24 lr=9.36e-04 loss=0.6475 ce=0.6304 tc=0.0856 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 27 train_loss=0.6475 train_ce=0.6304 train_tc=0.0856 val_ce=2.2136 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep28 step 24/24 lr=8.16e-04 loss=0.6347 ce=0.6179 tc=0.0839 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 28 train_loss=0.6347 train_ce=0.6179 train_tc=0.0839 val_ce=2.1993 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep29 step 24/24 lr=7.02e-04 loss=0.6257 ce=0.6091 tc=0.0831 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 29 train_loss=0.6257 train_ce=0.6091 train_tc=0.0831 val_ce=2.1884 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep30 step 24/24 lr=5.93e-04 loss=0.6210 ce=0.6046 tc=0.0819 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 30 train_loss=0.6210 train_ce=0.6046 train_tc=0.0819 val_ce=2.1795 epoch_time=2.7s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep31 step 24/24 lr=4.93e-04 loss=0.6104 ce=0.5943 tc=0.0806 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 31 train_loss=0.6104 train_ce=0.5943 train_tc=0.0806 val_ce=2.1708 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep32 step 24/24 lr=4.00e-04 loss=0.6076 ce=0.5913 tc=0.0814 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 32 train_loss=0.6076 train_ce=0.5913 train_tc=0.0814 val_ce=2.1650 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep33 step 24/24 lr=3.17e-04 loss=0.6059 ce=0.5896 tc=0.0811 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 33 train_loss=0.6059 train_ce=0.5896 train_tc=0.0811 val_ce=2.1609 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep34 step 24/24 lr=2.43e-04 loss=0.5982 ce=0.5823 tc=0.0795 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 34 train_loss=0.5982 train_ce=0.5823 train_tc=0.0795 val_ce=2.1567 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep35 step 24/24 lr=1.79e-04 loss=0.5973 ce=0.5813 tc=0.0805 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 35 train_loss=0.5973 train_ce=0.5813 train_tc=0.0805 val_ce=2.1535 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep36 step 24/24 lr=1.27e-04 loss=0.5946 ce=0.5788 tc=0.0791 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 36 train_loss=0.5946 train_ce=0.5788 train_tc=0.0791 val_ce=2.1504 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep37 step 24/24 lr=8.50e-05 loss=0.5897 ce=0.5740 tc=0.0786 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 37 train_loss=0.5897 train_ce=0.5740 train_tc=0.0786 val_ce=2.1485 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep38 step 24/24 lr=5.49e-05 loss=0.5904 ce=0.5748 tc=0.0781 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 38 train_loss=0.5904 train_ce=0.5748 train_tc=0.0781 val_ce=2.1471 epoch_time=2.7s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep39 step 24/24 lr=3.65e-05 loss=0.5902 ce=0.5745 tc=0.0784 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 39 train_loss=0.5902 train_ce=0.5745 train_tc=0.0784 val_ce=2.1451 epoch_time=2.7s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep40 step 24/24 lr=3.00e-05 loss=0.5914 ce=0.5757 tc=0.0789 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 40 train_loss=0.5914 train_ce=0.5757 train_tc=0.0789 val_ce=2.1440 epoch_time=2.7s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 CE+TC done. Best val CE=2.1440. Model -> model_tc_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overwrite] Removing existing model_tc_fold2_s1.pth to retrain CE+TC...\n=== Train CE+TC fold 2 (model_tc_fold2_s1.pth) : train_n=197 val_n=100 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep1 step 24/24 lr=5.75e-04 loss=3.8922 ce=3.8774 tc=0.3689 lam_tc=0.040 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 1 train_loss=3.8922 train_ce=3.8774 train_tc=0.3689 val_ce=5.1073 epoch_time=2.7s total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep2 step 24/24 lr=1.18e-03 loss=2.5656 ce=2.5520 tc=0.1695 lam_tc=0.080 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 2 train_loss=2.5656 train_ce=2.5520 train_tc=0.1695 val_ce=4.8708 epoch_time=2.7s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep3 step 24/24 lr=1.78e-03 loss=1.9598 ce=1.9348 tc=0.2081 lam_tc=0.120 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 3 train_loss=1.9598 train_ce=1.9348 train_tc=0.2081 val_ce=4.6621 epoch_time=2.6s total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep4 step 24/24 lr=2.37e-03 loss=1.6334 ce=1.6080 tc=0.1588 lam_tc=0.160 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 4 train_loss=1.6334 train_ce=1.6080 train_tc=0.1588 val_ce=4.4672 epoch_time=2.6s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep5 step 24/24 lr=2.98e-03 loss=1.5173 ce=1.4876 tc=0.1485 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 5 train_loss=1.5173 train_ce=1.4876 train_tc=0.1485 val_ce=4.2858 epoch_time=2.7s total=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep6 step 24/24 lr=2.99e-03 loss=1.3984 ce=1.3709 tc=0.1376 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 6 train_loss=1.3984 train_ce=1.3709 train_tc=0.1376 val_ce=4.1042 epoch_time=2.6s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep7 step 24/24 lr=2.98e-03 loss=1.3002 ce=1.2737 tc=0.1323 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 7 train_loss=1.3002 train_ce=1.2737 train_tc=0.1323 val_ce=3.9278 epoch_time=2.7s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep8 step 24/24 lr=2.95e-03 loss=1.1770 ce=1.1508 tc=0.1311 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 8 train_loss=1.1770 train_ce=1.1508 train_tc=0.1311 val_ce=3.7659 epoch_time=2.7s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep9 step 24/24 lr=2.91e-03 loss=1.1144 ce=1.0878 tc=0.1332 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 9 train_loss=1.1144 train_ce=1.0878 train_tc=0.1332 val_ce=3.6112 epoch_time=2.7s total=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep10 step 24/24 lr=2.86e-03 loss=1.0503 ce=1.0249 tc=0.1267 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 10 train_loss=1.0503 train_ce=1.0249 train_tc=0.1267 val_ce=3.4652 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep11 step 24/24 lr=2.79e-03 loss=1.0053 ce=0.9806 tc=0.1237 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 11 train_loss=1.0053 train_ce=0.9806 train_tc=0.1237 val_ce=3.3314 epoch_time=2.6s total=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep12 step 24/24 lr=2.72e-03 loss=0.9753 ce=0.9505 tc=0.1239 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 12 train_loss=0.9753 train_ce=0.9505 train_tc=0.1239 val_ce=3.2017 epoch_time=2.7s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep13 step 24/24 lr=2.64e-03 loss=0.9476 ce=0.9236 tc=0.1203 lam_tc=0.200 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 13 train_loss=0.9476 train_ce=0.9236 train_tc=0.1203 val_ce=3.0752 epoch_time=2.7s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep14 step 24/24 lr=2.55e-03 loss=0.9213 ce=0.8969 tc=0.1219 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 14 train_loss=0.9213 train_ce=0.8969 train_tc=0.1219 val_ce=2.9584 epoch_time=2.6s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep15 step 24/24 lr=2.45e-03 loss=0.8674 ce=0.8445 tc=0.1146 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 15 train_loss=0.8674 train_ce=0.8445 train_tc=0.1146 val_ce=2.8497 epoch_time=2.7s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep16 step 24/24 lr=2.34e-03 loss=0.8572 ce=0.8351 tc=0.1105 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 16 train_loss=0.8572 train_ce=0.8351 train_tc=0.1105 val_ce=2.7498 epoch_time=2.6s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep17 step 24/24 lr=2.22e-03 loss=0.8110 ce=0.7892 tc=0.1089 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 17 train_loss=0.8110 train_ce=0.7892 train_tc=0.1089 val_ce=2.6620 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep18 step 24/24 lr=2.10e-03 loss=0.7908 ce=0.7699 tc=0.1043 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 18 train_loss=0.7908 train_ce=0.7699 train_tc=0.1043 val_ce=2.5852 epoch_time=2.6s total=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep19 step 24/24 lr=1.98e-03 loss=0.7805 ce=0.7596 tc=0.1044 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 19 train_loss=0.7805 train_ce=0.7596 train_tc=0.1044 val_ce=2.5168 epoch_time=2.7s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep20 step 24/24 lr=1.85e-03 loss=0.7524 ce=0.7323 tc=0.1004 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 20 train_loss=0.7524 train_ce=0.7323 train_tc=0.1004 val_ce=2.4571 epoch_time=2.6s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep21 step 24/24 lr=1.72e-03 loss=0.7340 ce=0.7144 tc=0.0981 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 21 train_loss=0.7340 train_ce=0.7144 train_tc=0.0981 val_ce=2.4070 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep22 step 24/24 lr=1.59e-03 loss=0.7160 ce=0.6962 tc=0.0988 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 22 train_loss=0.7160 train_ce=0.6962 train_tc=0.0988 val_ce=2.3650 epoch_time=2.6s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep23 step 24/24 lr=1.45e-03 loss=0.6998 ce=0.6807 tc=0.0958 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 23 train_loss=0.6998 train_ce=0.6807 train_tc=0.0958 val_ce=2.3286 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep24 step 24/24 lr=1.32e-03 loss=0.6769 ce=0.6587 tc=0.0911 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 24 train_loss=0.6769 train_ce=0.6587 train_tc=0.0911 val_ce=2.2974 epoch_time=2.6s total=1.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep25 step 24/24 lr=1.19e-03 loss=0.6718 ce=0.6543 tc=0.0873 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 25 train_loss=0.6718 train_ce=0.6543 train_tc=0.0873 val_ce=2.2716 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep26 step 24/24 lr=1.06e-03 loss=0.6579 ce=0.6405 tc=0.0873 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 26 train_loss=0.6579 train_ce=0.6405 train_tc=0.0873 val_ce=2.2499 epoch_time=2.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep27 step 24/24 lr=9.36e-04 loss=0.6394 ce=0.6221 tc=0.0868 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 27 train_loss=0.6394 train_ce=0.6221 train_tc=0.0868 val_ce=2.2319 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep28 step 24/24 lr=8.16e-04 loss=0.6305 ce=0.6136 tc=0.0842 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 28 train_loss=0.6305 train_ce=0.6136 train_tc=0.0842 val_ce=2.2157 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep29 step 24/24 lr=7.02e-04 loss=0.6282 ce=0.6119 tc=0.0818 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 29 train_loss=0.6282 train_ce=0.6119 train_tc=0.0818 val_ce=2.2028 epoch_time=2.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep30 step 24/24 lr=5.93e-04 loss=0.6197 ce=0.6033 tc=0.0819 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 30 train_loss=0.6197 train_ce=0.6033 train_tc=0.0819 val_ce=2.1902 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep31 step 24/24 lr=4.93e-04 loss=0.6070 ce=0.5909 tc=0.0802 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 31 train_loss=0.6070 train_ce=0.5909 train_tc=0.0802 val_ce=2.1807 epoch_time=2.6s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep32 step 24/24 lr=4.00e-04 loss=0.6060 ce=0.5900 tc=0.0801 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 32 train_loss=0.6060 train_ce=0.5900 train_tc=0.0801 val_ce=2.1719 epoch_time=2.6s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep33 step 24/24 lr=3.17e-04 loss=0.6050 ce=0.5888 tc=0.0810 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 33 train_loss=0.6050 train_ce=0.5888 train_tc=0.0810 val_ce=2.1644 epoch_time=2.7s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep34 step 24/24 lr=2.43e-04 loss=0.5971 ce=0.5813 tc=0.0788 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 34 train_loss=0.5971 train_ce=0.5813 train_tc=0.0788 val_ce=2.1580 epoch_time=2.7s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep35 step 24/24 lr=1.79e-04 loss=0.5925 ce=0.5768 tc=0.0788 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 35 train_loss=0.5925 train_ce=0.5768 train_tc=0.0788 val_ce=2.1522 epoch_time=2.6s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep36 step 24/24 lr=1.27e-04 loss=0.5929 ce=0.5770 tc=0.0792 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 36 train_loss=0.5929 train_ce=0.5770 train_tc=0.0792 val_ce=2.1474 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep37 step 24/24 lr=8.50e-05 loss=0.5907 ce=0.5751 tc=0.0780 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 37 train_loss=0.5907 train_ce=0.5751 train_tc=0.0780 val_ce=2.1430 epoch_time=2.6s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep38 step 24/24 lr=5.49e-05 loss=0.5880 ce=0.5724 tc=0.0779 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 38 train_loss=0.5880 train_ce=0.5724 train_tc=0.0779 val_ce=2.1397 epoch_time=2.7s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep39 step 24/24 lr=3.65e-05 loss=0.5874 ce=0.5719 tc=0.0776 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 39 train_loss=0.5874 train_ce=0.5719 train_tc=0.0776 val_ce=2.1373 epoch_time=2.6s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ep40 step 24/24 lr=3.00e-05 loss=0.5916 ce=0.5760 tc=0.0781 lam_tc=0.200 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2 CE+TC] Epoch 40 train_loss=0.5916 train_ce=0.5760 train_tc=0.0781 val_ce=2.1350 epoch_time=2.6s total=1.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved best EMA weights to model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 CE+TC done. Best val CE=2.1350. Model -> model_tc_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All folds CE+TC processed.\n"
          ]
        }
      ]
    },
    {
      "id": "3b14b09e-ba08-438f-8255-c8e4a23364b6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cache OOF for TC models, sweep decoder on TC6 and CE6+TC6, and build test submission\n",
        "import os, json, time, math, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA:', torch.cuda.is_available(), flush=True)\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def load_feat(split, sid:int):\n",
        "    d = np.load((feat_tr_dir if split=='train' else feat_te_dir)/f\"{sid}.npz\");\n",
        "    return d['X'].astype(np.float32)\n",
        "\n",
        "def compute_fold_scaler(id_list):\n",
        "    n = 0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = load_feat('train', int(sid)); n_i = X.shape[0]\n",
        "        if mean is None:\n",
        "            mean = X.mean(axis=0); M2 = ((X - mean)**2).sum(axis=0); n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0); n_new = n + n_i; delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new))\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new))\n",
        "            n = n_new\n",
        "    var = M2 / max(1, (n - 1)); std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__();\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch); self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1); self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h);\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True);\n",
        "        return x + h\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__();\n",
        "        self.inp = nn.Conv1d(d_in, channels, 1); blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3));\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks); self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2); h = self.inp(x);\n",
        "        for b in self.blocks: h = b(h);\n",
        "        out = self.head(h); return out.transpose(1,2)\n",
        "\n",
        "def time_warp_probs(p_t_c: torch.Tensor, factor: float) -> torch.Tensor:\n",
        "    T, C = p_t_c.shape; tgt_len = max(1, int(round(T*factor)));\n",
        "    x = p_t_c.T.unsqueeze(0);\n",
        "    y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False);\n",
        "    y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T;\n",
        "    return y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        ps = time_warp_probs(p_t_c, s);\n",
        "        acc = ps if acc is None else (acc + ps)\n",
        "    out = acc / float(len(factors))\n",
        "    return out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2);\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k = max(1, int(k)); x = p_t.view(1,1,-1);\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "    pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1);\n",
        "    T = p_t.shape[0]\n",
        "    if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]))\n",
        "    elif y.shape[0] > T: y = y[:T]\n",
        "    return y\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T = p.shape[0]; a = max(0, t_star - w); b = min(T-1, t_star + w);\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype);\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8;\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def topk_candidates_per_class(p_s: torch.Tensor, scores: torch.Tensor, c: int, k_c: int, temp: float, K: int = 3):\n",
        "    T = p_s.shape[0]; s = scores[:, c]; vals, idxs = torch.topk(s, k=min(K, T));\n",
        "    cand = []; w_com = max(5, k_c//3); radius = max(10, k_c//2)\n",
        "    for v, t_star in zip(vals.tolist(), idxs.tolist()):\n",
        "        t_ref = refine_com(p_s[:,c], int(t_star), w=w_com);\n",
        "        t_idx = int(round(max(0, min(t_ref, T-1))));\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item();\n",
        "        pooled_at_ref = p_s[t_idx, c].item();\n",
        "        cand.append((t_ref, float(v), float(local_mean), float(pooled_at_ref)))\n",
        "    cand.sort(key=lambda x: (x[0], -x[1], -x[2], -x[3]))\n",
        "    return cand\n",
        "\n",
        "def decode_peaks_improved(p_t_c: torch.Tensor, med_k: dict, gamma: float = 1.0, pool_k=13, temp=0.9, min_sep=2, K=3, k_delta=4):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k); T, C = p_s.shape\n",
        "    scores = torch.zeros_like(p_s); ks=[13]*C\n",
        "    for c in range(C):\n",
        "        if c == 0:\n",
        "            scores[:, c] = p_s[:, c]; ks[c]=13; continue\n",
        "        base_k = med_k.get(c, 13)\n",
        "        k_c = int(np.clip(round(gamma * base_k), 9, 25))\n",
        "        if k_c % 2 == 0: k_c = min(25, k_c + 1)\n",
        "        ks[c] = k_c\n",
        "        ks_multi = sorted(set([int(np.clip(k_c - k_delta, 9, 25)), k_c, int(np.clip(k_c + k_delta, 9, 25))]))\n",
        "        ks_multi = [k if (k % 2)==1 else min(25, k+1) for k in ks_multi]\n",
        "        acc=None\n",
        "        for k in ks_multi:\n",
        "            di = duration_integral_single(p_s[:, c], k=k).unsqueeze(1)\n",
        "            acc = di if acc is None else (acc + di)\n",
        "        scores[:, c] = (acc / float(len(ks_multi))).squeeze(1)\n",
        "    all_cand = []\n",
        "    for c in range(1,21):\n",
        "        cand = topk_candidates_per_class(p_s, scores, c, ks[c], temp=temp, K=K)\n",
        "        if len(cand)==0:\n",
        "            all_cand.append((c, 0.0, -1e9, -1e9, -1e9))\n",
        "        else:\n",
        "            for (t_ref, v, lm, pr) in cand: all_cand.append((c, t_ref, v, lm, pr))\n",
        "    all_cand.sort(key=lambda x: (x[1], -x[2], -x[3], -x[4]))\n",
        "    chosen = {}; last_t = -1e9\n",
        "    for c, t_ref, v, lm, pr in all_cand:\n",
        "        if c in chosen: continue\n",
        "        if t_ref <= last_t + float(min_sep):\n",
        "            t_ref = last_t + float(min_sep)\n",
        "        last_t = min(t_ref, float(T-1))\n",
        "        chosen[c] = (last_t, v, lm, pr)\n",
        "        if len(chosen)==20: break\n",
        "    if len(chosen) < 20:\n",
        "        missing = [c for c in range(1,21) if c not in chosen]\n",
        "        t = max(last_t, 0.0)\n",
        "        for c in missing:\n",
        "            t = min(t + float(min_sep), float(T-1))\n",
        "            chosen[c] = (t, -1e9, -1e9, -1e9)\n",
        "    seq = [c for c,_ in sorted(chosen.items(), key=lambda kv: kv[1][0])]\n",
        "    return seq\n",
        "\n",
        "def gamma_with_length(gamma_cv: float, T: int, med_k: dict):\n",
        "    L_est = float(sum(med_k.get(c,13) for c in range(1,21)))\n",
        "    if L_est <= 0: return gamma_cv\n",
        "    ratio = float(T) / L_est\n",
        "    gamma_s = float(np.clip(ratio, 0.85, 1.15))\n",
        "    return float(gamma_cv * gamma_s)\n",
        "\n",
        "# 1) Cache OOF probs for TC models (per fold) with TTA; save {sid}_tc.npy and {sid}_tc_s1.npy\n",
        "def cache_fold_val_probs_tc(fold, seed_suffix: str):\n",
        "    fold_idx = int(fold['fold'])\n",
        "    ckpt = Path(f\"model_tc_fold{fold_idx}{seed_suffix}.pth\")\n",
        "    assert ckpt.exists(), f\"Missing {ckpt}; ensure TC training is finished\"\n",
        "    D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "    model = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device)); model.eval()\n",
        "    mean,std = compute_fold_scaler(fold['train_ids'])\n",
        "    mean_t = torch.from_numpy(mean).float().to(device); std_t = torch.from_numpy(std).float().to(device)\n",
        "    vids = fold['val_ids']; t0=time.time()\n",
        "    for i, sid in enumerate(vids, 1):\n",
        "        sid=int(sid); outp = probs_cache/f\"{sid}_tc{seed_suffix}.npy\"\n",
        "        # Force refresh after retrain: remove existing cache if present\n",
        "        if outp.exists():\n",
        "            try: outp.unlink()\n",
        "            except Exception as e: pass\n",
        "        X = load_feat('train', sid); xb = torch.from_numpy(X).float().to(device);\n",
        "        xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0)\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "            probs = model(xb)[0].softmax(dim=-1)\n",
        "            probs = apply_tta_timewarp(probs, factors=(0.9,1.0,1.1))\n",
        "        np.save(outp, probs.cpu().numpy())\n",
        "        if (i%25)==0 or i==len(vids):\n",
        "            print(f\"  [fold {fold_idx} TC{seed_suffix}] cached {i}/{len(vids)} elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "print('Caching OOF probs for TC models (both seeds)...', flush=True)\n",
        "for f in folds:\n",
        "    for suf in ['', '_s1']:\n",
        "        ckpt = Path(f\"model_tc_fold{int(f['fold'])}{suf}.pth\")\n",
        "        if not ckpt.exists():\n",
        "            print(f\"  [skip fold {f['fold']}{suf}] checkpoint not found yet\")\n",
        "            continue\n",
        "        cache_fold_val_probs_tc(f, suf)\n",
        "\n",
        "# 2) Evaluate decoder on TC6 and CE6+TC6 averaged OOF\n",
        "def load_cached_prob(path):\n",
        "    return torch.from_numpy(np.load(path)).to(device)\n",
        "\n",
        "def load_oof_avg(seed_paths):\n",
        "    ps = [load_cached_prob(p) for p in seed_paths]\n",
        "    p = sum(ps) / float(len(ps))\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def eval_cfg_on_fold_with_loader(fold, loader_fn, pool_k, temp, gamma, sep):\n",
        "    fi = int(fold['fold'])\n",
        "    med_k = compute_class_median_durations_for_ids(fold['train_ids'])\n",
        "    vids = fold['val_ids']; tot=0; cnt=0\n",
        "    for sid in vids:\n",
        "        sid=int(sid); p = loader_fn(sid); T = p.shape[0]\n",
        "        gamma_eff = gamma_with_length(gamma, T, med_k)\n",
        "        seq = decode_peaks_improved(p, med_k=med_k, gamma=gamma_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "        tot += levenshtein(seq, id2seq[sid]); cnt += 1\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# Loader for TC6 averaged OOF\n",
        "def loader_tc6(sid:int):\n",
        "    paths = [probs_cache/f\"{sid}_tc.npy\", probs_cache/f\"{sid}_tc_s1.npy\"]\n",
        "    paths = [str(p) for p in paths if Path(p).exists()]\n",
        "    assert len(paths)>0, f\"Missing TC OOF for sid={sid}\"\n",
        "    return load_oof_avg(paths)\n",
        "\n",
        "# Loader for CE6+TC6 averaged OOF (equal weights across 12)\n",
        "def loader_ce_tc_12(sid:int):\n",
        "    paths = []\n",
        "    # CE OOF (seed0 + seed1)\n",
        "    p0 = probs_cache/f\"{sid}_ce_new.npy\"; p1 = probs_cache/f\"{sid}_ce_new_s1.npy\"\n",
        "    if p0.exists(): paths.append(str(p0))\n",
        "    if p1.exists(): paths.append(str(p1))\n",
        "    # TC OOF (seed0 + seed1)\n",
        "    pt0 = probs_cache/f\"{sid}_tc.npy\"; pt1 = probs_cache/f\"{sid}_tc_s1.npy\"\n",
        "    if pt0.exists(): paths.append(str(pt0))\n",
        "    if pt1.exists(): paths.append(str(pt1))\n",
        "    assert len(paths)>0, f\"Missing CE/TC OOF for sid={sid}\"\n",
        "    return load_oof_avg(paths)\n",
        "\n",
        "pool_ks=[11,13,15]; temps=[0.90,0.95,1.00]; gammas=[0.90,0.95,0.975,1.00,1.025,1.05]; seps=[3,4,5]\n",
        "\n",
        "def sweep_with_loader(name, loader_fn):\n",
        "    print(f'Sweeping {name}...', flush=True)\n",
        "    results=[]\n",
        "    for pool_k in pool_ks:\n",
        "        for temp in temps:\n",
        "            for gamma in gammas:\n",
        "                for sep in seps:\n",
        "                    per_fold=[]\n",
        "                    ok=True\n",
        "                    for f in folds:\n",
        "                        try:\n",
        "                            lev = eval_cfg_on_fold_with_loader(f, loader_fn, pool_k, temp, gamma, sep)\n",
        "                            per_fold.append(lev)\n",
        "                        except AssertionError as e:\n",
        "                            ok=False; break\n",
        "                    if ok and len(per_fold)==len(folds):\n",
        "                        results.append((np.mean(per_fold), np.max(per_fold), {'pool_k':pool_k,'temp':temp,'gamma':gamma,'sep':sep}))\n",
        "    results.sort(key=lambda x: (x[1], x[0]))\n",
        "    return results\n",
        "\n",
        "res_tc = sweep_with_loader('TC6 (avg OOF)', loader_tc6)\n",
        "if len(res_tc)>0:\n",
        "    print('Top TC6 (mean, worst, cfg):')\n",
        "    for r in res_tc[:5]: print(r)\n",
        "    pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res_tc]).to_csv('cv_sweep_tc_6x_improved.csv', index=False)\n",
        "else:\n",
        "    print('TC6 sweep skipped (missing OOF).')\n",
        "\n",
        "res_ce_tc = sweep_with_loader('CE6+TC6 (avg OOF)', loader_ce_tc_12)\n",
        "if len(res_ce_tc)>0:\n",
        "    print('Top CE6+TC6 (mean, worst, cfg):')\n",
        "    for r in res_ce_tc[:5]: print(r)\n",
        "    pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res_ce_tc]).to_csv('cv_sweep_ce_tc_12x_improved.csv', index=False)\n",
        "else:\n",
        "    print('CE6+TC6 sweep skipped (missing OOF).')\n",
        "\n",
        "# 3) Build test submission using the best between TC6 and CE6+TC6 by worst-fold then mean\n",
        "def choose_best_cfg():\n",
        "    cand=[]\n",
        "    if Path('cv_sweep_tc_6x_improved.csv').exists():\n",
        "        df = pd.read_csv('cv_sweep_tc_6x_improved.csv').sort_values(['worst','mean'])\n",
        "        if len(df): cand.append(('tc6', df.iloc[0].to_dict()))\n",
        "    if Path('cv_sweep_ce_tc_12x_improved.csv').exists():\n",
        "        df = pd.read_csv('cv_sweep_ce_tc_12x_improved.csv').sort_values(['worst','mean'])\n",
        "        if len(df): cand.append(('ce_tc_12', df.iloc[0].to_dict()))\n",
        "    if not cand:\n",
        "        return None, {'pool_k':13,'temp':0.95,'gamma':1.0,'sep':3}\n",
        "    # pick by lowest worst, then mean\n",
        "    cand.sort(key=lambda kv: (kv[1]['worst'], kv[1]['mean']))\n",
        "    return cand[0][0], cand[0][1]\n",
        "\n",
        "blend, cfg_best = choose_best_cfg()\n",
        "print('Chosen blend:', blend, 'cfg:', cfg_best)\n",
        "\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "med_k_train_all = compute_class_median_durations_for_ids(pd.read_csv('training.csv')['Id'].astype(int).tolist())\n",
        "pool_k=int(cfg_best.get('pool_k',13)); temp=float(cfg_best.get('temp',0.95)); gamma=float(cfg_best.get('gamma',1.0)); sep=int(cfg_best.get('sep',3))\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "def infer_tc6():\n",
        "    # lazy-load each fold's two TC models per sample to control VRAM\n",
        "    scalers=[compute_fold_scaler(folds[fi]['train_ids']) for fi in range(3)]\n",
        "    scalers=[(torch.from_numpy(m).float().to(device), torch.from_numpy(s).float().to(device)) for (m,s) in scalers]\n",
        "    rows=[]; t0=time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat('test', int(sid)); T = X.shape[0]\n",
        "        acc=None\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "            for fi in range(3):\n",
        "                mean_t, std_t = scalers[fi]\n",
        "                for s in (0,1):\n",
        "                    ckpt = Path(f\"model_tc_fold{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                    if not ckpt.exists():\n",
        "                        continue\n",
        "                    m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                    m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                    xb = torch.from_numpy(X).float().to(device);\n",
        "                    xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0)\n",
        "                    p = m(xb)[0].softmax(dim=-1);\n",
        "                    p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1));\n",
        "                    acc = p if acc is None else (acc + p)\n",
        "                    del m\n",
        "            probs = acc / float(6); probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        gamma_eff = gamma_with_length(gamma, T, med_k_train_all)\n",
        "        seq = decode_peaks_improved(probs, med_k=med_k_train_all, gamma=gamma_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [infer TC-6x] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    return pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "\n",
        "def infer_ce_tc_12():\n",
        "    # lazy-load all 12 models (6 CE + 6 TC) per sample\n",
        "    scalers=[compute_fold_scaler(folds[fi]['train_ids']) for fi in range(3)]\n",
        "    scalers=[(torch.from_numpy(m).float().to(device), torch.from_numpy(s).float().to(device)) for (m,s) in scalers]\n",
        "    rows=[]; t0=time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat('test', int(sid)); T = X.shape[0]\n",
        "        acc=None\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "            for fi in range(3):\n",
        "                mean_t, std_t = scalers[fi]\n",
        "                # CE two seeds\n",
        "                for s in (0,1):\n",
        "                    ckpt = Path(f\"model_ce_fold{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                    if ckpt.exists():\n",
        "                        m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                        m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                        xb = torch.from_numpy(X).float().to(device);\n",
        "                        xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0)\n",
        "                        p = m(xb)[0].softmax(dim=-1);\n",
        "                        p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1));\n",
        "                        acc = p if acc is None else (acc + p)\n",
        "                        del m\n",
        "                # TC two seeds\n",
        "                for s in (0,1):\n",
        "                    ckpt = Path(f\"model_tc_fold{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                    if ckpt.exists():\n",
        "                        m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                        m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                        xb = torch.from_numpy(X).float().to(device);\n",
        "                        xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0)\n",
        "                        p = m(xb)[0].softmax(dim=-1);\n",
        "                        p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1));\n",
        "                        acc = p if acc is None else (acc + p)\n",
        "                        del m\n",
        "            denom = float(max(1, 12))\n",
        "            probs = acc / denom; probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        gamma_eff = gamma_with_length(gamma, T, med_k_train_all)\n",
        "        seq = decode_peaks_improved(probs, med_k=med_k_train_all, gamma=gamma_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [infer CE+TC-12x] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    return pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "\n",
        "sub=None\n",
        "if blend == 'tc6':\n",
        "    sub = infer_tc6()\n",
        "elif blend == 'ce_tc_12':\n",
        "    sub = infer_ce_tc_12()\n",
        "else:\n",
        "    print('No blend selected or missing sweeps; defaulting to TC6 if available else abort')\n",
        "    if Path('model_tc_fold0.pth').exists():\n",
        "        sub = infer_tc6()\n",
        "\n",
        "if sub is not None:\n",
        "    assert len(sub)==95\n",
        "    assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "    outp = 'submission_primary_tc_6x.csv' if blend=='tc6' else 'submission_primary_ce_tc_12x.csv'\n",
        "    sub.to_csv(outp, index=False); sub.to_csv('submission.csv', index=False)\n",
        "    print(f'Wrote {outp} and submission.csv; head:\\n', sub.head(), flush=True)\n",
        "else:\n",
        "    print('Submission not created (waiting for TC training to finish and OOF to be cached).')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching OOF probs for TC models (both seeds)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/162146045.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(ckpt, map_location=device)); model.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 TC] cached 25/98 elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 TC] cached 50/98 elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 TC] cached 75/98 elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 TC] cached 98/98 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 TC_s1] cached 25/98 elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 TC_s1] cached 50/98 elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 TC_s1] cached 75/98 elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 0 TC_s1] cached 98/98 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 TC] cached 25/99 elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 TC] cached 50/99 elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 TC] cached 75/99 elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 TC] cached 99/99 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 TC_s1] cached 25/99 elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 TC_s1] cached 50/99 elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 TC_s1] cached 75/99 elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 1 TC_s1] cached 99/99 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 TC] cached 25/100 elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 TC] cached 50/100 elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 TC] cached 75/100 elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 TC] cached 100/100 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 TC_s1] cached 25/100 elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 TC_s1] cached 50/100 elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 TC_s1] cached 75/100 elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [fold 2 TC_s1] cached 100/100 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweeping TC6 (avg OOF)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top TC6 (mean, worst, cfg):\n(4.855605717034288, 5.63, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.9, 'sep': 3})\n(4.855605717034288, 5.63, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.9, 'sep': 4})\n(4.855605717034288, 5.63, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.9, 'sep': 5})\n(4.855605717034288, 5.63, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.95, 'sep': 3})\n(4.855605717034288, 5.63, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.95, 'sep': 4})\nSweeping CE6+TC6 (avg OOF)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top CE6+TC6 (mean, worst, cfg):\n(4.579729265443551, 5.3, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.9, 'sep': 3})\n(4.579729265443551, 5.3, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.9, 'sep': 4})\n(4.579729265443551, 5.3, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.9, 'sep': 5})\n(4.579729265443551, 5.3, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.95, 'sep': 3})\n(4.579729265443551, 5.3, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.95, 'sep': 4})\nChosen blend: ce_tc_12 cfg: {'mean': 4.579729265443551, 'worst': 5.3, 'pool_k': 11.0, 'temp': 0.9, 'gamma': 0.9, 'sep': 3.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/162146045.py:370: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n/tmp/ipykernel_8891/162146045.py:382: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x] 20/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x] 30/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x] 40/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x] 50/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x] 60/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x] 70/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x] 80/95 elapsed=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x] 90/95 elapsed=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x] 95/95 elapsed=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_tc_12x.csv and submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 7 1...\n1  301  10 12 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 3 1...\n2  302  1 17 16 12 5 19 7 13 20 18 11 3 4 6 15 8 14 10...\n3  303  13 4 12 1 10 5 19 15 20 17 11 16 8 18 7 3 6 2 ...\n4  304  8 1 12 14 18 13 9 7 2 11 3 20 19 5 10 6 15 17 ...\n"
          ]
        }
      ]
    },
    {
      "id": "21d4fe14-95c3-471a-a8de-f91959665f50",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# P1: Per-class temperature calibration and CE/TC reliability blending on OOF; normalized LD diagnostics\n",
        "import os, json, time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "# Utilities: load OOF probs\n",
        "def load_oof_prob(sid:int, kind:str):\n",
        "    # kind in {'ce0','ce1','tc0','tc1'} mapping to filename suffixes\n",
        "    m = {'ce0': f\"{sid}_ce_new.npy\", 'ce1': f\"{sid}_ce_new_s1.npy\", 'tc0': f\"{sid}_tc.npy\", 'tc1': f\"{sid}_tc_s1.npy\"}\n",
        "    p = probs_cache/m[kind]; assert p.exists(), f\"Missing {p}\"\n",
        "    return torch.from_numpy(np.load(p)).to(device)\n",
        "\n",
        "def avg_seed(oof_a: torch.Tensor, oof_b: torch.Tensor):\n",
        "    p = (oof_a + oof_b) * 0.5\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "# Temperature helpers\n",
        "def apply_temp_prob(p_t_c: torch.Tensor, T: float):\n",
        "    # global temperature on all classes\n",
        "    if abs(T-1.0) < 1e-6: return p_t_c\n",
        "    q = torch.pow(torch.clamp(p_t_c, 1e-8, 1.0), 1.0/float(T))\n",
        "    return q / (q.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def apply_one_class_temp(p_t_c: torch.Tensor, c: int, T: float):\n",
        "    # adjust only class c by T, renormalize rows\n",
        "    if abs(T-1.0) < 1e-6: return p_t_c\n",
        "    q = p_t_c.clone()\n",
        "    qc = torch.pow(torch.clamp(q[:, c], 1e-8, 1.0), 1.0/float(T))\n",
        "    q[:, c] = qc\n",
        "    return q / (q.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def apply_per_class_temps(p_t_c: torch.Tensor, T_vec: np.ndarray):\n",
        "    # elementwise power per class then renormalize rows\n",
        "    T = torch.from_numpy(T_vec.astype(np.float32)).to(device)  # shape [C]\n",
        "    exps = 1.0 / (T + 1e-8)\n",
        "    q = torch.pow(torch.clamp(p_t_c, 1e-8, 1.0), exps.unsqueeze(0))\n",
        "    return q / (q.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "# Geometric blend per class alpha: p \u221d (p_ce**alpha_c) * (p_tc**(1-alpha_c))\n",
        "def blend_ce_tc_perclass(p_ce: torch.Tensor, p_tc: torch.Tensor, alpha_c: np.ndarray):\n",
        "    al = torch.from_numpy(alpha_c.astype(np.float32)).to(device)\n",
        "    log_ce = torch.log(torch.clamp(p_ce, 1e-8, 1.0))\n",
        "    log_tc = torch.log(torch.clamp(p_tc, 1e-8, 1.0))\n",
        "    comb = torch.exp(log_ce * al + log_tc * (1.0 - al))\n",
        "    return comb / (comb.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "# Per-frame NLL for temperature and alpha fitting\n",
        "def per_frame_nll(p_t_c: torch.Tensor, y_t: torch.Tensor):\n",
        "    m = (y_t >= 0)\n",
        "    if not torch.any(m):\n",
        "        return 0.0\n",
        "    idx = y_t[m].long()\n",
        "    picked = p_t_c[m, idx]\n",
        "    return float((-torch.log(torch.clamp(picked, 1e-8, 1.0))).mean().item())\n",
        "\n",
        "def load_labels(sid:int):\n",
        "    y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "    return torch.from_numpy(y).to(device)\n",
        "\n",
        "# Build fold-out datasets of per-frame probs and labels for calibration without leakage\n",
        "def collect_oof_for_ids(id_list, stream: str):\n",
        "    data = []  # list of (p_t_c, y_t)\n",
        "    for sid in id_list:\n",
        "        sid = int(sid)\n",
        "        y = load_labels(sid)\n",
        "        if stream == 'ce':\n",
        "            p0 = load_oof_prob(sid, 'ce0'); p1 = load_oof_prob(sid, 'ce1') if (probs_cache/f\"{sid}_ce_new_s1.npy\").exists() else None\n",
        "        else:\n",
        "            p0 = load_oof_prob(sid, 'tc0'); p1 = load_oof_prob(sid, 'tc1') if (probs_cache/f\"{sid}_tc_s1.npy\").exists() else None\n",
        "        p = avg_seed(p0, p1) if p1 is not None else p0\n",
        "        data.append((p, y))\n",
        "    return data\n",
        "\n",
        "# Fit per-class temperature T_c using one-class adjustment and NLL on frames of that class\n",
        "def fit_per_class_temperature(fold_idx: int):\n",
        "    val_ids_all = []\n",
        "    for f in folds:\n",
        "        if int(f['fold']) != int(fold_idx):\n",
        "            val_ids_all.extend(f['val_ids'])\n",
        "    ce_data = collect_oof_for_ids(val_ids_all, 'ce')\n",
        "    tc_data = collect_oof_for_ids(val_ids_all, 'tc')\n",
        "    T_grid = np.round(np.arange(0.85, 1.1501, 0.02), 2)\n",
        "    C = ce_data[0][0].shape[1]\n",
        "    T_ce = np.ones(C, dtype=np.float32)\n",
        "    T_tc = np.ones(C, dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        if c == 0:\n",
        "            T_ce[c] = 1.0; T_tc[c] = 1.0\n",
        "            continue\n",
        "        best_nll_ce, best_T_ce = 1e9, 1.0\n",
        "        best_nll_tc, best_T_tc = 1e9, 1.0\n",
        "        for T in T_grid:\n",
        "            nll_ce_c = 0.0; cnt_ce = 0\n",
        "            for p, y in ce_data:\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                q = apply_one_class_temp(p, c, float(T))\n",
        "                nll_ce_c += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt_ce += int(m.sum().item())\n",
        "            if cnt_ce > 0 and (nll_ce_c / cnt_ce) < best_nll_ce:\n",
        "                best_nll_ce = nll_ce_c / max(1, cnt_ce); best_T_ce = float(T)\n",
        "            nll_tc_c = 0.0; cnt_tc = 0\n",
        "            for p, y in tc_data:\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                q = apply_one_class_temp(p, c, float(T))\n",
        "                nll_tc_c += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt_tc += int(m.sum().item())\n",
        "            if cnt_tc > 0 and (nll_tc_c / cnt_tc) < best_nll_tc:\n",
        "                best_nll_tc = nll_tc_c / max(1, cnt_tc); best_T_tc = float(T)\n",
        "        T_ce[c] = best_T_ce; T_tc[c] = best_T_tc\n",
        "    return T_ce, T_tc\n",
        "\n",
        "# Fit per-class alpha reliability on non-fold data using per-class temperature vectors\n",
        "def fit_per_class_alpha(fold_idx: int, T_ce: np.ndarray, T_tc: np.ndarray):\n",
        "    val_ids_all = []\n",
        "    for f in folds:\n",
        "        if int(f['fold']) != int(fold_idx):\n",
        "            val_ids_all.extend(f['val_ids'])\n",
        "    ce_data = collect_oof_for_ids(val_ids_all, 'ce')\n",
        "    tc_data = collect_oof_for_ids(val_ids_all, 'tc')\n",
        "    A_grid = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "    C = ce_data[0][0].shape[1]\n",
        "    alpha = np.full(C, 0.8, dtype=np.float32)  # CE-heavy default\n",
        "    # precompute temperature-calibrated probs per sample (vector temps)\n",
        "    ce_calib = [apply_per_class_temps(p_ce, T_ce) for (p_ce, _) in ce_data]\n",
        "    tc_calib = [apply_per_class_temps(p_tc, T_tc) for (p_tc, _) in tc_data]\n",
        "    for c in range(C):\n",
        "        if c == 0:\n",
        "            alpha[c] = 0.8\n",
        "            continue\n",
        "        best_nll, best_a = 1e9, 0.8\n",
        "        for a in A_grid:\n",
        "            nll_c = 0.0; cnt = 0\n",
        "            for i, ((_, y),) in enumerate(zip(ce_data)):\n",
        "                q_ce = ce_calib[i]; q_tc = tc_calib[i]\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                a_vec = np.full(C, 0.8, dtype=np.float32); a_vec[c] = float(a)\n",
        "                q = blend_ce_tc_perclass(q_ce, q_tc, a_vec)\n",
        "                nll_c += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt += int(m.sum().item())\n",
        "            if cnt > 0 and (nll_c / cnt) < best_nll:\n",
        "                best_nll = nll_c / max(1, cnt); best_a = float(a)\n",
        "        alpha[c] = best_a\n",
        "    return alpha\n",
        "\n",
        "# Apply per-class temps (vector) and alpha to a given sid's OOF and return blended probs\n",
        "def calibrated_blend_for_sid(sid:int, T_ce: np.ndarray, T_tc: np.ndarray, alpha: np.ndarray):\n",
        "    p_ce0 = load_oof_prob(sid, 'ce0'); p_ce1 = load_oof_prob(sid, 'ce1') if (probs_cache/f\"{sid}_ce_new_s1.npy\").exists() else None\n",
        "    p_tc0 = load_oof_prob(sid, 'tc0'); p_tc1 = load_oof_prob(sid, 'tc1') if (probs_cache/f\"{sid}_tc_s1.npy\").exists() else None\n",
        "    p_ce = avg_seed(p_ce0, p_ce1) if p_ce1 is not None else p_ce0\n",
        "    p_tc = avg_seed(p_tc0, p_tc1) if p_tc1 is not None else p_tc0\n",
        "    q_ce = apply_per_class_temps(p_ce, T_ce)\n",
        "    q_tc = apply_per_class_temps(p_tc, T_tc)\n",
        "    q = blend_ce_tc_perclass(q_ce, q_tc, alpha)\n",
        "    return q\n",
        "\n",
        "# Decoder imports from Cell 10/13 context\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2); y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k = max(1, int(k)); x = p_t.view(1,1,-1); w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "    pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1); T = p_t.shape[0]\n",
        "    if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]));\n",
        "    elif y.shape[0] > T: y = y[:T];\n",
        "    return y\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T = p.shape[0]; a = max(0, t_star - w); b = min(T-1, t_star + w); idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype);\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8; return float(((idx * seg).sum() / s).item())\n",
        "def topk_candidates_per_class(p_s: torch.Tensor, scores: torch.Tensor, c: int, k_c: int, temp: float, K: int = 3):\n",
        "    T = p_s.shape[0]; s = scores[:, c]; vals, idxs = torch.topk(s, k=min(K, T));\n",
        "    cand = []; w_com = max(5, k_c//3); radius = max(10, k_c//2)\n",
        "    for v, t_star in zip(vals.tolist(), idxs.tolist()):\n",
        "        t_ref = refine_com(p_s[:,c], int(t_star), w=w_com);\n",
        "        t_idx = int(round(max(0, min(t_ref, T-1))));\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item();\n",
        "        pooled_at_ref = p_s[t_idx, c].item();\n",
        "        cand.append((t_ref, float(v), float(local_mean), float(pooled_at_ref)))\n",
        "    cand.sort(key=lambda x: (x[0], -x[1], -x[2], -x[3])); return cand\n",
        "def decode_peaks_improved(p_t_c: torch.Tensor, med_k: dict, gamma: float = 1.0, pool_k=13, temp=0.9, min_sep=3, K=3, k_delta=4):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (torch.clamp(p_t_c, 1e-8, 1.0) ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k); T, C = p_s.shape; scores = torch.zeros_like(p_s); ks=[13]*C\n",
        "    for c in range(C):\n",
        "        if c == 0: scores[:, c] = p_s[:, c]; ks[c]=13; continue\n",
        "        base_k = med_k.get(c, 13); k_c = int(np.clip(round(gamma * base_k), 9, 25));\n",
        "        if k_c % 2 == 0: k_c = min(25, k_c + 1); ks[c] = k_c\n",
        "        ks_multi = sorted(set([int(np.clip(k_c - k_delta, 9, 25)), k_c, int(np.clip(k_c + k_delta, 9, 25))]));\n",
        "        ks_multi = [k if (k % 2)==1 else min(25, k+1) for k in ks_multi]; acc=None\n",
        "        for k in ks_multi:\n",
        "            di = duration_integral_single(p_s[:, c], k=k).unsqueeze(1); acc = di if acc is None else (acc + di)\n",
        "        scores[:, c] = (acc / float(len(ks_multi))).squeeze(1)\n",
        "    all_cand=[]; last_t=-1e9; chosen={}\n",
        "    for c in range(1,21):\n",
        "        for (t_ref, v, lm, pr) in topk_candidates_per_class(p_s, scores, c, ks[c], temp=temp, K=3):\n",
        "            all_cand.append((c, t_ref, v, lm, pr))\n",
        "    all_cand.sort(key=lambda x: (x[1], -x[2], -x[3], -x[4]))\n",
        "    for c, t_ref, v, lm, pr in all_cand:\n",
        "        if c in chosen: continue\n",
        "        if t_ref <= last_t + float(min_sep): t_ref = last_t + float(min_sep)\n",
        "        last_t = min(t_ref, float(T-1)); chosen[c] = (last_t, v, lm, pr)\n",
        "        if len(chosen)==20: break\n",
        "    if len(chosen) < 20:\n",
        "        missing = [c for c in range(1,21) if c not in chosen]; t = max(last_t, 0.0)\n",
        "        for c in missing: t = min(t + float(min_sep), float(T-1)); chosen[c] = (t, -1e9, -1e9, -1e9)\n",
        "    seq = [c for c,_ in sorted(chosen.items(), key=lambda kv: kv[1][0])]; return seq\n",
        "\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {};\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "\n",
        "def gamma_with_length(gamma_cv: float, T: int, med_k: dict):\n",
        "    L_est = float(sum(med_k.get(c,13) for c in range(1,21)))\n",
        "    if L_est <= 0: return gamma_cv\n",
        "    ratio = float(T) / L_est; gamma_s = float(np.clip(ratio, 0.85, 1.15)); return float(gamma_cv * gamma_s)\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# Metric diagnostics: mean LD and normalized LD (total edits / total gt length) per setting\n",
        "def eval_fold_sequences(fold, seqs_by_sid):\n",
        "    vids = [int(s) for s in fold['val_ids']];\n",
        "    tot_edits=0; tot_len=0; per_s=[]\n",
        "    for sid in vids:\n",
        "        gt = id2seq[sid]; pred = seqs_by_sid[sid];\n",
        "        ld = levenshtein(pred, gt); tot_edits += ld; tot_len += len(gt); per_s.append(ld)\n",
        "    mean_ld = float(np.mean(per_s)) if per_s else 0.0\n",
        "    norm_ld = float(tot_edits / max(1, tot_len))\n",
        "    return mean_ld, norm_ld\n",
        "\n",
        "# Run fold-out calibration, then evaluate calibrated CE/TC blend on each fold using improved decoder; log normalized LD\n",
        "pool_ks=[11,13,15]; temps=[0.90,0.95,1.00]; gammas=[0.90,0.95,0.975,1.00,1.025,1.05]; seps=[3]\n",
        "results=[]\n",
        "print('Starting per-class calibration and reliability blending (fold-out) ...', flush=True)\n",
        "for f in folds:\n",
        "    fi = int(f['fold'])\n",
        "    print(f'  Calibrating using folds != {fi} ...', flush=True)\n",
        "    T_ce, T_tc = fit_per_class_temperature(fi)\n",
        "    alpha = fit_per_class_alpha(fi, T_ce, T_tc)\n",
        "    Path(f'calib_fold{fi}.json').write_text(json.dumps({'T_ce': T_ce.tolist(), 'T_tc': T_tc.tolist(), 'alpha': alpha.tolist()}))\n",
        "\n",
        "print('Sweeping decoder on calibrated CE+TC OOF ...', flush=True)\n",
        "rows=[]\n",
        "for pool_k in pool_ks:\n",
        "    for temp in temps:\n",
        "        for gamma in gammas:\n",
        "            for sep in seps:\n",
        "                worsts=[]; means=[]; norms=[]\n",
        "                ok=True\n",
        "                for f in folds:\n",
        "                    fi = int(f['fold'])\n",
        "                    calib = json.loads(Path(f'calib_fold{fi}.json').read_text())\n",
        "                    T_ce = np.array(calib['T_ce'], dtype=np.float32); T_tc = np.array(calib['T_tc'], dtype=np.float32); alpha = np.array(calib['alpha'], dtype=np.float32)\n",
        "                    med_k = compute_class_median_durations_for_ids(f['train_ids'])\n",
        "                    seqs_by_sid = {}\n",
        "                    for sid in f['val_ids']:\n",
        "                        sid = int(sid)\n",
        "                        try:\n",
        "                            q = calibrated_blend_for_sid(sid, T_ce, T_tc, alpha)\n",
        "                        except AssertionError:\n",
        "                            ok=False; break\n",
        "                        Tlen = q.shape[0]; gamma_eff = gamma_with_length(gamma, Tlen, med_k)\n",
        "                        seq = decode_peaks_improved(q, med_k=med_k, gamma=gamma_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "                        seqs_by_sid[sid] = seq\n",
        "                    if not ok: break\n",
        "                    mean_ld, norm_ld = eval_fold_sequences(f, seqs_by_sid)\n",
        "                    means.append(mean_ld); norms.append(norm_ld)\n",
        "                if ok and len(means)==len(folds):\n",
        "                    rows.append({'pool_k':pool_k,'temp':temp,'gamma':gamma,'sep':sep,'mean':float(np.mean(means)), 'worst':float(np.max(means)), 'norm_mean':float(np.mean(norms)), 'norm_worst': float(np.max(norms))})\n",
        "df = pd.DataFrame(rows)\n",
        "if len(df):\n",
        "    df.sort_values(['worst','mean'], inplace=True)\n",
        "    df.to_csv('cv_sweep_ce_tc_calibrated.csv', index=False)\n",
        "    print('Top calibrated (by worst then mean):')\n",
        "    print(df.head())\n",
        "else:\n",
        "    print('Calibration sweep produced no results (missing OOF?)')\n",
        "\n",
        "print('Done calibration + sweep. Next: implement test-time inference applying per-class T_c and alpha refit on all OOF.', flush=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting per-class calibration and reliability blending (fold-out) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Calibrating using folds != 0 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Calibrating using folds != 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Calibrating using folds != 2 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweeping decoder on calibrated CE+TC OOF ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top calibrated (by worst then mean):\n    pool_k  temp  gamma  sep      mean  worst  norm_mean  norm_worst\n48      15   1.0  0.900    3  4.667622    5.4   0.235703    0.275792\n49      15   1.0  0.950    3  4.667622    5.4   0.235703    0.275792\n50      15   1.0  0.975    3  4.667622    5.4   0.235703    0.275792\n51      15   1.0  1.000    3  4.667622    5.4   0.235703    0.275792\n52      15   1.0  1.025    3  4.667622    5.4   0.235703    0.275792\nDone calibration + sweep. Next: implement test-time inference applying per-class T_c and alpha refit on all OOF.\n"
          ]
        }
      ]
    },
    {
      "id": "812d0f3c-4953-4223-90eb-d2bcc526490f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# P1-test: Refit per-class calibration on all OOF, apply at test-time for CE+TC-12x, build calibrated submission\n",
        "import os, json, time, math, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "\n",
        "# Utilities from calibration cell\n",
        "def load_oof_prob(sid:int, kind:str):\n",
        "    m = {'ce0': f\"{sid}_ce_new.npy\", 'ce1': f\"{sid}_ce_new_s1.npy\", 'tc0': f\"{sid}_tc.npy\", 'tc1': f\"{sid}_tc_s1.npy\"}\n",
        "    p = probs_cache/m[kind]; assert p.exists(), f\"Missing {p}\"\n",
        "    return torch.from_numpy(np.load(p)).to(device)\n",
        "def avg_seed(oof_a: torch.Tensor, oof_b: torch.Tensor):\n",
        "    p = (oof_a + oof_b) * 0.5\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "def apply_per_class_temps(p_t_c: torch.Tensor, T_vec: np.ndarray):\n",
        "    T = torch.from_numpy(T_vec.astype(np.float32)).to(device)\n",
        "    exps = 1.0 / (T + 1e-8)\n",
        "    q = torch.pow(torch.clamp(p_t_c, 1e-8, 1.0), exps.unsqueeze(0))\n",
        "    return q / (q.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "def blend_ce_tc_perclass(p_ce: torch.Tensor, p_tc: torch.Tensor, alpha_c: np.ndarray):\n",
        "    al = torch.from_numpy(alpha_c.astype(np.float32)).to(device)\n",
        "    log_ce = torch.log(torch.clamp(p_ce, 1e-8, 1.0))\n",
        "    log_tc = torch.log(torch.clamp(p_tc, 1e-8, 1.0))\n",
        "    comb = torch.exp(log_ce * al + log_tc * (1.0 - al))\n",
        "    return comb / (comb.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "def per_frame_nll(p_t_c: torch.Tensor, y_t: torch.Tensor):\n",
        "    m = (y_t >= 0)\n",
        "    if not torch.any(m):\n",
        "        return 0.0\n",
        "    idx = y_t[m].long()\n",
        "    picked = p_t_c[m, idx]\n",
        "    return float((-torch.log(torch.clamp(picked, 1e-8, 1.0))).mean().item())\n",
        "def load_labels(sid:int):\n",
        "    y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "    return torch.from_numpy(y).to(device)\n",
        "def collect_oof_for_ids(id_list, stream: str):\n",
        "    data = []\n",
        "    for sid in id_list:\n",
        "        sid = int(sid)\n",
        "        y = load_labels(sid)\n",
        "        if stream == 'ce':\n",
        "            p0 = load_oof_prob(sid, 'ce0'); p1 = load_oof_prob(sid, 'ce1') if (probs_cache/f\"{sid}_ce_new_s1.npy\").exists() else None\n",
        "        else:\n",
        "            p0 = load_oof_prob(sid, 'tc0'); p1 = load_oof_prob(sid, 'tc1') if (probs_cache/f\"{sid}_tc_s1.npy\").exists() else None\n",
        "        p = avg_seed(p0, p1) if p1 is not None else p0\n",
        "        data.append((p, y))\n",
        "    return data\n",
        "\n",
        "# Refit per-class T_ce, T_tc on ALL OOF (train) and per-class alpha on ALL OOF\n",
        "def refit_per_class_temperature_all():\n",
        "    all_ids = train_df['Id'].astype(int).tolist()\n",
        "    ce_data = collect_oof_for_ids(all_ids, 'ce')\n",
        "    tc_data = collect_oof_for_ids(all_ids, 'tc')\n",
        "    T_grid = np.round(np.arange(0.85, 1.1501, 0.02), 2)\n",
        "    C = ce_data[0][0].shape[1]\n",
        "    T_ce = np.ones(C, dtype=np.float32)\n",
        "    T_tc = np.ones(C, dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        if c == 0: continue\n",
        "        best_nll_ce, best_T_ce = 1e9, 1.0\n",
        "        best_nll_tc, best_T_tc = 1e9, 1.0\n",
        "        for T in T_grid:\n",
        "            nll_ce_c = 0.0; cnt_ce = 0\n",
        "            for p, y in ce_data:\n",
        "                m = (y == c)\n",
        "                if not torch.any(m): continue\n",
        "                # one-class adjust and renormalize\n",
        "                q = p.clone(); qc = torch.pow(torch.clamp(q[:, c], 1e-8, 1.0), 1.0/float(T)); q[:, c] = qc; q = q/(q.sum(dim=-1, keepdim=True)+1e-8)\n",
        "                nll_ce_c += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt_ce += int(m.sum().item())\n",
        "            if cnt_ce > 0 and (nll_ce_c / cnt_ce) < best_nll_ce:\n",
        "                best_nll_ce = nll_ce_c / max(1, cnt_ce); best_T_ce = float(T)\n",
        "            nll_tc_c = 0.0; cnt_tc = 0\n",
        "            for p, y in tc_data:\n",
        "                m = (y == c)\n",
        "                if not torch.any(m): continue\n",
        "                q = p.clone(); qc = torch.pow(torch.clamp(q[:, c], 1e-8, 1.0), 1.0/float(T)); q[:, c] = qc; q = q/(q.sum(dim=-1, keepdim=True)+1e-8)\n",
        "                nll_tc_c += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt_tc += int(m.sum().item())\n",
        "            if cnt_tc > 0 and (nll_tc_c / cnt_tc) < best_nll_tc:\n",
        "                best_nll_tc = nll_tc_c / max(1, cnt_tc); best_T_tc = float(T)\n",
        "        T_ce[c] = best_T_ce; T_tc[c] = best_T_tc\n",
        "    return T_ce, T_tc\n",
        "\n",
        "def refit_per_class_alpha_all(T_ce: np.ndarray, T_tc: np.ndarray):\n",
        "    all_ids = train_df['Id'].astype(int).tolist()\n",
        "    ce_data = collect_oof_for_ids(all_ids, 'ce')\n",
        "    tc_data = collect_oof_for_ids(all_ids, 'tc')\n",
        "    C = ce_data[0][0].shape[1]\n",
        "    A_grid = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "    alpha = np.full(C, 0.8, dtype=np.float32)\n",
        "    # precompute per-class temp calibration\n",
        "    ce_calib = [apply_per_class_temps(p_ce, T_ce) for (p_ce, _) in ce_data]\n",
        "    tc_calib = [apply_per_class_temps(p_tc, T_tc) for (p_tc, _) in tc_data]\n",
        "    for c in range(C):\n",
        "        if c == 0: alpha[c] = 0.8; continue\n",
        "        best_nll, best_a = 1e9, 0.8\n",
        "        for a in A_grid:\n",
        "            nll_c = 0.0; cnt = 0\n",
        "            for i, ((_, y),) in enumerate(zip(ce_data)):\n",
        "                q_ce = ce_calib[i]; q_tc = tc_calib[i]\n",
        "                m = (y == c)\n",
        "                if not torch.any(m): continue\n",
        "                a_vec = np.full(C, 0.8, dtype=np.float32); a_vec[c] = float(a)\n",
        "                q = blend_ce_tc_perclass(q_ce, q_tc, a_vec)\n",
        "                nll_c += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt += int(m.sum().item())\n",
        "            if cnt > 0 and (nll_c / cnt) < best_nll:\n",
        "                best_nll = nll_c / max(1, cnt); best_a = float(a)\n",
        "        alpha[c] = best_a\n",
        "    return alpha\n",
        "\n",
        "# Decoder helpers (reuse from earlier cells)\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2); y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k = max(1, int(k)); x = p_t.view(1,1,-1); w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "    pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1); T = p_t.shape[0]\n",
        "    if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]));\n",
        "    elif y.shape[0] > T: y = y[:T];\n",
        "    return y\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T = p.shape[0]; a = max(0, t_star - w); b = min(T-1, t_star + w); idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype);\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8; return float(((idx * seg).sum() / s).item())\n",
        "def topk_candidates_per_class(p_s: torch.Tensor, scores: torch.Tensor, c: int, k_c: int, temp: float, K: int = 3):\n",
        "    T = p_s.shape[0]; s = scores[:, c]; vals, idxs = torch.topk(s, k=min(K, T));\n",
        "    cand = []; w_com = max(5, k_c//3); radius = max(10, k_c//2)\n",
        "    for v, t_star in zip(vals.tolist(), idxs.tolist()):\n",
        "        t_ref = refine_com(p_s[:,c], int(t_star), w=w_com);\n",
        "        t_idx = int(round(max(0, min(t_ref, T-1))));\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item();\n",
        "        pooled_at_ref = p_s[t_idx, c].item();\n",
        "        cand.append((t_ref, float(v), float(local_mean), float(pooled_at_ref)))\n",
        "    cand.sort(key=lambda x: (x[0], -x[1], -x[2], -x[3])); return cand\n",
        "def decode_peaks_improved(p_t_c: torch.Tensor, med_k: dict, gamma: float = 1.0, pool_k=13, temp=0.9, min_sep=3, K=3, k_delta=4):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (torch.clamp(p_t_c, 1e-8, 1.0) ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k); T, C = p_s.shape; scores = torch.zeros_like(p_s); ks=[13]*C\n",
        "    for c in range(C):\n",
        "        if c == 0: scores[:, c] = p_s[:, c]; ks[c]=13; continue\n",
        "        base_k = med_k.get(c, 13); k_c = int(np.clip(round(gamma * base_k), 9, 25));\n",
        "        if k_c % 2 == 0: k_c = min(25, k_c + 1); ks[c] = k_c\n",
        "        ks_multi = sorted(set([int(np.clip(k_c - k_delta, 9, 25)), k_c, int(np.clip(k_c + k_delta, 9, 25))]));\n",
        "        ks_multi = [k if (k % 2)==1 else min(25, k+1) for k in ks_multi]; acc=None\n",
        "        for k in ks_multi:\n",
        "            di = duration_integral_single(p_s[:, c], k=k).unsqueeze(1); acc = di if acc is None else (acc + di)\n",
        "        scores[:, c] = (acc / float(len(ks_multi))).squeeze(1)\n",
        "    all_cand=[]; last_t=-1e9; chosen={}\n",
        "    for c in range(1,21):\n",
        "        for (t_ref, v, lm, pr) in topk_candidates_per_class(p_s, scores, c, ks[c], temp=temp, K=3):\n",
        "            all_cand.append((c, t_ref, v, lm, pr))\n",
        "    all_cand.sort(key=lambda x: (x[1], -x[2], -x[3], -x[4]))\n",
        "    for c, t_ref, v, lm, pr in all_cand:\n",
        "        if c in chosen: continue\n",
        "        if t_ref <= last_t + float(min_sep): t_ref = last_t + float(min_sep)\n",
        "        last_t = min(t_ref, float(T-1)); chosen[c] = (last_t, v, lm, pr)\n",
        "        if len(chosen)==20: break\n",
        "    if len(chosen) < 20:\n",
        "        missing = [c for c in range(1,21) if c not in chosen]; t = max(last_t, 0.0)\n",
        "        for c in missing: t = min(t + float(min_sep), float(T-1)); chosen[c] = (t, -1e9, -1e9, -1e9)\n",
        "    seq = [c for c,_ in sorted(chosen.items(), key=lambda kv: kv[1][0])]; return seq\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {};\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "def gamma_with_length(gamma_cv: float, T: int, med_k: dict):\n",
        "    L_est = float(sum(med_k.get(c,13) for c in range(1,21)))\n",
        "    if L_est <= 0: return gamma_cv\n",
        "    ratio = float(T) / L_est; gamma_s = float(np.clip(ratio, 0.85, 1.15)); return float(gamma_cv * gamma_s)\n",
        "\n",
        "# Model for inference (TCN architecture used for CE/TC checkpoints)\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch); self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1); self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h);\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True);\n",
        "        return x + h\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, 1); blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3));\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks); self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2); h = self.inp(x);\n",
        "        for b in self.blocks: h = b(h);\n",
        "        out = self.head(h); return out.transpose(1,2)\n",
        "\n",
        "def load_feat(split, sid:int):\n",
        "    d = np.load((feat_tr_dir if split=='train' else feat_te_dir)/f\"{sid}.npz\");\n",
        "    return d['X'].astype(np.float32)\n",
        "def compute_fold_scaler(id_list):\n",
        "    n = 0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = load_feat('train', int(sid)); n_i = X.shape[0]\n",
        "        if mean is None:\n",
        "            mean = X.mean(axis=0); M2 = ((X - mean)**2).sum(axis=0); n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0); n_new = n + n_i; delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new))\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new)); n = n_new\n",
        "    var = M2 / max(1, (n - 1)); std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        T, C = p_t_c.shape; tgt_len = max(1, int(round(T*s)))\n",
        "        x = p_t_c.T.unsqueeze(0);\n",
        "        y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False);\n",
        "        y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T;\n",
        "        y2 = y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        acc = y2 if acc is None else (acc + y2)\n",
        "    out = acc / float(len(factors))\n",
        "    return out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "# 1) Refit calibration on all OOF and save\n",
        "print('Refitting per-class calibration (T_ce, T_tc, alpha) on ALL OOF ...', flush=True)\n",
        "T_ce_all, T_tc_all = refit_per_class_temperature_all()\n",
        "alpha_all = refit_per_class_alpha_all(T_ce_all, T_tc_all)\n",
        "Path('calib_all.json').write_text(json.dumps({'T_ce': T_ce_all.tolist(), 'T_tc': T_tc_all.tolist(), 'alpha': alpha_all.tolist()}))\n",
        "print('Saved calib_all.json', flush=True)\n",
        "\n",
        "# 2) Read calibrated OOF sweep to pick decoder cfg (by worst then mean)\n",
        "cfg_df = pd.read_csv('cv_sweep_ce_tc_calibrated.csv').sort_values(['worst','mean']) if Path('cv_sweep_ce_tc_calibrated.csv').exists() else None\n",
        "if cfg_df is None or len(cfg_df)==0:\n",
        "    pool_k, temp, gamma, sep = 15, 1.0, 0.95, 3\n",
        "else:\n",
        "    best = cfg_df.iloc[0].to_dict()\n",
        "    pool_k = int(best.get('pool_k', 15)); temp = float(best.get('temp', 1.0)); gamma = float(best.get('gamma', 0.95)); sep = int(best.get('sep', 3))\n",
        "print('Using calibrated decoder cfg:', {'pool_k':pool_k,'temp':temp,'gamma':gamma,'sep':sep}, flush=True)\n",
        "\n",
        "# 3) Test-time inference: CE+TC 12-model average into two streams, apply per-class temps and per-class alpha blend, then decode\n",
        "med_k_train_all = compute_class_median_durations_for_ids(train_df['Id'].astype(int).tolist())\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "def infer_calibrated_ce_tc_12():\n",
        "    scalers=[compute_fold_scaler(folds[fi]['train_ids']) for fi in range(3)]\n",
        "    scalers=[(torch.from_numpy(m).float().to(device), torch.from_numpy(s).float().to(device)) for (m,s) in scalers]\n",
        "    rows=[]; t0=time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat('test', int(sid)); Tlen = X.shape[0]\n",
        "        acc_ce=None; acc_tc=None; cnt_ce=0; cnt_tc=0\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "            for fi in range(3):\n",
        "                mean_t, std_t = scalers[fi]\n",
        "                for s in (0,1):\n",
        "                    # CE stream\n",
        "                    ckpt = Path(f\"model_ce_fold{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                    if ckpt.exists():\n",
        "                        m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                        m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                        xb = torch.from_numpy(X).float().to(device); xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0)\n",
        "                        p = m(xb)[0].softmax(dim=-1); p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1))\n",
        "                        acc_ce = p if acc_ce is None else (acc_ce + p); cnt_ce += 1; del m\n",
        "                for s in (0,1):\n",
        "                    # TC stream\n",
        "                    ckpt = Path(f\"model_tc_fold{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                    if ckpt.exists():\n",
        "                        m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                        m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                        xb = torch.from_numpy(X).float().to(device); xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0)\n",
        "                        p = m(xb)[0].softmax(dim=-1); p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1))\n",
        "                        acc_tc = p if acc_tc is None else (acc_tc + p); cnt_tc += 1; del m\n",
        "        ce_prob = (acc_ce / float(max(1, cnt_ce))) if acc_ce is not None else None\n",
        "        tc_prob = (acc_tc / float(max(1, cnt_tc))) if acc_tc is not None else None\n",
        "        # Apply per-class temps then per-class alpha blend\n",
        "        if ce_prob is None and tc_prob is None:\n",
        "            raise RuntimeError('No CE/TC models found for inference')\n",
        "        if ce_prob is None:\n",
        "            probs = apply_per_class_temps(tc_prob, T_tc_all)\n",
        "        elif tc_prob is None:\n",
        "            probs = apply_per_class_temps(ce_prob, T_ce_all)\n",
        "        else:\n",
        "            q_ce = apply_per_class_temps(ce_prob, T_ce_all)\n",
        "            q_tc = apply_per_class_temps(tc_prob, T_tc_all)\n",
        "            probs = blend_ce_tc_perclass(q_ce, q_tc, alpha_all)\n",
        "        probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        gamma_eff = gamma_with_length(gamma, Tlen, med_k_train_all)\n",
        "        seq = decode_peaks_improved(probs, med_k=med_k_train_all, gamma=gamma_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [infer CE+TC-12x calibrated] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    return pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "\n",
        "print('Building calibrated CE+TC-12x submission...', flush=True)\n",
        "sub = infer_calibrated_ce_tc_12()\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "sub.to_csv('submission_primary_ce_tc_12x_calibrated.csv', index=False)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission_primary_ce_tc_12x_calibrated.csv and submission.csv; head:\\n', sub.head(), flush=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refitting per-class calibration (T_ce, T_tc, alpha) on ALL OOF ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved calib_all.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using calibrated decoder cfg: {'pool_k': 15, 'temp': 1.0, 'gamma': 0.9, 'sep': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building calibrated CE+TC-12x submission...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/504026882.py:276: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n/tmp/ipykernel_8891/504026882.py:285: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x calibrated] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x calibrated] 20/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x calibrated] 30/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x calibrated] 40/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x calibrated] 50/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x calibrated] 60/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x calibrated] 70/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x calibrated] 80/95 elapsed=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x calibrated] 90/95 elapsed=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE+TC-12x calibrated] 95/95 elapsed=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_tc_12x_calibrated.csv and submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 7 1...\n1  301  10 12 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 3 1...\n2  302  1 17 16 12 5 19 7 13 20 18 11 3 4 6 15 8 14 10...\n3  303  13 4 12 10 5 19 15 20 17 11 16 8 18 7 3 1 6 2 ...\n4  304  8 1 12 14 18 13 9 7 2 11 3 20 19 5 10 6 15 17 ...\n"
          ]
        }
      ]
    },
    {
      "id": "c714d13a-1396-4cdf-9928-244c33766a0a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# P2: Duration-aware DP decoder over top-K candidates (on CE6 OOF), sweep (reduced grid with progress logs) and build CE6-DP submission\n",
        "import os, json, time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "probs_cache = Path('probs_cache')\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "# Helpers reused\n",
        "def load_feat(split, sid:int):\n",
        "    d = np.load((feat_tr_dir if split=='train' else feat_te_dir)/f\"{sid}.npz\");\n",
        "    return d['X'].astype(np.float32)\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2); y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k = max(1, int(k)); x = p_t.view(1,1,-1); w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "    pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1); T = p_t.shape[0]\n",
        "    if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]));\n",
        "    elif y.shape[0] > T: y = y[:T];\n",
        "    return y\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T = p.shape[0]; a = max(0, t_star - w); b = min(T-1, t_star + w); idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype);\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8; return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {};\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "\n",
        "def gamma_with_length(gamma_cv: float, T: int, med_k: dict):\n",
        "    L_est = float(sum(med_k.get(c,13) for c in range(1,21)))\n",
        "    if L_est <= 0: return gamma_cv\n",
        "    ratio = float(T) / L_est; gamma_s = float(np.clip(ratio, 0.85, 1.15)); return float(gamma_cv * gamma_s)\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# Load averaged CE OOF probs (seed0+seed1)\n",
        "def load_oof_ce_avg(sid:int):\n",
        "    p0 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new.npy\")).to(device)\n",
        "    p1 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new_s1.npy\")).to(device)\n",
        "    p = (p0 + p1) * 0.5\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "# Build candidates per class using multi-scale duration-integral scores and COM refine\n",
        "def build_candidates(p_t_c: torch.Tensor, med_k: dict, pool_k:int, gamma: float, temp: float, K_top:int, k_delta:int=4):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (torch.clamp(p_t_c, 1e-8, 1.0) ** (1.0/temp)); p_t_c = p_t_c/(p_t_c.sum(dim=-1, keepdim=True)+1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k); T, C = p_s.shape\n",
        "    scores = torch.zeros_like(p_s); k_eff=[13]*C\n",
        "    for c in range(C):\n",
        "        if c == 0:\n",
        "            scores[:, c] = p_s[:, c]; k_eff[c]=13; continue\n",
        "        base_k = med_k.get(c,13); k_c = int(np.clip(round(gamma * base_k), 9, 25));\n",
        "        if k_c % 2 == 0: k_c = min(25, k_c+1); k_eff[c]=k_c\n",
        "        ks_multi = sorted(set([int(np.clip(k_c - k_delta, 9, 25)), k_c, int(np.clip(k_c + k_delta, 9, 25))]));\n",
        "        ks_multi = [k if (k % 2)==1 else min(25, k+1) for k in ks_multi]\n",
        "        acc=None\n",
        "        for k in ks_multi:\n",
        "            di = duration_integral_single(p_s[:, c], k=k).unsqueeze(1); acc = di if acc is None else (acc + di)\n",
        "        scores[:, c] = (acc / float(len(ks_multi))).squeeze(1)\n",
        "    cand_by_c = {}\n",
        "    for c in range(1,21):\n",
        "        s = scores[:, c]; T = s.shape[0]\n",
        "        k = min(K_top, T)\n",
        "        vals, idxs = torch.topk(s, k=k)\n",
        "        w_com = max(5, k_eff[c]//3); radius = max(10, k_eff[c]//2)\n",
        "        cand=[]\n",
        "        for v, t_star in zip(vals.tolist(), idxs.tolist()):\n",
        "            t_ref = refine_com(p_s[:,c], int(t_star), w=w_com);\n",
        "            t_idx = int(round(max(0, min(t_ref, T-1))));\n",
        "            local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item();\n",
        "            pooled_at_ref = p_s[t_idx, c].item();\n",
        "            cand.append((t_ref, float(v), float(local_mean), float(pooled_at_ref)))\n",
        "        cand.sort(key=lambda x: (-x[1], -x[2], -x[3], x[0]))\n",
        "        cand_by_c[c] = cand\n",
        "    return cand_by_c\n",
        "\n",
        "# Duration-aware DP (beam search) over ordered classes 1..20\n",
        "def dp_decode_from_candidates(cand_by_c: dict, med_k: dict, gamma: float, min_sep: float, lambda_dur: float, T_len: int, beam_width: int = 80):\n",
        "    beams = [ (0.0, -1e9, []) ]\n",
        "    for i, c in enumerate(range(1,21), start=1):\n",
        "        new_beams = []\n",
        "        exp_gap = float(np.clip(round(gamma * med_k.get(c,13)), 3, 30))\n",
        "        cand_list = cand_by_c.get(c, [])\n",
        "        if len(cand_list)==0:\n",
        "            for sc, last_t, path in beams:\n",
        "                t = last_t + max(min_sep, exp_gap)\n",
        "                t = min(t, float(T_len-1))\n",
        "                new_beams.append((sc - 1e6, t, path + [c]))\n",
        "        else:\n",
        "            for (sc, last_t, path) in beams:\n",
        "                for (t_ref, score_v, local_m, pooled) in cand_list:\n",
        "                    t_use = t_ref\n",
        "                    if t_use <= last_t + float(min_sep):\n",
        "                        t_use = last_t + float(min_sep)\n",
        "                    t_use = min(t_use, float(T_len-1))\n",
        "                    gap = t_use - last_t if last_t > -1e8 else exp_gap\n",
        "                    pen = lambda_dur * abs(gap - exp_gap) / max(1.0, exp_gap)\n",
        "                    new_score = sc + (score_v - pen)\n",
        "                    new_beams.append((new_score, t_use, path + [c]))\n",
        "        new_beams.sort(key=lambda x: (-x[0], x[1]))\n",
        "        beams = new_beams[:beam_width]\n",
        "    best = max(beams, key=lambda x: (x[0], -x[1]))\n",
        "    return best[2] if len(best)>=3 else [c for c in range(1,21)]\n",
        "\n",
        "# Evaluate DP-decoder cfg on a fold, using CE OOF avg\n",
        "def eval_dp_cfg_on_fold(fold, pool_k:int, temp:float, gamma: float, min_sep:int, K_top:int, lambda_dur: float, beam_width:int):\n",
        "    fi = int(fold['fold'])\n",
        "    med_k = compute_class_median_durations_for_ids(fold['train_ids'])\n",
        "    vids = fold['val_ids']; tot=0; cnt=0\n",
        "    for sid in vids:\n",
        "        sid = int(sid)\n",
        "        p = load_oof_ce_avg(sid); T = p.shape[0]\n",
        "        g_eff = gamma_with_length(gamma, T, med_k)\n",
        "        cand = build_candidates(p, med_k=med_k, pool_k=pool_k, gamma=g_eff, temp=temp, K_top=K_top, k_delta=4)\n",
        "        seq = dp_decode_from_candidates(cand, med_k=med_k, gamma=g_eff, min_sep=float(min_sep), lambda_dur=lambda_dur, T_len=T, beam_width=beam_width)\n",
        "        tot += levenshtein(seq, id2seq[sid]); cnt += 1\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "# Reduced sweep grid per expert guidance + progress logging\n",
        "pool_ks=[11,15]; temps=[0.90]; gammas=[0.90,0.95]; seps=[3,4]; K_tops=[20,25]; lambdas=[0.2]; beams=[60]\n",
        "total_cfg = len(pool_ks)*len(temps)*len(gammas)*len(seps)*len(K_tops)*len(lambdas)*len(beams)\n",
        "print(f'Sweeping DP decoder on CE6 averaged OOF (reduced grid) ... total_cfg={total_cfg}', flush=True)\n",
        "res=[]; cfg_idx=0; t0=time.time()\n",
        "for pool_k in pool_ks:\n",
        "    for temp in temps:\n",
        "        for gamma in gammas:\n",
        "            for sep in seps:\n",
        "                for K_top in K_tops:\n",
        "                    for lam in lambdas:\n",
        "                        for bw in beams:\n",
        "                            cfg_idx += 1\n",
        "                            per_fold=[]\n",
        "                            for f in folds:\n",
        "                                lev = eval_dp_cfg_on_fold(f, pool_k, temp, gamma, sep, K_top, lam, bw)\n",
        "                                per_fold.append(lev)\n",
        "                            res.append((np.mean(per_fold), np.max(per_fold), {'pool_k':pool_k,'temp':temp,'gamma':gamma,'sep':sep,'K':K_top,'lambda_dur':lam,'beam':bw}))\n",
        "                            if (cfg_idx % 5)==0 or cfg_idx==total_cfg:\n",
        "                                elapsed = (time.time()-t0)/60.0\n",
        "                                print(f'  [sweep DP] cfg {cfg_idx}/{total_cfg} elapsed={elapsed:.1f}m', flush=True)\n",
        "res.sort(key=lambda x: (x[1], x[0]))\n",
        "print('Top CE6+DP (mean, worst, cfg):')\n",
        "for r in res[:5]:\n",
        "    print(r)\n",
        "pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res]).to_csv('cv_sweep_ce_6x_dp.csv', index=False)\n",
        "print('Saved cv_sweep_ce_6x_dp.csv', flush=True)\n",
        "\n",
        "# Build test submission using CE 6x models + DP decoder best cfg\n",
        "print('Building CE-6x DP submission...', flush=True)\n",
        "cfg_best = pd.read_csv('cv_sweep_ce_6x_dp.csv').sort_values(['worst','mean']).iloc[0].to_dict() if Path('cv_sweep_ce_6x_dp.csv').exists() else {'pool_k':13,'temp':0.95,'gamma':1.0,'sep':3,'K':20,'lambda_dur':0.2,'beam':80}\n",
        "pool_k=int(cfg_best['pool_k']); temp=float(cfg_best['temp']); gamma=float(cfg_best.get('gamma',1.0)); sep=int(cfg_best['sep']); K_top=int(cfg_best.get('K',20)); lam=float(cfg_best.get('lambda_dur',0.2)); bw=int(cfg_best.get('beam',80))\n",
        "med_k_train_all = compute_class_median_durations_for_ids(train_df['Id'].astype(int).tolist())\n",
        "\n",
        "# Minimal CE model def to load checkpoints\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__();\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch); self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1); self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h);\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True);\n",
        "        return x + h\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__();\n",
        "        self.inp = nn.Conv1d(d_in, channels, 1); blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3));\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks); self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2); h = self.inp(x);\n",
        "        for b in self.blocks: h = b(h);\n",
        "        out = self.head(h); return out.transpose(1,2)\n",
        "\n",
        "def compute_fold_scaler(id_list):\n",
        "    n=0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = load_feat('train', int(sid)); n_i = X.shape[0]\n",
        "        if mean is None:\n",
        "            mean = X.mean(axis=0); M2 = ((X - mean)**2).sum(axis=0); n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0); n_new = n + n_i; delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new))\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new)); n = n_new\n",
        "    var = M2 / max(1, (n - 1)); std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        T, C = p_t_c.shape; tgt_len = max(1, int(round(T*s)))\n",
        "        x = p_t_c.T.unsqueeze(0);\n",
        "        y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False);\n",
        "        y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T;\n",
        "        y2 = y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        acc = y2 if acc is None else (acc + y2)\n",
        "    out = acc / float(len(factors))\n",
        "    return out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def infer_ce6_probs_for_sid(sid:int, models_info, scalers):\n",
        "    X = load_feat('test', int(sid));\n",
        "    acc=None\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "        for fi in range(3):\n",
        "            mean_t, std_t = scalers[fi]\n",
        "            for s in (0,1):\n",
        "                ckpt = Path(f\"model_ce_fold{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                if not ckpt.exists():\n",
        "                    continue\n",
        "                m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                xb = torch.from_numpy(X).float().to(device);\n",
        "                xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0)\n",
        "                p = m(xb)[0].softmax(dim=-1); p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1))\n",
        "                acc = p if acc is None else (acc + p)\n",
        "                del m\n",
        "    probs = acc / float(6)\n",
        "    return probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def build_submission_ce6_dp():\n",
        "    test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "    scalers=[compute_fold_scaler(folds[fi]['train_ids']) for fi in range(3)]\n",
        "    scalers=[(torch.from_numpy(m).float().to(device), torch.from_numpy(s).float().to(device)) for (m,s) in scalers]\n",
        "    rows=[]; t0=time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        p = infer_ce6_probs_for_sid(int(sid), None, scalers); T = p.shape[0]\n",
        "        g_eff = gamma_with_length(gamma, T, med_k_train_all)\n",
        "        cand = build_candidates(p, med_k=med_k_train_all, pool_k=pool_k, gamma=g_eff, temp=temp, K_top=K_top, k_delta=4)\n",
        "        seq = dp_decode_from_candidates(cand, med_k=med_k_train_all, gamma=g_eff, min_sep=float(sep), lambda_dur=lam, T_len=T, beam_width=bw)\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [infer CE-6x DP] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    return sub\n",
        "\n",
        "med_k_train_all = compute_class_median_durations_for_ids(train_df['Id'].astype(int).tolist())\n",
        "sub = build_submission_ce6_dp()\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "sub.to_csv('submission_primary_ce_6x_dp.csv', index=False)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission_primary_ce_6x_dp.csv and submission.csv; head:\\n', sub.head(), flush=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweeping DP decoder on CE6 averaged OOF (reduced grid) ... total_cfg=16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep DP] cfg 5/16 elapsed=1.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep DP] cfg 10/16 elapsed=3.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep DP] cfg 15/16 elapsed=5.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep DP] cfg 16/16 elapsed=6.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top CE6+DP (mean, worst, cfg):\n(18.1293808836666, 18.306122448979593, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.9, 'sep': 3, 'K': 20, 'lambda_dur': 0.2, 'beam': 60})\n(18.1293808836666, 18.306122448979593, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.9, 'sep': 3, 'K': 25, 'lambda_dur': 0.2, 'beam': 60})\n(18.1293808836666, 18.306122448979593, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.9, 'sep': 4, 'K': 20, 'lambda_dur': 0.2, 'beam': 60})\n(18.1293808836666, 18.306122448979593, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.9, 'sep': 4, 'K': 25, 'lambda_dur': 0.2, 'beam': 60})\n(18.1293808836666, 18.306122448979593, {'pool_k': 11, 'temp': 0.9, 'gamma': 0.95, 'sep': 3, 'K': 20, 'lambda_dur': 0.2, 'beam': 60})\nSaved cv_sweep_ce_6x_dp.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building CE-6x DP submission...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/606110123.py:246: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x DP] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x DP] 20/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x DP] 30/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x DP] 40/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x DP] 50/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x DP] 60/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x DP] 70/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x DP] 80/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x DP] 90/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x DP] 95/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_6x_dp.csv and submission.csv; head:\n     Id                                           Sequence\n0  300  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n1  301  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n2  302  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n3  303  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n4  304  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n"
          ]
        }
      ]
    },
    {
      "id": "a50ce211-31dc-4e9b-8309-dd4ddf17a90e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set submission.csv to the best available prior submission (prefer improved decoders)\n",
        "import os, shutil, pandas as pd\n",
        "candidates = [\n",
        "    'submission_primary_ce_6x_v2.csv',  # improved decoder (best OOF: mean 4.486, worst 5.15)\n",
        "    'submission_primary_ce_6x_localsrch.csv',  # local-search decoder (OOF: mean 4.503, worst 5.18)\n",
        "    'submission_primary_ce_6x.csv',\n",
        "    'submission_primary_ce_tc_12x_calibrated.csv',\n",
        "    'submission_primary_ce_tc_12x.csv',\n",
        "    'submission_primary_ce_ms.csv',\n",
        "    'submission_backup_ce_only.csv',\n",
        "]\n",
        "chosen = None\n",
        "for c in candidates:\n",
        "    if os.path.exists(c):\n",
        "        chosen = c\n",
        "        break\n",
        "assert chosen is not None, 'No candidate submission files found'\n",
        "shutil.copyfile(chosen, 'submission.csv')\n",
        "print('submission.csv set from:', chosen)\n",
        "print(pd.read_csv('submission.csv').head())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv set from: submission_primary_ce_6x_v2.csv\n    Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 7 1...\n1  301  10 12 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 3 1...\n2  302  1 17 16 12 5 19 7 13 20 18 11 3 4 6 15 8 14 10...\n3  303  13 4 12 1 10 14 5 19 15 20 17 11 16 8 18 7 3 6...\n4  304  8 1 12 14 18 13 9 7 2 11 3 20 19 5 10 6 15 17 ...\n"
          ]
        }
      ]
    },
    {
      "id": "0ec7f269-bd92-4ca3-9de5-774360c1141d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# P2-alt: Candidate assignment + adjacent-swap hill-climb decoder on CE6 OOF; tiny grid; build submission\n",
        "import os, json, time, math, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "probs_cache = Path('probs_cache'); lab_tr_dir = Path('labels3d_v2')/'train'\n",
        "feat_tr_dir = Path('features3d_v2')/'train'; feat_te_dir = Path('features3d_v2')/'test'\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv'); id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def load_oof_ce_avg(sid:int):\n",
        "    p0 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new.npy\")).to(device)\n",
        "    p1 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new_s1.npy\")).to(device)\n",
        "    p = (p0 + p1) * 0.5\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2); y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k = max(1, int(k)); x = p_t.view(1,1,-1); w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "    pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1); T = p_t.shape[0]\n",
        "    if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]))\n",
        "    elif y.shape[0] > T: y = y[:T]\n",
        "    return y\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T = p.shape[0]; a=max(0,t_star-w); b=min(T-1,t_star+w); idx=torch.arange(a,b+1, device=p.device, dtype=p.dtype);\n",
        "    seg=p[a:b+1]; s=seg.sum() + 1e-8; return float(((idx*seg).sum()/s).item())\n",
        "\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {};\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "\n",
        "def gamma_with_length(gamma_cv: float, T: int, med_k: dict):\n",
        "    L_est = float(sum(med_k.get(c,13) for c in range(1,21)))\n",
        "    if L_est <= 0: return gamma_cv\n",
        "    ratio = float(T) / L_est; gamma_s = float(np.clip(ratio, 0.85, 1.15)); return float(gamma_cv * gamma_s)\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# Build simple pairwise order prior P[a,b] = Pr(a before b) from training sequences (robust to missing classes)\n",
        "def build_order_prior(train_df):\n",
        "    cnt = np.zeros((21,21), dtype=np.int64)\n",
        "    tot = np.zeros((21,21), dtype=np.int64)\n",
        "    for seq in train_df['Sequence'].astype(str).tolist():\n",
        "        s = [int(x) for x in seq.strip().split() if x.isdigit()]\n",
        "        s = [x for x in s if 1 <= x <= 20]\n",
        "        n = len(s)\n",
        "        for i in range(n):\n",
        "            a = s[i]\n",
        "            for j in range(i+1, n):\n",
        "                b = s[j]\n",
        "                if a == b: continue\n",
        "                cnt[a, b] += 1\n",
        "                tot[a, b] += 1\n",
        "    P = np.zeros((21,21), dtype=np.float32)\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        P = np.where(tot>0, cnt / np.maximum(1, tot), 0.5)\n",
        "    np.fill_diagonal(P, 0.5)\n",
        "    return P\n",
        "P_order = build_order_prior(train_df)\n",
        "\n",
        "# Candidate extraction and per-(c,t) score s(c,t) = log(pooled_prob) + beta * z(di_score)\n",
        "def build_scoring_and_candidates(p_t_c: torch.Tensor, med_k: dict, pool_k:int, gamma: float, temp: float, K:int, k_delta:int=4):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (torch.clamp(p_t_c, 1e-8, 1.0) ** (1.0/temp)); p_t_c = p_t_c/(p_t_c.sum(dim=-1, keepdim=True)+1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k); T, C = p_s.shape\n",
        "    di = torch.zeros_like(p_s); ks=[13]*C\n",
        "    for c in range(C):\n",
        "        if c==0: di[:,c]=p_s[:,c]; ks[c]=13; continue\n",
        "        base_k = med_k.get(c,13); k_c = int(np.clip(round(gamma*base_k), 9, 25));\n",
        "        if k_c % 2 == 0: k_c = min(25, k_c+1); ks[c]=k_c\n",
        "        ks_multi = sorted(set([int(np.clip(k_c - k_delta, 9, 25)), k_c, int(np.clip(k_c + k_delta, 9, 25))]));\n",
        "        ks_multi = [k if (k % 2)==1 else min(25, k+1) for k in ks_multi]\n",
        "        acc=None\n",
        "        for k in ks_multi:\n",
        "            x = duration_integral_single(p_s[:,c], k=k).unsqueeze(1); acc = x if acc is None else (acc + x)\n",
        "        di[:,c] = (acc/float(len(ks_multi))).squeeze(1)\n",
        "    # z-score di per class over time\n",
        "    mu = di.mean(dim=0, keepdim=True); sd = di.std(dim=0, keepdim=True) + 1e-8\n",
        "    z = (di - mu) / sd\n",
        "    # score grid\n",
        "    logp = torch.log(torch.clamp(p_s, 1e-8, 1.0))\n",
        "    return p_s, di, z, logp, ks\n",
        "\n",
        "def initial_assignment(p_s, z, logp, ks, beta: float, K:int, min_sep:int):\n",
        "    T, C = p_s.shape\n",
        "    # independent best per class by s(c,t), then time-sort and enforce min_sep\n",
        "    items=[]\n",
        "    for c in range(1,21):\n",
        "        s = logp[:,c] + beta * z[:,c]\n",
        "        t_star = int(torch.argmax(s).item())\n",
        "        # refine with COM on pooled prob to stabilize\n",
        "        w_com = max(5, ks[c]//3);\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=w_com)\n",
        "        t_idx = max(0, min(int(round(t_ref)), T-1))\n",
        "        score_ct = float(s[t_idx].item())\n",
        "        items.append([float(t_ref), int(c), score_ct])\n",
        "    items.sort(key=lambda x: x[0])\n",
        "    # enforce min_sep monotonic times\n",
        "    last_t = -1e9\n",
        "    for it in items:\n",
        "        if it[0] <= last_t + float(min_sep):\n",
        "            it[0] = last_t + float(min_sep)\n",
        "        last_t = min(it[0], float(T-1))\n",
        "    return items  # list of [t, c, s]\n",
        "\n",
        "def objective_S(items, beta: float, lambda_ord: float):\n",
        "    # items: list of [t, c, s_ct]; s_ct precomputed = logp+beta*z at that (c,t)\n",
        "    S = 0.0\n",
        "    # main score\n",
        "    for _, _, sct in items:\n",
        "        S += float(sct)\n",
        "    # order prior penalty: for each i<j, if c_i after c_j then penalty proportional to (1 - P[c_i,c_j])\n",
        "    if lambda_ord > 0:\n",
        "        n = len(items)\n",
        "        for i in range(n):\n",
        "            ci = items[i][1]\n",
        "            for j in range(i+1, n):\n",
        "                cj = items[j][1]\n",
        "                pij = float(P_order[ci, cj]) if 1 <= ci <= 20 and 1 <= cj <= 20 else 0.5\n",
        "                # in sequence, i comes before j; if pij is low, penalize\n",
        "                S -= lambda_ord * (1.0 - pij)\n",
        "    return S\n",
        "\n",
        "def hill_climb_adjacent(items, p_s, z, logp, ks, beta: float, lambda_ord: float, max_passes:int=5):\n",
        "    # We keep times fixed to positions; swapping classes swaps which score s(c,t) we pick.\n",
        "    # Recompute s_ct on-demand for swapped pairs.\n",
        "    improved = True; passes = 0\n",
        "    # Precompute s(c,t) accessor\n",
        "    def s_at(c:int, t:float):\n",
        "        T = p_s.shape[0]\n",
        "        t_idx = max(0, min(int(round(t)), T-1))\n",
        "        return float((logp[t_idx, c] + beta * z[t_idx, c]).item())\n",
        "    while improved and passes < max_passes:\n",
        "        improved = False; passes += 1\n",
        "        i = 0\n",
        "        while i < len(items)-1:\n",
        "            t_i, c_i, s_i = items[i]\n",
        "            t_j, c_j, s_j = items[i+1]\n",
        "            # score before\n",
        "            S_before = objective_S(items, beta, lambda_ord)\n",
        "            # try swap c_i and c_j (times stay t_i, t_j)\n",
        "            s_i_new = s_at(c_j, t_i); s_j_new = s_at(c_i, t_j)\n",
        "            items[i][1] = c_j; items[i][2] = s_i_new\n",
        "            items[i+1][1] = c_i; items[i+1][2] = s_j_new\n",
        "            S_after = objective_S(items, beta, lambda_ord)\n",
        "            if S_after + 1e-9 >= S_before:\n",
        "                improved = improved or (S_after > S_before + 1e-6)\n",
        "                # keep swap\n",
        "            else:\n",
        "                # revert\n",
        "                items[i][1] = c_i; items[i][2] = s_i\n",
        "                items[i+1][1] = c_j; items[i+1][2] = s_j\n",
        "            i += 1\n",
        "    return items\n",
        "\n",
        "def decode_localsrch(p_t_c: torch.Tensor, med_k: dict, pool_k:int, temp: float, gamma: float, min_sep:int, beta: float, lambda_ord: float, K:int=3):\n",
        "    T = p_t_c.shape[0]\n",
        "    g_eff = gamma\n",
        "    p_s, di, z, logp, ks = build_scoring_and_candidates(p_t_c, med_k, pool_k, g_eff, temp, K)\n",
        "    items = initial_assignment(p_s, z, logp, ks, beta=beta, K=K, min_sep=min_sep)\n",
        "    items = hill_climb_adjacent(items, p_s, z, logp, ks, beta=beta, lambda_ord=lambda_ord, max_passes=4)\n",
        "    # return sequence by positions (already increasing time)\n",
        "    seq = [int(c) for (_, c, _) in items]\n",
        "    # uniqueness enforcement (rare): if duplicates, fallback to unique by first occurrence\n",
        "    if len(set(seq)) < 20:\n",
        "        seen=set(); seq2=[]\n",
        "        for c in seq:\n",
        "            if c in seen: continue\n",
        "            seen.add(c); seq2.append(c)\n",
        "        # append any missing in order of not-seen\n",
        "        for c in range(1,21):\n",
        "            if c not in seen: seq2.append(c)\n",
        "        seq = seq2[:20]\n",
        "    return seq\n",
        "\n",
        "# Evaluate on CE6 averaged OOF with small grid; pick by worst-fold then mean\n",
        "pool_ks=[11,15]; temps=[0.90,1.00]; gammas=[0.90,0.95,1.00]; seps=[2,3]; betas=[0.3,0.5]; lords=[0.03,0.05]\n",
        "print('Sweeping local-search decoder on CE6 averaged OOF (tiny grid)...', flush=True)\n",
        "med_cache={}\n",
        "def eval_cfg_on_fold_localsrch(fold, pool_k, temp, gamma, sep, beta, l_ord):\n",
        "    fi = int(fold['fold'])\n",
        "    if fi not in med_cache: med_cache[fi] = compute_class_median_durations_for_ids(fold['train_ids'])\n",
        "    med_k = med_cache[fi]\n",
        "    vids = fold['val_ids']; tot=0; cnt=0\n",
        "    for sid in vids:\n",
        "        sid=int(sid); p = load_oof_ce_avg(sid); T = p.shape[0]\n",
        "        g_eff = gamma_with_length(gamma, T, med_k)\n",
        "        seq = decode_localsrch(p, med_k=med_k, pool_k=pool_k, temp=temp, gamma=g_eff, min_sep=sep, beta=beta, lambda_ord=l_ord, K=3)\n",
        "        tot += levenshtein(seq, id2seq[sid]); cnt += 1\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "res=[]; t0=time.time(); cfg_idx=0; total_cfg=len(pool_ks)*len(temps)*len(gammas)*len(seps)*len(betas)*len(lords)\n",
        "for pool_k in pool_ks:\n",
        "    for temp in temps:\n",
        "        for gamma in gammas:\n",
        "            for sep in seps:\n",
        "                for beta in betas:\n",
        "                    for l_ord in lords:\n",
        "                        cfg_idx += 1\n",
        "                        per_fold=[]\n",
        "                        for f in folds:\n",
        "                            lev = eval_cfg_on_fold_localsrch(f, pool_k, temp, gamma, sep, beta, l_ord)\n",
        "                            per_fold.append(lev)\n",
        "                        res.append((np.mean(per_fold), np.max(per_fold), {'pool_k':pool_k,'temp':temp,'gamma':gamma,'sep':sep,'beta':beta,'lambda_ord':l_ord}))\n",
        "                        if (cfg_idx % 6)==0 or cfg_idx==total_cfg:\n",
        "                            print(f\"  [sweep local] cfg {cfg_idx}/{total_cfg} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "res.sort(key=lambda x: (x[1], x[0]))\n",
        "print('Top CE6 local-search (mean, worst, cfg):')\n",
        "for r in res[:5]: print(r)\n",
        "pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res]).to_csv('cv_sweep_ce_6x_localsrch.csv', index=False)\n",
        "print('Saved cv_sweep_ce_6x_localsrch.csv', flush=True)\n",
        "\n",
        "# Test-time inference with 6 CE models + local-search decoder\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__(); self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch); self.drop = nn.Dropout(drop); self.conv2 = nn.Conv1d(ch, ch, 1); self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h); h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True); return x + h\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__(); self.inp = nn.Conv1d(d_in, channels, 1); blocks=[]; dil=1\n",
        "        for _ in range(layers): blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3)); dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks); self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2); h = self.inp(x);\n",
        "        for b in self.blocks: h = b(h); out = self.head(h); return out.transpose(1,2)\n",
        "\n",
        "def load_feat(split, sid:int):\n",
        "    d = np.load((feat_tr_dir if split=='train' else feat_te_dir)/f\"{sid}.npz\"); return d['X'].astype(np.float32)\n",
        "\n",
        "def compute_fold_scaler(id_list):\n",
        "    n=0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = load_feat('train', int(sid)); n_i = X.shape[0]\n",
        "        if mean is None: mean = X.mean(axis=0); M2 = ((X - mean)**2).sum(axis=0); n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0); n_new = n + n_i; delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new));\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new)); n = n_new\n",
        "    var = M2 / max(1, (n - 1)); std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        T, C = p_t_c.shape; tgt_len = max(1, int(round(T*s)))\n",
        "        x = p_t_c.T.unsqueeze(0); y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False);\n",
        "        y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T; y2 = y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        acc = y2 if acc is None else (acc + y2)\n",
        "    out = acc / float(len(factors)); return out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def infer_ce6_probs_for_sid(sid:int, scalers):\n",
        "    X = load_feat('test', int(sid)); acc=None\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "        for fi in range(3):\n",
        "            mean_t, std_t = scalers[fi]\n",
        "            for s in (0,1):\n",
        "                ckpt = Path(f\"model_ce_fold{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                if not ckpt.exists(): continue\n",
        "                m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                xb = torch.from_numpy(X).float().to(device); xb = (xb - mean_t) / (std_t + 1e-6); xb = xb.unsqueeze(0)\n",
        "                p = m(xb)[0].softmax(dim=-1); p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1))\n",
        "                acc = p if acc is None else (acc + p); del m\n",
        "    probs = acc / float(6); return probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def build_submission_ce6_localsrch():\n",
        "    cfg = pd.read_csv('cv_sweep_ce_6x_localsrch.csv').sort_values(['worst','mean']).iloc[0].to_dict() if Path('cv_sweep_ce_6x_localsrch.csv').exists() else {'pool_k':11,'temp':0.9,'gamma':0.95,'sep':2,'beta':0.5,'lambda_ord':0.05}\n",
        "    pool_k=int(cfg['pool_k']); temp=float(cfg['temp']); gamma=float(cfg.get('gamma',1.0)); sep=int(cfg['sep']); beta=float(cfg.get('beta',0.5)); l_ord=float(cfg.get('lambda_ord',0.05))\n",
        "    med_k_all = compute_class_median_durations_for_ids(train_df['Id'].astype(int).tolist())\n",
        "    scalers=[compute_fold_scaler(folds[fi]['train_ids']) for fi in range(3)]\n",
        "    scalers=[(torch.from_numpy(m).float().to(device), torch.from_numpy(s).float().to(device)) for (m,s) in scalers]\n",
        "    test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "    rows=[]; t0=time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        p = infer_ce6_probs_for_sid(int(sid), scalers)\n",
        "        T = p.shape[0]; g_eff = gamma_with_length(gamma, T, med_k_all)\n",
        "        seq = decode_localsrch(p, med_k=med_k_all, pool_k=pool_k, temp=temp, gamma=g_eff, min_sep=sep, beta=beta, lambda_ord=l_ord, K=3)\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [infer CE-6x local] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    assert len(sub)==95\n",
        "    assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "    sub.to_csv('submission_primary_ce_6x_localsrch.csv', index=False); sub.to_csv('submission.csv', index=False)\n",
        "    print('Wrote submission_primary_ce_6x_localsrch.csv and submission.csv; head:\\n', sub.head(), flush=True)\n",
        "\n",
        "# After sweep finishes, run test-time build\n",
        "print('Local-search decoder cell ready. Execute this cell to sweep and build submission.', flush=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweeping local-search decoder on CE6 averaged OOF (tiny grid)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 6/96 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 12/96 elapsed=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 18/96 elapsed=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 24/96 elapsed=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 30/96 elapsed=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 36/96 elapsed=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 42/96 elapsed=2.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 48/96 elapsed=2.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 54/96 elapsed=2.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 60/96 elapsed=3.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 66/96 elapsed=3.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 72/96 elapsed=3.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 78/96 elapsed=4.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 84/96 elapsed=4.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 90/96 elapsed=4.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep local] cfg 96/96 elapsed=4.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top CE6 local-search (mean, worst, cfg):\n(4.5029670858242286, 5.18, {'pool_k': 11, 'temp': 1.0, 'gamma': 0.9, 'sep': 2, 'beta': 0.5, 'lambda_ord': 0.03})\n(4.5029670858242286, 5.18, {'pool_k': 11, 'temp': 1.0, 'gamma': 0.9, 'sep': 2, 'beta': 0.5, 'lambda_ord': 0.05})\n(4.5029670858242286, 5.18, {'pool_k': 11, 'temp': 1.0, 'gamma': 0.9, 'sep': 3, 'beta': 0.5, 'lambda_ord': 0.03})\n(4.5029670858242286, 5.18, {'pool_k': 11, 'temp': 1.0, 'gamma': 0.9, 'sep': 3, 'beta': 0.5, 'lambda_ord': 0.05})\n(4.5029670858242286, 5.18, {'pool_k': 11, 'temp': 1.0, 'gamma': 0.95, 'sep': 2, 'beta': 0.5, 'lambda_ord': 0.03})\nSaved cv_sweep_ce_6x_localsrch.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local-search decoder cell ready. Execute this cell to sweep and build submission.\n"
          ]
        }
      ]
    },
    {
      "id": "118bc38f-23df-4b17-aee7-f38a36fc7a42",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build submission using best local-search cfg\n",
        "build_submission_ce6_localsrch()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/3851859880.py:290: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x local] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x local] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x local] 30/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x local] 40/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x local] 50/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x local] 60/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x local] 70/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x local] 80/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x local] 90/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-6x local] 95/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_6x_localsrch.csv and submission.csv; head:\n     Id                                           Sequence\n0  300  9 2 1 15 18 3 12 8 10 11 4 20 13 5 14 19 6 16 ...\n1  301  12 10 1 11 4 6 15 13 5 19 9 7 8 18 2 14 3 16 2...\n2  302  12 1 17 20 16 19 13 5 18 3 10 4 6 8 14 15 7 9 ...\n3  303  18 13 5 10 4 11 20 12 17 14 16 8 3 9 7 19 1 6 ...\n4  304  1 12 10 2 14 18 13 5 9 7 11 3 19 6 15 8 17 16 ...\n"
          ]
        }
      ]
    },
    {
      "id": "208a64a1-72f1-4a48-b03d-66b6dda26a59",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# P3: Build features3d_v3 by augmenting v2 with motion features (velocity, acceleration, |v|, EMA|v|)\n",
        "import os, json, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "src_tr = Path('features3d_v2')/'train'\n",
        "src_te = Path('features3d_v2')/'test'\n",
        "dst_tr = Path('features3d_v3')/'train'\n",
        "dst_te = Path('features3d_v3')/'test'\n",
        "dst_tr.mkdir(parents=True, exist_ok=True)\n",
        "dst_te.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def five_point_derivative(x_t_d: np.ndarray):\n",
        "    # x: [T, D]; compute 5-point symmetric first derivative per feature with edge replication\n",
        "    T, D = x_t_d.shape\n",
        "    if T < 5:\n",
        "        # fallback to simple 1-step diff with pad\n",
        "        dx = np.zeros_like(x_t_d, dtype=np.float32)\n",
        "        dx[1:] = x_t_d[1:] - x_t_d[:-1]\n",
        "        dx[0] = dx[1]\n",
        "        return dx.astype(np.float32)\n",
        "    x = x_t_d.astype(np.float32)\n",
        "    x_m2 = np.vstack([x[0:1], x[0:1], x[:-2]])\n",
        "    x_m1 = np.vstack([x[0:1], x[:-1]])\n",
        "    x_p1 = np.vstack([x[1:], x[-1:]])\n",
        "    x_p2 = np.vstack([x[2:], x[-1:], x[-1:]])\n",
        "    v = (-x_p2 + 8.0*x_p1 - 8.0*x_m1 + x_m2) / 12.0\n",
        "    return v.astype(np.float32)\n",
        "\n",
        "def five_point_second_derivative(x_t_d: np.ndarray):\n",
        "    # approximate second derivative via 5-tap stencil\n",
        "    T, D = x_t_d.shape\n",
        "    x = x_t_d.astype(np.float32)\n",
        "    if T < 5:\n",
        "        # fallback: second diff of simple diff\n",
        "        d1 = np.zeros_like(x); d1[1:] = x[1:] - x[:-1]; d1[0] = d1[1] if T>1 else 0.0\n",
        "        a = np.zeros_like(x); a[1:] = d1[1:] - d1[:-1]; a[0] = a[1] if T>1 else 0.0\n",
        "        return a.astype(np.float32)\n",
        "    x_m2 = np.vstack([x[0:1], x[0:1], x[:-2]])\n",
        "    x_m1 = np.vstack([x[0:1], x[:-1]])\n",
        "    x_p1 = np.vstack([x[1:], x[-1:]])\n",
        "    x_p2 = np.vstack([x[2:], x[-1:], x[-1:]])\n",
        "    a = (-x_p2 + 16.0*x_p1 - 30.0*x + 16.0*x_m1 - x_m2) / 12.0\n",
        "    return a.astype(np.float32)\n",
        "\n",
        "def ema(arr: np.ndarray, alpha: float = 0.9):\n",
        "    # arr: [T, D]\n",
        "    out = np.empty_like(arr, dtype=np.float32)\n",
        "    if arr.shape[0] == 0:\n",
        "        return out\n",
        "    out[0] = arr[0]\n",
        "    for t in range(1, arr.shape[0]):\n",
        "        out[t] = alpha * out[t-1] + (1.0 - alpha) * arr[t]\n",
        "    return out\n",
        "\n",
        "def build_v3_from_v2_file(src_path: Path, dst_path: Path):\n",
        "    d = np.load(src_path)\n",
        "    X = d['X'].astype(np.float32)  # [T, D]\n",
        "    v = five_point_derivative(X)               # [T, D]\n",
        "    a = five_point_second_derivative(X)        # [T, D]\n",
        "    abs_v = np.abs(v).astype(np.float32)       # [T, D]\n",
        "    ema_abs_v = ema(abs_v, alpha=0.9)          # [T, D]\n",
        "    Xv3 = np.concatenate([X, v, a, abs_v, ema_abs_v], axis=1).astype(np.float32)\n",
        "    np.savez_compressed(dst_path, X=Xv3)\n",
        "\n",
        "def process_split(src_dir: Path, dst_dir: Path, tag: str):\n",
        "    paths = sorted(src_dir.glob('*.npz'))\n",
        "    t0 = time.time()\n",
        "    for i, p in enumerate(paths, 1):\n",
        "        outp = dst_dir / p.name\n",
        "        if outp.exists():\n",
        "            continue\n",
        "        build_v3_from_v2_file(p, outp)\n",
        "        if (i % 25) == 0 or i == len(paths):\n",
        "            print(f\"  [{tag}] {i}/{len(paths)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "\n",
        "print('Building features3d_v3 train/test from features3d_v2 ...', flush=True)\n",
        "process_split(src_tr, dst_tr, 'train')\n",
        "process_split(src_te, dst_te, 'test')\n",
        "print('Done features3d_v3. Example shapes:', flush=True)\n",
        "ex = next(iter(sorted(dst_tr.glob('*.npz'))))\n",
        "d_ex = np.load(ex)\n",
        "print('Sample:', ex.name, 'X shape:', d_ex['X'].shape, flush=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building features3d_v3 train/test from features3d_v2 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 25/297 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 50/297 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 75/297 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 100/297 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 125/297 elapsed=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 150/297 elapsed=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 175/297 elapsed=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 200/297 elapsed=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 225/297 elapsed=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 250/297 elapsed=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 275/297 elapsed=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] 297/297 elapsed=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test] 25/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test] 50/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test] 75/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test] 95/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done features3d_v3. Example shapes:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample: 1.npz X shape: (1254, 1095)\n"
          ]
        }
      ]
    },
    {
      "id": "81db4166-b81b-44e8-bda1-62449453781f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# P3/P4: Train CE on features3d_v3 (motion-augmented), cache OOF, sweep improved decoder, build 6x submission\n",
        "import os, json, math, time, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA available:', torch.cuda.is_available(), flush=True)\n",
        "assert torch.cuda.is_available(), 'GPU required'\n",
        "torch.backends.cudnn.benchmark = True\n",
        "try: torch.set_float32_matmul_precision('high')\n",
        "except Exception: pass\n",
        "\n",
        "feat_tr_dir = Path('features3d_v3')/'train'\n",
        "feat_te_dir = Path('features3d_v3')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch); self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1); self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, 1)\n",
        "        blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3));\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2);\n",
        "        h = self.inp(x)\n",
        "        for b in self.blocks: h = b(h)\n",
        "        out = self.head(h)\n",
        "        return out.transpose(1,2)\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.decay = decay; self.shadow = {n: p.detach().clone() for n,p in model.named_parameters() if p.requires_grad}\n",
        "    @torch.no_grad()\n",
        "    def update(self, model):\n",
        "        for n,p in model.named_parameters():\n",
        "            if p.requires_grad: self.shadow[n].mul_(self.decay).add_(p.detach(), alpha=1.0-self.decay)\n",
        "    def apply_to(self, model):\n",
        "        self.backup={}\n",
        "        for n,p in model.named_parameters():\n",
        "            if p.requires_grad: self.backup[n]=p.detach().clone(); p.data.copy_(self.shadow[n].data)\n",
        "    def restore(self, model):\n",
        "        for n,p in model.named_parameters():\n",
        "            if p.requires_grad: p.data.copy_(self.backup[n].data)\n",
        "\n",
        "def load_feat_full(sample_id:int):\n",
        "    d = np.load((feat_tr_dir/f\"{sample_id}.npz\")); return d['X'].astype(np.float32)\n",
        "def load_feat(split, sid:int):\n",
        "    d = np.load((feat_tr_dir if split=='train' else feat_te_dir)/f\"{sid}.npz\"); return d['X'].astype(np.float32)\n",
        "def load_labels(sample_id:int):\n",
        "    return np.load(lab_tr_dir/f\"{sample_id}.npy\").astype(np.int64)\n",
        "\n",
        "def compute_fold_scaler(id_list):\n",
        "    n=0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = load_feat_full(int(sid)); n_i = X.shape[0]\n",
        "        if mean is None:\n",
        "            mean = X.mean(axis=0); M2 = ((X - mean)**2).sum(axis=0); n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0); n_new = n + n_i; delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new))\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new)); n = n_new\n",
        "    var = M2 / max(1, (n - 1)); std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def compute_class_weights(train_ids):\n",
        "    counts = np.zeros(21, dtype=np.int64)\n",
        "    for sid in train_ids:\n",
        "        y = load_labels(int(sid)); vals, cnts = np.unique(y, return_counts=True)\n",
        "        for v,c in zip(vals, cnts):\n",
        "            if 0 <= v <= 20: counts[v] += int(c)\n",
        "    freq = counts / max(1, counts.sum())\n",
        "    w = 1.0 / np.sqrt(np.clip(freq, 1e-12, None)); w = w / w.mean()\n",
        "    w[0] = min(w[0], 0.7 * w.mean())\n",
        "    return torch.tensor(w, dtype=torch.float32, device=device)\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, ids, mean, std, train=True, crop_min=1600, crop_max=4096, time_masks=(3,5), mask_len=(5,15), noise_std=0.01, seed=42, time_stretch=(0.95,1.05)):\n",
        "        self.ids=list(ids); self.mean=torch.from_numpy(mean).float(); self.std=torch.from_numpy(std).float()\n",
        "        self.train=train; self.crop_min=crop_min; self.crop_max=crop_max\n",
        "        self.tmask_lo, self.tmask_hi = time_masks; self.mlen_lo, self.mlen_hi = mask_len\n",
        "        self.noise_std=noise_std; self.ts=time_stretch; self.rng=random.Random(seed)\n",
        "    def __len__(self): return len(self.ids)\n",
        "    def _rand_crop(self, X, y):\n",
        "        T=X.shape[0];\n",
        "        if not self.train: return X,y\n",
        "        tgt=self.rng.randint(self.crop_min, min(self.crop_max, max(self.crop_min,T)))\n",
        "        if T<=tgt: return X,y\n",
        "        s=self.rng.randint(0, T - tgt); e=s+tgt; return X[s:e], y[s:e]\n",
        "    def _time_mask(self, X):\n",
        "        if not self.train: return X\n",
        "        T=X.shape[0]; m=self.rng.randint(self.tmask_lo, self.tmask_hi)\n",
        "        for _ in range(m):\n",
        "            L=self.rng.randint(self.mlen_lo, self.mlen_hi)\n",
        "            if T<=L: continue\n",
        "            s=self.rng.randint(0, T-L); e=s+L\n",
        "            seg_mean = X[max(0,s-5):min(T,e+5)].mean(axis=0, keepdims=True)\n",
        "            X[s:e] = seg_mean\n",
        "        return X\n",
        "    def _time_stretch(self, X, y):\n",
        "        if not self.train or self.ts is None: return X,y\n",
        "        lo,hi = self.ts; s = self.rng.uniform(lo, hi)\n",
        "        if abs(s-1.0) < 1e-3: return X,y\n",
        "        T = X.shape[0]; tgt = max(1, int(round(T*s)))\n",
        "        # linear interp for X\n",
        "        x_t = torch.from_numpy(X).float().unsqueeze(0).transpose(1,2)\n",
        "        Xs = F.interpolate(x_t, size=tgt, mode='linear', align_corners=False).transpose(1,2)[0].numpy()\n",
        "        # nearest for y\n",
        "        y_t = torch.from_numpy(y).long().unsqueeze(0).unsqueeze(0).float()\n",
        "        ys = F.interpolate(y_t, size=tgt, mode='nearest')[0,0].long().numpy()\n",
        "        return Xs, ys\n",
        "    def __getitem__(self, idx):\n",
        "        sid = int(self.ids[idx])\n",
        "        X = load_feat_full(sid); y = load_labels(sid)\n",
        "        X, y = self._rand_crop(X, y)\n",
        "        X, y = self._time_stretch(X, y)\n",
        "        X = (torch.from_numpy(X).float() - self.mean) / (self.std + 1e-6)\n",
        "        if self.train:\n",
        "            if self.noise_std>0: X = X + torch.randn_like(X) * self.noise_std\n",
        "            Xn = X.numpy(); Xn = self._time_mask(Xn); X = torch.from_numpy(Xn).float()\n",
        "        y = torch.from_numpy(y).long()\n",
        "        return X, y\n",
        "\n",
        "def collate_pad(batch):\n",
        "    xs, ys = zip(*batch); T_max = max(x.shape[0] for x in xs); D = xs[0].shape[1]\n",
        "    xb = torch.zeros((len(xs), T_max, D), dtype=torch.float32)\n",
        "    yb = torch.full((len(xs), T_max), -100, dtype=torch.long)\n",
        "    for i,(x,y) in enumerate(zip(xs,ys)):\n",
        "        T = x.shape[0]; xb[i,:T]=x; yb[i,:T]=y\n",
        "    return xb, yb\n",
        "\n",
        "def cosine_with_warmup(step, total_steps, warmup_steps, base_lr, min_lr):\n",
        "    if step < warmup_steps: return base_lr * (step / max(1, warmup_steps))\n",
        "    t = (step - warmup_steps) / max(1, (total_steps - warmup_steps))\n",
        "    return min_lr + 0.5*(base_lr - min_lr)*(1 + math.cos(math.pi * t))\n",
        "\n",
        "def train_fold(fold_idx, train_ids, val_ids, out_name, ds_seed, epochs=35, batch_size=8, base_lr=3e-3, min_lr=3e-5, wd=0.01, label_smooth=0.05):\n",
        "    print(f\"=== Train v3 fold {fold_idx} ({out_name}) ===\", flush=True)\n",
        "    mean, std = compute_fold_scaler(train_ids); class_w = compute_class_weights(train_ids)\n",
        "    D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "    model = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "    # seeds\n",
        "    torch.manual_seed(1337 + ds_seed); np.random.seed(4242 + ds_seed); random.seed(9001 + ds_seed)\n",
        "    ema = EMA(model, decay=0.999); scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=base_lr, weight_decay=wd, betas=(0.9,0.999))\n",
        "    tr_ds = SeqDataset(train_ids, mean, std, train=True, seed=ds_seed, time_stretch=(0.95,1.05))\n",
        "    va_ds = SeqDataset(val_ids, mean, std, train=False, seed=ds_seed+777, time_stretch=None)\n",
        "    tr_ld = DataLoader(tr_ds, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=0, collate_fn=collate_pad, pin_memory=True)\n",
        "    va_ld = DataLoader(va_ds, batch_size=1, shuffle=False, drop_last=False, num_workers=0, collate_fn=collate_pad, pin_memory=True)\n",
        "    steps_per_epoch = max(1, len(tr_ld)); total_steps = steps_per_epoch * epochs; warmup_steps = 5 * steps_per_epoch\n",
        "    crit = nn.CrossEntropyLoss(weight=class_w, label_smoothing=label_smooth, ignore_index=-100)\n",
        "    best_val = float('inf'); bad=0; patience=6; t0=time.time()\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train(); tr_loss=0.0; seen=0; t_ep=time.time(); opt.zero_grad(set_to_none=True)\n",
        "        for step,(xb,yb) in enumerate(tr_ld):\n",
        "            xb=xb.to(device, non_blocking=True); yb=yb.to(device, non_blocking=True); C=21\n",
        "            lr = cosine_with_warmup((ep-1)*steps_per_epoch + step, total_steps, warmup_steps, base_lr, min_lr)\n",
        "            for pg in opt.param_groups: pg['lr']=lr\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                logits = model(xb); loss = crit(logits.reshape(-1, C), yb.reshape(-1))\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt); torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler.step(opt); scaler.update(); opt.zero_grad(set_to_none=True); ema.update(model)\n",
        "            tr_loss += loss.item() * xb.shape[0]; seen += xb.shape[0]\n",
        "        # val\n",
        "        model.eval(); ema.apply_to(model); val_loss=0.0; vseen=0\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda'):\n",
        "            for xb,yb in va_ld:\n",
        "                xb=xb.to(device, non_blocking=True); yb=yb.to(device, non_blocking=True); C=21\n",
        "                logits = model(xb); loss = crit(logits.reshape(-1, C), yb.reshape(-1)); val_loss += loss.item(); vseen += 1\n",
        "        ema.restore(model); val_loss = val_loss / max(1, vseen)\n",
        "        print(f\"[v3 fold {fold_idx}] ep{ep} tr={tr_loss/max(1,seen):.4f} va={val_loss:.4f} elapsed={(time.time()-t_ep):.1f}s total={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "        if val_loss < best_val - 1e-4:\n",
        "            best_val = val_loss; bad=0; ema.apply_to(model); torch.save(model.state_dict(), out_name); ema.restore(model)\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience: print(f\"  Early stop at ep{ep}\", flush=True); break\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "    print(f\"Fold {fold_idx} v3 done. Best CE={best_val:.4f} -> {out_name}\")\n",
        "\n",
        "# Train v3 models: two seeds x 3 folds\n",
        "for f in folds:\n",
        "    fi = int(f['fold'])\n",
        "    for si, suf in enumerate(['', '_s1']):\n",
        "        outp = Path(f\"model_ce_v3_fold{fi}{suf}.pth\")\n",
        "        if outp.exists():\n",
        "            try: outp.unlink()\n",
        "            except Exception: pass\n",
        "        ds_seed = 2027 + fi*13 + si*101\n",
        "        train_fold(fi, f['train_ids'], f['val_ids'], out_name=str(outp), ds_seed=ds_seed, epochs=35, batch_size=8)\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "# Cache OOF probs for v3 models (both seeds), with TTA=(0.9,1.0,1.1)\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        T,C = p_t_c.shape; tgt_len = max(1, int(round(T*s)))\n",
        "        x = p_t_c.T.unsqueeze(0)\n",
        "        y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False)\n",
        "        y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T\n",
        "        y2 = y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        acc = y2 if acc is None else (acc + y2)\n",
        "    out = acc / float(len(factors))\n",
        "    return out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def cache_fold_val_probs_v3(fold, seed_suffix: str):\n",
        "    fi = int(fold['fold'])\n",
        "    ckpt = Path(f\"model_ce_v3_fold{fi}{seed_suffix}.pth\"); assert ckpt.exists(), f\"Missing {ckpt}\"\n",
        "    D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "    model = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "    model.load_state_dict(torch.load(ckpt, map_location=device)); model.eval()\n",
        "    mean,std = compute_fold_scaler(fold['train_ids'])\n",
        "    mean_t = torch.from_numpy(mean).float().to(device); std_t = torch.from_numpy(std).float().to(device)\n",
        "    vids = fold['val_ids']; t0=time.time()\n",
        "    for i, sid in enumerate(vids, 1):\n",
        "        sid=int(sid); outp = probs_cache/f\"{sid}_ce_v3{seed_suffix}.npy\"\n",
        "        X = load_feat('train', sid); xb = torch.from_numpy(X).float().to(device); xb = (xb - mean_t)/(std_t+1e-6); xb = xb.unsqueeze(0)\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda'):\n",
        "            p = model(xb)[0].softmax(dim=-1); p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1))\n",
        "        np.save(outp, p.cpu().numpy())\n",
        "        if (i%25)==0 or i==len(vids): print(f\"  [v3 fold {fi}{seed_suffix}] cached {i}/{len(vids)}\", flush=True)\n",
        "\n",
        "print('Caching v3 OOF probs ...', flush=True)\n",
        "for f in folds:\n",
        "    for suf in ['', '_s1']:\n",
        "        if Path(f\"model_ce_v3_fold{int(f['fold'])}{suf}.pth\").exists():\n",
        "            cache_fold_val_probs_v3(f, suf)\n",
        "\n",
        "# Improved decoder utilities (reuse from earlier)\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2); y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k = max(1, int(k)); x = p_t.view(1,1,-1); w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "    pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1); T = p_t.shape[0]\n",
        "    if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]))\n",
        "    elif y.shape[0] > T: y = y[:T]\n",
        "    return y\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T=p.shape[0]; a=max(0,t_star-w); b=min(T-1,t_star+w); idx=torch.arange(a,b+1, device=p.device, dtype=p.dtype);\n",
        "    seg=p[a:b+1]; s=seg.sum()+1e-8; return float(((idx*seg).sum()/s).item())\n",
        "def decode_peaks_improved(p_t_c: torch.Tensor, med_k: dict, gamma: float = 1.0, pool_k=13, temp=0.9, min_sep=2, K=3, k_delta=4):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c/(p_t_c.sum(dim=-1, keepdim=True)+1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k); T,C = p_s.shape\n",
        "    scores = torch.zeros_like(p_s); ks=[13]*C\n",
        "    for c in range(C):\n",
        "        if c==0: scores[:,c]=p_s[:,c]; ks[c]=13; continue\n",
        "        base_k = med_k.get(c,13); k_c = int(np.clip(round(gamma*base_k), 9, 25));\n",
        "        if k_c % 2 == 0: k_c = min(25, k_c+1); ks[c]=k_c\n",
        "        ks_multi = sorted(set([int(np.clip(k_c-4,9,25)), k_c, int(np.clip(k_c+4,9,25))]));\n",
        "        ks_multi = [k if (k%2)==1 else min(25, k+1) for k in ks_multi]\n",
        "        acc=None\n",
        "        for k in ks_multi:\n",
        "            di = duration_integral_single(p_s[:,c], k=k).unsqueeze(1); acc = di if acc is None else (acc + di)\n",
        "        scores[:,c] = (acc/float(len(ks_multi))).squeeze(1)\n",
        "    # candidates per class (best only) with COM refine\n",
        "    peaks=[]\n",
        "    for c in range(1,21):\n",
        "        k=ks[c]; s=scores[:,c]; t_star=int(torch.argmax(s).item())\n",
        "        w_com=max(5,k//3); radius=max(10,k//2); t_ref = refine_com(p_s[:,c], t_star, w=w_com)\n",
        "        t_idx=int(round(max(0,min(t_ref,T-1))))\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        pooled_at_ref = p_s[t_idx, c].item()\n",
        "        peaks.append([c, t_ref, float(scores[t_idx,c].item()), float(local_mean), float(pooled_at_ref)])\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3], -x[4]))\n",
        "    last_t=-1e9\n",
        "    for i in range(len(peaks)):\n",
        "        if peaks[i][1] <= last_t: peaks[i][1] = last_t + min_sep\n",
        "        last_t = min(peaks[i][1], float(T-1))\n",
        "    return [int(c) for c,_,_,_,_ in peaks]\n",
        "\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {};\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "\n",
        "def gamma_with_length(gamma_cv: float, T: int, med_k: dict):\n",
        "    L_est = float(sum(med_k.get(c,13) for c in range(1,21)))\n",
        "    if L_est <= 0: return gamma_cv\n",
        "    ratio = float(T) / L_est; gamma_s = float(np.clip(ratio, 0.85, 1.15)); return float(gamma_cv * gamma_s)\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# Sweep decoder on averaged v3 OOF (seed0+seed1) with small grid; select by worst-fold then mean\n",
        "def load_oof_v3_avg(sid:int):\n",
        "    p0 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_v3.npy\")).to(device)\n",
        "    p1 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_v3_s1.npy\")).to(device) if (probs_cache/f\"{sid}_ce_v3_s1.npy\").exists() else None\n",
        "    p = p0 if p1 is None else (p0 + p1) * 0.5\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "pool_ks=[11,13,15]; temps=[0.90,0.95,1.00]; gammas=[0.90,0.95,0.975,1.00,1.025]; seps=[2,3]\n",
        "print('Sweeping improved decoder on v3 averaged OOF...', flush=True)\n",
        "med_cache={}; res=[]\n",
        "for pool_k in pool_ks:\n",
        "    for temp in temps:\n",
        "        for gamma in gammas:\n",
        "            for sep in seps:\n",
        "                per_fold=[]\n",
        "                for f in folds:\n",
        "                    fi=int(f['fold'])\n",
        "                    if fi not in med_cache: med_cache[fi]=compute_class_median_durations_for_ids(f['train_ids'])\n",
        "                    med_k = med_cache[fi]\n",
        "                    vids=f['val_ids']; tot=0; cnt=0\n",
        "                    for sid in vids:\n",
        "                        sid=int(sid); p = load_oof_v3_avg(sid); T = p.shape[0]\n",
        "                        g_eff = gamma_with_length(gamma, T, med_k)\n",
        "                        seq = decode_peaks_improved(p, med_k=med_k, gamma=g_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "                        tot += levenshtein(seq, id2seq[sid]); cnt += 1\n",
        "                    per_fold.append(tot/max(cnt,1))\n",
        "                res.append((np.mean(per_fold), np.max(per_fold), {'pool_k':pool_k,'temp':temp,'gamma':gamma,'sep':sep}))\n",
        "res.sort(key=lambda x: (x[1], x[0]))\n",
        "print('Top v3 improved decoder (mean, worst, cfg):')\n",
        "for r in res[:5]: print(r)\n",
        "pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res]).to_csv('cv_sweep_ce_v3_6x_improved.csv', index=False)\n",
        "print('Saved cv_sweep_ce_v3_6x_improved.csv', flush=True)\n",
        "\n",
        "# Test-time inference: 6 v3 models (3 folds x 2 seeds), TTA, improved decoder, write submission\n",
        "print('Building CE v3 6-model ensemble test submission...', flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "cfg_best = pd.read_csv('cv_sweep_ce_v3_6x_improved.csv').sort_values(['worst','mean']).iloc[0].to_dict() if Path('cv_sweep_ce_v3_6x_improved.csv').exists() else {'pool_k':13,'temp':0.95,'gamma':1.0,'sep':2}\n",
        "pool_k=int(cfg_best['pool_k']); temp=float(cfg_best['temp']); gamma=float(cfg_best.get('gamma',1.0)); sep=int(cfg_best.get('sep',2))\n",
        "med_k_all = compute_class_median_durations_for_ids(train_df['Id'].astype(int).tolist())\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "def load_fold_scalers_v3():\n",
        "    sc=[]\n",
        "    for fi in range(3):\n",
        "        m,s = compute_fold_scaler(folds[fi]['train_ids'])\n",
        "        sc.append((torch.from_numpy(m).float().to(device), torch.from_numpy(s).float().to(device)))\n",
        "    return sc\n",
        "\n",
        "scalers = load_fold_scalers_v3()\n",
        "rows=[]; t0=time.time()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    X = load_feat('test', int(sid)); acc=None\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda'):\n",
        "        for fi in range(3):\n",
        "            mean_t, std_t = scalers[fi]\n",
        "            for s in (0,1):\n",
        "                ckpt = Path(f\"model_ce_v3_fold{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                if not ckpt.exists(): continue\n",
        "                m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                xb = torch.from_numpy(X).float().to(device); xb = (xb - mean_t)/(std_t+1e-6); xb = xb.unsqueeze(0)\n",
        "                p = m(xb)[0].softmax(dim=-1); p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1))\n",
        "                acc = p if acc is None else (acc + p); del m\n",
        "    probs = acc / float(6); probs = probs/(probs.sum(dim=-1, keepdim=True)+1e-8)\n",
        "    T = probs.shape[0]; g_eff = gamma_with_length(gamma, T, med_k_all)\n",
        "    seq = decode_peaks_improved(probs, med_k=med_k_all, gamma=g_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "    rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if (i%10)==0 or i==len(test_ids):\n",
        "        print(f\"  [infer CE-v3 6x] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "sub.to_csv('submission_primary_ce_v3_6x_v2.csv', index=False); sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission_primary_ce_v3_6x_v2.csv and submission.csv; head:\\n', sub.head(), flush=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train v3 fold 0 (model_ce_v3_fold0.pth) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep1 tr=3.6552 va=4.8023 elapsed=20.4s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep2 tr=2.8409 va=4.5217 elapsed=19.7s total=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep3 tr=2.3003 va=4.2815 elapsed=20.7s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep4 tr=1.9365 va=4.0719 elapsed=20.3s total=1.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep5 tr=1.7407 va=3.8802 elapsed=19.0s total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep6 tr=1.5912 va=3.6986 elapsed=19.4s total=2.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep7 tr=1.4666 va=3.5324 elapsed=18.3s total=2.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep8 tr=1.3781 va=3.3824 elapsed=18.5s total=2.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep9 tr=1.2774 va=3.2427 elapsed=19.1s total=2.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep10 tr=1.2287 va=3.1076 elapsed=19.0s total=3.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep11 tr=1.1766 va=2.9764 elapsed=18.0s total=3.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep12 tr=1.1075 va=2.8513 elapsed=18.2s total=3.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep13 tr=1.0555 va=2.7375 elapsed=18.3s total=4.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep14 tr=1.0100 va=2.6286 elapsed=18.1s total=4.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep15 tr=0.9431 va=2.5365 elapsed=18.2s total=4.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep16 tr=0.9316 va=2.4528 elapsed=18.3s total=5.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep17 tr=0.9035 va=2.3782 elapsed=18.5s total=5.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep18 tr=0.8474 va=2.3139 elapsed=18.2s total=5.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep19 tr=0.8160 va=2.2597 elapsed=18.3s total=6.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep20 tr=0.7827 va=2.2156 elapsed=18.4s total=6.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep21 tr=0.7729 va=2.1780 elapsed=17.9s total=6.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep22 tr=0.7355 va=2.1474 elapsed=17.9s total=6.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep23 tr=0.6992 va=2.1226 elapsed=18.0s total=7.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep24 tr=0.6780 va=2.1021 elapsed=17.8s total=7.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep25 tr=0.6611 va=2.0843 elapsed=18.2s total=7.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep26 tr=0.6434 va=2.0692 elapsed=17.8s total=8.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep27 tr=0.6263 va=2.0557 elapsed=18.0s total=8.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep28 tr=0.6243 va=2.0444 elapsed=17.6s total=8.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep29 tr=0.6062 va=2.0351 elapsed=17.5s total=9.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep30 tr=0.6009 va=2.0265 elapsed=17.9s total=9.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep31 tr=0.5964 va=2.0194 elapsed=17.5s total=9.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep32 tr=0.5900 va=2.0127 elapsed=17.8s total=9.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep33 tr=0.5894 va=2.0083 elapsed=17.8s total=10.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep34 tr=0.5886 va=2.0035 elapsed=18.0s total=10.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep35 tr=0.5787 va=1.9997 elapsed=17.9s total=10.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 v3 done. Best CE=1.9997 -> model_ce_v3_fold0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train v3 fold 0 (model_ce_v3_fold0_s1.pth) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep1 tr=3.9658 va=5.5504 elapsed=17.8s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep2 tr=2.8496 va=5.0544 elapsed=17.5s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep3 tr=2.3604 va=4.6543 elapsed=17.4s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep4 tr=1.9452 va=4.3339 elapsed=17.6s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep5 tr=1.6879 va=4.0681 elapsed=18.1s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep6 tr=1.5766 va=3.8328 elapsed=17.9s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep7 tr=1.4535 va=3.6257 elapsed=18.1s total=2.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep8 tr=1.3592 va=3.4524 elapsed=17.6s total=2.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep9 tr=1.3022 va=3.2881 elapsed=18.0s total=2.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep10 tr=1.2247 va=3.1398 elapsed=17.5s total=3.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep11 tr=1.1424 va=2.9964 elapsed=18.0s total=3.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep12 tr=1.1067 va=2.8586 elapsed=17.7s total=3.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep13 tr=1.0519 va=2.7272 elapsed=17.6s total=3.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep14 tr=0.9855 va=2.6011 elapsed=17.8s total=4.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep15 tr=0.9540 va=2.4812 elapsed=18.0s total=4.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep16 tr=0.9198 va=2.3735 elapsed=17.3s total=4.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep17 tr=0.8770 va=2.2805 elapsed=17.7s total=5.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep18 tr=0.8321 va=2.2001 elapsed=17.3s total=5.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep19 tr=0.8252 va=2.1313 elapsed=17.6s total=5.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep20 tr=0.7812 va=2.0742 elapsed=17.5s total=5.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep21 tr=0.7418 va=2.0304 elapsed=17.4s total=6.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep22 tr=0.7243 va=1.9933 elapsed=17.3s total=6.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep23 tr=0.6965 va=1.9627 elapsed=17.2s total=6.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep24 tr=0.6727 va=1.9388 elapsed=17.2s total=7.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep25 tr=0.6635 va=1.9196 elapsed=17.7s total=7.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep26 tr=0.6479 va=1.9047 elapsed=17.3s total=7.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep27 tr=0.6304 va=1.8933 elapsed=17.6s total=8.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep28 tr=0.6132 va=1.8842 elapsed=17.4s total=8.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep29 tr=0.6076 va=1.8782 elapsed=17.3s total=8.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep30 tr=0.5927 va=1.8737 elapsed=17.4s total=8.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep31 tr=0.5905 va=1.8705 elapsed=17.3s total=9.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep32 tr=0.5876 va=1.8687 elapsed=17.4s total=9.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep33 tr=0.5855 va=1.8673 elapsed=17.6s total=9.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep34 tr=0.5800 va=1.8672 elapsed=17.3s total=10.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 0] ep35 tr=0.5780 va=1.8671 elapsed=17.8s total=10.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 v3 done. Best CE=1.8672 -> model_ce_v3_fold0_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train v3 fold 1 (model_ce_v3_fold1.pth) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep1 tr=3.5768 va=4.0807 elapsed=19.1s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep2 tr=2.8262 va=3.9053 elapsed=19.0s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep3 tr=2.3220 va=3.7453 elapsed=19.2s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep4 tr=1.9018 va=3.6062 elapsed=18.6s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep5 tr=1.7112 va=3.4706 elapsed=19.4s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep6 tr=1.5473 va=3.3417 elapsed=18.6s total=1.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep7 tr=1.4130 va=3.2170 elapsed=18.7s total=2.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep8 tr=1.2879 va=3.0935 elapsed=19.1s total=2.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep9 tr=1.2328 va=2.9717 elapsed=19.1s total=2.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep10 tr=1.1917 va=2.8442 elapsed=18.8s total=3.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep11 tr=1.0971 va=2.7107 elapsed=19.3s total=3.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep12 tr=1.0251 va=2.5779 elapsed=19.1s total=3.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep13 tr=0.9920 va=2.4476 elapsed=19.3s total=4.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep14 tr=0.9527 va=2.3226 elapsed=19.3s total=4.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep15 tr=0.8992 va=2.2084 elapsed=18.8s total=4.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep16 tr=0.8735 va=2.1065 elapsed=18.6s total=5.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep17 tr=0.8369 va=2.0201 elapsed=18.4s total=5.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep18 tr=0.8266 va=1.9449 elapsed=18.7s total=5.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep19 tr=0.7638 va=1.8827 elapsed=18.2s total=6.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep20 tr=0.7414 va=1.8311 elapsed=18.5s total=6.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep21 tr=0.7003 va=1.7885 elapsed=18.3s total=6.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep22 tr=0.6845 va=1.7536 elapsed=18.3s total=7.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep23 tr=0.6621 va=1.7247 elapsed=19.0s total=7.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep24 tr=0.6437 va=1.7006 elapsed=18.5s total=7.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep25 tr=0.6302 va=1.6803 elapsed=18.4s total=7.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep26 tr=0.6123 va=1.6635 elapsed=18.7s total=8.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep27 tr=0.6026 va=1.6496 elapsed=18.6s total=8.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep28 tr=0.5952 va=1.6375 elapsed=18.5s total=8.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep29 tr=0.5826 va=1.6278 elapsed=18.2s total=9.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep30 tr=0.5748 va=1.6200 elapsed=18.5s total=9.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep31 tr=0.5716 va=1.6134 elapsed=18.0s total=9.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep32 tr=0.5687 va=1.6081 elapsed=18.0s total=10.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep33 tr=0.5629 va=1.6038 elapsed=18.3s total=10.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep34 tr=0.5629 va=1.6006 elapsed=18.6s total=10.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep35 tr=0.5631 va=1.5981 elapsed=17.8s total=11.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 v3 done. Best CE=1.5981 -> model_ce_v3_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train v3 fold 1 (model_ce_v3_fold1_s1.pth) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep1 tr=3.8627 va=4.9465 elapsed=17.9s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep2 tr=2.8492 va=4.5739 elapsed=18.7s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep3 tr=2.3798 va=4.2638 elapsed=18.5s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep4 tr=1.9935 va=4.0199 elapsed=18.7s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep5 tr=1.7532 va=3.8139 elapsed=18.4s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep6 tr=1.6284 va=3.6274 elapsed=18.4s total=1.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep7 tr=1.4479 va=3.4602 elapsed=17.9s total=2.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep8 tr=1.3500 va=3.3103 elapsed=18.5s total=2.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep9 tr=1.2536 va=3.1731 elapsed=18.3s total=2.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep10 tr=1.1745 va=3.0452 elapsed=18.3s total=3.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep11 tr=1.1198 va=2.9211 elapsed=18.3s total=3.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep12 tr=1.0487 va=2.7978 elapsed=18.1s total=3.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep13 tr=1.0060 va=2.6733 elapsed=18.3s total=4.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep14 tr=0.9648 va=2.5509 elapsed=18.3s total=4.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep15 tr=0.9313 va=2.4322 elapsed=18.6s total=4.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep16 tr=0.8799 va=2.3227 elapsed=18.1s total=4.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep17 tr=0.8447 va=2.2229 elapsed=18.8s total=5.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep18 tr=0.8396 va=2.1347 elapsed=18.0s total=5.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep19 tr=0.7859 va=2.0596 elapsed=18.6s total=5.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep20 tr=0.7482 va=1.9941 elapsed=18.3s total=6.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep21 tr=0.7301 va=1.9399 elapsed=18.2s total=6.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep22 tr=0.7018 va=1.8931 elapsed=18.9s total=6.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep23 tr=0.6816 va=1.8534 elapsed=18.0s total=7.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep24 tr=0.6576 va=1.8197 elapsed=18.3s total=7.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep25 tr=0.6414 va=1.7908 elapsed=18.7s total=7.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep26 tr=0.6222 va=1.7665 elapsed=18.4s total=8.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep27 tr=0.6104 va=1.7459 elapsed=18.4s total=8.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep28 tr=0.5957 va=1.7288 elapsed=18.8s total=8.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep29 tr=0.5903 va=1.7139 elapsed=18.6s total=9.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep30 tr=0.5795 va=1.7013 elapsed=18.0s total=9.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep31 tr=0.5741 va=1.6905 elapsed=18.4s total=9.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep32 tr=0.5763 va=1.6815 elapsed=18.6s total=9.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep33 tr=0.5722 va=1.6738 elapsed=18.6s total=10.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep34 tr=0.5715 va=1.6671 elapsed=18.1s total=10.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 1] ep35 tr=0.5674 va=1.6616 elapsed=18.4s total=10.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 v3 done. Best CE=1.6616 -> model_ce_v3_fold1_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train v3 fold 2 (model_ce_v3_fold2.pth) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep1 tr=3.8128 va=5.1485 elapsed=19.8s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep2 tr=2.6740 va=4.7698 elapsed=18.1s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep3 tr=2.0562 va=4.4569 elapsed=19.0s total=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep4 tr=1.6664 va=4.2153 elapsed=18.7s total=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep5 tr=1.5031 va=4.0110 elapsed=18.3s total=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep6 tr=1.4180 va=3.8303 elapsed=18.6s total=1.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep7 tr=1.3343 va=3.6682 elapsed=18.8s total=2.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep8 tr=1.2402 va=3.5284 elapsed=18.0s total=2.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep9 tr=1.1112 va=3.4096 elapsed=18.2s total=2.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep10 tr=1.0504 va=3.3013 elapsed=18.4s total=3.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep11 tr=1.0322 va=3.1948 elapsed=18.5s total=3.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep12 tr=0.9849 va=3.0900 elapsed=18.4s total=3.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep13 tr=0.9735 va=2.9892 elapsed=18.5s total=4.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep14 tr=0.9045 va=2.8923 elapsed=18.3s total=4.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep15 tr=0.8852 va=2.8047 elapsed=18.3s total=4.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep16 tr=0.8587 va=2.7231 elapsed=18.1s total=5.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep17 tr=0.8362 va=2.6514 elapsed=18.1s total=5.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep18 tr=0.7948 va=2.5885 elapsed=18.6s total=5.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep19 tr=0.7645 va=2.5365 elapsed=18.6s total=5.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep20 tr=0.7635 va=2.4914 elapsed=18.3s total=6.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep21 tr=0.7129 va=2.4554 elapsed=18.5s total=6.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep22 tr=0.6944 va=2.4255 elapsed=18.3s total=6.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep23 tr=0.6831 va=2.4015 elapsed=18.4s total=7.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep24 tr=0.6708 va=2.3809 elapsed=18.8s total=7.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep25 tr=0.6487 va=2.3633 elapsed=18.2s total=7.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep26 tr=0.6352 va=2.3483 elapsed=18.0s total=8.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep27 tr=0.6247 va=2.3357 elapsed=18.7s total=8.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep28 tr=0.6184 va=2.3273 elapsed=17.9s total=8.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep29 tr=0.6118 va=2.3182 elapsed=18.5s total=9.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep30 tr=0.6060 va=2.3129 elapsed=18.4s total=9.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep31 tr=0.6002 va=2.3071 elapsed=18.6s total=9.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep32 tr=0.5992 va=2.3026 elapsed=18.0s total=9.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep33 tr=0.5955 va=2.2993 elapsed=18.1s total=10.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep34 tr=0.5958 va=2.2972 elapsed=18.3s total=10.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep35 tr=0.5957 va=2.2948 elapsed=18.2s total=10.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 v3 done. Best CE=2.2948 -> model_ce_v3_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train v3 fold 2 (model_ce_v3_fold2_s1.pth) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep1 tr=3.7127 va=4.8984 elapsed=18.1s total=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep2 tr=2.5949 va=4.5837 elapsed=18.4s total=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep3 tr=1.9953 va=4.3230 elapsed=18.7s total=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep4 tr=1.6737 va=4.1047 elapsed=18.2s total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep5 tr=1.5184 va=3.9213 elapsed=18.2s total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep6 tr=1.3975 va=3.7586 elapsed=18.3s total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep7 tr=1.2728 va=3.6187 elapsed=18.3s total=2.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep8 tr=1.2083 va=3.4946 elapsed=17.9s total=2.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep9 tr=1.1289 va=3.3798 elapsed=18.3s total=2.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep10 tr=1.0963 va=3.2703 elapsed=18.4s total=3.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep11 tr=1.0303 va=3.1649 elapsed=18.7s total=3.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep12 tr=0.9859 va=3.0582 elapsed=17.9s total=3.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep13 tr=0.9470 va=2.9535 elapsed=17.7s total=4.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep14 tr=0.8960 va=2.8506 elapsed=18.5s total=4.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep15 tr=0.8631 va=2.7482 elapsed=18.2s total=4.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep16 tr=0.8252 va=2.6512 elapsed=18.2s total=4.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep17 tr=0.8134 va=2.5612 elapsed=18.5s total=5.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep18 tr=0.7836 va=2.4780 elapsed=18.3s total=5.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep19 tr=0.7546 va=2.4059 elapsed=17.9s total=5.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep20 tr=0.7325 va=2.3446 elapsed=18.2s total=6.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep21 tr=0.7155 va=2.2908 elapsed=18.4s total=6.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep22 tr=0.6939 va=2.2483 elapsed=18.0s total=6.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep23 tr=0.6718 va=2.2114 elapsed=18.4s total=7.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep24 tr=0.6609 va=2.1817 elapsed=18.1s total=7.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep25 tr=0.6472 va=2.1564 elapsed=18.4s total=7.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep26 tr=0.6344 va=2.1379 elapsed=18.2s total=8.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep27 tr=0.6260 va=2.1235 elapsed=18.0s total=8.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep28 tr=0.6162 va=2.1129 elapsed=18.2s total=8.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep29 tr=0.6109 va=2.1040 elapsed=18.5s total=8.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep30 tr=0.6054 va=2.0974 elapsed=18.0s total=9.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep31 tr=0.6022 va=2.0922 elapsed=18.4s total=9.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep32 tr=0.5950 va=2.0890 elapsed=18.4s total=9.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep33 tr=0.5934 va=2.0868 elapsed=18.5s total=10.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep34 tr=0.5938 va=2.0862 elapsed=18.0s total=10.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3 fold 2] ep35 tr=0.5898 va=2.0858 elapsed=18.3s total=10.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 v3 done. Best CE=2.0858 -> model_ce_v3_fold2_s1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching v3 OOF probs ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/1168219076.py:234: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(ckpt, map_location=device)); model.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 0] cached 25/98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 0] cached 50/98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 0] cached 75/98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 0] cached 98/98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 0_s1] cached 25/98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 0_s1] cached 50/98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 0_s1] cached 75/98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 0_s1] cached 98/98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 1] cached 25/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 1] cached 50/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 1] cached 75/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 1] cached 99/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 1_s1] cached 25/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 1_s1] cached 50/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 1_s1] cached 75/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 1_s1] cached 99/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 2] cached 25/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 2] cached 50/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 2] cached 75/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 2] cached 100/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 2_s1] cached 25/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 2_s1] cached 50/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 2_s1] cached 75/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3 fold 2_s1] cached 100/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweeping improved decoder on v3 averaged OOF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top v3 improved decoder (mean, worst, cfg):\n(4.916285301999587, 5.7, {'pool_k': 15, 'temp': 1.0, 'gamma': 0.9, 'sep': 2})\n(4.916285301999587, 5.7, {'pool_k': 15, 'temp': 1.0, 'gamma': 0.9, 'sep': 3})\n(4.916285301999587, 5.7, {'pool_k': 15, 'temp': 1.0, 'gamma': 0.95, 'sep': 2})\n(4.916285301999587, 5.7, {'pool_k': 15, 'temp': 1.0, 'gamma': 0.95, 'sep': 3})\n(4.916285301999587, 5.7, {'pool_k': 15, 'temp': 1.0, 'gamma': 0.975, 'sep': 2})\nSaved cv_sweep_ce_v3_6x_improved.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building CE v3 6-model ensemble test submission...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/1168219076.py:384: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-v3 6x] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-v3 6x] 20/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-v3 6x] 30/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-v3 6x] 40/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-v3 6x] 50/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-v3 6x] 60/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-v3 6x] 70/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-v3 6x] 80/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-v3 6x] 90/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE-v3 6x] 95/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_v3_6x_v2.csv and submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 7 1...\n1  301  10 12 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 3 1...\n2  302  1 17 16 12 5 19 7 13 20 18 11 3 4 6 15 8 14 10...\n3  303  13 4 12 10 15 5 19 7 20 17 11 16 8 18 9 1 3 6 ...\n4  304  8 1 12 14 18 13 9 7 2 11 3 20 19 15 5 10 6 17 ...\n"
          ]
        }
      ]
    },
    {
      "id": "261c74ba-6507-4f78-be48-1f0658c9de36",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# P3b: Blend CE-6x (features3d_v2) with CE-v3-6x (features3d_v3) at OOF, pick best, then build blended test submission\n",
        "import os, json, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "probs_cache = Path('probs_cache')\n",
        "lab_tr_dir = Path('labels3d_v2')/'train'\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "# Load averaged OOF for v2 (ce_new) and v3 (ce_v3)\n",
        "def load_oof_v2_avg(sid:int):\n",
        "    p0 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new.npy\")).to(device)\n",
        "    p1p = probs_cache/f\"{sid}_ce_new_s1.npy\"\n",
        "    if p1p.exists():\n",
        "        p1 = torch.from_numpy(np.load(p1p)).to(device); p = (p0 + p1) * 0.5\n",
        "    else:\n",
        "        p = p0\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def load_oof_v3_avg(sid:int):\n",
        "    p0p = probs_cache/f\"{sid}_ce_v3.npy\"\n",
        "    assert p0p.exists(), f\"Missing v3 OOF for {sid}: {p0p}\"\n",
        "    p0 = torch.from_numpy(np.load(p0p)).to(device)\n",
        "    p1p = probs_cache/f\"{sid}_ce_v3_s1.npy\"\n",
        "    if p1p.exists():\n",
        "        p1 = torch.from_numpy(np.load(p1p)).to(device); p = (p0 + p1) * 0.5\n",
        "    else:\n",
        "        p = p0\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def blend_probs_linear(p2: torch.Tensor, p3: torch.Tensor, w: float):\n",
        "    q = w * p2 + (1.0 - w) * p3\n",
        "    return q / (q.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "# Decoder helpers (reuse improved peak-time decoder with gamma length scaling)\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2); y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k = max(1, int(k)); x = p_t.view(1,1,-1); w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "    pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1); T = p_t.shape[0]\n",
        "    if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]))\n",
        "    elif y.shape[0] > T: y = y[:T]\n",
        "    return y\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T=p.shape[0]; a=max(0,t_star-w); b=min(T-1,t_star+w); idx=torch.arange(a,b+1, device=p.device, dtype=p.dtype);\n",
        "    seg=p[a:b+1]; s=seg.sum()+1e-8; return float(((idx*seg).sum()/s).item())\n",
        "def decode_peaks_improved(p_t_c: torch.Tensor, med_k: dict, gamma: float = 1.0, pool_k=13, temp=0.9, min_sep=2, K=3, k_delta=4):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c/(p_t_c.sum(dim=-1, keepdim=True)+1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k); T,C = p_s.shape\n",
        "    scores = torch.zeros_like(p_s); ks=[13]*C\n",
        "    for c in range(C):\n",
        "        if c==0: scores[:,c]=p_s[:,c]; ks[c]=13; continue\n",
        "        base_k = med_k.get(c,13); k_c = int(np.clip(round(gamma*base_k), 9, 25));\n",
        "        if k_c % 2 == 0: k_c = min(25, k_c+1); ks[c]=k_c\n",
        "        ks_multi = sorted(set([int(np.clip(k_c-4,9,25)), k_c, int(np.clip(k_c+4,9,25))]));\n",
        "        ks_multi = [k if (k%2)==1 else min(25, k+1) for k in ks_multi]\n",
        "        acc=None\n",
        "        for k in ks_multi:\n",
        "            di = duration_integral_single(p_s[:,c], k=k).unsqueeze(1); acc = di if acc is None else (acc + di)\n",
        "        scores[:,c] = (acc/float(len(ks_multi))).squeeze(1)\n",
        "    peaks=[]\n",
        "    for c in range(1,21):\n",
        "        k=ks[c]; s=scores[:,c]; t_star=int(torch.argmax(s).item())\n",
        "        w_com=max(5,k//3); radius=max(10,k//2); t_ref = refine_com(p_s[:,c], t_star, w=w_com)\n",
        "        t_idx=int(round(max(0,min(t_ref,T-1))))\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        pooled_at_ref = p_s[t_idx, c].item()\n",
        "        peaks.append([c, t_ref, float(scores[t_idx,c].item()), float(local_mean), float(pooled_at_ref)])\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3], -x[4]))\n",
        "    last_t=-1e9\n",
        "    for i in range(len(peaks)):\n",
        "        if peaks[i][1] <= last_t: peaks[i][1] = last_t + min_sep\n",
        "        last_t = min(peaks[i][1], float(T-1))\n",
        "    return [int(c) for c,_,_,_,_ in peaks]\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {};\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "def gamma_with_length(gamma_cv: float, T: int, med_k: dict):\n",
        "    L_est = float(sum(med_k.get(c,13) for c in range(1,21)))\n",
        "    if L_est <= 0: return gamma_cv\n",
        "    ratio = float(T) / L_est; gamma_s = float(np.clip(ratio, 0.85, 1.15)); return float(gamma_cv * gamma_s)\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# OOF sweep: small grid over weights and decoder params; select by worst-fold then mean\n",
        "w_list=[0.3, 0.5, 0.7]\n",
        "pool_ks=[11,15]; temps=[0.90,1.00]; gammas=[0.90,0.95]; seps=[2,3]\n",
        "print('Sweeping v2-v3 OOF blend...', flush=True)\n",
        "med_cache={}; res=[]; t0=time.time(); cfg_idx=0; total=len(w_list)*len(pool_ks)*len(temps)*len(gammas)*len(seps)\n",
        "for w in w_list:\n",
        "    for pool_k in pool_ks:\n",
        "        for temp in temps:\n",
        "            for gamma in gammas:\n",
        "                for sep in seps:\n",
        "                    cfg_idx += 1\n",
        "                    per_fold=[]\n",
        "                    for f in folds:\n",
        "                        fi = int(f['fold'])\n",
        "                        if fi not in med_cache: med_cache[fi]=compute_class_median_durations_for_ids(f['train_ids'])\n",
        "                        med_k = med_cache[fi]\n",
        "                        vids = f['val_ids']; tot=0; cnt=0\n",
        "                        for sid in vids:\n",
        "                            sid=int(sid); p2 = load_oof_v2_avg(sid); p3 = load_oof_v3_avg(sid); p = blend_probs_linear(p2, p3, float(w))\n",
        "                            T = p.shape[0]; g_eff = gamma_with_length(gamma, T, med_k)\n",
        "                            seq = decode_peaks_improved(p, med_k=med_k, gamma=g_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "                            tot += levenshtein(seq, id2seq[sid]); cnt += 1\n",
        "                        per_fold.append(tot/max(cnt,1))\n",
        "                    res.append((np.mean(per_fold), np.max(per_fold), {'w':w,'pool_k':pool_k,'temp':temp,'gamma':gamma,'sep':sep}))\n",
        "                    if (cfg_idx % 8)==0 or cfg_idx==total:\n",
        "                        print(f\"  [sweep v2v3] cfg {cfg_idx}/{total} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "res.sort(key=lambda x: (x[1], x[0]))\n",
        "print('Top v2-v3 blend OOF (mean,worst,cfg):')\n",
        "for r in res[:5]: print(r)\n",
        "pd.DataFrame([{'mean':m,'worst':wst, **cfg} for m,wst,cfg in res]).to_csv('cv_sweep_ce_v2v3_blend.csv', index=False)\n",
        "print('Saved cv_sweep_ce_v2v3_blend.csv', flush=True)\n",
        "\n",
        "# Test-time blended inference: load v2 CE-6x and v3 CE-6x models lazily per sample, combine probs with chosen w, decode\n",
        "feat_v2_tr = Path('features3d_v2')/'train'; feat_v2_te = Path('features3d_v2')/'test'\n",
        "feat_v3_tr = Path('features3d_v3')/'train'; feat_v3_te = Path('features3d_v3')/'test'\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__(); self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch); self.drop = nn.Dropout(drop); self.conv2 = nn.Conv1d(ch, ch, 1); self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h); h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True); return x + h\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__(); self.inp = nn.Conv1d(d_in, channels, 1); blocks=[]; dil=1\n",
        "        for _ in range(layers): blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3)); dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks); self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2); h = self.inp(x);\n",
        "        for b in self.blocks: h = b(h); out = self.head(h); return out.transpose(1,2)\n",
        "\n",
        "def compute_fold_scaler_from_dir(id_list, feat_dir: Path):\n",
        "    n=0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = np.load(feat_dir/f\"{int(sid)}.npz\")['X'].astype(np.float32); n_i = X.shape[0]\n",
        "        if mean is None: mean = X.mean(axis=0); M2 = ((X - mean)**2).sum(axis=0); n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0); n_new = n + n_i; delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new))\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new)); n = n_new\n",
        "    var = M2 / max(1, (n - 1)); std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        T,C = p_t_c.shape; tgt_len = max(1, int(round(T*s)))\n",
        "        x = p_t_c.T.unsqueeze(0); y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False);\n",
        "        y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T; y2 = y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        acc = y2 if acc is None else (acc + y2)\n",
        "    out = acc / float(len(factors)); return out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def infer_probs_for_sid_from_stack(sid:int, feat_dir: Path, folds_info, model_prefix: str):\n",
        "    # folds_info: list of (train_ids, ) used to compute scalers per fold index\n",
        "    # model_prefix like 'model_ce_fold' or 'model_ce_v3_fold'\n",
        "    X = np.load((feat_dir.parent/'test'/f\"{sid}.npz\"))['X'].astype(np.float32)\n",
        "    acc=None\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "        for fi in range(3):\n",
        "            mean,std = compute_fold_scaler_from_dir(folds[fi]['train_ids'], feat_dir)\n",
        "            mean_t = torch.from_numpy(mean).float().to(device); std_t = torch.from_numpy(std).float().to(device)\n",
        "            for s in (0,1):\n",
        "                ckpt = Path(f\"{model_prefix}{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                if not ckpt.exists(): continue\n",
        "                D_in = np.load(next(iter((feat_dir).glob('*.npz'))))['X'].shape[1]\n",
        "                m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                xb = torch.from_numpy(X).float().to(device); xb = (xb - mean_t)/(std_t+1e-6); xb = xb.unsqueeze(0)\n",
        "                p = m(xb)[0].softmax(dim=-1); p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1))\n",
        "                acc = p if acc is None else (acc + p); del m\n",
        "    probs = acc / float(6); return probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "print('Building blended v2+v3 CE-6x submission...', flush=True)\n",
        "cfg = pd.read_csv('cv_sweep_ce_v2v3_blend.csv').sort_values(['worst','mean']).iloc[0].to_dict() if Path('cv_sweep_ce_v2v3_blend.csv').exists() else {'w':0.7,'pool_k':15,'temp':0.9,'gamma':0.9,'sep':2}\n",
        "w_best=float(cfg['w']); pool_k=int(cfg['pool_k']); temp=float(cfg['temp']); gamma=float(cfg.get('gamma',1.0)); sep=int(cfg.get('sep',2))\n",
        "med_k_all = compute_class_median_durations_for_ids(train_df['Id'].astype(int).tolist())\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    sid=int(sid)\n",
        "    p2 = infer_probs_for_sid_from_stack(sid, feat_v2_tr, folds, 'model_ce_fold')\n",
        "    p3 = infer_probs_for_sid_from_stack(sid, feat_v3_tr, folds, 'model_ce_v3_fold')\n",
        "    p = blend_probs_linear(p2, p3, w_best)\n",
        "    T = p.shape[0]; g_eff = gamma_with_length(gamma, T, med_k_all)\n",
        "    seq = decode_peaks_improved(p, med_k=med_k_all, gamma=g_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "    rows.append({'Id': sid, 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if (i%10)==0 or i==len(test_ids):\n",
        "        print(f\"  [infer CE v2+v3 blend] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "sub.to_csv('submission_primary_ce_v2v3_blend.csv', index=False); sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission_primary_ce_v2v3_blend.csv and submission.csv; head:\\n', sub.head(), flush=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweeping v2-v3 OOF blend...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep v2v3] cfg 8/48 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep v2v3] cfg 16/48 elapsed=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep v2v3] cfg 24/48 elapsed=1.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep v2v3] cfg 32/48 elapsed=1.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep v2v3] cfg 40/48 elapsed=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [sweep v2v3] cfg 48/48 elapsed=1.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top v2-v3 blend OOF (mean,worst,cfg):\n(4.300865800865801, 5.0, {'w': 0.7, 'pool_k': 15, 'temp': 0.9, 'gamma': 0.9, 'sep': 2})\n(4.300865800865801, 5.0, {'w': 0.7, 'pool_k': 15, 'temp': 0.9, 'gamma': 0.9, 'sep': 3})\n(4.300865800865801, 5.0, {'w': 0.7, 'pool_k': 15, 'temp': 0.9, 'gamma': 0.95, 'sep': 2})\n(4.300865800865801, 5.0, {'w': 0.7, 'pool_k': 15, 'temp': 0.9, 'gamma': 0.95, 'sep': 3})\n(4.307463753178038, 5.02, {'w': 0.7, 'pool_k': 11, 'temp': 0.9, 'gamma': 0.9, 'sep': 2})\nSaved cv_sweep_ce_v2v3_blend.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building blended v2+v3 CE-6x submission...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/1227680540.py:197: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE v2+v3 blend] 10/95 elapsed=2.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE v2+v3 blend] 20/95 elapsed=5.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE v2+v3 blend] 30/95 elapsed=8.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE v2+v3 blend] 40/95 elapsed=11.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE v2+v3 blend] 50/95 elapsed=14.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE v2+v3 blend] 60/95 elapsed=17.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE v2+v3 blend] 70/95 elapsed=20.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE v2+v3 blend] 80/95 elapsed=23.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE v2+v3 blend] 90/95 elapsed=25.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer CE v2+v3 blend] 95/95 elapsed=27.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_v2v3_blend.csv and submission.csv; head:\n     Id                                           Sequence\n0  300  3 5 9 19 2 11 18 12 8 10 4 20 13 14 6 16 7 15 ...\n1  301  10 1 5 11 4 6 2 13 19 9 15 7 12 3 18 14 16 20 ...\n2  302  19 1 12 17 16 5 15 13 20 18 3 10 4 6 8 14 7 9 ...\n3  303  11 18 3 13 10 4 5 15 20 1 17 12 16 8 9 7 19 6 ...\n4  304  19 1 12 14 18 10 13 9 7 2 11 3 5 6 15 8 17 16 ...\n"
          ]
        }
      ]
    },
    {
      "id": "a84c9c90-28ba-4896-b860-7bc1827894b3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# P1 (v2-v3): Per-class meta-blend calibration on OOF (fold-safe), tiny grids; refit on all; build test submission\n",
        "import os, json, time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "# Load averaged OOF probs for v2 (ce_new) and v3 (ce_v3)\n",
        "def load_oof_v2_avg(sid:int):\n",
        "    p0 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new.npy\")).to(device)\n",
        "    p1p = probs_cache/f\"{sid}_ce_new_s1.npy\"\n",
        "    p = p0 if not p1p.exists() else (p0 + torch.from_numpy(np.load(p1p)).to(device)) * 0.5\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def load_oof_v3_avg(sid:int):\n",
        "    p0 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_v3.npy\")).to(device)\n",
        "    p1p = probs_cache/f\"{sid}_ce_v3_s1.npy\"\n",
        "    p = p0 if not p1p.exists() else (p0 + torch.from_numpy(np.load(p1p)).to(device)) * 0.5\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "# Per-class operations\n",
        "def apply_per_class_temps(p_t_c: torch.Tensor, T_vec: np.ndarray):\n",
        "    T = torch.from_numpy(T_vec.astype(np.float32)).to(device)  # [C]\n",
        "    exps = 1.0 / (T + 1e-8)\n",
        "    q = torch.pow(torch.clamp(p_t_c, 1e-8, 1.0), exps.unsqueeze(0))\n",
        "    return q / (q.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def blend_geom_perclass(p2: torch.Tensor, p3: torch.Tensor, alpha: np.ndarray):\n",
        "    a = torch.from_numpy(alpha.astype(np.float32)).to(device)\n",
        "    log2 = torch.log(torch.clamp(p2, 1e-8, 1.0)); log3 = torch.log(torch.clamp(p3, 1e-8, 1.0))\n",
        "    q = torch.exp(log2 * a + log3 * (1.0 - a))\n",
        "    return q / (q.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def load_labels(sid:int):\n",
        "    y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "    return torch.from_numpy(y).to(device)\n",
        "\n",
        "def per_frame_nll(p_t_c: torch.Tensor, y_t: torch.Tensor):\n",
        "    m = (y_t >= 0)\n",
        "    if not torch.any(m): return 0.0\n",
        "    idx = y_t[m].long()\n",
        "    return float((-torch.log(torch.clamp(p_t_c[m, idx], 1e-8, 1.0))).mean().item())\n",
        "\n",
        "# Fold-safe fit of per-class T2[c], T3[c], alpha[c] on data excluding the fold\n",
        "T_grid = np.array([0.9, 1.0, 1.1], dtype=np.float32)\n",
        "A_grid = np.array([0.3, 0.5, 0.7], dtype=np.float32)\n",
        "\n",
        "def collect_stream_data(ids, loader_fn):\n",
        "    data = []  # list of (p_t_c, y_t)\n",
        "    for sid in ids:\n",
        "        sid = int(sid)\n",
        "        p = loader_fn(sid); y = load_labels(sid)\n",
        "        data.append((p, y))\n",
        "    return data\n",
        "\n",
        "def fit_per_class_params_excluding_fold(fold_idx:int):\n",
        "    # build training ids = union of other folds' val ids\n",
        "    val_ids_rest = []\n",
        "    for f in folds:\n",
        "        if int(f['fold']) != int(fold_idx):\n",
        "            val_ids_rest.extend(f['val_ids'])\n",
        "    v2_data = collect_stream_data(val_ids_rest, load_oof_v2_avg)\n",
        "    v3_data = collect_stream_data(val_ids_rest, load_oof_v3_avg)\n",
        "    C = v2_data[0][0].shape[1]\n",
        "    T2 = np.ones(C, dtype=np.float32); T3 = np.ones(C, dtype=np.float32); alpha = np.full(C, 0.7, dtype=np.float32)\n",
        "    for c in range(1, C):\n",
        "        # fit T2[c]\n",
        "        best_nll, best_T = 1e9, 1.0\n",
        "        for T in T_grid:\n",
        "            nll_sum = 0.0; cnt = 0\n",
        "            for p, y in v2_data:\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                q = p.clone()\n",
        "                qc = torch.pow(torch.clamp(q[:, c], 1e-8, 1.0), 1.0/float(T)); q[:, c] = qc\n",
        "                q = q / (q.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "                nll_sum += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt += int(m.sum().item())\n",
        "            if cnt > 0:\n",
        "                nll = nll_sum / max(1, cnt)\n",
        "                if nll < best_nll: best_nll, best_T = nll, float(T)\n",
        "        T2[c] = best_T\n",
        "        # fit T3[c]\n",
        "        best_nll, best_T = 1e9, 1.0\n",
        "        for T in T_grid:\n",
        "            nll_sum = 0.0; cnt = 0\n",
        "            for p, y in v3_data:\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                q = p.clone()\n",
        "                qc = torch.pow(torch.clamp(q[:, c], 1e-8, 1.0), 1.0/float(T)); q[:, c] = qc\n",
        "                q = q / (q.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "                nll_sum += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt += int(m.sum().item())\n",
        "            if cnt > 0:\n",
        "                nll = nll_sum / max(1, cnt)\n",
        "                if nll < best_nll: best_nll, best_T = nll, float(T)\n",
        "        T3[c] = best_T\n",
        "        # fit alpha[c]\n",
        "        best_nll, best_a = 1e9, 0.7\n",
        "        # preapply temps once per sample for speed\n",
        "        v2_cal = [apply_per_class_temps(p, T2) for (p, _) in v2_data]\n",
        "        v3_cal = [apply_per_class_temps(p, T3) for (p, _) in v3_data]\n",
        "        for a in A_grid:\n",
        "            nll_sum = 0.0; cnt = 0\n",
        "            for i in range(len(v2_data)):\n",
        "                p2c, y = v2_cal[i], v2_data[i][1]\n",
        "                p3c = v3_cal[i]\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                a_vec = np.full(C, 0.7, dtype=np.float32); a_vec[c] = float(a)\n",
        "                q = blend_geom_perclass(p2c, p3c, a_vec)\n",
        "                nll_sum += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt += int(m.sum().item())\n",
        "            if cnt > 0:\n",
        "                nll = nll_sum / max(1, cnt)\n",
        "                if nll < best_nll: best_nll, best_a = nll, float(a)\n",
        "        alpha[c] = best_a\n",
        "    return T2, T3, alpha\n",
        "\n",
        "# Decoder helpers (reuse improved peak-time) + gamma-with-length\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2); y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k = max(1, int(k)); x = p_t.view(1,1,-1); w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k);\n",
        "    pad = (k-1)//2; y = F.conv1d(x, w, padding=pad).view(-1); T = p_t.shape[0]\n",
        "    if y.shape[0] < T: y = F.pad(y, (0, T - y.shape[0]))\n",
        "    elif y.shape[0] > T: y = y[:T]\n",
        "    return y\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T=p.shape[0]; a=max(0,t_star-w); b=min(T-1,t_star+w); idx=torch.arange(a,b+1, device=p.device, dtype=p.dtype);\n",
        "    seg=p[a:b+1]; s=seg.sum()+1e-8; return float(((idx*seg).sum()/s).item())\n",
        "def decode_peaks_improved(p_t_c: torch.Tensor, med_k: dict, gamma: float = 1.0, pool_k=13, temp=0.9, min_sep=2, K=3, k_delta=4):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c/(p_t_c.sum(dim=-1, keepdim=True)+1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k); T,C = p_s.shape\n",
        "    scores = torch.zeros_like(p_s); ks=[13]*C\n",
        "    for c in range(C):\n",
        "        if c==0: scores[:,c]=p_s[:,c]; ks[c]=13; continue\n",
        "        base_k = med_k.get(c,13); k_c = int(np.clip(round(gamma*base_k), 9, 25));\n",
        "        if k_c % 2 == 0: k_c = min(25, k_c+1); ks[c]=k_c\n",
        "        ks_multi = sorted(set([int(np.clip(k_c-4,9,25)), k_c, int(np.clip(k_c+4,9,25))]));\n",
        "        ks_multi = [k if (k%2)==1 else min(25, k+1) for k in ks_multi]\n",
        "        acc=None\n",
        "        for k in ks_multi:\n",
        "            di = duration_integral_single(p_s[:,c], k=k).unsqueeze(1); acc = di if acc is None else (acc + di)\n",
        "        scores[:,c] = (acc/float(len(ks_multi))).squeeze(1)\n",
        "    peaks=[]; last_t=-1e9\n",
        "    for c in range(1,21):\n",
        "        k=ks[c]; s=scores[:,c]; t_star=int(torch.argmax(s).item());\n",
        "        w_com=max(5,k//3); radius=max(10,k//2); t_ref = refine_com(p_s[:,c], t_star, w=w_com)\n",
        "        t_idx=int(round(max(0,min(t_ref,T-1))))\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        pooled_at_ref = p_s[t_idx, c].item()\n",
        "        peaks.append([c, t_ref, float(scores[t_idx,c].item()), float(local_mean), float(pooled_at_ref)])\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3], -x[4]))\n",
        "    for i in range(len(peaks)):\n",
        "        if peaks[i][1] <= last_t + float(min_sep): peaks[i][1] = last_t + float(min_sep)\n",
        "        last_t = min(peaks[i][1], float(T-1))\n",
        "    return [int(c) for c,_,_,_,_ in peaks]\n",
        "\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {};\n",
        "    for c in range(1,21):\n",
        "        m = np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13\n",
        "        med[c] = int(np.clip(m, 9, 25))\n",
        "    return med\n",
        "\n",
        "def gamma_with_length(gamma_cv: float, T: int, med_k: dict):\n",
        "    L_est = float(sum(med_k.get(c,13) for c in range(1,21)))\n",
        "    if L_est <= 0: return gamma_cv\n",
        "    ratio = float(T) / L_est; gamma_s = float(np.clip(ratio, 0.85, 1.15)); return float(gamma_cv * gamma_s)\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# Sweep tiny decoder grid on calibrated per-fold OOF with per-class meta-blend\n",
        "pool_ks=[13,15]; temps=[0.90]; gammas=[0.90,0.95]; seps=[2]\n",
        "print('Fitting per-class T2/T3/alpha per fold (fold-safe)...', flush=True)\n",
        "calib_by_fold = {}  # fold_idx -> dict\n",
        "for f in folds:\n",
        "    fi = int(f['fold'])\n",
        "    T2, T3, A = fit_per_class_params_excluding_fold(fi)\n",
        "    calib_by_fold[fi] = {'T2': T2.tolist(), 'T3': T3.tolist(), 'A': A.tolist()}\n",
        "\n",
        "print('Sweeping decoder on calibrated v2+v3 OOF meta-blend...', flush=True)\n",
        "res=[]; med_cache={}\n",
        "for pool_k in pool_ks:\n",
        "    for temp in temps:\n",
        "        for gamma in gammas:\n",
        "            for sep in seps:\n",
        "                per_fold=[]\n",
        "                for f in folds:\n",
        "                    fi = int(f['fold'])\n",
        "                    if fi not in med_cache: med_cache[fi] = compute_class_median_durations_for_ids(f['train_ids'])\n",
        "                    med_k = med_cache[fi]\n",
        "                    T2 = np.array(calib_by_fold[fi]['T2'], dtype=np.float32)\n",
        "                    T3 = np.array(calib_by_fold[fi]['T3'], dtype=np.float32)\n",
        "                    A  = np.array(calib_by_fold[fi]['A'],  dtype=np.float32)\n",
        "                    vids = f['val_ids']; tot=0; cnt=0\n",
        "                    for sid in vids:\n",
        "                        sid=int(sid); p2 = load_oof_v2_avg(sid); p3 = load_oof_v3_avg(sid)\n",
        "                        q2 = apply_per_class_temps(p2, T2); q3 = apply_per_class_temps(p3, T3)\n",
        "                        q = blend_geom_perclass(q2, q3, A)\n",
        "                        Tlen = q.shape[0]; g_eff = gamma_with_length(gamma, Tlen, med_k)\n",
        "                        seq = decode_peaks_improved(q, med_k=med_k, gamma=g_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "                        tot += levenshtein(seq, id2seq[sid]); cnt += 1\n",
        "                    per_fold.append(tot/max(cnt,1))\n",
        "                res.append((float(np.mean(per_fold)), float(np.max(per_fold)), {'pool_k':pool_k,'temp':temp,'gamma':gamma,'sep':sep}))\n",
        "res.sort(key=lambda x: (x[1], x[0]))\n",
        "print('Top v2-v3 meta-blend OOF (mean,worst,cfg):')\n",
        "for r in res[:5]: print(r)\n",
        "pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res]).to_csv('cv_sweep_ce_v2v3_meta.csv', index=False)\n",
        "print('Saved cv_sweep_ce_v2v3_meta.csv', flush=True)\n",
        "\n",
        "# Refit per-class T2/T3/alpha on ALL OOF (train) for test-time\n",
        "def refit_on_all():\n",
        "    all_ids = train_df['Id'].astype(int).tolist()\n",
        "    v2_data = collect_stream_data(all_ids, load_oof_v2_avg)\n",
        "    v3_data = collect_stream_data(all_ids, load_oof_v3_avg)\n",
        "    C = v2_data[0][0].shape[1]\n",
        "    T2 = np.ones(C, dtype=np.float32); T3 = np.ones(C, dtype=np.float32); A = np.full(C, 0.7, dtype=np.float32)\n",
        "    for c in range(1, C):\n",
        "        best_nll, best_T = 1e9, 1.0\n",
        "        for T in T_grid:\n",
        "            nll_sum=0.0; cnt=0\n",
        "            for p,y in v2_data:\n",
        "                m = (y==c);\n",
        "                if not torch.any(m): continue\n",
        "                q = p.clone(); qc = torch.pow(torch.clamp(q[:, c], 1e-8, 1.0), 1.0/float(T)); q[:, c] = qc; q = q/(q.sum(dim=-1, keepdim=True)+1e-8)\n",
        "                nll_sum += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt += int(m.sum().item())\n",
        "            if cnt>0 and (nll_sum/max(1,cnt)) < best_nll: best_nll, best_T = nll_sum/max(1,cnt), float(T)\n",
        "        T2[c] = best_T\n",
        "        best_nll, best_T = 1e9, 1.0\n",
        "        for T in T_grid:\n",
        "            nll_sum=0.0; cnt=0\n",
        "            for p,y in v3_data:\n",
        "                m = (y==c);\n",
        "                if not torch.any(m): continue\n",
        "                q = p.clone(); qc = torch.pow(torch.clamp(q[:, c], 1e-8, 1.0), 1.0/float(T)); q[:, c] = qc; q = q/(q.sum(dim=-1, keepdim=True)+1e-8)\n",
        "                nll_sum += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt += int(m.sum().item())\n",
        "            if cnt>0 and (nll_sum/max(1,cnt)) < best_nll: best_nll, best_T = nll_sum/max(1,cnt), float(T)\n",
        "        T3[c] = best_T\n",
        "        # preapply\n",
        "        v2_cal = [apply_per_class_temps(p2, T2) for (p2,_) in v2_data]\n",
        "        v3_cal = [apply_per_class_temps(p3, T3) for (p3,_) in v3_data]\n",
        "        best_nll, best_a = 1e9, 0.7\n",
        "        for a in A_grid:\n",
        "            nll_sum=0.0; cnt=0\n",
        "            for i in range(len(v2_data)):\n",
        "                y = v2_data[i][1]; m = (y==c)\n",
        "                if not torch.any(m): continue\n",
        "                a_vec = np.full(C, 0.7, dtype=np.float32); a_vec[c] = float(a)\n",
        "                q = blend_geom_perclass(v2_cal[i], v3_cal[i], a_vec)\n",
        "                nll_sum += per_frame_nll(q[m], y[m]) * int(m.sum().item()); cnt += int(m.sum().item())\n",
        "            if cnt>0 and (nll_sum/max(1,cnt)) < best_nll: best_nll, best_a = nll_sum/max(1,cnt), float(a)\n",
        "        A[c] = best_a\n",
        "    return T2, T3, A\n",
        "\n",
        "# Test-time inference: infer probs for v2 and v3 stacks, apply per-class temps and alpha, then decode\n",
        "from math import ceil\n",
        "feat_v2_tr = Path('features3d_v2')/'train'; feat_v3_tr = Path('features3d_v3')/'train'\n",
        "feat_v2_te = Path('features3d_v2')/'test'; feat_v3_te = Path('features3d_v3')/'test'\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__(); self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation);\n",
        "        self.gn1 = nn.GroupNorm(groups, ch); self.drop = nn.Dropout(drop); self.conv2 = nn.Conv1d(ch, ch, 1); self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h); h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True); return x + h\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__(); self.inp = nn.Conv1d(d_in, channels, 1); blocks=[]; dil=1\n",
        "        for _ in range(layers): blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3)); dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks); self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2); h = self.inp(x);\n",
        "        for b in self.blocks: h = b(h); out = self.head(h); return out.transpose(1,2)\n",
        "\n",
        "def compute_fold_scaler_from_dir(id_list, feat_dir: Path):\n",
        "    n=0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = np.load(feat_dir/f\"{int(sid)}.npz\")[\"X\"].astype(np.float32); n_i = X.shape[0]\n",
        "        if mean is None: mean = X.mean(axis=0); M2 = ((X - mean)**2).sum(axis=0); n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0); n_new = n + n_i; delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new));\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new)); n = n_new\n",
        "    var = M2 / max(1, (n - 1)); std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        T,C = p_t_c.shape; tgt_len = max(1, int(round(T*s)))\n",
        "        x = p_t_c.T.unsqueeze(0); y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False); y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T\n",
        "        y2 = y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8); acc = y2 if acc is None else (acc + y2)\n",
        "    out = acc / float(len(factors)); return out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def infer_probs_for_sid_from_stack(sid:int, feat_tr_dir: Path, model_prefix: str):\n",
        "    X = np.load((feat_tr_dir.parent/'test'/f\"{sid}.npz\"))['X'].astype(np.float32)\n",
        "    acc=None\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "        for fi in range(3):\n",
        "            mean,std = compute_fold_scaler_from_dir(folds[fi]['train_ids'], feat_tr_dir)\n",
        "            mean_t = torch.from_numpy(mean).float().to(device); std_t = torch.from_numpy(std).float().to(device)\n",
        "            D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "            for s in (0,1):\n",
        "                ckpt = Path(f\"{model_prefix}{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                if not ckpt.exists(): continue\n",
        "                m = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                xb = torch.from_numpy(X).float().to(device); xb = (xb - mean_t)/(std_t+1e-6); xb = xb.unsqueeze(0)\n",
        "                p = m(xb)[0].softmax(dim=-1); p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1))\n",
        "                acc = p if acc is None else (acc + p); del m\n",
        "    probs = acc / float(6); return probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "# Choose best decoder cfg by worst-fold then mean\n",
        "cfg_df = pd.read_csv('cv_sweep_ce_v2v3_meta.csv').sort_values(['worst','mean']) if Path('cv_sweep_ce_v2v3_meta.csv').exists() else None\n",
        "if cfg_df is None or len(cfg_df)==0:\n",
        "    best_cfg = {'pool_k':15,'temp':0.90,'gamma':0.90,'sep':2}\n",
        "else:\n",
        "    best_cfg = cfg_df.iloc[0].to_dict()\n",
        "pool_k=int(best_cfg.get('pool_k',15)); temp=float(best_cfg.get('temp',0.90)); gamma=float(best_cfg.get('gamma',0.90)); sep=int(best_cfg.get('sep',2))\n",
        "print('Chosen meta-blend decoder cfg:', {'pool_k':pool_k,'temp':temp,'gamma':gamma,'sep':sep}, flush=True)\n",
        "\n",
        "print('Refitting per-class T2/T3/alpha on ALL OOF ...', flush=True)\n",
        "T2_all, T3_all, A_all = refit_on_all()\n",
        "Path('calib_all_v2v3_meta.json').write_text(json.dumps({'T2': T2_all.tolist(), 'T3': T3_all.tolist(), 'A': A_all.tolist()}))\n",
        "\n",
        "print('Building v2+v3 per-class meta-blend submission...', flush=True)\n",
        "med_k_all = compute_class_median_durations_for_ids(train_df['Id'].astype(int).tolist())\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    sid=int(sid)\n",
        "    p2 = infer_probs_for_sid_from_stack(sid, feat_v2_tr, 'model_ce_fold')\n",
        "    p3 = infer_probs_for_sid_from_stack(sid, feat_v3_tr, 'model_ce_v3_fold')\n",
        "    q2 = apply_per_class_temps(p2, T2_all); q3 = apply_per_class_temps(p3, T3_all)\n",
        "    q = blend_geom_perclass(q2, q3, A_all)\n",
        "    Tlen = q.shape[0]; g_eff = gamma_with_length(gamma, Tlen, med_k_all)\n",
        "    seq = decode_peaks_improved(q, med_k=med_k_all, gamma=g_eff, pool_k=pool_k, temp=temp, min_sep=sep, K=3, k_delta=4)\n",
        "    rows.append({'Id': sid, 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if (i%10)==0 or i==len(test_ids):\n",
        "        print(f\"  [infer v2v3 meta] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "sub.to_csv('submission_primary_ce_v2v3_meta.csv', index=False)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission_primary_ce_v2v3_meta.csv and submission.csv; head:\\n', sub.head(), flush=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting per-class T2/T3/alpha per fold (fold-safe)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweeping decoder on calibrated v2+v3 OOF meta-blend...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top v2-v3 meta-blend OOF (mean,worst,cfg):\n(4.3069511440940005, 5.06, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.9, 'sep': 2})\n(4.3069511440940005, 5.06, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.95, 'sep': 2})\n(4.310318147461004, 5.06, {'pool_k': 13, 'temp': 0.9, 'gamma': 0.9, 'sep': 2})\n(4.310318147461004, 5.06, {'pool_k': 13, 'temp': 0.9, 'gamma': 0.95, 'sep': 2})\nSaved cv_sweep_ce_v2v3_meta.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen meta-blend decoder cfg: {'pool_k': 15, 'temp': 0.9, 'gamma': 0.9, 'sep': 2}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refitting per-class T2/T3/alpha on ALL OOF ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building v2+v3 per-class meta-blend submission...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/2422935404.py:336: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta] 10/95 elapsed=2.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta] 20/95 elapsed=5.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta] 30/95 elapsed=8.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta] 40/95 elapsed=11.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta] 50/95 elapsed=14.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta] 60/95 elapsed=17.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta] 70/95 elapsed=20.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta] 80/95 elapsed=22.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta] 90/95 elapsed=25.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta] 95/95 elapsed=27.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_v2v3_meta.csv and submission.csv; head:\n     Id                                           Sequence\n0  300  3 5 9 19 2 11 18 12 8 10 4 20 13 14 6 16 7 15 ...\n1  301  10 1 5 11 4 6 2 13 19 9 15 7 12 3 18 14 16 20 ...\n2  302  19 1 12 17 16 5 15 13 20 18 3 10 4 6 8 14 7 9 ...\n3  303  11 18 3 13 10 4 5 15 20 1 17 12 16 8 9 7 19 6 ...\n4  304  3 1 12 14 18 10 13 9 7 2 11 19 5 6 15 8 17 16 ...\n"
          ]
        }
      ]
    },
    {
      "id": "85d4025c-c663-4376-a454-badd3eb1cae9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# P1+Decoder++: v2-v3 per-class meta-blend + local-search with reinsertion; tiny OOF sweep; refit-all; build test submission\n",
        "import os, json, time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "train_df = pd.read_csv('training.csv')\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "# Streams: OOF loaders\n",
        "def load_oof_v2_avg(sid:int):\n",
        "    p0 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_new.npy\")).to(device)\n",
        "    p1p = probs_cache/f\"{sid}_ce_new_s1.npy\"\n",
        "    p = p0 if not p1p.exists() else (p0 + torch.from_numpy(np.load(p1p)).to(device)) * 0.5\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "def load_oof_v3_avg(sid:int):\n",
        "    p0 = torch.from_numpy(np.load(probs_cache/f\"{sid}_ce_v3.npy\")).to(device)\n",
        "    p1p = probs_cache/f\"{sid}_ce_v3_s1.npy\"\n",
        "    p = p0 if not p1p.exists() else (p0 + torch.from_numpy(np.load(p1p)).to(device)) * 0.5\n",
        "    return p / (p.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "# Per-class temps and geometric per-class blend\n",
        "def apply_per_class_temps(p_t_c: torch.Tensor, T_vec: np.ndarray):\n",
        "    T = torch.from_numpy(T_vec.astype(np.float32)).to(device)\n",
        "    q = torch.pow(torch.clamp(p_t_c, 1e-8, 1.0), (1.0/(T+1e-8)).unsqueeze(0))\n",
        "    return q / (q.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "def blend_geom_perclass(p2: torch.Tensor, p3: torch.Tensor, alpha: np.ndarray):\n",
        "    a = torch.from_numpy(alpha.astype(np.float32)).to(device)\n",
        "    q = torch.exp(torch.log(torch.clamp(p2,1e-8,1.0))*a + torch.log(torch.clamp(p3,1e-8,1.0))*(1.0-a))\n",
        "    return q / (q.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "def load_labels(sid:int):\n",
        "    return torch.from_numpy(np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int64)).to(device)\n",
        "\n",
        "def per_frame_nll(p_t_c: torch.Tensor, y_t: torch.Tensor):\n",
        "    m = (y_t >= 0)\n",
        "    if not torch.any(m): return 0.0\n",
        "    idx = y_t[m].long()\n",
        "    return float((-torch.log(torch.clamp(p_t_c[m, idx], 1e-8, 1.0))).mean().item())\n",
        "\n",
        "T_grid = np.array([0.9, 1.0, 1.1], dtype=np.float32)\n",
        "A_grid = np.array([0.3, 0.5, 0.7], dtype=np.float32)\n",
        "\n",
        "def collect_stream_data(ids, loader_fn):\n",
        "    data=[]\n",
        "    for sid in ids:\n",
        "        sid=int(sid); p=loader_fn(sid); y=load_labels(sid); data.append((p,y))\n",
        "    return data\n",
        "\n",
        "def fit_per_class_params_excluding_fold(fold_idx:int):\n",
        "    ids=[]\n",
        "    for f in folds:\n",
        "        if int(f['fold'])!=int(fold_idx): ids.extend(f['val_ids'])\n",
        "    v2 = collect_stream_data(ids, load_oof_v2_avg)\n",
        "    v3 = collect_stream_data(ids, load_oof_v3_avg)\n",
        "    C = v2[0][0].shape[1]\n",
        "    T2=np.ones(C, np.float32); T3=np.ones(C, np.float32); A=np.full(C, 0.7, np.float32)\n",
        "    for c in range(1, C):\n",
        "        # T2\n",
        "        best=(1e9,1.0)\n",
        "        for T in T_grid:\n",
        "            s=0.0; n=0\n",
        "            for p,y in v2:\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                q=p.clone(); q[:,c]=torch.pow(torch.clamp(q[:,c],1e-8,1.0), 1.0/float(T)); q=q/(q.sum(dim=-1,keepdim=True)+1e-8)\n",
        "                s += per_frame_nll(q[m], y[m]) * int(m.sum().item()); n += int(m.sum().item())\n",
        "            if n>0:\n",
        "                val = s/max(1,n)\n",
        "                if val<best[0]:\n",
        "                    best=(val,float(T))\n",
        "        T2[c]=best[1]\n",
        "        # T3\n",
        "        best=(1e9,1.0)\n",
        "        for T in T_grid:\n",
        "            s=0.0; n=0\n",
        "            for p,y in v3:\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                q=p.clone(); q[:,c]=torch.pow(torch.clamp(q[:,c],1e-8,1.0), 1.0/float(T)); q=q/(q.sum(dim=-1,keepdim=True)+1e-8)\n",
        "                s += per_frame_nll(q[m], y[m]) * int(m.sum().item()); n += int(m.sum().item())\n",
        "            if n>0:\n",
        "                val = s/max(1,n)\n",
        "                if val<best[0]:\n",
        "                    best=(val,float(T))\n",
        "        T3[c]=best[1]\n",
        "        # A[c]\n",
        "        v2c=[apply_per_class_temps(p,T2) for (p,_) in v2]\n",
        "        v3c=[apply_per_class_temps(p,T3) for (p,_) in v3]\n",
        "        best=(1e9,0.7)\n",
        "        for a in A_grid:\n",
        "            s=0.0; n=0\n",
        "            for i in range(len(v2)):\n",
        "                y = v2[i][1]\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                a_vec=np.full(C,0.7,np.float32); a_vec[c]=float(a)\n",
        "                q=blend_geom_perclass(v2c[i], v3c[i], a_vec)\n",
        "                s += per_frame_nll(q[m], y[m]) * int(m.sum().item()); n += int(m.sum().item())\n",
        "            if n>0:\n",
        "                val = s/max(1,n)\n",
        "                if val<best[0]:\n",
        "                    best=(val,float(a))\n",
        "        A[c]=best[1]\n",
        "    return T2,T3,A\n",
        "\n",
        "# Decoder helpers\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    x=p_t_c.unsqueeze(0).transpose(1,2); y=F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2);\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "def duration_integral_single(p_t: torch.Tensor, k:int) -> torch.Tensor:\n",
        "    k=max(1,int(k)); x=p_t.view(1,1,-1); w=torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype)/float(k);\n",
        "    pad=(k-1)//2; y=F.conv1d(x,w,padding=pad).view(-1); T=p_t.shape[0]\n",
        "    if y.shape[0]<T: y=F.pad(y,(0,T-y.shape[0]))\n",
        "    elif y.shape[0]>T: y=y[:T]\n",
        "    return y\n",
        "def refine_com(p: torch.Tensor, t_star:int, w:int=5) -> float:\n",
        "    T=p.shape[0]; a=max(0,t_star-w); b=min(T-1,t_star+w); idx=torch.arange(a,b+1, device=p.device, dtype=p.dtype);\n",
        "    seg=p[a:b+1]; s=seg.sum()+1e-8; return float(((idx*seg).sum()/s).item())\n",
        "def compute_class_median_durations_for_ids(id_list):\n",
        "    dur={c:[] for c in range(1,21)}\n",
        "    for sid in id_list:\n",
        "        y=np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt=int((y==c).sum());\n",
        "            if cnt>0: dur[c].append(cnt)\n",
        "    med={}\n",
        "    for c in range(1,21):\n",
        "        m=np.median(dur[c]) if len(dur[c])>0 else 13; med[c]=int(np.clip(m,9,25))\n",
        "    return med\n",
        "def gamma_with_length(gamma_cv: float, T: int, med_k: dict):\n",
        "    L=float(sum(med_k.get(c,13) for c in range(1,21)));\n",
        "    if L<=0: return gamma_cv\n",
        "    ratio=float(T)/L; g=float(np.clip(ratio,0.85,1.15)); return float(gamma_cv*g)\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# Order prior from training sequences (robust to missing classes)\n",
        "def build_order_prior(train_df):\n",
        "    cnt=np.zeros((21,21),dtype=np.int64); tot=np.zeros((21,21),dtype=np.int64)\n",
        "    for seq in train_df['Sequence'].astype(str).tolist():\n",
        "        s=[int(x) for x in seq.strip().split() if x.isdigit()]; s=[x for x in s if 1<=x<=20]\n",
        "        n=len(s)\n",
        "        for i in range(n):\n",
        "            a=s[i]\n",
        "            for j in range(i+1,n):\n",
        "                b=s[j]\n",
        "                if a==b: continue\n",
        "                cnt[a,b]+=1; tot[a,b]+=1\n",
        "    P=np.zeros((21,21),dtype=np.float32)\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        P=np.where(tot>0, cnt/np.maximum(1, tot), 0.5)\n",
        "    np.fill_diagonal(P,0.5)\n",
        "    return P\n",
        "P_order = build_order_prior(train_df)\n",
        "\n",
        "# Build blended calibrated probs for a sid given fold-safe T2/T3/A\n",
        "def blended_q_for_sid(sid:int, T2: np.ndarray, T3: np.ndarray, A: np.ndarray):\n",
        "    p2 = load_oof_v2_avg(sid); p3 = load_oof_v3_avg(sid)\n",
        "    q2 = apply_per_class_temps(p2, T2); q3 = apply_per_class_temps(p3, T3)\n",
        "    return blend_geom_perclass(q2, q3, A)\n",
        "\n",
        "# Local-search with adjacent swap + reinsertion\n",
        "def build_scoring(p_t_c: torch.Tensor, med_k: dict, pool_k:int, gamma: float, temp: float, k_delta:int=4):\n",
        "    if temp!=1.0:\n",
        "        p_t_c=(torch.clamp(p_t_c,1e-8,1.0)**(1.0/temp)); p_t_c=p_t_c/(p_t_c.sum(dim=-1,keepdim=True)+1e-8)\n",
        "    p_s=avg_pool_probs(p_t_c, k=pool_k); T,C=p_s.shape\n",
        "    di=torch.zeros_like(p_s); ks=[13]*C\n",
        "    for c in range(C):\n",
        "        if c==0: di[:,c]=p_s[:,c]; ks[c]=13; continue\n",
        "        base=med_k.get(c,13); k_c=int(np.clip(round(gamma*base),9,25));\n",
        "        if (k_c%2)==0: k_c=min(25,k_c+1); ks[c]=k_c\n",
        "        ks_multi=sorted(set([int(np.clip(k_c-k_delta,9,25)), k_c, int(np.clip(k_c+k_delta,9,25))]));\n",
        "        ks_multi=[k if (k%2)==1 else min(25,k+1) for k in ks_multi]\n",
        "        acc=None\n",
        "        for k in ks_multi:\n",
        "            x=duration_integral_single(p_s[:,c], k=k).unsqueeze(1); acc=x if acc is None else (acc+x)\n",
        "        di[:,c]=(acc/float(len(ks_multi))).squeeze(1)\n",
        "    mu=di.mean(dim=0,keepdim=True); sd=di.std(dim=0,keepdim=True)+1e-8; z=(di-mu)/sd\n",
        "    logp=torch.log(torch.clamp(p_s,1e-8,1.0))\n",
        "    return p_s, di, z, logp, ks\n",
        "\n",
        "def initial_assignment(p_s, z, logp, ks, beta: float, min_sep:int):\n",
        "    T,C=p_s.shape; items=[]\n",
        "    for c in range(1,21):\n",
        "        s_vec = logp[:,c] + beta*z[:,c]\n",
        "        t_star=int(torch.argmax(s_vec).item())\n",
        "        w_com=max(5, ks[c]//3); t_ref=refine_com(p_s[:,c], t_star, w=w_com)\n",
        "        t_idx=max(0,min(int(round(t_ref)), T-1))\n",
        "        score=float(s_vec[t_idx].item())\n",
        "        items.append([float(t_ref), int(c), score])\n",
        "    items.sort(key=lambda x: x[0])\n",
        "    last=-1e9\n",
        "    for it in items:\n",
        "        if it[0] <= last + float(min_sep): it[0]=last+float(min_sep)\n",
        "        last=min(it[0], float(T-1))\n",
        "    return items  # list of [t, c, s]\n",
        "\n",
        "def objective_S(items, beta: float, lambda_ord: float, lambda_len: float, exp_gap: dict):\n",
        "    S=0.0\n",
        "    n=len(items)\n",
        "    # main per-(t,c) score already stored\n",
        "    for _,_,sct in items: S += float(sct)\n",
        "    # order prior\n",
        "    if lambda_ord>0:\n",
        "        for i in range(n):\n",
        "            ci=items[i][1]\n",
        "            for j in range(i+1,n):\n",
        "                cj=items[j][1]\n",
        "                pij=float(P_order[ci, cj]) if 1<=ci<=20 and 1<=cj<=20 else 0.5\n",
        "                S -= lambda_ord * (1.0 - pij)\n",
        "    # duration (gap) penalty\n",
        "    if lambda_len>0 and n>1:\n",
        "        for i in range(1,n):\n",
        "            t_i=items[i][0]; t_im1=items[i-1][0]; ci=items[i][1]\n",
        "            gap=max(1.0, float(t_i - t_im1))\n",
        "            eg=max(1.0, float(exp_gap.get(ci, 13.0)))\n",
        "            S -= lambda_len * abs(gap - eg) / eg\n",
        "    return S\n",
        "\n",
        "def s_at(c:int, t:float, logp, z, beta: float):\n",
        "    T=logp.shape[0]; t_idx=max(0,min(int(round(t)), T-1))\n",
        "    return float((logp[t_idx, c] + beta * z[t_idx, c]).item())\n",
        "\n",
        "def hill_climb_with_reinsertion(items, p_s, z, logp, ks, beta: float, lambda_ord: float, lambda_len: float, exp_gap: dict, max_passes:int=4):\n",
        "    improved=True; passes=0\n",
        "    while improved and passes<max_passes:\n",
        "        improved=False; passes+=1\n",
        "        # 1) adjacent swaps pass\n",
        "        i=0\n",
        "        S_base = objective_S(items, beta, lambda_ord, lambda_len, exp_gap)\n",
        "        while i < len(items)-1:\n",
        "            t_i, c_i, s_i = items[i]; t_j, c_j, s_j = items[i+1]\n",
        "            # swap classes (times fixed)\n",
        "            s_i_new = s_at(c_j, t_i, logp, z, beta); s_j_new = s_at(c_i, t_j, logp, z, beta)\n",
        "            items[i][1]=c_j; items[i][2]=s_i_new\n",
        "            items[i+1][1]=c_i; items[i+1][2]=s_j_new\n",
        "            S_new = objective_S(items, beta, lambda_ord, lambda_len, exp_gap)\n",
        "            if S_new + 1e-9 >= S_base:\n",
        "                improved = improved or (S_new > S_base + 1e-6); S_base = S_new\n",
        "            else:\n",
        "                # revert\n",
        "                items[i][1]=c_i; items[i][2]=s_i\n",
        "                items[i+1][1]=c_j; items[i+1][2]=s_j\n",
        "            i+=1\n",
        "        # 2) reinsertion moves (i -> i\u00b11, i\u00b12)\n",
        "        changed=True; iter_lim=2\n",
        "        while changed and iter_lim>0:\n",
        "            changed=False; iter_lim-=1\n",
        "            S_base = objective_S(items, beta, lambda_ord, lambda_len, exp_gap)\n",
        "            n=len(items)\n",
        "            for i in range(n):\n",
        "                for d in (-2,-1,1,2):\n",
        "                    j=i+d\n",
        "                    if j<0 or j>=n or j==i: continue\n",
        "                    # remove item i and insert at j\n",
        "                    it=items.pop(i)\n",
        "                    items.insert(j, it)\n",
        "                    # recompute s at affected positions i..j range\n",
        "                    a=min(i,j); b=max(i,j)\n",
        "                    for k in range(a, b+1):\n",
        "                        t_k, c_k, _ = items[k]\n",
        "                        items[k][2] = s_at(c_k, t_k, logp, z, beta)\n",
        "                    S_new = objective_S(items, beta, lambda_ord, lambda_len, exp_gap)\n",
        "                    if S_new + 1e-9 >= S_base:\n",
        "                        changed = changed or (S_new > S_base + 1e-6); S_base = S_new\n",
        "                    else:\n",
        "                        # revert reinsertion\n",
        "                        it2=items.pop(j); items.insert(i, it2)\n",
        "            improved = improved or changed\n",
        "    return items\n",
        "\n",
        "def decode_localsrch_meta(q: torch.Tensor, med_k: dict, gamma: float, pool_k:int, temp: float, min_sep:int, beta: float, lambda_ord: float, lambda_len: float):\n",
        "    p_s, di, z, logp, ks = build_scoring(q, med_k, pool_k, gamma, temp, k_delta=4)\n",
        "    items = initial_assignment(p_s, z, logp, ks, beta=beta, min_sep=min_sep)\n",
        "    # expected gaps by class\n",
        "    exp_gap={c: float(np.clip(round(gamma*med_k.get(c,13)), 3, 30)) for c in range(1,21)}\n",
        "    items = hill_climb_with_reinsertion(items, p_s, z, logp, ks, beta, lambda_ord, lambda_len, exp_gap, max_passes=4)\n",
        "    seq = [int(c) for (_,c,_) in items]\n",
        "    if len(set(seq))<20:\n",
        "        seen=set(); out=[]\n",
        "        for c in seq:\n",
        "            if c in seen: continue\n",
        "            seen.add(c); out.append(c)\n",
        "        for c in range(1,21):\n",
        "            if c not in seen: out.append(c)\n",
        "        seq=out[:20]\n",
        "    return seq\n",
        "\n",
        "# Tiny OOF sweep over localsrch params (fold-safe T2/T3/A), select by worst then mean\n",
        "print('Fitting per-class T2/T3/alpha per fold (fold-safe) for local-search...', flush=True)\n",
        "calib_by_fold={}\n",
        "for f in folds:\n",
        "    fi=int(f['fold'])\n",
        "    T2,T3,A = fit_per_class_params_excluding_fold(fi)\n",
        "    calib_by_fold[fi]={'T2':T2.tolist(),'T3':T3.tolist(),'A':A.tolist()}\n",
        "\n",
        "pool_k=15; temps=[0.90]; gammas=[0.90,0.95]; seps=[2,3]; betas=[0.4,0.5]; lords=[0.03]; llens=[0.15,0.25]\n",
        "print('Sweeping localsrch (reinsertion) on v2+v3 calibrated OOF...', flush=True)\n",
        "res=[]\n",
        "for temp in temps:\n",
        "  for gamma in gammas:\n",
        "    for sep in seps:\n",
        "      for beta in betas:\n",
        "        for l_ord in lords:\n",
        "          for l_len in llens:\n",
        "            per_fold=[]\n",
        "            for f in folds:\n",
        "                fi=int(f['fold'])\n",
        "                T2=np.array(calib_by_fold[fi]['T2'], np.float32); T3=np.array(calib_by_fold[fi]['T3'], np.float32); A=np.array(calib_by_fold[fi]['A'], np.float32)\n",
        "                med_k = compute_class_median_durations_for_ids(f['train_ids'])\n",
        "                vids=f['val_ids']; tot=0; cnt=0\n",
        "                for sid in vids:\n",
        "                    sid=int(sid); q = blended_q_for_sid(sid, T2, T3, A); Tlen=q.shape[0]\n",
        "                    g_eff = gamma_with_length(gamma, Tlen, med_k)\n",
        "                    seq = decode_localsrch_meta(q, med_k=med_k, gamma=g_eff, pool_k=pool_k, temp=temp, min_sep=sep, beta=beta, lambda_ord=l_ord, lambda_len=l_len)\n",
        "                    tot += levenshtein(seq, id2seq[sid]); cnt += 1\n",
        "                per_fold.append(tot/max(cnt,1))\n",
        "            res.append((float(np.mean(per_fold)), float(np.max(per_fold)), {'pool_k':pool_k,'temp':temp,'gamma':gamma,'sep':sep,'beta':beta,'lambda_ord':l_ord,'lambda_len':l_len}))\n",
        "res.sort(key=lambda x: (x[1], x[0]))\n",
        "print('Top localsrch-meta (mean,worst,cfg):')\n",
        "for r in res[:5]: print(r)\n",
        "pd.DataFrame([{'mean':m,'worst':w, **cfg} for m,w,cfg in res]).to_csv('cv_sweep_ce_v2v3_meta_localsrch.csv', index=False)\n",
        "print('Saved cv_sweep_ce_v2v3_meta_localsrch.csv', flush=True)\n",
        "\n",
        "# Refit T2/T3/A on ALL OOF (train) for test-time\n",
        "def refit_on_all():\n",
        "    ids=train_df['Id'].astype(int).tolist()\n",
        "    v2=collect_stream_data(ids, load_oof_v2_avg); v3=collect_stream_data(ids, load_oof_v3_avg)\n",
        "    C=v2[0][0].shape[1]\n",
        "    T2=np.ones(C,np.float32); T3=np.ones(C,np.float32); A=np.full(C,0.7,np.float32)\n",
        "    for c in range(1,C):\n",
        "        best=(1e9,1.0)\n",
        "        for T in T_grid:\n",
        "            s=0.0; n=0\n",
        "            for p,y in v2:\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                q=p.clone(); q[:,c]=torch.pow(torch.clamp(q[:,c],1e-8,1.0), 1.0/float(T)); q=q/(q.sum(dim=-1,keepdim=True)+1e-8)\n",
        "                s += per_frame_nll(q[m], y[m]) * int(m.sum().item()); n += int(m.sum().item())\n",
        "            if n>0:\n",
        "                val = s/max(1,n)\n",
        "                if val<best[0]:\n",
        "                    best=(val,float(T))\n",
        "        T2[c]=best[1]\n",
        "        best=(1e9,1.0)\n",
        "        for T in T_grid:\n",
        "            s=0.0; n=0\n",
        "            for p,y in v3:\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                q=p.clone(); q[:,c]=torch.pow(torch.clamp(q[:,c],1e-8,1.0), 1.0/float(T)); q=q/(q.sum(dim=-1,keepdim=True)+1e-8)\n",
        "                s += per_frame_nll(q[m], y[m]) * int(m.sum().item()); n += int(m.sum().item())\n",
        "            if n>0:\n",
        "                val = s/max(1,n)\n",
        "                if val<best[0]:\n",
        "                    best=(val,float(T))\n",
        "        T3[c]=best[1]\n",
        "        v2c=[apply_per_class_temps(p,T2) for (p,_) in v2]; v3c=[apply_per_class_temps(p,T3) for (p,_) in v3]\n",
        "        best=(1e9,0.7)\n",
        "        for a in A_grid:\n",
        "            s=0.0; n=0\n",
        "            for i in range(len(v2)):\n",
        "                y = v2[i][1]\n",
        "                m = (y == c)\n",
        "                if not torch.any(m):\n",
        "                    continue\n",
        "                a_vec=np.full(C,0.7,np.float32); a_vec[c]=float(a)\n",
        "                q=blend_geom_perclass(v2c[i], v3c[i], a_vec)\n",
        "                s += per_frame_nll(q[m], y[m]) * int(m.sum().item()); n += int(m.sum().item())\n",
        "            if n>0:\n",
        "                val = s/max(1,n)\n",
        "                if val<best[0]:\n",
        "                    best=(val,float(a))\n",
        "        A[c]=best[1]\n",
        "    return T2,T3,A\n",
        "\n",
        "cfg = pd.read_csv('cv_sweep_ce_v2v3_meta_localsrch.csv').sort_values(['worst','mean']).iloc[0].to_dict() if Path('cv_sweep_ce_v2v3_meta_localsrch.csv').exists() else {'pool_k':15,'temp':0.90,'gamma':0.90,'sep':2,'beta':0.5,'lambda_ord':0.03,'lambda_len':0.15}\n",
        "pool_k=int(cfg['pool_k']); temp=float(cfg['temp']); gamma=float(cfg.get('gamma',0.90)); sep=int(cfg['sep']); beta=float(cfg.get('beta',0.5)); l_ord=float(cfg.get('lambda_ord',0.03)); l_len=float(cfg.get('lambda_len',0.15))\n",
        "print('Chosen localsrch-meta cfg:', {'pool_k':pool_k,'temp':temp,'gamma':gamma,'sep':sep,'beta':beta,'lambda_ord':l_ord,'lambda_len':l_len}, flush=True)\n",
        "\n",
        "print('Refitting T2/T3/alpha on ALL OOF for test...', flush=True)\n",
        "T2_all, T3_all, A_all = refit_on_all()\n",
        "Path('calib_all_v2v3_meta.json').write_text(json.dumps({'T2':T2_all.tolist(),'T3':T3_all.tolist(),'A':A_all.tolist()}))\n",
        "\n",
        "# Test-time inference: reuse stack inference from previous cells\n",
        "feat_v2_tr = Path('features3d_v2')/'train'; feat_v3_tr = Path('features3d_v3')/'train'\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__(); self.conv1=nn.Conv1d(ch,ch,k,padding=dilation,dilation=dilation); self.gn1=nn.GroupNorm(groups,ch); self.drop=nn.Dropout(drop); self.conv2=nn.Conv1d(ch,ch,1); self.gn2=nn.GroupNorm(groups,ch)\n",
        "    def forward(self,x):\n",
        "        h=self.conv1(x); h=self.gn1(h); h=F.relu(h, inplace=True); h=self.drop(h); h=self.conv2(h); h=self.gn2(h); h=F.relu(h,inplace=True); return x+h\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__(); self.inp=nn.Conv1d(d_in,channels,1); blks=[]; dil=1\n",
        "        for _ in range(layers): blks.append(DilatedResBlock(channels,dil,drop=dropout,groups=8,k=3)); dil=min(dil*2,512)\n",
        "        self.blocks=nn.ModuleList(blks); self.head=nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for b in self.blocks:\n",
        "            h = b(h)\n",
        "        out = self.head(h)\n",
        "        return out.transpose(1,2)\n",
        "\n",
        "def compute_fold_scaler_from_dir(id_list, feat_dir: Path):\n",
        "    n=0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X=np.load(feat_dir/f\"{int(sid)}.npz\")[\"X\"].astype(np.float32); n_i=X.shape[0]\n",
        "        if mean is None: mean=X.mean(axis=0); M2=((X-mean)**2).sum(axis=0); n=n_i\n",
        "        else:\n",
        "            mean_i=X.mean(axis=0); n_new=n+n_i; delta=mean_i-mean; mean=mean+delta*(n_i/max(1,n_new)); M2=M2+((X-mean_i)**2).sum(axis=0)+(delta**2)*(n*n_i/max(1,n_new)); n=n_new\n",
        "    var=M2/max(1,(n-1)); std=np.sqrt(np.clip(var,1e-8,None)); return mean.astype(np.float32), std.astype(np.float32)\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        T,C = p_t_c.shape; tgt=max(1,int(round(T*s))); x=p_t_c.T.unsqueeze(0); y=F.interpolate(x,size=tgt,mode='linear',align_corners=False); y2=F.interpolate(y,size=T,mode='linear',align_corners=False)[0].T; y2=y2/(y2.sum(dim=-1,keepdim=True)+1e-8); acc=y2 if acc is None else (acc+y2)\n",
        "    out=acc/float(len(factors)); return out/(out.sum(dim=-1,keepdim=True)+1e-8)\n",
        "def infer_probs_for_sid_from_stack(sid:int, feat_tr_dir: Path, model_prefix: str):\n",
        "    X=np.load((feat_tr_dir.parent/'test'/f\"{sid}.npz\"))['X'].astype(np.float32); acc=None\n",
        "    with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "        for fi in range(3):\n",
        "            mean,std = compute_fold_scaler_from_dir(folds[fi]['train_ids'], feat_tr_dir)\n",
        "            mean_t=torch.from_numpy(mean).float().to(device); std_t=torch.from_numpy(std).float().to(device)\n",
        "            D_in=np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "            for s in (0,1):\n",
        "                ckpt=Path(f\"{model_prefix}{fi}{'_s1' if s==1 else ''}.pth\")\n",
        "                if not ckpt.exists(): continue\n",
        "                m=DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device);\n",
        "                m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n",
        "                xb=torch.from_numpy(X).float().to(device); xb=(xb - mean_t)/(std_t+1e-6); xb=xb.unsqueeze(0)\n",
        "                p=m(xb)[0].softmax(dim=-1); p=apply_tta_timewarp(p, factors=(0.9,1.0,1.1)); acc=p if acc is None else (acc+p); del m\n",
        "    probs=acc/float(6); return probs/(probs.sum(dim=-1,keepdim=True)+1e-8)\n",
        "\n",
        "print('Building v2+v3 meta-blend with localsrch+reinsertion submission...', flush=True)\n",
        "med_k_all = compute_class_median_durations_for_ids(train_df['Id'].astype(int).tolist())\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "for i,sid in enumerate(test_ids,1):\n",
        "    sid=int(sid)\n",
        "    p2 = infer_probs_for_sid_from_stack(sid, Path('features3d_v2')/'train', 'model_ce_fold')\n",
        "    p3 = infer_probs_for_sid_from_stack(sid, Path('features3d_v3')/'train', 'model_ce_v3_fold')\n",
        "    q2 = apply_per_class_temps(p2, T2_all); q3 = apply_per_class_temps(p3, T3_all)\n",
        "    q  = blend_geom_perclass(q2, q3, A_all)\n",
        "    Tlen=q.shape[0]; g_eff=gamma_with_length(gamma, Tlen, med_k_all)\n",
        "    seq = decode_localsrch_meta(q, med_k=med_k_all, gamma=g_eff, pool_k=pool_k, temp=temp, min_sep=sep, beta=beta, lambda_ord=l_ord, lambda_len=l_len)\n",
        "    rows.append({'Id': sid, 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if (i%10)==0 or i==len(test_ids):\n",
        "        print(f\"  [infer v2v3 meta-localsrch] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub=pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), 'Submission format invalid'\n",
        "sub.to_csv('submission_primary_ce_v2v3_meta_localsrch.csv', index=False)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission_primary_ce_v2v3_meta_localsrch.csv and submission.csv; head:\\n', sub.head(), flush=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting per-class T2/T3/alpha per fold (fold-safe) for local-search...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweeping localsrch (reinsertion) on v2+v3 calibrated OOF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top localsrch-meta (mean,worst,cfg):\n(4.290319521748093, 5.02, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.9, 'sep': 3, 'beta': 0.4, 'lambda_ord': 0.03, 'lambda_len': 0.25})\n(4.293652855081427, 5.03, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.9, 'sep': 3, 'beta': 0.4, 'lambda_ord': 0.03, 'lambda_len': 0.15})\n(4.293652855081427, 5.03, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.95, 'sep': 2, 'beta': 0.4, 'lambda_ord': 0.03, 'lambda_len': 0.15})\n(4.293652855081427, 5.03, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.95, 'sep': 2, 'beta': 0.4, 'lambda_ord': 0.03, 'lambda_len': 0.25})\n(4.293652855081427, 5.03, {'pool_k': 15, 'temp': 0.9, 'gamma': 0.95, 'sep': 3, 'beta': 0.4, 'lambda_ord': 0.03, 'lambda_len': 0.15})\nSaved cv_sweep_ce_v2v3_meta_localsrch.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen localsrch-meta cfg: {'pool_k': 15, 'temp': 0.9, 'gamma': 0.9, 'sep': 3, 'beta': 0.4, 'lambda_ord': 0.03, 'lambda_len': 0.25}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refitting T2/T3/alpha on ALL OOF for test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building v2+v3 meta-blend with localsrch+reinsertion submission...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_8891/2988353367.py:450: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(ckpt, map_location=device)); m.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta-localsrch] 10/95 elapsed=2.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta-localsrch] 20/95 elapsed=5.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta-localsrch] 30/95 elapsed=8.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta-localsrch] 40/95 elapsed=11.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta-localsrch] 50/95 elapsed=14.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta-localsrch] 60/95 elapsed=17.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta-localsrch] 70/95 elapsed=20.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta-localsrch] 80/95 elapsed=23.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta-localsrch] 90/95 elapsed=25.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer v2v3 meta-localsrch] 95/95 elapsed=27.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_v2v3_meta_localsrch.csv and submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 7 1...\n1  301  10 12 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 3 1...\n2  302  1 17 16 12 5 19 7 13 20 18 11 3 4 6 15 8 14 10...\n3  303  13 4 12 10 5 19 15 20 17 11 16 8 18 7 3 1 6 2 ...\n4  304  8 1 12 14 18 13 9 7 2 11 3 20 19 5 10 6 15 17 ...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}