{
  "cells": [
    {
      "id": "a271864a-143b-47b6-835c-222656fbbdd5",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan: Multi-modal Gesture Recognition (MMRGC)\n",
        "\n",
        "Objectives:\n",
        "- Establish GPU-enabled environment and robust, reproducible pipeline.\n",
        "- Build fast baseline \u2192 improve via feature engineering and modeling.\n",
        "- Achieve medal-level Levenshtein distance.\n",
        "\n",
        "Milestones & Expert Checkpoints:\n",
        "1) Planning (this doc) \u2192 Request expert feedback on medal-winning strategies and pitfalls.\n",
        "2) Environment check: verify GPU; install correct cu121 PyTorch stack if needed.\n",
        "3) Data audit:\n",
        "   - Inspect training.csv/test.csv formats and required submission schema.\n",
        "   - Inventory archives (training*.tar.gz, validation*.tar.gz, test.tar.gz) and contents (e.g., Sample*_data.mat).\n",
        "   - Verify mapping between Video.Labels in .mat and training.csv sequences.\n",
        "4) Baseline data loader:\n",
        "   - Implement reader to parse per-sample modalities (skeleton, depth/RGB features if available) and labels.\n",
        "   - Cache parsed features to disk (npz/parquet) to iterate quickly.\n",
        "5) Validation protocol:\n",
        "   - User-independent splits mirroring challenge (use provided validation sets if aligned).\n",
        "   - Deterministic KFold/GroupKFold (group by subject/session). Save folds to disk.\n",
        "6) Baseline model:\n",
        "   - Sequence model on skeleton features first (GRU/LSTM/TemporalConv) with CTC/seq2seq.\n",
        "   - Alt: classical per-frame classifier + Viterbi/DP decoding into sequences.\n",
        "   - Quick smoke-run on subsample; enable mixed precision; early stopping.\n",
        "7) Evaluation:\n",
        "   - Compute Levenshtein distance on validation (OOF). Log confusion/error buckets.\n",
        "8) Feature engineering:\n",
        "   - Temporal deltas, velocities, joint angles, distances, normalized by body size.\n",
        "   - Optional: fuse audio/RGB-depth derived features if present (late fusion).\n",
        "9) Model improvements:\n",
        "   - BiGRU/TemporalConvNet; SpecAug/time mask; label smoothing.\n",
        "   - Calibration and decoding tweaks (beam search, penalties).\n",
        "10) Ensembling:\n",
        "   - Blend diverse seeds/architectures; average logits then decode.\n",
        "11) Inference & Submission:\n",
        "   - Generate test predictions; ensure submission.csv format matches sample.\n",
        "   - Sanity-check file before submit.\n",
        "\n",
        "Logging/Discipline:\n",
        "- Print progress and elapsed time per fold.\n",
        "- Cache features/logits; avoid recompute.\n",
        "- Change one thing at a time; track deltas.\n",
        "\n",
        "Next Actions:\n",
        "1) Run environment and GPU check; list files; peek CSV heads.\n",
        "2) Request expert review of plan and ask for medal-winning strategy specifics."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c2f2ddf3-1b95-4403-ab33-9734f7c121ae",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, time, json, shutil, tarfile, zipfile, subprocess, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def run(cmd):\n",
        "    print(\"$\", \" \".join(cmd), flush=True)\n",
        "    try:\n",
        "        out = subprocess.run(cmd, capture_output=True, text=True, check=False)\n",
        "        print(out.stdout, flush=True)\n",
        "        if out.stderr:\n",
        "            print(out.stderr, file=sys.stderr, flush=True)\n",
        "        return out.returncode\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR running {cmd}: {e}\")\n",
        "        return -1\n",
        "\n",
        "print(\"=== GPU CHECK (nvidia-smi) ===\", flush=True)\n",
        "run(['bash','-lc','nvidia-smi || true'])\n",
        "\n",
        "print(\"=== List files in CWD ===\", flush=True)\n",
        "for p in sorted(Path('.').iterdir()):\n",
        "    try:\n",
        "        sz = p.stat().st_size\n",
        "    except Exception:\n",
        "        sz = -1\n",
        "    print(f\"{p.name}\\t{sz}\")\n",
        "\n",
        "def head_csv(path, n=3):\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        print(f\"\\n--- {path} shape={df.shape} ---\")\n",
        "        print(df.head(n))\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to read {path}: {e}\")\n",
        "\n",
        "head_csv('training.csv', 5)\n",
        "head_csv('test.csv', 5)\n",
        "head_csv('randomPredictions.csv', 5)\n",
        "\n",
        "print(\"\\n=== Inspect sample_code_mmrgc.zip entries (first 20) ===\")\n",
        "try:\n",
        "    with zipfile.ZipFile('sample_code_mmrgc.zip') as z:\n",
        "        names = z.namelist()\n",
        "        for name in names[:20]:\n",
        "            print(name)\n",
        "        print(f\"Total entries: {len(names)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Zip inspect failed: {e}\")\n",
        "\n",
        "def list_tarfirst(tarpath, k=10):\n",
        "    print(f\"\\n=== List first {k} members of {tarpath} ===\")\n",
        "    try:\n",
        "        with tarfile.open(tarpath, 'r:*') as tf:\n",
        "            for i, m in enumerate(tf):\n",
        "                if i>=k: break\n",
        "                print(m.name)\n",
        "    except Exception as e:\n",
        "        print(f\"Tar inspect failed for {tarpath}: {e}\")\n",
        "\n",
        "list_tarfirst('training1.tar.gz', 10)\n",
        "list_tarfirst('validation1.tar.gz', 10)\n",
        "list_tarfirst('test.tar.gz', 10)\n",
        "\n",
        "print(\"\\n=== Done env/data audit ===\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GPU CHECK (nvidia-smi) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ bash -lc nvidia-smi || true\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 29 04:13:08 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== List files in CWD ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".00_eda_and_planning_kernel_state.json\t182\n00_eda_and_planning.ipynb\t6375\nagent_metadata\t4096\ndescription.md\t21508\ndevel01-40.7z\t2177920674\ndocker_run.log\t43548\nrandomPredictions.csv\t5332\nrequirements.txt\t2021\nsample_code_mmrgc.zip\t7708\ntask.txt\t3949\ntest.csv\t478\ntest.tar.gz\t2041016729\ntraining.csv\t16513\ntraining1.tar.gz\t4370421093\ntraining2.tar.gz\t1755486450\ntraining3.tar.gz\t2300959544\nvalid_all_files_combined.7z\t961765673\nvalidation1.tar.gz\t2909694856\nvalidation2.tar.gz\t3456269325\nvalidation3.tar.gz\t3253929930\n\n--- training.csv shape=(297, 2) ---\n   Id                                           Sequence\n0   1  2 14 20 6 7 3 1 13 18 5 12 16 15 4 9 10 8 17 1...\n1   3  12 3 18 14 16 20 5 2 4 1 10 6 9 19 15 17 11 13...\n2   4  13 1 8 18 7 17 16 9 5 10 11 4 20 3 19 2 14 6 1...\n3   5  10 4 7 13 19 15 9 11 17 1 8 5 18 3 12 16 14 2 ...\n4   6  14 15 10 16 11 2 20 8 7 9 1 19 17 18 6 4 13 3 ...\n\n--- test.csv shape=(95, 1) ---\n    Id\n0  300\n1  301\n2  302\n3  303\n4  304\n\n--- randomPredictions.csv shape=(95, 2) ---\n    Id                                           Sequence\n0  300  13 14 2 9 16 7 20 5 8 6 10 4 3 12 18 1 15 17 1...\n1  301  4 3 11 16 20 6 7 15 10 18 17 9 8 12 5 19 1 13 ...\n2  302  13 1 16 11 8 12 6 15 2 4 10 17 9 7 20 5 18 19 ...\n3  303  17 16 4 10 20 12 2 9 6 13 18 11 5 19 1 8 7 14 ...\n4  304  6 7 20 2 9 8 17 14 11 3 12 1 13 18 5 4 10 19 1...\n\n=== Inspect sample_code_mmrgc.zip entries (first 20) ===\nsample_code_mmrgc_working/\nsample_code_mmrgc_working/dtw.m\nsample_code_mmrgc_working/extract_zip_files.m\nsample_code_mmrgc_working/getGestureID.m\nsample_code_mmrgc_working/load_challenge_data.m\nsample_code_mmrgc_working/main.m\nsample_code_mmrgc_working/motion.m\nsample_code_mmrgc_working/motion_histograms.m\nsample_code_mmrgc_working/read_movie.m\nTotal entries: 9\n\n=== List first 10 members of training1.tar.gz ===\n./Sample00001.zip\n./Sample00003.zip\n./Sample00004.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./Sample00005.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./Sample00006.zip\n./Sample00007.zip\n./Sample00008.zip\n./Sample00009.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./Sample00010.zip\n./Sample00011.zip\n\n=== List first 10 members of validation1.tar.gz ===\nSample00410.zip\nSample00411.zip\nSample00412.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample00413.zip\nSample00414.zip\nSample00415.zip\nSample00416.zip\nSample00417.zip\nSample00418.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample00420.zip\n\n=== List first 10 members of test.tar.gz ===\n./Sample00300.zip\n./Sample00301.zip\n./Sample00302.zip\n./Sample00303.zip\n./Sample00304.zip\n./Sample00305.zip\n./Sample00306.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./Sample00307.zip\n./Sample00308.zip\n./Sample00309.zip\n\n=== Done env/data audit ===\n"
          ]
        }
      ]
    },
    {
      "id": "d5769288-aef9-42fd-92d7-71ff04b733f4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import io, tarfile, zipfile, sys, time\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=== Inspect a couple of MAT files inside training/validation archives ===\", flush=True)\n",
        "targets = [\n",
        "    (\"training1.tar.gz\", [\"./Sample00001.zip\", \"./Sample00003.zip\"]),\n",
        "    (\"validation1.tar.gz\", [\"Sample00410.zip\"])\n",
        "]\n",
        "\n",
        "def ensure_scipy():\n",
        "    try:\n",
        "        import scipy.io as sio  # noqa\n",
        "        return True\n",
        "    except Exception:\n",
        "        import subprocess, sys as _sys\n",
        "        print(\"Installing scipy...\", flush=True)\n",
        "        rc = subprocess.run([_sys.executable, \"-m\", \"pip\", \"install\", \"scipy\", \"--quiet\"], check=False).returncode\n",
        "        print(\"pip rc=\", rc, flush=True)\n",
        "        try:\n",
        "            import scipy.io as sio  # noqa\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(\"Failed to import scipy after install:\", e, flush=True)\n",
        "            return False\n",
        "\n",
        "ok_scipy = ensure_scipy()\n",
        "if ok_scipy:\n",
        "    import scipy.io as sio\n",
        "else:\n",
        "    sio = None\n",
        "\n",
        "def inspect_zip_bytes(zb: bytes, label_hint: str = \"\"):\n",
        "    with zipfile.ZipFile(io.BytesIO(zb)) as zf:\n",
        "        names = zf.namelist()\n",
        "        print(f\"ZIP has {len(names)} entries. First 15:\")\n",
        "        for n in names[:15]:\n",
        "            print(\"  \", n)\n",
        "        # pick a *_data.mat if present\n",
        "        mat_name = None\n",
        "        for n in names:\n",
        "            if n.lower().endswith(\"_data.mat\") or n.lower().endswith(\".mat\"):\n",
        "                mat_name = n\n",
        "                break\n",
        "        if mat_name and ok_scipy:\n",
        "            with zf.open(mat_name) as f:\n",
        "                b = f.read()\n",
        "                try:\n",
        "                    md = sio.loadmat(io.BytesIO(b), squeeze_me=True, struct_as_record=False)\n",
        "                except TypeError:\n",
        "                    # Older scipy may not accept BytesIO; write to tmp\n",
        "                    tmp = Path(\"_tmp_inspect.mat\")\n",
        "                    tmp.write_bytes(b)\n",
        "                    md = sio.loadmat(str(tmp), squeeze_me=True, struct_as_record=False)\n",
        "                    try: tmp.unlink()\n",
        "                    except Exception: pass\n",
        "            print(f\"MAT keys: {sorted([k for k in md.keys() if not k.startswith('__')])}\")\n",
        "            # Try common fields\n",
        "            for key in (\"Video\", \"video\", \"Labels\", \"labels\", \"Gesture\", \"gesture\"):\n",
        "                if key in md:\n",
        "                    v = md[key]\n",
        "                    print(f\"Field {key}: type={type(v)}\")\n",
        "                    # Attempt to explore nested struct\n",
        "                    try:\n",
        "                        attrs = [a for a in dir(v) if not a.startswith('_')]\n",
        "                        print(f\"  attrs(sample): {attrs[:12]}\")\n",
        "                        # Look for Labels inside Video\n",
        "                        for sub in (\"Labels\", \"labels\", \"numFrames\", \"nframes\", \"fps\", \"SubjectID\", \"user\", \"Acquisition\"):\n",
        "                            if hasattr(v, sub):\n",
        "                                sv = getattr(v, sub)\n",
        "                                try:\n",
        "                                    shp = getattr(sv, \"shape\", None)\n",
        "                                except Exception:\n",
        "                                    shp = None\n",
        "                                print(f\"  {key}.{sub}: type={type(sv)}, shape={shp}\")\n",
        "                    except Exception as e:\n",
        "                        print(\"  could not introspect struct:\", e)\n",
        "\n",
        "for tarpath, members in targets:\n",
        "    if not Path(tarpath).exists():\n",
        "        print(f\"Missing {tarpath}\")\n",
        "        continue\n",
        "    print(f\"\\n-- TAR {tarpath} --\", flush=True)\n",
        "    with tarfile.open(tarpath, 'r:*') as tf:\n",
        "        tf_members = {m.name: m for m in tf}\n",
        "        for m in members:\n",
        "            cand = m if m in tf_members else (m.lstrip('./') if m.lstrip('./') in tf_members else None)\n",
        "            if not cand:\n",
        "                print(f\"Member {m} not found\")\n",
        "                continue\n",
        "            print(f\"Reading {cand} ...\", flush=True)\n",
        "            fobj = tf.extractfile(tf_members[cand])\n",
        "            if not fobj:\n",
        "                print(\"  cannot extract file object\")\n",
        "                continue\n",
        "            data = fobj.read()\n",
        "            print(f\"  bytes: {len(data):,}\")\n",
        "            try:\n",
        "                inspect_zip_bytes(data, label_hint=cand)\n",
        "            except zipfile.BadZipFile:\n",
        "                print(\"  Not a ZIP; skipping.\")\n",
        "\n",
        "print(\"\\n=== Done MAT inspection probe ===\", flush=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Inspect a couple of MAT files inside training/validation archives ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n-- TAR training1.tar.gz --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading ./Sample00001.zip ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  bytes: 44,147,690\nZIP has 5 entries. First 15:\n   Sample00001_color.mp4\n   Sample00001_depth.mp4\n   Sample00001_user.mp4\n   Sample00001_data.mat\n   Sample00001_audio.wav\nMAT keys: ['Video']\nField Video: type=<class 'scipy.io.matlab._mio5_params.mat_struct'>\n  attrs(sample): ['FrameRate', 'Frames', 'Labels', 'MaxDepth', 'NumFrames']\n  Video.Labels: type=<class 'numpy.ndarray'>, shape=(20,)\nReading ./Sample00003.zip ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  bytes: 39,357,003\nZIP has 5 entries. First 15:\n   Sample00003_color.mp4\n   Sample00003_depth.mp4\n   Sample00003_user.mp4\n   Sample00003_data.mat\n   Sample00003_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAT keys: ['Video']\nField Video: type=<class 'scipy.io.matlab._mio5_params.mat_struct'>\n  attrs(sample): ['FrameRate', 'Frames', 'Labels', 'MaxDepth', 'NumFrames']\n  Video.Labels: type=<class 'numpy.ndarray'>, shape=(20,)\n\n-- TAR validation1.tar.gz --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Sample00410.zip ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  bytes: 25,534,061\nZIP has 5 entries. First 15:\n   Sample00410_color.mp4\n   Sample00410_depth.mp4\n   Sample00410_user.mp4\n   Sample00410_audio.wav\n   Sample00410_data.mat\nMAT keys: ['Video']\nField Video: type=<class 'scipy.io.matlab._mio5_params.mat_struct'>\n  attrs(sample): ['FrameRate', 'Frames', 'Labels', 'MaxDepth', 'NumFrames']\n  Video.Labels: type=<class 'numpy.ndarray'>, shape=(0,)\n\n=== Done MAT inspection probe ===\n"
          ]
        }
      ]
    },
    {
      "id": "a9a7be1f-0b02-44e6-a780-5c4c07ab652f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import io, tarfile, zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=== Deep inspect one MAT: fields, shapes, label structure ===\", flush=True)\n",
        "tarpath = \"training1.tar.gz\"\n",
        "member = \"./Sample00001.zip\"\n",
        "\n",
        "with tarfile.open(tarpath, 'r:*') as tf:\n",
        "    tf_members = {m.name: m for m in tf}\n",
        "    cand = member if member in tf_members else member.lstrip('./')\n",
        "    fobj = tf.extractfile(tf_members[cand])\n",
        "    data = fobj.read()\n",
        "with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "    # find mat\n",
        "    mat_name = [n for n in zf.namelist() if n.lower().endswith('_data.mat') or n.lower().endswith('.mat')][0]\n",
        "    b = zf.read(mat_name)\n",
        "import scipy.io as sio\n",
        "md = sio.loadmat(io.BytesIO(b), squeeze_me=True, struct_as_record=False)\n",
        "V = md['Video']\n",
        "def safe_shape(x):\n",
        "    try: return getattr(x, 'shape', None)\n",
        "    except Exception: return None\n",
        "print(\"Video has attrs:\", [a for a in dir(V) if not a.startswith('_')])\n",
        "for fld in (\"NumFrames\",\"FrameRate\",\"Frames\",\"Labels\",\"MaxDepth\"):\n",
        "    if hasattr(V, fld):\n",
        "        val = getattr(V, fld)\n",
        "        print(f\"Video.{fld}: type={type(val)}, shape={safe_shape(val)}\")\n",
        "        if fld==\"Frames\":\n",
        "            try:\n",
        "                # Try to peek one frame entry\n",
        "                fr0 = val[0] if hasattr(val, '__getitem__') else None\n",
        "                print(\"  Frames[0] type=\", type(fr0))\n",
        "                if hasattr(fr0, 'shape'):\n",
        "                    print(\"  Frames[0].shape=\", fr0.shape)\n",
        "            except Exception as e:\n",
        "                print(\"  Could not index Frames:\", e)\n",
        "        if fld==\"Labels\":\n",
        "            try:\n",
        "                L = val\n",
        "                print(\"  Labels len:\", len(L))\n",
        "                if len(L)>0:\n",
        "                    l0 = L[0]\n",
        "                    print(\"  Label[0] type:\", type(l0))\n",
        "                    # Try common fields of a label struct\n",
        "                    if hasattr(l0, '__dict__') or hasattr(l0, 'dtype'):\n",
        "                        try:\n",
        "                            print(\"  Label[0] dir:\", [a for a in dir(l0) if not a.startswith('_')][:15])\n",
        "                        except Exception:\n",
        "                            pass\n",
        "                    # If it's an array like [start end class]\n",
        "                    try:\n",
        "                        import numpy as np\n",
        "                        arr = np.array(l0)\n",
        "                        print(\"  Label[0] as array:\", arr, arr.shape)\n",
        "                    except Exception as e:\n",
        "                        print(\"  Could not array-ize label:\", e)\n",
        "            except Exception as e:\n",
        "                print(\"  Could not inspect Labels:\", e)\n",
        "print(\"=== Done deep inspect ===\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Deep inspect one MAT: fields, shapes, label structure ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video has attrs: ['FrameRate', 'Frames', 'Labels', 'MaxDepth', 'NumFrames']\nVideo.NumFrames: type=<class 'int'>, shape=None\nVideo.FrameRate: type=<class 'int'>, shape=None\nVideo.Frames: type=<class 'numpy.ndarray'>, shape=(1254,)\n  Frames[0] type= <class 'scipy.io.matlab._mio5_params.mat_struct'>\nVideo.Labels: type=<class 'numpy.ndarray'>, shape=(20,)\n  Labels len: 20\n  Label[0] type: <class 'scipy.io.matlab._mio5_params.mat_struct'>\n  Label[0] dir: ['Begin', 'End', 'Name']\n  Label[0] as array: <scipy.io.matlab._mio5_params.mat_struct object at 0x73bc5557b490> ()\nVideo.MaxDepth: type=<class 'int'>, shape=None\n=== Done deep inspect ===\n"
          ]
        }
      ]
    },
    {
      "id": "003376eb-af55-444e-920c-8f9341e4a756",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import io, tarfile, zipfile\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "\n",
        "print(\"=== Inspect first frame struct fields and shapes ===\", flush=True)\n",
        "tarpath = \"training1.tar.gz\"\n",
        "member = \"./Sample00001.zip\"\n",
        "with tarfile.open(tarpath, 'r:*') as tf:\n",
        "    tf_members = {m.name: m for m in tf}\n",
        "    cand = member if member in tf_members else member.lstrip('./')\n",
        "    data = tf.extractfile(tf_members[cand]).read()\n",
        "with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "    mat_name = [n for n in zf.namelist() if n.lower().endswith('_data.mat') or n.lower().endswith('.mat')][0]\n",
        "    b = zf.read(mat_name)\n",
        "md = sio.loadmat(io.BytesIO(b), squeeze_me=True, struct_as_record=False)\n",
        "V = md['Video']\n",
        "frames = V.Frames\n",
        "print(\"NumFrames:\", getattr(V, 'NumFrames', None), \"FrameRate:\", getattr(V, 'FrameRate', None))\n",
        "fr0 = frames[0]\n",
        "attrs = [a for a in dir(fr0) if not a.startswith('_')]\n",
        "print(\"Frame[0] attrs (first 40):\", attrs[:40])\n",
        "\n",
        "def show_attr(obj, name):\n",
        "    try:\n",
        "        val = getattr(obj, name)\n",
        "    except Exception as e:\n",
        "        print(f\"  {name}: <error {e}>\")\n",
        "        return\n",
        "    shp = getattr(val, 'shape', None)\n",
        "    typ = type(val)\n",
        "    info = None\n",
        "    if isinstance(val, (np.ndarray, list, tuple)):\n",
        "        try:\n",
        "            if isinstance(val, np.ndarray) and val.size>0:\n",
        "                info = f\"dtype={val.dtype}, min={val.min()}, max={val.max()}\" if np.issubdtype(val.dtype, np.number) else f\"dtype={val.dtype}\"\n",
        "        except Exception:\n",
        "            info = None\n",
        "    print(f\"  {name}: type={typ}, shape={shp}, {info}\")\n",
        "\n",
        "# Probe common fields that might exist in ChaLearn frames\n",
        "for name in (\"Depth\", \"User\", \"Map\", \"Skeleton\", \"RGB\", \"Audio\", \"LeftHand\", \"RightHand\", \"PointCloud\", \"XYZ\", \"Coordinates\"):\n",
        "    if hasattr(fr0, name):\n",
        "        show_attr(fr0, name)\n",
        "\n",
        "# If Skeleton exists as nested struct/array, peek deeper and print key fields\n",
        "if hasattr(fr0, 'Skeleton'):\n",
        "    sk = getattr(fr0, 'Skeleton')\n",
        "    try:\n",
        "        print(\"Skeleton dir:\", [a for a in dir(sk) if not a.startswith('_')][:30])\n",
        "        for sub in (\"JointType\", \"PixelPosition\", \"WorldPosition\", \"WorldRotation\"):\n",
        "            if hasattr(sk, sub):\n",
        "                val = getattr(sk, sub)\n",
        "                print(f\"  Skeleton.{sub} type={type(val)}, shape={getattr(val, 'shape', None)}\")\n",
        "                if isinstance(val, np.ndarray):\n",
        "                    # Show small preview of shape details\n",
        "                    try:\n",
        "                        print(\"    ndim=\", val.ndim, \"dtype=\", val.dtype)\n",
        "                        if val.ndim>=1:\n",
        "                            print(\"    first element type:\", type(val.flat[0]))\n",
        "                    except Exception as e:\n",
        "                        print(\"    preview error:\", e)\n",
        "    except Exception as e:\n",
        "        print(\"Skeleton inspect error:\", e)\n",
        "\n",
        "# Inspect first label fully\n",
        "L = V.Labels\n",
        "print(\"Labels count:\", len(L))\n",
        "if len(L)>0:\n",
        "    l0 = L[0]\n",
        "    print(\"Label[0] fields:\", [a for a in dir(l0) if not a.startswith('_')])\n",
        "    try:\n",
        "        print(\"  Begin:\", getattr(l0, 'Begin', None), \"End:\", getattr(l0, 'End', None), \"Name:\", getattr(l0, 'Name', None))\n",
        "    except Exception as e:\n",
        "        print(\"  Could not print label fields:\", e)\n",
        "print(\"=== Done frame inspection ===\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Inspect first frame struct fields and shapes ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumFrames: 1254 FrameRate: 20\nFrame[0] attrs (first 40): ['Skeleton']\n  Skeleton: type=<class 'scipy.io.matlab._mio5_params.mat_struct'>, shape=None, None\nSkeleton dir: ['JointType', 'PixelPosition', 'WorldPosition', 'WorldRotation']\n  Skeleton.JointType type=<class 'numpy.ndarray'>, shape=(20,)\n    ndim= 1 dtype= object\n    first element type: <class 'numpy.ndarray'>\n  Skeleton.PixelPosition type=<class 'numpy.ndarray'>, shape=(20, 2)\n    ndim= 2 dtype= uint8\n    first element type: <class 'numpy.uint8'>\n  Skeleton.WorldPosition type=<class 'numpy.ndarray'>, shape=(20, 3)\n    ndim= 2 dtype= uint8\n    first element type: <class 'numpy.uint8'>\n  Skeleton.WorldRotation type=<class 'numpy.ndarray'>, shape=(20, 4)\n    ndim= 2 dtype= uint8\n    first element type: <class 'numpy.uint8'>\nLabels count: 20\nLabel[0] fields: ['Begin', 'End', 'Name']\n  Begin: 1 End: 79 Name: vieniqui\n=== Done frame inspection ===\n"
          ]
        }
      ]
    },
    {
      "id": "beb7d589-4139-4580-b3cd-75542846c507",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import io, tarfile, zipfile, json, math, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=== Build archive index and cache small subset of skeleton features ===\", flush=True)\n",
        "CWD = Path('.')\n",
        "TRAIN_TARS = [CWD/'training1.tar.gz', CWD/'training2.tar.gz', CWD/'training3.tar.gz']\n",
        "VAL_TARS = [CWD/'validation1.tar.gz', CWD/'validation2.tar.gz', CWD/'validation3.tar.gz']\n",
        "TEST_TAR = CWD/'test.tar.gz'\n",
        "\n",
        "def build_tar_index(tar_paths):\n",
        "    idx = {}  # name -> (tarpath, TarInfo)\n",
        "    for tp in tar_paths:\n",
        "        if not tp.exists():\n",
        "            continue\n",
        "        with tarfile.open(tp, 'r:*') as tf:\n",
        "            for m in tf:\n",
        "                if not m.isreg():\n",
        "                    continue\n",
        "                nm = m.name.lstrip('./')\n",
        "                if nm.endswith('.zip') and nm.startswith('Sample'):\n",
        "                    idx[nm] = (tp, m)\n",
        "    return idx\n",
        "\n",
        "train_idx = build_tar_index(TRAIN_TARS)\n",
        "val_idx = build_tar_index(VAL_TARS)\n",
        "test_idx = build_tar_index([TEST_TAR])\n",
        "print(f\"Index sizes: train={len(train_idx)}, val={len(val_idx)}, test={len(test_idx)}\")\n",
        "\n",
        "def id_to_zipname(sample_id: int) -> str:\n",
        "    return f\"Sample{sample_id:05d}.zip\"\n",
        "\n",
        "def load_mat_from_zip(tarpath: Path, tarinfo: tarfile.TarInfo):\n",
        "    with tarfile.open(tarpath, 'r:*') as tf:\n",
        "        fobj = tf.extractfile(tarinfo)\n",
        "        if fobj is None:\n",
        "            raise RuntimeError(\"Failed to extract tar member\")\n",
        "        data = fobj.read()\n",
        "    with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "        mat_name = None\n",
        "        for n in zf.namelist():\n",
        "            ln = n.lower()\n",
        "            if ln.endswith('_data.mat') or ln.endswith('.mat'):\n",
        "                mat_name = n; break\n",
        "        if mat_name is None:\n",
        "            raise RuntimeError(\"No MAT file found in zip\")\n",
        "        b = zf.read(mat_name)\n",
        "    import scipy.io as sio\n",
        "    md = sio.loadmat(io.BytesIO(b), squeeze_me=True, struct_as_record=False)\n",
        "    return md\n",
        "\n",
        "def extract_skeleton_xy(md):\n",
        "    V = md['Video']\n",
        "    frames = V.Frames  # ndarray of mat_struct, len T\n",
        "    T = frames.shape[0]\n",
        "    # Each frame has Skeleton.PixelPosition (20,2) uint8; use that as base feature\n",
        "    D = 20*2\n",
        "    X = np.zeros((T, D), dtype=np.float32)\n",
        "    for t in range(T):\n",
        "        fr = frames[t]\n",
        "        sk = getattr(fr, 'Skeleton')\n",
        "        px = getattr(sk, 'PixelPosition')  # (20,2) uint8\n",
        "        arr = np.asarray(px, dtype=np.float32)\n",
        "        X[t] = arr.reshape(-1)\n",
        "    # Normalize per-frame: center and scale\n",
        "    mu = X.reshape(T, 20, 2).mean(axis=1, keepdims=False)  # (T,2)\n",
        "    Xc = X.reshape(T, 20, 2) - mu[:, None, :]\n",
        "    # scale by RMS distance to center to be size-invariant\n",
        "    rms = np.sqrt((Xc**2).sum(axis=(1,2)) / (20*2))  # (T,)\n",
        "    rms[rms == 0] = 1.0\n",
        "    Xn = (Xc / rms[:, None, None]).reshape(T, D)\n",
        "    return Xn, int(getattr(V, 'FrameRate', 20)), int(getattr(V, 'NumFrames', Xn.shape[0]))\n",
        "\n",
        "def temporal_features(X, stride=2):\n",
        "    # Downsample by stride, then compute velocities and accelerations on downsampled sequence\n",
        "    Xds = X[::stride].astype(np.float32)\n",
        "    V = np.diff(Xds, axis=0, prepend=Xds[:1])\n",
        "    A = np.diff(V, axis=0, prepend=V[:1])\n",
        "    return np.concatenate([Xds, V, A], axis=1)\n",
        "\n",
        "def cache_one(sample_id: int, split: str, outdir: Path):\n",
        "    if split=='train':\n",
        "        idx = train_idx\n",
        "    elif split=='val':\n",
        "        idx = val_idx\n",
        "    elif split=='test':\n",
        "        idx = test_idx\n",
        "    else:\n",
        "        raise ValueError('split must be train/val/test')\n",
        "    zipname = id_to_zipname(sample_id)\n",
        "    if zipname not in idx:\n",
        "        raise KeyError(f\"{zipname} not found in index for split={split}\")\n",
        "    tarpath, tarinfo = idx[zipname]\n",
        "    md = load_mat_from_zip(tarpath, tarinfo)\n",
        "    X, fps, nframes = extract_skeleton_xy(md)\n",
        "    # Build features\n",
        "    Xf = temporal_features(X, stride=2)  # ~10 fps\n",
        "    meta = dict(fps=fps, nframes=nframes, stride=2)\n",
        "    outdir.mkdir(parents=True, exist_ok=True)\n",
        "    np.savez_compressed(outdir/f\"{sample_id}.npz\", X=Xf, meta=json.dumps(meta))\n",
        "    del md, X, Xf; gc.collect()\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "print(train_df.head(2))\n",
        "print(test_df.head(2))\n",
        "\n",
        "features_dir = Path('features')\n",
        "small_ids = train_df['Id'].head(8).tolist()\n",
        "t0 = time.time()\n",
        "for i, sid in enumerate(small_ids):\n",
        "    st = time.time()\n",
        "    cache_one(int(sid), 'train', features_dir/'train')\n",
        "    dt = time.time()-st\n",
        "    print(f\"cached train id={sid} ({i+1}/{len(small_ids)}) in {dt:.2f}s\", flush=True)\n",
        "print(f\"Subset caching done in {time.time()-t0:.2f}s\")\n",
        "print(\"List cached files:\")\n",
        "for p in sorted((features_dir/'train').glob('*.npz'))[:5]:\n",
        "    print(\"  \", p.name)\n",
        "print(\"=== Done subset caching ===\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Build archive index and cache small subset of skeleton features ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index sizes: train=298, val=287, test=95\n   Id                                           Sequence\n0   1  2 14 20 6 7 3 1 13 18 5 12 16 15 4 9 10 8 17 1...\n1   3  12 3 18 14 16 20 5 2 4 1 10 6 9 19 15 17 11 13...\n    Id\n0  300\n1  301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cached train id=1 (1/8) in 0.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cached train id=3 (2/8) in 0.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cached train id=4 (3/8) in 0.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cached train id=5 (4/8) in 0.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cached train id=6 (5/8) in 0.42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cached train id=7 (6/8) in 0.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cached train id=8 (7/8) in 0.53s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cached train id=9 (8/8) in 0.59s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset caching done in 3.21s\nList cached files:\n   1.npz\n   3.npz\n   4.npz\n   5.npz\n   6.npz\n=== Done subset caching ===\n"
          ]
        }
      ]
    },
    {
      "id": "c485ef98-2f74-44dc-99af-1df832b4d26d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import io, tarfile, zipfile, json, math, gc, sys, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "\n",
        "print(\"=== Switch caching to 3D WorldPosition with torso-centering and shoulder-width scaling ===\", flush=True)\n",
        "\n",
        "# Reuse indices if present from prior cell; else rebuild\n",
        "CWD = Path('.')\n",
        "TRAIN_TARS = [CWD/'training1.tar.gz', CWD/'training2.tar.gz', CWD/'training3.tar.gz']\n",
        "VAL_TARS = [CWD/'validation1.tar.gz', CWD/'validation2.tar.gz', CWD/'validation3.tar.gz']\n",
        "TEST_TAR = CWD/'test.tar.gz'\n",
        "\n",
        "def build_tar_index(tar_paths):\n",
        "    idx = {}\n",
        "    for tp in tar_paths:\n",
        "        if not tp.exists(): continue\n",
        "        with tarfile.open(tp, 'r:*') as tf:\n",
        "            for m in tf:\n",
        "                if not m.isreg(): continue\n",
        "                nm = m.name.lstrip('./')\n",
        "                if nm.endswith('.zip') and nm.startswith('Sample'):\n",
        "                    idx[nm] = (tp, m)\n",
        "    return idx\n",
        "\n",
        "try:\n",
        "    train_idx\n",
        "except NameError:\n",
        "    train_idx = build_tar_index(TRAIN_TARS)\n",
        "    val_idx = build_tar_index(VAL_TARS)\n",
        "    test_idx = build_tar_index([TEST_TAR])\n",
        "\n",
        "def id_to_zipname(sample_id: int) -> str:\n",
        "    return f\"Sample{sample_id:05d}.zip\"\n",
        "\n",
        "def load_mat_from_zip(tarpath: Path, tarinfo: tarfile.TarInfo):\n",
        "    with tarfile.open(tarpath, 'r:*') as tf:\n",
        "        fobj = tf.extractfile(tarinfo); data = fobj.read()\n",
        "    with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "        mat_name = None\n",
        "        for n in zf.namelist():\n",
        "            ln = n.lower()\n",
        "            if ln.endswith('_data.mat') or ln.endswith('.mat'): mat_name = n; break\n",
        "        b = zf.read(mat_name)\n",
        "    md = sio.loadmat(io.BytesIO(b), squeeze_me=True, struct_as_record=False)\n",
        "    return md\n",
        "\n",
        "def get_joint_names(md):\n",
        "    V = md['Video']\n",
        "    fr0 = V.Frames[0]\n",
        "    jt = getattr(fr0.Skeleton, 'JointType')\n",
        "    names = []\n",
        "    for j in jt:\n",
        "        # Elements may be numpy arrays or strings/bytes\n",
        "        if isinstance(j, np.ndarray):\n",
        "            v = j\n",
        "            try:\n",
        "                s = ''.join(chr(int(x)) for x in v.flatten())\n",
        "            except Exception:\n",
        "                try:\n",
        "                    s = v.tobytes().decode(errors='ignore')\n",
        "                except Exception:\n",
        "                    s = str(v)\n",
        "        else:\n",
        "            s = str(j)\n",
        "        s = s.strip().replace('\\x00','')\n",
        "        names.append(s)\n",
        "    return names\n",
        "\n",
        "def infer_indices(names):\n",
        "    # Build a case-insensitive map\n",
        "    lower = {n.lower(): i for i,n in enumerate(names)}\n",
        "    def find_any(keys):\n",
        "        for k in keys:\n",
        "            if k in lower: return lower[k]\n",
        "        return None\n",
        "    idx = {}\n",
        "    idx['shoulder_left']  = find_any(['shoulderleft','leftshoulder','lshoulder'])\n",
        "    idx['shoulder_right'] = find_any(['shoulderright','rightshoulder','rshoulder'])\n",
        "    idx['hip_left']       = find_any(['hipleft','lefthip','lhip'])\n",
        "    idx['hip_right']      = find_any(['hipright','righthip','rhip'])\n",
        "    idx['hip_center']     = find_any(['hipcenter','centership','spinebase','base'])\n",
        "    return idx\n",
        "\n",
        "def extract_world3d(md):\n",
        "    V = md['Video']\n",
        "    frames = V.Frames\n",
        "    T = frames.shape[0]\n",
        "    X = np.zeros((T, 20, 3), dtype=np.float32)\n",
        "    for t in range(T):\n",
        "        wp = getattr(frames[t].Skeleton, 'WorldPosition')  # (20,3) uint8\n",
        "        X[t] = np.asarray(wp, dtype=np.float32)\n",
        "    names = get_joint_names(md)\n",
        "    idxs = infer_indices(names)\n",
        "    # Center on hip_center if available, else midpoint of hips\n",
        "    if idxs.get('hip_center') is not None:\n",
        "        center = X[:, idxs['hip_center'], :]\n",
        "    else:\n",
        "        hl = X[:, idxs['hip_left'], :] if idxs.get('hip_left') is not None else X[:, 0, :]\n",
        "        hr = X[:, idxs['hip_right'], :] if idxs.get('hip_right') is not None else X[:, 1, :]\n",
        "        center = (hl + hr) / 2.0\n",
        "    Xc = X - center[:, None, :]\n",
        "    # Scale by shoulder width; fallback to shoulder-hip\n",
        "    if idxs.get('shoulder_left') is not None and idxs.get('shoulder_right') is not None:\n",
        "        sl = X[:, idxs['shoulder_left'], :]; sr = X[:, idxs['shoulder_right'], :]\n",
        "        scale = np.linalg.norm(sl - sr, axis=1)  # (T,)\n",
        "    else:\n",
        "        # Fallback: distance hip_left to shoulder_left if available else RMS\n",
        "        if idxs.get('hip_left') is not None and idxs.get('shoulder_left') is not None:\n",
        "            scale = np.linalg.norm(X[:, idxs['hip_left'], :] - X[:, idxs['shoulder_left'], :], axis=1)\n",
        "        else:\n",
        "            scale = np.sqrt((Xc**2).sum(axis=(1,2)) / (20*3))\n",
        "    scale[scale <= 1e-6] = 1.0\n",
        "    Xn = Xc / scale[:, None, None]\n",
        "    return Xn.reshape(T, -1), int(getattr(V,'FrameRate',20)), int(getattr(V,'NumFrames', X.shape[0]))\n",
        "\n",
        "def temporal_features(X, stride=2):\n",
        "    Xds = X[::stride].astype(np.float32)\n",
        "    V = np.diff(Xds, axis=0, prepend=Xds[:1])\n",
        "    A = np.diff(V, axis=0, prepend=V[:1])\n",
        "    return np.concatenate([Xds, V, A], axis=1)\n",
        "\n",
        "def cache_one_world3d(sample_id: int, split: str, outdir: Path):\n",
        "    idx = train_idx if split=='train' else (val_idx if split=='val' else test_idx)\n",
        "    zipname = id_to_zipname(sample_id)\n",
        "    tarpath, tarinfo = idx[zipname]\n",
        "    md = load_mat_from_zip(tarpath, tarinfo)\n",
        "    X, fps, nframes = extract_world3d(md)\n",
        "    Xf = temporal_features(X, stride=2)  # ~10 fps\n",
        "    meta = dict(fps=fps, nframes=nframes, stride=2, feat='world3d_pos+vel+acc')\n",
        "    outdir.mkdir(parents=True, exist_ok=True)\n",
        "    np.savez_compressed(outdir/f\"{sample_id}.npz\", X=Xf, meta=json.dumps(meta))\n",
        "    del md, X, Xf; gc.collect()\n",
        "\n",
        "# Smoke cache a few samples with 3D features\n",
        "train_df = pd.read_csv('training.csv')\n",
        "small_ids = train_df['Id'].head(6).tolist()\n",
        "outdir = Path('features3d')/'train'\n",
        "t0 = time.time()\n",
        "for i, sid in enumerate(small_ids):\n",
        "    st = time.time()\n",
        "    cache_one_world3d(int(sid), 'train', outdir)\n",
        "    print(f\"[3D] cached train id={sid} ({i+1}/{len(small_ids)}) in {time.time()-st:.2f}s\", flush=True)\n",
        "print(f\"[3D] subset caching done in {time.time()-t0:.2f}s; list:\")\n",
        "for p in sorted(outdir.glob('*.npz'))[:6]:\n",
        "    print('  ', p.name)\n",
        "print(\"=== Done 3D subset caching ===\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Switch caching to 3D WorldPosition with torso-centering and shoulder-width scaling ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3D] cached train id=1 (1/6) in 0.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3D] cached train id=3 (2/6) in 0.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3D] cached train id=4 (3/6) in 0.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3D] cached train id=5 (4/6) in 0.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3D] cached train id=6 (5/6) in 0.43s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3D] cached train id=7 (6/6) in 0.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3D] subset caching done in 2.12s; list:\n   1.npz\n   3.npz\n   4.npz\n   5.npz\n   6.npz\n   7.npz\n=== Done 3D subset caching ===\n"
          ]
        }
      ]
    },
    {
      "id": "73d56b12-e560-4ed3-a1f5-6365cb6d7f9f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, json, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=== Full TRAIN caching: 3D world pos + vel/acc at ~10 fps ===\", flush=True)\n",
        "\n",
        "# Reuse helpers and indices from previous cells: cache_one_world3d, train_idx, id_to_zipname, etc.\n",
        "train_df = pd.read_csv('training.csv')\n",
        "train_ids = train_df['Id'].astype(int).tolist()\n",
        "outdir = Path('features3d')/'train'\n",
        "outdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "total = len(train_ids)\n",
        "t0 = time.time()\n",
        "done = 0\n",
        "skipped = 0\n",
        "for i, sid in enumerate(train_ids, 1):\n",
        "    outp = outdir/f\"{sid}.npz\"\n",
        "    if outp.exists():\n",
        "        skipped += 1\n",
        "        if i % 20 == 0:\n",
        "            dt = time.time() - t0\n",
        "            rate = (i)/(dt+1e-9)\n",
        "            eta = (total - i)/max(rate,1e-6)\n",
        "            print(f\"[train] {i}/{total} (skip={skipped}) elapsed={dt/60:.1f}m eta={eta/60:.1f}m\", flush=True)\n",
        "        continue\n",
        "    st = time.time()\n",
        "    try:\n",
        "        cache_one_world3d(int(sid), 'train', outdir)\n",
        "        done += 1\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] failed id={sid}: {e}\", flush=True)\n",
        "        continue\n",
        "    if (i % 10) == 0 or i == total:\n",
        "        dt = time.time() - t0\n",
        "        rate = (i)/(dt+1e-9)\n",
        "        eta = (total - i)/max(rate,1e-6)\n",
        "        print(f\"[train] {i}/{total} cached={done} skip={skipped} last={time.time()-st:.2f}s elapsed={dt/60:.1f}m eta={eta/60:.1f}m\", flush=True)\n",
        "    gc.collect()\n",
        "\n",
        "print(f\"=== TRAIN caching done: cached={done}, skipped={skipped}, total={total}, elapsed={(time.time()-t0)/60:.2f}m ===\", flush=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Full TRAIN caching: 3D world pos + vel/acc at ~10 fps ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 10/297 cached=4 skip=6 last=0.70s elapsed=0.0m eta=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 20/297 cached=14 skip=6 last=1.21s elapsed=0.2m eta=2.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 30/297 cached=24 skip=6 last=1.71s elapsed=0.5m eta=4.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 40/297 cached=34 skip=6 last=2.28s elapsed=0.8m eta=5.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 50/297 cached=44 skip=6 last=3.11s elapsed=1.3m eta=6.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 60/297 cached=54 skip=6 last=3.82s elapsed=1.8m eta=7.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 70/297 cached=64 skip=6 last=4.51s elapsed=2.5m eta=8.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 80/297 cached=74 skip=6 last=5.21s elapsed=3.4m eta=9.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 90/297 cached=84 skip=6 last=5.48s elapsed=4.3m eta=9.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 100/297 cached=94 skip=6 last=0.20s elapsed=5.0m eta=9.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 110/297 cached=104 skip=6 last=0.41s elapsed=5.1m eta=8.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 120/297 cached=114 skip=6 last=0.60s elapsed=5.2m eta=7.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 130/297 cached=124 skip=6 last=0.84s elapsed=5.3m eta=6.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 140/297 cached=134 skip=6 last=1.05s elapsed=5.5m eta=6.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 150/297 cached=144 skip=6 last=1.27s elapsed=5.7m eta=5.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 160/297 cached=154 skip=6 last=1.47s elapsed=5.9m eta=5.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 170/297 cached=164 skip=6 last=1.67s elapsed=6.2m eta=4.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 180/297 cached=174 skip=6 last=1.86s elapsed=6.5m eta=4.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 190/297 cached=184 skip=6 last=2.06s elapsed=6.8m eta=3.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 200/297 cached=194 skip=6 last=0.22s elapsed=7.1m eta=3.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 210/297 cached=204 skip=6 last=0.45s elapsed=7.1m eta=2.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 220/297 cached=214 skip=6 last=0.67s elapsed=7.2m eta=2.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 230/297 cached=224 skip=6 last=1.19s elapsed=7.4m eta=2.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 240/297 cached=234 skip=6 last=1.70s elapsed=7.6m eta=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 250/297 cached=244 skip=6 last=2.00s elapsed=7.9m eta=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 260/297 cached=254 skip=6 last=2.21s elapsed=8.3m eta=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 270/297 cached=264 skip=6 last=2.40s elapsed=8.7m eta=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 280/297 cached=274 skip=6 last=2.67s elapsed=9.1m eta=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 290/297 cached=284 skip=6 last=2.91s elapsed=9.6m eta=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] 297/297 cached=291 skip=6 last=3.08s elapsed=9.9m eta=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TRAIN caching done: cached=291, skipped=6, total=297, elapsed=9.94m ===\n"
          ]
        }
      ]
    },
    {
      "id": "d3ba2877-0972-47c5-b98e-c93dfa4d835b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, subprocess, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=== Install PyTorch cu121 stack and sanity check GPU ===\", flush=True)\n",
        "def pip(*args):\n",
        "    print(\">\", *args, flush=True)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", *args], check=True)\n",
        "\n",
        "# Uninstall any stray torch stacks (ignore errors)\n",
        "for pkg in (\"torch\",\"torchvision\",\"torchaudio\"):\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg], check=False)\n",
        "\n",
        "# Clean possible shadow dirs (idempotent)\n",
        "for d in (\n",
        "    \"/app/.pip-target/torch\",\n",
        "    \"/app/.pip-target/torchvision\",\n",
        "    \"/app/.pip-target/torchaudio\",\n",
        "    \"/app/.pip-target/torch-2.4.1.dist-info\",\n",
        "    \"/app/.pip-target/torchvision-0.19.1.dist-info\",\n",
        "    \"/app/.pip-target/torchaudio-2.4.1.dist-info\",\n",
        "    \"/app/.pip-target/torchgen\",\n",
        "    \"/app/.pip-target/functorch\",\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print(\"Removing\", d, flush=True)\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# Install exact cu121 stack\n",
        "pip(\"install\",\n",
        "    \"--index-url\", \"https://download.pytorch.org/whl/cu121\",\n",
        "    \"--extra-index-url\", \"https://pypi.org/simple\",\n",
        "    \"torch==2.4.1\", \"torchvision==0.19.1\", \"torchaudio==2.4.1\")\n",
        "\n",
        "# Freeze constraints for subsequent installs\n",
        "Path(\"constraints.txt\").write_text(\"torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n\")\n",
        "\n",
        "# Sanity check\n",
        "import torch\n",
        "print(\"torch:\", torch.__version__, \"built CUDA:\", getattr(torch.version, \"cuda\", None))\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "assert str(getattr(torch.version, \"cuda\", \"\")).startswith(\"12.1\"), f\"Wrong CUDA build: {torch.version.cuda}\"\n",
        "assert torch.cuda.is_available(), \"CUDA not available\"\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "print(\"=== Torch install OK ===\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Install PyTorch cu121 stack and sanity check GPU ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchvision as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> install --index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.org/simple torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 543.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 536.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 439.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 205.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 516.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 514.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 228.3 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 199.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 227.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 482.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 198.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 308.2 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 209.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 198.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 210.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 430.1 MB/s eta 0:00:00\nCollecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 415.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 119.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 257.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 508.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 484.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 252.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 198.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 526.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.3 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 built CUDA: 12.1\nCUDA available: True\nGPU: NVIDIA A10-24Q\n=== Torch install OK ===\n"
          ]
        }
      ]
    },
    {
      "id": "adb97f71-a3ed-4654-8ac3-168c9e2df0a4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, json, math, time, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "print(\"=== Train BiGRU+CTC on cached 3D features (train split with small val) ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "random.seed(42); np.random.seed(42); torch.manual_seed(42);\n",
        "\n",
        "features_dir = Path('features3d')/'train'\n",
        "train_df = pd.read_csv('training.csv')\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "class_n = 21  # 0 is blank, labels 1..20\n",
        "\n",
        "def load_npz(sample_id: int):\n",
        "    p = features_dir/f\"{sample_id}.npz\"\n",
        "    d = np.load(p)\n",
        "    X = d['X'].astype(np.float32)  # (T, D)\n",
        "    return X\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, ids):\n",
        "        self.ids = ids\n",
        "    def __len__(self): return len(self.ids)\n",
        "    def __getitem__(self, idx):\n",
        "        sid = self.ids[idx]\n",
        "        X = load_npz(sid)\n",
        "        y = np.array(id2seq[sid], dtype=np.int64)  # (L,) tokens 1..20\n",
        "        # Truncate very long sequences for speed (keep up to 1200 frames after DS)\n",
        "        if X.shape[0] > 1200: X = X[:1200]\n",
        "        return torch.from_numpy(X), torch.from_numpy(y), sid\n",
        "\n",
        "def collate(batch):\n",
        "    xs, ys, sids = zip(*batch)\n",
        "    x_lens = torch.tensor([x.shape[0] for x in xs], dtype=torch.int32)\n",
        "    y_lens = torch.tensor([y.shape[0] for y in ys], dtype=torch.int32)\n",
        "    x_pad = pad_sequence(xs, batch_first=False)  # (T, B, D)\n",
        "    y_cat = torch.cat(ys, dim=0)  # concat targets for CTC\n",
        "    return x_pad, x_lens, y_cat, y_lens, sids\n",
        "\n",
        "all_ids = [int(x) for x in train_df['Id'].tolist()]\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "tr_ids = all_ids[val_n:]\n",
        "print(f\"Train videos: {len(tr_ids)}, Val videos: {len(val_ids)}\")\n",
        "\n",
        "train_ds = SeqDataset(tr_ids)\n",
        "val_ds = SeqDataset(val_ids)\n",
        "\n",
        "def make_loader(ds, bs=16, shuffle=True):\n",
        "    return DataLoader(ds, batch_size=bs, shuffle=shuffle, num_workers=2, pin_memory=True, collate_fn=collate)\n",
        "\n",
        "train_loader = make_loader(train_ds, bs=24, shuffle=True)\n",
        "val_loader = make_loader(val_ds, bs=24, shuffle=False)\n",
        "\n",
        "class BiGRUCTC(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=256, layers=2, num_classes=21, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.GRU(input_size=in_dim, hidden_size=hidden, num_layers=layers,\n",
        "                          dropout=dropout, bidirectional=True)\n",
        "        self.proj = nn.Linear(hidden*2, num_classes)\n",
        "    def forward(self, x, x_lens):  # x: (T,B,D)\n",
        "        packed = pack_padded_sequence(x, x_lens.cpu(), enforce_sorted=False)\n",
        "        out, _ = self.rnn(packed)\n",
        "        out, _ = pad_packed_sequence(out)  # (T,B,2H)\n",
        "        logits = self.proj(out)  # (T,B,C)\n",
        "        return logits\n",
        "\n",
        "def ctc_greedy_decode(logits):\n",
        "    # logits: (T,B,C)\n",
        "    with torch.no_grad():\n",
        "        pred = logits.argmax(dim=-1)  # (T,B)\n",
        "        pred = pred.cpu().numpy()\n",
        "    seqs = []\n",
        "    T, B = pred.shape\n",
        "    for b in range(B):\n",
        "        last = -1\n",
        "        out = []\n",
        "        for t in range(T):\n",
        "            p = int(pred[t, b])\n",
        "            if p != last:\n",
        "                if p != 0:  # skip blank\n",
        "                    out.append(p)\n",
        "                last = p\n",
        "        seqs.append(out)\n",
        "    return seqs\n",
        "\n",
        "def levenshtein(a, b):\n",
        "    # a, b: lists of ints\n",
        "    n, m = len(a), len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp = list(range(m+1))\n",
        "    for i in range(1, n+1):\n",
        "        prev = dp[0]\n",
        "        dp[0] = i\n",
        "        ai = a[i-1]\n",
        "        for j in range(1, m+1):\n",
        "            tmp = dp[j]\n",
        "            cost = 0 if ai==b[j-1] else 1\n",
        "            dp[j] = min(dp[j]+1, dp[j-1]+1, prev+cost)\n",
        "            prev = tmp\n",
        "    return dp[m]\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_lev = 0.0; total = 0;\n",
        "    with torch.no_grad():\n",
        "        for xb, x_lens, y_cat, y_lens, sids in loader:\n",
        "            xb = xb.to(device)\n",
        "            x_lens = x_lens.to(device)\n",
        "            logits = model(xb, x_lens)  # (T,B,C)\n",
        "            seqs = ctc_greedy_decode(logits)\n",
        "            # split y_cat into per-sample\n",
        "            ys = []\n",
        "            off = 0\n",
        "            for L in y_lens.tolist():\n",
        "                ys.append(y_cat[off:off+L].tolist()); off += L\n",
        "            for p, t in zip(seqs, ys):\n",
        "                # Optionally enforce min-length to reduce insertions (cheap post-process)\n",
        "                total_lev += levenshtein(p, t)\n",
        "                total += 1\n",
        "    return total_lev/total if total>0 else math.inf\n",
        "\n",
        "D_sample = np.load(next(iter(features_dir.glob('*.npz'))))['X'].shape[1]\n",
        "print(\"Feature dim:\", D_sample)\n",
        "model = BiGRUCTC(in_dim=D_sample, hidden=256, layers=2, num_classes=class_n, dropout=0.2).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "\n",
        "def train_epoch(ep):\n",
        "    model.train()\n",
        "    t0 = time.time()\n",
        "    total_loss = 0.0; nb = 0\n",
        "    for it, (xb, x_lens, y_cat, y_lens, sids) in enumerate(train_loader):\n",
        "        xb = xb.to(device)\n",
        "        y_cat = y_cat.to(device)\n",
        "        x_lens = x_lens.to(device, non_blocking=True)\n",
        "        y_lens = y_lens.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "            logits = model(xb, x_lens)  # (T,B,C)\n",
        "            log_probs = logits.log_softmax(dim=-1)\n",
        "            # CTC expects (T,B,C)\n",
        "            loss = ctc_loss(log_probs, y_cat, x_lens, y_lens)\n",
        "        scaler.scale(loss).backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        scaler.step(optimizer); scaler.update()\n",
        "        total_loss += loss.item(); nb += 1\n",
        "        if (it+1) % 20 == 0:\n",
        "            print(f\"ep{ep} it{it+1} loss={total_loss/nb:.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "    return total_loss/max(nb,1)\n",
        "\n",
        "best_val = math.inf; best_state = None; patience = 3; bad = 0\n",
        "max_epochs = 6\n",
        "for ep in range(1, max_epochs+1):\n",
        "    tr_loss = train_epoch(ep)\n",
        "    val_lev = evaluate(model, val_loader)\n",
        "    print(f\"Epoch {ep}: train_loss={tr_loss:.4f} val_lev={val_lev:.4f}\", flush=True)\n",
        "    if val_lev < best_val - 1e-4:\n",
        "        best_val = val_lev; best_state = {k:v.cpu() for k,v in model.state_dict().items()}; bad = 0\n",
        "        print(f\"  New best val_lev={best_val:.4f}\", flush=True)\n",
        "    else:\n",
        "        bad += 1\n",
        "        if bad >= patience:\n",
        "            print(\"Early stopping.\", flush=True); break\n",
        "\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state)\n",
        "torch.save(model.state_dict(), 'model_ctc_bgru.pth')\n",
        "print(\"=== Training complete. Saved model_ctc_bgru.pth ===\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train BiGRU+CTC on cached 3D features (train split with small val) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train videos: 253, Val videos: 44\nFeature dim: 180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/3203993078.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/3203993078.py:150: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss=51.8156 val_lev=18.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=18.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: train_loss=3.7155 val_lev=18.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: train_loss=3.3192 val_lev=18.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: train_loss=3.1670 val_lev=18.8409\n"
          ]
        }
      ]
    },
    {
      "id": "6f8cbb26-b9d1-4a95-bee4-08f932e461d8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, json, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=== Cache TEST features: 3D world pos + vel/acc at ~10 fps ===\", flush=True)\n",
        "\n",
        "# Reuse helpers from earlier cells: cache_one_world3d, test_idx, id_to_zipname\n",
        "test_df = pd.read_csv('test.csv')\n",
        "test_ids = test_df['Id'].astype(int).tolist()\n",
        "outdir = Path('features3d')/'test'\n",
        "outdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "total = len(test_ids)\n",
        "t0 = time.time()\n",
        "done = 0\n",
        "skipped = 0\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    outp = outdir/f\"{sid}.npz\"\n",
        "    if outp.exists():\n",
        "        skipped += 1\n",
        "        if i % 10 == 0:\n",
        "            dt = time.time() - t0\n",
        "            rate = (i)/(dt+1e-9)\n",
        "            eta = (total - i)/max(rate,1e-6)\n",
        "            print(f\"[test] {i}/{total} (skip={skipped}) elapsed={dt/60:.1f}m eta={eta/60:.1f}m\", flush=True)\n",
        "        continue\n",
        "    st = time.time()\n",
        "    try:\n",
        "        cache_one_world3d(int(sid), 'test', outdir)\n",
        "        done += 1\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] test id={sid} failed: {e}\", flush=True)\n",
        "        continue\n",
        "    if (i % 10) == 0 or i == total:\n",
        "        dt = time.time() - t0\n",
        "        rate = (i)/(dt+1e-9)\n",
        "        eta = (total - i)/max(rate,1e-6)\n",
        "        print(f\"[test] {i}/{total} cached={done} skip={skipped} last={time.time()-st:.2f}s elapsed={dt/60:.1f}m eta={eta/60:.1f}m\", flush=True)\n",
        "    gc.collect()\n",
        "\n",
        "print(f\"=== TEST caching done: cached={done}, skipped={skipped}, total={total}, elapsed={(time.time()-t0)/60:.2f}m ===\", flush=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Cache TEST features: 3D world pos + vel/acc at ~10 fps ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] 10/95 cached=10 skip=0 last=0.43s elapsed=0.1m eta=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] 20/95 cached=20 skip=0 last=0.69s elapsed=0.2m eta=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] 30/95 cached=30 skip=0 last=0.91s elapsed=0.3m eta=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] 40/95 cached=40 skip=0 last=1.25s elapsed=0.5m eta=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] 50/95 cached=50 skip=0 last=1.51s elapsed=0.8m eta=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] 60/95 cached=60 skip=0 last=1.79s elapsed=1.1m eta=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] 70/95 cached=70 skip=0 last=2.16s elapsed=1.4m eta=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] 80/95 cached=80 skip=0 last=2.30s elapsed=1.8m eta=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] 90/95 cached=90 skip=0 last=2.53s elapsed=2.2m eta=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] 95/95 cached=95 skip=0 last=2.64s elapsed=2.4m eta=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEST caching done: cached=95, skipped=0, total=95, elapsed=2.43m ===\n"
          ]
        }
      ]
    },
    {
      "id": "804f4dfc-1981-48fb-9b34-d721404f6816",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math, json, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"=== Inference on TEST: greedy CTC with fallback to class-ranking; write submission.csv ===\", flush=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "test_ids = test_df['Id'].astype(int).tolist()\n",
        "feat_dir = Path('features3d')/'test'\n",
        "\n",
        "class BiGRUCTC(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=256, layers=2, num_classes=21, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.GRU(input_size=in_dim, hidden_size=hidden, num_layers=layers,\n",
        "                          dropout=dropout, bidirectional=True)\n",
        "        self.proj = nn.Linear(hidden*2, num_classes)\n",
        "    def forward(self, x, x_lens):\n",
        "        from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "        packed = pack_padded_sequence(x, x_lens.cpu(), enforce_sorted=False)\n",
        "        out, _ = self.rnn(packed)\n",
        "        out, _ = pad_packed_sequence(out)\n",
        "        logits = self.proj(out)\n",
        "        return logits\n",
        "\n",
        "def load_feat(sample_id: int):\n",
        "    p = feat_dir/f\"{sample_id}.npz\"\n",
        "    d = np.load(p)\n",
        "    X = d['X'].astype(np.float32)\n",
        "    if X.shape[0] > 1200: X = X[:1200]\n",
        "    return X\n",
        "\n",
        "def ctc_greedy(logits):\n",
        "    # logits: (T,C) tensor\n",
        "    pred = logits.argmax(dim=-1).cpu().numpy().tolist()\n",
        "    out = []\n",
        "    last = -1\n",
        "    for p in pred:\n",
        "        if p != last:\n",
        "            if p != 0:\n",
        "                out.append(int(p))\n",
        "            last = p\n",
        "    return out\n",
        "\n",
        "def fallback_rank(logits):\n",
        "    # logits: (T,C) tensor; compute per-class mean score and rank 1..20\n",
        "    with torch.no_grad():\n",
        "        lp = logits[:, 1:21].mean(dim=0)  # exclude blank\n",
        "        order = torch.argsort(lp, descending=True).cpu().numpy().tolist()\n",
        "    seq = [int(i+1) for i in order[:20]]\n",
        "    return seq\n",
        "\n",
        "def ensure_len20(seq, logits):\n",
        "    # If seq invalid (len!=20 or duplicates or out of range), use fallback ranking\n",
        "    ok = (len(seq) == 20) and all(1 <= s <= 20 for s in seq) and (len(set(seq)) == 20)\n",
        "    if ok: return seq\n",
        "    return fallback_rank(logits)\n",
        "\n",
        "# Load model with inferred input dim from one train npz\n",
        "train_any = next(iter((Path('features3d')/'train').glob('*.npz')))\n",
        "in_dim = np.load(train_any)['X'].shape[1]\n",
        "model = BiGRUCTC(in_dim=in_dim, hidden=256, layers=2, num_classes=21, dropout=0.2).to(device)\n",
        "state = torch.load('model_ctc_bgru.pth', map_location=device)\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "\n",
        "pred_rows = []\n",
        "t0 = time.time()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    X = load_feat(sid)  # (T,D)\n",
        "    xb = torch.from_numpy(X).to(device)  # (T,D)\n",
        "    xb = xb.unsqueeze(1)  # (T,1,D)\n",
        "    x_lens = torch.tensor([xb.shape[0]], dtype=torch.int32, device=device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(xb, x_lens)  # (T,1,C)\n",
        "        logits = logits[:,0,:]  # (T,C)\n",
        "    seq = ctc_greedy(logits)\n",
        "    seq = ensure_len20(seq, logits)\n",
        "    pred_rows.append({'Id': sid, 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if i % 10 == 0 or i == len(test_ids):\n",
        "        print(f\"[infer] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "\n",
        "sub = pd.DataFrame(pred_rows, columns=['Id','Sequence'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print(\"Wrote submission.csv; head:\\n\", sub.head())\n",
        "print(\"=== Inference done ===\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Inference on TEST: greedy CTC with fallback to class-ranking; write submission.csv ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/3346178340.py:66: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load('model_ctc_bgru.pth', map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] 80/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] 90/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer] 95/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv; head:\n     Id                                           Sequence\n0  300  9 18 20 16 2 5 10 15 14 13 7 17 4 11 3 19 1 8 ...\n1  301  9 18 16 20 2 5 10 15 14 13 7 17 4 3 11 19 1 8 ...\n2  302  9 18 16 20 2 5 10 15 14 13 7 17 4 3 11 19 1 8 ...\n3  303  9 18 16 20 2 5 10 15 7 14 13 17 4 3 11 19 1 8 ...\n4  304  9 18 16 20 2 5 10 15 7 14 13 17 4 3 11 19 1 8 ...\n=== Inference done ===\n"
          ]
        }
      ]
    },
    {
      "id": "f3b53de2-c79f-4bf1-8eb8-787c2c9d9c10",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"=== Inference (CTC beam) with penalties and constraints -> submission.csv ===\", flush=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "test_ids = test_df['Id'].astype(int).tolist()\n",
        "feat_dir = Path('features3d')/'test'\n",
        "\n",
        "# Hyperparams (tune later):\n",
        "beam_width = 50\n",
        "temperature = 1.4  # divide logits by this before log_softmax\n",
        "insertion_penalty = 0.6  # subtract only when appending a non-blank token\n",
        "min_run_len = 6  # frames at ~10 fps\n",
        "blank_prob_thresh = 0.985  # prune non-blank expansions on very-blank frames\n",
        "top_k_nonblank = 8  # per-frame top-k for non-blank expansions\n",
        "\n",
        "class BiGRUCTC(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=256, layers=2, num_classes=21, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.GRU(input_size=in_dim, hidden_size=hidden, num_layers=layers,\n",
        "                          dropout=dropout, bidirectional=True)\n",
        "        self.proj = nn.Linear(hidden*2, num_classes)\n",
        "    def forward(self, x, x_lens):\n",
        "        from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "        packed = pack_padded_sequence(x, x_lens.cpu(), enforce_sorted=False)\n",
        "        out, _ = self.rnn(packed)\n",
        "        out, _ = pad_packed_sequence(out)\n",
        "        logits = self.proj(out)\n",
        "        return logits\n",
        "\n",
        "def load_feat(sample_id: int):\n",
        "    p = feat_dir/f\"{sample_id}.npz\"\n",
        "    d = np.load(p)\n",
        "    X = d['X'].astype(np.float32)\n",
        "    if X.shape[0] > 1200: X = X[:1200]\n",
        "    return X\n",
        "\n",
        "def runs_from_path(tokens, timesteps):\n",
        "    # returns list of (token, start_t, end_t) inclusive on time axis (end_t included)\n",
        "    runs = []\n",
        "    if len(tokens) == 0:\n",
        "        return runs\n",
        "    cur_tok = tokens[0]\n",
        "    start_idx = 0\n",
        "    for i in range(1, len(tokens)+1):\n",
        "        nxt = tokens[i] if i < len(tokens) else None\n",
        "        if nxt != cur_tok:\n",
        "            # segment covers indices [start_idx, i-1] in tokens/timesteps\n",
        "            t_start = timesteps[start_idx]\n",
        "            t_end = timesteps[i-1]\n",
        "            runs.append((cur_tok, int(t_start), int(t_end)))\n",
        "            if nxt is None: break\n",
        "            cur_tok = nxt\n",
        "            start_idx = i\n",
        "    return runs\n",
        "\n",
        "def collapse_and_prune(tokens, timesteps, min_len_frames):\n",
        "    # collapse identical consecutive tokens, convert to runs, then drop short runs by frame duration\n",
        "    runs = runs_from_path(tokens, timesteps)\n",
        "    kept = []\n",
        "    for tok, t0, t1 in runs:\n",
        "        if tok == 0 or tok is None:\n",
        "            continue\n",
        "        duration = (t1 - t0 + 1)\n",
        "        if duration >= min_len_frames:\n",
        "            kept.append((tok, t0, t1))\n",
        "    return kept  # list of (tok, t0, t1)\n",
        "\n",
        "def enforce_exact_20(runs, lp):\n",
        "    # runs: list of (tok, t0, t1), lp: (T,C) log-probs\n",
        "    # Step 1: order-preserving trim if > 20 using mean score over time span\n",
        "    if len(runs) > 20:\n",
        "        # score by mean log-prob over the token's segment\n",
        "        scores = []\n",
        "        for tok, t0, t1 in runs:\n",
        "            seg = lp[t0:t1+1, tok]\n",
        "            scores.append(float(seg.mean().item()))\n",
        "        # get indices sorted by score desc, keep top 20 but preserve original temporal order\n",
        "        keep_idx = set([i for i,_ in sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[:20]])\n",
        "        runs = [r for i, r in enumerate(runs) if i in keep_idx]\n",
        "        runs.sort(key=lambda x: x[1])  # sort by start time to preserve order\n",
        "    # Step 2: if < 20, insert missing classes by peak time; preserve order\n",
        "    have = [tok for tok, _, _ in runs]\n",
        "    need = [c for c in range(1, 21) if c not in have]\n",
        "    if len(runs) < 20 and len(need) > 0:\n",
        "        peaks = []\n",
        "        for c in need:\n",
        "            t_star = int(torch.argmax(lp[:, c]).item())\n",
        "            peaks.append((c, t_star))\n",
        "        # insert as tiny runs [t*, t*] then merge and sort\n",
        "        for c, t_star in peaks:\n",
        "            runs.append((c, t_star, t_star))\n",
        "        runs.sort(key=lambda x: x[1])\n",
        "        # if still > 20 due to excessive insertions (unlikely), trim by per-run mean score\n",
        "        if len(runs) > 20:\n",
        "            scores = [float(lp[t0:t1+1, tok].mean().item()) for tok, t0, t1 in runs]\n",
        "            keep_idx = set([i for i,_ in sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[:20]])\n",
        "            runs = [r for i, r in enumerate(runs) if i in keep_idx]\n",
        "            runs.sort(key=lambda x: x[1])\n",
        "    # Deduplicate by first occurrence (should already be unique)\n",
        "    seen = set(); seq = []\n",
        "    for tok, _, _ in runs:\n",
        "        if tok not in seen:\n",
        "            seq.append(tok); seen.add(tok)\n",
        "    # final guard\n",
        "    if len(seq) > 20: seq = seq[:20]\n",
        "    # if somehow <20 (very weak logits), fill by global ranking\n",
        "    if len(seq) < 20:\n",
        "        # rank by mean nonblank\n",
        "        mean_nonblank = lp[:, 1:21].mean(dim=0)\n",
        "        order = torch.argsort(mean_nonblank, descending=True).cpu().numpy().tolist()\n",
        "        for idx in order:\n",
        "            c = idx + 1\n",
        "            if c not in seq:\n",
        "                seq.append(c)\n",
        "                if len(seq) == 20: break\n",
        "    return seq\n",
        "\n",
        "def simple_beam_decode(logits):\n",
        "    # logits: (T,C) tensor on device; C=21, blank=0\n",
        "    # Apply temperature and convert to log-probs\n",
        "    lp = (logits / temperature).log_softmax(dim=-1)  # (T,C)\n",
        "    T, C = lp.shape\n",
        "    # Beams: (logp, last_token, tokens_list, timesteps_list)\n",
        "    beams = [(0.0, 0, [], [])]\n",
        "    for t in range(T):\n",
        "        frame = lp[t]  # (C,)\n",
        "        p_blank = torch.exp(frame[0]).item()\n",
        "        new_beams = []\n",
        "        # Always allow blank transition (stay)\n",
        "        for logp, last, toks, ts in beams:\n",
        "            stay_lp = logp + frame[0].item()\n",
        "            new_beams.append((stay_lp, last, toks, ts))\n",
        "        # If frame is highly blank, skip non-blank expansions\n",
        "        if p_blank < blank_prob_thresh:\n",
        "            # Expand non-blank with per-frame top-k\n",
        "            vals, idxs = torch.topk(frame[1:], k=min(top_k_nonblank, C-1))\n",
        "            vals = vals.tolist(); idxs = idxs.tolist()\n",
        "            for logp, last, toks, ts in beams:\n",
        "                for v, idx in zip(vals, idxs):\n",
        "                    c = idx + 1\n",
        "                    # Enforce CTC no-repeat without blank: if last == c, discourage by not adding\n",
        "                    if last == c:\n",
        "                        continue\n",
        "                    nl = logp + v - insertion_penalty  # apply insertion penalty only on non-blank\n",
        "                    new_beams.append((nl, c, toks + [c], ts + [t]))\n",
        "        # prune to beam_width\n",
        "        new_beams.sort(key=lambda x: x[0], reverse=True)\n",
        "        beams = new_beams[:beam_width]\n",
        "    # pick best beam and post-process\n",
        "    best = max(beams, key=lambda x: x[0])\n",
        "    _, _, toks, ts = best\n",
        "    kept_runs = collapse_and_prune(toks, ts, min_run_len)\n",
        "    seq = enforce_exact_20(kept_runs, lp)\n",
        "    return seq\n",
        "\n",
        "# Load model\n",
        "train_any = next(iter((Path('features3d')/'train').glob('*.npz')))\n",
        "in_dim = np.load(train_any)['X'].shape[1]\n",
        "model = BiGRUCTC(in_dim=in_dim, hidden=256, layers=2, num_classes=21, dropout=0.2).to(device)\n",
        "state = torch.load('model_ctc_bgru.pth', map_location=device)\n",
        "model.load_state_dict(state); model.eval()\n",
        "\n",
        "pred_rows = []\n",
        "t0 = time.time()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    X = load_feat(sid)  # (T,D)\n",
        "    xb = torch.from_numpy(X).to(device).unsqueeze(1)  # (T,1,D)\n",
        "    x_lens = torch.tensor([xb.shape[0]], dtype=torch.int32, device=device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(xb, x_lens)[:,0,:]  # (T,C)\n",
        "    seq = simple_beam_decode(logits)\n",
        "    pred_rows.append({'Id': sid, 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if i % 10 == 0 or i == len(test_ids):\n",
        "        print(f\"[beam infer] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "\n",
        "sub = pd.DataFrame(pred_rows, columns=['Id','Sequence'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv; head:\\n', sub.head())\n",
        "print(\"=== Beam inference done ===\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Inference (CTC beam) with penalties and constraints -> submission.csv ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/1065424625.py:167: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load('model_ctc_bgru.pth', map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[beam infer] 10/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[beam infer] 20/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[beam infer] 30/95 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[beam infer] 40/95 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[beam infer] 50/95 elapsed=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[beam infer] 60/95 elapsed=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[beam infer] 70/95 elapsed=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[beam infer] 80/95 elapsed=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[beam infer] 90/95 elapsed=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[beam infer] 95/95 elapsed=0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv; head:\n     Id                                           Sequence\n0  300  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n1  301  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n2  302  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n3  303  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n4  304  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...\n=== Beam inference done ===\n"
          ]
        }
      ]
    },
    {
      "id": "56cc105b-06a3-4b06-951e-b14e34525c76",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math, time, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"=== Validate beam decoder on internal holdout and tune hyperparams ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feat_dir_tr = Path('features3d')/'train'\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "# Deterministic split to mirror earlier run\n",
        "all_ids = [int(x) for x in train_df['Id'].tolist()]\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "print(f\"Val videos: {len(val_ids)}\")\n",
        "\n",
        "def load_feat_tr(sample_id: int):\n",
        "    p = feat_dir_tr/f\"{sample_id}.npz\"\n",
        "    d = np.load(p)\n",
        "    X = d['X'].astype(np.float32)\n",
        "    if X.shape[0] > 1200: X = X[:1200]\n",
        "    return X\n",
        "\n",
        "class BiGRUCTC(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=256, layers=2, num_classes=21, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.GRU(input_size=in_dim, hidden_size=hidden, num_layers=layers,\n",
        "                          dropout=dropout, bidirectional=True)\n",
        "        self.proj = nn.Linear(hidden*2, num_classes)\n",
        "    def forward(self, x, x_lens):\n",
        "        from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "        packed = pack_padded_sequence(x, x_lens.cpu(), enforce_sorted=False)\n",
        "        out, _ = self.rnn(packed)\n",
        "        out, _ = pad_packed_sequence(out)\n",
        "        logits = self.proj(out)\n",
        "        return logits\n",
        "\n",
        "def levenshtein(a, b):\n",
        "    n, m = len(a), len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp = list(range(m+1))\n",
        "    for i in range(1, n+1):\n",
        "        prev = dp[0]; dp[0] = i; ai = a[i-1]\n",
        "        for j in range(1, m+1):\n",
        "            tmp = dp[j]\n",
        "            cost = 0 if ai==b[j-1] else 1\n",
        "            dp[j] = min(dp[j]+1, dp[j-1]+1, prev+cost)\n",
        "            prev = tmp\n",
        "    return dp[m]\n",
        "\n",
        "# Reuse decoder/utilities from Cell 12 if present; otherwise import minimal versions\n",
        "assert 'simple_beam_decode' in globals(), \"Run Cell 12 once before this tuning cell.\"\n",
        "assert 'enforce_exact_20' in globals() and 'collapse_and_prune' in globals(), \"Run Cell 12 first.\"\n",
        "\n",
        "# Build model\n",
        "in_dim = np.load(next(iter(feat_dir_tr.glob('*.npz'))))['X'].shape[1]\n",
        "model = BiGRUCTC(in_dim=in_dim, hidden=256, layers=2, num_classes=21, dropout=0.2).to(device)\n",
        "state = torch.load('model_ctc_bgru.pth', map_location=device)\n",
        "model.load_state_dict(state); model.eval()\n",
        "\n",
        "def decode_val_once():\n",
        "    tot_lev = 0.0; n = 0; lens = []; uniq_ok = 0\n",
        "    t0 = time.time()\n",
        "    for i, sid in enumerate(val_ids, 1):\n",
        "        X = load_feat_tr(sid)\n",
        "        xb = torch.from_numpy(X).to(device).unsqueeze(1)\n",
        "        x_lens = torch.tensor([xb.shape[0]], dtype=torch.int32, device=device)\n",
        "        with torch.no_grad():\n",
        "            logits = model(xb, x_lens)[:,0,:]\n",
        "        seq = simple_beam_decode(logits)\n",
        "        tgt = id2seq[sid]\n",
        "        tot_lev += levenshtein(seq, tgt)\n",
        "        n += 1\n",
        "        lens.append(len(seq))\n",
        "        uniq_ok += int(len(seq)==20 and len(set(seq))==20 and all(1<=x<=20 for x in seq))\n",
        "        if (i % 10) == 0 or i==len(val_ids):\n",
        "            print(f\"  [val] {i}/{len(val_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    return (tot_lev/n if n else math.inf), (sum(lens)/max(n,1)), (uniq_ok/max(n,1))\n",
        "\n",
        "# Small grid per expert advice (keep fast):\n",
        "cfgs = []\n",
        "for bw in [40, 50]:\n",
        "    for temp in [1.3, 1.4]:\n",
        "        for pen in [0.6, 0.8]:\n",
        "            for mlen in [6, 8]:\n",
        "                for bth in [0.985, 0.99]:\n",
        "                    cfgs.append(dict(beam_width=bw, temperature=temp, insertion_penalty=pen, min_run_len=mlen, blank_prob_thresh=bth))\n",
        "\n",
        "results = []\n",
        "print(f\"Testing {len(cfgs)} configs on {len(val_ids)} videos\", flush=True)\n",
        "for ci, cfg in enumerate(cfgs, 1):\n",
        "    # assign globals used by simple_beam_decode\n",
        "    beam_width = cfg['beam_width']\n",
        "    temperature = cfg['temperature']\n",
        "    insertion_penalty = cfg['insertion_penalty']\n",
        "    min_run_len = cfg['min_run_len']\n",
        "    blank_prob_thresh = cfg['blank_prob_thresh']\n",
        "    print(f\"[{ci}/{len(cfgs)}] cfg={cfg}\", flush=True)\n",
        "    lev, avg_len, uniq = decode_val_once()\n",
        "    results.append((lev, avg_len, uniq, cfg))\n",
        "    print(f\"  -> val_lev={lev:.4f} avg_len={avg_len:.2f} uniq_ok={uniq:.2f}\", flush=True)\n",
        "\n",
        "results.sort(key=lambda x: x[0])\n",
        "print(\"=== Top configs ===\")\n",
        "for r in results[:5]:\n",
        "    print(f\"lev={r[0]:.4f} avg_len={r[1]:.2f} uniq={r[2]:.2f} cfg={r[3]}\")\n",
        "best = results[0]\n",
        "print(\"BEST:\", best)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Validate beam decoder on internal holdout and tune hyperparams ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val videos: 44\nTesting 32 configs on 44 videos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/32] cfg={'beam_width': 40, 'temperature': 1.3, 'insertion_penalty': 0.6, 'min_run_len': 6, 'blank_prob_thresh': 0.985}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/2058221973.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load('model_ctc_bgru.pth', map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2727 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2/32] cfg={'beam_width': 40, 'temperature': 1.3, 'insertion_penalty': 0.6, 'min_run_len': 6, 'blank_prob_thresh': 0.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2727 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3/32] cfg={'beam_width': 40, 'temperature': 1.3, 'insertion_penalty': 0.6, 'min_run_len': 8, 'blank_prob_thresh': 0.985}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2727 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4/32] cfg={'beam_width': 40, 'temperature': 1.3, 'insertion_penalty': 0.6, 'min_run_len': 8, 'blank_prob_thresh': 0.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2727 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5/32] cfg={'beam_width': 40, 'temperature': 1.3, 'insertion_penalty': 0.8, 'min_run_len': 6, 'blank_prob_thresh': 0.985}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2727 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6/32] cfg={'beam_width': 40, 'temperature': 1.3, 'insertion_penalty': 0.8, 'min_run_len': 6, 'blank_prob_thresh': 0.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2727 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7/32] cfg={'beam_width': 40, 'temperature': 1.3, 'insertion_penalty': 0.8, 'min_run_len': 8, 'blank_prob_thresh': 0.985}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2727 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8/32] cfg={'beam_width': 40, 'temperature': 1.3, 'insertion_penalty': 0.8, 'min_run_len': 8, 'blank_prob_thresh': 0.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2727 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9/32] cfg={'beam_width': 40, 'temperature': 1.4, 'insertion_penalty': 0.6, 'min_run_len': 6, 'blank_prob_thresh': 0.985}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2955 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10/32] cfg={'beam_width': 40, 'temperature': 1.4, 'insertion_penalty': 0.6, 'min_run_len': 6, 'blank_prob_thresh': 0.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2955 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11/32] cfg={'beam_width': 40, 'temperature': 1.4, 'insertion_penalty': 0.6, 'min_run_len': 8, 'blank_prob_thresh': 0.985}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2955 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12/32] cfg={'beam_width': 40, 'temperature': 1.4, 'insertion_penalty': 0.6, 'min_run_len': 8, 'blank_prob_thresh': 0.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2955 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13/32] cfg={'beam_width': 40, 'temperature': 1.4, 'insertion_penalty': 0.8, 'min_run_len': 6, 'blank_prob_thresh': 0.985}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2955 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14/32] cfg={'beam_width': 40, 'temperature': 1.4, 'insertion_penalty': 0.8, 'min_run_len': 6, 'blank_prob_thresh': 0.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2955 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15/32] cfg={'beam_width': 40, 'temperature': 1.4, 'insertion_penalty': 0.8, 'min_run_len': 8, 'blank_prob_thresh': 0.985}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2955 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16/32] cfg={'beam_width': 40, 'temperature': 1.4, 'insertion_penalty': 0.8, 'min_run_len': 8, 'blank_prob_thresh': 0.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2955 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17/32] cfg={'beam_width': 50, 'temperature': 1.3, 'insertion_penalty': 0.6, 'min_run_len': 6, 'blank_prob_thresh': 0.985}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 30/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 40/44 elapsed=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44/44 elapsed=0.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> val_lev=18.2727 avg_len=20.00 uniq_ok=1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18/32] cfg={'beam_width': 50, 'temperature': 1.3, 'insertion_penalty': 0.6, 'min_run_len': 6, 'blank_prob_thresh': 0.99}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 10/44 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 20/44 elapsed=0.2m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 106\u001b[39m\n\u001b[32m    104\u001b[39m blank_prob_thresh = cfg[\u001b[33m'\u001b[39m\u001b[33mblank_prob_thresh\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    105\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mci\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(cfgs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] cfg=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m lev, avg_len, uniq = \u001b[43mdecode_val_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m results.append((lev, avg_len, uniq, cfg))\n\u001b[32m    108\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  -> val_lev=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlev\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m avg_len=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_len\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m uniq_ok=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muniq\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mdecode_val_once\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     76\u001b[39m     logits = model(xb, x_lens)[:,\u001b[32m0\u001b[39m,:]\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m seq = \u001b[43msimple_beam_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m tgt = id2seq[sid]\n\u001b[32m     79\u001b[39m tot_lev += levenshtein(seq, tgt)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36msimple_beam_decode\u001b[39m\u001b[34m(logits)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Always allow blank transition (stay)\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m logp, last, toks, ts \u001b[38;5;129;01min\u001b[39;00m beams:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     stay_lp = logp + \u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m     new_beams.append((stay_lp, last, toks, ts))\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# If frame is highly blank, skip non-blank expansions\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "95cf8c3b-6087-438d-b046-fee738a43901",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, math, time, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "print(\"=== Train 3x384 BiGRU+CTC with input projection, LN, time masking, feature standardization ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "random.seed(42); np.random.seed(42); torch.manual_seed(42);\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "feat_dir = Path('features3d')/'train'\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "all_ids = [int(x) for x in train_df['Id'].tolist()]\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "tr_ids = all_ids[val_n:]\n",
        "print(f\"Train videos: {len(tr_ids)}, Val videos: {len(val_ids)}\")\n",
        "\n",
        "# Compute and cache global mean/std over TRAIN features (across time and samples)\n",
        "scaler_path = Path('feature_scaler.npz')\n",
        "if scaler_path.exists():\n",
        "    sc = np.load(scaler_path)\n",
        "    mu, sigma = sc['mean'].astype(np.float32), sc['std'].astype(np.float32)\n",
        "else:\n",
        "    sum_vec = None; sumsq_vec = None; count = 0\n",
        "    t0 = time.time()\n",
        "    for i, sid in enumerate(tr_ids, 1):\n",
        "        d = np.load(feat_dir/f\"{sid}.npz\")['X'].astype(np.float32)\n",
        "        if d.shape[0] > 1200: d = d[:1200]\n",
        "        if sum_vec is None:\n",
        "            sum_vec = np.zeros(d.shape[1], np.float32)\n",
        "            sumsq_vec = np.zeros(d.shape[1], np.float32)\n",
        "        sum_vec += d.sum(axis=0)\n",
        "        sumsq_vec += (d*d).sum(axis=0)\n",
        "        count += d.shape[0]\n",
        "        if (i % 50) == 0 or i == len(tr_ids):\n",
        "            print(f\"[scaler] {i}/{len(tr_ids)} frames_accum={count} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    mu = sum_vec / max(count,1)\n",
        "    var = np.maximum(sumsq_vec / max(count,1) - mu*mu, 1e-6)\n",
        "    sigma = np.sqrt(var).astype(np.float32)\n",
        "    np.savez_compressed(scaler_path, mean=mu, std=sigma)\n",
        "print(\"Scaler stats:\", mu.shape, sigma.shape, \"std min/max:\", float(sigma.min()), float(sigma.max()))\n",
        "\n",
        "def load_npz_std(sample_id: int):\n",
        "    d = np.load(feat_dir/f\"{sample_id}.npz\")\n",
        "    X = d['X'].astype(np.float32)\n",
        "    if X.shape[0] > 1200: X = X[:1200]\n",
        "    X = (X - mu) / sigma\n",
        "    return X\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, ids): self.ids = ids\n",
        "    def __len__(self): return len(self.ids)\n",
        "    def __getitem__(self, idx):\n",
        "        sid = self.ids[idx]\n",
        "        X = load_npz_std(sid)\n",
        "        y = np.array(id2seq[sid], dtype=np.int64)\n",
        "        return torch.from_numpy(X), torch.from_numpy(y), sid\n",
        "\n",
        "def collate(batch):\n",
        "    xs, ys, sids = zip(*batch)\n",
        "    x_lens = torch.tensor([x.shape[0] for x in xs], dtype=torch.int32)\n",
        "    y_lens = torch.tensor([y.shape[0] for y in ys], dtype=torch.int32)\n",
        "    x_pad = pad_sequence(xs, batch_first=False)  # (T,B,D)\n",
        "    y_cat = torch.cat(ys, dim=0)\n",
        "    return x_pad, x_lens, y_cat, y_lens, sids\n",
        "\n",
        "train_loader = DataLoader(SeqDataset(tr_ids), batch_size=24, shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate)\n",
        "val_loader   = DataLoader(SeqDataset(val_ids), batch_size=24, shuffle=False, num_workers=2, pin_memory=True, collate_fn=collate)\n",
        "\n",
        "class InputProj(nn.Module):\n",
        "    def __init__(self, in_dim, hid):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(in_dim, hid)\n",
        "        self.ln = nn.LayerNorm(hid)\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "    def forward(self, x):  # x: (T,B,D)\n",
        "        y = self.lin(x)\n",
        "        y = self.ln(y)\n",
        "        return self.act(y)\n",
        "\n",
        "class BiGRUCTCStrong(nn.Module):\n",
        "    def __init__(self, in_dim, proj=256, hidden=384, layers=3, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = InputProj(in_dim, proj)\n",
        "        self.rnn = nn.GRU(input_size=proj, hidden_size=hidden, num_layers=layers, dropout=dropout, bidirectional=True)\n",
        "        self.proj = nn.Linear(hidden*2, num_classes)\n",
        "    def forward(self, x, x_lens):\n",
        "        x = self.inp(x)\n",
        "        packed = pack_padded_sequence(x, x_lens.cpu(), enforce_sorted=False)\n",
        "        out, _ = self.rnn(packed)\n",
        "        out, _ = pad_packed_sequence(out)\n",
        "        return self.proj(out)\n",
        "\n",
        "def time_mask(x, max_width=16, nmask=2, p=0.5):\n",
        "    # x: (T,B,D), inplace mask\n",
        "    if random.random() > p: return x\n",
        "    T = x.size(0)\n",
        "    for _ in range(nmask):\n",
        "        w = random.randint(1, max_width)\n",
        "        t0 = random.randint(0, max(0, T - w))\n",
        "        x[t0:t0+w] = 0\n",
        "    return x\n",
        "\n",
        "def ctc_greedy(logits):\n",
        "    pred = logits.argmax(dim=-1).cpu().numpy()  # (T,B)\n",
        "    T,B = pred.shape\n",
        "    seqs = []\n",
        "    for b in range(B):\n",
        "        out = []; last = -1\n",
        "        for t in range(T):\n",
        "            p = int(pred[t,b])\n",
        "            if p != last:\n",
        "                if p != 0: out.append(p)\n",
        "                last = p\n",
        "        seqs.append(out)\n",
        "    return seqs\n",
        "\n",
        "def fallback_rank_framewise(logits_b):\n",
        "    # logits_b: (T,C) for one sample\n",
        "    with torch.no_grad():\n",
        "        lp = logits_b[:,1:21].mean(dim=0)\n",
        "        order = torch.argsort(lp, descending=True).cpu().numpy().tolist()\n",
        "    return [int(i+1) for i in order[:20]]\n",
        "\n",
        "def ensure_len20_list(seq, logits_b):\n",
        "    ok = (len(seq)==20) and (len(set(seq))==20) and all(1<=s<=20 for s in seq)\n",
        "    if ok: return seq\n",
        "    return fallback_rank_framewise(logits_b)\n",
        "\n",
        "def levenshtein(a, b):\n",
        "    n, m = len(a), len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp = list(range(m+1))\n",
        "    for i in range(1, n+1):\n",
        "        prev = dp[0]; dp[0] = i; ai = a[i-1]\n",
        "        for j in range(1, m+1):\n",
        "            tmp = dp[j]\n",
        "            dp[j] = min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1))\n",
        "            prev = tmp\n",
        "    return dp[m]\n",
        "\n",
        "D_sample = np.load(next(iter(feat_dir.glob('*.npz'))))['X'].shape[1]\n",
        "model = BiGRUCTCStrong(in_dim=D_sample, proj=256, hidden=384, layers=3, num_classes=21, dropout=0.3).to(device).float()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
        "# Use scaler but keep training in full float32 to avoid dtype mismatch\n",
        "scaler = torch.amp.GradScaler('cuda' if torch.cuda.is_available() else 'cpu', enabled=False)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15)\n",
        "\n",
        "def train_epoch(ep):\n",
        "    model.train()\n",
        "    t0 = time.time(); tot=0.0; nb=0\n",
        "    for it, (xb, x_lens, y_cat, y_lens, sids) in enumerate(train_loader):\n",
        "        xb = xb.to(device, non_blocking=True).float()\n",
        "        # Time masking augmentation\n",
        "        xb = time_mask(xb, max_width=16, nmask=2, p=0.5)\n",
        "        y_cat = y_cat.to(device, non_blocking=True)\n",
        "        x_lens = x_lens.to(device, non_blocking=True)\n",
        "        y_lens = y_lens.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(xb, x_lens)\n",
        "        log_probs = logits.log_softmax(dim=-1)\n",
        "        loss = ctc_loss(log_probs, y_cat, x_lens, y_lens)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        tot += loss.item(); nb += 1\n",
        "        if (it+1) % 20 == 0:\n",
        "            print(f\"ep{ep} it{it+1} loss={tot/max(nb,1):.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "    scheduler.step()\n",
        "    return tot/max(nb,1)\n",
        "\n",
        "def evaluate_fast(model):\n",
        "    model.eval()\n",
        "    total_lev = 0.0; total = 0\n",
        "    t0 = time.time()\n",
        "    with torch.no_grad():\n",
        "        for xb, x_lens, y_cat, y_lens, sids in val_loader:\n",
        "            xb = xb.to(device, non_blocking=True).float()\n",
        "            x_lens = x_lens.to(device, non_blocking=True)\n",
        "            logits = model(xb, x_lens)  # (T,B,C)\n",
        "            T,B,C = logits.shape\n",
        "            seqs = ctc_greedy(logits)\n",
        "            # split targets\n",
        "            ys = []; off=0\n",
        "            for L in y_lens.tolist(): ys.append(y_cat[off:off+L].tolist()); off+=L\n",
        "            # ensure sequences length 20 via fallback ranking using per-sample logits\n",
        "            for b in range(B):\n",
        "                seq = ensure_len20_list(seqs[b], logits[:,b,:])\n",
        "                tgt = ys[b]\n",
        "                total_lev += levenshtein(seq, tgt)\n",
        "                total += 1\n",
        "    print(f\"  [val] evaluated {total} samples in {(time.time()-t0)/60:.2f}m\", flush=True)\n",
        "    return total_lev / max(total,1)\n",
        "\n",
        "best_val = math.inf; best_state = None; patience = 3; bad = 0\n",
        "max_epochs = 15\n",
        "for ep in range(1, max_epochs+1):\n",
        "    tr_loss = train_epoch(ep)\n",
        "    val_lev = evaluate_fast(model)\n",
        "    print(f\"Epoch {ep}: train_loss={tr_loss:.4f} val_lev={val_lev:.4f} lr={scheduler.get_last_lr()[0]:.6f}\", flush=True)\n",
        "    if val_lev < best_val - 1e-4:\n",
        "        best_val = val_lev; best_state = {k:v.detach().cpu() for k,v in model.state_dict().items()}; bad = 0\n",
        "        print(f\"  New best val_lev={best_val:.4f}\", flush=True)\n",
        "    else:\n",
        "        bad += 1\n",
        "        if bad >= patience:\n",
        "            print(\"Early stopping.\", flush=True); break\n",
        "\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state)\n",
        "torch.save(model.state_dict(), 'model_ctc_bgru_v2.pth')\n",
        "print(\"=== Training complete. Saved model_ctc_bgru_v2.pth; best val_lev=\", best_val)\n",
        "\n",
        "# Note: After this finishes, re-run Cell 12 with the new checkpoint and tuned beam or fast greedy+fallback."
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train 3x384 BiGRU+CTC with input projection, LN, time masking, feature standardization ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train videos: 253, Val videos: 44\nScaler stats: (180,) (180,) std min/max: 0.0011892978800460696 0.9245076775550842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss=23.5679 val_lev=18.2500 lr=0.000297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=18.2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: train_loss=8.4269 val_lev=18.4773 lr=0.000287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: train_loss=6.7487 val_lev=18.1136 lr=0.000250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=18.1136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: train_loss=6.4927 val_lev=18.0455 lr=0.000225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=18.0455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: train_loss=6.6235 val_lev=17.9091 lr=0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=17.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: train_loss=6.3430 val_lev=18.2727 lr=0.000166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: train_loss=5.3549 val_lev=18.0227 lr=0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: train_loss=5.1989 val_lev=17.7727 lr=0.000104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=17.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: train_loss=5.6111 val_lev=18.0227 lr=0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: train_loss=5.0718 val_lev=17.9773 lr=0.000050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] evaluated 44 samples in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: train_loss=5.9004 val_lev=18.0455 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Training complete. Saved model_ctc_bgru_v2.pth; best val_lev= 17.772727272727273\n"
          ]
        }
      ]
    },
    {
      "id": "7981f5b2-a4b2-4643-9c04-edb0f2aa0687",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "print(\"=== Inference on TEST with stronger 3x384 BiGRU (greedy+fallback) -> submission.csv ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feat_dir = Path('features3d')/'test'\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "\n",
        "# Load feature standardization stats used in training\n",
        "sc = np.load('feature_scaler.npz')\n",
        "mu = sc['mean'].astype(np.float32)\n",
        "sigma = sc['std'].astype(np.float32)\n",
        "\n",
        "def load_feat_std(sample_id: int):\n",
        "    d = np.load(feat_dir/f\"{sample_id}.npz\")\n",
        "    X = d['X'].astype(np.float32)\n",
        "    if X.shape[0] > 1200: X = X[:1200]\n",
        "    return (X - mu) / sigma\n",
        "\n",
        "class InputProj(nn.Module):\n",
        "    def __init__(self, in_dim, hid):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(in_dim, hid)\n",
        "        self.ln = nn.LayerNorm(hid)\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "    def forward(self, x):\n",
        "        y = self.lin(x); y = self.ln(y); return self.act(y)\n",
        "\n",
        "class BiGRUCTCStrong(nn.Module):\n",
        "    def __init__(self, in_dim, proj=256, hidden=384, layers=3, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = InputProj(in_dim, proj)\n",
        "        self.rnn = nn.GRU(input_size=proj, hidden_size=hidden, num_layers=layers, dropout=dropout, bidirectional=True)\n",
        "        self.proj = nn.Linear(hidden*2, num_classes)\n",
        "    def forward(self, x, x_lens):\n",
        "        x = self.inp(x)\n",
        "        packed = pack_padded_sequence(x, x_lens.cpu(), enforce_sorted=False)\n",
        "        out, _ = self.rnn(packed)\n",
        "        out, _ = pad_packed_sequence(out)\n",
        "        return self.proj(out)\n",
        "\n",
        "def ctc_greedy_one(logits_T_C: torch.Tensor):\n",
        "    pred = logits_T_C.argmax(dim=-1).tolist()\n",
        "    out = []; last = -1\n",
        "    for p in pred:\n",
        "        if p != last:\n",
        "            if p != 0: out.append(int(p))\n",
        "            last = p\n",
        "    return out\n",
        "\n",
        "def fallback_rank_framewise(logits_T_C: torch.Tensor):\n",
        "    with torch.no_grad():\n",
        "        lp = logits_T_C[:,1:21].mean(dim=0)\n",
        "        order = torch.argsort(lp, descending=True).tolist()\n",
        "    return [int(i+1) for i in order[:20]]\n",
        "\n",
        "def ensure_len20_list(seq, logits_T_C):\n",
        "    ok = (len(seq)==20) and (len(set(seq))==20) and all(1<=s<=20 for s in seq)\n",
        "    if ok: return seq\n",
        "    return fallback_rank_framewise(logits_T_C)\n",
        "\n",
        "# Build and load model\n",
        "in_dim = np.load(next(iter((Path('features3d')/'train').glob('*.npz'))))['X'].shape[1]\n",
        "model = BiGRUCTCStrong(in_dim=in_dim, proj=256, hidden=384, layers=3, num_classes=21, dropout=0.3).to(device).float()\n",
        "state = torch.load('model_ctc_bgru_v2.pth', map_location=device)\n",
        "model.load_state_dict(state); model.eval()\n",
        "\n",
        "rows = []; t0 = time.time()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    X = load_feat_std(sid)\n",
        "    xb = torch.from_numpy(X).to(device).unsqueeze(1)  # (T,1,D)\n",
        "    x_lens = torch.tensor([xb.shape[0]], dtype=torch.int32, device=device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(xb.float(), x_lens)[:,0,:]  # (T,C)\n",
        "    seq = ctc_greedy_one(logits)\n",
        "    seq = ensure_len20_list(seq, logits)\n",
        "    rows.append({'Id': sid, 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "    if i % 10 == 0 or i == len(test_ids):\n",
        "        print(f\"[infer v2] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv; head:\\n', sub.head())\n",
        "print('=== Inference v2 done ===')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Inference on TEST with stronger 3x384 BiGRU (greedy+fallback) -> submission.csv ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/358262059.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load('model_ctc_bgru_v2.pth', map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer v2] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer v2] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer v2] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer v2] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer v2] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer v2] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer v2] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer v2] 80/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer v2] 90/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer v2] 95/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv; head:\n     Id                                           Sequence\n0  300  17 16 11 18 13 12 8 14 9 20 15 10 1 5 6 4 3 2 ...\n1  301  17 16 11 18 13 12 8 14 15 9 20 10 1 5 6 4 3 2 ...\n2  302  17 16 11 18 13 12 8 14 15 9 20 10 1 5 6 4 3 2 ...\n3  303  17 16 11 13 18 12 8 14 15 9 20 10 5 1 6 4 3 2 ...\n4  304  17 16 11 13 18 12 8 14 15 9 20 10 5 1 6 4 3 2 ...\n=== Inference v2 done ===\n"
          ]
        }
      ]
    },
    {
      "id": "9e021532-39bf-4e22-af79-491f45af7efc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import io, tarfile, zipfile, json, math, gc, os, tempfile\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "\n",
        "print(\"=== Recache v2: dequantized 3D skeleton + extra scalars + vel/acc @20fps ===\", flush=True)\n",
        "\n",
        "CWD = Path('.')\n",
        "TRAIN_TARS = [CWD/'training1.tar.gz', CWD/'training2.tar.gz', CWD/'training3.tar.gz']\n",
        "VAL_TARS = [CWD/'validation1.tar.gz', CWD/'validation2.tar.gz', CWD/'validation3.tar.gz']\n",
        "TEST_TAR = CWD/'test.tar.gz'\n",
        "\n",
        "def build_tar_index(tar_paths):\n",
        "    idx = {}\n",
        "    for tp in tar_paths:\n",
        "        if not tp.exists(): continue\n",
        "        with tarfile.open(tp, 'r:*') as tf:\n",
        "            for m in tf:\n",
        "                if m.isreg():\n",
        "                    nm = m.name.lstrip('./')\n",
        "                    if nm.endswith('.zip') and nm.startswith('Sample'):\n",
        "                        idx[nm] = (tp, m)\n",
        "    return idx\n",
        "\n",
        "train_idx = build_tar_index(TRAIN_TARS)\n",
        "val_idx = build_tar_index(VAL_TARS)\n",
        "test_idx = build_tar_index([TEST_TAR])\n",
        "\n",
        "def id_to_zipname(sample_id: int) -> str:\n",
        "    return f\"Sample{sample_id:05d}.zip\"\n",
        "\n",
        "def read_mat_bytes_from_zip(tarpath: Path, tarinfo: tarfile.TarInfo) -> bytes:\n",
        "    with tarfile.open(tarpath, 'r:*') as tf:\n",
        "        fobj = tf.extractfile(tarinfo); data = fobj.read()\n",
        "    with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "        mat_name = None\n",
        "        for n in zf.namelist():\n",
        "            ln = n.lower()\n",
        "            if ln.endswith('_data.mat') or ln.endswith('.mat'): mat_name = n; break\n",
        "        b = zf.read(mat_name)\n",
        "    return b\n",
        "\n",
        "def load_video_struct(mat_bytes: bytes):\n",
        "    md = sio.loadmat(io.BytesIO(mat_bytes), squeeze_me=True, struct_as_record=False)\n",
        "    return md['Video']\n",
        "\n",
        "# Joint index map (0-based) per expert advice\n",
        "HIP_CENTER=0; SPINE=1; SHOULDER_CENTER=2; HEAD=3;\n",
        "SHOULDER_L=4; ELBOW_L=5; WRIST_L=6; HAND_L=7;\n",
        "SHOULDER_R=8; ELBOW_R=9; WRIST_R=10; HAND_R=11;\n",
        "HIP_L=12; KNEE_L=13; ANKLE_L=14; FOOT_L=15;\n",
        "HIP_R=16; KNEE_R=17; ANKLE_R=18; FOOT_R=19\n",
        "\n",
        "def dequantize_u8(arr_u8: np.ndarray) -> np.ndarray:\n",
        "    # Map uint8 to approx [-1,1]\n",
        "    return (arr_u8.astype(np.float32) - 128.0) / 128.0\n",
        "\n",
        "def ema_smooth_scale(scales: np.ndarray, alpha: float = 0.7) -> np.ndarray:\n",
        "    s = np.empty_like(scales, dtype=np.float32)\n",
        "    if len(scales) == 0: return s\n",
        "    s[0] = scales[0]\n",
        "    for t in range(1, len(scales)):\n",
        "        s[t] = alpha * s[t-1] + (1.0 - alpha) * scales[t]\n",
        "    s[s <= 1e-6] = 1.0\n",
        "    return s\n",
        "\n",
        "def elbow_angle(a, b, c):\n",
        "    # angle at b between vectors a-b and c-b\n",
        "    v1 = a - b; v2 = c - b\n",
        "    num = np.sum(v1*v2, axis=-1)\n",
        "    d1 = np.linalg.norm(v1, axis=-1) + 1e-8\n",
        "    d2 = np.linalg.norm(v2, axis=-1) + 1e-8\n",
        "    cosang = np.clip(num/(d1*d2), -1.0, 1.0)\n",
        "    return np.arccos(cosang).astype(np.float32)  # radians\n",
        "\n",
        "def build_features_from_video(V):\n",
        "    T = int(getattr(V, 'NumFrames', 0))\n",
        "    frames = V.Frames\n",
        "    # Collect 3D u8 positions\n",
        "    X = np.zeros((T, 20, 3), dtype=np.float32)\n",
        "    for t in range(T):\n",
        "        wp = getattr(frames[t].Skeleton, 'WorldPosition')  # (20,3) uint8\n",
        "        X[t] = dequantize_u8(np.asarray(wp))\n",
        "    # Center on hip center and scale by shoulder width with EMA smoothing\n",
        "    center = X[:, HIP_CENTER, :]  # (T,3)\n",
        "    Xc = X - center[:, None, :]\n",
        "    shoulder_width = np.linalg.norm(X[:, SHOULDER_L, :] - X[:, SHOULDER_R, :], axis=1)\n",
        "    scale = ema_smooth_scale(shoulder_width, alpha=0.7)\n",
        "    Xn = Xc / scale[:, None, None]\n",
        "    # Extra scalars per frame (computed on normalized coords)\n",
        "    HL = Xn[:, HAND_L, :]; HR = Xn[:, HAND_R, :]\n",
        "    SHL = Xn[:, SHOULDER_L, :]; SHR = Xn[:, SHOULDER_R, :]\n",
        "    HD = Xn[:, HEAD, :]; HC = Xn[:, HIP_CENTER, :]\n",
        "    WRL = Xn[:, WRIST_L, :]; WRI = Xn[:, WRIST_R, :]\n",
        "    ELL = Xn[:, ELBOW_L, :]; ELR = Xn[:, ELBOW_R, :]\n",
        "    # distances\n",
        "    d_hands = np.linalg.norm(HL - HR, axis=1)[:, None]\n",
        "    d_hl_head = np.linalg.norm(HL - HD, axis=1)[:, None]\n",
        "    d_hr_head = np.linalg.norm(HR - HD, axis=1)[:, None]\n",
        "    d_hl_shl = np.linalg.norm(HL - SHL, axis=1)[:, None]\n",
        "    d_hr_shr = np.linalg.norm(HR - SHR, axis=1)[:, None]\n",
        "    d_hl_hip = np.linalg.norm(HL - HC, axis=1)[:, None]\n",
        "    d_hr_hip = np.linalg.norm(HR - HC, axis=1)[:, None]\n",
        "    # speeds (magnitudes) and vertical velocities (z') for hands\n",
        "    def temporal_diff(x):\n",
        "        v = np.diff(x, axis=0, prepend=x[:1])\n",
        "        return v\n",
        "    v_hl = temporal_diff(HL); v_hr = temporal_diff(HR)\n",
        "    sp_hl = np.linalg.norm(v_hl, axis=1)[:, None]; sp_hr = np.linalg.norm(v_hr, axis=1)[:, None]\n",
        "    vz_hl = v_hl[:, 2:3]; vz_hr = v_hr[:, 2:3]\n",
        "    # elbow angles\n",
        "    ang_l = elbow_angle(SHL, ELL, WRL)[:, None]\n",
        "    ang_r = elbow_angle(SHR, ELR, WRI)[:, None]\n",
        "    scalars = np.concatenate([d_hands, d_hl_head, d_hr_head, d_hl_shl, d_hr_shr, d_hl_hip, d_hr_hip, sp_hl, sp_hr, vz_hl, vz_hr, ang_l, ang_r], axis=1)\n",
        "    # Base per-frame vector: flattened joints + scalars\n",
        "    base = np.concatenate([Xn.reshape(T, -1), scalars], axis=1).astype(np.float32)\n",
        "    # Derivatives\n",
        "    V1 = np.diff(base, axis=0, prepend=base[:1])\n",
        "    A1 = np.diff(V1, axis=0, prepend=V1[:1])\n",
        "    Xf = np.concatenate([base, V1, A1], axis=1).astype(np.float32)\n",
        "    meta = dict(fps=int(getattr(V, 'FrameRate', 20)), nframes=T, stride=1, feat='world3d_dequant_norm+scalars+vel+acc')\n",
        "    return Xf, meta\n",
        "\n",
        "def cache_one_v2(sample_id: int, split: str, outdir: Path):\n",
        "    idx = train_idx if split=='train' else (val_idx if split=='val' else test_idx)\n",
        "    zipname = id_to_zipname(sample_id)\n",
        "    if zipname not in idx: raise KeyError(f\"{zipname} not in index for split={split}\")\n",
        "    tarpath, tarinfo = idx[zipname]\n",
        "    mat_bytes = read_mat_bytes_from_zip(tarpath, tarinfo)\n",
        "    V = load_video_struct(mat_bytes)\n",
        "    Xf, meta = build_features_from_video(V)\n",
        "    outdir.mkdir(parents=True, exist_ok=True)\n",
        "    np.savez_compressed(outdir/f\"{sample_id}.npz\", X=Xf, meta=json.dumps(meta))\n",
        "\n",
        "def recache_split(split: str, ids: list, outdir: Path):\n",
        "    total = len(ids); t0 = time.time(); done=0; skip=0\n",
        "    outdir.mkdir(parents=True, exist_ok=True)\n",
        "    for i, sid in enumerate(ids, 1):\n",
        "        p = outdir/f\"{sid}.npz\"\n",
        "        if p.exists():\n",
        "            skip += 1\n",
        "        else:\n",
        "            st = time.time()\n",
        "            try:\n",
        "                cache_one_v2(int(sid), split, outdir); done += 1\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] {split} id={sid} failed: {e}\", flush=True); continue\n",
        "        if (i % 10)==0 or i==total:\n",
        "            dt = time.time()-t0; rate = i/max(dt,1e-9); eta = (total-i)/max(rate,1e-6)\n",
        "            print(f\"[{split} v2] {i}/{total} cached={done} skip={skip} elapsed={dt/60:.1f}m eta={eta/60:.1f}m\", flush=True)\n",
        "        gc.collect()\n",
        "    print(f\"=== {split.upper()} v2 caching done: cached={done} skip={skip} total={total} elapsed={(time.time()-t0)/60:.2f}m ===\", flush=True)\n",
        "\n",
        "# Run recache for train and test into features3d_v2/\n",
        "train_ids = pd.read_csv('training.csv')['Id'].astype(int).tolist()\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "recache_split('train', train_ids, Path('features3d_v2')/'train')\n",
        "recache_split('test', test_ids, Path('features3d_v2')/'test')\n",
        "print(\"=== Recache v2 complete ===\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Recache v2: dequantized 3D skeleton + extra scalars + vel/acc @20fps ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 10/297 cached=10 skip=0 elapsed=0.1m eta=2.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 20/297 cached=20 skip=0 elapsed=0.3m eta=3.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 30/297 cached=30 skip=0 elapsed=0.5m eta=4.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 40/297 cached=40 skip=0 elapsed=0.9m eta=5.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 50/297 cached=50 skip=0 elapsed=1.4m eta=6.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 60/297 cached=60 skip=0 elapsed=2.0m eta=7.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 70/297 cached=70 skip=0 elapsed=2.7m eta=8.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 80/297 cached=80 skip=0 elapsed=3.5m eta=9.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 90/297 cached=90 skip=0 elapsed=4.4m eta=10.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 100/297 cached=100 skip=0 elapsed=5.2m eta=10.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 110/297 cached=110 skip=0 elapsed=5.3m eta=9.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 120/297 cached=120 skip=0 elapsed=5.4m eta=7.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 130/297 cached=130 skip=0 elapsed=5.5m eta=7.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 140/297 cached=140 skip=0 elapsed=5.7m eta=6.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 150/297 cached=150 skip=0 elapsed=5.9m eta=5.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 160/297 cached=160 skip=0 elapsed=6.1m eta=5.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 170/297 cached=170 skip=0 elapsed=6.4m eta=4.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 180/297 cached=180 skip=0 elapsed=6.7m eta=4.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 190/297 cached=190 skip=0 elapsed=7.1m eta=4.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 200/297 cached=200 skip=0 elapsed=7.4m eta=3.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 210/297 cached=210 skip=0 elapsed=7.4m eta=3.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 220/297 cached=220 skip=0 elapsed=7.5m eta=2.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 230/297 cached=230 skip=0 elapsed=7.7m eta=2.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 240/297 cached=240 skip=0 elapsed=8.0m eta=1.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 250/297 cached=250 skip=0 elapsed=8.3m eta=1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 260/297 cached=260 skip=0 elapsed=8.7m eta=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 270/297 cached=270 skip=0 elapsed=9.1m eta=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 280/297 cached=280 skip=0 elapsed=9.5m eta=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 290/297 cached=290 skip=0 elapsed=10.0m eta=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train v2] 297/297 cached=297 skip=0 elapsed=10.4m eta=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TRAIN v2 caching done: cached=297 skip=0 total=297 elapsed=10.36m ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test v2] 10/95 cached=10 skip=0 elapsed=0.1m eta=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test v2] 20/95 cached=20 skip=0 elapsed=0.2m eta=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test v2] 30/95 cached=30 skip=0 elapsed=0.3m eta=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test v2] 40/95 cached=40 skip=0 elapsed=0.5m eta=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test v2] 50/95 cached=50 skip=0 elapsed=0.7m eta=0.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test v2] 60/95 cached=60 skip=0 elapsed=1.0m eta=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test v2] 70/95 cached=70 skip=0 elapsed=1.4m eta=0.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test v2] 80/95 cached=80 skip=0 elapsed=1.7m eta=0.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test v2] 90/95 cached=90 skip=0 elapsed=2.2m eta=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test v2] 95/95 cached=95 skip=0 elapsed=2.4m eta=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEST v2 caching done: cached=95 skip=0 total=95 elapsed=2.38m ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Recache v2 complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "abafab3d-fc29-49f6-aa8e-efcb5dc8917b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import io, tarfile, zipfile, json, time, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "\n",
        "print(\"=== Build per-frame labels for train (v2) from Video.Labels and training.csv sequences ===\", flush=True)\n",
        "\n",
        "CWD = Path('.')\n",
        "TRAIN_TARS = [CWD/'training1.tar.gz', CWD/'training2.tar.gz', CWD/'training3.tar.gz']\n",
        "\n",
        "def build_tar_index(tar_paths):\n",
        "    idx = {}\n",
        "    for tp in tar_paths:\n",
        "        if not tp.exists(): continue\n",
        "        with tarfile.open(tp, 'r:*') as tf:\n",
        "            for m in tf:\n",
        "                if m.isreg():\n",
        "                    nm = m.name.lstrip('./')\n",
        "                    if nm.endswith('.zip') and nm.startswith('Sample'):\n",
        "                        idx[nm] = (tp, m)\n",
        "    return idx\n",
        "\n",
        "train_idx = build_tar_index(TRAIN_TARS)\n",
        "\n",
        "def id_to_zipname(sample_id: int) -> str:\n",
        "    return f\"Sample{sample_id:05d}.zip\"\n",
        "\n",
        "def read_mat_bytes_from_zip(tarpath: Path, tarinfo: tarfile.TarInfo) -> bytes:\n",
        "    with tarfile.open(tarpath, 'r:*') as tf:\n",
        "        fobj = tf.extractfile(tarinfo); data = fobj.read()\n",
        "    with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "        mat_name = None\n",
        "        for n in zf.namelist():\n",
        "            ln = n.lower()\n",
        "            if ln.endswith('_data.mat') or ln.endswith('.mat'): mat_name = n; break\n",
        "        b = zf.read(mat_name)\n",
        "    return b\n",
        "\n",
        "def load_video_struct(mat_bytes: bytes):\n",
        "    md = sio.loadmat(io.BytesIO(mat_bytes), squeeze_me=True, struct_as_record=False)\n",
        "    return md['Video']\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "train_ids = train_df['Id'].astype(int).tolist()\n",
        "\n",
        "labels_dir = Path('labels3d_v2')/'train'\n",
        "labels_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def cache_labels_one(sample_id: int):\n",
        "    zipname = id_to_zipname(sample_id)\n",
        "    if zipname not in train_idx:\n",
        "        raise KeyError(f\"{zipname} not in train index\")\n",
        "    tarpath, tarinfo = train_idx[zipname]\n",
        "    mat_bytes = read_mat_bytes_from_zip(tarpath, tarinfo)\n",
        "    V = load_video_struct(mat_bytes)\n",
        "    T = int(getattr(V, 'NumFrames', 0))\n",
        "    y = np.zeros(T, dtype=np.int16)\n",
        "    labels = V.Labels  # array of 20 structs with Begin, End, Name\n",
        "    seq = id2seq[sample_id]  # list of 20 gesture IDs\n",
        "    K = min(len(labels), len(seq))\n",
        "    for k in range(K):\n",
        "        lab = labels[k]\n",
        "        b = int(getattr(lab, 'Begin', 1)); e = int(getattr(lab, 'End', b))\n",
        "        b = max(1, b); e = min(T, e)\n",
        "        if e >= b:\n",
        "            y[b-1:e] = int(seq[k])  # 1..20\n",
        "    np.save(labels_dir/f\"{sample_id}.npy\", y)\n",
        "\n",
        "t0 = time.time(); done=0; skip=0\n",
        "for i, sid in enumerate(train_ids, 1):\n",
        "    outp = labels_dir/f\"{sid}.npy\"\n",
        "    if outp.exists():\n",
        "        skip += 1\n",
        "    else:\n",
        "        try:\n",
        "            cache_labels_one(int(sid)); done += 1\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] label cache failed id={sid}: {e}\", flush=True)\n",
        "            continue\n",
        "    if (i % 10)==0 or i==len(train_ids):\n",
        "        dt = time.time()-t0; rate = i/max(dt,1e-9); eta = (len(train_ids)-i)/max(rate,1e-6)\n",
        "        print(f\"[labels v2] {i}/{len(train_ids)} cached={done} skip={skip} elapsed={dt/60:.1f}m eta={eta/60:.1f}m\", flush=True)\n",
        "    gc.collect()\n",
        "print(f\"=== Label caching done: cached={done} skip={skip} total={len(train_ids)} elapsed={(time.time()-t0)/60:.2f}m ===\", flush=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Build per-frame labels for train (v2) from Video.Labels and training.csv sequences ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 10/297 cached=10 skip=0 elapsed=0.1m eta=2.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 20/297 cached=20 skip=0 elapsed=0.3m eta=3.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 30/297 cached=30 skip=0 elapsed=0.5m eta=4.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 40/297 cached=40 skip=0 elapsed=0.8m eta=5.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 50/297 cached=50 skip=0 elapsed=1.3m eta=6.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 60/297 cached=60 skip=0 elapsed=1.9m eta=7.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 70/297 cached=70 skip=0 elapsed=2.6m eta=8.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 80/297 cached=80 skip=0 elapsed=3.4m eta=9.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 90/297 cached=90 skip=0 elapsed=4.3m eta=10.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 100/297 cached=100 skip=0 elapsed=5.1m eta=10.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 110/297 cached=110 skip=0 elapsed=5.1m eta=8.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 120/297 cached=120 skip=0 elapsed=5.2m eta=7.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 130/297 cached=130 skip=0 elapsed=5.4m eta=6.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 140/297 cached=140 skip=0 elapsed=5.5m eta=6.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 150/297 cached=150 skip=0 elapsed=5.7m eta=5.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 160/297 cached=160 skip=0 elapsed=6.0m eta=5.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 170/297 cached=170 skip=0 elapsed=6.2m eta=4.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 180/297 cached=180 skip=0 elapsed=6.6m eta=4.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 190/297 cached=190 skip=0 elapsed=6.9m eta=3.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 200/297 cached=200 skip=0 elapsed=7.2m eta=3.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 210/297 cached=210 skip=0 elapsed=7.2m eta=3.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 220/297 cached=220 skip=0 elapsed=7.3m eta=2.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 230/297 cached=230 skip=0 elapsed=7.5m eta=2.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 240/297 cached=240 skip=0 elapsed=7.7m eta=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 250/297 cached=250 skip=0 elapsed=8.1m eta=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 260/297 cached=260 skip=0 elapsed=8.4m eta=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 270/297 cached=270 skip=0 elapsed=8.8m eta=0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 280/297 cached=280 skip=0 elapsed=9.2m eta=0.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 290/297 cached=290 skip=0 elapsed=9.7m eta=0.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[labels v2] 297/297 cached=297 skip=0 elapsed=10.1m eta=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Label caching done: cached=297 skip=0 total=297 elapsed=10.06m ===\n"
          ]
        }
      ]
    },
    {
      "id": "49c81ec3-8d27-4710-b8ec-8ac405bf8191",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math, time, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "print(\"=== Per-frame CE model (dilated 1D CNN) on features3d_v2 + labels3d_v2 ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
        "if torch.cuda.is_available(): torch.backends.cudnn.benchmark = True\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "tr_ids = all_ids[val_n:]\n",
        "print(f\"Train videos: {len(tr_ids)}, Val videos: {len(val_ids)}\")\n",
        "\n",
        "def load_feat(sample_id: int):\n",
        "    d = np.load(feat_tr_dir/f\"{sample_id}.npz\")\n",
        "    X = d['X'].astype(np.float32)  # (T,D)\n",
        "    return X\n",
        "\n",
        "def load_lab(sample_id: int):\n",
        "    y = np.load(lab_tr_dir/f\"{sample_id}.npy\").astype(np.int64)  # (T,)\n",
        "    return y\n",
        "\n",
        "class FrameDataset(Dataset):\n",
        "    def __init__(self, ids, max_T=1800):\n",
        "        self.ids = list(ids); self.max_T = max_T\n",
        "    def __len__(self): return len(self.ids)\n",
        "    def __getitem__(self, idx):\n",
        "        sid = self.ids[idx]\n",
        "        X = load_feat(sid); y = load_lab(sid)\n",
        "        T = min(len(X), len(y))\n",
        "        X = X[:T]; y = y[:T]\n",
        "        if T > self.max_T:\n",
        "            X = X[:self.max_T]; y = y[:self.max_T]; T = self.max_T\n",
        "        return torch.from_numpy(X), torch.from_numpy(y), int(sid)\n",
        "\n",
        "def collate(batch):\n",
        "    xs, ys, sids = zip(*batch)\n",
        "    T_max = max(x.shape[0] for x in xs)\n",
        "    D = xs[0].shape[1]\n",
        "    B = len(xs)\n",
        "    xb = torch.zeros(B, T_max, D, dtype=torch.float32)\n",
        "    yb = torch.zeros(B, T_max, dtype=torch.long)\n",
        "    mask = torch.zeros(B, T_max, dtype=torch.bool)\n",
        "    for i,(x,y) in enumerate(zip(xs,ys)):\n",
        "        T = x.shape[0]\n",
        "        xb[i,:T] = x\n",
        "        yb[i,:T] = y\n",
        "        mask[i,:T] = True\n",
        "    return xb, yb, mask, list(sids)\n",
        "\n",
        "train_ds = FrameDataset(tr_ids, max_T=1800)\n",
        "val_ds   = FrameDataset(val_ids, max_T=1800)\n",
        "train_loader = DataLoader(train_ds, batch_size=12, shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate)\n",
        "val_loader   = DataLoader(val_ds, batch_size=12, shuffle=False, num_workers=2, pin_memory=True, collate_fn=collate)\n",
        "\n",
        "D_in = np.load(next(iter(feat_tr_dir.glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []\n",
        "        dil = 1\n",
        "        for i in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d, mask_b_t=None):\n",
        "        # x: (B,T,D) -> (B,C,T)\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h\n",
        "            h = blk(h)\n",
        "            h = h + res\n",
        "        logits = self.head(h)  # (B,C,T)\n",
        "        return logits.transpose(1,2)  # (B,T,C)\n",
        "\n",
        "model = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "def ce_loss_ignore_bg(logits_b_t_c, y_b_t, mask_b_t):\n",
        "    # logits: (B,T,C), y: (B,T), mask True for valid frames. Ignore_index=0\n",
        "    B,T,C = logits_b_t_c.shape\n",
        "    logits = logits_b_t_c.reshape(B*T, C)\n",
        "    targets = y_b_t.reshape(B*T)\n",
        "    valid = mask_b_t.reshape(B*T)\n",
        "    # Compute loss only on valid & label>0\n",
        "    valid_fg = valid & (targets > 0)\n",
        "    if valid_fg.sum() == 0:\n",
        "        return logits.new_zeros([])\n",
        "    loss = F.cross_entropy(logits[valid_fg], targets[valid_fg], reduction='mean')\n",
        "    return loss\n",
        "\n",
        "def decode_sequence_from_frame_probs(probs_b_t_c):\n",
        "    # probs: (B,T,C) softmax over C; class 0 is background. Return list of sequences (len 20) per batch.\n",
        "    B,T,C = probs_b_t_c.shape\n",
        "    seqs = []\n",
        "    # optional temporal smoothing with average pool over time\n",
        "    smoothed = F.avg_pool1d(probs_b_t_c.transpose(1,2), kernel_size=7, stride=1, padding=3).transpose(1,2)\n",
        "    for b in range(B):\n",
        "        p = smoothed[b]  # (T,C)\n",
        "        peaks = []\n",
        "        for c in range(1,21):\n",
        "            t_star = int(torch.argmax(p[:,c]).item())\n",
        "            peaks.append((c, t_star))\n",
        "        peaks.sort(key=lambda x: x[1])\n",
        "        seq = [c for c,_ in peaks]\n",
        "        seqs.append(seq)\n",
        "    return seqs\n",
        "\n",
        "def levenshtein(a, b):\n",
        "    n, m = len(a), len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp = list(range(m+1))\n",
        "    for i in range(1, n+1):\n",
        "        prev = dp[0]; dp[0] = i; ai = a[i-1]\n",
        "        for j in range(1, m+1):\n",
        "            tmp = dp[j]\n",
        "            dp[j] = min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1))\n",
        "            prev = tmp\n",
        "    return dp[m]\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def eval_val():\n",
        "    model.eval()\n",
        "    tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, mask, sids in val_loader:\n",
        "            xb = xb.to(device); yb = yb.to(device); mask = mask.to(device)\n",
        "            logits = model(xb, mask)  # (B,T,C)\n",
        "            probs = logits.softmax(dim=-1)\n",
        "            seqs = decode_sequence_from_frame_probs(probs)\n",
        "            for sid, seq in zip(sids, seqs):\n",
        "                tgt = id2seq[sid]\n",
        "                tot += levenshtein(seq, tgt); cnt += 1\n",
        "    print(f\"  [val] {cnt} vids evaluated in {(time.time()-t0)/60:.2f}m\", flush=True)\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "best = math.inf; best_state=None; patience=3; bad=0; max_epochs=20\n",
        "for ep in range(1, max_epochs+1):\n",
        "    model.train(); t0=time.time(); nb=0; tot_loss=0.0\n",
        "    for it, (xb, yb, mask, sids) in enumerate(train_loader):\n",
        "        xb = xb.to(device); yb = yb.to(device); mask = mask.to(device)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        logits = model(xb, mask)  # (B,T,C)\n",
        "        loss = ce_loss_ignore_bg(logits, yb, mask)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        opt.step()\n",
        "        tot_loss += float(loss.item()); nb += 1\n",
        "        if (it+1)%20==0:\n",
        "            print(f\"ep{ep} it{it+1} loss={tot_loss/nb:.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "    val_lev = eval_val()\n",
        "    print(f\"Epoch {ep}: train_loss={tot_loss/max(nb,1):.4f} val_lev={val_lev:.4f}\", flush=True)\n",
        "    if val_lev < best - 1e-4:\n",
        "        best = val_lev; best_state = {k:v.detach().cpu() for k,v in model.state_dict().items()}; bad=0\n",
        "        print(f\"  New best val_lev={best:.4f}\", flush=True)\n",
        "    else:\n",
        "        bad += 1\n",
        "        if bad>=patience:\n",
        "            print(\"Early stopping.\", flush=True); break\n",
        "\n",
        "if best_state is not None: model.load_state_dict(best_state)\n",
        "torch.save(model.state_dict(), 'model_ce_tcn_v2.pth')\n",
        "print(\"Saved model_ce_tcn_v2.pth; best val_lev=\", best)\n",
        "\n",
        "print(\"=== Inference TEST with CE model (peak-time sort) -> submission.csv ===\", flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "\n",
        "rows=[]; t0=time.time()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(feat_te_dir/f\"{sid}.npz\"); X = d['X'].astype(np.float32)\n",
        "        if X.shape[0] > 1800: X = X[:1800]\n",
        "        xb = torch.from_numpy(X).unsqueeze(0).to(device)  # (1,T,D)\n",
        "        mask = torch.ones(1, xb.shape[1], dtype=torch.bool, device=device)\n",
        "        logits = model(xb, mask)[0]  # (T,C)\n",
        "        probs = logits.softmax(dim=-1).unsqueeze(0)  # (1,T,C)\n",
        "        seq = decode_sequence_from_frame_probs(probs)[0]\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if i%10==0 or i==len(test_ids):\n",
        "            print(f\"[infer CE] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv; head:\\n', sub.head())\n",
        "print('=== CE pipeline done ===')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Per-frame CE model (dilated 1D CNN) on features3d_v2 + labels3d_v2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train videos: 253, Val videos: 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1 it20 loss=3.4702 elapsed=4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2 it20 loss=2.7898 elapsed=2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: train_loss=2.7797 val_lev=15.3409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=15.3409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3 it20 loss=2.4210 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: train_loss=2.4131 val_lev=12.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=12.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4 it20 loss=2.1485 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: train_loss=2.1501 val_lev=11.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=11.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5 it20 loss=1.9746 elapsed=1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: train_loss=1.9515 val_lev=9.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=9.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6 it20 loss=1.8270 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: train_loss=1.8068 val_lev=9.1136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=9.1136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7 it20 loss=1.6773 elapsed=1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: train_loss=1.6813 val_lev=8.0909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=8.0909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8 it20 loss=1.5661 elapsed=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: train_loss=1.5550 val_lev=7.2727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=7.2727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9 it20 loss=1.4629 elapsed=1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: train_loss=1.4420 val_lev=6.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=6.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10 it20 loss=1.3680 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: train_loss=1.3534 val_lev=7.0227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11 it20 loss=1.3136 elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: train_loss=1.3133 val_lev=6.7955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=6.7955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12 it20 loss=1.2645 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: train_loss=1.2627 val_lev=6.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=6.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13 it20 loss=1.2082 elapsed=1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: train_loss=1.2088 val_lev=5.8636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=5.8636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14 it20 loss=1.1473 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: train_loss=1.1720 val_lev=5.3182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=5.3182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15 it20 loss=1.0832 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: train_loss=1.1719 val_lev=5.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16 it20 loss=1.0814 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: train_loss=1.0737 val_lev=5.1818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=5.1818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep17 it20 loss=1.0425 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: train_loss=1.0108 val_lev=5.8864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep18 it20 loss=0.9959 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: train_loss=1.0098 val_lev=5.4091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep19 it20 loss=0.9714 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: train_loss=0.9486 val_lev=4.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best val_lev=4.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep20 it20 loss=0.9346 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val] 44 vids evaluated in 0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: train_loss=0.9092 val_lev=5.0227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model_ce_tcn_v2.pth; best val_lev= 4.840909090909091\n=== Inference TEST with CE model (peak-time sort) -> submission.csv ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer CE] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer CE] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer CE] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer CE] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer CE] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer CE] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer CE] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer CE] 80/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer CE] 90/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[infer CE] 95/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 14 11 6 16 19 15 1...\n1  301  10 1 5 4 6 2 11 14 13 19 15 7 9 20 12 8 18 3 1...\n2  302  1 17 16 12 5 19 13 15 20 18 11 3 4 6 8 14 10 9...\n3  303  13 4 3 10 14 5 19 15 20 17 1 11 16 8 18 7 12 6...\n4  304  8 1 7 12 18 13 9 2 11 3 20 19 15 5 14 6 17 16 ...\n=== CE pipeline done ===\n"
          ]
        }
      ]
    },
    {
      "id": "28eaf6aa-1d64-4845-9c7a-1494adbf11e9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math, time, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"=== Refined decoder: smoothing + duration prior + NMS + CoM refinement ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "# Rebuild the same val split as Cell 18\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "tr_ids = all_ids[val_n:]\n",
        "print(f\"Train videos: {len(tr_ids)}, Val videos: {len(val_ids)}\")\n",
        "\n",
        "D_in = np.load(next(iter((Path('features3d_v2')/'train').glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []\n",
        "        dil = 1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h\n",
        "            h = blk(h)\n",
        "            h = h + res\n",
        "        logits = self.head(h)\n",
        "        return logits.transpose(1,2)\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p)\n",
        "    X = d['X'].astype(np.float32)\n",
        "    if X.shape[0] > max_T: X = X[:max_T]\n",
        "    return X\n",
        "\n",
        "def compute_class_median_durations():\n",
        "    # Per-class durations from labels (frames at 20 fps)\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df['Id'].astype(int).tolist()\n",
        "    t0=time.time()\n",
        "    for i, sid in enumerate(ids, 1):\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        # durations: since exactly one occurrence per class, just count frames\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum())\n",
        "            if cnt > 0: dur_by_c[c].append(cnt)\n",
        "        if (i%50)==0 or i==len(ids):\n",
        "            print(f\"  [dur] {i}/{len(ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        if len(dur_by_c[c])==0:\n",
        "            med[c] = 13  # sensible default\n",
        "        else:\n",
        "            med[c] = int(np.median(dur_by_c[c]))\n",
        "        med[c] = int(np.clip(med[c], 9, 25))\n",
        "    return med\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int = 13) -> torch.Tensor:\n",
        "    # p_t_c: (T,C)\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)  # (1,C,T)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral(p_t_c: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    # Convolve per-class probs with box kernel of size k\n",
        "    T,C = p_t_c.shape\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)  # (1,C,T)\n",
        "    weight = torch.ones(C, 1, k, device=p_t_c.device, dtype=p_t_c.dtype) / float(k)\n",
        "    y = F.conv1d(x, weight, padding=k//2, groups=C)  # (1,C,T)\n",
        "    return y.transpose(1,2).squeeze(0)  # (T,C)\n",
        "\n",
        "def nms1d(scores: np.ndarray, radius: int = 12) -> int:\n",
        "    # Return top-1 peak index with simple NMS (since we only need one peak per class)\n",
        "    t0 = int(np.argmax(scores))\n",
        "    return t0\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star: int, w: int = 5) -> float:\n",
        "    # center-of-mass refinement within \u00b1w\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w); b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]\n",
        "    s = seg.sum() + 1e-8\n",
        "    com = (idx * seg).sum() / s\n",
        "    return float(com.item())\n",
        "\n",
        "def decode_video_probs(p_t_c: torch.Tensor, med_k: dict, pool_k: int = 13, nms_radius: int = 12) -> list:\n",
        "    # p_t_c: (T,C), C=21 with bg at 0\n",
        "    # 1) mild smoothing\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    # 2) duration prior via per-class integral\n",
        "    T,C = p_s.shape\n",
        "    # build per-class duration integrals\n",
        "    integ = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = med_k.get(c, 13) if c!=0 else 13\n",
        "        integ[:, c] = duration_integral(p_s[:, c:c+1], k=k).squeeze(1)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        s = integ[:, c].cpu().numpy()\n",
        "        t_star = nms1d(s, radius=nms_radius)\n",
        "        t_ref = refine_com(p_s[:, c], t_star, w=5)\n",
        "        peaks.append((c, t_ref, float(integ[int(round(t_ref)) if 0<=int(round(t_ref))<T else t_star, c].item())))\n",
        "    # 3) sort by refined time; break ties by higher integral score\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2]))\n",
        "    seq = [c for c,_,_ in peaks]\n",
        "    # fallback if needed\n",
        "    if len(set(seq))<20:\n",
        "        meanp = p_s[:,1:21].mean(dim=0)\n",
        "        order = torch.argsort(meanp, descending=True).cpu().numpy().tolist()\n",
        "        seq = [int(i+1) for i in order[:20]]\n",
        "    return seq\n",
        "\n",
        "print(\"Computing per-class median durations...\", flush=True)\n",
        "med_k = compute_class_median_durations()\n",
        "print({k: med_k[k] for k in list(med_k.keys())[:5]}, \"...\", flush=True)\n",
        "\n",
        "# Load CE model\n",
        "model = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "state = torch.load('model_ce_tcn_v2.pth', map_location=device)\n",
        "model.load_state_dict(state); model.eval()\n",
        "\n",
        "def eval_val_refined():\n",
        "    tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, sid in enumerate(val_ids, 1):\n",
        "            X = load_feat(sid, split='train', max_T=1800)\n",
        "            xb = torch.from_numpy(X).unsqueeze(0).to(device)  # (1,T,D)\n",
        "            logits = model(xb)[0]  # (T,C)\n",
        "            probs = logits.softmax(dim=-1)\n",
        "            seq = decode_video_probs(probs, med_k, pool_k=13, nms_radius=12)\n",
        "            tgt = [int(x) for x in str(train_df.loc[train_df['Id']==sid, 'Sequence'].iloc[0]).split()]\n",
        "            # Levenshtein\n",
        "            n,m=len(seq),len(tgt)\n",
        "            if n==0:\n",
        "                lev = m\n",
        "            else:\n",
        "                dp = list(range(m+1))\n",
        "                for ii in range(1, n+1):\n",
        "                    prev = dp[0]; dp[0] = ii; ai = seq[ii-1]\n",
        "                    for jj in range(1, m+1):\n",
        "                        tmp = dp[jj]\n",
        "                        dp[jj] = min(dp[jj]+1, dp[jj-1]+1, prev + (0 if ai==tgt[jj-1] else 1))\n",
        "                        prev = tmp\n",
        "                lev = dp[m]\n",
        "            tot += lev; cnt += 1\n",
        "            if (i%10)==0 or i==len(val_ids):\n",
        "                print(f\"  [val refined] {i}/{len(val_ids)} elapsed={(time.time()-t0)/60:.2f}m\", flush=True)\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "val_lev = eval_val_refined()\n",
        "print(f\"Refined decoder val_lev={val_lev:.4f} (normalized ~{val_lev/20:.5f})\", flush=True)\n",
        "\n",
        "print(\"=== Inference TEST with refined decoder -> submission.csv ===\", flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "with torch.no_grad():\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat(sid, split='test', max_T=1800)\n",
        "        xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "        logits = model(xb)[0]\n",
        "        probs = logits.softmax(dim=-1)\n",
        "        seq = decode_video_probs(probs, med_k, pool_k=13, nms_radius=12)\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [test refined] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv; head:\\n', sub.head())\n",
        "print('=== Refined decoding complete ===')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Refined decoder: smoothing + duration prior + NMS + CoM refinement ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train videos: 253, Val videos: 44\nComputing per-class median durations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [dur] 50/297 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [dur] 100/297 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [dur] 150/297 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [dur] 200/297 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [dur] 250/297 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [dur] 297/297 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 25, 2: 25, 3: 25, 4: 25, 5: 25} ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val refined] 10/44 elapsed=0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/3370880709.py:149: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load('model_ce_tcn_v2.pth', map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val refined] 20/44 elapsed=0.00m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val refined] 30/44 elapsed=0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val refined] 40/44 elapsed=0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val refined] 44/44 elapsed=0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refined decoder val_lev=4.5000 (normalized ~0.22500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Inference TEST with refined decoder -> submission.csv ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test refined] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test refined] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test refined] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test refined] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test refined] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test refined] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test refined] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test refined] 80/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test refined] 90/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test refined] 95/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 1...\n1  301  10 1 5 4 6 2 11 14 13 19 15 7 9 20 12 8 18 3 1...\n2  302  1 17 16 12 5 19 13 15 20 18 11 3 4 6 8 14 10 9...\n3  303  13 4 3 10 14 5 19 15 20 17 1 11 16 8 18 7 12 6...\n4  304  8 1 7 12 18 13 9 2 11 3 20 19 15 5 14 6 17 16 ...\n=== Refined decoding complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "427fc534-4bcc-4d9b-a22e-895532555c77",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math, time, random, gc, os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "print(\"=== MS-TCN multi-stage CE training with temporal smoothing and refined decoding ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "# Deterministic split matching prior cells\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "tr_ids = all_ids[val_n:]\n",
        "print(f\"Train videos: {len(tr_ids)}, Val videos: {len(val_ids)}\")\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p)\n",
        "    X = d['X'].astype(np.float32)\n",
        "    if X.shape[0] > max_T: X = X[:max_T]\n",
        "    return X\n",
        "\n",
        "def load_lab(sample_id: int, max_T=1800):\n",
        "    y = np.load(lab_tr_dir/f\"{sample_id}.npy\").astype(np.int64)\n",
        "    if y.shape[0] > max_T: y = y[:max_T]\n",
        "    return y\n",
        "\n",
        "class FrameDataset(Dataset):\n",
        "    def __init__(self, ids, max_T=1800):\n",
        "        self.ids = list(ids); self.max_T=max_T\n",
        "    def __len__(self): return len(self.ids)\n",
        "    def __getitem__(self, idx):\n",
        "        sid = int(self.ids[idx])\n",
        "        X = load_feat(sid, 'train', self.max_T)\n",
        "        y = load_lab(sid, self.max_T)\n",
        "        T = min(len(X), len(y))\n",
        "        X = X[:T]; y = y[:T]\n",
        "        return torch.from_numpy(X), torch.from_numpy(y), sid\n",
        "\n",
        "def collate(batch):\n",
        "    xs, ys, sids = zip(*batch)\n",
        "    Tm = max(x.shape[0] for x in xs); D = xs[0].shape[1]; B=len(xs)\n",
        "    xb = torch.zeros(B, Tm, D, dtype=torch.float32)\n",
        "    yb = torch.zeros(B, Tm, dtype=torch.long)\n",
        "    mask = torch.zeros(B, Tm, dtype=torch.bool)\n",
        "    for i,(x,y) in enumerate(zip(xs,ys)):\n",
        "        T=len(x); xb[i,:T]=x; yb[i,:T]=y; mask[i,:T]=True\n",
        "    return xb, yb, mask, list(sids)\n",
        "\n",
        "train_loader = DataLoader(FrameDataset(tr_ids, 1800), batch_size=12, shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate)\n",
        "val_loader   = DataLoader(FrameDataset(val_ids, 1800), batch_size=12, shuffle=False, num_workers=2, pin_memory=True, collate_fn=collate)\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.3, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        pad = dilation\n",
        "        self.conv1 = nn.Conv1d(ch, ch, kernel_size=k, padding=pad, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, kernel_size=1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class Stage(nn.Module):\n",
        "    def __init__(self, in_ch, ch=96, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(in_ch, ch, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(ch, dil, drop=drop))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(ch, 21, kernel_size=1)\n",
        "    def forward(self, x):  # x: (B,Fin,T)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            h = blk(h)\n",
        "        logits = self.head(h)  # (B,21,T)\n",
        "        return logits\n",
        "\n",
        "class MSTCN(nn.Module):\n",
        "    def __init__(self, d_in, stages=4, ch=96, layers=10, drop=0.3, concat_feat=True):\n",
        "        super().__init__()\n",
        "        self.concat_feat = concat_feat\n",
        "        self.stages = nn.ModuleList()\n",
        "        fin = d_in\n",
        "        self.input_proj = nn.Conv1d(d_in, d_in, kernel_size=1)  # identity-capable\n",
        "        for s in range(stages):\n",
        "            in_ch = (fin + 21) if (s>0 and concat_feat) else (21 if s>0 else fin)\n",
        "            self.stages.append(Stage(in_ch, ch=ch, layers=layers, drop=drop))\n",
        "    def forward(self, x_b_t_d):  # (B,T,D)\n",
        "        x = x_b_t_d.transpose(1,2)  # (B,D,T)\n",
        "        x = self.input_proj(x)\n",
        "        logits_list = []\n",
        "        prev_logits = None\n",
        "        for i, st in enumerate(self.stages):\n",
        "            if i == 0:\n",
        "                inp = x\n",
        "            else:\n",
        "                if self.concat_feat:\n",
        "                    inp = torch.cat([x, prev_logits], dim=1)\n",
        "                else:\n",
        "                    inp = prev_logits\n",
        "            l = st(inp)  # (B,21,T)\n",
        "            prev_logits = l\n",
        "            logits_list.append(l.transpose(1,2))  # (B,T,21)\n",
        "        return logits_list  # list of (B,T,21)\n",
        "\n",
        "# Losses\n",
        "def ce_ignore_bg_with_ls(logits, targets, mask, label_smoothing=0.05):\n",
        "    # logits: (B,T,C), targets: (B,T), mask: (B,T) True valid; ignore targets==0 (bg)\n",
        "    B,T,C = logits.shape\n",
        "    valid = mask & (targets > 0)\n",
        "    if valid.sum() == 0:\n",
        "        return logits.new_zeros([])\n",
        "    # gather valid logits and targets\n",
        "    lg = logits[valid]  # (N,C)\n",
        "    y = targets[valid]  # (N,)\n",
        "    if label_smoothing > 0:\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(lg).scatter_(1, y.unsqueeze(1), 1.0)\n",
        "            true_dist = true_dist * (1 - label_smoothing) + label_smoothing / (lg.size(1) - 1)\n",
        "        logp = F.log_softmax(lg, dim=-1)\n",
        "        return F.kl_div(logp, true_dist, reduction='batchmean')\n",
        "    else:\n",
        "        return F.cross_entropy(lg, y, reduction='mean')\n",
        "\n",
        "def temporal_mse(probs, mask):\n",
        "    # probs: (B,T,C), encourage p_t ~ p_{t-1} on valid frames, ignore bg explicitly not needed\n",
        "    diff = (probs[:,1:,:] - probs[:,:-1,:])**2  # (B,T-1,C)\n",
        "    m = (mask[:,1:] & mask[:,:-1]).float().unsqueeze(-1)\n",
        "    num = (diff * m).sum()\n",
        "    den = m.sum().clamp_min(1.0)\n",
        "    return num / den\n",
        "\n",
        "# Augmentations\n",
        "def time_mask(x, mask, n=2, wmin=8, wmax=16, p=0.5):\n",
        "    if random.random() > p: return x, mask\n",
        "    B,T,D = x.shape\n",
        "    for _ in range(n):\n",
        "        w = random.randint(wmin, wmax)\n",
        "        t0 = random.randint(0, max(0, T-w))\n",
        "        x[:, t0:t0+w, :] = 0.0\n",
        "        mask[:, t0:t0+w] = mask[:, t0:t0+w]  # mask unchanged (still valid frames)\n",
        "    return x, mask\n",
        "\n",
        "def frame_drop(x, y, mask, p=0.2):\n",
        "    # randomly drop a small number of frames per sample, keep length by duplicating neighbors\n",
        "    if random.random() > p: return x, y, mask\n",
        "    B,T,D = x.shape\n",
        "    for b in range(B):\n",
        "        valid_T = int(mask[b].sum().item())\n",
        "        if valid_T < 3: continue\n",
        "        drop_t = random.randint(1, max(1, int(0.02*valid_T)))\n",
        "        for _ in range(drop_t):\n",
        "            t = random.randint(1, valid_T-2)\n",
        "            x[b,t] = (x[b,t-1] + x[b,t+1]) * 0.5\n",
        "            y[b,t] = y[b,t-1]\n",
        "    return x, y, mask\n",
        "\n",
        "def jitter(x, sigma=0.01):\n",
        "    return x + torch.randn_like(x)*sigma\n",
        "\n",
        "# Refined decoder utilities (reuse from cell 19, inlined for safety)\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int = 13) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    y = F.conv1d(x, w, padding=k//2)\n",
        "    return y.view(-1)\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star: int, w: int = 5) -> float:\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w); b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]\n",
        "    s = seg.sum() + 1e-8\n",
        "    com = (idx * seg).sum() / s\n",
        "    return float(com.item())\n",
        "\n",
        "def compute_class_median_durations():\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df['Id'].astype(int).tolist()\n",
        "    for sid in ids:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        med[c] = int(np.clip(np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13, 9, 25))\n",
        "    return med\n",
        "\n",
        "med_k = compute_class_median_durations()\n",
        "\n",
        "def decode_video_probs_refined(p_t_c: torch.Tensor, pool_k=13):\n",
        "    # p_t_c: (T,C), C=21; class 0 bg\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    T,C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = med_k.get(c, 13) if c!=0 else 13\n",
        "        if c==0:\n",
        "            scores[:,c] = p_s[:,c]\n",
        "        else:\n",
        "            scores[:,c] = duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        t_star = int(torch.argmax(scores[:,c]).item())\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=5)\n",
        "        t_idx = int(round(t_ref));\n",
        "        t_idx = min(max(t_idx, 0), T-1)\n",
        "        peaks.append((c, t_ref, float(scores[t_idx, c].item())))\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2]))\n",
        "    return [c for c,_,_ in peaks]\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def levenshtein(a, b):\n",
        "    n, m = len(a), len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp = list(range(m+1))\n",
        "    for i in range(1, n+1):\n",
        "        prev = dp[0]; dp[0] = i; ai = a[i-1]\n",
        "        for j in range(1, m+1):\n",
        "            tmp = dp[j]\n",
        "            dp[j] = min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1))\n",
        "            prev = tmp\n",
        "    return dp[m]\n",
        "\n",
        "def eval_val(model):\n",
        "    model.eval()\n",
        "    tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, mask, sids in val_loader:\n",
        "            xb = xb.to(device); mask = mask.to(device)\n",
        "            logits_list = model(xb)  # list of (B,T,C)\n",
        "            # use final stage probs\n",
        "            probs = logits_list[-1].softmax(dim=-1)  # (B,T,C)\n",
        "            for b, sid in enumerate(sids):\n",
        "                T = int(mask[b].sum().item())\n",
        "                p = probs[b,:T,:]\n",
        "                seq = decode_video_probs_refined(p, pool_k=13)\n",
        "                tgt = id2seq[int(sid)]\n",
        "                tot += levenshtein(seq, tgt); cnt += 1\n",
        "    print(f\"  [val decode] {cnt} vids in {(time.time()-t0)/60:.2f}m\", flush=True)\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "def train_seed(seed=0, epochs=18, patience=3, ch=96, stages=4, layers=10, ls=0.05, lambda_t=0.2, concat_feat=True):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    model = MSTCN(d_in=D_in, stages=stages, ch=ch, layers=layers, drop=0.3, concat_feat=concat_feat).to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=15)\n",
        "    best = math.inf; best_state=None; bad=0\n",
        "    stage_w = [0.3,0.3,0.3,1.0][:stages]\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train(); t0=time.time(); nb=0; tot_loss=0.0\n",
        "        for it, (xb, yb, mask, sids) in enumerate(train_loader):\n",
        "            xb = xb.to(device); yb = yb.to(device); mask = mask.to(device)\n",
        "            # augment\n",
        "            xb, mask = time_mask(xb, mask, n=2, wmin=8, wmax=16, p=0.5)\n",
        "            xb, yb, mask = frame_drop(xb, yb, mask, p=0.2)\n",
        "            xb = jitter(xb, sigma=0.01)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits_list = model(xb)  # list len=stages of (B,T,21)\n",
        "            loss_ce = 0.0\n",
        "            probs_last = None\n",
        "            for s, lg in enumerate(logits_list):\n",
        "                loss_ce = loss_ce + stage_w[min(s, len(stage_w)-1)] * ce_ignore_bg_with_ls(lg, yb, mask, label_smoothing=ls)\n",
        "                probs_last = lg.softmax(dim=-1)\n",
        "            loss_t = temporal_mse(probs_last, mask) * lambda_t\n",
        "            loss = loss_ce + loss_t\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "            tot_loss += float(loss.item()); nb += 1\n",
        "            if (it+1)%20==0:\n",
        "                print(f\"ep{ep} it{it+1} loss={tot_loss/nb:.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "        sched.step()\n",
        "        val_lev = eval_val(model)\n",
        "        print(f\"Seed{seed} Epoch {ep}: train_loss={tot_loss/max(nb,1):.4f} val_lev={val_lev:.4f} lr={sched.get_last_lr()[0]:.6f}\", flush=True)\n",
        "        if val_lev < best - 1e-4:\n",
        "            best = val_lev; best_state = {k:v.detach().cpu() for k,v in model.state_dict().items()}; bad=0\n",
        "            print(f\"  New best (seed {seed}) val_lev={best:.4f}\", flush=True)\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience:\n",
        "                print(\"Early stopping.\", flush=True); break\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    out_path = f\"model_mstcn_s{seed}.pth\"\n",
        "    torch.save(model.state_dict(), out_path)\n",
        "    print(f\"Saved {out_path}; best val_lev={best:.4f}\")\n",
        "    return out_path, best\n",
        "\n",
        "# Train 3 seeds sequentially\n",
        "seeds = [0,1,2]\n",
        "ckpts = []; scores=[]\n",
        "for s in seeds:\n",
        "    p, sc = train_seed(seed=s, epochs=18, patience=3, ch=96, stages=4, layers=10, ls=0.05, lambda_t=0.2, concat_feat=True)\n",
        "    ckpts.append(p); scores.append(sc)\n",
        "print(\"Seed scores:\", list(zip(seeds, scores)))\n",
        "\n",
        "# Optionally, ensemble on VAL to verify gain and then run TEST ensemble\n",
        "def ensemble_val_and_test(ckpt_paths):\n",
        "    models = []\n",
        "    for p in ckpt_paths:\n",
        "        m = MSTCN(d_in=D_in, stages=4, ch=96, layers=10, drop=0.3, concat_feat=True).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device)); m.eval(); models.append(m)\n",
        "    # VAL\n",
        "    tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, mask, sids in val_loader:\n",
        "            xb = xb.to(device); mask = mask.to(device)\n",
        "            probs_ens = None\n",
        "            for m in models:\n",
        "                logits = m(xb)[-1]  # (B,T,C)\n",
        "                p = logits.softmax(dim=-1)\n",
        "                probs_ens = p if probs_ens is None else (probs_ens + p)\n",
        "            probs_ens = probs_ens / len(models)\n",
        "            for b, sid in enumerate(sids):\n",
        "                T = int(mask[b].sum().item())\n",
        "                seq = decode_video_probs_refined(probs_ens[b,:T,:], pool_k=13)\n",
        "                tgt = id2seq[int(sid)]\n",
        "                tot += levenshtein(seq, tgt); cnt += 1\n",
        "    val_lev = tot/max(cnt,1)\n",
        "    print(f\"Ensemble VAL Levenshtein={val_lev:.4f} (norm ~{val_lev/20:.5f}), evaluated {cnt} vids in {(time.time()-t0)/60:.2f}m\")\n",
        "    # TEST inference and submission\n",
        "    test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "    rows=[]; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, sid in enumerate(test_ids, 1):\n",
        "            X = load_feat(int(sid), split='test', max_T=1800)\n",
        "            xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "            probs_ens = None\n",
        "            for m in models:\n",
        "                logits = m(xb)[-1][0]  # (T,C)\n",
        "                p = logits.softmax(dim=-1)\n",
        "                probs_ens = p if probs_ens is None else (probs_ens + p)\n",
        "            probs_ens = probs_ens / len(models)\n",
        "            seq = decode_video_probs_refined(probs_ens, pool_k=13)\n",
        "            rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "            if (i%10)==0 or i==len(test_ids):\n",
        "                print(f\"  [test ens] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Wrote submission.csv; head:\\n', sub.head())\n",
        "\n",
        "# After training completes, run ensemble_val_and_test(ckpts) in a subsequent execution if desired.\n",
        "print(\"=== MS-TCN setup complete; training launched for seeds ===\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MS-TCN multi-stage CE training with temporal smoothing and refined decoding ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train videos: 253, Val videos: 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1 it20 loss=5.8197 elapsed=3.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 1: train_loss=5.7760 val_lev=17.7273 lr=0.000297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=17.7273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2 it20 loss=4.8505 elapsed=2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 2: train_loss=4.8603 val_lev=17.1364 lr=0.000287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=17.1364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3 it20 loss=4.4697 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 3: train_loss=4.4398 val_lev=15.5909 lr=0.000271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=15.5909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4 it20 loss=4.0490 elapsed=2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 4: train_loss=4.0128 val_lev=13.7727 lr=0.000250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=13.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5 it20 loss=3.6743 elapsed=2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 5: train_loss=3.6420 val_lev=12.4318 lr=0.000225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=12.4318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6 it20 loss=3.3811 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 6: train_loss=3.4042 val_lev=11.5000 lr=0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=11.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7 it20 loss=3.1541 elapsed=2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 7: train_loss=3.1402 val_lev=11.4318 lr=0.000166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=11.4318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8 it20 loss=3.0225 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 8: train_loss=2.9932 val_lev=10.3182 lr=0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=10.3182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9 it20 loss=2.8482 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 9: train_loss=2.8160 val_lev=9.3182 lr=0.000104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=9.3182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10 it20 loss=2.7327 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 10: train_loss=2.7251 val_lev=9.2500 lr=0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=9.2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11 it20 loss=2.6681 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 11: train_loss=2.6431 val_lev=9.0455 lr=0.000050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=9.0455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12 it20 loss=2.6100 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 12: train_loss=2.6019 val_lev=8.9545 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=8.9545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13 it20 loss=2.5490 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 13: train_loss=2.5416 val_lev=8.9318 lr=0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=8.9318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14 it20 loss=2.5104 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 14: train_loss=2.5212 val_lev=8.7045 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=8.7045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15 it20 loss=2.5166 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 15: train_loss=2.5446 val_lev=8.7727 lr=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16 it20 loss=2.5043 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 16: train_loss=2.5064 val_lev=8.7727 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep17 it20 loss=2.5038 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 17: train_loss=2.5036 val_lev=8.6364 lr=0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=8.6364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep18 it20 loss=2.4864 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 18: train_loss=2.4934 val_lev=8.4091 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=8.4091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model_mstcn_s0.pth; best val_lev=8.4091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1 it20 loss=6.0162 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 1: train_loss=5.9412 val_lev=17.9773 lr=0.000297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=17.9773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2 it20 loss=4.8995 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 2: train_loss=4.8880 val_lev=16.5000 lr=0.000287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=16.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3 it20 loss=4.3934 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 3: train_loss=4.3701 val_lev=15.2045 lr=0.000271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=15.2045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4 it20 loss=3.9950 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 4: train_loss=3.9589 val_lev=13.7273 lr=0.000250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=13.7273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5 it20 loss=3.6042 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 5: train_loss=3.5903 val_lev=12.5909 lr=0.000225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=12.5909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6 it20 loss=3.3214 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 6: train_loss=3.3323 val_lev=11.6591 lr=0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=11.6591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7 it20 loss=3.1208 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 7: train_loss=3.1247 val_lev=11.0682 lr=0.000166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=11.0682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8 it20 loss=2.9295 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 8: train_loss=2.9262 val_lev=9.8636 lr=0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=9.8636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9 it20 loss=2.7755 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 9: train_loss=2.7838 val_lev=9.9091 lr=0.000104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10 it20 loss=2.6603 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 10: train_loss=2.6420 val_lev=9.4091 lr=0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=9.4091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11 it20 loss=2.5681 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 11: train_loss=2.5553 val_lev=9.1818 lr=0.000050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=9.1818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12 it20 loss=2.5154 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 12: train_loss=2.4691 val_lev=8.7955 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=8.7955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13 it20 loss=2.4683 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 13: train_loss=2.4512 val_lev=8.3182 lr=0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=8.3182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14 it20 loss=2.4317 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 14: train_loss=2.4244 val_lev=8.5227 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15 it20 loss=2.4105 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 15: train_loss=2.4095 val_lev=8.3409 lr=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16 it20 loss=2.4181 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 16: train_loss=2.3833 val_lev=8.3409 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model_mstcn_s1.pth; best val_lev=8.3182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1 it20 loss=6.0658 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 1: train_loss=5.9872 val_lev=17.8864 lr=0.000297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=17.8864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2 it20 loss=4.8765 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 2: train_loss=4.8706 val_lev=16.2273 lr=0.000287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=16.2273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3 it20 loss=4.4174 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 3: train_loss=4.4294 val_lev=14.5000 lr=0.000271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=14.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4 it20 loss=4.0161 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 4: train_loss=4.0090 val_lev=13.0909 lr=0.000250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=13.0909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5 it20 loss=3.6612 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 5: train_loss=3.6524 val_lev=11.8182 lr=0.000225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=11.8182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6 it20 loss=3.3170 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 6: train_loss=3.3090 val_lev=10.4318 lr=0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=10.4318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7 it20 loss=3.0512 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 7: train_loss=3.0383 val_lev=9.8636 lr=0.000166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=9.8636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8 it20 loss=2.8271 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 8: train_loss=2.8518 val_lev=9.1591 lr=0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=9.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9 it20 loss=2.6718 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 9: train_loss=2.6690 val_lev=9.2045 lr=0.000104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10 it20 loss=2.5676 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 10: train_loss=2.5371 val_lev=8.7500 lr=0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11 it20 loss=2.4912 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 11: train_loss=2.6466 val_lev=8.6818 lr=0.000050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.6818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12 it20 loss=2.4345 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 12: train_loss=2.4175 val_lev=8.5227 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.5227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13 it20 loss=2.4044 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 13: train_loss=2.4229 val_lev=8.4545 lr=0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14 it20 loss=2.3559 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 14: train_loss=2.3273 val_lev=8.4318 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.4318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15 it20 loss=2.3471 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 15: train_loss=2.3249 val_lev=8.2955 lr=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16 it20 loss=2.3719 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 16: train_loss=2.3625 val_lev=8.2955 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep17 it20 loss=2.3549 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 17: train_loss=2.3444 val_lev=8.4318 lr=0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep18 it20 loss=2.3443 elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 18: train_loss=2.3099 val_lev=8.1591 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model_mstcn_s2.pth; best val_lev=8.1591\nSeed scores: [(0, 8.409090909090908), (1, 8.318181818181818), (2, 8.159090909090908)]\n=== MS-TCN setup complete; training launched for seeds ===\n"
          ]
        }
      ]
    },
    {
      "id": "e19230df-b8ab-4b08-889c-1e6e03688fbb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"=== Ensembling 3 MS-TCN seeds and generating submission ===\", flush=True)\n",
        "ckpts = [\"model_mstcn_s0.pth\", \"model_mstcn_s1.pth\", \"model_mstcn_s2.pth\"]\n",
        "for p in ckpts:\n",
        "    assert Path(p).exists(), f\"Missing checkpoint {p}\"\n",
        "ensemble_val_and_test(ckpts)\n",
        "print(\"=== Ensemble complete ===\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Ensembling 3 MS-TCN seeds and generating submission ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/887928681.py:333: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(p, map_location=device)); m.eval(); models.append(m)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble VAL Levenshtein=7.7045 (norm ~0.38523), evaluated 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens] 80/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens] 90/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens] 95/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 15 14 11 10 6 16 1...\n1  301  15 12 3 1 5 4 6 2 10 11 20 7 13 19 9 8 18 14 1...\n2  302  1 17 16 3 5 7 19 13 20 18 12 11 4 10 6 8 14 15...\n3  303  13 18 12 4 3 11 15 16 19 20 17 10 5 8 7 1 6 2 ...\n4  304  8 7 1 2 14 12 18 13 9 11 10 3 20 19 5 15 6 17 ...\n=== Ensemble complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "fb764fd6-56e9-4f9c-aef4-52c7faac70db",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"=== Ensemble CE-TCN (best) + MS-TCN (best seed) with refined decoder ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "# Recreate split and utilities from previous cells\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "import random, numpy as np\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p)\n",
        "    X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "def compute_class_median_durations():\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df['Id'].astype(int).tolist()\n",
        "    for sid in ids:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum())\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}; import numpy as _np\n",
        "    for c in range(1,21):\n",
        "        med[c] = int(_np.clip(_np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13, 9, 25))\n",
        "    return med\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int = 13) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    y = F.conv1d(x, w, padding=k//2)\n",
        "    return y.view(-1)\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star: int, w: int = 5) -> float:\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w); b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]\n",
        "    s = seg.sum() + 1e-8\n",
        "    com = (idx * seg).sum() / s\n",
        "    return float(com.item())\n",
        "\n",
        "med_k = compute_class_median_durations()\n",
        "\n",
        "def decode_video_probs_refined(p_t_c: torch.Tensor, pool_k=13):\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    T,C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = med_k.get(c, 13) if c!=0 else 13\n",
        "        if c==0: scores[:,c] = p_s[:,c]\n",
        "        else:   scores[:,c] = duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        t_star = int(torch.argmax(scores[:,c]).item())\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=5)\n",
        "        t_idx = int(round(t_ref)); t_idx = min(max(t_idx, 0), T-1)\n",
        "        peaks.append((c, t_ref, float(scores[t_idx, c].item())))\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2]))\n",
        "    return [c for c,_,_ in peaks]\n",
        "\n",
        "# Model defs must match trained checkpoints\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h; h = blk(h); h = h + res\n",
        "        logits = self.head(h)\n",
        "        return logits.transpose(1,2)\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.3, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, kernel_size=k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, kernel_size=1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class Stage(nn.Module):\n",
        "    def __init__(self, in_ch, ch=96, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(in_ch, ch, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(ch, dil, drop=drop))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(ch, 21, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            h = blk(h)\n",
        "        return self.head(h)\n",
        "\n",
        "class MSTCN(nn.Module):\n",
        "    def __init__(self, d_in, stages=4, ch=96, layers=10, drop=0.3, concat_feat=True):\n",
        "        super().__init__()\n",
        "        self.concat_feat = concat_feat\n",
        "        self.stages = nn.ModuleList()\n",
        "        xproj = nn.Conv1d(d_in, d_in, kernel_size=1)\n",
        "        self.input_proj = xproj\n",
        "        fin = d_in\n",
        "        for s in range(stages):\n",
        "            in_ch = (fin + 21) if (s>0 and concat_feat) else (21 if s>0 else fin)\n",
        "            self.stages.append(Stage(in_ch, ch=ch, layers=layers, drop=drop))\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        x = self.input_proj(x)\n",
        "        logits_list = []; prev=None\n",
        "        for i, st in enumerate(self.stages):\n",
        "            inp = x if i==0 else (torch.cat([x, prev], dim=1) if self.concat_feat else prev)\n",
        "            prev = st(inp)\n",
        "            logits_list.append(prev.transpose(1,2))\n",
        "        return logits_list\n",
        "\n",
        "# Load best CE-TCN\n",
        "ce_model = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "ce_model.load_state_dict(torch.load('model_ce_tcn_v2.pth', map_location=device)); ce_model.eval()\n",
        "# Load best MS-TCN seed (seed2 best)\n",
        "ms_model = MSTCN(d_in=D_in, stages=4, ch=96, layers=10, drop=0.3, concat_feat=True).to(device)\n",
        "ms_model.load_state_dict(torch.load('model_mstcn_s2.pth', map_location=device)); ms_model.eval()\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def levenshtein(a, b):\n",
        "    n, m = len(a), len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp = list(range(m+1))\n",
        "    for i in range(1, n+1):\n",
        "        prev = dp[0]; dp[0] = i; ai = a[i-1]\n",
        "        for j in range(1, m+1):\n",
        "            tmp = dp[j]\n",
        "            dp[j] = min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1))\n",
        "            prev = tmp\n",
        "    return dp[m]\n",
        "\n",
        "def eval_val_ensemble(w_ce=0.8, w_ms=0.2):\n",
        "    tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for sid in val_ids:\n",
        "            X = load_feat(sid, 'train', 1800)\n",
        "            xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "            p_ce = ce_model(xb)[0].softmax(dim=-1)\n",
        "            p_ms = ms_model(xb)[-1][0].softmax(dim=-1)\n",
        "            probs = (w_ce*p_ce + w_ms*p_ms)\n",
        "            seq = decode_video_probs_refined(probs, pool_k=13)\n",
        "            tgt = id2seq[int(sid)]\n",
        "            tot += levenshtein(seq, tgt); cnt += 1\n",
        "            if (cnt % 10)==0 or cnt==len(val_ids):\n",
        "                print(f\"  [val ens] {cnt}/{len(val_ids)}\", flush=True)\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "val_lev = eval_val_ensemble(0.8, 0.2)\n",
        "print(f\"Ensemble (CE 0.8 + MS 0.2) VAL Levenshtein={val_lev:.4f} (norm ~{val_lev/20:.5f})\")\n",
        "\n",
        "print(\"=== TEST inference for CE+MS ensemble ===\", flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "with torch.no_grad():\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat(int(sid), 'test', 1800)\n",
        "        xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "        p_ce = ce_model(xb)[0].softmax(dim=-1)\n",
        "        p_ms = ms_model(xb)[-1][0].softmax(dim=-1)\n",
        "        probs = (0.8*p_ce + 0.2*p_ms)\n",
        "        seq = decode_video_probs_refined(probs, pool_k=13)\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [test ens ce+ms] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv; head:\\n', sub.head())\n",
        "print('=== CE+MS ensemble complete ===')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Ensemble CE-TCN (best) + MS-TCN (best seed) with refined decoder ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/385016801.py:165: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ce_model.load_state_dict(torch.load('model_ce_tcn_v2.pth', map_location=device)); ce_model.eval()\n/tmp/ipykernel_183/385016801.py:168: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ms_model.load_state_dict(torch.load('model_mstcn_s2.pth', map_location=device)); ms_model.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val ens] 10/44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val ens] 20/44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val ens] 30/44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val ens] 40/44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val ens] 44/44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble (CE 0.8 + MS 0.2) VAL Levenshtein=4.6591 (norm ~0.23295)\n=== TEST inference for CE+MS ensemble ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens ce+ms] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens ce+ms] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens ce+ms] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens ce+ms] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens ce+ms] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens ce+ms] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens ce+ms] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens ce+ms] 80/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens ce+ms] 90/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ens ce+ms] 95/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 1...\n1  301  10 1 5 4 6 2 11 14 13 19 15 7 9 20 12 8 18 3 1...\n2  302  1 17 16 12 5 19 13 20 18 11 3 4 10 6 8 14 15 9...\n3  303  13 4 3 10 14 5 19 15 20 17 11 16 8 18 7 12 1 6...\n4  304  8 1 7 12 18 13 9 2 11 3 20 19 15 5 14 6 17 16 ...\n=== CE+MS ensemble complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "f1f2b4b9-390b-4da7-9fa7-fad19bf5acb1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math, time, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "print(\"=== MS-TCN++ (probs-only refinement) training + improved decoder (pool_k=15, classwise NMS) ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available(): torch.backends.cudnn.benchmark = True\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "# Split (match earlier) \n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "tr_ids = all_ids[val_n:]\n",
        "print(f\"Train videos: {len(tr_ids)}, Val videos: {len(val_ids)}\")\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p)\n",
        "    X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "def load_lab(sample_id: int, max_T=1800):\n",
        "    y = np.load(lab_tr_dir/f\"{sample_id}.npy\").astype(np.int64)\n",
        "    return y[:max_T] if y.shape[0] > max_T else y\n",
        "\n",
        "class FrameDataset(Dataset):\n",
        "    def __init__(self, ids, max_T=1800):\n",
        "        self.ids = list(ids); self.max_T=max_T\n",
        "    def __len__(self): return len(self.ids)\n",
        "    def __getitem__(self, idx):\n",
        "        sid = int(self.ids[idx])\n",
        "        X = load_feat(sid, 'train', self.max_T)\n",
        "        y = load_lab(sid, self.max_T)\n",
        "        T = min(len(X), len(y))\n",
        "        return torch.from_numpy(X[:T]), torch.from_numpy(y[:T]), sid\n",
        "\n",
        "def collate(batch):\n",
        "    xs, ys, sids = zip(*batch)\n",
        "    Tm = max(x.shape[0] for x in xs); D = xs[0].shape[1]; B=len(xs)\n",
        "    xb = torch.zeros(B, Tm, D, dtype=torch.float32)\n",
        "    yb = torch.zeros(B, Tm, dtype=torch.long)\n",
        "    mask = torch.zeros(B, Tm, dtype=torch.bool)\n",
        "    for i,(x,y) in enumerate(zip(xs,ys)):\n",
        "        T=len(x); xb[i,:T]=x; yb[i,:T]=y; mask[i,:T]=True\n",
        "    return xb, yb, mask, list(sids)\n",
        "\n",
        "train_loader = DataLoader(FrameDataset(tr_ids, 1800), batch_size=12, shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate)\n",
        "val_loader   = DataLoader(FrameDataset(val_ids, 1800), batch_size=12, shuffle=False, num_workers=2, pin_memory=True, collate_fn=collate)\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.3, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, kernel_size=k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, kernel_size=1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class Stage(nn.Module):\n",
        "    def __init__(self, in_ch, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(in_ch, ch, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(ch, dil, drop=drop))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(ch, 21, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            h = blk(h)\n",
        "        return self.head(h)  # (B,21,T)\n",
        "\n",
        "class MSTCNPP(nn.Module):\n",
        "    # Stage 1: features -> logits\n",
        "    # Stages 2+: probs-only refinement (no feature concat), i.e., input is prev softmax logits as channels\n",
        "    def __init__(self, d_in, stages=4, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.stages = nn.ModuleList()\n",
        "        self.input_proj = nn.Conv1d(d_in, d_in, kernel_size=1)\n",
        "        # Stage 1 takes features\n",
        "        self.stages.append(Stage(d_in, ch=ch, layers=layers, drop=drop))\n",
        "        # Subsequent stages take 21-channel probs/logits as input\n",
        "        for _ in range(stages-1):\n",
        "            self.stages.append(Stage(21, ch=ch, layers=layers, drop=drop))\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)  # (B,D,T)\n",
        "        x = self.input_proj(x)\n",
        "        logits_list = []\n",
        "        prev = self.stages[0](x)  # (B,21,T)\n",
        "        logits_list.append(prev.transpose(1,2))\n",
        "        for s in range(1, len(self.stages)):\n",
        "            # use probs-only refinement\n",
        "            probs = prev.softmax(dim=1)  # (B,21,T)\n",
        "            prev = self.stages[s](probs)  # (B,21,T)\n",
        "            logits_list.append(prev.transpose(1,2))\n",
        "        return logits_list  # list of (B,T,21)\n",
        "\n",
        "def ce_ignore_bg_with_ls(logits, targets, mask, label_smoothing=0.10):\n",
        "    B,T,C = logits.shape\n",
        "    valid = mask & (targets > 0)\n",
        "    if valid.sum() == 0: return logits.new_zeros([])\n",
        "    lg = logits[valid]; y = targets[valid]\n",
        "    if label_smoothing > 0:\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(lg).scatter_(1, y.unsqueeze(1), 1.0)\n",
        "            true_dist = true_dist * (1 - label_smoothing) + label_smoothing / (lg.size(1) - 1)\n",
        "        logp = F.log_softmax(lg, dim=-1)\n",
        "        return F.kl_div(logp, true_dist, reduction='batchmean')\n",
        "    else:\n",
        "        return F.cross_entropy(lg, y, reduction='mean')\n",
        "\n",
        "def temporal_mse(probs, mask):\n",
        "    diff = (probs[:,1:,:] - probs[:,:-1,:])**2\n",
        "    m = (mask[:,1:] & mask[:,:-1]).float().unsqueeze(-1)\n",
        "    num = (diff * m).sum(); den = m.sum().clamp_min(1.0)\n",
        "    return num / den\n",
        "\n",
        "# Augmentations\n",
        "def time_mask(x, mask, n=2, wmin=8, wmax=16, p=0.5):\n",
        "    if random.random() > p: return x, mask\n",
        "    B,T,D = x.shape\n",
        "    for _ in range(n):\n",
        "        w = random.randint(wmin, wmax)\n",
        "        t0 = random.randint(0, max(0, T-w))\n",
        "        x[:, t0:t0+w, :] = 0.0\n",
        "    return x, mask\n",
        "\n",
        "def jitter(x, sigma=0.01):\n",
        "    return x + torch.randn_like(x)*sigma\n",
        "\n",
        "# Decoder utils with pool_k=15, classwise NMS radius and tie-breaks\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int = 15) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    y = F.conv1d(x, w, padding=k//2)\n",
        "    return y.view(-1)\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star: int, w: int = 5) -> float:\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w); b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def compute_class_medians():\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df['Id'].astype(int).tolist()\n",
        "    for sid in ids:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        med[c] = int(np.clip(np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13, 9, 25))\n",
        "    return med\n",
        "\n",
        "MED_K = compute_class_medians()\n",
        "\n",
        "def decode_video_probs_refined(p_t_c: torch.Tensor, pool_k=15):\n",
        "    # classwise radius\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    T,C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = MED_K.get(c, 13) if c!=0 else 13\n",
        "        scores[:,c] = p_s[:,c] if c==0 else duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        radius = max(10, MED_K.get(c,13)//2)\n",
        "        s = scores[:,c]\n",
        "        t_star = int(torch.argmax(s).item())\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=5)\n",
        "        t_idx = int(round(t_ref)); t_idx = min(max(t_idx, 0), T-1)\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        peaks.append((c, t_ref, float(scores[t_idx, c].item()), float(local_mean)))\n",
        "    # sort by time, then integral, then local mean prob\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3]))\n",
        "    return [c for c,_,_,_ in peaks]\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "def eval_val(model):\n",
        "    model.eval(); tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, mask, sids in val_loader:\n",
        "            xb = xb.to(device); mask = mask.to(device)\n",
        "            probs = model(xb)[-1].softmax(dim=-1)  # (B,T,C)\n",
        "            for b, sid in enumerate(sids):\n",
        "                T = int(mask[b].sum().item())\n",
        "                seq = decode_video_probs_refined(probs[b,:T,:], pool_k=15)\n",
        "                tot += levenshtein(seq, id2seq[int(sid)]); cnt += 1\n",
        "    print(f\"  [val decode] {cnt} vids in {(time.time()-t0)/60:.2f}m\", flush=True)\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "def train_seed(seed=0, epochs=18, patience=5, ch=128, stages=4, layers=10, ls=0.10, lambda_t=0.15):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    model = MSTCNPP(d_in=D_in, stages=stages, ch=ch, layers=layers, drop=0.3).to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=15)\n",
        "    best = math.inf; best_state=None; bad=0\n",
        "    stage_w = [0.2,0.3,0.4,1.0][:stages]\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train(); t0=time.time(); nb=0; tot_loss=0.0\n",
        "        for it, (xb, yb, mask, sids) in enumerate(train_loader):\n",
        "            xb = xb.to(device); yb = yb.to(device); mask = mask.to(device)\n",
        "            xb, mask = time_mask(xb, mask, n=2, wmin=8, wmax=16, p=0.5)\n",
        "            xb = jitter(xb, sigma=0.01)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits_list = model(xb)  # list (B,T,21)\n",
        "            loss_ce = 0.0; probs_last=None\n",
        "            for s, lg in enumerate(logits_list):\n",
        "                loss_ce = loss_ce + stage_w[min(s, len(stage_w)-1)] * ce_ignore_bg_with_ls(lg, yb, mask, label_smoothing=ls)\n",
        "                probs_last = lg.softmax(dim=-1)\n",
        "            loss_t = temporal_mse(probs_last, mask) * lambda_t\n",
        "            loss = loss_ce + loss_t\n",
        "            loss.backward(); nn.utils.clip_grad_norm_(model.parameters(), 1.0); opt.step()\n",
        "            tot_loss += float(loss.item()); nb += 1\n",
        "            if (it+1)%20==0: print(f\"ep{ep} it{it+1} loss={tot_loss/nb:.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "        sched.step()\n",
        "        val_lev = eval_val(model)\n",
        "        print(f\"Seed{seed} Epoch {ep}: train_loss={tot_loss/max(nb,1):.4f} val_lev={val_lev:.4f} lr={sched.get_last_lr()[0]:.6f}\", flush=True)\n",
        "        if val_lev < best - 1e-4:\n",
        "            best = val_lev; best_state = {k:v.detach().cpu() for k,v in model.state_dict().items()}; bad=0\n",
        "            print(f\"  New best (seed {seed}) val_lev={best:.4f}\", flush=True)\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience: print(\"Early stopping.\", flush=True); break\n",
        "    if best_state is not None: model.load_state_dict(best_state)\n",
        "    out_path = f\"model_mstcnpp_s{seed}.pth\"\n",
        "    torch.save(model.state_dict(), out_path)\n",
        "    print(f\"Saved {out_path}; best val_lev={best:.4f}\")\n",
        "    return out_path, best\n",
        "\n",
        "# Train 3 seeds\n",
        "seeds=[0,1,2]; ckpts=[]; scores=[]\n",
        "for s in seeds:\n",
        "    p, sc = train_seed(seed=s, epochs=18, patience=5, ch=128, stages=4, layers=10, ls=0.10, lambda_t=0.15)\n",
        "    ckpts.append(p); scores.append(sc)\n",
        "print(\"MS-TCN++ seed scores:\", list(zip(seeds, scores)))\n",
        "\n",
        "def ensemble_val_and_test_mstcnpp(ckpt_paths, do_test=True):\n",
        "    models=[]\n",
        "    for p in ckpt_paths:\n",
        "        m = MSTCNPP(d_in=D_in, stages=4, ch=128, layers=10, drop=0.3).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device)); m.eval(); models.append(m)\n",
        "    tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, mask, sids in val_loader:\n",
        "            xb = xb.to(device); mask = mask.to(device)\n",
        "            probs_ens=None\n",
        "            for m in models:\n",
        "                p = m(xb)[-1].softmax(dim=-1)\n",
        "                probs_ens = p if probs_ens is None else (probs_ens + p)\n",
        "            probs_ens = probs_ens/len(models)\n",
        "            for b, sid in enumerate(sids):\n",
        "                T = int(mask[b].sum().item())\n",
        "                seq = decode_video_probs_refined(probs_ens[b,:T,:], pool_k=15)\n",
        "                tot += levenshtein(seq, id2seq[int(sid)]); cnt += 1\n",
        "    val_lev = tot/max(cnt,1)\n",
        "    print(f\"MS-TCN++ ensemble VAL Levenshtein={val_lev:.4f} (norm ~{val_lev/20:.5f})\", flush=True)\n",
        "    if not do_test: return val_lev\n",
        "    # TEST inference\n",
        "    test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "    rows=[]; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, sid in enumerate(test_ids, 1):\n",
        "            X = load_feat(int(sid), 'test', 1800)\n",
        "            xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "            probs_ens=None\n",
        "            for m in models:\n",
        "                p = m(xb)[-1][0].softmax(dim=-1)\n",
        "                probs_ens = p if probs_ens is None else (probs_ens + p)\n",
        "            probs_ens = probs_ens/len(models)\n",
        "            seq = decode_video_probs_refined(probs_ens, pool_k=15)\n",
        "            rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "            if (i%10)==0 or i==len(test_ids):\n",
        "                print(f\"  [test mstcnpp ens] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Wrote submission.csv; head:\\n', sub.head())\n",
        "\n",
        "print(\"=== MS-TCN++ setup complete; training will run now ===\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MS-TCN++ (probs-only refinement) training + improved decoder (pool_k=15, classwise NMS) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train videos: 253, Val videos: 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1 it20 loss=5.4824 elapsed=7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 1: train_loss=5.4213 val_lev=18.0000 lr=0.000297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=18.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2 it20 loss=4.6555 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 2: train_loss=4.6408 val_lev=18.0455 lr=0.000287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3 it20 loss=4.3243 elapsed=3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 3: train_loss=4.2902 val_lev=17.3409 lr=0.000271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=17.3409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4 it20 loss=3.7280 elapsed=3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 4: train_loss=3.7560 val_lev=15.2955 lr=0.000250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=15.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5 it20 loss=3.2218 elapsed=2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 5: train_loss=3.2104 val_lev=12.9091 lr=0.000225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=12.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6 it20 loss=2.7979 elapsed=2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 6: train_loss=2.7874 val_lev=12.0682 lr=0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=12.0682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7 it20 loss=2.5941 elapsed=3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 7: train_loss=2.5480 val_lev=10.9773 lr=0.000166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=10.9773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8 it20 loss=2.4562 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 8: train_loss=2.4607 val_lev=11.1364 lr=0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9 it20 loss=2.3614 elapsed=2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 9: train_loss=2.3683 val_lev=10.5227 lr=0.000104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=10.5227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10 it20 loss=2.2584 elapsed=2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 10: train_loss=2.2584 val_lev=11.3636 lr=0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11 it20 loss=2.2435 elapsed=2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 11: train_loss=2.2412 val_lev=9.6591 lr=0.000050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=9.6591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12 it20 loss=2.1435 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 12: train_loss=2.1187 val_lev=8.9318 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=8.9318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13 it20 loss=2.0830 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 13: train_loss=2.0909 val_lev=9.2727 lr=0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14 it20 loss=2.0801 elapsed=2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 14: train_loss=2.0720 val_lev=8.8864 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=8.8864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15 it20 loss=2.0485 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 15: train_loss=2.0528 val_lev=8.7727 lr=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=8.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16 it20 loss=2.0430 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 16: train_loss=2.0360 val_lev=8.7727 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep17 it20 loss=2.0409 elapsed=2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 17: train_loss=2.0380 val_lev=8.7273 lr=0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=8.7273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep18 it20 loss=2.0534 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 18: train_loss=2.0419 val_lev=8.8182 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model_mstcnpp_s0.pth; best val_lev=8.7273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1 it20 loss=5.5497 elapsed=2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 1: train_loss=5.4868 val_lev=18.0227 lr=0.000297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=18.0227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2 it20 loss=4.6859 elapsed=2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 2: train_loss=4.6717 val_lev=17.8409 lr=0.000287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=17.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3 it20 loss=4.3505 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 3: train_loss=4.3258 val_lev=17.3636 lr=0.000271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=17.3636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4 it20 loss=3.7449 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 4: train_loss=3.6927 val_lev=14.6136 lr=0.000250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=14.6136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5 it20 loss=3.1122 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 5: train_loss=3.0992 val_lev=12.6591 lr=0.000225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=12.6591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6 it20 loss=2.7589 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 6: train_loss=2.7028 val_lev=10.9773 lr=0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=10.9773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7 it20 loss=2.5463 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 7: train_loss=2.5338 val_lev=10.7727 lr=0.000166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=10.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8 it20 loss=2.4246 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 8: train_loss=2.3871 val_lev=9.5000 lr=0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=9.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9 it20 loss=2.2632 elapsed=2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 9: train_loss=2.2296 val_lev=9.1818 lr=0.000104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=9.1818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10 it20 loss=2.1442 elapsed=2.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 10: train_loss=2.1311 val_lev=8.7727 lr=0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=8.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11 it20 loss=2.0835 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 11: train_loss=2.0940 val_lev=8.2727 lr=0.000050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=8.2727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12 it20 loss=1.9958 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 12: train_loss=1.9803 val_lev=8.1591 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=8.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13 it20 loss=1.9546 elapsed=2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 13: train_loss=1.9623 val_lev=8.1591 lr=0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14 it20 loss=1.9215 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 14: train_loss=1.9180 val_lev=7.9091 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=7.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15 it20 loss=1.8955 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 15: train_loss=1.8813 val_lev=7.9318 lr=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16 it20 loss=1.8928 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 16: train_loss=1.8652 val_lev=7.9318 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep17 it20 loss=1.8795 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 17: train_loss=1.8733 val_lev=7.9318 lr=0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep18 it20 loss=1.8908 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 18: train_loss=1.8744 val_lev=8.0000 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model_mstcnpp_s1.pth; best val_lev=7.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1 it20 loss=5.5922 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 1: train_loss=5.5171 val_lev=17.8409 lr=0.000297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=17.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2 it20 loss=4.6995 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 2: train_loss=4.6883 val_lev=17.7955 lr=0.000287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=17.7955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3 it20 loss=4.4384 elapsed=2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 3: train_loss=4.4129 val_lev=17.5000 lr=0.000271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=17.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4 it20 loss=3.9758 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 4: train_loss=3.9535 val_lev=15.6136 lr=0.000250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=15.6136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5 it20 loss=3.2630 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 5: train_loss=3.2257 val_lev=12.9545 lr=0.000225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=12.9545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6 it20 loss=2.8166 elapsed=2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 6: train_loss=2.7765 val_lev=11.0909 lr=0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=11.0909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7 it20 loss=2.5760 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 7: train_loss=2.5348 val_lev=10.7500 lr=0.000166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=10.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8 it20 loss=2.4262 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 8: train_loss=2.3824 val_lev=9.6818 lr=0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=9.6818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9 it20 loss=2.2519 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 9: train_loss=2.2687 val_lev=9.0909 lr=0.000104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=9.0909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10 it20 loss=2.1238 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 10: train_loss=2.1091 val_lev=8.6818 lr=0.000075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.6818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11 it20 loss=2.0603 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 11: train_loss=2.0215 val_lev=8.4091 lr=0.000050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.4091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12 it20 loss=1.9854 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 12: train_loss=1.9678 val_lev=8.2727 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.2727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13 it20 loss=1.9321 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 13: train_loss=1.9249 val_lev=8.1364 lr=0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.1364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14 it20 loss=1.9089 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 14: train_loss=1.9317 val_lev=7.7045 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=7.7045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15 it20 loss=1.8738 elapsed=2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 15: train_loss=1.8997 val_lev=7.6591 lr=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=7.6591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16 it20 loss=1.8829 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 16: train_loss=1.8641 val_lev=7.6591 lr=0.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep17 it20 loss=1.8732 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 17: train_loss=1.8596 val_lev=7.6136 lr=0.000013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=7.6136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep18 it20 loss=1.8742 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val decode] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 18: train_loss=1.8584 val_lev=7.3409 lr=0.000029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=7.3409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model_mstcnpp_s2.pth; best val_lev=7.3409\nMS-TCN++ seed scores: [(0, 8.727272727272727), (1, 7.909090909090909), (2, 7.340909090909091)]\n=== MS-TCN++ setup complete; training will run now ===\n"
          ]
        }
      ]
    },
    {
      "id": "a4731997-49c9-4c27-ae67-d15692c9783d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, math, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"=== CE model: improved refined decoder (pool_k=15, classwise radius, tie-breaks, temp=0.9) ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p); X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "def compute_class_median_durations():\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df['Id'].astype(int).tolist()\n",
        "    for sid in ids:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum())\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        med[c] = int(np.clip(np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13, 9, 25))\n",
        "    return med\n",
        "\n",
        "MED_K = compute_class_median_durations()\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int = 15) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    y = F.conv1d(x, w, padding=k//2)\n",
        "    return y.view(-1)\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star: int, w: int = 5) -> float:\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w); b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def decode_video_probs_refined(p_t_c: torch.Tensor, pool_k=15, temp=0.9):\n",
        "    # temperature sharpening then normalize\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    T,C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = MED_K.get(c, 13) if c!=0 else 13\n",
        "        scores[:,c] = p_s[:,c] if c==0 else duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        radius = max(10, MED_K.get(c,13)//2)\n",
        "        s = scores[:,c]\n",
        "        t_star = int(torch.argmax(s).item())\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=5)\n",
        "        t_idx = int(round(t_ref)); t_idx = min(max(t_idx, 0), T-1)\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        peaks.append((c, t_ref, float(scores[t_idx, c].item()), float(local_mean)))\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3]))\n",
        "    return [c for c,_,_,_ in peaks]\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h; h = blk(h); h = h + res\n",
        "        logits = self.head(h)\n",
        "        return logits.transpose(1,2)\n",
        "\n",
        "model = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "state = torch.load('model_ce_tcn_v2.pth', map_location=device)\n",
        "model.load_state_dict(state); model.eval()\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "def eval_val():\n",
        "    tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for sid in val_ids:\n",
        "            X = load_feat(sid, 'train', 1800)\n",
        "            xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "            logits = model(xb)[0]\n",
        "            probs = logits.softmax(dim=-1)\n",
        "            seq = decode_video_probs_refined(probs, pool_k=15, temp=0.9)\n",
        "            tot += levenshtein(seq, id2seq[int(sid)]); cnt += 1\n",
        "    print(f\"  [val improved] {cnt} vids in {(time.time()-t0)/60:.2f}m\", flush=True)\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "val_lev = eval_val()\n",
        "print(f\"Improved refined decoder VAL Levenshtein={val_lev:.4f} (norm ~{val_lev/20:.5f})\", flush=True)\n",
        "\n",
        "print(\"=== TEST inference (CE + improved refined decoder) -> submission.csv ===\", flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "with torch.no_grad():\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat(int(sid), 'test', 1800)\n",
        "        xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "        logits = model(xb)[0]\n",
        "        probs = logits.softmax(dim=-1)\n",
        "        seq = decode_video_probs_refined(probs, pool_k=15, temp=0.9)\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [test ce+improved] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv; head:\\n', sub.head())\n",
        "print('=== CE improved refined decoding complete ===')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CE model: improved refined decoder (pool_k=15, classwise radius, tie-breaks, temp=0.9) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/4230030798.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load('model_ce_tcn_v2.pth', map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val improved] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved refined decoder VAL Levenshtein=4.5455 (norm ~0.22727)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEST inference (CE + improved refined decoder) -> submission.csv ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ce+improved] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ce+improved] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ce+improved] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ce+improved] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ce+improved] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ce+improved] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ce+improved] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ce+improved] 80/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ce+improved] 90/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test ce+improved] 95/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 1...\n1  301  10 1 5 4 6 2 11 14 13 19 15 7 9 20 12 8 18 3 1...\n2  302  1 17 16 12 5 19 13 20 18 11 3 4 6 8 14 15 10 9...\n3  303  13 4 3 10 14 5 19 15 20 17 1 11 16 8 18 7 12 6...\n4  304  8 1 7 12 18 13 9 2 11 3 20 19 15 5 14 6 17 16 ...\n=== CE improved refined decoding complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "a5e19046-a5ff-46f9-93e8-48ef8a5e1435",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math, time, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "print(\"=== Train 3 CE DilatedTCN seeds and ensemble with improved decoder ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available(): torch.backends.cudnn.benchmark = True\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "# Split same as earlier\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "tr_ids = all_ids[val_n:]\n",
        "print(f\"Train videos: {len(tr_ids)}, Val videos: {len(val_ids)}\")\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p); X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "def load_lab(sample_id: int, max_T=1800):\n",
        "    y = np.load(lab_tr_dir/f\"{sample_id}.npy\").astype(np.int64)\n",
        "    return y[:max_T] if y.shape[0] > max_T else y\n",
        "\n",
        "class FrameDataset(Dataset):\n",
        "    def __init__(self, ids, max_T=1800):\n",
        "        self.ids=list(ids); self.max_T=max_T\n",
        "    def __len__(self): return len(self.ids)\n",
        "    def __getitem__(self, idx):\n",
        "        sid = int(self.ids[idx])\n",
        "        X = load_feat(sid, 'train', self.max_T)\n",
        "        y = load_lab(sid, self.max_T)\n",
        "        T = min(len(X), len(y))\n",
        "        return torch.from_numpy(X[:T]), torch.from_numpy(y[:T]), sid\n",
        "\n",
        "def collate(batch):\n",
        "    xs, ys, sids = zip(*batch)\n",
        "    Tm = max(x.shape[0] for x in xs); D = xs[0].shape[1]; B=len(xs)\n",
        "    xb = torch.zeros(B, Tm, D, dtype=torch.float32)\n",
        "    yb = torch.zeros(B, Tm, dtype=torch.long)\n",
        "    mask = torch.zeros(B, Tm, dtype=torch.bool)\n",
        "    for i,(x,y) in enumerate(zip(xs,ys)):\n",
        "        T=len(x); xb[i,:T]=x; yb[i,:T]=y; mask[i,:T]=True\n",
        "    return xb, yb, mask, list(sids)\n",
        "\n",
        "train_loader = DataLoader(FrameDataset(tr_ids, 1800), batch_size=12, shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate)\n",
        "val_loader   = DataLoader(FrameDataset(val_ids, 1800), batch_size=12, shuffle=False, num_workers=2, pin_memory=True, collate_fn=collate)\n",
        "\n",
        "D_in = np.load(next(iter(feat_tr_dir.glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h; h = blk(h); h = h + res\n",
        "        logits = self.head(h)\n",
        "        return logits.transpose(1,2)\n",
        "\n",
        "def ce_loss_ignore_bg(logits_b_t_c, y_b_t, mask_b_t):\n",
        "    B,T,C = logits_b_t_c.shape\n",
        "    logits = logits_b_t_c.reshape(B*T, C)\n",
        "    targets = y_b_t.reshape(B*T)\n",
        "    valid_fg = (mask_b_t.reshape(B*T)) & (targets > 0)\n",
        "    if valid_fg.sum() == 0: return logits.new_zeros([])\n",
        "    return F.cross_entropy(logits[valid_fg], targets[valid_fg], reduction='mean')\n",
        "\n",
        "# Improved decoder (pool_k=15, classwise radius, temp=0.9, tie-breaks)\n",
        "train_df_local = train_df\n",
        "def compute_class_median_durations():\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df_local['Id'].astype(int).tolist()\n",
        "    for sid in ids:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        med[c] = int(np.clip(np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13, 9, 25))\n",
        "    return med\n",
        "MED_K = compute_class_median_durations()\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int = 15) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    y = F.conv1d(x, w, padding=k//2)\n",
        "    return y.view(-1)\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star: int, w: int = 5) -> float:\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w); b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def decode_video_probs_refined(p_t_c: torch.Tensor, pool_k=15, temp=0.9):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    T,C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = MED_K.get(c, 13) if c!=0 else 13\n",
        "        scores[:,c] = p_s[:,c] if c==0 else duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        radius = max(10, MED_K.get(c,13)//2)\n",
        "        s = scores[:,c]\n",
        "        t_star = int(torch.argmax(s).item())\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=5)\n",
        "        t_idx = int(round(t_ref)); t_idx = min(max(t_idx, 0), T-1)\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        peaks.append((c, t_ref, float(scores[t_idx, c].item()), float(local_mean)))\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3]))\n",
        "    return [c for c,_,_,_ in peaks]\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "def eval_val(model):\n",
        "    model.eval(); tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, mask, sids in val_loader:\n",
        "            xb = xb.to(device); mask=mask.to(device)\n",
        "            logits = model(xb)  # (B,T,C)\n",
        "            probs = logits.softmax(dim=-1)\n",
        "            for b, sid in enumerate(sids):\n",
        "                T = int(mask[b].sum().item())\n",
        "                seq = decode_video_probs_refined(probs[b,:T,:], pool_k=15, temp=0.9)\n",
        "                tot += levenshtein(seq, id2seq[int(sid)]); cnt += 1\n",
        "    print(f\"  [val CE] {cnt} vids in {(time.time()-t0)/60:.2f}m\", flush=True)\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "def train_ce_seed(seed=0, epochs=20, patience=3, ch=96, layers=10):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "    model = DilatedTCN(d_in=D_in, channels=ch, layers=layers, num_classes=21, dropout=0.3).to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "    best=math.inf; best_state=None; bad=0\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train(); t0=time.time(); nb=0; tot_loss=0.0\n",
        "        for it,(xb,yb,mask,sids) in enumerate(train_loader):\n",
        "            xb=xb.to(device); yb= yb.to(device); mask=mask.to(device)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(xb)\n",
        "            loss = ce_loss_ignore_bg(logits, yb, mask)\n",
        "            loss.backward(); nn.utils.clip_grad_norm_(model.parameters(), 1.0); opt.step()\n",
        "            tot_loss += float(loss.item()); nb += 1\n",
        "            if (it+1)%20==0: print(f\"ep{ep} it{it+1} loss={tot_loss/nb:.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "        val_lev = eval_val(model)\n",
        "        print(f\"Seed{seed} Epoch {ep}: train_loss={tot_loss/max(nb,1):.4f} val_lev={val_lev:.4f}\", flush=True)\n",
        "        if val_lev < best - 1e-4:\n",
        "            best = val_lev; best_state = {k:v.detach().cpu() for k,v in model.state_dict().items()}; bad=0\n",
        "            print(f\"  New best (seed {seed}) val_lev={best:.4f}\", flush=True)\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience: print(\"Early stopping.\", flush=True); break\n",
        "    if best_state is not None: model.load_state_dict(best_state)\n",
        "    outp = f\"model_ce_tcn_s{seed}.pth\"\n",
        "    torch.save(model.state_dict(), outp)\n",
        "    print(f\"Saved {outp}; best val_lev={best:.4f}\")\n",
        "    return outp, best\n",
        "\n",
        "# Train seeds\n",
        "seeds=[0,1,2]; ckpts=[]; scores=[]\n",
        "for s in seeds:\n",
        "    p, sc = train_ce_seed(seed=s, epochs=20, patience=3, ch=96, layers=10)\n",
        "    ckpts.append(p); scores.append(sc)\n",
        "print(\"CE seed scores:\", list(zip(seeds, scores)))\n",
        "\n",
        "def ensemble_val_and_test_ce(ckpt_paths, weights=None):\n",
        "    models=[]\n",
        "    for p in ckpt_paths:\n",
        "        m = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device)); m.eval(); models.append(m)\n",
        "    if weights is None: weights=[1.0]*len(models)\n",
        "    sw = float(sum(weights)); weights=[w/sw for w in weights]\n",
        "    # VAL\n",
        "    tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, mask, sids in val_loader:\n",
        "            xb=xb.to(device); mask=mask.to(device)\n",
        "            probs_ens=None\n",
        "            for w,m in zip(weights, models):\n",
        "                p = m(xb).softmax(dim=-1)\n",
        "                probs_ens = (w*p) if probs_ens is None else (probs_ens + w*p)\n",
        "            for b, sid in enumerate(sids):\n",
        "                T = int(mask[b].sum().item())\n",
        "                seq = decode_video_probs_refined(probs_ens[b,:T,:], pool_k=15, temp=0.9)\n",
        "                tot += levenshtein(seq, id2seq[int(sid)]); cnt += 1\n",
        "    val_lev = tot/max(cnt,1)\n",
        "    print(f\"CE 3-seed ensemble VAL Levenshtein={val_lev:.4f} (norm ~{val_lev/20:.5f})\", flush=True)\n",
        "    # TEST\n",
        "    test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "    rows=[]; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, sid in enumerate(test_ids, 1):\n",
        "            X = load_feat(int(sid), 'test', 1800)\n",
        "            xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "            probs_ens=None\n",
        "            for w,m in zip(weights, models):\n",
        "                p = m(xb)[0].softmax(dim=-1)\n",
        "                probs_ens = (w*p) if probs_ens is None else (probs_ens + w*p)\n",
        "            seq = decode_video_probs_refined(probs_ens, pool_k=15, temp=0.9)\n",
        "            rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "            if (i%10)==0 or i==len(test_ids):\n",
        "                print(f\"  [test CE ens] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Wrote submission.csv; head:\\n', sub.head())\n",
        "\n",
        "print(\"=== CE seeds training complete; to run ensemble, execute this cell or call ensemble_val_and_test_ce(ckpts) in a new cell ===\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train 3 CE DilatedTCN seeds and ensemble with improved decoder ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train videos: 253, Val videos: 44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1 it20 loss=3.4281 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 1: train_loss=3.3908 val_lev=17.2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=17.2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2 it20 loss=2.8129 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 2: train_loss=2.7979 val_lev=14.0682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=14.0682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3 it20 loss=2.4472 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 3: train_loss=2.4370 val_lev=10.3864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=10.3864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4 it20 loss=2.0752 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 4: train_loss=2.0535 val_lev=9.3864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=9.3864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5 it20 loss=1.8425 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 5: train_loss=1.8369 val_lev=8.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=8.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6 it20 loss=1.6757 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 6: train_loss=1.6922 val_lev=7.8636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=7.8636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7 it20 loss=1.5507 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 7: train_loss=1.5676 val_lev=7.2273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=7.2273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8 it20 loss=1.4680 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 8: train_loss=1.4467 val_lev=6.6136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=6.6136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9 it20 loss=1.3741 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 9: train_loss=1.3875 val_lev=5.9773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=5.9773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10 it20 loss=1.3021 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 10: train_loss=1.3047 val_lev=6.0227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11 it20 loss=1.2392 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 11: train_loss=1.2707 val_lev=6.0682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12 it20 loss=1.1808 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 12: train_loss=1.1604 val_lev=5.5682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=5.5682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13 it20 loss=1.1572 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 13: train_loss=1.1314 val_lev=5.6136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14 it20 loss=1.0956 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 14: train_loss=1.0962 val_lev=5.1818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=5.1818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15 it20 loss=1.0652 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 15: train_loss=1.0386 val_lev=5.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16 it20 loss=1.0082 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 16: train_loss=1.0235 val_lev=5.2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep17 it20 loss=1.0231 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 17: train_loss=1.0077 val_lev=4.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=4.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep18 it20 loss=0.9888 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 18: train_loss=0.9921 val_lev=4.7955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep19 it20 loss=0.9280 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 19: train_loss=0.9234 val_lev=4.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 0) val_lev=4.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep20 it20 loss=0.9072 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed0 Epoch 20: train_loss=0.9340 val_lev=5.0227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model_ce_tcn_s0.pth; best val_lev=4.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1 it20 loss=3.4189 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 1: train_loss=3.3810 val_lev=17.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=17.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2 it20 loss=2.7834 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 2: train_loss=2.7790 val_lev=13.8182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=13.8182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3 it20 loss=2.4219 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 3: train_loss=2.3808 val_lev=10.9545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=10.9545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4 it20 loss=2.0586 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 4: train_loss=2.0177 val_lev=9.3409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=9.3409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5 it20 loss=1.8065 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 5: train_loss=1.8060 val_lev=8.1818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=8.1818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6 it20 loss=1.6391 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 6: train_loss=1.6239 val_lev=7.9545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=7.9545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7 it20 loss=1.5237 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 7: train_loss=1.5237 val_lev=7.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=7.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8 it20 loss=1.4200 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 8: train_loss=1.4148 val_lev=7.1818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9 it20 loss=1.3697 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 9: train_loss=1.3538 val_lev=7.1364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=7.1364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10 it20 loss=1.3158 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 10: train_loss=1.3156 val_lev=7.0455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=7.0455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11 it20 loss=1.2497 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 11: train_loss=1.2390 val_lev=6.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=6.2955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12 it20 loss=1.2047 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 12: train_loss=1.2260 val_lev=6.1136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=6.1136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13 it20 loss=1.1604 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 13: train_loss=1.1566 val_lev=5.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=5.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14 it20 loss=1.1068 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 14: train_loss=1.1232 val_lev=5.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15 it20 loss=1.0754 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 15: train_loss=1.0800 val_lev=5.8409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16 it20 loss=1.0490 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 16: train_loss=1.0498 val_lev=5.4091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=5.4091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep17 it20 loss=0.9897 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 17: train_loss=1.0080 val_lev=5.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=5.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep18 it20 loss=0.9634 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 18: train_loss=0.9550 val_lev=5.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep19 it20 loss=0.9419 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 19: train_loss=0.9488 val_lev=5.0909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=5.0909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep20 it20 loss=0.9321 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed1 Epoch 20: train_loss=0.9333 val_lev=4.6136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 1) val_lev=4.6136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model_ce_tcn_s1.pth; best val_lev=4.6136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep1 it20 loss=3.4203 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 1: train_loss=3.3915 val_lev=17.7045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=17.7045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep2 it20 loss=2.8858 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 2: train_loss=2.8721 val_lev=14.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=14.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep3 it20 loss=2.4782 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 3: train_loss=2.4531 val_lev=11.6591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=11.6591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep4 it20 loss=2.1195 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 4: train_loss=2.1406 val_lev=9.9318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=9.9318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep5 it20 loss=1.8914 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 5: train_loss=1.8653 val_lev=9.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=9.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep6 it20 loss=1.7092 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 6: train_loss=1.7235 val_lev=8.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=8.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep7 it20 loss=1.5989 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 7: train_loss=1.5665 val_lev=7.9773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=7.9773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep8 it20 loss=1.4937 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 8: train_loss=1.4881 val_lev=7.7273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=7.7273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep9 it20 loss=1.4162 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 9: train_loss=1.4135 val_lev=6.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=6.9091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep10 it20 loss=1.3416 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 10: train_loss=1.3444 val_lev=6.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=6.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep11 it20 loss=1.2781 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 11: train_loss=1.2827 val_lev=6.3409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=6.3409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep12 it20 loss=1.2430 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 12: train_loss=1.2172 val_lev=5.9773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=5.9773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep13 it20 loss=1.1911 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 13: train_loss=1.1720 val_lev=6.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep14 it20 loss=1.1639 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 14: train_loss=1.1520 val_lev=5.5227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=5.5227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep15 it20 loss=1.0988 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 15: train_loss=1.0987 val_lev=5.4318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=5.4318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep16 it20 loss=1.0733 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 16: train_loss=1.0704 val_lev=5.1364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=5.1364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep17 it20 loss=1.0300 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 17: train_loss=1.0300 val_lev=5.1591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep18 it20 loss=0.9820 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 18: train_loss=0.9954 val_lev=5.1136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=5.1136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep19 it20 loss=0.9772 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 19: train_loss=0.9703 val_lev=5.2045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep20 it20 loss=0.9313 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val CE] 44 vids in 0.01m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed2 Epoch 20: train_loss=0.9177 val_lev=4.5227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  New best (seed 2) val_lev=4.5227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model_ce_tcn_s2.pth; best val_lev=4.5227\nCE seed scores: [(0, 4.454545454545454), (1, 4.613636363636363), (2, 4.5227272727272725)]\n=== CE seeds training complete; to run ensemble, execute this cell or call ensemble_val_and_test_ce(ckpts) in a new cell ===\n"
          ]
        }
      ]
    },
    {
      "id": "b93e9dba-7a59-436b-ba1c-c6add7a57782",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"=== Ensembling CE 3 seeds with improved decoder and generating submission ===\", flush=True)\n",
        "ckpts = [\"model_ce_tcn_s0.pth\", \"model_ce_tcn_s1.pth\", \"model_ce_tcn_s2.pth\"]\n",
        "from pathlib import Path\n",
        "for p in ckpts:\n",
        "    assert Path(p).exists(), f\"Missing checkpoint {p}\"\n",
        "ensemble_val_and_test_ce(ckpts)\n",
        "print(\"=== CE 3-seed ensemble complete ===\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Ensembling CE 3 seeds with improved decoder and generating submission ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/696874339.py:220: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(p, map_location=device)); m.eval(); models.append(m)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CE 3-seed ensemble VAL Levenshtein=4.3864 (norm ~0.21932)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE ens] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE ens] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE ens] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE ens] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE ens] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE ens] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE ens] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE ens] 80/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE ens] 90/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE ens] 95/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 1...\n1  301  10 12 3 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 1...\n2  302  1 17 16 12 3 5 19 13 20 18 11 4 6 15 8 14 10 9...\n3  303  13 4 12 3 10 14 5 19 15 20 17 1 11 16 8 18 7 6...\n4  304  8 1 7 12 18 13 9 2 11 3 20 19 5 14 6 15 17 16 ...\n=== CE 3-seed ensemble complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "f69207a5-0d0f-4f56-94ce-51c2d69f0ba6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"=== Geometric ensemble: CE (3 seeds) + MS-TCN++ (3 seeds) with refined decoder ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "import random\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p)\n",
        "    X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "def compute_class_median_durations():\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df['Id'].astype(int).tolist()\n",
        "    for sid in ids:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum())\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        med[c] = int(np.clip(np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13, 9, 25))\n",
        "    return med\n",
        "\n",
        "MED_K = compute_class_median_durations()\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int = 15) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    y = F.conv1d(x, w, padding=k//2)\n",
        "    return y.view(-1)\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star: int, w: int = 5) -> float:\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w); b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def decode_video_probs_refined(p_t_c: torch.Tensor, pool_k=15, temp=0.95):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    T,C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = MED_K.get(c, 13) if c!=0 else 13\n",
        "        scores[:,c] = p_s[:,c] if c==0 else duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        radius = max(10, MED_K.get(c,13)//2)\n",
        "        s = scores[:,c]\n",
        "        t_star = int(torch.argmax(s).item())\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=5)\n",
        "        t_idx = int(round(t_ref)); t_idx = min(max(t_idx, 0), T-1)\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        peaks.append((c, t_ref, float(scores[t_idx, c].item()), float(local_mean)))\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3]))\n",
        "    return [c for c,_,_,_ in peaks]\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h; h = blk(h); h = h + res\n",
        "        logits = self.head(h)\n",
        "        return logits.transpose(1,2)\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.3, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, kernel_size=k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, kernel_size=1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class Stage(nn.Module):\n",
        "    def __init__(self, in_ch, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(in_ch, ch, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(ch, dil, drop=drop))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(ch, 21, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            h = blk(h)\n",
        "        return self.head(h)\n",
        "\n",
        "class MSTCNPP(nn.Module):\n",
        "    def __init__(self, d_in, stages=4, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.stages = nn.ModuleList()\n",
        "        self.input_proj = nn.Conv1d(d_in, d_in, kernel_size=1)\n",
        "        self.stages.append(Stage(d_in, ch=ch, layers=layers, drop=drop))\n",
        "        for _ in range(stages-1):\n",
        "            self.stages.append(Stage(21, ch=ch, layers=layers, drop=drop))\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        x = self.input_proj(x)\n",
        "        logits_list = []\n",
        "        prev = self.stages[0](x)\n",
        "        logits_list.append(prev.transpose(1,2))\n",
        "        for s in range(1, len(self.stages)):\n",
        "            probs = prev.softmax(dim=1)\n",
        "            prev = self.stages[s](probs)\n",
        "            logits_list.append(prev.transpose(1,2))\n",
        "        return logits_list\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def levenshtein(a, b):\n",
        "    n, m = len(a), len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp = list(range(m+1))\n",
        "    for i in range(1, n+1):\n",
        "        prev = dp[0]; dp[0] = i; ai = a[i-1]\n",
        "        for j in range(1, m+1):\n",
        "            tmp = dp[j]\n",
        "            dp[j] = min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1))\n",
        "            prev = tmp\n",
        "    return dp[m]\n",
        "\n",
        "def load_models():\n",
        "    ce_paths = [\"model_ce_tcn_s0.pth\", \"model_ce_tcn_s1.pth\", \"model_ce_tcn_s2.pth\"]\n",
        "    ms_paths = [\"model_mstcnpp_s0.pth\", \"model_mstcnpp_s1.pth\", \"model_mstcnpp_s2.pth\"]\n",
        "    for p in ce_paths + ms_paths:\n",
        "        assert Path(p).exists(), f\"Missing checkpoint {p}\"\n",
        "    ce_models = []\n",
        "    for p in ce_paths:\n",
        "        m = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ce_models.append(m)\n",
        "    ms_models = []\n",
        "    for p in ms_paths:\n",
        "        m = MSTCNPP(d_in=D_in, stages=4, ch=128, layers=10, drop=0.3).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ms_models.append(m)\n",
        "    return ce_models, ms_models\n",
        "\n",
        "def geo_mean_ensemble_probs(xb, ce_models, ms_models, w_ce=0.7, w_ms=0.3):\n",
        "    # compute geometric mean across models and families\n",
        "    # probs_final \u221d (prod_ce p_ce)^(w_ce/len_ce) * (prod_ms p_ms)^(w_ms/len_ms)\n",
        "    with torch.no_grad():\n",
        "        ce_log = None\n",
        "        for m in ce_models:\n",
        "            p = m(xb)[0].softmax(dim=-1)\n",
        "            ce_log = torch.log(p + 1e-8) if ce_log is None else ce_log + torch.log(p + 1e-8)\n",
        "        ce_log = ce_log / max(len(ce_models),1)\n",
        "        ms_log = None\n",
        "        for m in ms_models:\n",
        "            p = m(xb)[-1][0].softmax(dim=-1)\n",
        "            ms_log = torch.log(p + 1e-8) if ms_log is None else ms_log + torch.log(p + 1e-8)\n",
        "        ms_log = ms_log / max(len(ms_models),1)\n",
        "        log_comb = w_ce*ce_log + w_ms*ms_log\n",
        "        probs = torch.exp(log_comb); probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        return probs\n",
        "\n",
        "ce_models, ms_models = load_models()\n",
        "\n",
        "def eval_val_geo():\n",
        "    tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for sid in val_ids:\n",
        "            X = load_feat(sid, 'train', 1800)\n",
        "            xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "            probs = geo_mean_ensemble_probs(xb, ce_models, ms_models, w_ce=0.7, w_ms=0.3)\n",
        "            seq = decode_video_probs_refined(probs, pool_k=15, temp=0.95)\n",
        "            tgt = id2seq[int(sid)]\n",
        "            tot += levenshtein(seq, tgt); cnt += 1\n",
        "            if (cnt%10)==0 or cnt==len(val_ids):\n",
        "                print(f\"  [val geo] {cnt}/{len(val_ids)}\", flush=True)\n",
        "    return tot/max(cnt,1)\n",
        "\n",
        "val_lev = eval_val_geo()\n",
        "print(f\"Geo-ensemble (CE^0.7 * MS^0.3) VAL Levenshtein={val_lev:.4f} (norm ~{val_lev/20:.5f})\")\n",
        "\n",
        "print(\"=== TEST inference for CE+MS geometric ensemble ===\", flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "with torch.no_grad():\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat(int(sid), 'test', 1800)\n",
        "        xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "        probs = geo_mean_ensemble_probs(xb, ce_models, ms_models, w_ce=0.7, w_ms=0.3)\n",
        "        seq = decode_video_probs_refined(probs, pool_k=15, temp=0.95)\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [test geo ens] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv; head:\\n', sub.head())\n",
        "print('=== Geometric ensemble complete ===')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Geometric ensemble: CE (3 seeds) + MS-TCN++ (3 seeds) with refined decoder ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/769283171.py:185: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ce_models.append(m)\n/tmp/ipykernel_183/769283171.py:189: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ms_models.append(m)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val geo] 10/44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val geo] 20/44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val geo] 30/44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val geo] 40/44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val geo] 44/44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geo-ensemble (CE^0.7 * MS^0.3) VAL Levenshtein=4.3182 (norm ~0.21591)\n=== TEST inference for CE+MS geometric ensemble ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test geo ens] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test geo ens] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test geo ens] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test geo ens] 40/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test geo ens] 50/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test geo ens] 60/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test geo ens] 70/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test geo ens] 80/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test geo ens] 90/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test geo ens] 95/95 elapsed=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv; head:\n     Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 1...\n1  301  10 12 3 1 5 4 20 6 2 11 15 13 19 9 7 8 18 14 1...\n2  302  1 17 16 12 3 5 19 13 20 18 11 4 6 15 8 14 10 9...\n3  303  13 4 12 3 10 5 19 15 20 17 1 11 16 8 18 7 6 2 ...\n4  304  8 1 7 12 18 13 9 2 11 3 20 19 5 14 6 15 17 16 ...\n=== Geometric ensemble complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "1f0affdd-cd89-422e-9dfc-690e17449402",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"=== V2 sweep: Geometric ensemble variants (pruned MS seeds, CE-biased weights, small decoder grid) ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "import random\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p)\n",
        "    X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "def compute_class_median_durations():\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df['Id'].astype(int).tolist()\n",
        "    for sid in ids:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum())\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        med[c] = int(np.clip(np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13, 9, 25))\n",
        "    return med\n",
        "\n",
        "MED_K = compute_class_median_durations()\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    y = F.conv1d(x, w, padding=k//2)\n",
        "    return y.view(-1)\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star: int, w: int = 5) -> float:\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w); b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def decode_video_probs_refined(p_t_c: torch.Tensor, pool_k=15, temp=0.95):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    T,C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = MED_K.get(c, 13) if c!=0 else 13\n",
        "        scores[:,c] = p_s[:,c] if c==0 else duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        radius = max(10, MED_K.get(c,13)//2)\n",
        "        s = scores[:,c]\n",
        "        t_star = int(torch.argmax(s).item())\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=5)\n",
        "        t_idx = int(round(t_ref)); t_idx = min(max(t_idx, 0), T-1)\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        peaks.append((c, t_ref, float(scores[t_idx, c].item()), float(local_mean)))\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3]))\n",
        "    return [c for c,_,_,_ in peaks]\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h; h = blk(h); h = h + res\n",
        "        logits = self.head(h)\n",
        "        return logits.transpose(1,2)\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.3, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, kernel_size=k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, kernel_size=1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class Stage(nn.Module):\n",
        "    def __init__(self, in_ch, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(in_ch, ch, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(ch, dil, drop=drop))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(ch, 21, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            h = blk(h)\n",
        "        return self.head(h)\n",
        "\n",
        "class MSTCNPP(nn.Module):\n",
        "    def __init__(self, d_in, stages=4, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.stages = nn.ModuleList()\n",
        "        self.input_proj = nn.Conv1d(d_in, d_in, kernel_size=1)\n",
        "        self.stages.append(Stage(d_in, ch=ch, layers=layers, drop=drop))\n",
        "        for _ in range(stages-1):\n",
        "            self.stages.append(Stage(21, ch=ch, layers=layers, drop=drop))\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        x = self.input_proj(x)\n",
        "        logits_list = []\n",
        "        prev = self.stages[0](x)\n",
        "        logits_list.append(prev.transpose(1,2))\n",
        "        for s in range(1, len(self.stages)):\n",
        "            probs = prev.softmax(dim=1)\n",
        "            prev = self.stages[s](probs)\n",
        "            logits_list.append(prev.transpose(1,2))\n",
        "        return logits_list\n",
        "\n",
        "def levenshtein(a, b):\n",
        "    n, m = len(a), len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp = list(range(m+1))\n",
        "    for i in range(1, n+1):\n",
        "        prev = dp[0]; dp[0] = i; ai = a[i-1]\n",
        "        for j in range(1, m+1):\n",
        "            tmp = dp[j]\n",
        "            dp[j] = min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1))\n",
        "            prev = tmp\n",
        "    return dp[m]\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def load_models(ce_ckpts, ms_ckpts):\n",
        "    ce_models = []\n",
        "    for p in ce_ckpts:\n",
        "        m = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ce_models.append(m)\n",
        "    ms_models = []\n",
        "    for p in ms_ckpts:\n",
        "        m = MSTCNPP(d_in=D_in, stages=4, ch=128, layers=10, drop=0.3).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ms_models.append(m)\n",
        "    return ce_models, ms_models\n",
        "\n",
        "def geo_mean_probs(xb, ce_models, ms_models, w_ce=0.8, w_ms=0.2):\n",
        "    with torch.no_grad():\n",
        "        ce_log=None\n",
        "        for m in ce_models:\n",
        "            p = m(xb)[0].softmax(dim=-1)\n",
        "            ce_log = torch.log(p + 1e-8) if ce_log is None else ce_log + torch.log(p + 1e-8)\n",
        "        ce_log = ce_log / max(len(ce_models),1)\n",
        "        ms_log=None\n",
        "        for m in ms_models:\n",
        "            p = m(xb)[-1][0].softmax(dim=-1)\n",
        "            ms_log = torch.log(p + 1e-8) if ms_log is None else ms_log + torch.log(p + 1e-8)\n",
        "        ms_log = ms_log / max(len(ms_models),1) if len(ms_models)>0 else 0.0\n",
        "        if len(ms_models)==0:\n",
        "            log_comb = ce_log\n",
        "        else:\n",
        "            log_comb = w_ce*ce_log + w_ms*ms_log\n",
        "        probs = torch.exp(log_comb); probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        return probs\n",
        "\n",
        "# Configs per expert advice\n",
        "ce_ckpts = [\"model_ce_tcn_s0.pth\", \"model_ce_tcn_s1.pth\", \"model_ce_tcn_s2.pth\"]\n",
        "ms_all = {\n",
        "    's2': \"model_mstcnpp_s2.pth\",\n",
        "    's1': \"model_mstcnpp_s1.pth\",\n",
        "    's0': \"model_mstcnpp_s0.pth\",\n",
        "}\n",
        "ms_sets = [ ['s2'], ['s2','s1'] ]\n",
        "weights = [ (0.8,0.2), (0.9,0.1) ]\n",
        "pool_ks = [13,15]\n",
        "temps = [0.90, 0.95]\n",
        "\n",
        "best = (1e9, None)\n",
        "results = []\n",
        "\n",
        "for ms_set in ms_sets:\n",
        "    ms_ckpts = [ms_all[k] for k in ms_set]\n",
        "    for w_ce, w_ms in weights:\n",
        "        # load once per weight-set to avoid reloading in pool/temp loop\n",
        "        ce_models, ms_models = load_models(ce_ckpts, ms_ckpts)\n",
        "        for pool_k in pool_ks:\n",
        "            for temp in temps:\n",
        "                t0=time.time()\n",
        "                tot=0; cnt=0\n",
        "                with torch.no_grad():\n",
        "                    for sid in val_ids:\n",
        "                        X = load_feat(sid, 'train', 1800)\n",
        "                        xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "                        probs = geo_mean_probs(xb, ce_models, ms_models, w_ce=w_ce, w_ms=w_ms)\n",
        "                        seq = decode_video_probs_refined(probs, pool_k=pool_k, temp=temp)\n",
        "                        tgt = id2seq[int(sid)]\n",
        "                        tot += levenshtein(seq, tgt); cnt += 1\n",
        "                val_lev = tot/max(cnt,1)\n",
        "                cfg = dict(ms_set=ms_set, w_ce=w_ce, w_ms=w_ms, pool_k=pool_k, temp=temp)\n",
        "                results.append((val_lev, cfg))\n",
        "                print(f\"  [val V2] lev={val_lev:.4f} cfg={cfg} elapsed={(time.time()-t0):.1f}s\", flush=True)\n",
        "                if val_lev < best[0]:\n",
        "                    best = (val_lev, cfg)\n",
        "\n",
        "results.sort(key=lambda x: x[0])\n",
        "print(\"=== Top 5 V2 configs ===\")\n",
        "for r in results[:5]:\n",
        "    print(r)\n",
        "print(\"BEST:\", best)\n",
        "\n",
        "# Build TEST submission using best config\n",
        "best_val, best_cfg = best\n",
        "print(f\"=== TEST inference with BEST V2 cfg: {best_cfg} (val_lev={best_val:.4f}) ===\", flush=True)\n",
        "ms_ckpts = [ms_all[k] for k in best_cfg['ms_set']]\n",
        "ce_models, ms_models = load_models(ce_ckpts, ms_ckpts)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "with torch.no_grad():\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat(int(sid), 'test', 1800)\n",
        "        xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "        probs = geo_mean_probs(xb, ce_models, ms_models, w_ce=best_cfg['w_ce'], w_ms=best_cfg['w_ms'])\n",
        "        seq = decode_video_probs_refined(probs, pool_k=best_cfg['pool_k'], temp=best_cfg['temp'])\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [test V2] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "# Format assertions\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), \"Submission row format invalid\"\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv with BEST V2 cfg; head:\\n', sub.head())\n",
        "print('=== V2 sweep complete ===')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== V2 sweep: Geometric ensemble variants (pruned MS seeds, CE-biased weights, small decoder grid) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/237523318.py:181: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ce_models.append(m)\n/tmp/ipykernel_183/237523318.py:185: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ms_models.append(m)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.3636 cfg={'ms_set': ['s2'], 'w_ce': 0.8, 'w_ms': 0.2, 'pool_k': 13, 'temp': 0.9} elapsed=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.2500 cfg={'ms_set': ['s2'], 'w_ce': 0.8, 'w_ms': 0.2, 'pool_k': 13, 'temp': 0.95} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.2955 cfg={'ms_set': ['s2'], 'w_ce': 0.8, 'w_ms': 0.2, 'pool_k': 15, 'temp': 0.9} elapsed=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.2273 cfg={'ms_set': ['s2'], 'w_ce': 0.8, 'w_ms': 0.2, 'pool_k': 15, 'temp': 0.95} elapsed=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.1364 cfg={'ms_set': ['s2'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 13, 'temp': 0.9} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.1818 cfg={'ms_set': ['s2'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 13, 'temp': 0.95} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.1364 cfg={'ms_set': ['s2'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 15, 'temp': 0.9} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.1818 cfg={'ms_set': ['s2'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 15, 'temp': 0.95} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.2273 cfg={'ms_set': ['s2', 's1'], 'w_ce': 0.8, 'w_ms': 0.2, 'pool_k': 13, 'temp': 0.9} elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.2045 cfg={'ms_set': ['s2', 's1'], 'w_ce': 0.8, 'w_ms': 0.2, 'pool_k': 13, 'temp': 0.95} elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.2273 cfg={'ms_set': ['s2', 's1'], 'w_ce': 0.8, 'w_ms': 0.2, 'pool_k': 15, 'temp': 0.9} elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.2045 cfg={'ms_set': ['s2', 's1'], 'w_ce': 0.8, 'w_ms': 0.2, 'pool_k': 15, 'temp': 0.95} elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.1364 cfg={'ms_set': ['s2', 's1'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 13, 'temp': 0.9} elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.1364 cfg={'ms_set': ['s2', 's1'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 13, 'temp': 0.95} elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.1364 cfg={'ms_set': ['s2', 's1'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 15, 'temp': 0.9} elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [val V2] lev=4.1591 cfg={'ms_set': ['s2', 's1'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 15, 'temp': 0.95} elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Top 5 V2 configs ===\n(4.136363636363637, {'ms_set': ['s2'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 13, 'temp': 0.9})\n(4.136363636363637, {'ms_set': ['s2'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 15, 'temp': 0.9})\n(4.136363636363637, {'ms_set': ['s2', 's1'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 13, 'temp': 0.9})\n(4.136363636363637, {'ms_set': ['s2', 's1'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 13, 'temp': 0.95})\n(4.136363636363637, {'ms_set': ['s2', 's1'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 15, 'temp': 0.9})\nBEST: (4.136363636363637, {'ms_set': ['s2'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 13, 'temp': 0.9})\n=== TEST inference with BEST V2 cfg: {'ms_set': ['s2'], 'w_ce': 0.9, 'w_ms': 0.1, 'pool_k': 13, 'temp': 0.9} (val_lev=4.1364) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V2] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V2] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V2] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V2] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V2] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V2] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V2] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V2] 80/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V2] 90/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V2] 95/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv with BEST V2 cfg; head:\n     Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 1...\n1  301  10 12 3 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 1...\n2  302  1 17 16 12 3 5 7 19 13 20 18 11 4 6 15 8 14 10...\n3  303  13 4 12 3 10 5 19 15 20 17 1 11 16 8 18 7 6 2 ...\n4  304  8 1 7 12 18 13 9 2 11 3 20 19 5 14 6 15 17 16 ...\n=== V2 sweep complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "a8f0ac51-7671-4531-9de4-8d480a4d3d17",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"=== CE-only 3-seed ensemble with simple TTA (frame shifts -1/0/+1) and refined decoder ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "import random\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p)\n",
        "    X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "def compute_class_median_durations():\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df['Id'].astype(int).tolist()\n",
        "    for sid in ids:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum())\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        med[c] = int(np.clip(np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13, 9, 25))\n",
        "    return med\n",
        "\n",
        "MED_K = compute_class_median_durations()\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h; h = blk(h); h = h + res\n",
        "        logits = self.head(h)\n",
        "        return logits.transpose(1,2)\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int = 15) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    y = F.conv1d(x, w, padding=k//2)\n",
        "    return y.view(-1)\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star: int, w: int = 5) -> float:\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w); b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def decode_video_probs_refined(p_t_c: torch.Tensor, pool_k=15, temp=0.9):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    T,C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = MED_K.get(c, 13) if c!=0 else 13\n",
        "        scores[:,c] = p_s[:,c] if c==0 else duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        radius = max(10, MED_K.get(c,13)//2)\n",
        "        s = scores[:,c]\n",
        "        t_star = int(torch.argmax(s).item())\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=5)\n",
        "        t_idx = int(round(t_ref)); t_idx = min(max(t_idx, 0), T-1)\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        peaks.append((c, t_ref, float(scores[t_idx, c].item()), float(local_mean)))\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3]))\n",
        "    return [c for c,_,_,_ in peaks]\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def load_ce_models(paths):\n",
        "    models=[]\n",
        "    for p in paths:\n",
        "        m = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device)); m.eval(); models.append(m)\n",
        "    return models\n",
        "\n",
        "def tta_shift_probs(p_t_c: torch.Tensor, shift: int) -> torch.Tensor:\n",
        "    # p_t_c: (T,C), shift in {-1,0,+1}; pad edge by repeating border\n",
        "    if shift == 0:\n",
        "        return p_t_c\n",
        "    T, C = p_t_c.shape\n",
        "    if shift > 0:\n",
        "        pad = p_t_c[:shift, :]\n",
        "        return torch.cat([pad, p_t_c[:-shift, :]], dim=0)\n",
        "    else:\n",
        "        s = -shift\n",
        "        pad = p_t_c[-s:, :]\n",
        "        return torch.cat([p_t_c[s:, :], pad], dim=0)\n",
        "\n",
        "def ensemble_probs_with_tta(xb, models, shifts=(-1,0,1)) -> torch.Tensor:\n",
        "    with torch.no_grad():\n",
        "        probs_sum = None\n",
        "        for m in models:\n",
        "            p = m(xb)[0].softmax(dim=-1)  # (T,C)\n",
        "            # TTA average over shifts\n",
        "            p_tta = None\n",
        "            for sh in shifts:\n",
        "                ps = tta_shift_probs(p, sh)\n",
        "                p_tta = ps if p_tta is None else (p_tta + ps)\n",
        "            p_tta = p_tta / float(len(shifts))\n",
        "            probs_sum = p_tta if probs_sum is None else (probs_sum + p_tta)\n",
        "        probs = probs_sum / float(len(models))\n",
        "        probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        return probs\n",
        "\n",
        "ce_ckpts = [\"model_ce_tcn_s0.pth\", \"model_ce_tcn_s1.pth\", \"model_ce_tcn_s2.pth\"]\n",
        "for p in ce_ckpts: assert Path(p).exists(), f\"Missing {p}\"\n",
        "ce_models = load_ce_models(ce_ckpts)\n",
        "\n",
        "def eval_val_ce_tta(pool_k=15, temp=0.9):\n",
        "    tot=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for sid in val_ids:\n",
        "            X = load_feat(int(sid), 'train', 1800)\n",
        "            xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "            probs = ensemble_probs_with_tta(xb, ce_models, shifts=(-1,0,1))\n",
        "            seq = decode_video_probs_refined(probs, pool_k=pool_k, temp=temp)\n",
        "            tgt = id2seq[int(sid)]\n",
        "            tot += levenshtein(seq, tgt); cnt += 1\n",
        "    val_lev = tot/max(cnt,1)\n",
        "    print(f\"CE-only 3-seed + TTA VAL Levenshtein={val_lev:.4f} (norm ~{val_lev/20:.5f})\", flush=True)\n",
        "    return val_lev\n",
        "\n",
        "val_lev = eval_val_ce_tta(pool_k=15, temp=0.9)\n",
        "\n",
        "print(\"=== TEST inference: CE-only 3-seed + TTA (pool_k=15, temp=0.9) -> submission.csv ===\", flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "with torch.no_grad():\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat(int(sid), 'test', 1800)\n",
        "        xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "        probs = ensemble_probs_with_tta(xb, ce_models, shifts=(-1,0,1))\n",
        "        seq = decode_video_probs_refined(probs, pool_k=15, temp=0.9)\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [test CE TTA] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "# Format assertions\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), \"Submission row format invalid\"\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv (CE-only + TTA); head:\\n', sub.head())\n",
        "print('=== CE-only TTA complete ===')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CE-only 3-seed ensemble with simple TTA (frame shifts -1/0/+1) and refined decoder ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/537395712.py:130: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(p, map_location=device)); m.eval(); models.append(m)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CE-only 3-seed + TTA VAL Levenshtein=4.3636 (norm ~0.21818)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEST inference: CE-only 3-seed + TTA (pool_k=15, temp=0.9) -> submission.csv ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE TTA] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE TTA] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE TTA] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE TTA] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE TTA] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE TTA] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE TTA] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE TTA] 80/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE TTA] 90/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test CE TTA] 95/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv (CE-only + TTA); head:\n     Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 1...\n1  301  10 12 3 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 1...\n2  302  1 17 16 12 3 5 19 13 20 18 11 4 6 15 8 14 10 9...\n3  303  13 4 12 3 10 14 5 19 15 20 17 1 11 16 8 18 7 6...\n4  304  8 1 7 12 18 13 9 2 11 3 20 19 5 14 6 15 17 16 ...\n=== CE-only TTA complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "4302dfba-00f5-42e8-9567-89d99efc5869",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"=== V3: CE(3) \u00d7 MS++(s2) geometric ensemble + time-warp TTA + global temperature (grid on VAL) ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "import random\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p); X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "def compute_class_median_durations():\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df['Id'].astype(int).tolist()\n",
        "    for sid in ids:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum())\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        med[c] = int(np.clip(np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13, 9, 25))\n",
        "    return med\n",
        "\n",
        "MED_K = compute_class_median_durations()\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h; h = blk(h); h = h + res\n",
        "        logits = self.head(h)\n",
        "        return logits.transpose(1,2)\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.3, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, kernel_size=k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, kernel_size=1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class Stage(nn.Module):\n",
        "    def __init__(self, in_ch, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(in_ch, ch, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(ch, dil, drop=drop))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(ch, 21, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            h = blk(h)\n",
        "        return self.head(h)\n",
        "\n",
        "class MSTCNPP(nn.Module):\n",
        "    def __init__(self, d_in, stages=4, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.stages = nn.ModuleList()\n",
        "        self.input_proj = nn.Conv1d(d_in, d_in, kernel_size=1)\n",
        "        self.stages.append(Stage(d_in, ch=ch, layers=layers, drop=drop))\n",
        "        for _ in range(stages-1):\n",
        "            self.stages.append(Stage(21, ch=ch, layers=layers, drop=drop))\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        x = self.input_proj(x)\n",
        "        logits_list = []\n",
        "        prev = self.stages[0](x)\n",
        "        logits_list.append(prev.transpose(1,2))\n",
        "        for s in range(1, len(self.stages)):\n",
        "            probs = prev.softmax(dim=1)\n",
        "            prev = self.stages[s](probs)\n",
        "            logits_list.append(prev.transpose(1,2))\n",
        "        return logits_list\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    y = F.conv1d(x, w, padding=k//2)\n",
        "    return y.view(-1)\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star: int, w: int = 5) -> float:\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w); b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def decode_video_probs_refined(p_t_c: torch.Tensor, pool_k=13, temp=1.0):\n",
        "    # global temp scaling then normalize\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    T,C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = MED_K.get(c, 13) if c!=0 else 13\n",
        "        scores[:,c] = p_s[:,c] if c==0 else duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        s = scores[:,c]\n",
        "        t_star = int(torch.argmax(s).item())\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=5)\n",
        "        t_idx = int(round(t_ref)); t_idx = min(max(t_idx, 0), T-1)\n",
        "        peaks.append([c, t_ref, float(scores[t_idx, c].item())])\n",
        "    # collision fix: if two t_ref (rounded) collide, shift the later one by +1 frame\n",
        "    # then re-sort by time and tie-break by integral score\n",
        "    peaks.sort(key=lambda x: x[1])\n",
        "    seen_times = set()\n",
        "    for i in range(len(peaks)):\n",
        "        t_i = int(round(peaks[i][1]))\n",
        "        while t_i in seen_times:\n",
        "            t_i += 1\n",
        "        seen_times.add(t_i)\n",
        "        # clamp to [0, T-1]\n",
        "        t_i = min(max(t_i, 0), T-1)\n",
        "        peaks[i][1] = float(t_i)\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2]))\n",
        "    return [c for c,_,_ in peaks]\n",
        "\n",
        "def load_models():\n",
        "    ce_paths = [\"model_ce_tcn_s0.pth\", \"model_ce_tcn_s1.pth\", \"model_ce_tcn_s2.pth\"]\n",
        "    ms_path = \"model_mstcnpp_s2.pth\"\n",
        "    for p in ce_paths + [ms_path]:\n",
        "        assert Path(p).exists(), f\"Missing checkpoint {p}\"\n",
        "    ce_models = []\n",
        "    for p in ce_paths:\n",
        "        m = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ce_models.append(m)\n",
        "    ms_model = MSTCNPP(d_in=D_in, stages=4, ch=128, layers=10, drop=0.3).to(device)\n",
        "    ms_model.load_state_dict(torch.load(ms_path, map_location=device)); ms_model.eval()\n",
        "    return ce_models, ms_model\n",
        "\n",
        "def geo_mean_probs_ce_ms(xb, ce_models, ms_model, w_ce=0.9):\n",
        "    w_ms = 1.0 - w_ce\n",
        "    with torch.no_grad():\n",
        "        ce_log=None\n",
        "        for m in ce_models:\n",
        "            p = m(xb)[0].softmax(dim=-1)\n",
        "            ce_log = torch.log(p + 1e-8) if ce_log is None else ce_log + torch.log(p + 1e-8)\n",
        "        ce_log = ce_log / max(len(ce_models),1)\n",
        "        p_ms = ms_model(xb)[-1][0].softmax(dim=-1)\n",
        "        ms_log = torch.log(p_ms + 1e-8)\n",
        "        log_comb = w_ce*ce_log + w_ms*ms_log\n",
        "        probs = torch.exp(log_comb); probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        return probs\n",
        "\n",
        "def time_warp_probs(p_t_c: torch.Tensor, factor: float) -> torch.Tensor:\n",
        "    # p_t_c: (T,C); resample to int(T*factor) then back to T; linear interp, no corner align\n",
        "    T, C = p_t_c.shape\n",
        "    tgt_len = max(1, int(round(T*factor)))\n",
        "    x = p_t_c.T.unsqueeze(0)  # (1,C,T)\n",
        "    y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False)  # (1,C,tgt)\n",
        "    y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T  # (T,C)\n",
        "    y2 = y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    return y2\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    # average warped versions, always warp from original\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        ps = time_warp_probs(p_t_c, s)\n",
        "        acc = ps if acc is None else (acc + ps)\n",
        "    out = acc / float(len(factors))\n",
        "    out = out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    return out\n",
        "\n",
        "ce_models, ms_model = load_models()\n",
        "\n",
        "temps = [0.85, 0.90, 0.95, 1.00]\n",
        "pool_ks = [13, 15]\n",
        "w_ces = [0.90, 0.95]\n",
        "\n",
        "best = (1e9, None)\n",
        "results = []\n",
        "t0_all = time.time()\n",
        "with torch.no_grad():\n",
        "    for w_ce in w_ces:\n",
        "        for pool_k in pool_ks:\n",
        "            for temp in temps:\n",
        "                tot=0; cnt=0; t0=time.time()\n",
        "                for sid in val_ids:\n",
        "                    X = load_feat(int(sid), 'train', 1800)\n",
        "                    xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "                    probs = geo_mean_probs_ce_ms(xb, ce_models, ms_model, w_ce=w_ce)  # (T,C)\n",
        "                    probs = apply_tta_timewarp(probs, factors=(0.9,1.0,1.1))\n",
        "                    seq = decode_video_probs_refined(probs, pool_k=pool_k, temp=temp)\n",
        "                    tot += levenshtein(seq, id2seq[int(sid)]); cnt += 1\n",
        "                val_lev = tot/max(cnt,1)\n",
        "                cfg = dict(w_ce=w_ce, pool_k=pool_k, temp=temp)\n",
        "                results.append((val_lev, cfg))\n",
        "                print(f\"  [VAL V3] lev={val_lev:.4f} cfg={cfg} elapsed={(time.time()-t0):.1f}s\", flush=True)\n",
        "                if val_lev < best[0]:\n",
        "                    best = (val_lev, cfg)\n",
        "\n",
        "results.sort(key=lambda x: x[0])\n",
        "print(\"=== Top 5 V3 configs (VAL) ===\")\n",
        "for r in results[:5]:\n",
        "    print(r)\n",
        "print(\"BEST V3:\", best, f\"total elapsed={(time.time()-t0_all)/60:.2f}m\")\n",
        "\n",
        "best_val, best_cfg = best\n",
        "print(f\"=== TEST inference V3 (w_ce={best_cfg['w_ce']}, pool_k={best_cfg['pool_k']}, temp={best_cfg['temp']}) with time-warp TTA ===\", flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "with torch.no_grad():\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat(int(sid), 'test', 1800)\n",
        "        xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "        probs = geo_mean_probs_ce_ms(xb, ce_models, ms_model, w_ce=best_cfg['w_ce'])\n",
        "        probs = apply_tta_timewarp(probs, factors=(0.9,1.0,1.1))\n",
        "        seq = decode_video_probs_refined(probs, pool_k=best_cfg['pool_k'], temp=best_cfg['temp'])\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [test V3] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "# Safety checks\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), \"Submission row format invalid\"\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv (V3 TTA+temp); head:\\n', sub.head())\n",
        "print('=== V3 complete ===')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== V3: CE(3) \u00d7 MS++(s2) geometric ensemble + time-warp TTA + global temperature (grid on VAL) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/1219251802.py:193: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ce_models.append(m)\n/tmp/ipykernel_183/1219251802.py:195: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ms_model.load_state_dict(torch.load(ms_path, map_location=device)); ms_model.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.1591 cfg={'w_ce': 0.9, 'pool_k': 13, 'temp': 0.85} elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.1364 cfg={'w_ce': 0.9, 'pool_k': 13, 'temp': 0.9} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.1818 cfg={'w_ce': 0.9, 'pool_k': 13, 'temp': 0.95} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.2500 cfg={'w_ce': 0.9, 'pool_k': 13, 'temp': 1.0} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.1364 cfg={'w_ce': 0.9, 'pool_k': 15, 'temp': 0.9} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.1818 cfg={'w_ce': 0.9, 'pool_k': 15, 'temp': 0.95} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.2500 cfg={'w_ce': 0.9, 'pool_k': 15, 'temp': 1.0} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.2273 cfg={'w_ce': 0.95, 'pool_k': 13, 'temp': 0.85} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.2273 cfg={'w_ce': 0.95, 'pool_k': 13, 'temp': 0.9} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.2727 cfg={'w_ce': 0.95, 'pool_k': 13, 'temp': 0.95} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.2500 cfg={'w_ce': 0.95, 'pool_k': 13, 'temp': 1.0} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.2273 cfg={'w_ce': 0.95, 'pool_k': 15, 'temp': 0.85} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.2727 cfg={'w_ce': 0.95, 'pool_k': 15, 'temp': 0.9} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.2955 cfg={'w_ce': 0.95, 'pool_k': 15, 'temp': 0.95} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V3] lev=4.2727 cfg={'w_ce': 0.95, 'pool_k': 15, 'temp': 1.0} elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Top 5 V3 configs (VAL) ===\n(4.136363636363637, {'w_ce': 0.9, 'pool_k': 13, 'temp': 0.9})\n(4.136363636363637, {'w_ce': 0.9, 'pool_k': 15, 'temp': 0.9})\n(4.159090909090909, {'w_ce': 0.9, 'pool_k': 13, 'temp': 0.85})\n(4.159090909090909, {'w_ce': 0.9, 'pool_k': 15, 'temp': 0.85})\n(4.181818181818182, {'w_ce': 0.9, 'pool_k': 13, 'temp': 0.95})\nBEST V3: (4.136363636363637, {'w_ce': 0.9, 'pool_k': 13, 'temp': 0.9}) total elapsed=0.30m\n=== TEST inference V3 (w_ce=0.9, pool_k=13, temp=0.9) with time-warp TTA ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V3] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V3] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V3] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V3] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V3] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V3] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V3] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V3] 80/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V3] 90/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V3] 95/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv (V3 TTA+temp); head:\n     Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 1...\n1  301  10 12 3 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 1...\n2  302  1 17 16 12 3 5 7 19 13 20 18 11 4 6 15 8 14 10...\n3  303  13 4 12 3 10 5 19 15 20 17 1 11 16 8 18 7 6 2 ...\n4  304  8 1 7 12 18 13 9 2 11 3 20 19 5 14 6 15 17 16 ...\n=== V3 complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "2c656093-6816-41da-90c7-07b719268b00",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"=== V4: Order-first decoder (expectation + pairwise) on CE(3)\u00d7MS++(s2) with time-warp TTA ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "import random\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p); X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "def compute_class_median_durations():\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df['Id'].astype(int).tolist()\n",
        "    for sid in ids:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum());\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        med[c] = int(np.clip(np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13, 9, 25))\n",
        "    return med\n",
        "\n",
        "MED_K = compute_class_median_durations()\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h; h = blk(h); h = h + res\n",
        "        logits = self.head(h)\n",
        "        return logits.transpose(1,2)\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.3, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, kernel_size=k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, kernel_size=1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class Stage(nn.Module):\n",
        "    def __init__(self, in_ch, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(in_ch, ch, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(ch, dil, drop=drop))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(ch, 21, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            h = blk(h)\n",
        "        return self.head(h)\n",
        "\n",
        "class MSTCNPP(nn.Module):\n",
        "    def __init__(self, d_in, stages=4, ch=128, layers=10, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.stages = nn.ModuleList()\n",
        "        self.input_proj = nn.Conv1d(d_in, d_in, kernel_size=1)\n",
        "        self.stages.append(Stage(d_in, ch=ch, layers=layers, drop=drop))\n",
        "        for _ in range(stages-1):\n",
        "            self.stages.append(Stage(21, ch=ch, layers=layers, drop=drop))\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        x = self.input_proj(x)\n",
        "        logits_list = []\n",
        "        prev = self.stages[0](x)\n",
        "        logits_list.append(prev.transpose(1,2))\n",
        "        for s in range(1, len(self.stages)):\n",
        "            probs = prev.softmax(dim=1)\n",
        "            prev = self.stages[s](probs)\n",
        "            logits_list.append(prev.transpose(1,2))\n",
        "        return logits_list\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int = 13) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    y = F.conv1d(x, w, padding=k//2)\n",
        "    return y.view(-1)\n",
        "\n",
        "def smooth_probs(p_t_c: torch.Tensor, pool_k=13, temp=0.9) -> torch.Tensor:\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    return avg_pool_probs(p_t_c, k=pool_k)\n",
        "\n",
        "def order_decoder_expectation(p_t_c: torch.Tensor, pool_k=13, temp=0.9) -> list:\n",
        "    # Compute expected time per class using duration-integral as weights; sort by expectation\n",
        "    p_s = smooth_probs(p_t_c, pool_k=pool_k, temp=temp)  # (T,C)\n",
        "    T, C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = MED_K.get(c, 13) if c!=0 else 13\n",
        "        scores[:,c] = p_s[:,c] if c==0 else duration_integral_single(p_s[:,c], k=k)\n",
        "    idx = torch.arange(T, device=scores.device, dtype=scores.dtype).unsqueeze(1)  # (T,1)\n",
        "    exp_t = torch.sum(idx * scores, dim=0) / (torch.sum(scores, dim=0) + 1e-8)  # (C,)\n",
        "    # classes 1..20 sorted by expected time\n",
        "    order = torch.argsort(exp_t[1:21]).tolist()\n",
        "    seq = [int(i+1) for i in order]\n",
        "    return seq\n",
        "\n",
        "def order_decoder_pairwise(p_t_c: torch.Tensor, pool_k=13, temp=0.9) -> list:\n",
        "    # Pairwise dominance: score[i] = sum_t sum_j max(p_i - p_j, 0); rank by score ascending in time\n",
        "    p_s = smooth_probs(p_t_c, pool_k=pool_k, temp=temp)  # (T,C)\n",
        "    p = p_s[:,1:21]  # exclude bg -> (T,20)\n",
        "    T, K = p.shape\n",
        "    # compute pairwise advantages\n",
        "    # naive O(T*K*K) is fine: 1800*400 ~ 720k ops per sample\n",
        "    scores = torch.zeros(K, device=p.device, dtype=p.dtype)\n",
        "    for i in range(K):\n",
        "        pi = p[:, i].unsqueeze(1)  # (T,1)\n",
        "        diff = pi - p  # (T,K)\n",
        "        diff[:, i] = 0.0\n",
        "        scores[i] = torch.clamp(diff, min=0).sum()\n",
        "    order = torch.argsort(scores).tolist()  # smaller score ~ earlier in time (less dominates others later)\n",
        "    seq = [int(i+1) for i in order]\n",
        "    return seq\n",
        "\n",
        "def hybrid_order_decoder(p_t_c: torch.Tensor, pool_k=13, temp=0.9) -> list:\n",
        "    seq_e = order_decoder_expectation(p_t_c, pool_k=pool_k, temp=temp)\n",
        "    seq_p = order_decoder_pairwise(p_t_c, pool_k=pool_k, temp=temp)\n",
        "    # Borda-like fusion: assign ranks and sum; lower sum wins\n",
        "    rank_e = {c: r for r, c in enumerate(seq_e)}\n",
        "    rank_p = {c: r for r, c in enumerate(seq_p)}\n",
        "    classes = list(range(1,21))\n",
        "    scores = [(c, rank_e.get(c, 0) + rank_p.get(c, 0)) for c in classes]\n",
        "    scores.sort(key=lambda x: x[1])\n",
        "    return [c for c,_ in scores]\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "# Loader for best ensemble (CE 3 seeds + MS++ s2), with time-warp TTA on probs\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "def load_models():\n",
        "    ce_paths = [\"model_ce_tcn_s0.pth\", \"model_ce_tcn_s1.pth\", \"model_ce_tcn_s2.pth\"]\n",
        "    ms_path = \"model_mstcnpp_s2.pth\"\n",
        "    for p in ce_paths + [ms_path]:\n",
        "        assert Path(p).exists(), f\"Missing checkpoint {p}\"\n",
        "    ce_models = []\n",
        "    for p in ce_paths:\n",
        "        m = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ce_models.append(m)\n",
        "    ms_model = MSTCNPP(d_in=D_in, stages=4, ch=128, layers=10, drop=0.3).to(device)\n",
        "    ms_model.load_state_dict(torch.load(ms_path, map_location=device)); ms_model.eval()\n",
        "    return ce_models, ms_model\n",
        "\n",
        "def geo_mean_probs_ce_ms(xb, ce_models, ms_model, w_ce=0.9):\n",
        "    w_ms = 1.0 - w_ce\n",
        "    with torch.no_grad():\n",
        "        ce_log=None\n",
        "        for m in ce_models:\n",
        "            p = m(xb)[0].softmax(dim=-1)\n",
        "            ce_log = torch.log(p + 1e-8) if ce_log is None else ce_log + torch.log(p + 1e-8)\n",
        "        ce_log = ce_log / max(len(ce_models),1)\n",
        "        p_ms = ms_model(xb)[-1][0].softmax(dim=-1)\n",
        "        ms_log = torch.log(p_ms + 1e-8)\n",
        "        log_comb = w_ce*ce_log + w_ms*ms_log\n",
        "        probs = torch.exp(log_comb); probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        return probs\n",
        "\n",
        "def time_warp_probs(p_t_c: torch.Tensor, factor: float) -> torch.Tensor:\n",
        "    T, C = p_t_c.shape\n",
        "    tgt_len = max(1, int(round(T*factor)))\n",
        "    x = p_t_c.T.unsqueeze(0)\n",
        "    y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False)\n",
        "    y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T\n",
        "    y2 = y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    return y2\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        ps = time_warp_probs(p_t_c, s)\n",
        "        acc = ps if acc is None else (acc + ps)\n",
        "    out = acc / float(len(factors))\n",
        "    out = out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    return out\n",
        "\n",
        "ce_models, ms_model = load_models()\n",
        "\n",
        "def eval_val_order_decoders(pool_k=13, temp=0.9):\n",
        "    totE=totP=totH=0; cnt=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for sid in val_ids:\n",
        "            X = load_feat(int(sid), 'train', 1800)\n",
        "            xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "            probs = geo_mean_probs_ce_ms(xb, ce_models, ms_model, w_ce=0.9)\n",
        "            probs = apply_tta_timewarp(probs, factors=(0.9,1.0,1.1))\n",
        "            seqE = order_decoder_expectation(probs, pool_k=pool_k, temp=temp)\n",
        "            seqP = order_decoder_pairwise(probs, pool_k=pool_k, temp=temp)\n",
        "            seqH = hybrid_order_decoder(probs, pool_k=pool_k, temp=temp)\n",
        "            tgt = id2seq[int(sid)]\n",
        "            def lev(a,b):\n",
        "                n,m=len(a),len(b);\n",
        "                if n==0: return m\n",
        "                if m==0: return n\n",
        "                dp=list(range(m+1))\n",
        "                for i in range(1,n+1):\n",
        "                    prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "                    for j in range(1,m+1):\n",
        "                        tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "                return dp[m]\n",
        "            totE += lev(seqE, tgt); totP += lev(seqP, tgt); totH += lev(seqH, tgt); cnt += 1\n",
        "    print(f\"VAL (pool_k={pool_k}, temp={temp}): Expect={totE/max(cnt,1):.4f} Pair={totP/max(cnt,1):.4f} Hybrid={totH/max(cnt,1):.4f}\", flush=True)\n",
        "    return (totE/max(cnt,1), totP/max(cnt,1), totH/max(cnt,1))\n",
        "\n",
        "# Small grid over pool_k and temp\n",
        "cands = [(13,0.9),(15,0.9)]\n",
        "best = (1e9, None, None)  # (lev, (pool,temp), decoder_name)\n",
        "for pool_k, temp in cands:\n",
        "    e,p,h = eval_val_order_decoders(pool_k=pool_k, temp=temp)\n",
        "    for name,lev in (('expect',e),('pair',p),('hybrid',h)):\n",
        "        if lev < best[0]: best = (lev, (pool_k,temp), name)\n",
        "print(\"BEST order-decoder:\", best, flush=True)\n",
        "\n",
        "# Build TEST submission using best order-decoder\n",
        "best_lev, (pool_k, temp), name = best\n",
        "print(f\"=== TEST inference V4 using {name} (pool_k={pool_k}, temp={temp}) ===\", flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "with torch.no_grad():\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat(int(sid), 'test', 1800)\n",
        "        xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "        probs = geo_mean_probs_ce_ms(xb, ce_models, ms_model, w_ce=0.9)\n",
        "        probs = apply_tta_timewarp(probs, factors=(0.9,1.0,1.1))\n",
        "        if name=='expect':\n",
        "            seq = order_decoder_expectation(probs, pool_k=pool_k, temp=temp)\n",
        "        elif name=='pair':\n",
        "            seq = order_decoder_pairwise(probs, pool_k=pool_k, temp=temp)\n",
        "        else:\n",
        "            seq = hybrid_order_decoder(probs, pool_k=pool_k, temp=temp)\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [test V4 order] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), \"Submission row format invalid\"\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv (V4 order-first); head:\\n', sub.head())\n",
        "print('=== V4 order-first complete ===')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== V4: Order-first decoder (expectation + pairwise) on CE(3)\u00d7MS++(s2) with time-warp TTA ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/2849038863.py:205: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(p, map_location=device)); m.eval(); ce_models.append(m)\n/tmp/ipykernel_183/2849038863.py:207: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ms_model.load_state_dict(torch.load(ms_path, map_location=device)); ms_model.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL (pool_k=13, temp=0.9): Expect=12.1591 Pair=18.0000 Hybrid=16.1818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAL (pool_k=15, temp=0.9): Expect=12.1818 Pair=17.9773 Hybrid=16.2045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEST order-decoder: (12.159090909090908, (13, 0.9), 'expect')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== TEST inference V4 using expect (pool_k=13, temp=0.9) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4 order] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4 order] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4 order] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4 order] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4 order] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4 order] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4 order] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4 order] 80/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4 order] 90/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4 order] 95/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv (V4 order-first); head:\n     Id                                           Sequence\n0  300  9 5 1 7 18 2 8 3 20 12 4 16 13 15 14 11 10 6 1...\n1  301  5 10 4 6 1 12 20 11 3 15 2 19 13 7 14 9 8 18 1...\n2  302  17 16 5 12 19 1 13 20 3 18 11 7 4 6 15 10 2 8 ...\n3  303  13 4 10 15 12 19 5 3 8 11 20 17 18 1 16 14 6 7...\n4  304  8 7 1 13 18 2 12 9 3 11 14 20 19 10 15 5 17 6 ...\n=== V4 order-first complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "4ba38878-c396-44dd-b81d-c27b485176ee",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"=== V4b: CE-only (3 seeds) + time-warp TTA + global temperature grid ===\", flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "feat_tr_dir = Path('features3d_v2')/'train'\n",
        "feat_te_dir = Path('features3d_v2')/'test'\n",
        "lab_tr_dir  = Path('labels3d_v2')/'train'\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "all_ids = train_df['Id'].astype(int).tolist()\n",
        "import random\n",
        "random.seed(42); np.random.seed(42)\n",
        "random.shuffle(all_ids)\n",
        "val_ratio = 0.15\n",
        "val_n = max(30, int(len(all_ids)*val_ratio))\n",
        "val_ids = all_ids[:val_n]\n",
        "\n",
        "def load_feat(sample_id: int, split='train', max_T=1800):\n",
        "    p = (feat_tr_dir if split=='train' else feat_te_dir)/f\"{sample_id}.npz\"\n",
        "    d = np.load(p); X = d['X'].astype(np.float32)\n",
        "    return X[:max_T] if X.shape[0] > max_T else X\n",
        "\n",
        "def compute_class_median_durations():\n",
        "    dur_by_c = {c: [] for c in range(1,21)}\n",
        "    ids = train_df['Id'].astype(int).tolist()\n",
        "    for sid in ids:\n",
        "        y = np.load(lab_tr_dir/f\"{sid}.npy\").astype(np.int16)\n",
        "        for c in range(1,21):\n",
        "            cnt = int((y==c).sum())\n",
        "            if cnt>0: dur_by_c[c].append(cnt)\n",
        "    med = {}\n",
        "    for c in range(1,21):\n",
        "        med[c] = int(np.clip(np.median(dur_by_c[c]) if len(dur_by_c[c])>0 else 13, 9, 25))\n",
        "    return med\n",
        "\n",
        "MED_K = compute_class_median_durations()\n",
        "\n",
        "D_in = np.load(next(iter((feat_tr_dir).glob('*.npz'))))['X'].shape[1]\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=96, layers=10, num_classes=21, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, kernel_size=1)\n",
        "        blocks = []; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(nn.Sequential(\n",
        "                nn.Conv1d(channels, channels, kernel_size=3, padding=dil, dilation=dil),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Conv1d(channels, channels, kernel_size=1),\n",
        "                nn.GroupNorm(num_groups=8, num_channels=channels),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ))\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, kernel_size=1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for blk in self.blocks:\n",
        "            res = h; h = blk(h); h = h + res\n",
        "        logits = self.head(h)\n",
        "        return logits.transpose(1,2)\n",
        "\n",
        "def avg_pool_probs(p_t_c: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t_c.unsqueeze(0).transpose(1,2)\n",
        "    y = F.avg_pool1d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return y.transpose(1,2).squeeze(0)\n",
        "\n",
        "def duration_integral_single(p_t: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    x = p_t.view(1,1,-1)\n",
        "    w = torch.ones(1,1,k, device=p_t.device, dtype=p_t.dtype) / float(k)\n",
        "    y = F.conv1d(x, w, padding=k//2)\n",
        "    return y.view(-1)\n",
        "\n",
        "def refine_com(p: torch.Tensor, t_star: int, w: int = 5) -> float:\n",
        "    T = p.shape[0]\n",
        "    a = max(0, t_star - w); b = min(T-1, t_star + w)\n",
        "    idx = torch.arange(a, b+1, device=p.device, dtype=p.dtype)\n",
        "    seg = p[a:b+1]; s = seg.sum() + 1e-8\n",
        "    return float(((idx * seg).sum() / s).item())\n",
        "\n",
        "def decode_video_probs_refined(p_t_c: torch.Tensor, pool_k=13, temp=0.9):\n",
        "    if temp != 1.0:\n",
        "        p_t_c = (p_t_c ** (1.0/temp)); p_t_c = p_t_c / (p_t_c.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    p_s = avg_pool_probs(p_t_c, k=pool_k)\n",
        "    T,C = p_s.shape\n",
        "    scores = torch.empty_like(p_s)\n",
        "    for c in range(C):\n",
        "        k = MED_K.get(c, 13) if c!=0 else 13\n",
        "        scores[:,c] = p_s[:,c] if c==0 else duration_integral_single(p_s[:,c], k=k)\n",
        "    peaks = []\n",
        "    for c in range(1,21):\n",
        "        radius = max(10, MED_K.get(c,13)//2)\n",
        "        s = scores[:,c]\n",
        "        t_star = int(torch.argmax(s).item())\n",
        "        t_ref = refine_com(p_s[:,c], t_star, w=5)\n",
        "        t_idx = int(round(t_ref)); t_idx = min(max(t_idx, 0), T-1)\n",
        "        local_mean = p_s[max(0,t_idx-radius):min(T,t_idx+radius+1), c].mean().item()\n",
        "        peaks.append((c, t_ref, float(scores[t_idx, c].item()), float(local_mean)))\n",
        "    peaks.sort(key=lambda x: (x[1], -x[2], -x[3]))\n",
        "    return [c for c,_,_,_ in peaks]\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "id2seq = {int(r.Id): [int(x) for x in str(r.Sequence).strip().split()] for _, r in train_df.iterrows()}\n",
        "\n",
        "def load_ce_models(paths):\n",
        "    models=[]\n",
        "    for p in paths:\n",
        "        m = DilatedTCN(d_in=D_in, channels=96, layers=10, num_classes=21, dropout=0.3).to(device)\n",
        "        m.load_state_dict(torch.load(p, map_location=device)); m.eval(); models.append(m)\n",
        "    return models\n",
        "\n",
        "def time_warp_probs(p_t_c: torch.Tensor, factor: float) -> torch.Tensor:\n",
        "    T, C = p_t_c.shape\n",
        "    tgt_len = max(1, int(round(T*factor)))\n",
        "    x = p_t_c.T.unsqueeze(0)\n",
        "    y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False)\n",
        "    y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T\n",
        "    y2 = y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    return y2\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        ps = time_warp_probs(p_t_c, s)\n",
        "        acc = ps if acc is None else (acc + ps)\n",
        "    out = acc / float(len(factors))\n",
        "    out = out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "    return out\n",
        "\n",
        "def ensemble_ce_probs(xb, models) -> torch.Tensor:\n",
        "    with torch.no_grad():\n",
        "        probs_sum=None\n",
        "        for m in models:\n",
        "            p = m(xb)[0].softmax(dim=-1)\n",
        "            probs_sum = p if probs_sum is None else (probs_sum + p)\n",
        "        probs = probs_sum / float(len(models))\n",
        "        probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        return probs\n",
        "\n",
        "ce_ckpts = [\"model_ce_tcn_s0.pth\", \"model_ce_tcn_s1.pth\", \"model_ce_tcn_s2.pth\"]\n",
        "for p in ce_ckpts: assert Path(p).exists(), f\"Missing {p}\"\n",
        "ce_models = load_ce_models(ce_ckpts)\n",
        "\n",
        "temps = [0.85, 0.90, 0.95, 1.00]\n",
        "pool_ks = [13, 15]\n",
        "\n",
        "best=(1e9, None)\n",
        "results=[]\n",
        "with torch.no_grad():\n",
        "    for pool_k in pool_ks:\n",
        "        for temp in temps:\n",
        "            tot=0; cnt=0; t0=time.time()\n",
        "            for sid in val_ids:\n",
        "                X = load_feat(int(sid), 'train', 1800)\n",
        "                xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "                probs = ensemble_ce_probs(xb, ce_models)\n",
        "                probs = apply_tta_timewarp(probs, factors=(0.9,1.0,1.1))\n",
        "                seq = decode_video_probs_refined(probs, pool_k=pool_k, temp=temp)\n",
        "                tot += levenshtein(seq, id2seq[int(sid)]); cnt += 1\n",
        "            val_lev = tot/max(cnt,1)\n",
        "            cfg = dict(pool_k=pool_k, temp=temp)\n",
        "            results.append((val_lev, cfg))\n",
        "            print(f\"  [VAL V4b] lev={val_lev:.4f} cfg={cfg} elapsed={(time.time()-t0):.1f}s\", flush=True)\n",
        "            if val_lev < best[0]: best=(val_lev, cfg)\n",
        "\n",
        "results.sort(key=lambda x: x[0])\n",
        "print(\"=== Top V4b configs ===\")\n",
        "for r in results[:5]:\n",
        "    print(r)\n",
        "print(\"BEST V4b:\", best)\n",
        "\n",
        "best_val, best_cfg = best\n",
        "print(f\"=== TEST inference V4b CE-only with TTA using cfg={best_cfg} ===\", flush=True)\n",
        "test_ids = pd.read_csv('test.csv')['Id'].astype(int).tolist()\n",
        "rows=[]; t0=time.time()\n",
        "with torch.no_grad():\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        X = load_feat(int(sid), 'test', 1800)\n",
        "        xb = torch.from_numpy(X).unsqueeze(0).to(device)\n",
        "        probs = ensemble_ce_probs(xb, ce_models)\n",
        "        probs = apply_tta_timewarp(probs, factors=(0.9,1.0,1.1))\n",
        "        seq = decode_video_probs_refined(probs, pool_k=best_cfg['pool_k'], temp=best_cfg['temp'])\n",
        "        rows.append({'Id': int(sid), 'Sequence': ' '.join(str(x) for x in seq)})\n",
        "        if (i%10)==0 or i==len(test_ids):\n",
        "            print(f\"  [test V4b] {i}/{len(test_ids)} elapsed={(time.time()-t0)/60:.1f}m\", flush=True)\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "assert len(sub)==95\n",
        "assert all(len(s.split())==20 and len(set(s.split()))==20 and all(1<=int(t)<=20 for t in s.split()) for s in sub.Sequence), \"Submission row format invalid\"\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv (V4b CE-only TTA+temp); head:\\n', sub.head())\n",
        "print('=== V4b complete ===')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== V4b: CE-only (3 seeds) + time-warp TTA + global temperature grid ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_183/1855572424.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m.load_state_dict(torch.load(p, map_location=device)); m.eval(); models.append(m)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V4b] lev=4.3182 cfg={'pool_k': 13, 'temp': 0.85} elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V4b] lev=4.3636 cfg={'pool_k': 13, 'temp': 0.9} elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V4b] lev=4.3182 cfg={'pool_k': 13, 'temp': 0.95} elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V4b] lev=4.2955 cfg={'pool_k': 13, 'temp': 1.0} elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V4b] lev=4.3182 cfg={'pool_k': 15, 'temp': 0.85} elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V4b] lev=4.3636 cfg={'pool_k': 15, 'temp': 0.9} elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V4b] lev=4.3409 cfg={'pool_k': 15, 'temp': 0.95} elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VAL V4b] lev=4.3409 cfg={'pool_k': 15, 'temp': 1.0} elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Top V4b configs ===\n(4.295454545454546, {'pool_k': 13, 'temp': 1.0})\n(4.318181818181818, {'pool_k': 13, 'temp': 0.85})\n(4.318181818181818, {'pool_k': 13, 'temp': 0.95})\n(4.318181818181818, {'pool_k': 15, 'temp': 0.85})\n(4.340909090909091, {'pool_k': 15, 'temp': 0.95})\nBEST V4b: (4.295454545454546, {'pool_k': 13, 'temp': 1.0})\n=== TEST inference V4b CE-only with TTA using cfg={'pool_k': 13, 'temp': 1.0} ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4b] 10/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4b] 20/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4b] 30/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4b] 40/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4b] 50/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4b] 60/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4b] 70/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4b] 80/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4b] 90/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [test V4b] 95/95 elapsed=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv (V4b CE-only TTA+temp); head:\n     Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 1...\n1  301  10 12 3 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 1...\n2  302  1 17 16 12 3 5 19 13 20 18 11 4 6 15 8 14 10 9...\n3  303  13 4 12 3 10 14 5 19 15 20 17 1 11 16 8 18 7 6...\n4  304  8 1 7 12 18 13 9 2 11 3 20 19 5 14 6 15 17 16 ...\n=== V4b complete ===\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}