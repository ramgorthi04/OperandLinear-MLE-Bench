{
  "cells": [
    {
      "id": "1bc63d95-f078-4039-8fab-83a99c8c2741",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Medal-push plan and checkpoints\n",
        "\n",
        "Goal: Beat current best OOF mean=4.290 (worst=5.02) and secure a medal.\n",
        "\n",
        "Milestones (request expert review at each):\n",
        "- M0: Environment sanity (GPU check).\n",
        "- M1: Cheap feature add-ons (v3+global motions):\n",
        "  - Add g1[t]=sum(|v[t]|) across joints, g2[t]=EMA(g1).\n",
        "  - Train 1 fold x 1 seed CE baseline on v3+g; compare \u0394OOF vs v3 and v2.\n",
        "  - If \u22650.05 OOF gain, train remaining folds/seeds; else abort.\n",
        "- M2: Model diversity (MS-TCN++):\n",
        "  - Train minimal MS-TCN++ (1 seed per fold) on best features (current v2/v3 or v3+g).\n",
        "  - Ensemble with CE meta-blend using small weight (start w_ms\u2208{0.05,0.1,0.2}).\n",
        "- M3: Decoder refinements:\n",
        "  - Extend local-search with duration-aware penalty and temperature per class (reuse per-class temps from meta-blend).\n",
        "  - Validate via OOF sweep; keep only if \u22650.02 gain.\n",
        "- M4: v4 canonicalized features (root-centering, scale, yaw-align); add hand-face distances and hand speed norms.\n",
        "  - Prototype on 1 fold x 1 seed; proceed only if \u22650.05 gain.\n",
        "- M5: Multi-modality (RGB):\n",
        "  - Extract lightweight per-frame CNN embeddings (e.g., MobileNetV2 at 112-160px).\n",
        "  - Late-fuse probs with skeleton models; start with small weights; validate via OOF.\n",
        "\n",
        "Discipline:\n",
        "- No retraining unless OOF on small pilot justifies.\n",
        "- Reuse cached OOF/test probs in probs_cache/; avoid recompute.\n",
        "- Always log per-fold times and progress; interrupt long runs if stalled.\n",
        "- Keep next.ipynb lean; one change per experiment; track \u0394OOF.\n",
        "\n",
        "Immediate next steps:\n",
        "1) M0: Add a GPU check cell (nvidia-smi).\n",
        "2) Implement v3+global motions feature join (reuse cached v3 and derive g1,g2 on-the-fly for a pilot).\n",
        "3) Train CE on fold0 seed0 only; cache OOF/test probs; quick decoder sweep; compare OOF.\n",
        "4) Request expert review on whether to scale to 3 folds x 2 seeds or pivot to MS-TCN++."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "75ed9534-4d16-439b-9254-38e6e2990ce8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# M0: GPU sanity check\n",
        "import subprocess, time\n",
        "t0 = time.time()\n",
        "print(\"Running nvidia-smi...\", flush=True)\n",
        "subprocess.run(['bash','-lc','nvidia-smi || true'], check=False)\n",
        "try:\n",
        "    import torch\n",
        "    print(\"torch:\", getattr(torch, '__version__', None), \"CUDA build:\", getattr(torch.version, 'cuda', None))\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    print(\"torch not installed or error:\", e)\n",
        "print(f\"Done in {time.time()-t0:.2f}s\", flush=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running nvidia-smi...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 29 15:01:10 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |    1551MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 CUDA build: 12.1\nCUDA available: True\nGPU: NVIDIA A10-24Q\nDone in 0.92s\n"
          ]
        }
      ]
    },
    {
      "id": "639385a0-f78b-42c9-9a99-b287a52d5668",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspect features3d_v3 structure to design g1/g2 augmentation\n",
        "import os, json, numpy as np, glob\n",
        "from pathlib import Path\n",
        "\n",
        "train_dir = Path('features3d_v3/train')\n",
        "files = sorted(train_dir.glob('*.npz'))\n",
        "print('num train files v3:', len(files))\n",
        "sample = np.load(files[0])\n",
        "print('keys:', list(sample.keys()))\n",
        "for k in sample.files:\n",
        "    arr = sample[k]\n",
        "    try:\n",
        "        shape = arr.shape\n",
        "        dtype = arr.dtype\n",
        "        print(f'  {k}: shape={shape}, dtype={dtype}')\n",
        "    except Exception as e:\n",
        "        print('  key error for', k, e)\n",
        "\n",
        "# If a consolidated array exists (e.g., x or feat), show stats\n",
        "for k in ('x','feat','features','data'):\n",
        "    if k in sample.files:\n",
        "        a = sample[k]\n",
        "        print(k, 'C x T:', a.shape if a.ndim==2 else a.shape)\n",
        "        print('mean/std:', float(a.mean()), float(a.std()))\n",
        "\n",
        "# Persist a brief schema summary for reference\n",
        "schema = {k: (sample[k].shape, str(sample[k].dtype)) for k in sample.files}\n",
        "with open('features3d_v3_schema.json','w') as f:\n",
        "    json.dump(schema, f, indent=2)\n",
        "print('Saved schema to features3d_v3_schema.json')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num train files v3: 297\nkeys: ['X']\n  X: shape=(1254, 1095), dtype=float32\nSaved schema to features3d_v3_schema.json\n"
          ]
        }
      ]
    },
    {
      "id": "eeb1302f-f678-495e-a9f2-ea2b9fd664be",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspect probs_cache and calibration to prepare duration-aware decoder pilot (no retraining)\n",
        "import glob, json, os, re\n",
        "from pathlib import Path\n",
        "\n",
        "cache_dir = Path('probs_cache')\n",
        "paths = sorted(glob.glob(str(cache_dir / '*')))[:20]\n",
        "print('probs_cache sample (first 20):')\n",
        "for p in paths:\n",
        "    print(os.path.basename(p))\n",
        "\n",
        "print('\\nCounts by suffix:')\n",
        "from collections import Counter\n",
        "cnt = Counter(Path(p).suffix for p in glob.glob(str(cache_dir / '*')))\n",
        "print(cnt)\n",
        "\n",
        "# Show some representative filenames by pattern\n",
        "samples = sorted([os.path.basename(p) for p in glob.glob(str(cache_dir / '*fold*'))])[:30]\n",
        "print('\\nfiles with fold in name (first 30):')\n",
        "for s in samples:\n",
        "    print(s)\n",
        "\n",
        "# Load per-class meta calibration if present\n",
        "calib_meta_path = Path('calib_all_v2v3_meta.json')\n",
        "if calib_meta_path.exists():\n",
        "    with open(calib_meta_path) as f:\n",
        "        calib = json.load(f)\n",
        "    print('\\nLoaded calib_all_v2v3_meta.json with keys:', list(calib.keys()))\n",
        "    # Print a small snippet of parameters\n",
        "    for k in ('alpha','T2','T3'):\n",
        "        if k in calib:\n",
        "            if isinstance(calib[k], dict):\n",
        "                # show first 5 classes\n",
        "                items = sorted((int(c), v) for c, v in calib[k].items())[:5]\n",
        "                print(k, 'sample:', items)\n",
        "            else:\n",
        "                print(k, calib[k])\n",
        "else:\n",
        "    print('\\ncalib_all_v2v3_meta.json not found')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probs_cache sample (first 20):\n101_ce.npy\n101_ce_new.npy\n101_ce_new_s1.npy\n101_ce_v3.npy\n101_ce_v3_s1.npy\n101_ms.npy\n101_tc.npy\n101_tc_s1.npy\n102_ce.npy\n102_ce_new.npy\n102_ce_new_s1.npy\n102_ce_v3.npy\n102_ce_v3_s1.npy\n102_ms.npy\n102_tc.npy\n102_tc_s1.npy\n103_ce.npy\n103_ce_new.npy\n103_ce_new_s1.npy\n103_ce_v3.npy\n\nCounts by suffix:\nCounter({'.npy': 2376})\n\nfiles with fold in name (first 30):\n\nLoaded calib_all_v2v3_meta.json with keys: ['T2', 'T3', 'A']\nT2 [1.0, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858]\nT3 [1.0, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858, 1.100000023841858]\n"
          ]
        }
      ]
    },
    {
      "id": "d46e5536-5714-4b0b-879b-9ff6de8cd71d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Duration-aware post-process decoder pilot on OOF (fold0) using cached probs and meta calibration\n",
        "import numpy as np, json, os, time\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "t0=time.time()\n",
        "cache = Path('probs_cache')\n",
        "train_v3 = Path('features3d_v3/train')\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "\n",
        "# Load fold splits (list of dicts with keys: fold, train_ids, val_ids)\n",
        "with open('folds_archive_cv.json') as f:\n",
        "    folds_list = json.load(f)\n",
        "fold0 = next(fd for fd in folds_list if int(fd.get('fold', -1)) == 0)\n",
        "fold0_train_ids = set(map(int, fold0['train_ids']))\n",
        "fold0_val_ids = set(map(int, fold0['val_ids']))\n",
        "\n",
        "# Load calibration (per-class temperatures and blend weights)\n",
        "calib_path = Path('calib_all_v2v3_meta.json')\n",
        "assert calib_path.exists(), 'Missing calib_all_v2v3_meta.json'\n",
        "calib = json.loads(calib_path.read_text())\n",
        "T2 = np.array(calib.get('T2'), dtype=np.float32)\n",
        "T3 = np.array(calib.get('T3'), dtype=np.float32)\n",
        "A = np.array(calib.get('A'), dtype=np.float32) if isinstance(calib.get('A', None), list) else None\n",
        "if A is None:\n",
        "    # fallback alpha if not per-class provided\n",
        "    A = np.full_like(T2, 0.7, dtype=np.float32)\n",
        "\n",
        "def temp_scale(p, T):\n",
        "    # Robust to orientation: accepts CxT or TxC; returns same orientation as input\n",
        "    T = np.asarray(T, dtype=np.float32).reshape(-1)\n",
        "    p = np.clip(p, 1e-8, 1.0)\n",
        "    logp = np.log(p)\n",
        "    if p.shape[0] == T.shape[0]:  # CxT\n",
        "        logp = logp / np.maximum(T[:, None], 1e-6)\n",
        "        out = np.exp(logp)\n",
        "        out /= out.sum(axis=0, keepdims=True)\n",
        "        return out\n",
        "    elif p.shape[-1] == T.shape[0]:  # TxC\n",
        "        logp = logp / np.maximum(T[None, :], 1e-6)\n",
        "        out = np.exp(logp)\n",
        "        out /= out.sum(axis=1, keepdims=True)\n",
        "        return out\n",
        "    else:\n",
        "        raise ValueError(f'Temperature length {T.shape[0]} not matching probs shape {p.shape}')\n",
        "\n",
        "def ensure_CxT(p, C):\n",
        "    # Ensure output is CxT\n",
        "    if p.shape[0] == C:\n",
        "        return p\n",
        "    if p.shape[1] == C:\n",
        "        return p.T\n",
        "    raise ValueError(f'Cannot ensure CxT; probs shape {p.shape}, C={C}')\n",
        "\n",
        "def load_probs(seq_id):\n",
        "    # Expect ensemble-level caches: <id>_ce.npy (v2) and <id>_ce_v3.npy (v3)\n",
        "    p2 = np.load(cache / f\"{seq_id}_ce.npy\").astype(np.float32)  # CxT or TxC\n",
        "    p3 = np.load(cache / f\"{seq_id}_ce_v3.npy\").astype(np.float32)\n",
        "    # Apply per-class temperatures (keep native orientation for stability)\n",
        "    p2 = temp_scale(p2, T2)\n",
        "    p3 = temp_scale(p3, T3)\n",
        "    # Ensure both are CxT before per-class blending\n",
        "    C = int(T2.shape[0])\n",
        "    p2 = ensure_CxT(p2, C)\n",
        "    p3 = ensure_CxT(p3, C)\n",
        "    # Time-align by cropping to the minimum T\n",
        "    Tm = min(p2.shape[1], p3.shape[1])\n",
        "    if p2.shape[1] != Tm:\n",
        "        p2 = p2[:, :Tm]\n",
        "    if p3.shape[1] != Tm:\n",
        "        p3 = p3[:, :Tm]\n",
        "    # Per-class blend\n",
        "    alpha = A.reshape(-1,1)\n",
        "    p = alpha*p2 + (1.0-alpha)*p3\n",
        "    p /= p.sum(axis=0, keepdims=True)\n",
        "    return p  # CxT\n",
        "\n",
        "def load_frame_labels(seq_id):\n",
        "    # labels3d_v2 contains per-frame integer labels, saved as .npy, shape (T,), classes 1..20\n",
        "    y = np.load(labels_dir / f\"{seq_id}.npy\")\n",
        "    return y.astype(np.int32)\n",
        "\n",
        "def compress_to_sequence(y_frames):\n",
        "    # remove repeats and zeros\n",
        "    seq = []\n",
        "    last = -1\n",
        "    for c in y_frames:\n",
        "        if c == 0:\n",
        "            continue\n",
        "        if c != last:\n",
        "            seq.append(int(c))\n",
        "            last = int(c)\n",
        "    return seq\n",
        "\n",
        "def levenshtein(a, b):\n",
        "    # sequences of ints\n",
        "    n, m = len(a), len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp = list(range(m+1))\n",
        "    for i in range(1, n+1):\n",
        "        prev = dp[0]\n",
        "        dp[0] = i\n",
        "        for j in range(1, m+1):\n",
        "            temp = dp[j]\n",
        "            cost = 0 if a[i-1]==b[j-1] else 1\n",
        "            dp[j] = min(dp[j]+1, dp[j-1]+1, prev+cost)\n",
        "            prev = temp\n",
        "    return dp[m]\n",
        "\n",
        "def segment_lengths(y_frames):\n",
        "    # returns dict class->list of lengths (excluding 0)\n",
        "    lens = defaultdict(list)\n",
        "    cur_c, run = None, 0\n",
        "    for c in y_frames:\n",
        "        if c==0:\n",
        "            if cur_c is not None:\n",
        "                lens[cur_c].append(run)\n",
        "                cur_c, run = None, 0\n",
        "            continue\n",
        "        if cur_c is None:\n",
        "            cur_c, run = int(c), 1\n",
        "        elif c == cur_c:\n",
        "            run += 1\n",
        "        else:\n",
        "            lens[cur_c].append(run)\n",
        "            cur_c, run = int(c), 1\n",
        "    if cur_c is not None:\n",
        "        lens[cur_c].append(run)\n",
        "    return lens\n",
        "\n",
        "def compute_min_dur_stats(ids):\n",
        "    # Use ground-truth frame labels on train folds to get median lens\n",
        "    agg = defaultdict(list)\n",
        "    for sid in ids:\n",
        "        y = load_frame_labels(sid)\n",
        "        lens = segment_lengths(y)\n",
        "        for c, ls in lens.items():\n",
        "            if c!=0:\n",
        "                agg[c].extend(ls)\n",
        "    med = np.zeros(21, dtype=np.float32)\n",
        "    for c in range(21):\n",
        "        if c==0:\n",
        "            med[c]=0\n",
        "            continue\n",
        "        ls = agg.get(c, [])\n",
        "        med[c] = float(np.median(ls)) if ls else 1.0\n",
        "    return med\n",
        "\n",
        "def decode_with_min_segment(p, min_dur):\n",
        "    # p: CxT probs, min_dur: per-class minimal duration (frames)\n",
        "    # initial argmax path\n",
        "    y = p.argmax(axis=0).astype(np.int32)\n",
        "    # post-process: merge segments shorter than threshold\n",
        "    Tlen = y.shape[0]\n",
        "    i = 0\n",
        "    while i < Tlen:\n",
        "        c = y[i]\n",
        "        j = i+1\n",
        "        while j<Tlen and y[j]==c:\n",
        "            j+=1\n",
        "        seg_len = j-i\n",
        "        if c!=0 and seg_len < min_dur[c]:\n",
        "            # decide merge direction by average alt prob in neighbors\n",
        "            left_c = y[i-1] if i>0 else None\n",
        "            right_c = y[j] if j<Tlen else None\n",
        "            # compute average probability for left/right classes over this segment\n",
        "            left_score = -np.inf\n",
        "            right_score = -np.inf\n",
        "            if left_c is not None:\n",
        "                left_score = float(p[left_c, i:j].mean())\n",
        "            if right_c is not None:\n",
        "                right_score = float(p[right_c, i:j].mean())\n",
        "            if right_score >= left_score:\n",
        "                # merge into right\n",
        "                y[i:j] = right_c if right_c is not None else 0\n",
        "            else:\n",
        "                y[i:j] = left_c if left_c is not None else 0\n",
        "            # step back a bit to re-evaluate merges\n",
        "            i = max(0, i-1)\n",
        "            continue\n",
        "        i = j\n",
        "    return y\n",
        "\n",
        "# Build train/val id sets for fold0 (already parsed above)\n",
        "# Compute per-class median lengths from fold0 TRAIN ids (not val) to avoid leakage\n",
        "med_lens = compute_min_dur_stats(sorted(fold0_train_ids))\n",
        "print('Median segment lengths (sample):', med_lens[1:6])\n",
        "\n",
        "def eval_oof_val(min_dur_mult=0.5):\n",
        "    min_dur = np.floor(med_lens * min_dur_mult + 0.5).astype(np.int32)\n",
        "    min_dur[0]=0\n",
        "    dists = []\n",
        "    base_dists = []\n",
        "    n=0\n",
        "    t_start=time.time()\n",
        "    for npz_path in sorted(train_v3.glob('*.npz')):\n",
        "        sid = int(npz_path.stem)\n",
        "        if sid not in fold0_val_ids:\n",
        "            continue\n",
        "        # load probs and labels\n",
        "        p = load_probs(sid)  # CxT\n",
        "        y_true = load_frame_labels(sid)\n",
        "        # baseline greedy\n",
        "        y_base = p.argmax(axis=0).astype(np.int32)\n",
        "        seq_base = compress_to_sequence(y_base)\n",
        "        seq_true = compress_to_sequence(y_true)\n",
        "        base_dists.append(levenshtein(seq_base, seq_true))\n",
        "        # duration-aware merge\n",
        "        y_hat = decode_with_min_segment(p, min_dur)\n",
        "        seq_hat = compress_to_sequence(y_hat)\n",
        "        dists.append(levenshtein(seq_hat, seq_true))\n",
        "        n+=1\n",
        "        if n%20==0:\n",
        "            print(f'.. processed {n} seqs, elapsed {time.time()-t_start:.1f}s', flush=True)\n",
        "    return float(np.mean(base_dists)), float(np.mean(dists)), n\n",
        "\n",
        "for mult in [0.3, 0.5, 0.7, 1.0]:\n",
        "    b, d, n = eval_oof_val(mult)\n",
        "    print(f'min_dur_mult={mult}: baseline_mean={b:.3f} -> duraware_mean={d:.3f} over {n} seqs')\n",
        "\n",
        "print('Done in', time.time()-t0, 's')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median segment lengths (sample): [40. 40. 50. 46. 48.]\n.. processed 20 seqs, elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 40 seqs, elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 60 seqs, elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 80 seqs, elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_dur_mult=0.3: baseline_mean=27.510 -> duraware_mean=5.949 over 98 seqs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 20 seqs, elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 40 seqs, elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 60 seqs, elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 80 seqs, elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_dur_mult=0.5: baseline_mean=27.510 -> duraware_mean=4.153 over 98 seqs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 20 seqs, elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 40 seqs, elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 60 seqs, elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 80 seqs, elapsed 1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_dur_mult=0.7: baseline_mean=27.510 -> duraware_mean=3.878 over 98 seqs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 20 seqs, elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 40 seqs, elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 60 seqs, elapsed 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. processed 80 seqs, elapsed 1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "min_dur_mult=1.0: baseline_mean=27.510 -> duraware_mean=5.061 over 98 seqs\nDone in 6.200224876403809 s\n"
          ]
        }
      ]
    },
    {
      "id": "48106b29-55f9-4f18-8a90-d0a8af3d0b2c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspect folds_archive_cv.json structure to fix indexing\n",
        "import json, pprint\n",
        "with open('folds_archive_cv.json') as f:\n",
        "    folds_raw = json.load(f)\n",
        "print('type:', type(folds_raw))\n",
        "if isinstance(folds_raw, dict):\n",
        "    print('dict keys:', list(folds_raw.keys())[:10])\n",
        "    # show a sample entry\n",
        "    for k,v in list(folds_raw.items())[:1]:\n",
        "        print('sample key:', k, 'type:', type(v))\n",
        "        pprint.pprint(v if isinstance(v, (dict,list)) else str(v))\n",
        "elif isinstance(folds_raw, list):\n",
        "    print('list length:', len(folds_raw))\n",
        "    if folds_raw:\n",
        "        print('elem0 type:', type(folds_raw[0]))\n",
        "        pprint.pprint(folds_raw[0])\n",
        "else:\n",
        "    print('Unknown structure')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type: <class 'list'>\nlist length: 3\nelem0 type: <class 'dict'>\n{'fold': 0,\n 'train_ids': [101,\n               102,\n               103,\n               104,\n               105,\n               106,\n               107,\n               108,\n               109,\n               110,\n               111,\n               112,\n               113,\n               114,\n               115,\n               116,\n               117,\n               118,\n               119,\n               120,\n               121,\n               122,\n               123,\n               124,\n               125,\n               126,\n               127,\n               128,\n               129,\n               130,\n               131,\n               132,\n               133,\n               134,\n               135,\n               136,\n               137,\n               138,\n               139,\n               140,\n               141,\n               142,\n               143,\n               144,\n               145,\n               146,\n               147,\n               148,\n               149,\n               150,\n               151,\n               152,\n               153,\n               154,\n               155,\n               156,\n               157,\n               158,\n               159,\n               160,\n               161,\n               162,\n               163,\n               164,\n               165,\n               166,\n               167,\n               168,\n               169,\n               170,\n               171,\n               172,\n               173,\n               174,\n               175,\n               176,\n               177,\n               178,\n               179,\n               180,\n               181,\n               182,\n               183,\n               184,\n               185,\n               186,\n               187,\n               188,\n               189,\n               190,\n               191,\n               192,\n               193,\n               194,\n               195,\n               196,\n               197,\n               198,\n               199,\n               200,\n               201,\n               202,\n               203,\n               204,\n               205,\n               206,\n               207,\n               208,\n               209,\n               210,\n               211,\n               212,\n               213,\n               214,\n               215,\n               216,\n               217,\n               218,\n               219,\n               220,\n               221,\n               222,\n               223,\n               224,\n               225,\n               226,\n               227,\n               228,\n               229,\n               230,\n               231,\n               232,\n               233,\n               234,\n               235,\n               236,\n               237,\n               238,\n               239,\n               240,\n               241,\n               242,\n               243,\n               244,\n               245,\n               246,\n               247,\n               248,\n               249,\n               250,\n               251,\n               252,\n               253,\n               254,\n               255,\n               256,\n               257,\n               258,\n               259,\n               260,\n               261,\n               262,\n               263,\n               264,\n               265,\n               266,\n               267,\n               268,\n               269,\n               270,\n               271,\n               272,\n               273,\n               274,\n               275,\n               276,\n               277,\n               278,\n               279,\n               280,\n               281,\n               282,\n               283,\n               284,\n               285,\n               286,\n               287,\n               288,\n               289,\n               290,\n               291,\n               292,\n               293,\n               294,\n               295,\n               296,\n               297,\n               298,\n               299],\n 'val_ids': [1,\n             3,\n             4,\n             5,\n             6,\n             7,\n             8,\n             9,\n             10,\n             11,\n             12,\n             13,\n             14,\n             15,\n             16,\n             17,\n             18,\n             19,\n             20,\n             21,\n             22,\n             23,\n             24,\n             25,\n             26,\n             27,\n             28,\n             29,\n             30,\n             31,\n             32,\n             33,\n             34,\n             35,\n             36,\n             37,\n             38,\n             39,\n             40,\n             41,\n             42,\n             43,\n             44,\n             45,\n             46,\n             47,\n             48,\n             49,\n             50,\n             51,\n             52,\n             53,\n             54,\n             55,\n             56,\n             57,\n             58,\n             59,\n             60,\n             61,\n             62,\n             63,\n             64,\n             65,\n             66,\n             67,\n             68,\n             69,\n             70,\n             71,\n             72,\n             73,\n             74,\n             75,\n             76,\n             77,\n             78,\n             79,\n             80,\n             81,\n             82,\n             83,\n             84,\n             85,\n             86,\n             87,\n             88,\n             89,\n             90,\n             91,\n             92,\n             93,\n             94,\n             95,\n             96,\n             97,\n             98,\n             99]}\n"
          ]
        }
      ]
    },
    {
      "id": "874f6107-d862-422f-910b-063cedd84536",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspect labels3d_v2/train to determine file naming and format\n",
        "import glob, os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "lbl_files = sorted(labels_dir.glob('*'))\n",
        "print('labels count:', len(lbl_files))\n",
        "print('first 10:', [os.path.basename(p) for p in lbl_files[:10]])\n",
        "if lbl_files:\n",
        "    p0 = lbl_files[0]\n",
        "    print('Sample file:', p0.name)\n",
        "    try:\n",
        "        if p0.suffix == '.npz':\n",
        "            z = np.load(p0)\n",
        "            print('npz keys:', list(z.keys()))\n",
        "            for k in z.files:\n",
        "                arr = z[k]\n",
        "                print('  ', k, arr.shape, arr.dtype, 'min/max', float(arr.min()), float(arr.max()))\n",
        "        elif p0.suffix == '.npy':\n",
        "            a = np.load(p0)\n",
        "            print('npy shape:', a.shape, a.dtype, 'min/max', float(a.min()), float(a.max()))\n",
        "        else:\n",
        "            print('Unknown suffix:', p0.suffix)\n",
        "    except Exception as e:\n",
        "        print('Error reading sample label file:', e)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels count: 297\nfirst 10: ['1.npy', '10.npy', '101.npy', '102.npy', '103.npy', '104.npy', '105.npy', '106.npy', '107.npy', '108.npy']\nSample file: 1.npy\nnpy shape: (1254,) int16 min/max 1.0 20.0\n"
          ]
        }
      ]
    },
    {
      "id": "8ebab2d0-6ae3-425b-90ea-d1d379ffe256",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Full OOF sweep across folds with guardrails, then test decode + submission (sweep rho too)\n",
        "import numpy as np, json, time\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "def compute_runlen_stats(ids):\n",
        "    agg = defaultdict(list)\n",
        "    for sid in ids:\n",
        "        y = load_frame_labels(sid)\n",
        "        cur, run = None, 0\n",
        "        for c in y:\n",
        "            if c==0:\n",
        "                if cur is not None:\n",
        "                    agg[cur].append(run)\n",
        "                    cur, run = None, 0\n",
        "                continue\n",
        "            if cur is None:\n",
        "                cur, run = int(c), 1\n",
        "            elif c==cur:\n",
        "                run += 1\n",
        "            else:\n",
        "                agg[cur].append(run)\n",
        "                cur, run = int(c), 1\n",
        "        if cur is not None:\n",
        "            agg[cur].append(run)\n",
        "    med = np.zeros(21, dtype=np.float32)\n",
        "    q75 = np.zeros(21, dtype=np.float32)\n",
        "    for c in range(21):\n",
        "        if c==0:\n",
        "            continue\n",
        "        ls = agg.get(c, [])\n",
        "        if ls:\n",
        "            arr = np.array(ls, dtype=np.float32)\n",
        "            med[c] = float(np.median(arr))\n",
        "            q75[c] = float(np.percentile(arr, 75.0))\n",
        "        else:\n",
        "            med[c] = 1.0\n",
        "            q75[c] = 2.0\n",
        "    return med, q75\n",
        "\n",
        "def build_min_dur(med, q75, mult):\n",
        "    md = np.round(med * mult).astype(np.int32)\n",
        "    md = np.clip(md, 2, np.maximum(q75.astype(np.int32), 2))\n",
        "    md[0] = 0\n",
        "    return md\n",
        "\n",
        "def decode_minseg_guarded(p, min_dur, rho=None):\n",
        "    # p: CxT probs\n",
        "    y = p.argmax(axis=0).astype(np.int32)\n",
        "    Tlen = y.shape[0]\n",
        "    i = 0\n",
        "    merges = 0\n",
        "    blocked_rho = 0\n",
        "    blocked_zero = 0\n",
        "    while i < Tlen:\n",
        "        c = y[i]\n",
        "        j = i+1\n",
        "        while j<Tlen and y[j]==c:\n",
        "            j += 1\n",
        "        seg_len = j-i\n",
        "        if c!=0 and seg_len < min_dur[c]:\n",
        "            left_c = y[i-1] if i>0 else None\n",
        "            right_c = y[j] if j<Tlen else None\n",
        "            # pick neighbor candidate (avoid 0 if possible)\n",
        "            cand = None\n",
        "            if left_c is not None and right_c is not None:\n",
        "                L = left_c if left_c!=0 else None\n",
        "                R = right_c if right_c!=0 else None\n",
        "                if L is None and R is None:\n",
        "                    cand = None\n",
        "                elif L is None:\n",
        "                    cand = R\n",
        "                elif R is None:\n",
        "                    cand = L\n",
        "                else:\n",
        "                    lscore = float(p[L, i:j].mean())\n",
        "                    rscore = float(p[R, i:j].mean())\n",
        "                    cand = R if rscore >= lscore else L\n",
        "            else:\n",
        "                only = left_c if right_c is None else right_c\n",
        "                if only == 0:\n",
        "                    cand = None\n",
        "                else:\n",
        "                    cand = only\n",
        "            if cand is not None and cand!=0:\n",
        "                mean_c = float(p[c, i:j].mean())\n",
        "                mean_k = float(p[cand, i:j].mean())\n",
        "                # if rho is None: always allow; else require mean_k >= rho*mean_c\n",
        "                if (rho is None) or (mean_k >= rho * mean_c):\n",
        "                    y[i:j] = cand\n",
        "                    merges += 1\n",
        "                    i = max(0, i-1)\n",
        "                    continue\n",
        "                else:\n",
        "                    blocked_rho += 1\n",
        "            else:\n",
        "                blocked_zero += 1\n",
        "        i = j\n",
        "    return y, merges, blocked_rho, blocked_zero\n",
        "\n",
        "# Load folds list\n",
        "with open('folds_archive_cv.json') as f:\n",
        "    folds_list = json.load(f)\n",
        "\n",
        "def eval_all_folds(mult_list=(0.5,0.6,0.7,0.8), rho_list=(None,0.9,0.95,1.0)):\n",
        "    results = []  # list of dict per fold\n",
        "    for fd in folds_list:\n",
        "        fidx = int(fd['fold'])\n",
        "        tr_ids = list(map(int, fd['train_ids']))\n",
        "        va_ids = set(map(int, fd['val_ids']))\n",
        "        print(f'Fold {fidx}: computing run-length stats on train ({len(tr_ids)} seqs) ...', flush=True)\n",
        "        med, q75 = compute_runlen_stats(tr_ids)\n",
        "        print('  med[1:6]=', med[1:6], ' q75[1:6]=', q75[1:6])\n",
        "        # baseline and per setting metrics\n",
        "        base_d = []\n",
        "        per_setting = {(m,r): {'d': [], 'merges':0, 'blocked_rho':0, 'blocked_zero':0} for m in mult_list for r in rho_list}\n",
        "        n=0\n",
        "        t0 = time.time()\n",
        "        for npz_path in sorted(Path('features3d_v3/train').glob('*.npz')):\n",
        "            sid = int(npz_path.stem)\n",
        "            if sid not in va_ids:\n",
        "                continue\n",
        "            p = load_probs(sid)  # CxT\n",
        "            if n==0:\n",
        "                # sanity check normalization\n",
        "                sums = p.sum(axis=0)\n",
        "                print(f'  sanity: p shape {p.shape}, mean frame sum {float(sums.mean()):.4f}, min/max {float(sums.min()):.4f}/{float(sums.max()):.4f}')\n",
        "            y_true = load_frame_labels(sid)\n",
        "            y_base = p.argmax(axis=0).astype(np.int32)\n",
        "            base_d.append(levenshtein(compress_to_sequence(y_base), compress_to_sequence(y_true)))\n",
        "            for m in mult_list:\n",
        "                md = build_min_dur(med, q75, m)\n",
        "                for r in rho_list:\n",
        "                    y_hat, merges, br, bz = decode_minseg_guarded(p, md, rho=r)\n",
        "                    per_setting[(m,r)]['d'].append(levenshtein(compress_to_sequence(y_hat), compress_to_sequence(y_true)))\n",
        "                    per_setting[(m,r)]['merges'] += merges\n",
        "                    per_setting[(m,r)]['blocked_rho'] += br\n",
        "                    per_setting[(m,r)]['blocked_zero'] += bz\n",
        "            n+=1\n",
        "            if n%20==0:\n",
        "                print(f'  .. fold {fidx} processed {n} seqs, elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "        base_mean = float(np.mean(base_d)) if base_d else 0.0\n",
        "        fold_rec = {'fold': fidx, 'baseline': base_mean, 'per_setting': {}}\n",
        "        for m in mult_list:\n",
        "            for r in rho_list:\n",
        "                ds = per_setting[(m,r)]['d']\n",
        "                fold_rec['per_setting'][f'{m}_{r}'] = {\n",
        "                    'mean': float(np.mean(ds)) if ds else 0.0,\n",
        "                    'merges': per_setting[(m,r)]['merges'],\n",
        "                    'blocked_rho': per_setting[(m,r)]['blocked_rho'],\n",
        "                    'blocked_zero': per_setting[(m,r)]['blocked_zero'],\n",
        "                    'n': len(ds)\n",
        "                }\n",
        "        results.append(fold_rec)\n",
        "        print(f\"Fold {fidx} baseline={base_mean:.3f}\")\n",
        "        for m in mult_list:\n",
        "            for r in rho_list:\n",
        "                rec = fold_rec['per_setting'][f'{m}_{r}']\n",
        "                print(f\"  mult={m} rho={r}: mean={rec['mean']:.3f} merges={rec['merges']} blocked_rho={rec['blocked_rho']} blocked_zero={rec['blocked_zero']} n={rec['n']}\")\n",
        "    # choose global (mult, rho) by worst-fold then mean\n",
        "    candidates = [(m,r) for m in mult_list for r in rho_list]\n",
        "    worst_by = {}\n",
        "    mean_by = {}\n",
        "    for (m,r) in candidates:\n",
        "        vals = []\n",
        "        for fd in results:\n",
        "            vals.append(fd['per_setting'][f'{m}_{r}']['mean'])\n",
        "        worst_by[(m,r)] = max(vals)\n",
        "        mean_by[(m,r)] = float(np.mean(vals))\n",
        "    best_pair = min(candidates, key=lambda k: (worst_by[k], mean_by[k]))\n",
        "    print('Selection summary (by worst then mean):')\n",
        "    for (m,r) in candidates:\n",
        "        print(f'  mult={m} rho={r}: worst-fold={worst_by[(m,r)]:.3f} mean={mean_by[(m,r)]:.3f}')\n",
        "    print('Chosen (mult, rho):', best_pair)\n",
        "    overall = {\n",
        "        'results': results,\n",
        "        'chosen': {'mult': best_pair[0], 'rho': best_pair[1]},\n",
        "        'worst_by': {f'{m}_{r}': worst_by[(m,r)] for (m,r) in candidates},\n",
        "        'mean_by': {f'{m}_{r}': mean_by[(m,r)] for (m,r) in candidates}\n",
        "    }\n",
        "    with open('cv_sweep_decoder_minseg.json','w') as f:\n",
        "        json.dump(overall, f, indent=2)\n",
        "    return best_pair, results\n",
        "\n",
        "def decode_test_and_write(best_mult, rho=None, out_path='submission_primary_ce_v2v3_meta_minseg.csv'):\n",
        "    # recompute med/q75 on all training IDs\n",
        "    all_train_ids = []\n",
        "    for fd in folds_list:\n",
        "        all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "    med, q75 = compute_runlen_stats(sorted(set(all_train_ids)))\n",
        "    md = build_min_dur(med, q75, best_mult)\n",
        "    test_dir = Path('features3d_v3/test')\n",
        "    rows = []\n",
        "    ids = []\n",
        "    n=0; t0=time.time()\n",
        "    for npz_path in sorted(test_dir.glob('*.npz')):\n",
        "        sid = int(npz_path.stem)\n",
        "        p2 = Path('probs_cache') / f\"{sid}_ce.npy\"\n",
        "        p3 = Path('probs_cache') / f\"{sid}_ce_v3.npy\"\n",
        "        if not (p2.exists() and p3.exists()):\n",
        "            # no cached test probs available; skip (will produce 0 rows)\n",
        "            continue\n",
        "        else:\n",
        "            p = load_probs(sid)\n",
        "        y_hat, _, _, _ = decode_minseg_guarded(p, md, rho=rho)\n",
        "        seq = compress_to_sequence(y_hat)\n",
        "        ids.append(sid)\n",
        "        rows.append(' '.join(map(str, seq)))\n",
        "        n+=1\n",
        "        if n%20==0:\n",
        "            print(f'.. decoded {n} test seqs, elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "    import pandas as pd\n",
        "    sub = pd.DataFrame({'Id': ids, 'Predicted': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_path, index=False)\n",
        "    print('Wrote', out_path, 'with', len(sub), 'rows')\n",
        "\n",
        "print('Running full OOF sweep with guardrails (sweeping rho incl. None to allow merges)...', flush=True)\n",
        "best_pair, res = eval_all_folds(mult_list=(0.5,0.6,0.7,0.8), rho_list=(None,0.9,0.95,1.0))\n",
        "print('Best (mult, rho) from OOF:', best_pair)\n",
        "print('Decoding test and writing submission...')\n",
        "decode_test_and_write(best_pair[0], rho=best_pair[1], out_path='submission_primary_ce_v2v3_meta_minseg.csv')\n",
        "print('Done.')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running full OOF sweep with guardrails (sweeping rho incl. None to allow merges)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: computing run-length stats on train (199 seqs) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  med[1:6]= [40. 40. 50. 46. 48.]  q75[1:6]= [79.75 61.   60.   80.   60.  ]\n  sanity: p shape (21, 1254), mean frame sum 1.0000, min/max 1.0000/1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 0 processed 20 seqs, elapsed 2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 0 processed 40 seqs, elapsed 5.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 0 processed 60 seqs, elapsed 9.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 0 processed 80 seqs, elapsed 13.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 baseline=27.510\n  mult=0.5 rho=None: mean=4.827 merges=31911 blocked_rho=0 blocked_zero=82 n=98\n  mult=0.5 rho=0.9: mean=13.765 merges=12077 blocked_rho=1464 blocked_zero=57 n=98\n  mult=0.5 rho=0.95: mean=18.184 merges=5822 blocked_rho=1889 blocked_zero=57 n=98\n  mult=0.5 rho=1.0: mean=27.510 merges=0 blocked_rho=2509 blocked_zero=56 n=98\n  mult=0.6 rho=None: mean=4.592 merges=40909 blocked_rho=0 blocked_zero=83 n=98\n  mult=0.6 rho=0.9: mean=13.673 merges=14281 blocked_rho=1601 blocked_zero=57 n=98\n  mult=0.6 rho=0.95: mean=18.184 merges=6759 blocked_rho=2005 blocked_zero=57 n=98\n  mult=0.6 rho=1.0: mean=27.510 merges=0 blocked_rho=2614 blocked_zero=56 n=98\n  mult=0.7 rho=None: mean=4.520 merges=51015 blocked_rho=0 blocked_zero=83 n=98\n  mult=0.7 rho=0.9: mean=13.643 merges=16249 blocked_rho=1728 blocked_zero=57 n=98\n  mult=0.7 rho=0.95: mean=18.163 merges=7644 blocked_rho=2119 blocked_zero=57 n=98\n  mult=0.7 rho=1.0: mean=27.510 merges=0 blocked_rho=2720 blocked_zero=56 n=98\n  mult=0.8 rho=None: mean=4.735 merges=60951 blocked_rho=0 blocked_zero=83 n=98\n  mult=0.8 rho=0.9: mean=13.622 merges=18098 blocked_rho=1883 blocked_zero=57 n=98\n  mult=0.8 rho=0.95: mean=18.163 merges=8448 blocked_rho=2248 blocked_zero=57 n=98\n  mult=0.8 rho=1.0: mean=27.510 merges=0 blocked_rho=2839 blocked_zero=56 n=98\nFold 1: computing run-length stats on train (198 seqs) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  med[1:6]= [40. 40. 49. 40. 42.]  q75[1:6]= [68. 60. 60. 60. 60.]\n  sanity: p shape (21, 1286), mean frame sum 1.0000, min/max 1.0000/1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 1 processed 20 seqs, elapsed 2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 1 processed 40 seqs, elapsed 4.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 1 processed 60 seqs, elapsed 7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 1 processed 80 seqs, elapsed 11.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 baseline=22.758\n  mult=0.5 rho=None: mean=3.101 merges=26678 blocked_rho=0 blocked_zero=94 n=99\n  mult=0.5 rho=0.9: mean=12.242 merges=7533 blocked_rho=1458 blocked_zero=84 n=99\n  mult=0.5 rho=0.95: mean=16.323 merges=3688 blocked_rho=1805 blocked_zero=83 n=99\n  mult=0.5 rho=1.0: mean=22.758 merges=0 blocked_rho=2222 blocked_zero=82 n=99\n  mult=0.6 rho=None: mean=3.091 merges=33127 blocked_rho=0 blocked_zero=94 n=99\n  mult=0.6 rho=0.9: mean=12.242 merges=8825 blocked_rho=1558 blocked_zero=84 n=99\n  mult=0.6 rho=0.95: mean=16.323 merges=4264 blocked_rho=1877 blocked_zero=83 n=99\n  mult=0.6 rho=1.0: mean=22.758 merges=0 blocked_rho=2282 blocked_zero=82 n=99\n  mult=0.7 rho=None: mean=3.303 merges=40478 blocked_rho=0 blocked_zero=95 n=99\n  mult=0.7 rho=0.9: mean=12.232 merges=10095 blocked_rho=1673 blocked_zero=85 n=99\n  mult=0.7 rho=0.95: mean=16.313 merges=4841 blocked_rho=1976 blocked_zero=84 n=99\n  mult=0.7 rho=1.0: mean=22.758 merges=0 blocked_rho=2372 blocked_zero=83 n=99\n  mult=0.8 rho=None: mean=3.657 merges=48678 blocked_rho=0 blocked_zero=96 n=99\n  mult=0.8 rho=0.9: mean=12.232 merges=11186 blocked_rho=1790 blocked_zero=86 n=99\n  mult=0.8 rho=0.95: mean=16.313 merges=5359 blocked_rho=2080 blocked_zero=85 n=99\n  mult=0.8 rho=1.0: mean=22.758 merges=0 blocked_rho=2458 blocked_zero=84 n=99\nFold 2: computing run-length stats on train (197 seqs) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  med[1:6]= [33. 35. 38. 37. 37.]  q75[1:6]= [40.   43.   47.25 44.   42.25]\n  sanity: p shape (21, 1147), mean frame sum 1.0000, min/max 1.0000/1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 2 processed 20 seqs, elapsed 2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 2 processed 40 seqs, elapsed 4.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 2 processed 60 seqs, elapsed 7.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 2 processed 80 seqs, elapsed 9.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  .. fold 2 processed 100 seqs, elapsed 12.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 baseline=21.070\n  mult=0.5 rho=None: mean=4.960 merges=15656 blocked_rho=0 blocked_zero=128 n=100\n  mult=0.5 rho=0.9: mean=11.290 merges=5735 blocked_rho=1148 blocked_zero=118 n=100\n  mult=0.5 rho=0.95: mean=14.910 merges=2987 blocked_rho=1479 blocked_zero=118 n=100\n  mult=0.5 rho=1.0: mean=21.070 merges=0 blocked_rho=1908 blocked_zero=116 n=100\n  mult=0.6 rho=None: mean=4.710 merges=19837 blocked_rho=0 blocked_zero=130 n=100\n  mult=0.6 rho=0.9: mean=11.210 merges=6792 blocked_rho=1252 blocked_zero=119 n=100\n  mult=0.6 rho=0.95: mean=14.900 merges=3475 blocked_rho=1575 blocked_zero=119 n=100\n  mult=0.6 rho=1.0: mean=21.070 merges=0 blocked_rho=1987 blocked_zero=117 n=100\n  mult=0.7 rho=None: mean=4.610 merges=24359 blocked_rho=0 blocked_zero=134 n=100\n  mult=0.7 rho=0.9: mean=11.190 merges=7750 blocked_rho=1337 blocked_zero=122 n=100\n  mult=0.7 rho=0.95: mean=14.900 merges=3856 blocked_rho=1654 blocked_zero=121 n=100\n  mult=0.7 rho=1.0: mean=21.070 merges=0 blocked_rho=2054 blocked_zero=118 n=100\n  mult=0.8 rho=None: mean=4.580 merges=28907 blocked_rho=0 blocked_zero=136 n=100\n  mult=0.8 rho=0.9: mean=11.160 merges=8601 blocked_rho=1431 blocked_zero=122 n=100\n  mult=0.8 rho=0.95: mean=14.890 merges=4244 blocked_rho=1734 blocked_zero=121 n=100\n  mult=0.8 rho=1.0: mean=21.070 merges=0 blocked_rho=2124 blocked_zero=118 n=100\nSelection summary (by worst then mean):\n  mult=0.5 rho=None: worst-fold=4.960 mean=4.296\n  mult=0.5 rho=0.9: worst-fold=13.765 mean=12.433\n  mult=0.5 rho=0.95: worst-fold=18.184 mean=16.472\n  mult=0.5 rho=1.0: worst-fold=27.510 mean=23.779\n  mult=0.6 rho=None: worst-fold=4.710 mean=4.131\n  mult=0.6 rho=0.9: worst-fold=13.673 mean=12.375\n  mult=0.6 rho=0.95: worst-fold=18.184 mean=16.469\n  mult=0.6 rho=1.0: worst-fold=27.510 mean=23.779\n  mult=0.7 rho=None: worst-fold=4.610 mean=4.144\n  mult=0.7 rho=0.9: worst-fold=13.643 mean=12.355\n  mult=0.7 rho=0.95: worst-fold=18.163 mean=16.459\n  mult=0.7 rho=1.0: worst-fold=27.510 mean=23.779\n  mult=0.8 rho=None: worst-fold=4.735 mean=4.324\n  mult=0.8 rho=0.9: worst-fold=13.622 mean=12.338\n  mult=0.8 rho=0.95: worst-fold=18.163 mean=16.455\n  mult=0.8 rho=1.0: worst-fold=27.510 mean=23.779\nChosen (mult, rho): (0.7, None)\nBest (mult, rho) from OOF: (0.7, None)\nDecoding test and writing submission...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_v2v3_meta_minseg.csv with 0 rows\nDone.\n"
          ]
        }
      ]
    },
    {
      "id": "eac32ece-d62e-458d-822e-0c6ba95c6518",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspect test IDs and availability of cached probs for test\n",
        "from pathlib import Path\n",
        "import numpy as np, os\n",
        "test_dir = Path('features3d_v3/test')\n",
        "cache = Path('probs_cache')\n",
        "test_files = sorted(test_dir.glob('*.npz'))\n",
        "print('num test seqs:', len(test_files))\n",
        "ids = [int(p.stem) for p in test_files]\n",
        "print('first 15 test ids:', ids[:15])\n",
        "missing_both = 0\n",
        "have_v2 = 0\n",
        "have_v3 = 0\n",
        "for sid in ids[:50]:\n",
        "    p2 = cache / f\"{sid}_ce.npy\"\n",
        "    p3 = cache / f\"{sid}_ce_v3.npy\"\n",
        "    have_v2 += int(p2.exists())\n",
        "    have_v3 += int(p3.exists())\n",
        "    if not p2.exists() and not p3.exists():\n",
        "        missing_both += 1\n",
        "print('among first 50 test ids: have_v2:', have_v2, 'have_v3:', have_v3, 'missing both:', missing_both)\n",
        "# Also check a few random ids across all\n",
        "miss_total = sum(1 for sid in ids if not (cache / f\"{sid}_ce.npy\").exists() and not (cache / f\"{sid}_ce_v3.npy\").exists())\n",
        "print('total missing both across all test ids:', miss_total)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num test seqs: 95\nfirst 15 test ids: [300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314]\namong first 50 test ids: have_v2: 0 have_v3: 0 missing both: 50\ntotal missing both across all test ids: 95\n"
          ]
        }
      ]
    },
    {
      "id": "5b166b2d-bb88-43de-bb47-39d76d329105",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Cache test per-frame probs for v2 and v3 CE models into probs_cache/<id>_ce.npy and <id>_ce_v3.npy\n",
        "import os, json, time, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA available:', torch.cuda.is_available(), flush=True)\n",
        "\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "folds = json.load(open('folds_archive_cv.json','r'))\n",
        "test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "\n",
        "def load_feat(split_dir: Path, sid: int):\n",
        "    d = np.load(split_dir / f\"{sid}.npz\")\n",
        "    # Support either 'X' or single array\n",
        "    if 'X' in d.files:\n",
        "        X = d['X'].astype(np.float32)\n",
        "    else:\n",
        "        # fall back: first array\n",
        "        X = d[d.files[0]].astype(np.float32)\n",
        "    return X\n",
        "\n",
        "def compute_fold_scaler(id_list, feat_train_dir: Path):\n",
        "    n = 0; mean=None; M2=None\n",
        "    for sid in id_list:\n",
        "        X = load_feat(feat_train_dir, int(sid))\n",
        "        n_i = X.shape[0]\n",
        "        if mean is None:\n",
        "            mean = X.mean(axis=0); M2 = ((X - mean)**2).sum(axis=0); n = n_i\n",
        "        else:\n",
        "            mean_i = X.mean(axis=0); n_new = n + n_i; delta = mean_i - mean\n",
        "            mean = mean + delta * (n_i / max(1, n_new))\n",
        "            M2 = M2 + ((X - mean_i)**2).sum(axis=0) + (delta**2) * (n * n_i / max(1, n_new)); n = n_new\n",
        "    var = M2 / max(1, (n - 1)); std = np.sqrt(np.clip(var, 1e-8, None))\n",
        "    return mean.astype(np.float32), std.astype(np.float32)\n",
        "\n",
        "def apply_tta_timewarp(p_t_c: torch.Tensor, factors=(0.9,1.0,1.1)) -> torch.Tensor:\n",
        "    acc=None\n",
        "    for s in factors:\n",
        "        T, C = p_t_c.shape\n",
        "        tgt_len = max(1, int(round(T*s)))\n",
        "        x = p_t_c.T.unsqueeze(0)\n",
        "        y = F.interpolate(x, size=tgt_len, mode='linear', align_corners=False)\n",
        "        y2 = F.interpolate(y, size=T, mode='linear', align_corners=False)[0].T\n",
        "        y2 = y2 / (y2.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        acc = y2 if acc is None else (acc + y2)\n",
        "    out = acc / float(len(factors))\n",
        "    return out / (out.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class DilatedTCN(nn.Module):\n",
        "    def __init__(self, d_in, channels=128, layers=12, num_classes=21, dropout=0.35):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, channels, 1)\n",
        "        blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(channels, dil, drop=dropout, groups=8, k=3));\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(channels, num_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)\n",
        "        h = self.inp(x)\n",
        "        for b in self.blocks:\n",
        "            h = b(h)\n",
        "        out = self.head(h)\n",
        "        return out.transpose(1,2)  # B,T,C\n",
        "\n",
        "def cache_test_probs_for_feature_set(tag: str, feat_train_dir: Path, feat_test_dir: Path, ckpt_tmpl: str, out_suffix: str):\n",
        "    # tag: 'v2' or 'v3'\n",
        "    # ckpt_tmpl: e.g., 'model_ce_fold{fi}{suf}.pth' or 'model_ce_v3_fold{fi}{suf}.pth'\n",
        "    # out_suffix: '_ce.npy' or '_ce_v3.npy'\n",
        "    # Determine input dim from train file\n",
        "    sample_npz = next(iter(sorted(feat_train_dir.glob('*.npz'))))\n",
        "    D_in = load_feat(feat_train_dir, int(sample_npz.stem)).shape[1]\n",
        "    print(f'[{tag}] D_in={D_in}', flush=True)\n",
        "    # Precompute per-fold scalers on TRAIN ids for this feature set\n",
        "    fold_scalers = []\n",
        "    for fd in folds:\n",
        "        mean,std = compute_fold_scaler(fd['train_ids'], feat_train_dir)\n",
        "        fold_scalers.append((torch.from_numpy(mean).float().to(device), torch.from_numpy(std).float().to(device)))\n",
        "    t0 = time.time(); n_saved=0; n_skip=0\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        out_path = probs_cache / f\"{sid}{out_suffix}\"\n",
        "        if out_path.exists():\n",
        "            n_skip += 1\n",
        "            if (i%20)==0 or i==len(test_ids):\n",
        "                print(f'  [{tag}] skip {i}/{len(test_ids)} (exists) elapsed={(time.time()-t0):.1f}s', flush=True)\n",
        "            continue\n",
        "        X = load_feat(feat_test_dir, int(sid))\n",
        "        acc=None; n_models=0\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda' if device.type=='cuda' else 'cpu'):\n",
        "            for fi in range(3):\n",
        "                mean_t, std_t = fold_scalers[fi]\n",
        "                for suf in ['', '_s1']:\n",
        "                    ckpt = Path(ckpt_tmpl.format(fi=fi, suf=suf))\n",
        "                    if not ckpt.exists():\n",
        "                        continue\n",
        "                    model = DilatedTCN(d_in=D_in, channels=128, layers=12, num_classes=21, dropout=0.35).to(device)\n",
        "                    model.load_state_dict(torch.load(ckpt, map_location=device)); model.eval()\n",
        "                    xb = torch.from_numpy(X).float().to(device)\n",
        "                    xb = (xb - mean_t) / (std_t + 1e-6)\n",
        "                    xb = xb.unsqueeze(0)\n",
        "                    p = model(xb)[0].softmax(dim=-1)  # T,C\n",
        "                    p = apply_tta_timewarp(p, factors=(0.9,1.0,1.1))\n",
        "                    acc = p if acc is None else (acc + p)\n",
        "                    n_models += 1\n",
        "                    del model\n",
        "        if acc is None or n_models == 0:\n",
        "            print(f'  [{tag}] WARNING: no models found for sid={sid}; skipping save', flush=True)\n",
        "            continue\n",
        "        probs = acc / float(n_models)  # T,C\n",
        "        probs = probs / (probs.sum(dim=-1, keepdim=True) + 1e-8)\n",
        "        # Save as CxT to be consistent with downstream ensure_CxT\n",
        "        np.save(out_path, probs.transpose(0,1).cpu().numpy().astype(np.float32))  # CxT\n",
        "        n_saved += 1\n",
        "        if (i%20)==0 or i==len(test_ids):\n",
        "            print(f'  [{tag}] saved {n_saved} (processed {i}/{len(test_ids)}) elapsed={(time.time()-t0):.1f}s', flush=True)\n",
        "    print(f'[{tag}] Done. saved={n_saved} skipped_existing={n_skip} total={len(test_ids)} elapsed={(time.time()-t0):.1f}s', flush=True)\n",
        "\n",
        "# Paths for v2 and v3\n",
        "feat_v2_tr = Path('features3d_v2')/'train'\n",
        "feat_v2_te = Path('features3d_v2')/'test'\n",
        "feat_v3_tr = Path('features3d_v3')/'train'\n",
        "feat_v3_te = Path('features3d_v3')/'test'\n",
        "\n",
        "# Run caching for v2 and v3\n",
        "print('Caching test probs for v2 CE models -> _ce.npy ...', flush=True)\n",
        "cache_test_probs_for_feature_set('v2', feat_v2_tr, feat_v2_te, ckpt_tmpl='model_ce_fold{fi}{suf}.pth', out_suffix='_ce.npy')\n",
        "print('Caching test probs for v3 CE models -> _ce_v3.npy ...', flush=True)\n",
        "cache_test_probs_for_feature_set('v3', feat_v3_tr, feat_v3_te, ckpt_tmpl='model_ce_v3_fold{fi}{suf}.pth', out_suffix='_ce_v3.npy')\n",
        "print('All test probs cached.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching test probs for v2 CE models -> _ce.npy ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v2] D_in=219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_9704/3118380685.py:116: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(ckpt, map_location=device)); model.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v2] saved 20 (processed 20/95) elapsed=3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v2] saved 40 (processed 40/95) elapsed=6.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v2] saved 60 (processed 60/95) elapsed=9.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v2] saved 80 (processed 80/95) elapsed=12.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v2] saved 95 (processed 95/95) elapsed=14.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v2] Done. saved=95 skipped_existing=0 total=95 elapsed=14.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caching test probs for v3 CE models -> _ce_v3.npy ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3] D_in=1095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3] saved 20 (processed 20/95) elapsed=3.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3] saved 40 (processed 40/95) elapsed=6.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3] saved 60 (processed 60/95) elapsed=9.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3] saved 80 (processed 80/95) elapsed=13.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [v3] saved 95 (processed 95/95) elapsed=15.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[v3] Done. saved=95 skipped_existing=0 total=95 elapsed=15.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All test probs cached.\n"
          ]
        }
      ]
    },
    {
      "id": "5fa389f1-c405-4ecf-8e73-334bd1a4947a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate duration-aware minseg submission with uniqueness enforcement (perm20)\n",
        "import numpy as np, json, time, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def make_perm20(seq, p_c_t):\n",
        "    # seq: list of ints (1..20), p_c_t: CxT probs (C=21 with index 0 unused)\n",
        "    seen=set(); out=[]\n",
        "    for c in seq:\n",
        "        if 1<=c<=20 and c not in seen:\n",
        "            seen.add(c); out.append(int(c))\n",
        "    if len(out) < 20:\n",
        "        # score missing classes by total prob mass over time\n",
        "        C = p_c_t.shape[0]\n",
        "        scores=[]\n",
        "        for c in range(1,21):\n",
        "            if c in seen: continue\n",
        "            if c < C:\n",
        "                s=float(p_c_t[c].sum())\n",
        "            else:\n",
        "                s=0.0\n",
        "            scores.append((s, c))\n",
        "        scores.sort(key=lambda x: -x[0])\n",
        "        for _, c in scores:\n",
        "            if len(out) >= 20: break\n",
        "            out.append(int(c))\n",
        "    return out[:20]\n",
        "\n",
        "def decode_test_and_write_perm20(best_mult=0.7, rho=None, out_path='submission_primary_ce_v2v3_meta_minseg.csv', col_name='Sequence'):\n",
        "    # Reuse helpers from Cell 7: folds_list, compute_runlen_stats, build_min_dur, load_probs, decode_minseg_guarded, compress_to_sequence\n",
        "    all_train_ids=[]\n",
        "    for fd in folds_list:\n",
        "        all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "    med, q75 = compute_runlen_stats(sorted(set(all_train_ids)))\n",
        "    md = build_min_dur(med, q75, best_mult)\n",
        "    test_dir = Path('features3d_v3/test')\n",
        "    rows=[]; ids=[]; n=0; t0=time.time()\n",
        "    for npz_path in sorted(test_dir.glob('*.npz')):\n",
        "        sid = int(npz_path.stem)\n",
        "        p2 = Path('probs_cache')/f\"{sid}_ce.npy\"\n",
        "        p3 = Path('probs_cache')/f\"{sid}_ce_v3.npy\"\n",
        "        if not (p2.exists() and p3.exists()):\n",
        "            continue\n",
        "        p = load_probs(sid)  # CxT\n",
        "        y_hat, _, _, _ = decode_minseg_guarded(p, md, rho=rho)\n",
        "        seq_raw = compress_to_sequence(y_hat)\n",
        "        seq = make_perm20(seq_raw, p)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95:\n",
        "            print(f\".. decoded {n} test seqs in {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, col_name: rows}).sort_values('Id')\n",
        "    sub.to_csv(out_path, index=False)\n",
        "    print('Wrote', out_path, 'with', len(sub), 'rows; head:\\n', sub.head())\n",
        "    # Basic sanity checks\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    toks_ok = sub[col_name].apply(lambda s: len(s.split())==20 and set(map(int, s.split()))==set(range(1,21))).all()\n",
        "    assert toks_ok, 'Each row must be a permutation of 1..20'\n",
        "    # Copy to submission.csv\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('submission.csv written ->', out_path)\n",
        "\n",
        "print('Decoding test with minseg (mult=0.7, rho=None) and enforcing perm20...', flush=True)\n",
        "decode_test_and_write_perm20(best_mult=0.7, rho=None, out_path='submission_primary_ce_v2v3_meta_minseg.csv', col_name='Sequence')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding test with minseg (mult=0.7, rho=None) and enforcing perm20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 20 test seqs in 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 40 test seqs in 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 60 test seqs in 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 80 test seqs in 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 95 test seqs in 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_v2v3_meta_minseg.csv with 95 rows; head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 3 5 9 19 13 20 18 11 4 6 8 14 10 2 7 1...\n3  303  17 18 13 4 3 10 14 6 5 19 20 7 11 16 8 2 9 15 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 6 17 16 4 15 1...\nsubmission.csv written -> submission_primary_ce_v2v3_meta_minseg.csv\n"
          ]
        }
      ]
    },
    {
      "id": "7fc2720c-78be-4383-84f8-d4a4bc65457a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# HSMM (fixed K=20 segmental DP) decoder with downsampling and duration priors; quick test decode\n",
        "import numpy as np, time, math, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Reuse helpers already defined in earlier cells: folds_list, compute_runlen_stats, load_probs, make_perm20\n",
        "\n",
        "def avg_pool_time(p_c_t: np.ndarray, k: int) -> np.ndarray:\n",
        "    # p_c_t: CxT\n",
        "    C,T = p_c_t.shape\n",
        "    if k <= 1: return p_c_t\n",
        "    pad = k//2\n",
        "    x = np.pad(p_c_t, ((0,0),(pad,pad)), mode='edge')\n",
        "    y = np.empty((C,T), dtype=np.float32)\n",
        "    kk = float(k)\n",
        "    for t in range(T):\n",
        "        y[:,t] = x[:, t:t+k].mean(axis=1)\n",
        "    y /= (y.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return y\n",
        "\n",
        "def downsample_time(p_c_t: np.ndarray, s: int) -> np.ndarray:\n",
        "    # average over non-overlapping windows of size s\n",
        "    if s <= 1: return p_c_t\n",
        "    C,T = p_c_t.shape\n",
        "    T2 = T // s\n",
        "    if T2 <= 0:\n",
        "        return p_c_t\n",
        "    x = p_c_t[:, :T2*s].reshape(C, T2, s).mean(axis=2)\n",
        "    x /= (x.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return x\n",
        "\n",
        "def build_duration_bounds_from_stats(med: np.ndarray, q95: np.ndarray, a: float, b: float, cap_max: int = 150):\n",
        "    # med, q95: arrays size >=21, index 0 unused\n",
        "    lmin = np.zeros_like(med, dtype=np.int32)\n",
        "    lmax = np.zeros_like(med, dtype=np.int32)\n",
        "    for c in range(21):\n",
        "        if c == 0:\n",
        "            lmin[c] = 0; lmax[c] = 0; continue\n",
        "        m = float(med[c]) if med[c] > 0 else 10.0\n",
        "        q = float(q95[c]) if q95[c] > 0 else (m * 2.0)\n",
        "        lmin[c] = max(3, int(math.floor(a * m)))\n",
        "        lmax[c] = min(int(math.ceil(b * m)), int(q), int(cap_max))\n",
        "        if lmax[c] < lmin[c]:\n",
        "            lmax[c] = lmin[c]\n",
        "    return lmin, lmax\n",
        "\n",
        "def robust_q95_from_ids(ids):\n",
        "    from collections import defaultdict\n",
        "    agg = defaultdict(list)\n",
        "    for sid in ids:\n",
        "        y = load_frame_labels(int(sid))\n",
        "        cur, run = None, 0\n",
        "        for c in y:\n",
        "            if c == 0:\n",
        "                if cur is not None:\n",
        "                    agg[cur].append(run); cur=None; run=0\n",
        "                continue\n",
        "            if cur is None:\n",
        "                cur, run = int(c), 1\n",
        "            elif c == cur:\n",
        "                run += 1\n",
        "            else:\n",
        "                agg[cur].append(run); cur=int(c); run=1\n",
        "        if cur is not None:\n",
        "            agg[cur].append(run)\n",
        "    med = np.zeros(21, dtype=np.float32)\n",
        "    q95 = np.zeros(21, dtype=np.float32)\n",
        "    for c in range(1,21):\n",
        "        ls = agg.get(c, [])\n",
        "        if ls:\n",
        "            arr = np.array(ls, dtype=np.float32)\n",
        "            med[c] = float(np.median(arr))\n",
        "            q95[c] = float(np.percentile(arr, 95.0))\n",
        "        else:\n",
        "            med[c] = 10.0; q95[c] = 30.0\n",
        "    return med, q95\n",
        "\n",
        "def hsmm_decode_perm20(p_c_t: np.ndarray, med: np.ndarray, lmin: np.ndarray, lmax: np.ndarray, lambda_len: float = 0.4, mu: float = 0.1, smooth_k: int = 5, ds: int = 4):\n",
        "    # p_c_t: CxT with C>=21 and index 0 unused\n",
        "    p = np.clip(p_c_t, 1e-8, 1.0)\n",
        "    p = p / (p.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    if smooth_k > 1:\n",
        "        p = avg_pool_time(p, k=smooth_k)\n",
        "    pds = downsample_time(p, s=ds) if ds > 1 else p\n",
        "    C, T = pds.shape\n",
        "    # precompute negative log probs cumulative per class\n",
        "    neglog = -np.log(pds + 1e-8)\n",
        "    cum = np.cumsum(neglog, axis=1)\n",
        "    def seg_cost(c, t0, t1):\n",
        "        # inclusive t0..t1\n",
        "        if t0 > 0:\n",
        "            s = cum[c, t1] - cum[c, t0-1]\n",
        "        else:\n",
        "            s = cum[c, t1]\n",
        "        L = (t1 - t0 + 1)\n",
        "        m = float(med[c]) if med[c] > 0 else 10.0\n",
        "        phi = abs(math.log(max(1.0, L)) - math.log(max(1.0, m/ds)))  # log-scale penalty in ds domain\n",
        "        return float(s) + lambda_len * phi\n",
        "    # bounds in ds domain\n",
        "    lmin_ds = np.maximum(1, (lmin // max(1, ds))).astype(np.int32)\n",
        "    lmax_ds = np.maximum(lmin_ds, (lmax // max(1, ds)).astype(np.int32))\n",
        "    K = 20\n",
        "    # DP arrays: for current k segment end at t, best cost per class; and backpointers\n",
        "    INF = 1e18\n",
        "    best = np.full((K+1, T, C), INF, dtype=np.float32)\n",
        "    prev_t = -np.ones((K+1, T, C), dtype=np.int32)\n",
        "    prev_c = -np.ones((K+1, T, C), dtype=np.int16)\n",
        "    # initialize k=1\n",
        "    k = 1\n",
        "    for t in range(T):\n",
        "        # feasible l for segment ending at t given remaining segments\n",
        "        for c in range(1,21):\n",
        "            Lmin = lmin_ds[c]; Lmax = lmax_ds[c]\n",
        "            # remaining time must allow K-k segments with at least min_l each; use global min over classes ~1\n",
        "            for L in range(Lmin, Lmax+1):\n",
        "                t0 = t - L + 1\n",
        "                if t0 < 0: break\n",
        "                # ensure remaining space for (K-1) segments\n",
        "                if (T - 1 - t) < (K - k) * 1:  # min 1 per remaining segment\n",
        "                    continue\n",
        "                cost = seg_cost(c, t0, t)\n",
        "                if cost < best[k, t, c]:\n",
        "                    best[k, t, c] = cost\n",
        "                    prev_t[k, t, c] = t0 - 1  # previous end index\n",
        "                    prev_c[k, t, c] = 0      # marker for start\n",
        "    # iterate k=2..K\n",
        "    for k in range(2, K+1):\n",
        "        # precompute for each u (prev end time) the best and second-best across classes for k-1\n",
        "        # to implement 'best previous except same class' trick\n",
        "        best1_val = np.full((T,), INF, dtype=np.float32)\n",
        "        best1_c = -np.ones((T,), dtype=np.int16)\n",
        "        best2_val = np.full((T,), INF, dtype=np.float32)\n",
        "        for u in range(T):\n",
        "            # prune: at least k-1 frames must be used before u; simple guard\n",
        "            v = best[k-1, u, 1:21]\n",
        "            if v.size == 0: continue\n",
        "            i_min1 = int(np.argmin(v)) + 1\n",
        "            val1 = float(v[i_min1-1])\n",
        "            best1_val[u] = val1; best1_c[u] = i_min1\n",
        "            if v.size >= 2:\n",
        "                # mask out i_min1 to get second-best\n",
        "                tmp = v.copy()\n",
        "                tmp[i_min1-1] = INF\n",
        "                val2 = float(tmp.min())\n",
        "                best2_val[u] = val2\n",
        "        for t in range(T):\n",
        "            # At least k segments of length >=1 must fit in 0..t\n",
        "            if t < k - 1:\n",
        "                continue\n",
        "            rem_after = T - 1 - t\n",
        "            # feasible per-class lengths\n",
        "            for c in range(1,21):\n",
        "                Lmin = lmin_ds[c]; Lmax = lmax_ds[c]\n",
        "                # loop lengths\n",
        "                for L in range(Lmin, Lmax+1):\n",
        "                    t0 = t - L + 1\n",
        "                    if t0 < 0: break\n",
        "                    # feasibility: remaining segments K-k must fit in rem_after with at least 1 each\n",
        "                    if rem_after < (K - k) * 1:\n",
        "                        continue\n",
        "                    u = t0 - 1  # previous segment end index\n",
        "                    if u < 0:\n",
        "                        continue\n",
        "                    # best prev except same class\n",
        "                    prev_val = best1_val[u]\n",
        "                    if best1_c[u] == c:\n",
        "                        prev_val = best2_val[u]\n",
        "                    if not np.isfinite(prev_val):\n",
        "                        continue\n",
        "                    cost = prev_val + mu + seg_cost(c, t0, t)\n",
        "                    if cost < best[k, t, c]:\n",
        "                        best[k, t, c] = cost\n",
        "                        prev_t[k, t, c] = u\n",
        "                        prev_c[k, t, c] = best1_c[u] if best1_c[u] != c else -1  # store some prev class info\n",
        "    # termination: choose best end t for k=K\n",
        "    end_t = -1; end_c = -1; val = INF\n",
        "    for t in range(T):\n",
        "        # all frames used by K segments is not required; choose best overall\n",
        "        v = best[K, t, 1:21]\n",
        "        if v.size == 0: continue\n",
        "        i = int(np.argmin(v)) + 1\n",
        "        if v[i-1] < val:\n",
        "            val = float(v[i-1]); end_t = t; end_c = i\n",
        "    # backtrack to get classes (lengths optional)\n",
        "    classes = []\n",
        "    k = K; t = end_t; c = end_c\n",
        "    if end_t < 0 or end_c < 0:\n",
        "        # fallback: peak order by center-of-mass\n",
        "        C,T = pds.shape\n",
        "        com = []\n",
        "        idx = np.arange(T, dtype=np.float32)\n",
        "        for cc in range(1,21):\n",
        "            w = pds[cc]; s = float(w.sum()) + 1e-8; com_t = float((idx * w).sum() / s); com.append((com_t, cc))\n",
        "        com.sort(key=lambda x: x[0])\n",
        "        seq = [c for _,c in com][:20]\n",
        "    else:\n",
        "        while k >= 1 and t >= 0:\n",
        "            classes.append(int(c))\n",
        "            u = int(prev_t[k, t, c])\n",
        "            # find prev class: among best[k-1, u, :] minimal, excluding current c ideally\n",
        "            if k > 1 and u >= 0:\n",
        "                v = best[k-1, u, 1:21]\n",
        "                if v.size > 0:\n",
        "                    i = int(np.argmin(v)) + 1\n",
        "                else:\n",
        "                    i = 1\n",
        "                c = i; t = u; k -= 1\n",
        "            else:\n",
        "                break\n",
        "        classes = classes[::-1]\n",
        "        seq = classes if len(classes)==20 else (classes + [c for c in range(1,21) if c not in set(classes)])[:20]\n",
        "    # Map to original timeline only for ordering; HSMM already yields order. Enforce perm20 with make_perm20 using original probs.\n",
        "    return seq\n",
        "\n",
        "def decode_test_hsmm_and_write(mu=0.1, lambda_len=0.4, a=0.7, b=1.5, smooth_k=5, ds=4, out_path='submission_hsmm_perm20.csv', col_name='Sequence'):\n",
        "    # durations from ALL train ids (non-leaky for test)\n",
        "    all_train_ids=[]\n",
        "    for fd in folds_list:\n",
        "        all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "    med, q95 = robust_q95_from_ids(sorted(set(all_train_ids)))\n",
        "    lmin, lmax = build_duration_bounds_from_stats(med, q95, a=a, b=b, cap_max=150)\n",
        "    test_dir = Path('features3d_v3/test')\n",
        "    rows=[]; ids=[]; t0=time.time()\n",
        "    n=0\n",
        "    for npz_path in sorted(test_dir.glob('*.npz')):\n",
        "        sid = int(npz_path.stem)\n",
        "        p2 = Path('probs_cache')/f\"{sid}_ce.npy\"\n",
        "        p3 = Path('probs_cache')/f\"{sid}_ce_v3.npy\"\n",
        "        if not (p2.exists() and p3.exists()):\n",
        "            continue\n",
        "        p = load_probs(sid)  # CxT blended\n",
        "        seq_h = hsmm_decode_perm20(p, med, lmin, lmax, lambda_len=lambda_len, mu=mu, smooth_k=smooth_k, ds=ds)\n",
        "        seq = make_perm20(seq_h, p)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%10)==0 or n==95:\n",
        "            print(f\"  [HSMM test] {n}/95 elapsed={(time.time()-t0):.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, col_name: rows}).sort_values('Id')\n",
        "    sub.to_csv(out_path, index=False)\n",
        "    print('Wrote', out_path, 'rows=', len(sub), 'head:\\n', sub.head(), flush=True)\n",
        "    # Sanity\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    ok = sub[col_name].apply(lambda s: len(s.split())==20 and set(map(int, s.split()))==set(range(1,21))).all()\n",
        "    assert ok, 'Each row must be permutation of 1..20'\n",
        "    # also copy to submission.csv if desired (manual step later)\n",
        "    return out_path\n",
        "\n",
        "print('HSMM decoder ready. To run test decode quickly with default params:')\n",
        "print(\"decode_test_hsmm_and_write(mu=0.1, lambda_len=0.4, a=0.7, b=1.5, smooth_k=5, ds=4, out_path='submission_hsmm_perm20.csv')\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HSMM decoder ready. To run test decode quickly with default params:\ndecode_test_hsmm_and_write(mu=0.1, lambda_len=0.4, a=0.7, b=1.5, smooth_k=5, ds=4, out_path='submission_hsmm_perm20.csv')\n"
          ]
        }
      ]
    },
    {
      "id": "1041b11a-5425-4409-95dc-54d4474f3e33",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run HSMM decode on test and prepare submission\n",
        "import pandas as pd, shutil, os, time\n",
        "print('Running HSMM test decode (mu=0.1, lambda_len=0.4, a=0.7, b=1.5, smooth_k=5, ds=4)...', flush=True)\n",
        "out_path = decode_test_hsmm_and_write(mu=0.1, lambda_len=0.4, a=0.7, b=1.5, smooth_k=5, ds=4, out_path='submission_hsmm_perm20.csv', col_name='Sequence')\n",
        "assert os.path.exists(out_path), 'HSMM submission not written'\n",
        "shutil.copyfile(out_path, 'submission.csv')\n",
        "print('submission.csv updated ->', out_path)\n",
        "print(pd.read_csv('submission.csv').head())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running HSMM test decode (mu=0.1, lambda_len=0.4, a=0.7, b=1.5, smooth_k=5, ds=4)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [HSMM test] 10/95 elapsed=57.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [HSMM test] 20/95 elapsed=115.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [HSMM test] 30/95 elapsed=172.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [HSMM test] 40/95 elapsed=243.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [HSMM test] 50/95 elapsed=300.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [HSMM test] 60/95 elapsed=359.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [HSMM test] 70/95 elapsed=424.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [HSMM test] 80/95 elapsed=481.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [HSMM test] 90/95 elapsed=540.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [HSMM test] 95/95 elapsed=569.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_hsmm_perm20.csv rows= 95 head:\n     Id                                           Sequence\n0  300  8 4 20 13 12 3 15 14 11 6 16 19 7 10 9 2 17 1 ...\n1  301  1 7 5 4 20 6 2 11 15 13 19 9 18 3 17 8 14 10 1...\n2  302  17 16 12 3 5 9 7 19 13 20 18 11 4 6 2 14 8 1 1...\n3  303  5 19 15 20 17 1 11 7 16 8 18 9 3 6 2 14 4 13 1...\n4  304  13 9 7 2 11 3 20 19 5 10 14 6 15 17 16 4 18 8 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv updated -> submission_hsmm_perm20.csv\n    Id                                           Sequence\n0  300  8 4 20 13 12 3 15 14 11 6 16 19 7 10 9 2 17 1 ...\n1  301  1 7 5 4 20 6 2 11 15 13 19 9 18 3 17 8 14 10 1...\n2  302  17 16 12 3 5 9 7 19 13 20 18 11 4 6 2 14 8 1 1...\n3  303  5 19 15 20 17 1 11 7 16 8 18 9 3 6 2 14 4 13 1...\n4  304  13 9 7 2 11 3 20 19 5 10 14 6 15 17 16 4 18 8 ...\n"
          ]
        }
      ]
    },
    {
      "id": "63a3db42-83af-4ae7-9fa3-a4d16cd2fe4f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# HSMM OOF sweep (leave-one-archive-out) with tight grid; select by worst-fold then mean\n",
        "import numpy as np, json, time\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "# Uses helpers/functions defined earlier in this notebook:\n",
        "# - folds_list (loaded in Cell 7), load_probs, load_frame_labels, hsmm_decode_perm20, robust_q95_from_ids, build_duration_bounds_from_stats, make_perm20\n",
        "\n",
        "def compress_to_sequence(y_frames):\n",
        "    seq=[]; last=-1\n",
        "    for c in y_frames:\n",
        "        if c==0: continue\n",
        "        if c!=last: seq.append(int(c)); last=int(c)\n",
        "    return seq\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]\n",
        "            dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1))\n",
        "            prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "def eval_hsmm_on_fold(fd, mu, lambda_len, a, b, smooth_k=5, ds=4):\n",
        "    tr_ids = list(map(int, fd['train_ids']))\n",
        "    va_ids = list(map(int, fd['val_ids']))\n",
        "    med, q95 = robust_q95_from_ids(tr_ids)  # train-only (fold-pure)\n",
        "    lmin, lmax = build_duration_bounds_from_stats(med, q95, a=a, b=b, cap_max=150)\n",
        "    dists=[]; n=0\n",
        "    t0=time.time()\n",
        "    for sid in va_ids:\n",
        "        p = load_probs(int(sid))  # CxT blended v2+v3\n",
        "        seq_h = hsmm_decode_perm20(p, med, lmin, lmax, lambda_len=lambda_len, mu=mu, smooth_k=smooth_k, ds=ds)\n",
        "        seq = make_perm20(seq_h, p)\n",
        "        y_true = load_frame_labels(int(sid))\n",
        "        seq_true = compress_to_sequence(y_true)\n",
        "        dists.append(levenshtein(seq, seq_true)); n+=1\n",
        "        if (n%30)==0 or n==len(va_ids):\n",
        "            print(f\"    fold {fd['fold']} {n}/{len(va_ids)} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "    return float(np.mean(dists)) if dists else 0.0\n",
        "\n",
        "def hsmm_oof_sweep(mu_list=(0.0,0.05,0.1,0.2), lam_list=(0.2,0.4,0.6), a_list=(0.6,0.7), b_list=(1.4,1.5), smooth_k=5, ds=4):\n",
        "    cfgs=[]\n",
        "    for mu in mu_list:\n",
        "        for lam in lam_list:\n",
        "            for a in a_list:\n",
        "                for b in b_list:\n",
        "                    cfgs.append((mu,lam,a,b))\n",
        "    results=[]\n",
        "    print(f\"Sweeping {len(cfgs)} HSMM configs across {len(folds_list)} folds ...\", flush=True)\n",
        "    for (mu,lam,a,b) in cfgs:\n",
        "        per_fold=[]\n",
        "        print(f\"  cfg mu={mu} lam={lam} a={a} b={b}\", flush=True)\n",
        "        for fd in folds_list:\n",
        "            m = eval_hsmm_on_fold(fd, mu=mu, lambda_len=lam, a=a, b=b, smooth_k=smooth_k, ds=ds)\n",
        "            per_fold.append(m)\n",
        "        mean_v=float(np.mean(per_fold)); worst_v=float(np.max(per_fold))\n",
        "        results.append((worst_v, mean_v, {'mu':mu,'lambda_len':lam,'a':a,'b':b,'smooth_k':smooth_k,'ds':ds}))\n",
        "        print(f\"    -> worst={worst_v:.3f} mean={mean_v:.3f}\", flush=True)\n",
        "    results.sort(key=lambda x: (x[0], x[1]))\n",
        "    print('\\nTop 5 by worst then mean:')\n",
        "    for r in results[:5]:\n",
        "        print(r)\n",
        "    # save\n",
        "    import pandas as pd\n",
        "    pd.DataFrame([{'worst':w,'mean':m, **cfg} for (w,m,cfg) in results]).to_csv('cv_sweep_hsmm.csv', index=False)\n",
        "    print('Saved cv_sweep_hsmm.csv', flush=True)\n",
        "    best=results[0] if results else None\n",
        "    return best, results\n",
        "\n",
        "print('Running HSMM OOF sweep (tight grid)...', flush=True)\n",
        "best, res = hsmm_oof_sweep()\n",
        "print('Best (worst, mean, cfg)=', best)\n",
        "print('Reference minseg OOF: worst~4.61 mean~4.144 (lower is better).')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running HSMM OOF sweep (tight grid)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweeping 48 HSMM configs across 3 folds ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  cfg mu=0.0 lam=0.2 a=0.6 b=1.4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m best, results\n\u001b[32m     76\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mRunning HSMM OOF sweep (tight grid)...\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m best, res = \u001b[43mhsmm_oof_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mBest (worst, mean, cfg)=\u001b[39m\u001b[33m'\u001b[39m, best)\n\u001b[32m     79\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mReference minseg OOF: worst~4.61 mean~4.144 (lower is better).\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mhsmm_oof_sweep\u001b[39m\u001b[34m(mu_list, lam_list, a_list, b_list, smooth_k, ds)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  cfg mu=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmu\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m lam=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlam\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m a=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m b=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fd \u001b[38;5;129;01min\u001b[39;00m folds_list:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     m = \u001b[43meval_hsmm_on_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m=\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43msmooth_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m     per_fold.append(m)\n\u001b[32m     62\u001b[39m mean_v=\u001b[38;5;28mfloat\u001b[39m(np.mean(per_fold)); worst_v=\u001b[38;5;28mfloat\u001b[39m(np.max(per_fold))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36meval_hsmm_on_fold\u001b[39m\u001b[34m(fd, mu, lambda_len, a, b, smooth_k, ds)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sid \u001b[38;5;129;01min\u001b[39;00m va_ids:\n\u001b[32m     37\u001b[39m     p = load_probs(\u001b[38;5;28mint\u001b[39m(sid))  \u001b[38;5;66;03m# CxT blended v2+v3\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     seq_h = \u001b[43mhsmm_decode_perm20\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlambda_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43msmooth_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m     seq = make_perm20(seq_h, p)\n\u001b[32m     40\u001b[39m     y_true = load_frame_labels(\u001b[38;5;28mint\u001b[39m(sid))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 167\u001b[39m, in \u001b[36mhsmm_decode_perm20\u001b[39m\u001b[34m(p_c_t, med, lmin, lmax, lambda_len, mu, smooth_k, ds)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best1_c[u] == c:\n\u001b[32m    166\u001b[39m     prev_val = best2_val[u]\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_val\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    169\u001b[39m cost = prev_val + mu + seg_cost(c, t0, t)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "99abf829-a8f7-4d62-a151-0e4e33a9a415",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set localsrch-meta submission as current submission.csv and preview head\n",
        "import shutil, pandas as pd, os\n",
        "src = 'submission_primary_ce_v2v3_meta_localsrch.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "shutil.copyfile(src, 'submission.csv')\n",
        "print('submission.csv ->', src)\n",
        "print(pd.read_csv('submission.csv').head())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv -> submission_primary_ce_v2v3_meta_localsrch.csv\n    Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 7 1...\n1  301  10 12 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 3 1...\n2  302  1 17 16 12 5 19 7 13 20 18 11 3 4 6 15 8 14 10...\n3  303  13 4 12 10 5 19 15 20 17 11 16 8 18 7 3 1 6 2 ...\n4  304  8 1 12 14 18 13 9 7 2 11 3 20 19 5 10 6 15 17 ...\n"
          ]
        }
      ]
    },
    {
      "id": "701bdce6-388c-4412-9890-ddc8d3758e1c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick alt decode: minseg perm20 with mult=0.6 (slightly better mean OOF), then set as submission.csv\n",
        "print('Decoding test with minseg (mult=0.6, rho=None) and enforcing perm20...', flush=True)\n",
        "alt_path = 'submission_primary_ce_v2v3_meta_minseg_m06.csv'\n",
        "decode_test_and_write_perm20(best_mult=0.6, rho=None, out_path=alt_path, col_name='Sequence')\n",
        "import shutil, os, pandas as pd\n",
        "assert os.path.exists(alt_path)\n",
        "shutil.copyfile(alt_path, 'submission.csv')\n",
        "print('submission.csv ->', alt_path)\n",
        "print(pd.read_csv('submission.csv').head())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding test with minseg (mult=0.6, rho=None) and enforcing perm20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 20 test seqs in 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 40 test seqs in 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 60 test seqs in 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 80 test seqs in 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 95 test seqs in 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_primary_ce_v2v3_meta_minseg_m06.csv with 95 rows; head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 12 5 9 19 13 20 18 11 3 4 6 8 14 10 2 ...\n3  303  17 18 13 4 3 7 10 14 6 5 19 20 2 11 16 8 9 15 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 10 6 17 16 4 1...\nsubmission.csv written -> submission_primary_ce_v2v3_meta_minseg_m06.csv\nsubmission.csv -> submission_primary_ce_v2v3_meta_minseg_m06.csv\n    Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 12 5 9 19 13 20 18 11 3 4 6 8 14 10 2 ...\n3  303  17 18 13 4 3 7 10 14 6 5 19 20 2 11 16 8 9 15 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 10 6 17 16 4 1...\n"
          ]
        }
      ]
    },
    {
      "id": "718ca0ad-df4b-4874-9270-30c663966cf0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Time-align v2/v3 before blending, quick OOF check (mult in {0.6,0.7}), then test decode + perm20 submission\n",
        "import numpy as np, json, time, os\n",
        "from pathlib import Path\n",
        "\n",
        "# Aligned loader: replaces previous load_probs by applying integer shift alignment via entropy corr (fallback: foreground mass)\n",
        "def _entropy_series(p_c_t: np.ndarray) -> np.ndarray:\n",
        "    # p: CxT (probabilities, normalized per frame). Return length-T entropy series.\n",
        "    p = np.clip(p_c_t, 1e-8, 1.0)\n",
        "    return (- (p * np.log(p)).sum(axis=0)).astype(np.float32)\n",
        "\n",
        "def _fgmass_series(p_c_t: np.ndarray) -> np.ndarray:\n",
        "    # 1 - prob of class 0 per frame\n",
        "    return (1.0 - np.clip(p_c_t[0], 0.0, 1.0)).astype(np.float32)\n",
        "\n",
        "def _best_shift_by_corr(a: np.ndarray, b: np.ndarray, max_shift: int = 15) -> int:\n",
        "    # Find s in [-max_shift, +max_shift] maximizing Pearson corr between a and b shifted by s (b shifted relative to a)\n",
        "    best_s = 0; best_r = -1e9\n",
        "    T = int(min(a.shape[0], b.shape[0]))\n",
        "    a = a[:T]; b = b[:T]\n",
        "    for s in range(-max_shift, max_shift+1):\n",
        "        if s >= 0:\n",
        "            x = a[:T - s]\n",
        "            y = b[s:T]\n",
        "        else:\n",
        "            x = a[-s:T]\n",
        "            y = b[:T + s]\n",
        "        if x.size < 8:\n",
        "            continue\n",
        "        sx = float(np.std(x)); sy = float(np.std(y))\n",
        "        if sx < 1e-6 or sy < 1e-6:\n",
        "            continue\n",
        "        r = float(np.corrcoef(x, y)[0,1])\n",
        "        if np.isfinite(r) and r > best_r:\n",
        "            best_r = r; best_s = s\n",
        "    return int(best_s)\n",
        "\n",
        "def load_probs_aligned(seq_id: int):\n",
        "    # robustly access global temps; else reload\n",
        "    global T2, T3, A\n",
        "    if 'T2' not in globals() or 'T3' not in globals() or 'A' not in globals():\n",
        "        calib = json.loads(Path('calib_all_v2v3_meta.json').read_text())\n",
        "        T2 = np.array(calib.get('T2'), dtype=np.float32)\n",
        "        T3 = np.array(calib.get('T3'), dtype=np.float32)\n",
        "        A = np.array(calib.get('A'), dtype=np.float32) if isinstance(calib.get('A', None), list) else np.full_like(T2, 0.7, dtype=np.float32)\n",
        "    cache = Path('probs_cache')\n",
        "    p2 = np.load(cache / f\"{seq_id}_ce.npy\").astype(np.float32)\n",
        "    p3 = np.load(cache / f\"{seq_id}_ce_v3.npy\").astype(np.float32)\n",
        "    # temp scale, ensure CxT\n",
        "    p2 = temp_scale(p2, T2); p3 = temp_scale(p3, T3)\n",
        "    C = int(T2.shape[0])\n",
        "    p2 = ensure_CxT(p2, C); p3 = ensure_CxT(p3, C)\n",
        "    # Normalize per frame for stability\n",
        "    p2 /= (p2.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    p3 /= (p3.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    # Compute entropy series\n",
        "    e2 = _entropy_series(p2); e3 = _entropy_series(p3)\n",
        "    s = _best_shift_by_corr(e2, e3, max_shift=15)\n",
        "    # If degenerate (no variance), fallback to foreground mass\n",
        "    if s == 0:\n",
        "        if (np.std(e2) < 1e-6) or (np.std(e3) < 1e-6):\n",
        "            f2 = _fgmass_series(p2); f3 = _fgmass_series(p3)\n",
        "            s = _best_shift_by_corr(f2, f3, max_shift=15)\n",
        "    # Apply shift: shift p3 by s relative to p2 (s>0 means p3 lags -> drop first s frames of p3)\n",
        "    if s > 0:\n",
        "        p3s = p3[:, s:]\n",
        "        p2s = p2[:, :p3s.shape[1]]\n",
        "    elif s < 0:\n",
        "        s2 = -s\n",
        "        p2s = p2[:, s2:]\n",
        "        p3s = p3[:, :p2s.shape[1]]\n",
        "    else:\n",
        "        Tm = min(p2.shape[1], p3.shape[1])\n",
        "        p2s = p2[:, :Tm]; p3s = p3[:, :Tm]\n",
        "    # Final crop to common length\n",
        "    Tm = min(p2s.shape[1], p3s.shape[1])\n",
        "    if Tm <= 0:\n",
        "        # fallback to min-crop without shift\n",
        "        Tm = min(p2.shape[1], p3.shape[1])\n",
        "        p2s = p2[:, :Tm]; p3s = p3[:, :Tm]\n",
        "    alpha = A.reshape(-1,1).astype(np.float32)\n",
        "    p = alpha * p2s + (1.0 - alpha) * p3s\n",
        "    p /= (p.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return p  # CxT\n",
        "\n",
        "# Override global loader used by decoders\n",
        "load_probs = load_probs_aligned\n",
        "print('Aligned load_probs installed (entropy-based, window +-15).', flush=True)\n",
        "\n",
        "# Quick OOF check: mult in {0.6, 0.7}, rho=None\n",
        "def quick_oof_check(mult_list=(0.6, 0.7)):\n",
        "    with open('folds_archive_cv.json') as f:\n",
        "        folds_list_local = json.load(f)\n",
        "    from collections import defaultdict\n",
        "    def compute_runlen_stats(ids):\n",
        "        agg = defaultdict(list)\n",
        "        for sid in ids:\n",
        "            y = load_frame_labels(int(sid))\n",
        "            cur, run = None, 0\n",
        "            for c in y:\n",
        "                if c==0:\n",
        "                    if cur is not None:\n",
        "                        agg[cur].append(run); cur=None; run=0\n",
        "                    continue\n",
        "                if cur is None:\n",
        "                    cur, run = int(c), 1\n",
        "                elif c==cur:\n",
        "                    run += 1\n",
        "                else:\n",
        "                    agg[cur].append(run); cur=int(c); run=1\n",
        "            if cur is not None:\n",
        "                agg[cur].append(run)\n",
        "        med = np.zeros(21, dtype=np.float32); q75 = np.zeros(21, dtype=np.float32)\n",
        "        for c in range(1,21):\n",
        "            ls = agg.get(c, [])\n",
        "            if ls:\n",
        "                arr = np.array(ls, np.float32); med[c] = float(np.median(arr)); q75[c] = float(np.percentile(arr, 75.0))\n",
        "            else:\n",
        "                med[c] = 1.0; q75[c] = 2.0\n",
        "        return med, q75\n",
        "    def build_min_dur(med, q75, mult):\n",
        "        md = np.round(med * mult).astype(np.int32)\n",
        "        md = np.clip(md, 2, np.maximum(q75.astype(np.int32), 2)); md[0]=0; return md\n",
        "    def compress_to_sequence(y_frames):\n",
        "        seq=[]; last=-1\n",
        "        for c in y_frames:\n",
        "            if c==0: continue\n",
        "            if c!=last: seq.append(int(c)); last=int(c)\n",
        "        return seq\n",
        "    def levenshtein(a,b):\n",
        "        n,m=len(a),len(b)\n",
        "        if n==0: return m\n",
        "        if m==0: return n\n",
        "        dp=list(range(m+1))\n",
        "        for i in range(1,n+1):\n",
        "            prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "            for j in range(1,m+1):\n",
        "                tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "        return dp[m]\n",
        "    print('Running quick OOF with aligned blending...', flush=True)\n",
        "    worst_by={}; mean_by={}\n",
        "    for mult in mult_list:\n",
        "        per_fold=[]\n",
        "        for fd in folds_list_local:\n",
        "            tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "            med, q75 = compute_runlen_stats(tr_ids); md = build_min_dur(med, q75, mult)\n",
        "            dists=[]; n=0; t0=time.time()\n",
        "            for sid in va_ids:\n",
        "                p = load_probs(int(sid))\n",
        "                y_hat, _, _, _ = decode_minseg_guarded(p, md, rho=None)\n",
        "                seq = compress_to_sequence(y_hat); seq_true = compress_to_sequence(load_frame_labels(int(sid)))\n",
        "                dists.append(levenshtein(seq, seq_true)); n+=1\n",
        "            mval = float(np.mean(dists)) if dists else 0.0\n",
        "            per_fold.append(mval)\n",
        "        worst_by[mult] = max(per_fold); mean_by[mult] = float(np.mean(per_fold))\n",
        "    print('OOF (aligned) summary:')\n",
        "    for mult in mult_list:\n",
        "        print(f'  mult={mult}: worst={worst_by[mult]:.3f} mean={mean_by[mult]:.3f}')\n",
        "    best_mult = min(mult_list, key=lambda m: (worst_by[m], mean_by[m]))\n",
        "    return best_mult, worst_by, mean_by\n",
        "\n",
        "t0=time.time()\n",
        "best_mult, worst_by, mean_by = quick_oof_check(mult_list=(0.6, 0.7))\n",
        "print('Chosen mult (by worst then mean):', best_mult, 'elapsed', f'{time.time()-t0:.1f}s', flush=True)\n",
        "\n",
        "# Decode test with aligned loader and perm20\n",
        "print('Decoding test with aligned blend + minseg perm20... (rho=None)')\n",
        "out_path = f'submission_aligned_minseg_perm20_m{str(best_mult).replace(\".\",\"\")}.csv'\n",
        "decode_test_and_write_perm20(best_mult=best_mult, rho=None, out_path=out_path, col_name='Sequence')\n",
        "print('Done aligned decode; wrote', out_path, flush=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned load_probs installed (entropy-based, window +-15).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running quick OOF with aligned blending...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF (aligned) summary:\n  mult=0.6: worst=4.710 mean=4.090\n  mult=0.7: worst=4.580 mean=4.114\nChosen mult (by worst then mean): 0.7 elapsed 13.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding test with aligned blend + minseg perm20... (rho=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 20 test seqs in 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 40 test seqs in 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 60 test seqs in 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 80 test seqs in 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 95 test seqs in 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_aligned_minseg_perm20_m07.csv with 95 rows; head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 3 5 9 19 13 20 18 11 4 6 8 14 10 2 7 1...\n3  303  18 17 13 4 3 10 14 6 5 19 20 7 11 16 8 2 9 15 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 6 17 16 4 15 1...\nsubmission.csv written -> submission_aligned_minseg_perm20_m07.csv\nDone aligned decode; wrote submission_aligned_minseg_perm20_m07.csv\n"
          ]
        }
      ]
    },
    {
      "id": "0f8c3770-daa9-4ae8-8f13-4661c314986e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Switch to CE+MS geometric blend submission as probe\n",
        "import shutil, os, pandas as pd\n",
        "src = 'submission_primary_ce_ms.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "shutil.copyfile(src, 'submission.csv')\n",
        "print('submission.csv ->', src)\n",
        "print(pd.read_csv('submission.csv').head())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv -> submission_primary_ce_ms.csv\n    Id                                           Sequence\n0  300  5 9 7 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 1...\n1  301  10 12 3 1 5 4 20 6 2 11 15 13 19 7 9 8 18 14 1...\n2  302  1 17 16 12 3 5 19 13 20 18 11 4 6 15 8 14 10 9...\n3  303  13 4 12 3 10 5 19 15 20 17 1 11 16 8 18 7 6 2 ...\n4  304  8 1 7 12 18 13 9 2 11 3 20 19 5 14 6 15 17 16 ...\n"
          ]
        }
      ]
    },
    {
      "id": "23eedf13-dc7e-4164-b5b4-0d4c047932d9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Micro-tweak: pre-smooth probs (k=5) and collapse ABA islands (len<=2, ratio r=1.04); quick OOF pick mult in {0.65,0.7}; decode test\n",
        "import numpy as np, json, time\n",
        "from pathlib import Path\n",
        "\n",
        "def smooth_probs_time(p: np.ndarray, k: int = 5) -> np.ndarray:\n",
        "    # p: CxT, moving average per class; renormalize per frame\n",
        "    if k <= 1: return p\n",
        "    C, T = p.shape\n",
        "    pad = k // 2\n",
        "    x = np.pad(p, ((0,0),(pad,pad)), mode='edge')\n",
        "    y = np.empty_like(p, dtype=np.float32)\n",
        "    for t in range(T):\n",
        "        y[:, t] = x[:, t:t+k].mean(axis=1)\n",
        "    y = np.clip(y, 1e-8, None)\n",
        "    y /= (y.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return y\n",
        "\n",
        "def collapse_ABA(y: np.ndarray, p: np.ndarray, max_len: int = 2, ratio: float = 1.04) -> np.ndarray:\n",
        "    # y: int path length T; p: CxT; replace A-B-A where len(B)<=max_len and mean_p(A) >= ratio*mean_p(B)\n",
        "    T = y.shape[0]\n",
        "    i = 0\n",
        "    while i < T:\n",
        "        a = y[i];\n",
        "        j = i + 1\n",
        "        while j < T and y[j] == a:\n",
        "            j += 1\n",
        "        # now [i, j-1] is A\n",
        "        k = j\n",
        "        if k >= T:\n",
        "            break\n",
        "        b = y[k]\n",
        "        m = k + 1\n",
        "        while m < T and y[m] == b:\n",
        "            m += 1\n",
        "        # [k, m-1] is B\n",
        "        if (m - k) <= max_len:\n",
        "            n = m\n",
        "            if n < T and y[n] == a:\n",
        "                # have A-B-A\n",
        "                mean_a = float(p[a, k:m].mean()) if a != 0 else 0.0\n",
        "                mean_b = float(p[b, k:m].mean()) if b != 0 else 1e-8\n",
        "                if mean_a >= ratio * mean_b:\n",
        "                    y[k:m] = a\n",
        "                    i = max(0, i - 1)\n",
        "                    continue\n",
        "        i = m\n",
        "    return y\n",
        "\n",
        "def decode_minseg_smooth_aba(p: np.ndarray, min_dur: np.ndarray, smooth_k: int = 5, aba_len: int = 2, aba_ratio: float = 1.04):\n",
        "    # Pre-smooth\n",
        "    ps = smooth_probs_time(p, k=smooth_k) if smooth_k and smooth_k > 1 else p\n",
        "    # Argmax + min-seg merge (reuse existing guarded merge with rho=None)\n",
        "    y_hat, _, _, _ = decode_minseg_guarded(ps, min_dur, rho=None)\n",
        "    # ABA collapse\n",
        "    y_hat = collapse_ABA(y_hat, ps, max_len=aba_len, ratio=aba_ratio)\n",
        "    return y_hat\n",
        "\n",
        "def quick_oof_smooth_aba(mult_list=(0.65, 0.7), smooth_k=5, aba_len=2, aba_ratio=1.04):\n",
        "    with open('folds_archive_cv.json') as f:\n",
        "        folds_local = json.load(f)\n",
        "    from collections import defaultdict\n",
        "    def compute_runlen_stats(ids):\n",
        "        agg = defaultdict(list)\n",
        "        for sid in ids:\n",
        "            y = load_frame_labels(int(sid))\n",
        "            cur, run = None, 0\n",
        "            for c in y:\n",
        "                if c == 0:\n",
        "                    if cur is not None:\n",
        "                        agg[cur].append(run); cur=None; run=0\n",
        "                    continue\n",
        "                if cur is None:\n",
        "                    cur, run = int(c), 1\n",
        "                elif c == cur:\n",
        "                    run += 1\n",
        "                else:\n",
        "                    agg[cur].append(run); cur=int(c); run=1\n",
        "            if cur is not None:\n",
        "                agg[cur].append(run)\n",
        "        med = np.zeros(21, dtype=np.float32); q75 = np.zeros(21, dtype=np.float32)\n",
        "        for c in range(1,21):\n",
        "            ls = agg.get(c, [])\n",
        "            if ls:\n",
        "                arr = np.array(ls, np.float32); med[c] = float(np.median(arr)); q75[c] = float(np.percentile(arr, 75.0))\n",
        "            else:\n",
        "                med[c] = 1.0; q75[c] = 2.0\n",
        "        return med, q75\n",
        "    def build_min_dur(med, q75, mult):\n",
        "        md = np.round(med * mult).astype(np.int32)\n",
        "        md = np.clip(md, 2, np.maximum(q75.astype(np.int32), 2)); md[0] = 0; return md\n",
        "    def compress_to_sequence(y_frames):\n",
        "        seq=[]; last=-1\n",
        "        for c in y_frames:\n",
        "            if c==0: continue\n",
        "            if c!=last: seq.append(int(c)); last=int(c)\n",
        "        return seq\n",
        "    def levenshtein(a,b):\n",
        "        n,m=len(a),len(b)\n",
        "        if n==0: return m\n",
        "        if m==0: return n\n",
        "        dp=list(range(m+1))\n",
        "        for i in range(1,n+1):\n",
        "            prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "            for j in range(1,m+1):\n",
        "                tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "        return dp[m]\n",
        "    worst_by={}; mean_by={}\n",
        "    print('Running OOF (aligned) with smoothing+ABA...')\n",
        "    for mult in mult_list:\n",
        "        per_fold=[]\n",
        "        for fd in folds_local:\n",
        "            tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "            med, q75 = compute_runlen_stats(tr_ids); md = build_min_dur(med, q75, mult)\n",
        "            dists=[]\n",
        "            for sid in va_ids:\n",
        "                p = load_probs(int(sid))  # aligned, CxT\n",
        "                y_hat = decode_minseg_smooth_aba(p, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "                seq = compress_to_sequence(y_hat); seq_true = compress_to_sequence(load_frame_labels(int(sid)))\n",
        "                dists.append(levenshtein(seq, seq_true))\n",
        "            per_fold.append(float(np.mean(dists)))\n",
        "        worst_by[mult] = max(per_fold); mean_by[mult] = float(np.mean(per_fold))\n",
        "    print('OOF smooth+ABA summary:')\n",
        "    for m in mult_list:\n",
        "        print(f'  mult={m}: worst={worst_by[m]:.3f} mean={mean_by[m]:.3f}')\n",
        "    best_mult = min(mult_list, key=lambda m: (worst_by[m], mean_by[m]))\n",
        "    return best_mult, worst_by, mean_by\n",
        "\n",
        "# Run quick OOF for smoothing+ABA and decode test\n",
        "t0=time.time()\n",
        "best_mult_s, worst_by_s, mean_by_s = quick_oof_smooth_aba(mult_list=(0.65, 0.7), smooth_k=5, aba_len=2, aba_ratio=1.04)\n",
        "print('Chosen mult (smooth+ABA):', best_mult_s, 'elapsed', f'{time.time()-t0:.1f}s')\n",
        "\n",
        "print('Decoding test with aligned blend + smooth+ABA minseg perm20...')\n",
        "def make_perm20(seq, p_c_t):\n",
        "    seen=set(); out=[]\n",
        "    for c in seq:\n",
        "        if 1<=c<=20 and c not in seen:\n",
        "            seen.add(c); out.append(int(c))\n",
        "    if len(out) < 20:\n",
        "        C = p_c_t.shape[0]; scores=[]\n",
        "        for c in range(1,21):\n",
        "            if c in seen: continue\n",
        "            s=float(p_c_t[c].sum()) if c < C else 0.0\n",
        "            scores.append((s, c))\n",
        "        scores.sort(key=lambda x: -x[0])\n",
        "        for _, c in scores:\n",
        "            if len(out) >= 20: break\n",
        "            out.append(int(c))\n",
        "    return out[:20]\n",
        "\n",
        "test_dir = Path('features3d_v3/test')\n",
        "rows=[]; ids=[]; n=0; t1=time.time()\n",
        "from collections import defaultdict\n",
        "all_train_ids=[]\n",
        "for fd in json.load(open('folds_archive_cv.json','r')):\n",
        "    all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "def compute_runlen_stats_all(ids):\n",
        "    agg=defaultdict(list)\n",
        "    for sid in ids:\n",
        "        y=load_frame_labels(int(sid)); cur=None; run=0\n",
        "        for c in y:\n",
        "            if c==0:\n",
        "                if cur is not None: agg[cur].append(run); cur=None; run=0; continue\n",
        "            if cur is None: cur=int(c); run=1\n",
        "            elif c==cur: run+=1\n",
        "            else: agg[cur].append(run); cur=int(c); run=1\n",
        "        if cur is not None: agg[cur].append(run)\n",
        "    med = np.zeros(21, np.float32); q75=np.zeros(21, np.float32)\n",
        "    for c in range(1,21):\n",
        "        ls=agg.get(c, [])\n",
        "        if ls:\n",
        "            arr=np.array(ls, np.float32); med[c]=float(np.median(arr)); q75[c]=float(np.percentile(arr, 75.0))\n",
        "        else:\n",
        "            med[c]=1.0; q75[c]=2.0\n",
        "    return med, q75\n",
        "med_all, q75_all = compute_runlen_stats_all(sorted(set(all_train_ids)))\n",
        "md_all = np.clip(np.round(med_all * float(best_mult_s)).astype(np.int32), 2, np.maximum(q75_all.astype(np.int32), 2)); md_all[0]=0\n",
        "for npz_path in sorted(test_dir.glob('*.npz')):\n",
        "    sid = int(npz_path.stem)\n",
        "    p2 = Path('probs_cache')/f\"{sid}_ce.npy\"\n",
        "    p3 = Path('probs_cache')/f\"{sid}_ce_v3.npy\"\n",
        "    if not (p2.exists() and p3.exists()):\n",
        "        continue\n",
        "    p = load_probs(int(sid))\n",
        "    y_hat = decode_minseg_smooth_aba(p, md_all, smooth_k=5, aba_len=2, aba_ratio=1.04)\n",
        "    # perm20\n",
        "    seq_raw = []\n",
        "    last=-1\n",
        "    for c in y_hat:\n",
        "        if c==0: continue\n",
        "        if c!=last: seq_raw.append(int(c)); last=int(c)\n",
        "    seq = make_perm20(seq_raw, p)\n",
        "    ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "    if (n%20)==0 or n==95:\n",
        "        print(f\".. decoded {n} test seqs in {time.time()-t1:.1f}s\", flush=True)\n",
        "import pandas as pd\n",
        "sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "out_path = f'submission_aligned_smoothABA_perm20_m{str(best_mult_s).replace(\".\",\"\")}.csv'\n",
        "sub.to_csv(out_path, index=False)\n",
        "print('Wrote', out_path, 'rows=', len(sub))\n",
        "assert len(sub)==95\n",
        "ok = sub['Sequence'].apply(lambda s: len(s.split())==20 and set(map(int, s.split()))==set(range(1,21))).all()\n",
        "assert ok, 'Permutation 1..20 check failed'\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('submission.csv written ->', out_path)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running OOF (aligned) with smoothing+ABA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF smooth+ABA summary:\n  mult=0.65: worst=4.560 mean=3.837\n  mult=0.7: worst=4.500 mean=3.861\nChosen mult (smooth+ABA): 0.7 elapsed 15.0s\nDecoding test with aligned blend + smooth+ABA minseg perm20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 20 test seqs in 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 40 test seqs in 1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 60 test seqs in 1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 80 test seqs in 1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. decoded 95 test seqs in 2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_aligned_smoothABA_perm20_m07.csv rows= 95\nsubmission.csv written -> submission_aligned_smoothABA_perm20_m07.csv\n"
          ]
        }
      ]
    },
    {
      "id": "2876f0f2-5b8a-451f-8011-501e6d747cb5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# RGB modality: inspect archives and map IDs -> video paths\n",
        "import os, tarfile, json, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "print('Preparing RGB pipeline: listing archive contents and mapping IDs...', flush=True)\n",
        "id_map_path = Path('id_to_archive.csv')\n",
        "assert id_map_path.exists(), 'id_to_archive.csv missing'\n",
        "id_map = pd.read_csv(id_map_path)\n",
        "print('id_to_archive head:')\n",
        "print(id_map.head())\n",
        "\n",
        "# Known archives\n",
        "archives = {\n",
        "    'training1.tar.gz': Path('training1.tar.gz'),\n",
        "    'training2.tar.gz': Path('training2.tar.gz'),\n",
        "    'training3.tar.gz': Path('training3.tar.gz'),\n",
        "    'validation1.tar.gz': Path('validation1.tar.gz'),\n",
        "    'validation2.tar.gz': Path('validation2.tar.gz'),\n",
        "    'validation3.tar.gz': Path('validation3.tar.gz'),\n",
        "    'test.tar.gz': Path('test.tar.gz'),\n",
        "}\n",
        "\n",
        "for k,p in archives.items():\n",
        "    if not p.exists():\n",
        "        print('MISSING', k)\n",
        "\n",
        "# Peek inside each archive (sample first 10 members) to detect video file patterns\n",
        "def list_archive_members(arc_path: Path, max_show: int = 20):\n",
        "    names = []\n",
        "    with tarfile.open(arc_path, 'r:gz') as tf:\n",
        "        for i, m in enumerate(tf):\n",
        "            if not m.isreg():\n",
        "                continue\n",
        "            names.append(m.name)\n",
        "            if len(names) >= max_show:\n",
        "                break\n",
        "    return names\n",
        "\n",
        "for name, arc in archives.items():\n",
        "    if not arc.exists():\n",
        "        continue\n",
        "    print(f'\\nArchive {name}:')\n",
        "    try:\n",
        "        sample = list_archive_members(arc, max_show=30)\n",
        "        # Show a few and collect suspected video entries\n",
        "        vids = [s for s in sample if any(s.lower().endswith(ext) for ext in ('.mp4', '.avi', '.mov', '.mkv'))]\n",
        "        print('  sample members (first up to 10):')\n",
        "        for s in sample[:10]:\n",
        "            print('   ', s)\n",
        "        print('  suspected video entries among sample:', vids[:5])\n",
        "    except Exception as e:\n",
        "        print('  error reading', name, e)\n",
        "\n",
        "# Build per-ID candidate member prefixes by probing a few IDs to learn path pattern\n",
        "probe_ids = []\n",
        "if len(id_map) > 0:\n",
        "    probe_ids = id_map['Id'].astype(int).tolist()[:5] + id_map['Id'].astype(int).tolist()[-5:]\n",
        "probe_ids = sorted(set(probe_ids))\n",
        "print('\\nProbing member paths for IDs:', probe_ids)\n",
        "\n",
        "def find_members_for_id(arc_path: Path, sid: int):\n",
        "    hits = []\n",
        "    with tarfile.open(arc_path, 'r:gz') as tf:\n",
        "        for m in tf:\n",
        "            if not m.isreg():\n",
        "                continue\n",
        "            nm = m.name\n",
        "            # Heuristics: id embedded in folder or filename, e.g., /<sid>/ or _<sid> or <sid>.\n",
        "            if f'/{sid}/' in nm or nm.endswith(f'/{sid}') or f'_{sid}_' in nm or nm.endswith(f'_{sid}.mp4') or nm.endswith(f'/{sid}.mp4') or nm.endswith(f'/{sid}.avi') or nm.endswith(f'/{sid}.mov') or nm.endswith(f'/{sid}.mkv') or f'/{sid}_' in nm:\n",
        "                hits.append(nm)\n",
        "    return hits\n",
        "\n",
        "for _, row in id_map.iterrows():\n",
        "    sid = int(row['Id'])\n",
        "    arc_name = str(row['Archive']) if 'Archive' in row else None\n",
        "    if not arc_name or arc_name not in archives:\n",
        "        continue\n",
        "    arc = archives[arc_name]\n",
        "    if not arc.exists():\n",
        "        continue\n",
        "    hits = find_members_for_id(arc, sid)\n",
        "    if hits:\n",
        "        print(f'Id {sid} in {arc_name}:', hits[:5])\n",
        "    if len(probe_ids) and sid in probe_ids:\n",
        "        print(f'  (probe) first hits for id {sid}:', hits[:10])\n",
        "\n",
        "print('\\nNext: implement cached extraction -> rgb_videos/{split}/{id}.mp4 and embeddings -> rgb_embed/{split}/{id}.npy')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing RGB pipeline: listing archive contents and mapping IDs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id_to_archive head:\n   Id  archive_group\n0   1              1\n1   3              1\n2   4              1\n3   5              1\n4   6              1\n\nArchive training1.tar.gz:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sample members (first up to 10):\n    ./Sample00001.zip\n    ./Sample00003.zip\n    ./Sample00004.zip\n    ./Sample00005.zip\n    ./Sample00006.zip\n    ./Sample00007.zip\n    ./Sample00008.zip\n    ./Sample00009.zip\n    ./Sample00010.zip\n    ./Sample00011.zip\n  suspected video entries among sample: []\n\nArchive training2.tar.gz:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sample members (first up to 10):\n    ./Sample00101.zip\n    ./Sample00102.zip\n    ./Sample00103.zip\n    ./Sample00104.zip\n    ./Sample00105.zip\n    ./Sample00106.zip\n    ./Sample00107.zip\n    ./Sample00108.zip\n    ./Sample00109.zip\n    ./Sample00110.zip\n  suspected video entries among sample: []\n\nArchive training3.tar.gz:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sample members (first up to 10):\n    ./Sample00200.zip\n    ./Sample00201.zip\n    ./Sample00202.zip\n    ./Sample00203.zip\n    ./Sample00204.zip\n    ./Sample00205.zip\n    ./Sample00206.zip\n    ./Sample00207.zip\n    ./Sample00208.zip\n    ./Sample00209.zip\n  suspected video entries among sample: []\n\nArchive validation1.tar.gz:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sample members (first up to 10):\n    Sample00410.zip\n    Sample00411.zip\n    Sample00412.zip\n    Sample00413.zip\n    Sample00414.zip\n    Sample00415.zip\n    Sample00416.zip\n    Sample00417.zip\n    Sample00418.zip\n    Sample00420.zip\n  suspected video entries among sample: []\n\nArchive validation2.tar.gz:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sample members (first up to 10):\n    Sample00510.zip\n    Sample00516.zip\n    Sample00517.zip\n    Sample00518.zip\n    Sample00519.zip\n    Sample00520.zip\n    Sample00521.zip\n    Sample00522.zip\n    Sample00523.zip\n    Sample00524.zip\n  suspected video entries among sample: []\n\nArchive validation3.tar.gz:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sample members (first up to 10):\n    Sample00621.zip\n    Sample00622.zip\n    Sample00623.zip\n    Sample00624.zip\n    Sample00625.zip\n    Sample00626.zip\n    Sample00627.zip\n    Sample00628.zip\n    Sample00629.zip\n    Sample00630.zip\n  suspected video entries among sample: []\n\nArchive test.tar.gz:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sample members (first up to 10):\n    ./Sample00300.zip\n    ./Sample00301.zip\n    ./Sample00302.zip\n    ./Sample00303.zip\n    ./Sample00304.zip\n    ./Sample00305.zip\n    ./Sample00306.zip\n    ./Sample00307.zip\n    ./Sample00308.zip\n    ./Sample00309.zip\n  suspected video entries among sample: []\n\nProbing member paths for IDs: [1, 3, 4, 5, 6, 295, 296, 297, 298, 299]\n\nNext: implement cached extraction -> rgb_videos/{split}/{id}.mp4 and embeddings -> rgb_embed/{split}/{id}.npy\n"
          ]
        }
      ]
    },
    {
      "id": "56ddc683-8a81-47ae-8d9e-b57d6ee5aaf7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# RGB modality: inspect inner ZIPs (SampleXXXXX.zip) to find RGB video filenames\n",
        "import tarfile, zipfile, io, re\n",
        "from pathlib import Path\n",
        "\n",
        "def list_zip_members_from_tar(tar_path: Path, sample_zip_name: str, max_show: int = 50):\n",
        "    print(f'Opening {tar_path} -> {sample_zip_name}', flush=True)\n",
        "    with tarfile.open(tar_path, 'r:gz') as tf:\n",
        "        m = next((m for m in tf if m.isreg() and Path(m.name).name == sample_zip_name), None)\n",
        "        if m is None:\n",
        "            print('  zip member not found')\n",
        "            return []\n",
        "        data = tf.extractfile(m).read()\n",
        "    with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "        names = zf.namelist()\n",
        "        print('  zip contains', len(names), 'files; showing up to', max_show)\n",
        "        for s in names[:max_show]:\n",
        "            print('   ', s)\n",
        "        # detect likely video files\n",
        "        vids = [s for s in names if s.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
        "        print('  suspected video files:', vids)\n",
        "        return names\n",
        "\n",
        "def id_to_sample_name(sid: int) -> str:\n",
        "    # Training IDs mapping observed from tar listing: 1->Sample00001.zip, 101->Sample00101.zip, 200->Sample00200.zip, 300->Sample00300.zip\n",
        "    return f\"Sample{sid:05d}.zip\"\n",
        "\n",
        "def id_to_tar(sid: int) -> Path | None:\n",
        "    if 1 <= sid <= 99: return Path('training1.tar.gz')\n",
        "    if 101 <= sid <= 199: return Path('training2.tar.gz')\n",
        "    if 200 <= sid <= 299: return Path('training3.tar.gz')\n",
        "    if 300 <= sid <= 399: return Path('test.tar.gz')\n",
        "    # validation archives (4xx-6xx) exist but labels only for 1..299; skip for now\n",
        "    return None\n",
        "\n",
        "# Probe a few known IDs across groups\n",
        "probe_ids = [1, 3, 10, 101, 150, 200, 250, 299, 300, 305]\n",
        "for sid in probe_ids:\n",
        "    tar_p = id_to_tar(sid)\n",
        "    if tar_p is None or not tar_p.exists():\n",
        "        print(f'ID {sid}: tar not found or unsupported ->', tar_p)\n",
        "        continue\n",
        "    zip_name = id_to_sample_name(sid)\n",
        "    try:\n",
        "        list_zip_members_from_tar(tar_p, zip_name, max_show=40)\n",
        "    except Exception as e:\n",
        "        print(f'Error reading {zip_name} from {tar_p}:', e)\n",
        "\n",
        "print('Done ZIP inspection. Next: implement extraction of RGB video file from ZIP into cache and MobileNetV2 embedding.', flush=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening training1.tar.gz -> Sample00001.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  zip contains 5 files; showing up to 40\n    Sample00001_color.mp4\n    Sample00001_depth.mp4\n    Sample00001_user.mp4\n    Sample00001_data.mat\n    Sample00001_audio.wav\n  suspected video files: ['Sample00001_color.mp4', 'Sample00001_depth.mp4', 'Sample00001_user.mp4']\nOpening training1.tar.gz -> Sample00003.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  zip contains 5 files; showing up to 40\n    Sample00003_color.mp4\n    Sample00003_depth.mp4\n    Sample00003_user.mp4\n    Sample00003_data.mat\n    Sample00003_audio.wav\n  suspected video files: ['Sample00003_color.mp4', 'Sample00003_depth.mp4', 'Sample00003_user.mp4']\nOpening training1.tar.gz -> Sample00010.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  zip contains 5 files; showing up to 40\n    Sample00010_color.mp4\n    Sample00010_depth.mp4\n    Sample00010_user.mp4\n    Sample00010_data.mat\n    Sample00010_audio.wav\n  suspected video files: ['Sample00010_color.mp4', 'Sample00010_depth.mp4', 'Sample00010_user.mp4']\nOpening training2.tar.gz -> Sample00101.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  zip contains 5 files; showing up to 40\n    Sample00101_data.mat\n    Sample00101_user.mp4\n    Sample00101_color.mp4\n    Sample00101_audio.wav\n    Sample00101_depth.mp4\n  suspected video files: ['Sample00101_user.mp4', 'Sample00101_color.mp4', 'Sample00101_depth.mp4']\nOpening training2.tar.gz -> Sample00150.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  zip contains 5 files; showing up to 40\n    Sample00150_color.mp4\n    Sample00150_depth.mp4\n    Sample00150_user.mp4\n    Sample00150_data.mat\n    Sample00150_audio.wav\n  suspected video files: ['Sample00150_color.mp4', 'Sample00150_depth.mp4', 'Sample00150_user.mp4']\nOpening training3.tar.gz -> Sample00200.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  zip contains 5 files; showing up to 40\n    Sample00200_color.mp4\n    Sample00200_depth.mp4\n    Sample00200_user.mp4\n    Sample00200_data.mat\n    Sample00200_audio.wav\n  suspected video files: ['Sample00200_color.mp4', 'Sample00200_depth.mp4', 'Sample00200_user.mp4']\nOpening training3.tar.gz -> Sample00250.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  zip contains 5 files; showing up to 40\n    Sample00250_color.mp4\n    Sample00250_depth.mp4\n    Sample00250_user.mp4\n    Sample00250_data.mat\n    Sample00250_audio.wav\n  suspected video files: ['Sample00250_color.mp4', 'Sample00250_depth.mp4', 'Sample00250_user.mp4']\nOpening training3.tar.gz -> Sample00299.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  zip contains 5 files; showing up to 40\n    Sample00299_color.mp4\n    Sample00299_depth.mp4\n    Sample00299_user.mp4\n    Sample00299_data.mat\n    Sample00299_audio.wav\n  suspected video files: ['Sample00299_color.mp4', 'Sample00299_depth.mp4', 'Sample00299_user.mp4']\nOpening test.tar.gz -> Sample00300.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  zip contains 5 files; showing up to 40\n    Sample00300_color.mp4\n    Sample00300_depth.mp4\n    Sample00300_user.mp4\n    Sample00300_data.mat\n    Sample00300_audio.wav\n  suspected video files: ['Sample00300_color.mp4', 'Sample00300_depth.mp4', 'Sample00300_user.mp4']\nOpening test.tar.gz -> Sample00305.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  zip contains 5 files; showing up to 40\n    Sample00305_color.mp4\n    Sample00305_depth.mp4\n    Sample00305_user.mp4\n    Sample00305_data.mat\n    Sample00305_audio.wav\n  suspected video files: ['Sample00305_color.mp4', 'Sample00305_depth.mp4', 'Sample00305_user.mp4']\nDone ZIP inspection. Next: implement extraction of RGB video file from ZIP into cache and MobileNetV2 embedding.\n"
          ]
        }
      ]
    },
    {
      "id": "4717a91d-133f-4e65-8ec0-f45a5e87f061",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# RGB modality: extract color.mp4 from nested archives and cache MobileNetV2 embeddings (stride=2, 112x112, fp16)\n",
        "import os, io, time, tarfile, zipfile, math, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
        "\n",
        "# Optional readers\n",
        "try:\n",
        "    import decord\n",
        "    from decord import VideoReader, cpu\n",
        "    HAS_DECORD = True\n",
        "except Exception:\n",
        "    HAS_DECORD = False\n",
        "try:\n",
        "    import cv2\n",
        "    HAS_CV2 = True\n",
        "except Exception:\n",
        "    HAS_CV2 = False\n",
        "try:\n",
        "    import imageio.v3 as iio\n",
        "    HAS_IMAGEIO = True\n",
        "except Exception:\n",
        "    HAS_IMAGEIO = False\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('CUDA available for RGB:', torch.cuda.is_available(), 'decord:', HAS_DECORD, 'cv2:', HAS_CV2, 'imageio:', HAS_IMAGEIO, flush=True)\n",
        "\n",
        "# Paths\n",
        "rgb_vid_dir = Path('rgb_videos'); (rgb_vid_dir/'train').mkdir(parents=True, exist_ok=True); (rgb_vid_dir/'test').mkdir(parents=True, exist_ok=True)\n",
        "rgb_emb_dir = Path('rgb_embed'); (rgb_emb_dir/'train').mkdir(parents=True, exist_ok=True); (rgb_emb_dir/'test').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def id_to_sample_name(sid: int) -> str:\n",
        "    return f\"Sample{sid:05d}.zip\"\n",
        "\n",
        "def id_to_tar(sid: int) -> Path | None:\n",
        "    if 1 <= sid <= 99: return Path('training1.tar.gz')\n",
        "    if 101 <= sid <= 199: return Path('training2.tar.gz')\n",
        "    if 200 <= sid <= 299: return Path('training3.tar.gz')\n",
        "    if 300 <= sid <= 399: return Path('test.tar.gz')\n",
        "    # validation sets not used for training labels here\n",
        "    return None\n",
        "\n",
        "def split_of_id(sid: int) -> str:\n",
        "    return 'train' if sid < 300 else 'test'\n",
        "\n",
        "def extract_color_mp4_to_cache(sid: int) -> Path | None:\n",
        "    split = split_of_id(sid)\n",
        "    out_path = rgb_vid_dir / split / f\"{sid}.mp4\"\n",
        "    if out_path.exists():\n",
        "        return out_path\n",
        "    tar_p = id_to_tar(sid)\n",
        "    if tar_p is None or not tar_p.exists():\n",
        "        print(f'[extract] Missing tar for id={sid}:', tar_p); return None\n",
        "    zip_name = id_to_sample_name(sid)\n",
        "    color_member = f\"Sample{sid:05d}_color.mp4\"\n",
        "    try:\n",
        "        with tarfile.open(tar_p, 'r:gz') as tf:\n",
        "            m = next((m for m in tf if m.isreg() and Path(m.name).name == zip_name), None)\n",
        "            if m is None:\n",
        "                print(f'[extract] zip {zip_name} not found in {tar_p}'); return None\n",
        "            data = tf.extractfile(m).read()\n",
        "        with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "            if color_member not in zf.namelist():\n",
        "                # fallback: find *_color.mp4\n",
        "                cand = [n for n in zf.namelist() if n.lower().endswith('_color.mp4')]\n",
        "                if not cand:\n",
        "                    print(f'[extract] color mp4 not found for id={sid}')\n",
        "                    return None\n",
        "                member = cand[0]\n",
        "            else:\n",
        "                member = color_member\n",
        "            # extract to temp then move\n",
        "            tmp = out_path.with_suffix('.mp4.tmp')\n",
        "            with zf.open(member) as fsrc, open(tmp, 'wb') as fdst:\n",
        "                shutil.copyfileobj(fsrc, fdst)\n",
        "            tmp.replace(out_path)\n",
        "        return out_path\n",
        "    except Exception as e:\n",
        "        print(f'[extract] error id={sid}:', e); return None\n",
        "\n",
        "# Preprocess and model setup\n",
        "weights = MobileNet_V2_Weights.IMAGENET1K_V1\n",
        "# Use standard ImageNet normalization constants (do not rely on weights.meta)\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "preproc = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((112,112)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
        "])\n",
        "mb = mobilenet_v2(weights=weights).features.eval().to(device)\n",
        "pool = nn.AdaptiveAvgPool2d((1,1)).to(device)\n",
        "mb.requires_grad_(False)\n",
        "\n",
        "def read_video_frames(path: Path, stride: int = 2):\n",
        "    frames = []\n",
        "    # Try decord first; if 0 frames, fallback to cv2 then imageio\n",
        "    if HAS_DECORD:\n",
        "        try:\n",
        "            vr = VideoReader(str(path), ctx=cpu(0))\n",
        "            nfr = len(vr)\n",
        "            if nfr > 0:\n",
        "                idxs = list(range(0, nfr, stride))\n",
        "                for i in idxs:\n",
        "                    img = vr[i].asnumpy()  # HWC RGB uint8\n",
        "                    frames.append(img)\n",
        "            else:\n",
        "                print('[decord] zero frames for', path, '-> fallback')\n",
        "        except Exception as e:\n",
        "            print('[decord] fail, fallback readers:', e)\n",
        "            frames = []\n",
        "    if not frames and HAS_CV2:\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(str(path))\n",
        "            ok = cap.isOpened()\n",
        "            if not ok:\n",
        "                print('[cv2] cannot open', path)\n",
        "            i = 0\n",
        "            while ok:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret: break\n",
        "                if (i % stride)==0:\n",
        "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    frames.append(frame)\n",
        "                i += 1\n",
        "            cap.release()\n",
        "            if len(frames)==0:\n",
        "                print('[cv2] zero frames for', path, '-> fallback')\n",
        "        except Exception as e:\n",
        "            print('[cv2] fail, fallback readers:', e)\n",
        "            frames = []\n",
        "    if not frames and HAS_IMAGEIO:\n",
        "        try:\n",
        "            i = 0\n",
        "            for frm in iio.imiter(str(path)):\n",
        "                if (i % stride)==0:\n",
        "                    frames.append(frm)  # already RGB HxWxC uint8\n",
        "                i += 1\n",
        "            if len(frames)==0:\n",
        "                print('[imageio] zero frames for', path)\n",
        "        except Exception as e:\n",
        "            print('[imageio] fail:', e)\n",
        "    if not frames:\n",
        "        print('[read_video_frames] FAILED to read frames from', path)\n",
        "    else:\n",
        "        print(f'[read_video_frames] {path.name}: frames={len(frames)} stride={stride} first_shape={frames[0].shape}')\n",
        "    return frames\n",
        "\n",
        "def embed_frames(frames, batch_size: int = 128, use_fp16: bool = True):\n",
        "    if not frames:\n",
        "        return np.zeros((0, 1280), dtype=np.float16)\n",
        "    embs = []\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type='cuda', enabled=(device.type=='cuda' and use_fp16)):\n",
        "        batch = []\n",
        "        for i, img in enumerate(frames, 1):\n",
        "            x = preproc(img)  # C,H,W\n",
        "            batch.append(x)\n",
        "            if (len(batch) == batch_size) or (i == len(frames)):\n",
        "                xb = torch.stack(batch, dim=0).to(device)\n",
        "                feat = mb(xb)  # B,1280,H',W'\n",
        "                feat = pool(feat).flatten(1)  # B,1280\n",
        "                embs.append(feat.detach().float().cpu())\n",
        "                batch.clear()\n",
        "    E = torch.cat(embs, dim=0).numpy().astype(np.float16)\n",
        "    return E\n",
        "\n",
        "def upsample_to_T(emb: np.ndarray, T: int) -> np.ndarray:\n",
        "    # emb: (T',D), linear interp to T along time\n",
        "    if emb.shape[0] == 0:\n",
        "        return np.zeros((T, emb.shape[1] if emb.ndim==2 else 1280), dtype=np.float16)\n",
        "    if emb.shape[0] == T:\n",
        "        return emb\n",
        "    import torch.nn.functional as F\n",
        "    x = torch.from_numpy(emb.astype(np.float32)).unsqueeze(0).transpose(1,2)  # 1, D, T'\n",
        "    y = F.interpolate(x, size=T, mode='linear', align_corners=False)  # 1, D, T\n",
        "    y = y.transpose(1,2).squeeze(0).cpu().numpy().astype(np.float16)  # T, D\n",
        "    return y\n",
        "\n",
        "def cache_rgb_embedding_for_id(sid: int, stride: int = 2, force: bool = False):\n",
        "    split = split_of_id(sid)\n",
        "    out = rgb_emb_dir / split / f\"{sid}.npy\"\n",
        "    if out.exists() and not force:\n",
        "        try:\n",
        "            arr = np.load(out, mmap_mode='r')\n",
        "            if arr.shape[0] > 0:\n",
        "                return out\n",
        "            else:\n",
        "                print(f'[cache] existing empty embedding for id={sid}, recomputing...')\n",
        "        except Exception:\n",
        "            print(f'[cache] failed to read existing embedding for id={sid}, recomputing...')\n",
        "    vpath = extract_color_mp4_to_cache(sid)\n",
        "    if vpath is None:\n",
        "        return None\n",
        "    frames = read_video_frames(vpath, stride=stride)\n",
        "    E = embed_frames(frames, batch_size=128, use_fp16=True)  # (T',1280)\n",
        "    np.save(out, E.astype(np.float16))\n",
        "    return out\n",
        "\n",
        "# Pilot: extract and embed a few IDs to validate the pipeline (force recompute if empty)\n",
        "pilot_ids = [1, 3, 10, 101, 200, 250, 299, 300]\n",
        "t0=time.time()\n",
        "ok, fail = 0, 0\n",
        "for sid in pilot_ids:\n",
        "    vpath = extract_color_mp4_to_cache(sid)\n",
        "    if vpath is None:\n",
        "        print('[pilot] FAIL id', sid); fail += 1; continue\n",
        "    _ = read_video_frames(vpath, stride=2)\n",
        "    p = cache_rgb_embedding_for_id(sid, stride=2, force=True)\n",
        "    if p is None:\n",
        "        print('[pilot] FAIL id', sid); fail += 1\n",
        "    else:\n",
        "        arr = np.load(p, mmap_mode='r')\n",
        "        print('[pilot] id', sid, '->', p, 'shape', arr.shape, 'dtype', arr.dtype)\n",
        "        ok += 1\n",
        "print(f'[pilot] done ok={ok} fail={fail} elapsed={time.time()-t0:.1f}s')\n",
        "\n",
        "print('Next steps: bulk-extract embeddings for all train/test IDs, then train per-frame linear head on frozen embeddings (fold-pure) and cache RGB probs.', flush=True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available for RGB: True decord: True cv2: True imageio: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 1.mp4: frames=627 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 1.mp4: frames=627 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pilot] id 1 -> rgb_embed/train/1.npy shape (627, 1280) dtype float16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 3.mp4: frames=559 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 3.mp4: frames=559 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pilot] id 3 -> rgb_embed/train/3.npy shape (559, 1280) dtype float16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 10.mp4: frames=613 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 10.mp4: frames=613 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pilot] id 10 -> rgb_embed/train/10.npy shape (613, 1280) dtype float16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 101.mp4: frames=643 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 101.mp4: frames=643 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pilot] id 101 -> rgb_embed/train/101.npy shape (643, 1280) dtype float16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 200.mp4: frames=574 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 200.mp4: frames=574 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pilot] id 200 -> rgb_embed/train/200.npy shape (574, 1280) dtype float16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 250.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 250.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pilot] id 250 -> rgb_embed/train/250.npy shape (606, 1280) dtype float16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 299.mp4: frames=576 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 299.mp4: frames=576 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pilot] id 299 -> rgb_embed/train/299.npy shape (576, 1280) dtype float16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 300.mp4: frames=624 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 300.mp4: frames=624 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pilot] id 300 -> rgb_embed/test/300.npy shape (624, 1280) dtype float16\n[pilot] done ok=8 fail=0 elapsed=15.4s\nNext steps: bulk-extract embeddings for all train/test IDs, then train per-frame linear head on frozen embeddings (fold-pure) and cache RGB probs.\n"
          ]
        }
      ]
    },
    {
      "id": "98c83fd7-604a-43d0-92a6-6d38121400e7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install video I/O deps (decord, opencv-headless, imageio-ffmpeg) with torch constraints\n",
        "import sys, subprocess, time, shutil, os\n",
        "def pip(*args):\n",
        "    print('> pip', ' '.join(args), flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "print('Installing decord, opencv-python-headless, imageio-ffmpeg with constraints...', flush=True)\n",
        "constr = 'constraints.txt' if os.path.exists('constraints.txt') else None\n",
        "args = ['install']\n",
        "if constr: args += ['-c', constr]\n",
        "args += ['decord==0.6.0', 'opencv-python-headless==4.10.0.84', 'imageio-ffmpeg==0.5.1']\n",
        "t0=time.time()\n",
        "pip(*args)\n",
        "print(f'Done installs in {time.time()-t0:.1f}s', flush=True)\n",
        "\n",
        "# Sanity import checks\n",
        "try:\n",
        "    import decord; from decord import VideoReader, cpu\n",
        "    print('decord:', decord.__version__)\n",
        "except Exception as e:\n",
        "    print('decord import FAIL:', e)\n",
        "try:\n",
        "    import cv2\n",
        "    print('cv2:', cv2.__version__)\n",
        "except Exception as e:\n",
        "    print('cv2 import FAIL:', e)\n",
        "try:\n",
        "    import imageio.v3 as iio, imageio_ffmpeg\n",
        "    print('imageio-ffmpeg OK:', getattr(imageio_ffmpeg, '__version__', 'unknown'))\n",
        "except Exception as e:\n",
        "    print('imageio-ffmpeg import FAIL:', e)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing decord, opencv-python-headless, imageio-ffmpeg with constraints...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install -c constraints.txt decord==0.6.0 opencv-python-headless==4.10.0.84 imageio-ffmpeg==0.5.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting decord==0.6.0\n  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 13.6/13.6 MB 92.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.10.0.84\n  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 49.9/49.9 MB 39.7 MB/s eta 0:00:00\nCollecting imageio-ffmpeg==0.5.1\n  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 26.9/26.9 MB 131.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy>=1.14.0\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 228.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting setuptools\n  Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.2/1.2 MB 550.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: setuptools, numpy, opencv-python-headless, imageio-ffmpeg, decord\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed decord-0.6.0 imageio-ffmpeg-0.5.1 numpy-1.26.4 opencv-python-headless-4.10.0.84 setuptools-80.9.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done installs in 6.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decord: 0.6.0\ncv2: 4.10.0\nimageio-ffmpeg OK: 0.5.1\n"
          ]
        }
      ]
    },
    {
      "id": "6da68406-450d-4297-97d0-1e73ffb2206b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# RGB modality: bulk extraction of MobileNetV2 embeddings for all train/test IDs\n",
        "import json, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "# Reuse helpers from cell 21: cache_rgb_embedding_for_id, split_of_id\n",
        "\n",
        "def list_ids_from_features(split: str):\n",
        "    base = Path('features3d_v3')/split\n",
        "    ids = sorted(int(p.stem) for p in base.glob('*.npz'))\n",
        "    return ids\n",
        "\n",
        "train_ids = list_ids_from_features('train')\n",
        "test_ids = list_ids_from_features('test')\n",
        "print('Found ids -> train:', len(train_ids), 'test:', len(test_ids))\n",
        "\n",
        "def bulk_extract(ids, stride=2, split_hint=None):\n",
        "    t0=time.time(); ok=0; skip=0; fail=0\n",
        "    for i, sid in enumerate(ids, 1):\n",
        "        out = (Path('rgb_embed')/(split_of_id(sid)) / f\"{sid}.npy\")\n",
        "        if out.exists():\n",
        "            try:\n",
        "                arr = np.load(out, mmap_mode='r')\n",
        "                if arr.shape[0] > 0:\n",
        "                    skip += 1\n",
        "                    if (i%20)==0 or i==len(ids):\n",
        "                        print(f'  skip {i}/{len(ids)} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "                    continue\n",
        "            except Exception:\n",
        "                pass\n",
        "        p = cache_rgb_embedding_for_id(int(sid), stride=stride, force=False)\n",
        "        if p is None:\n",
        "            fail += 1\n",
        "        else:\n",
        "            ok += 1\n",
        "        if (i%20)==0 or i==len(ids):\n",
        "            print(f'  processed {i}/{len(ids)} ok={ok} skip={skip} fail={fail} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    print(f'Done: ok={ok} skip={skip} fail={fail} total={len(ids)} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "\n",
        "print('Bulk extracting TRAIN embeddings (stride=2)...', flush=True)\n",
        "bulk_extract(train_ids, stride=2)\n",
        "print('Bulk extracting TEST embeddings (stride=2)...', flush=True)\n",
        "bulk_extract(test_ids, stride=2)\n",
        "print('RGB embedding cache complete. Next: train per-frame linear head fold-pure and cache RGB probs for fusion.', flush=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found ids -> train: 297 test: 95\nBulk extracting TRAIN embeddings (stride=2)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 4.mp4: frames=668 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 5.mp4: frames=667 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 6.mp4: frames=601 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 7.mp4: frames=562 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 8.mp4: frames=596 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 9.mp4: frames=610 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 11.mp4: frames=571 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 12.mp4: frames=592 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 13.mp4: frames=608 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 14.mp4: frames=623 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 15.mp4: frames=650 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 16.mp4: frames=585 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 17.mp4: frames=584 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 18.mp4: frames=593 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 19.mp4: frames=605 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 20.mp4: frames=589 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 21.mp4: frames=552 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 20/297 ok=17 skip=3 fail=0 elapsed=36.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 22.mp4: frames=787 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 23.mp4: frames=741 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 24.mp4: frames=745 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 25.mp4: frames=591 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 26.mp4: frames=560 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 27.mp4: frames=596 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 28.mp4: frames=637 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 29.mp4: frames=578 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 30.mp4: frames=632 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 31.mp4: frames=668 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 32.mp4: frames=646 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 33.mp4: frames=601 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 34.mp4: frames=612 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 35.mp4: frames=670 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 36.mp4: frames=599 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 37.mp4: frames=627 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 38.mp4: frames=573 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 39.mp4: frames=562 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 40.mp4: frames=549 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 41.mp4: frames=916 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 40/297 ok=37 skip=3 fail=0 elapsed=101.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 42.mp4: frames=816 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 43.mp4: frames=833 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 44.mp4: frames=768 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 45.mp4: frames=853 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 46.mp4: frames=824 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 47.mp4: frames=834 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 48.mp4: frames=823 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 49.mp4: frames=844 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 50.mp4: frames=804 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 51.mp4: frames=841 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 52.mp4: frames=781 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 53.mp4: frames=873 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 54.mp4: frames=804 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 55.mp4: frames=844 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 56.mp4: frames=773 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 57.mp4: frames=646 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 58.mp4: frames=636 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 59.mp4: frames=613 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 60.mp4: frames=663 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 61.mp4: frames=655 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 60/297 ok=57 skip=3 fail=0 elapsed=200.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 62.mp4: frames=653 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 63.mp4: frames=646 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 64.mp4: frames=644 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 65.mp4: frames=617 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 66.mp4: frames=629 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 67.mp4: frames=564 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 68.mp4: frames=565 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 69.mp4: frames=590 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 70.mp4: frames=668 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 71.mp4: frames=830 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 72.mp4: frames=810 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 73.mp4: frames=791 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 74.mp4: frames=805 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 75.mp4: frames=810 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 76.mp4: frames=745 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 77.mp4: frames=823 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 78.mp4: frames=817 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 79.mp4: frames=836 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 80.mp4: frames=858 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 81.mp4: frames=643 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 80/297 ok=77 skip=3 fail=0 elapsed=324.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 82.mp4: frames=685 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 83.mp4: frames=587 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 84.mp4: frames=717 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 85.mp4: frames=522 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 86.mp4: frames=643 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 87.mp4: frames=661 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 88.mp4: frames=623 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 89.mp4: frames=605 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 90.mp4: frames=601 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 91.mp4: frames=653 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 92.mp4: frames=599 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 93.mp4: frames=586 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 94.mp4: frames=641 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 95.mp4: frames=687 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 96.mp4: frames=541 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 97.mp4: frames=522 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 98.mp4: frames=622 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 99.mp4: frames=562 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 102.mp4: frames=640 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 100/297 ok=96 skip=4 fail=0 elapsed=446.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 103.mp4: frames=578 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 104.mp4: frames=644 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 105.mp4: frames=632 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 106.mp4: frames=586 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 107.mp4: frames=643 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 108.mp4: frames=630 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 109.mp4: frames=627 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 110.mp4: frames=647 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 111.mp4: frames=660 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 112.mp4: frames=632 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 113.mp4: frames=621 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 114.mp4: frames=652 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 115.mp4: frames=583 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 116.mp4: frames=560 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 117.mp4: frames=619 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 118.mp4: frames=625 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 119.mp4: frames=643 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 120.mp4: frames=610 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 121.mp4: frames=574 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 122.mp4: frames=582 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 120/297 ok=116 skip=4 fail=0 elapsed=478.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 123.mp4: frames=666 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 124.mp4: frames=651 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 125.mp4: frames=615 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 126.mp4: frames=621 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 127.mp4: frames=532 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 128.mp4: frames=602 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 129.mp4: frames=603 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 130.mp4: frames=674 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 131.mp4: frames=601 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 132.mp4: frames=643 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 133.mp4: frames=581 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 134.mp4: frames=638 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 135.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 136.mp4: frames=637 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 137.mp4: frames=663 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 138.mp4: frames=672 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 139.mp4: frames=671 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 140.mp4: frames=592 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 141.mp4: frames=591 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 142.mp4: frames=584 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 140/297 ok=136 skip=4 fail=0 elapsed=518.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 143.mp4: frames=613 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 144.mp4: frames=507 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 145.mp4: frames=630 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 146.mp4: frames=605 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 147.mp4: frames=603 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 148.mp4: frames=552 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 149.mp4: frames=609 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 150.mp4: frames=577 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 151.mp4: frames=602 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 152.mp4: frames=601 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 153.mp4: frames=598 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 154.mp4: frames=591 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 155.mp4: frames=596 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 156.mp4: frames=572 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 157.mp4: frames=603 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 158.mp4: frames=632 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 159.mp4: frames=545 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 160.mp4: frames=617 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 161.mp4: frames=596 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 162.mp4: frames=562 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 160/297 ok=156 skip=4 fail=0 elapsed=566.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 163.mp4: frames=560 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 164.mp4: frames=642 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 165.mp4: frames=568 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 166.mp4: frames=616 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 167.mp4: frames=577 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 168.mp4: frames=553 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 169.mp4: frames=605 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 170.mp4: frames=640 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 171.mp4: frames=615 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 172.mp4: frames=540 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 173.mp4: frames=611 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 174.mp4: frames=565 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 175.mp4: frames=566 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 176.mp4: frames=670 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 177.mp4: frames=670 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 178.mp4: frames=616 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 179.mp4: frames=522 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 180.mp4: frames=647 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 181.mp4: frames=577 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 182.mp4: frames=611 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 180/297 ok=176 skip=4 fail=0 elapsed=623.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 183.mp4: frames=650 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 184.mp4: frames=627 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 185.mp4: frames=637 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 186.mp4: frames=549 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 187.mp4: frames=598 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 188.mp4: frames=564 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 189.mp4: frames=581 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 190.mp4: frames=690 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 191.mp4: frames=655 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 192.mp4: frames=607 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 193.mp4: frames=590 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 194.mp4: frames=623 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 195.mp4: frames=593 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 196.mp4: frames=620 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 197.mp4: frames=591 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 198.mp4: frames=639 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 199.mp4: frames=615 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 201.mp4: frames=585 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 202.mp4: frames=595 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 200/297 ok=195 skip=5 fail=0 elapsed=681.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 203.mp4: frames=636 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 204.mp4: frames=628 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 205.mp4: frames=609 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 206.mp4: frames=588 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 207.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 208.mp4: frames=608 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 209.mp4: frames=689 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 210.mp4: frames=587 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 211.mp4: frames=692 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 212.mp4: frames=590 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 213.mp4: frames=601 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 214.mp4: frames=585 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 215.mp4: frames=613 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 216.mp4: frames=618 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 217.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 218.mp4: frames=548 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 219.mp4: frames=617 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 220.mp4: frames=573 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 221.mp4: frames=595 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 222.mp4: frames=627 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 220/297 ok=215 skip=5 fail=0 elapsed=713.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 223.mp4: frames=565 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 224.mp4: frames=567 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 225.mp4: frames=524 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 226.mp4: frames=563 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 227.mp4: frames=616 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 228.mp4: frames=573 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 229.mp4: frames=640 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 230.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 231.mp4: frames=622 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 232.mp4: frames=647 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 233.mp4: frames=684 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 234.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 235.mp4: frames=621 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 236.mp4: frames=579 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 237.mp4: frames=631 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 238.mp4: frames=645 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 239.mp4: frames=600 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 240.mp4: frames=665 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 241.mp4: frames=661 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 242.mp4: frames=590 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 240/297 ok=235 skip=5 fail=0 elapsed=766.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 243.mp4: frames=576 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 244.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 245.mp4: frames=613 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 246.mp4: frames=599 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 247.mp4: frames=603 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 248.mp4: frames=622 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 249.mp4: frames=625 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 251.mp4: frames=706 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 252.mp4: frames=717 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 253.mp4: frames=836 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 254.mp4: frames=616 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 255.mp4: frames=620 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 256.mp4: frames=619 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 257.mp4: frames=545 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 258.mp4: frames=549 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 259.mp4: frames=584 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 260.mp4: frames=587 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 261.mp4: frames=585 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 262.mp4: frames=660 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 260/297 ok=254 skip=6 fail=0 elapsed=827.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 263.mp4: frames=604 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 264.mp4: frames=605 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 265.mp4: frames=647 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 266.mp4: frames=603 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 267.mp4: frames=690 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 268.mp4: frames=645 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 269.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 270.mp4: frames=616 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 271.mp4: frames=530 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 272.mp4: frames=716 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 273.mp4: frames=808 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 274.mp4: frames=748 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 275.mp4: frames=577 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 276.mp4: frames=517 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 277.mp4: frames=577 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 278.mp4: frames=613 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 279.mp4: frames=573 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 280.mp4: frames=628 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 281.mp4: frames=577 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 282.mp4: frames=573 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 280/297 ok=274 skip=6 fail=0 elapsed=898.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 283.mp4: frames=632 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 284.mp4: frames=585 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 285.mp4: frames=593 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 286.mp4: frames=624 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 287.mp4: frames=586 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 288.mp4: frames=652 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 289.mp4: frames=603 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 290.mp4: frames=605 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 291.mp4: frames=569 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 292.mp4: frames=569 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 293.mp4: frames=575 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 294.mp4: frames=549 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 295.mp4: frames=610 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 296.mp4: frames=581 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 297.mp4: frames=530 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 298.mp4: frames=596 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  skip 297/297 elapsed=962.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done: ok=290 skip=7 fail=0 total=297 elapsed=962.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bulk extracting TEST embeddings (stride=2)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 301.mp4: frames=626 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 302.mp4: frames=661 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 303.mp4: frames=575 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 304.mp4: frames=614 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 305.mp4: frames=620 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 306.mp4: frames=612 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 307.mp4: frames=594 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 308.mp4: frames=565 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 309.mp4: frames=591 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 310.mp4: frames=604 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 311.mp4: frames=695 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 312.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 313.mp4: frames=607 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 314.mp4: frames=608 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 315.mp4: frames=662 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 316.mp4: frames=611 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 317.mp4: frames=631 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 318.mp4: frames=601 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 319.mp4: frames=579 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 20/95 ok=19 skip=1 fail=0 elapsed=30.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 320.mp4: frames=573 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 321.mp4: frames=589 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 322.mp4: frames=657 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 323.mp4: frames=580 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 324.mp4: frames=620 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 325.mp4: frames=621 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 326.mp4: frames=636 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 327.mp4: frames=599 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 328.mp4: frames=565 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 329.mp4: frames=609 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 330.mp4: frames=576 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 332.mp4: frames=781 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 333.mp4: frames=776 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 334.mp4: frames=704 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 335.mp4: frames=762 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 336.mp4: frames=787 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 337.mp4: frames=768 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 338.mp4: frames=854 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 339.mp4: frames=820 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 340.mp4: frames=602 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 40/95 ok=39 skip=1 fail=0 elapsed=73.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 341.mp4: frames=662 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 342.mp4: frames=529 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 343.mp4: frames=601 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 344.mp4: frames=634 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 345.mp4: frames=590 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 346.mp4: frames=615 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 347.mp4: frames=581 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 348.mp4: frames=530 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 351.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 352.mp4: frames=621 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 353.mp4: frames=604 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 354.mp4: frames=605 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 355.mp4: frames=701 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 356.mp4: frames=652 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 357.mp4: frames=608 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 358.mp4: frames=685 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 359.mp4: frames=632 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 360.mp4: frames=647 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 361.mp4: frames=596 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 362.mp4: frames=569 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 60/95 ok=59 skip=1 fail=0 elapsed=126.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 363.mp4: frames=599 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 364.mp4: frames=572 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 365.mp4: frames=655 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 366.mp4: frames=639 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 367.mp4: frames=598 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 368.mp4: frames=688 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 369.mp4: frames=602 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 370.mp4: frames=634 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 371.mp4: frames=933 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 372.mp4: frames=848 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 373.mp4: frames=639 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 374.mp4: frames=547 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 375.mp4: frames=629 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 376.mp4: frames=654 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 377.mp4: frames=602 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 378.mp4: frames=702 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 379.mp4: frames=564 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 380.mp4: frames=598 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 381.mp4: frames=606 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 383.mp4: frames=588 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 80/95 ok=79 skip=1 fail=0 elapsed=191.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 384.mp4: frames=684 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 385.mp4: frames=592 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 386.mp4: frames=578 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 389.mp4: frames=585 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 390.mp4: frames=637 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 391.mp4: frames=667 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 392.mp4: frames=618 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 393.mp4: frames=577 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 394.mp4: frames=641 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 395.mp4: frames=611 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 396.mp4: frames=628 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[read_video_frames] 397.mp4: frames=654 stride=2 first_shape=(480, 640, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[extract] Missing tar for id=401: None\n[extract] Missing tar for id=402: None\n[extract] Missing tar for id=403: None\n  processed 95/95 ok=91 skip=1 fail=3 elapsed=234.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done: ok=91 skip=1 fail=3 total=95 elapsed=234.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RGB embedding cache complete. Next: train per-frame linear head fold-pure and cache RGB probs for fusion.\n"
          ]
        }
      ]
    },
    {
      "id": "2ebe30c3-245b-4a0c-9127-09a69ce52d58",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# RGB modality: train fold-pure linear per-frame head on cached embeddings; cache OOF/test probs; fit scalar temperature per fold\n",
        "import os, json, time, math, random\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
        "\n",
        "rgb_emb_dir = Path('rgb_embed')\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "\n",
        "# Helper: load skeleton T for train/test to upsample RGB embeddings appropriately\n",
        "def get_T_train(sid: int) -> int:\n",
        "    y = np.load(labels_dir / f\"{sid}.npy\")\n",
        "    return int(y.shape[0])\n",
        "def get_T_test(sid: int) -> int:\n",
        "    # use v3 CE probs length if available; else infer from features3d_v3/test npz 'X' first dim\n",
        "    p3 = probs_cache / f\"{sid}_ce_v3.npy\"\n",
        "    if p3.exists():\n",
        "        return int(np.load(p3, mmap_mode='r').shape[1])  # CxT\n",
        "    # fallback: features3d_v3\n",
        "    d = np.load(Path('features3d_v3/test')/f\"{sid}.npz\")\n",
        "    if 'X' in d.files:\n",
        "        X = d['X']\n",
        "        # X observed shape (T, D) in this repo schema (first dim matches labels length)\n",
        "        return int(X.shape[0])\n",
        "    return None\n",
        "\n",
        "def upsample_to_T_np(E: np.ndarray, T: int) -> np.ndarray:\n",
        "    if E.shape[0] == T:\n",
        "        return E.astype(np.float32)\n",
        "    if E.shape[0] == 0:\n",
        "        return np.zeros((T, E.shape[1] if E.ndim==2 else 1280), dtype=np.float32)\n",
        "    import torch.nn.functional as Fnn\n",
        "    x = torch.from_numpy(E.astype(np.float32)).unsqueeze(0).transpose(1,2)  # 1,D,T'\n",
        "    y = Fnn.interpolate(x, size=T, mode='linear', align_corners=False).transpose(1,2).squeeze(0).contiguous()\n",
        "    return y.numpy().astype(np.float32)\n",
        "\n",
        "class RGBSeqDataset(Dataset):\n",
        "    def __init__(self, ids: List[int], split: str, chunk_len: int = 1024):\n",
        "        self.ids = list(ids)\n",
        "        self.split = split  # 'train' only here\n",
        "        self.chunk_len = chunk_len\n",
        "        # build index of (sid, start, end) chunks for efficient batching\n",
        "        self.index = []\n",
        "        for sid in self.ids:\n",
        "            E = np.load(rgb_emb_dir/'train'/f\"{sid}.npy\", mmap_mode='r')  # (T',1280)\n",
        "            T = get_T_train(sid)\n",
        "            Eu = upsample_to_T_np(np.array(E), T)  # (T,1280)\n",
        "            n = Eu.shape[0]\n",
        "            # create chunks\n",
        "            if n <= chunk_len:\n",
        "                self.index.append((sid, 0, n))\n",
        "            else:\n",
        "                s = 0\n",
        "                while s < n:\n",
        "                    e = min(n, s + chunk_len)\n",
        "                    self.index.append((sid, s, e))\n",
        "                    s = e\n",
        "        random.shuffle(self.index)\n",
        "    def __len__(self):\n",
        "        return len(self.index)\n",
        "    def __getitem__(self, i):\n",
        "        sid, s, e = self.index[i]\n",
        "        E = np.load(rgb_emb_dir/'train'/f\"{sid}.npy\", mmap_mode='r')\n",
        "        T = get_T_train(sid)\n",
        "        Eu = upsample_to_T_np(np.array(E), T)  # (T,1280)\n",
        "        y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)  # (T,)\n",
        "        x = Eu[s:e].astype(np.float32)\n",
        "        t = y[s:e]  # include background (0..20)\n",
        "        return torch.from_numpy(x), torch.from_numpy(t)\n",
        "\n",
        "class RGBLinearHead(nn.Module):\n",
        "    def __init__(self, d_in=1280, n_classes=21, p_drop=0.5):\n",
        "        super().__init__()\n",
        "        self.drop = nn.Dropout(p_drop)\n",
        "        self.fc = nn.Linear(d_in, n_classes)\n",
        "    def forward(self, x):  # x: B, L, D\n",
        "        x = self.drop(x)\n",
        "        return self.fc(x)  # B, L, C\n",
        "\n",
        "def train_rgb_fold(train_ids: List[int], val_ids: List[int],\n",
        "                    epochs: int = 12, lr: float = 1e-3, wd: float = 1e-5,\n",
        "                    chunk_len: int = 1024, batch_size: int = 1, patience: int = 3):\n",
        "    model = RGBLinearHead().to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    best_val = 1e9; bad = 0\n",
        "    for ep in range(1, epochs+1):\n",
        "        t0 = time.time()\n",
        "        model.train()\n",
        "        ds = RGBSeqDataset(train_ids, split='train', chunk_len=chunk_len)\n",
        "        dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        tr_loss = 0.0; n_tok = 0\n",
        "        for xb, yb in dl:\n",
        "            xb = xb.to(device, non_blocking=True)  # B,L,D\n",
        "            yb = yb.to(device, non_blocking=True)  # B,L\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(xb)  # B,L,C\n",
        "            loss = F.cross_entropy(logits.reshape(-1, logits.shape[-1]), yb.reshape(-1))\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            tr_loss += float(loss.item()) * yb.numel()\n",
        "            n_tok += int(yb.numel())\n",
        "        tr_loss = tr_loss / max(1, n_tok)\n",
        "        # quick val NLL\n",
        "        model.eval()\n",
        "        val_loss = 0.0; n_tok = 0\n",
        "        with torch.no_grad():\n",
        "            for sid in val_ids:\n",
        "                E = np.load(rgb_emb_dir/'train'/f\"{sid}.npy\", mmap_mode='r')\n",
        "                T = get_T_train(sid)\n",
        "                Eu = upsample_to_T_np(np.array(E), T)  # (T,1280)\n",
        "                y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)  # (T,)\n",
        "                xb = torch.from_numpy(Eu).unsqueeze(0).to(device)  # 1,T,D\n",
        "                logits = model(xb)  # 1,T,C\n",
        "                ll = F.cross_entropy(logits.reshape(-1, logits.shape[-1]), torch.from_numpy(y).to(device))\n",
        "                val_loss += float(ll.item()) * int(T)\n",
        "                n_tok += int(T)\n",
        "        val_loss = val_loss / max(1, n_tok)\n",
        "        print(f\"[RGB fold] ep {ep:02d} tr_nll={tr_loss:.4f} val_nll={val_loss:.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "        if val_loss < best_val - 1e-4:\n",
        "            best_val = val_loss; bad = 0\n",
        "            torch.save(model.state_dict(), 'rgb_head_tmp.pth')\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience:\n",
        "                break\n",
        "    # load best\n",
        "    model.load_state_dict(torch.load('rgb_head_tmp.pth', map_location=device))\n",
        "    return model\n",
        "\n",
        "def infer_probs_for_ids(model: nn.Module, ids: List[int], split: str, out_suffix: str):\n",
        "    # Import embed cache helper from previous cell (21) if available\n",
        "    from __main__ import cache_rgb_embedding_for_id  # notebook context\n",
        "    model.eval()\n",
        "    saved = 0; t0 = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, sid in enumerate(ids, 1):\n",
        "            if split == 'train':\n",
        "                T = get_T_train(sid)\n",
        "                emb_path = rgb_emb_dir/'train'/f\"{sid}.npy\"\n",
        "            else:\n",
        "                T = get_T_test(sid)\n",
        "                emb_path = rgb_emb_dir/'test'/f\"{sid}.npy\"\n",
        "            if not emb_path.exists():\n",
        "                # attempt on-the-fly embedding extraction (stride=2) if missing\n",
        "                try:\n",
        "                    cache_rgb_embedding_for_id(int(sid), stride=2, force=False)\n",
        "                except Exception as e:\n",
        "                    print(f\"  [RGB infer] missing embedding for id={sid}, skip. err={e}\")\n",
        "                    continue\n",
        "            if not emb_path.exists():\n",
        "                print(f\"  [RGB infer] still missing embedding for id={sid}, skipping.\")\n",
        "                continue\n",
        "            E = np.load(emb_path, mmap_mode='r')\n",
        "            Eu = upsample_to_T_np(np.array(E), T)  # (T,1280)\n",
        "            xb = torch.from_numpy(Eu).unsqueeze(0).to(device)  # 1,T,D\n",
        "            logits = model(xb)[0]  # T,C\n",
        "            p = logits.softmax(dim=-1).cpu().numpy().astype(np.float32)  # T,C\n",
        "            p = p / (p.sum(axis=1, keepdims=True) + 1e-8)\n",
        "            np.save(probs_cache/f\"{sid}{out_suffix}\", p.T)  # save CxT\n",
        "            saved += 1\n",
        "            if (i%20)==0 or i==len(ids):\n",
        "                print(f\"  saved {saved}/{len(ids)} split={split} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "def fit_scalar_temperature_on_val(val_ids: List[int], suffix: str) -> float:\n",
        "    # find T in [0.8, 1.5] grid minimizing NLL on RGB val probs (pre-calibration)\n",
        "    grid = [round(x,2) for x in np.linspace(0.8, 1.5, 15)]\n",
        "    best_T = 1.0; best_nll = 1e18\n",
        "    for Tval in grid:\n",
        "        nll = 0.0; n_tok = 0\n",
        "        for sid in val_ids:\n",
        "            p = np.load(probs_cache/f\"{sid}{suffix}\")  # CxT\n",
        "            y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)  # (T,)\n",
        "            logp = np.log(np.clip(p, 1e-8, 1.0)) / float(Tval)\n",
        "            q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)  # CxT\n",
        "            # gather -log q[y_t, t]\n",
        "            idx = (y >= 0) & (y < q.shape[0])\n",
        "            yy = y[idx]\n",
        "            nll += -float(np.log(q[yy, np.nonzero(idx)[0]] + 1e-8).sum())\n",
        "            n_tok += int(idx.sum())\n",
        "        if n_tok > 0:\n",
        "            nll /= float(n_tok)\n",
        "            if nll < best_nll:\n",
        "                best_nll = nll; best_T = Tval\n",
        "    print(f\"[Temp] best scalar T={best_T} NLL={best_nll:.4f} on {len(val_ids)} val ids\", flush=True)\n",
        "    return float(best_T)\n",
        "\n",
        "def apply_scalar_temperature(ids: List[int], suffix: str, Tscalar: float):\n",
        "    for sid in ids:\n",
        "        p = np.load(probs_cache/f\"{sid}{suffix}\")  # CxT\n",
        "        logp = np.log(np.clip(p, 1e-8, 1.0)) / float(Tscalar)\n",
        "        q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "        np.save(probs_cache/f\"{sid}{suffix}\", q.astype(np.float32))\n",
        "\n",
        "# Main fold loop\n",
        "with open('folds_archive_cv.json') as f:\n",
        "    folds_list = json.load(f)\n",
        "print('Training RGB linear head per fold, caching OOF and test probs...', flush=True)\n",
        "# Use test.csv for test id order (avoid stray ids like 401..403) \n",
        "test_ids_list = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "# For test accumulation, save per-fold files as _rgb_f{fold}.npy; later average to _rgb.npy\n",
        "for fd in folds_list:\n",
        "    fidx = int(fd['fold'])\n",
        "    tr_ids = list(map(int, fd['train_ids']))\n",
        "    va_ids = list(map(int, fd['val_ids']))\n",
        "    print(f'Fold {fidx}: train={len(tr_ids)} val={len(va_ids)}', flush=True)\n",
        "    model = train_rgb_fold(tr_ids, va_ids, epochs=12, lr=1e-3, wd=1e-5, chunk_len=1024, batch_size=1, patience=3)\n",
        "    # Inference OOF (val) -> save as {id}_rgb.npy (CxT)\n",
        "    infer_probs_for_ids(model, va_ids, split='train', out_suffix='_rgb.npy')\n",
        "    # Inference TEST -> save per-fold {id}_rgb_f{fidx}.npy, using test.csv ids\n",
        "    infer_probs_for_ids(model, test_ids_list, split='test', out_suffix=f'_rgb_f{fidx}.npy')\n",
        "    # Fit scalar temperature on val and apply to val probs\n",
        "    Tbest = fit_scalar_temperature_on_val(va_ids, suffix='_rgb.npy')\n",
        "    apply_scalar_temperature(va_ids, suffix='_rgb.npy', Tscalar=Tbest)\n",
        "    # Save fold temperature for later applying to test fusion if needed\n",
        "    Path(f'rgb_temp_fold{fidx}.json').write_text(json.dumps({'T': Tbest}))\n",
        "print('Done RGB head training per fold.')\n",
        "print('Next: average test per-fold RGB probs to probs_cache/{id}_rgb.npy and proceed to fusion (alpha grid) and decoding.', flush=True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RGB linear head per fold, caching OOF and test probs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: train=199 val=98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 01 tr_nll=3.2055 val_nll=3.7633 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 02 tr_nll=3.0332 val_nll=3.7617 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 03 tr_nll=2.9287 val_nll=3.6381 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 04 tr_nll=2.9361 val_nll=3.0754 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 05 tr_nll=2.8915 val_nll=3.9235 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 06 tr_nll=2.8633 val_nll=3.4826 elapsed=4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 07 tr_nll=2.8273 val_nll=3.5811 elapsed=3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/98 split=train elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_9704/1401274909.py:136: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('rgb_head_tmp.pth', map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/98 split=train elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/98 split=train elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/98 split=train elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 98/98 split=train elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[extract] Missing tar for id=401: None\n  [RGB infer] still missing embedding for id=401, skipping.\n[extract] Missing tar for id=402: None\n  [RGB infer] still missing embedding for id=402, skipping.\n[extract] Missing tar for id=403: None\n  [RGB infer] still missing embedding for id=403, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp] best scalar T=1.5 NLL=2.9172 on 98 val ids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: train=198 val=99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 01 tr_nll=3.1472 val_nll=3.2586 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 02 tr_nll=2.9689 val_nll=3.5512 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 03 tr_nll=2.8852 val_nll=3.2042 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 04 tr_nll=2.8335 val_nll=3.3165 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 05 tr_nll=2.8508 val_nll=3.2487 elapsed=4.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 06 tr_nll=2.8143 val_nll=3.5368 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/99 split=train elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/99 split=train elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/99 split=train elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/99 split=train elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 99/99 split=train elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[extract] Missing tar for id=401: None\n  [RGB infer] still missing embedding for id=401, skipping.\n[extract] Missing tar for id=402: None\n  [RGB infer] still missing embedding for id=402, skipping.\n[extract] Missing tar for id=403: None\n  [RGB infer] still missing embedding for id=403, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp] best scalar T=1.5 NLL=3.0672 on 99 val ids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: train=197 val=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 01 tr_nll=2.7794 val_nll=3.7412 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 02 tr_nll=2.5739 val_nll=3.8235 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 03 tr_nll=2.5227 val_nll=4.3732 elapsed=4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB fold] ep 04 tr_nll=2.5053 val_nll=3.9944 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/100 split=train elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/100 split=train elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/100 split=train elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/100 split=train elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 100/100 split=train elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[extract] Missing tar for id=401: None\n  [RGB infer] still missing embedding for id=401, skipping.\n[extract] Missing tar for id=402: None\n  [RGB infer] still missing embedding for id=402, skipping.\n[extract] Missing tar for id=403: None\n  [RGB infer] still missing embedding for id=403, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp] best scalar T=1.5 NLL=3.3059 on 100 val ids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done RGB head training per fold.\nNext: average test per-fold RGB probs to probs_cache/{id}_rgb.npy and proceed to fusion (alpha grid) and decoding.\n"
          ]
        }
      ]
    },
    {
      "id": "f1020864-f2d7-46ff-8adb-8149ef9fc155",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# RGB fusion: OOF alpha tuning (geometric PoE), align RGB->skeleton, decode, and test submission\n",
        "import numpy as np, json, time, os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "\n",
        "# Utilities: ensure CxT, entropy/fg-mass, best shift, align\n",
        "def ensure_CxT(p: np.ndarray, C: int) -> np.ndarray:\n",
        "    if p.ndim != 2:\n",
        "        raise ValueError(f'Expected 2D probs, got {p.shape}')\n",
        "    if p.shape[0] == C:\n",
        "        return p.astype(np.float32)\n",
        "    if p.shape[1] == C:\n",
        "        return p.T.astype(np.float32)\n",
        "    raise ValueError(f'Cannot ensure CxT; probs shape {p.shape}, C={C}')\n",
        "\n",
        "def entropy_series(p_c_t: np.ndarray) -> np.ndarray:\n",
        "    p = np.clip(p_c_t, 1e-8, 1.0)\n",
        "    return (- (p * np.log(p)).sum(axis=0)).astype(np.float32)\n",
        "\n",
        "def fg_series(p_c_t: np.ndarray) -> np.ndarray:\n",
        "    return (1.0 - np.clip(p_c_t[0], 0.0, 1.0)).astype(np.float32)\n",
        "\n",
        "def best_shift_by_corr(a: np.ndarray, b: np.ndarray, max_shift: int = 15) -> int:\n",
        "    best_s = 0; best_r = -1e9\n",
        "    T = int(min(a.shape[0], b.shape[0])); a = a[:T]; b = b[:T]\n",
        "    for s in range(-max_shift, max_shift+1):\n",
        "        if s >= 0:\n",
        "            x = a[:T - s]; y = b[s:T]\n",
        "        else:\n",
        "            x = a[-s:T]; y = b[:T + s]\n",
        "        if x.size < 8: continue\n",
        "        sx = float(np.std(x)); sy = float(np.std(y))\n",
        "        if sx < 1e-6 or sy < 1e-6: continue\n",
        "        r = float(np.corrcoef(x, y)[0,1])\n",
        "        if np.isfinite(r) and r > best_r:\n",
        "            best_r = r; best_s = s\n",
        "    return int(best_s)\n",
        "\n",
        "def align_rgb_to_skel(p_rgb: np.ndarray, p_skel: np.ndarray, max_shift: int = 15) -> np.ndarray:\n",
        "    # Inputs CxT, already normalized per frame\n",
        "    e_r = entropy_series(p_rgb); e_s = entropy_series(p_skel)\n",
        "    s = best_shift_by_corr(e_r, e_s, max_shift=max_shift)\n",
        "    if s == 0 and (np.std(e_r) < 1e-6 or np.std(e_s) < 1e-6):\n",
        "        f_r = fg_series(p_rgb); f_s = fg_series(p_skel)\n",
        "        s = best_shift_by_corr(f_r, f_s, max_shift=max_shift)\n",
        "    if s > 0:\n",
        "        pr = p_rgb[:, s:]; ps = p_skel[:, :pr.shape[1]]\n",
        "    elif s < 0:\n",
        "        s2 = -s; ps = p_skel[:, s2:]; pr = p_rgb[:, :ps.shape[1]]\n",
        "    else:\n",
        "        Tm = min(p_rgb.shape[1], p_skel.shape[1]); pr = p_rgb[:, :Tm]; ps = p_skel[:, :Tm]\n",
        "    Tm = min(pr.shape[1], ps.shape[1])\n",
        "    pr = pr[:, :Tm]; ps = ps[:, :Tm]\n",
        "    # renorm\n",
        "    pr = pr / (pr.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    ps = ps / (ps.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return pr, ps\n",
        "\n",
        "# Geometric fusion (product of experts) in log-space with weight alpha\n",
        "def fuse_geometric(p_skel: np.ndarray, p_rgb: np.ndarray, alpha: float) -> np.ndarray:\n",
        "    p_s = np.clip(p_skel, 1e-8, 1.0); p_r = np.clip(p_rgb, 1e-8, 1.0)\n",
        "    logp = (1.0 - float(alpha)) * np.log(p_s) + float(alpha) * np.log(p_r)\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "# Decoder pieces reused from earlier cells: compute_runlen_stats, build_min_dur, decode_minseg_smooth_aba, load_frame_labels, make_perm20\n",
        "from collections import defaultdict\n",
        "def compute_runlen_stats(ids):\n",
        "    agg = defaultdict(list)\n",
        "    for sid in ids:\n",
        "        y = load_frame_labels(int(sid))\n",
        "        cur=None; run=0\n",
        "        for c in y:\n",
        "            if c==0:\n",
        "                if cur is not None: agg[cur].append(run); cur=None; run=0\n",
        "                continue\n",
        "            if cur is None: cur=int(c); run=1\n",
        "            elif c==cur: run+=1\n",
        "            else: agg[cur].append(run); cur=int(c); run=1\n",
        "        if cur is not None: agg[cur].append(run)\n",
        "    med = np.zeros(21, np.float32); q75 = np.zeros(21, np.float32)\n",
        "    for c in range(1,21):\n",
        "        ls = agg.get(c, [])\n",
        "        if ls:\n",
        "            arr = np.array(ls, np.float32); med[c]=float(np.median(arr)); q75[c]=float(np.percentile(arr, 75.0))\n",
        "        else:\n",
        "            med[c]=1.0; q75[c]=2.0\n",
        "    return med, q75\n",
        "\n",
        "def build_min_dur(med, q75, mult):\n",
        "    md = np.round(med * float(mult)).astype(np.int32)\n",
        "    md = np.clip(md, 2, np.maximum(q75.astype(np.int32), 2)); md[0]=0; return md\n",
        "\n",
        "def compress_to_sequence(y_frames):\n",
        "    seq=[]; last=-1\n",
        "    for c in y_frames:\n",
        "        if c==0: continue\n",
        "        if c!=last: seq.append(int(c)); last=int(c)\n",
        "    return seq\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "# Helper: temperature scale probs (CxT) with scalar T\n",
        "def temp_scale_array(p: np.ndarray, T: float) -> np.ndarray:\n",
        "    q = np.exp(np.log(np.clip(p, 1e-8, 1.0)) / float(T))\n",
        "    q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "# Average test per-fold RGB probs -> {id}_rgb.npy, applying per-fold temperature first\n",
        "def average_test_rgb_folds():\n",
        "    # Load per-fold temperatures\n",
        "    Ts = []\n",
        "    for f in range(3):\n",
        "        jf = Path(f'rgb_temp_fold{f}.json')\n",
        "        if jf.exists():\n",
        "            try:\n",
        "                Ts.append(float(json.loads(jf.read_text())['T']))\n",
        "            except Exception:\n",
        "                Ts.append(1.0)\n",
        "        else:\n",
        "            Ts.append(1.0)\n",
        "    # Use test.csv to define the canonical id list (avoid stray 401..403 etc.)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    n_avg=0\n",
        "    for sid in test_ids:\n",
        "        outs = [probs_cache/f\"{sid}_rgb_f0.npy\", probs_cache/f\"{sid}_rgb_f1.npy\", probs_cache/f\"{sid}_rgb_f2.npy\"]\n",
        "        arrs=[]\n",
        "        for idx, p in enumerate(outs):\n",
        "            if p.exists():\n",
        "                a = np.load(p, mmap_mode='r').astype(np.float32)\n",
        "                a = temp_scale_array(a, Ts[idx])  # apply per-fold T\n",
        "                arrs.append(a)\n",
        "        if not arrs:\n",
        "            continue\n",
        "        # align lengths if small drift\n",
        "        Tm = min(a.shape[1] for a in arrs)\n",
        "        arrs = [a[:, :Tm].astype(np.float32) for a in arrs]\n",
        "        m = np.mean(arrs, axis=0)\n",
        "        m = m / (m.sum(axis=0, keepdims=True) + 1e-8)\n",
        "        np.save(probs_cache/f\"{sid}_rgb.npy\", m.astype(np.float32))\n",
        "        n_avg += 1\n",
        "    print('Averaged test RGB per-fold files ->', n_avg, 'ids')\n",
        "\n",
        "# OOF alpha tuning: use leave-one-archive-out folds, align RGB to skeleton per id, fuse, decode, score\n",
        "def oof_alpha_tune(alpha_list=(0.22,0.24,0.25,0.26,0.28,0.30), mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04):\n",
        "    with open('folds_archive_cv.json') as f:\n",
        "        folds_list_local = json.load(f)\n",
        "    worst_by={}; mean_by={}\n",
        "    for alpha in alpha_list:\n",
        "        per_fold=[]\n",
        "        print(f'[OOF] alpha={alpha}', flush=True)\n",
        "        for fd in folds_list_local:\n",
        "            tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "            med, q75 = compute_runlen_stats(tr_ids); md = build_min_dur(med, q75, mult=mult)\n",
        "            dists=[]; n=0; t0=time.time()\n",
        "            for sid in va_ids:\n",
        "                # Load RGB OOF (already at skeleton T): CxT\n",
        "                p_rgb = np.load(probs_cache/f\"{sid}_rgb.npy\").astype(np.float32)\n",
        "                # Load skeleton probs (aligned v2+v3) via load_probs (already installed to aligned version)\n",
        "                p_skel = load_probs(int(sid)).astype(np.float32)\n",
        "                # Align RGB to skeleton\n",
        "                pr, ps = align_rgb_to_skel(p_rgb, p_skel, max_shift=15)\n",
        "                # Fuse\n",
        "                pf = fuse_geometric(ps, pr, alpha=alpha)  # CxT\n",
        "                # Decode\n",
        "                y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "                seq = compress_to_sequence(y_hat); seq_true = compress_to_sequence(load_frame_labels(int(sid)))\n",
        "                dists.append(levenshtein(seq, seq_true)); n+=1\n",
        "            mval = float(np.mean(dists)) if dists else 0.0\n",
        "            per_fold.append(mval)\n",
        "            print(f'  fold {fd[\"fold\"]}: mean={mval:.3f} (n={n})', flush=True)\n",
        "        worst_by[alpha] = max(per_fold); mean_by[alpha] = float(np.mean(per_fold))\n",
        "        print(f'  -> worst={worst_by[alpha]:.3f} mean={mean_by[alpha]:.3f}', flush=True)\n",
        "    print('OOF alpha tuning summary (lower better):')\n",
        "    for a in alpha_list:\n",
        "        print(f'  alpha={a}: worst={worst_by[a]:.3f} mean={mean_by[a]:.3f}')\n",
        "    best_alpha = min(alpha_list, key=lambda a: (worst_by[a], mean_by[a]))\n",
        "    print('Chosen alpha (by worst then mean):', best_alpha)\n",
        "    return best_alpha, worst_by, mean_by\n",
        "\n",
        "# Test fusion + decode + perm20 submission\n",
        "def fuse_decode_test(alpha: float, mult: float = 0.7, smooth_k: int = 5, aba_len: int = 2, aba_ratio: float = 1.04, out_csv: str = 'submission_rgb_fused.csv'):\n",
        "    # duration stats from all training ids\n",
        "    all_train_ids=[]\n",
        "    for fd in json.load(open('folds_archive_cv.json','r')):\n",
        "        all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "    med, q75 = compute_runlen_stats(sorted(set(all_train_ids))); md = build_min_dur(med, q75, mult=mult)\n",
        "    rows=[]; ids=[]; n=0; t0=time.time()\n",
        "    # Use test.csv canonical ids to ensure 95 rows even if some RGB missing\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    for sid in test_ids:\n",
        "        # need skeleton probs and rgb probs (rgb optional)\n",
        "        p2 = probs_cache/f\"{sid}_ce.npy\"; p3 = probs_cache/f\"{sid}_ce_v3.npy\"; prgb = probs_cache/f\"{sid}_rgb.npy\"\n",
        "        if not (p2.exists() and p3.exists()):\n",
        "            continue  # cannot decode without skeleton\n",
        "        p_skel = load_probs(int(sid)).astype(np.float32)  # aligned v2+v3\n",
        "        if prgb.exists():\n",
        "            p_rgb = np.load(prgb).astype(np.float32)\n",
        "            pr, ps = align_rgb_to_skel(p_rgb, p_skel, max_shift=15)\n",
        "            pf = fuse_geometric(ps, pr, alpha=alpha)\n",
        "        else:\n",
        "            # fallback: no RGB -> use skeleton only\n",
        "            pf = p_skel\n",
        "        y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "        # perm20\n",
        "        seq_raw=[]; last=-1\n",
        "        for c in y_hat:\n",
        "            if c==0: continue\n",
        "            if c!=last: seq_raw.append(int(c)); last=int(c)\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95:\n",
        "            print(f'  test fused decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, 'rows=', len(sub), 'head:\\n', sub.head())\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    # also mirror to submission.csv for convenience\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('Step 1: Calibrate per-fold TEST RGB probs and average -> _rgb.npy ...', flush=True)\n",
        "average_test_rgb_folds()\n",
        "print('Step 2: OOF alpha tuning (geometric fusion, tight grid) ...', flush=True)\n",
        "best_alpha, worst_by, mean_by = oof_alpha_tune(alpha_list=(0.22,0.24,0.25,0.26,0.28,0.30), mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04)\n",
        "print('Step 3: Fuse + decode test with best alpha ...', flush=True)\n",
        "out_csv = f'submission_fused_rgb_alpha{str(best_alpha).replace(\".\", \"\")}.csv'\n",
        "fuse_decode_test(alpha=best_alpha, mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04, out_csv=out_csv)\n",
        "print('RGB fusion pipeline complete.')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Calibrate per-fold TEST RGB probs and average -> _rgb.npy ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averaged test RGB per-fold files -> 92 ids\nStep 2: OOF alpha tuning (geometric fusion, tight grid) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.041 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.040 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.460 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.460 mean=3.847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.990 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.051 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.400 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.400 mean=3.813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.949 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.040 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.350 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.350 mean=3.780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.959 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.071 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.340 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.340 mean=3.790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.990 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.061 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.410 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.410 mean=3.820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.980 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.162 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.390 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.390 mean=3.844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF alpha tuning summary (lower better):\n  alpha=0.22: worst=4.460 mean=3.847\n  alpha=0.24: worst=4.400 mean=3.813\n  alpha=0.25: worst=4.350 mean=3.780\n  alpha=0.26: worst=4.340 mean=3.790\n  alpha=0.28: worst=4.410 mean=3.820\n  alpha=0.3: worst=4.390 mean=3.844\nChosen alpha (by worst then mean): 0.26\nStep 3: Fuse + decode test with best alpha ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  test fused decoded 20/95 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  test fused decoded 40/95 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  test fused decoded 60/95 elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  test fused decoded 80/95 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  test fused decoded 95/95 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_fused_rgb_alpha026.csv rows= 95 head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 12 5 9 19 13 20 18 11 3 4 6 8 14 10 2 ...\n3  303  18 13 4 3 10 14 6 5 19 20 17 2 11 16 9 7 12 1 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 6 17 16 4 12 1...\nsubmission.csv written -> submission_fused_rgb_alpha026.csv\nRGB fusion pipeline complete.\n"
          ]
        }
      ]
    },
    {
      "id": "49685a7a-2ee5-4351-81d2-b2b947ae3cd0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# RGB fusion alt: Arithmetic blend OOF tuning and submission\n",
        "import numpy as np, json, time, os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "probs_cache = Path('probs_cache')\n",
        "\n",
        "def fuse_arithmetic(p_skel: np.ndarray, p_rgb: np.ndarray, alpha: float) -> np.ndarray:\n",
        "    q = (1.0 - float(alpha)) * np.clip(p_skel, 1e-8, 1.0) + float(alpha) * np.clip(p_rgb, 1e-8, 1.0)\n",
        "    q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def oof_alpha_tune_arith(alpha_list=(0.22,0.24,0.25,0.26,0.28,0.30), mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04):\n",
        "    with open('folds_archive_cv.json') as f:\n",
        "        folds_list_local = json.load(f)\n",
        "    worst_by={}; mean_by={}\n",
        "    for alpha in alpha_list:\n",
        "        per_fold=[]\n",
        "        print(f'[OOF-ARITH] alpha={alpha}', flush=True)\n",
        "        for fd in folds_list_local:\n",
        "            tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "            med, q75 = compute_runlen_stats(tr_ids); md = build_min_dur(med, q75, mult=mult)\n",
        "            dists=[]; n=0\n",
        "            for sid in va_ids:\n",
        "                p_rgb = np.load(probs_cache/f\"{sid}_rgb.npy\").astype(np.float32)\n",
        "                p_skel = load_probs(int(sid)).astype(np.float32)\n",
        "                pr, ps = align_rgb_to_skel(p_rgb, p_skel, max_shift=15)\n",
        "                pf = fuse_arithmetic(ps, pr, alpha=alpha)\n",
        "                y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "                seq = compress_to_sequence(y_hat); seq_true = compress_to_sequence(load_frame_labels(int(sid)))\n",
        "                dists.append(levenshtein(seq, seq_true)); n+=1\n",
        "            mval = float(np.mean(dists)) if dists else 0.0\n",
        "            per_fold.append(mval)\n",
        "            print(f'  fold {fd[\"fold\"]}: mean={mval:.3f} (n={n})', flush=True)\n",
        "        worst_by[alpha] = max(per_fold); mean_by[alpha] = float(np.mean(per_fold))\n",
        "        print(f'  -> worst={worst_by[alpha]:.3f} mean={mean_by[alpha]:.3f}', flush=True)\n",
        "    print('OOF-ARITH alpha tuning summary (lower better):')\n",
        "    for a in alpha_list:\n",
        "        print(f'  alpha={a}: worst={worst_by[a]:.3f} mean={mean_by[a]:.3f}')\n",
        "    best_alpha = min(alpha_list, key=lambda a: (worst_by[a], mean_by[a]))\n",
        "    print('Chosen alpha (ARITH, by worst then mean):', best_alpha)\n",
        "    return best_alpha, worst_by, mean_by\n",
        "\n",
        "def fuse_decode_test_arith(alpha: float, mult: float = 0.7, smooth_k: int = 5, aba_len: int = 2, aba_ratio: float = 1.04, out_csv: str = 'submission_fused_rgb_arith.csv'):\n",
        "    all_train_ids=[]\n",
        "    for fd in json.load(open('folds_archive_cv.json','r')):\n",
        "        all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "    med, q75 = compute_runlen_stats(sorted(set(all_train_ids))); md = build_min_dur(med, q75, mult=mult)\n",
        "    rows=[]; ids=[]; n=0; t0=time.time()\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    for sid in test_ids:\n",
        "        p2 = probs_cache/f\"{sid}_ce.npy\"; p3 = probs_cache/f\"{sid}_ce_v3.npy\"; prgb = probs_cache/f\"{sid}_rgb.npy\"\n",
        "        if not (p2.exists() and p3.exists()):\n",
        "            continue\n",
        "        p_skel = load_probs(int(sid)).astype(np.float32)\n",
        "        if prgb.exists():\n",
        "            p_rgb = np.load(prgb).astype(np.float32)\n",
        "            pr, ps = align_rgb_to_skel(p_rgb, p_skel, max_shift=15)\n",
        "            pf = fuse_arithmetic(ps, pr, alpha=alpha)\n",
        "        else:\n",
        "            pf = p_skel\n",
        "        y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "        seq_raw=[]; last=-1\n",
        "        for c in y_hat:\n",
        "            if c==0: continue\n",
        "            if c!=last: seq_raw.append(int(c)); last=int(c)\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95:\n",
        "            print(f'  [ARITH] test fused decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, 'rows=', len(sub), 'head:\\n', sub.head())\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('ARITH Step 1: OOF alpha tuning (tight grid) ...', flush=True)\n",
        "best_alpha_arith, worst_by_arith, mean_by_arith = oof_alpha_tune_arith(alpha_list=(0.22,0.24,0.25,0.26,0.28,0.30), mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04)\n",
        "print('ARITH Step 2: Fuse + decode test with best alpha ...', flush=True)\n",
        "out_csv_arith = f'submission_fused_rgb_arith_alpha{str(best_alpha_arith).replace(\".\", \"\")}.csv'\n",
        "fuse_decode_test_arith(alpha=best_alpha_arith, mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04, out_csv=out_csv_arith)\n",
        "print('Arithmetic fusion pipeline complete.')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARITH Step 1: OOF alpha tuning (tight grid) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ARITH] alpha=0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.980 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.020 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.480 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.480 mean=3.827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ARITH] alpha=0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.949 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.010 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.520 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.520 mean=3.826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ARITH] alpha=0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.929 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=2.990 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.530 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.530 mean=3.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ARITH] alpha=0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.939 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=2.980 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.510 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.510 mean=3.810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ARITH] alpha=0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.000 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=2.970 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.550 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.550 mean=3.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ARITH] alpha=0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.980 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.000 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.540 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.540 mean=3.840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF-ARITH alpha tuning summary (lower better):\n  alpha=0.22: worst=4.480 mean=3.827\n  alpha=0.24: worst=4.520 mean=3.826\n  alpha=0.25: worst=4.530 mean=3.816\n  alpha=0.26: worst=4.510 mean=3.810\n  alpha=0.28: worst=4.550 mean=3.840\n  alpha=0.3: worst=4.540 mean=3.840\nChosen alpha (ARITH, by worst then mean): 0.22\nARITH Step 2: Fuse + decode test with best alpha ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [ARITH] test fused decoded 20/95 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [ARITH] test fused decoded 40/95 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [ARITH] test fused decoded 60/95 elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [ARITH] test fused decoded 80/95 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [ARITH] test fused decoded 95/95 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_fused_rgb_arith_alpha022.csv rows= 95 head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 12 5 9 19 13 20 18 11 3 4 6 8 14 10 2 ...\n3  303  18 13 4 3 10 14 6 5 19 20 17 2 11 16 7 9 12 1 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 6 17 16 4 12 1...\nsubmission.csv written -> submission_fused_rgb_arith_alpha022.csv\nArithmetic fusion pipeline complete.\n"
          ]
        }
      ]
    },
    {
      "id": "2bd3d94a-0d0d-424c-87d8-9fc08ef04f31",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# RGB fusion PoE with smooth_k=3 and mult sweep; retune alpha and write submission\n",
        "import json, time, pandas as pd\n",
        "\n",
        "def tune_mult_alpha_smooth3(mult_list=(0.65, 0.7), alpha_list=(0.22,0.24,0.25,0.26,0.28,0.30)):\n",
        "    best = None\n",
        "    recs = []\n",
        "    for m in mult_list:\n",
        "        print(f'[OOF smooth_k=3] mult={m}', flush=True)\n",
        "        a, wb, mb = oof_alpha_tune(alpha_list=alpha_list, mult=m, smooth_k=3, aba_len=2, aba_ratio=1.04)\n",
        "        recs.append((m, a, wb[a], mb[a]))\n",
        "        cand = (wb[a], mb[a], m, a)\n",
        "        if (best is None) or (cand < best):\n",
        "            best = cand\n",
        "    # best tuple: (worst, mean, mult, alpha)\n",
        "    return best, recs\n",
        "\n",
        "print('PoE fusion with smoothing k=3: tuning mult and alpha...', flush=True)\n",
        "best_tuple, recs = tune_mult_alpha_smooth3(mult_list=(0.65,0.7), alpha_list=(0.22,0.24,0.25,0.26,0.28,0.30))\n",
        "worst, mean_v, best_mult, best_alpha = best_tuple\n",
        "print('Chosen (mult, alpha) by worst then mean:', best_mult, best_alpha, '-> worst=', worst, 'mean=', mean_v, flush=True)\n",
        "out_csv = f'submission_fused_rgb_poe_s3_m{str(best_mult).replace(\".\", \"\")}_a{str(best_alpha).replace(\".\", \"\")}.csv'\n",
        "print('Decoding test with best settings (smooth_k=3)...', flush=True)\n",
        "fuse_decode_test(alpha=best_alpha, mult=best_mult, smooth_k=3, aba_len=2, aba_ratio=1.04, out_csv=out_csv)\n",
        "print('Done PoE smooth_k=3 submission:', out_csv, flush=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PoE fusion with smoothing k=3: tuning mult and alpha...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF smooth_k=3] mult=0.65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.010 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=2.909 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.460 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.460 mean=3.793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.082 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=2.949 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.470 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.470 mean=3.834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.071 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=2.980 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.440 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.440 mean=3.830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.092 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=2.990 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.450 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.450 mean=3.844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.112 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.020 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.400 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.400 mean=3.844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.143 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.020 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.440 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.440 mean=3.868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF alpha tuning summary (lower better):\n  alpha=0.22: worst=4.460 mean=3.793\n  alpha=0.24: worst=4.470 mean=3.834\n  alpha=0.25: worst=4.440 mean=3.830\n  alpha=0.26: worst=4.450 mean=3.844\n  alpha=0.28: worst=4.400 mean=3.844\n  alpha=0.3: worst=4.440 mean=3.868\nChosen alpha (by worst then mean): 0.28\n[OOF smooth_k=3] mult=0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.051 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.101 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.450 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.450 mean=3.867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.102 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.131 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.450 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.450 mean=3.894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.010 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.162 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.360 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.360 mean=3.844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.010 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.152 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.360 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.360 mean=3.841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.102 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.192 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.390 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.390 mean=3.895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] alpha=0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.092 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.202 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.400 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.400 mean=3.898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF alpha tuning summary (lower better):\n  alpha=0.22: worst=4.450 mean=3.867\n  alpha=0.24: worst=4.450 mean=3.894\n  alpha=0.25: worst=4.360 mean=3.844\n  alpha=0.26: worst=4.360 mean=3.841\n  alpha=0.28: worst=4.390 mean=3.895\n  alpha=0.3: worst=4.400 mean=3.898\nChosen alpha (by worst then mean): 0.26\nChosen (mult, alpha) by worst then mean: 0.7 0.26 -> worst= 4.36 mean= 3.8405730777159355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoding test with best settings (smooth_k=3)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  test fused decoded 20/95 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  test fused decoded 40/95 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  test fused decoded 60/95 elapsed=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  test fused decoded 80/95 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  test fused decoded 95/95 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_fused_rgb_poe_s3_m07_a026.csv rows= 95 head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 12 5 9 19 13 20 18 11 3 4 6 8 14 10 2 ...\n3  303  18 13 4 3 10 14 6 5 19 20 17 2 11 16 9 7 12 1 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 6 17 16 4 12 1...\nsubmission.csv written -> submission_fused_rgb_poe_s3_m07_a026.csv\nDone PoE smooth_k=3 submission: submission_fused_rgb_poe_s3_m07_a026.csv\n"
          ]
        }
      ]
    },
    {
      "id": "a9f5dba6-3a8b-484a-9a93-68391228f58b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add depth/user streams: extract *_depth.mp4 and *_user.mp4, cache embeddings with MobileNetV2 (stride=2)\n",
        "import os, io, time, tarfile, zipfile, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "try:\n",
        "    import decord\n",
        "    from decord import VideoReader, cpu\n",
        "    HAS_DECORD = True\n",
        "except Exception:\n",
        "    HAS_DECORD = False\n",
        "try:\n",
        "    import cv2\n",
        "    HAS_CV2 = True\n",
        "except Exception:\n",
        "    HAS_CV2 = False\n",
        "try:\n",
        "    import imageio.v3 as iio\n",
        "    HAS_IMAGEIO = True\n",
        "except Exception:\n",
        "    HAS_IMAGEIO = False\n",
        "\n",
        "# Reuse id->tar helpers\n",
        "def id_to_tar(sid: int) -> Path | None:\n",
        "    if 1 <= sid <= 99: return Path('training1.tar.gz')\n",
        "    if 101 <= sid <= 199: return Path('training2.tar.gz')\n",
        "    if 200 <= sid <= 299: return Path('training3.tar.gz')\n",
        "    if 300 <= sid <= 399: return Path('test.tar.gz')\n",
        "    return None\n",
        "def split_of_id(sid: int) -> str:\n",
        "    return 'train' if sid < 300 else 'test'\n",
        "\n",
        "# Output dirs\n",
        "vid_depth_dir = Path('rgb_videos_depth'); (vid_depth_dir/'train').mkdir(parents=True, exist_ok=True); (vid_depth_dir/'test').mkdir(parents=True, exist_ok=True)\n",
        "vid_user_dir = Path('rgb_videos_user'); (vid_user_dir/'train').mkdir(parents=True, exist_ok=True); (vid_user_dir/'test').mkdir(parents=True, exist_ok=True)\n",
        "emb_depth_dir = Path('rgb_embed_depth'); (emb_depth_dir/'train').mkdir(parents=True, exist_ok=True); (emb_depth_dir/'test').mkdir(parents=True, exist_ok=True)\n",
        "emb_user_dir = Path('rgb_embed_user'); (emb_user_dir/'train').mkdir(parents=True, exist_ok=True); (emb_user_dir/'test').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def extract_stream_mp4_to_cache(sid: int, stream: str) -> Path | None:\n",
        "    # stream in {'color','depth','user'}\n",
        "    split = split_of_id(sid)\n",
        "    out_base = {'color': Path('rgb_videos'), 'depth': vid_depth_dir, 'user': vid_user_dir}[stream]\n",
        "    out_path = out_base / split / f\"{sid}.mp4\"\n",
        "    if out_path.exists():\n",
        "        return out_path\n",
        "    tar_p = id_to_tar(sid)\n",
        "    if tar_p is None or not tar_p.exists():\n",
        "        print(f'[extract-{stream}] Missing tar for id={sid}:', tar_p); return None\n",
        "    zip_name = f\"Sample{sid:05d}.zip\"\n",
        "    member_name = f\"Sample{sid:05d}_{stream}.mp4\"\n",
        "    try:\n",
        "        with tarfile.open(tar_p, 'r:gz') as tf:\n",
        "            m = next((m for m in tf if m.isreg() and Path(m.name).name == zip_name), None)\n",
        "            if m is None:\n",
        "                print(f'[extract-{stream}] zip {zip_name} not in {tar_p}'); return None\n",
        "            data = tf.extractfile(m).read()\n",
        "        with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "            names = zf.namelist()\n",
        "            cand = member_name if member_name in names else next((n for n in names if n.lower().endswith(f'_{stream}.mp4')), None)\n",
        "            if cand is None:\n",
        "                print(f'[extract-{stream}] mp4 not found for id={sid}')\n",
        "                return None\n",
        "            tmp = out_path.with_suffix('.mp4.tmp')\n",
        "            with zf.open(cand) as fsrc, open(tmp, 'wb') as fdst:\n",
        "                shutil.copyfileobj(fsrc, fdst)\n",
        "            tmp.replace(out_path)\n",
        "        return out_path\n",
        "    except Exception as e:\n",
        "        print(f'[extract-{stream}] error id={sid}:', e); return None\n",
        "\n",
        "# Readers and embedding (reuse MobileNetV2 features head)\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "preproc = transforms.Compose([transforms.ToPILImage(), transforms.Resize((112,112)), transforms.ToTensor(), transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)])\n",
        "mb = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V1).features.eval().to(device)\n",
        "pool = nn.AdaptiveAvgPool2d((1,1)).to(device)\n",
        "mb.requires_grad_(False)\n",
        "\n",
        "def read_video_frames(path: Path, stride: int = 2):\n",
        "    frames = []\n",
        "    if HAS_DECORD:\n",
        "        try:\n",
        "            vr = VideoReader(str(path), ctx=cpu(0))\n",
        "            nfr = len(vr)\n",
        "            if nfr > 0:\n",
        "                for i in range(0, nfr, stride):\n",
        "                    frames.append(vr[i].asnumpy())\n",
        "            else:\n",
        "                print('[decord] zero frames for', path)\n",
        "        except Exception as e:\n",
        "            print('[decord] fail', e); frames = []\n",
        "    if not frames and HAS_CV2:\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(str(path)); i = 0\n",
        "            if not cap.isOpened():\n",
        "                print('[cv2] cannot open', path)\n",
        "            while cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                if not ret: break\n",
        "                if (i % stride)==0:\n",
        "                    frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "                i += 1\n",
        "            cap.release()\n",
        "        except Exception as e:\n",
        "            print('[cv2] fail', e); frames = []\n",
        "    if not frames and HAS_IMAGEIO:\n",
        "        try:\n",
        "            i = 0\n",
        "            for frm in iio.imiter(str(path)):\n",
        "                if (i % stride)==0:\n",
        "                    frames.append(frm)\n",
        "                i += 1\n",
        "        except Exception as e:\n",
        "            print('[imageio] fail', e)\n",
        "    return frames\n",
        "\n",
        "def embed_frames(frames, batch_size: int = 128, use_fp16: bool = True) -> np.ndarray:\n",
        "    if not frames:\n",
        "        return np.zeros((0,1280), dtype=np.float16)\n",
        "    embs = []\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type='cuda', enabled=(device.type=='cuda' and use_fp16)):\n",
        "        batch = []\n",
        "        for i, img in enumerate(frames, 1):\n",
        "            x = preproc(img); batch.append(x)\n",
        "            if len(batch)==batch_size or i==len(frames):\n",
        "                xb = torch.stack(batch, 0).to(device)\n",
        "                feat = mb(xb); feat = pool(feat).flatten(1)\n",
        "                embs.append(feat.float().cpu()); batch.clear()\n",
        "    return torch.cat(embs, 0).numpy().astype(np.float16)\n",
        "\n",
        "def cache_stream_embedding_for_id(sid: int, stream: str, stride: int = 2, force: bool = False) -> Path | None:\n",
        "    emb_base = {'depth': emb_depth_dir, 'user': emb_user_dir}[stream]\n",
        "    out = emb_base / split_of_id(sid) / f\"{sid}.npy\"\n",
        "    if out.exists() and not force:\n",
        "        try:\n",
        "            arr = np.load(out, mmap_mode='r')\n",
        "            if arr.shape[0] > 0:\n",
        "                return out\n",
        "        except Exception:\n",
        "            pass\n",
        "    vpath = extract_stream_mp4_to_cache(sid, stream=stream)\n",
        "    if vpath is None:\n",
        "        return None\n",
        "    frames = read_video_frames(vpath, stride=stride)\n",
        "    E = embed_frames(frames, batch_size=128, use_fp16=True)\n",
        "    np.save(out, E.astype(np.float16))\n",
        "    return out\n",
        "\n",
        "def list_ids_from_features(split: str):\n",
        "    base = Path('features3d_v3')/split\n",
        "    return sorted(int(p.stem) for p in base.glob('*.npz'))\n",
        "\n",
        "def bulk_extract_stream(stream: str, ids: list[int], stride: int = 2):\n",
        "    t0=time.time(); ok=0; skip=0; fail=0\n",
        "    for i, sid in enumerate(ids, 1):\n",
        "        emb_base = {'depth': emb_depth_dir, 'user': emb_user_dir}[stream]\n",
        "        out = emb_base / split_of_id(sid) / f\"{sid}.npy\"\n",
        "        if out.exists():\n",
        "            try:\n",
        "                arr = np.load(out, mmap_mode='r')\n",
        "                if arr.shape[0] > 0:\n",
        "                    skip += 1\n",
        "                    if (i%20)==0 or i==len(ids):\n",
        "                        print(f'  [{stream}] skip {i}/{len(ids)} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "                    continue\n",
        "            except Exception:\n",
        "                pass\n",
        "        p = cache_stream_embedding_for_id(int(sid), stream=stream, stride=stride, force=False)\n",
        "        if p is None:\n",
        "            fail += 1\n",
        "        else:\n",
        "            ok += 1\n",
        "        if (i%20)==0 or i==len(ids):\n",
        "            print(f'  [{stream}] processed {i}/{len(ids)} ok={ok} skip={skip} fail={fail} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    print(f'[{stream}] Done: ok={ok} skip={skip} fail={fail} total={len(ids)} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "\n",
        "train_ids = list_ids_from_features('train')\n",
        "test_ids = list_ids_from_features('test')\n",
        "print('Depth/User embedding extraction starting... train:', len(train_ids), 'test:', len(test_ids))\n",
        "print('Extracting DEPTH embeddings (stride=2)...', flush=True)\n",
        "bulk_extract_stream('depth', train_ids, stride=2)\n",
        "bulk_extract_stream('depth', test_ids, stride=2)\n",
        "print('Extracting USER embeddings (stride=2)...', flush=True)\n",
        "bulk_extract_stream('user', train_ids, stride=2)\n",
        "bulk_extract_stream('user', test_ids, stride=2)\n",
        "print('Depth/User embedding caches complete.')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depth/User embedding extraction starting... train: 297 test: 95\nExtracting DEPTH embeddings (stride=2)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 20/297 ok=20 skip=0 fail=0 elapsed=39.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 40/297 ok=40 skip=0 fail=0 elapsed=100.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 60/297 ok=60 skip=0 fail=0 elapsed=197.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 80/297 ok=80 skip=0 fail=0 elapsed=320.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 100/297 ok=100 skip=0 fail=0 elapsed=441.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 120/297 ok=120 skip=0 fail=0 elapsed=472.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 140/297 ok=140 skip=0 fail=0 elapsed=512.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 160/297 ok=160 skip=0 fail=0 elapsed=559.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 180/297 ok=180 skip=0 fail=0 elapsed=615.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 200/297 ok=200 skip=0 fail=0 elapsed=672.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 220/297 ok=220 skip=0 fail=0 elapsed=704.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 240/297 ok=240 skip=0 fail=0 elapsed=753.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 260/297 ok=260 skip=0 fail=0 elapsed=815.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 280/297 ok=280 skip=0 fail=0 elapsed=886.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 297/297 ok=297 skip=0 fail=0 elapsed=953.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[depth] Done: ok=297 skip=0 fail=0 total=297 elapsed=953.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 20/95 ok=20 skip=0 fail=0 elapsed=30.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 40/95 ok=40 skip=0 fail=0 elapsed=74.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 60/95 ok=60 skip=0 fail=0 elapsed=127.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [depth] processed 80/95 ok=80 skip=0 fail=0 elapsed=192.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[extract-depth] Missing tar for id=401: None\n[extract-depth] Missing tar for id=402: None\n[extract-depth] Missing tar for id=403: None\n  [depth] processed 95/95 ok=92 skip=0 fail=3 elapsed=235.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[depth] Done: ok=92 skip=0 fail=3 total=95 elapsed=235.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting USER embeddings (stride=2)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 20/297 ok=20 skip=0 fail=0 elapsed=37.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 40/297 ok=40 skip=0 fail=0 elapsed=96.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 60/297 ok=60 skip=0 fail=0 elapsed=190.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 80/297 ok=80 skip=0 fail=0 elapsed=309.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 100/297 ok=100 skip=0 fail=0 elapsed=431.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 120/297 ok=120 skip=0 fail=0 elapsed=461.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 140/297 ok=140 skip=0 fail=0 elapsed=501.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 160/297 ok=160 skip=0 fail=0 elapsed=548.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 180/297 ok=180 skip=0 fail=0 elapsed=603.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 200/297 ok=200 skip=0 fail=0 elapsed=661.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 220/297 ok=220 skip=0 fail=0 elapsed=692.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 240/297 ok=240 skip=0 fail=0 elapsed=739.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 260/297 ok=260 skip=0 fail=0 elapsed=801.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 280/297 ok=280 skip=0 fail=0 elapsed=872.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 297/297 ok=297 skip=0 fail=0 elapsed=940.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[user] Done: ok=297 skip=0 fail=0 total=297 elapsed=940.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 20/95 ok=20 skip=0 fail=0 elapsed=30.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 40/95 ok=40 skip=0 fail=0 elapsed=73.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 60/95 ok=60 skip=0 fail=0 elapsed=125.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [user] processed 80/95 ok=80 skip=0 fail=0 elapsed=189.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[extract-user] Missing tar for id=401: None\n[extract-user] Missing tar for id=402: None\n[extract-user] Missing tar for id=403: None\n  [user] processed 95/95 ok=92 skip=0 fail=3 elapsed=232.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[user] Done: ok=92 skip=0 fail=3 total=95 elapsed=232.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depth/User embedding caches complete.\n"
          ]
        }
      ]
    },
    {
      "id": "454a2f38-b760-4c82-90e9-a092a10a55ca",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train depth/user linear heads on embeddings; cache OOF/test probs; per-fold temp; average TEST per-fold -> probs_cache/{id}_{depth,user}.npy\n",
        "import os, json, time, random\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
        "\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "\n",
        "# Generic helpers reused from RGB head cell\n",
        "def get_T_train(sid: int) -> int:\n",
        "    y = np.load(labels_dir / f\"{sid}.npy\"); return int(y.shape[0])\n",
        "def get_T_test(sid: int) -> int:\n",
        "    p3 = probs_cache / f\"{sid}_ce_v3.npy\"\n",
        "    if p3.exists():\n",
        "        return int(np.load(p3, mmap_mode='r').shape[1])\n",
        "    d = np.load(Path('features3d_v3/test')/f\"{sid}.npz\")\n",
        "    X = d['X'] if 'X' in d.files else d[d.files[0]]\n",
        "    return int(X.shape[0])\n",
        "def upsample_to_T_np(E: np.ndarray, T: int) -> np.ndarray:\n",
        "    if E.shape[0] == T: return E.astype(np.float32)\n",
        "    if E.shape[0] == 0: return np.zeros((T, E.shape[1] if E.ndim==2 else 1280), dtype=np.float32)\n",
        "    import torch.nn.functional as Fnn\n",
        "    x = torch.from_numpy(E.astype(np.float32)).unsqueeze(0).transpose(1,2)\n",
        "    y = Fnn.interpolate(x, size=T, mode='linear', align_corners=False).transpose(1,2).squeeze(0).contiguous()\n",
        "    return y.numpy().astype(np.float32)\n",
        "\n",
        "class EmbSeqDataset(Dataset):\n",
        "    def __init__(self, emb_dir: Path, ids: List[int], chunk_len: int = 1024):\n",
        "        self.emb_dir = emb_dir; self.ids = list(ids); self.chunk_len = chunk_len; self.index = []\n",
        "        for sid in self.ids:\n",
        "            E = np.load(emb_dir/'train'/f\"{sid}.npy\", mmap_mode='r')\n",
        "            T = get_T_train(sid); Eu = upsample_to_T_np(np.array(E), T); n = Eu.shape[0]\n",
        "            if n <= chunk_len: self.index.append((sid, 0, n))\n",
        "            else:\n",
        "                s = 0\n",
        "                while s < n:\n",
        "                    e = min(n, s + chunk_len); self.index.append((sid, s, e)); s = e\n",
        "        random.shuffle(self.index)\n",
        "    def __len__(self): return len(self.index)\n",
        "    def __getitem__(self, i):\n",
        "        sid, s, e = self.index[i]\n",
        "        E = np.load(self.emb_dir/'train'/f\"{sid}.npy\", mmap_mode='r')\n",
        "        T = get_T_train(sid); Eu = upsample_to_T_np(np.array(E), T)\n",
        "        y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "        x = Eu[s:e].astype(np.float32); t = y[s:e]\n",
        "        return torch.from_numpy(x), torch.from_numpy(t)\n",
        "\n",
        "class LinearHead(nn.Module):\n",
        "    def __init__(self, d_in=1280, n_classes=21, p_drop=0.5):\n",
        "        super().__init__(); self.drop = nn.Dropout(p_drop); self.fc = nn.Linear(d_in, n_classes)\n",
        "    def forward(self, x): return self.fc(self.drop(x))\n",
        "\n",
        "def train_stream_fold(emb_dir: Path, train_ids: List[int], val_ids: List[int], epochs: int = 12, lr: float = 1e-3, wd: float = 1e-5, chunk_len: int = 1024, batch_size: int = 1, patience: int = 3):\n",
        "    model = LinearHead().to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    best = 1e9; bad=0\n",
        "    for ep in range(1, epochs+1):\n",
        "        t0=time.time(); model.train()\n",
        "        ds = EmbSeqDataset(emb_dir, train_ids, chunk_len=chunk_len)\n",
        "        dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        tr_loss=0.0; n_tok=0\n",
        "        for xb, yb in dl:\n",
        "            xb=xb.to(device, non_blocking=True); yb=yb.to(device, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True); logits = model(xb)\n",
        "            loss = F.cross_entropy(logits.reshape(-1, logits.shape[-1]), yb.reshape(-1))\n",
        "            loss.backward(); opt.step()\n",
        "            tr_loss += float(loss.item()) * yb.numel(); n_tok += int(yb.numel())\n",
        "        tr_loss /= max(1, n_tok)\n",
        "        # val\n",
        "        model.eval(); val_loss=0.0; n_tok=0\n",
        "        with torch.no_grad():\n",
        "            for sid in val_ids:\n",
        "                E = np.load(emb_dir/'train'/f\"{sid}.npy\", mmap_mode='r')\n",
        "                T = get_T_train(sid); Eu = upsample_to_T_np(np.array(E), T)\n",
        "                y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "                xb = torch.from_numpy(Eu).unsqueeze(0).to(device); logits = model(xb)\n",
        "                ll = F.cross_entropy(logits.reshape(-1, logits.shape[-1]), torch.from_numpy(y).to(device))\n",
        "                val_loss += float(ll.item()) * int(T); n_tok += int(T)\n",
        "        val_loss /= max(1, n_tok)\n",
        "        print(f\"[STREAM fold] ep {ep:02d} tr_nll={tr_loss:.4f} val_nll={val_loss:.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "        if val_loss < best - 1e-4: best = val_loss; bad=0; torch.save(model.state_dict(), 'stream_head_tmp.pth')\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience: break\n",
        "    model.load_state_dict(torch.load('stream_head_tmp.pth', map_location=device)); return model\n",
        "\n",
        "def infer_probs_for_ids(model: nn.Module, emb_dir: Path, ids: List[int], split: str, out_suffix: str):\n",
        "    model.eval(); saved=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, sid in enumerate(ids, 1):\n",
        "            if split=='train':\n",
        "                T = get_T_train(sid); emb_path = emb_dir/'train'/f\"{sid}.npy\"\n",
        "            else:\n",
        "                T = get_T_test(sid); emb_path = emb_dir/'test'/f\"{sid}.npy\"\n",
        "            if not emb_path.exists():\n",
        "                print(f\"  [infer {out_suffix}] missing emb for id={sid}, skip\"); continue\n",
        "            E = np.load(emb_path, mmap_mode='r'); Eu = upsample_to_T_np(np.array(E), T)\n",
        "            xb = torch.from_numpy(Eu).unsqueeze(0).to(device); logits = model(xb)[0]\n",
        "            p = logits.softmax(dim=-1).cpu().numpy().astype(np.float32).T  # CxT\n",
        "            p /= (p.sum(axis=0, keepdims=True) + 1e-8)\n",
        "            np.save(probs_cache/f\"{sid}{out_suffix}\", p)\n",
        "            saved += 1\n",
        "            if (i%20)==0 or i==len(ids): print(f\"  saved {saved}/{len(ids)} split={split} {out_suffix} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "def fit_scalar_temperature_on_val(val_ids: List[int], suffix: str) -> float:\n",
        "    grid = [round(x,2) for x in np.linspace(0.8, 1.5, 15)]\n",
        "    best_T=1.0; best_nll=1e18\n",
        "    for Tval in grid:\n",
        "        nll=0.0; n_tok=0\n",
        "        for sid in val_ids:\n",
        "            p = np.load(probs_cache/f\"{sid}{suffix}\")\n",
        "            y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "            logp = np.log(np.clip(p, 1e-8, 1.0)) / float(Tval)\n",
        "            q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "            idx = (y >= 0) & (y < q.shape[0]); yy = y[idx]\n",
        "            nll += -float(np.log(q[yy, np.nonzero(idx)[0]] + 1e-8).sum()); n_tok += int(idx.sum())\n",
        "        if n_tok>0:\n",
        "            nll /= float(n_tok)\n",
        "            if nll < best_nll: best_nll = nll; best_T = Tval\n",
        "    print(f\"[Temp] best T={best_T} NLL={best_nll:.4f} on {len(val_ids)} val ids for {suffix}\", flush=True)\n",
        "    return float(best_T)\n",
        "\n",
        "def apply_scalar_temperature(ids: List[int], suffix: str, Tscalar: float):\n",
        "    for sid in ids:\n",
        "        p = np.load(probs_cache/f\"{sid}{suffix}\")\n",
        "        logp = np.log(np.clip(p, 1e-8, 1.0)) / float(Tscalar)\n",
        "        q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "        np.save(probs_cache/f\"{sid}{suffix}\", q.astype(np.float32))\n",
        "\n",
        "def average_test_per_fold_with_temps(stream: str, temp_prefix: str):\n",
        "    # temp files saved as {temp_prefix}_fold{f}.json with key 'T'\n",
        "    Ts=[]\n",
        "    for f in range(3):\n",
        "        jf = Path(f'{temp_prefix}_fold{f}.json')\n",
        "        if jf.exists():\n",
        "            try: Ts.append(float(json.loads(jf.read_text())['T']))\n",
        "            except Exception: Ts.append(1.0)\n",
        "        else: Ts.append(1.0)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    n_avg=0\n",
        "    for sid in test_ids:\n",
        "        arrs=[]\n",
        "        for f in range(3):\n",
        "            p = probs_cache/f\"{sid}_{stream}_f{f}.npy\"\n",
        "            if p.exists():\n",
        "                a = np.load(p, mmap_mode='r').astype(np.float32)\n",
        "                # apply T_f\n",
        "                logp = np.log(np.clip(a, 1e-8, 1.0)) / float(Ts[f])\n",
        "                q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "                arrs.append(q)\n",
        "        if not arrs: continue\n",
        "        Tm = min(a.shape[1] for a in arrs); arrs = [a[:, :Tm] for a in arrs]\n",
        "        m = np.mean(arrs, axis=0); m /= (m.sum(axis=0, keepdims=True) + 1e-8)\n",
        "        np.save(probs_cache/f\"{sid}_{stream}.npy\", m.astype(np.float32)); n_avg+=1\n",
        "    print(f\"Averaged TEST per-fold -> {stream}.npy for {n_avg} ids\")\n",
        "\n",
        "def list_ids_from_features(split: str):\n",
        "    base = Path('features3d_v3')/split; return sorted(int(p.stem) for p in base.glob('*.npz'))\n",
        "\n",
        "print('Training DEPTH and USER linear heads per fold...', flush=True)\n",
        "emb_dirs = {'depth': Path('rgb_embed_depth'), 'user': Path('rgb_embed_user')}\n",
        "suffix_val = {'depth': '_depth.npy', 'user': '_user.npy'}\n",
        "suffix_test_fold = {'depth': '_depth_f{f}.npy', 'user': '_user_f{f}.npy'}\n",
        "temp_prefix = {'depth': 'depth_temp', 'user': 'user_temp'}\n",
        "\n",
        "with open('folds_archive_cv.json') as f:\n",
        "    folds_list = json.load(f)\n",
        "test_ids_list = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "\n",
        "for stream in ('depth','user'):\n",
        "    emb_dir = emb_dirs[stream]\n",
        "    print(f'== Stream {stream.upper()} ==', flush=True)\n",
        "    for fd in folds_list:\n",
        "        fidx = int(fd['fold'])\n",
        "        tr_ids = list(map(int, fd['train_ids']))\n",
        "        va_ids = list(map(int, fd['val_ids']))\n",
        "        print(f'Fold {fidx}: train={len(tr_ids)} val={len(va_ids)}', flush=True)\n",
        "        model = train_stream_fold(emb_dir, tr_ids, va_ids, epochs=12, lr=1e-3, wd=1e-5, chunk_len=1024, batch_size=1, patience=3)\n",
        "        # OOF val\n",
        "        infer_probs_for_ids(model, emb_dir, va_ids, split='train', out_suffix=suffix_val[stream])\n",
        "        # TEST per-fold\n",
        "        infer_probs_for_ids(model, emb_dir, test_ids_list, split='test', out_suffix=suffix_test_fold[stream].format(f=fidx))\n",
        "        # Fit temp on val and apply\n",
        "        Tbest = fit_scalar_temperature_on_val(va_ids, suffix=suffix_val[stream])\n",
        "        apply_scalar_temperature(va_ids, suffix=suffix_val[stream], Tscalar=Tbest)\n",
        "        Path(f\"{temp_prefix[stream]}_fold{fidx}.json\").write_text(json.dumps({'T': Tbest}))\n",
        "    # After all folds, average TEST per-fold with temps\n",
        "    print(f'Calibrating and averaging TEST per-fold for {stream} ...', flush=True)\n",
        "    average_test_per_fold_with_temps(stream=stream, temp_prefix=temp_prefix[stream])\n",
        "\n",
        "print('Depth/User stream training + calibration complete. Ready for multi-stream fusion.')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DEPTH and USER linear heads per fold...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Stream DEPTH ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: train=199 val=98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 01 tr_nll=3.0346 val_nll=3.6526 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 02 tr_nll=2.8945 val_nll=3.7958 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 03 tr_nll=2.8094 val_nll=3.9268 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 04 tr_nll=2.7961 val_nll=3.3064 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 05 tr_nll=2.7602 val_nll=3.9697 elapsed=4.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 06 tr_nll=2.7501 val_nll=3.8719 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 07 tr_nll=2.7375 val_nll=3.6817 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/98 split=train _depth.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_9704/16151589.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('stream_head_tmp.pth', map_location=device)); return model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/98 split=train _depth.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/98 split=train _depth.npy elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/98 split=train _depth.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 98/98 split=train _depth.npy elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test _depth_f0.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test _depth_f0.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test _depth_f0.npy elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test _depth_f0.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer _depth_f0.npy] missing emb for id=401, skip\n  [infer _depth_f0.npy] missing emb for id=402, skip\n  [infer _depth_f0.npy] missing emb for id=403, skip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp] best T=1.5 NLL=3.0751 on 98 val ids for _depth.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: train=198 val=99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 01 tr_nll=2.9756 val_nll=2.7973 elapsed=4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 02 tr_nll=2.8168 val_nll=3.1141 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 03 tr_nll=2.7564 val_nll=2.5984 elapsed=4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 04 tr_nll=2.6883 val_nll=2.6988 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 05 tr_nll=2.7007 val_nll=2.7162 elapsed=4.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 06 tr_nll=2.6762 val_nll=2.8661 elapsed=4.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/99 split=train _depth.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/99 split=train _depth.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/99 split=train _depth.npy elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/99 split=train _depth.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 99/99 split=train _depth.npy elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test _depth_f1.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test _depth_f1.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test _depth_f1.npy elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test _depth_f1.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer _depth_f1.npy] missing emb for id=401, skip\n  [infer _depth_f1.npy] missing emb for id=402, skip\n  [infer _depth_f1.npy] missing emb for id=403, skip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp] best T=1.05 NLL=2.5980 on 99 val ids for _depth.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: train=197 val=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 01 tr_nll=2.6015 val_nll=3.5215 elapsed=4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 02 tr_nll=2.3895 val_nll=3.6274 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 03 tr_nll=2.3667 val_nll=3.8904 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 04 tr_nll=2.3507 val_nll=3.5062 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 05 tr_nll=2.3015 val_nll=3.9293 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 06 tr_nll=2.2875 val_nll=3.8968 elapsed=4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 07 tr_nll=2.2851 val_nll=3.8442 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/100 split=train _depth.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/100 split=train _depth.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/100 split=train _depth.npy elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/100 split=train _depth.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 100/100 split=train _depth.npy elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test _depth_f2.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test _depth_f2.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test _depth_f2.npy elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test _depth_f2.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer _depth_f2.npy] missing emb for id=401, skip\n  [infer _depth_f2.npy] missing emb for id=402, skip\n  [infer _depth_f2.npy] missing emb for id=403, skip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp] best T=1.5 NLL=3.1499 on 100 val ids for _depth.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibrating and averaging TEST per-fold for depth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averaged TEST per-fold -> depth.npy for 92 ids\n== Stream USER ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: train=199 val=98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 01 tr_nll=2.9689 val_nll=2.6789 elapsed=4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 02 tr_nll=2.8107 val_nll=3.1903 elapsed=4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 03 tr_nll=2.7805 val_nll=2.9851 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 04 tr_nll=2.7405 val_nll=3.2149 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/98 split=train _user.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_9704/16151589.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('stream_head_tmp.pth', map_location=device)); return model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/98 split=train _user.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/98 split=train _user.npy elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/98 split=train _user.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 98/98 split=train _user.npy elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test _user_f0.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test _user_f0.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test _user_f0.npy elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test _user_f0.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer _user_f0.npy] missing emb for id=401, skip\n  [infer _user_f0.npy] missing emb for id=402, skip\n  [infer _user_f0.npy] missing emb for id=403, skip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp] best T=0.9 NLL=2.6752 on 98 val ids for _user.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: train=198 val=99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 01 tr_nll=2.9029 val_nll=2.8047 elapsed=4.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 02 tr_nll=2.7489 val_nll=2.6743 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 03 tr_nll=2.7089 val_nll=2.7961 elapsed=4.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 04 tr_nll=2.6661 val_nll=2.7395 elapsed=4.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 05 tr_nll=2.6547 val_nll=2.6886 elapsed=4.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/99 split=train _user.npy elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/99 split=train _user.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/99 split=train _user.npy elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/99 split=train _user.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 99/99 split=train _user.npy elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test _user_f1.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test _user_f1.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test _user_f1.npy elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test _user_f1.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer _user_f1.npy] missing emb for id=401, skip\n  [infer _user_f1.npy] missing emb for id=402, skip\n  [infer _user_f1.npy] missing emb for id=403, skip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp] best T=1.2 NLL=2.6593 on 99 val ids for _user.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: train=197 val=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 01 tr_nll=2.5475 val_nll=3.5018 elapsed=4.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 02 tr_nll=2.3867 val_nll=3.6107 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 03 tr_nll=2.3458 val_nll=3.4831 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 04 tr_nll=2.3140 val_nll=3.6888 elapsed=4.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 05 tr_nll=2.2945 val_nll=3.5335 elapsed=4.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM fold] ep 06 tr_nll=2.2631 val_nll=3.6726 elapsed=4.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/100 split=train _user.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/100 split=train _user.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/100 split=train _user.npy elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/100 split=train _user.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 100/100 split=train _user.npy elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test _user_f2.npy elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test _user_f2.npy elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test _user_f2.npy elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test _user_f2.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [infer _user_f2.npy] missing emb for id=401, skip\n  [infer _user_f2.npy] missing emb for id=402, skip\n  [infer _user_f2.npy] missing emb for id=403, skip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp] best T=1.5 NLL=3.1568 on 100 val ids for _user.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibrating and averaging TEST per-fold for user ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averaged TEST per-fold -> user.npy for 92 ids\nDepth/User stream training + calibration complete. Ready for multi-stream fusion.\n"
          ]
        }
      ]
    },
    {
      "id": "ab7a2e4e-1091-42fa-823e-e5bf8ee3c133",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Multi-stream fusion: visual-avg (color+depth+user) vs skeleton with PoE; OOF alpha grid and test submission\n",
        "import numpy as np, json, time, os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "\n",
        "# Reuse helpers from prior cells: load_probs (aligned v2+v3), align_rgb_to_skel, fuse_geometric,\n",
        "# compute_runlen_stats, build_min_dur, decode_minseg_smooth_aba, load_frame_labels, make_perm20\n",
        "\n",
        "def build_visual_avg_aligned(sid: int, p_skel: np.ndarray, max_shift: int = 15) -> np.ndarray | None:\n",
        "    streams = []\n",
        "    # color\n",
        "    p_rgb_p = probs_cache/f\"{sid}_rgb.npy\"\n",
        "    if p_rgb_p.exists():\n",
        "        p_rgb = np.load(p_rgb_p).astype(np.float32)\n",
        "        pr, ps = align_rgb_to_skel(p_rgb, p_skel, max_shift=max_shift)\n",
        "        streams.append(pr)\n",
        "        p_skel = ps  # ps cropped to match pr length; we'll re-crop later to common\n",
        "    # depth\n",
        "    p_dep_p = probs_cache/f\"{sid}_depth.npy\"\n",
        "    if p_dep_p.exists():\n",
        "        p_dep = np.load(p_dep_p).astype(np.float32)\n",
        "        pr, ps = align_rgb_to_skel(p_dep, p_skel, max_shift=max_shift)\n",
        "        streams.append(pr)\n",
        "        p_skel = ps\n",
        "    # user\n",
        "    p_usr_p = probs_cache/f\"{sid}_user.npy\"\n",
        "    if p_usr_p.exists():\n",
        "        p_usr = np.load(p_usr_p).astype(np.float32)\n",
        "        pr, ps = align_rgb_to_skel(p_usr, p_skel, max_shift=max_shift)\n",
        "        streams.append(pr)\n",
        "        p_skel = ps\n",
        "    if not streams:\n",
        "        return None\n",
        "    # crop all streams to common minimal T and average\n",
        "    Tm = min(s.shape[1] for s in streams)\n",
        "    streams = [s[:, :Tm] for s in streams]\n",
        "    vavg = np.mean(streams, axis=0)\n",
        "    vavg /= (vavg.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    # also crop skeleton to Tm to return along with visual\n",
        "    ps_out = p_skel[:, :Tm]\n",
        "    ps_out /= (ps_out.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return vavg, ps_out\n",
        "\n",
        "def oof_alpha_tune_visual(alpha_list=None, mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04):\n",
        "    if alpha_list is None:\n",
        "        alpha_list = [round(a,2) for a in np.linspace(0.10, 0.50, 21)]\n",
        "    with open('folds_archive_cv.json') as f:\n",
        "        folds_list_local = json.load(f)\n",
        "    worst_by={}; mean_by={}\n",
        "    for alpha in alpha_list:\n",
        "        per_fold=[]\n",
        "        print(f'[OOF-VIS] alpha={alpha}', flush=True)\n",
        "        for fd in folds_list_local:\n",
        "            tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "            med, q75 = compute_runlen_stats(tr_ids); md = build_min_dur(med, q75, mult=mult)\n",
        "            dists=[]; n=0\n",
        "            for sid in va_ids:\n",
        "                p_skel_full = load_probs(int(sid)).astype(np.float32)\n",
        "                vis = build_visual_avg_aligned(int(sid), p_skel_full, max_shift=15)\n",
        "                if vis is None:\n",
        "                    # fallback to color-only if available\n",
        "                    p_rgb_p = probs_cache/f\"{sid}_rgb.npy\"\n",
        "                    if not p_rgb_p.exists():\n",
        "                        continue\n",
        "                    p_rgb = np.load(p_rgb_p).astype(np.float32)\n",
        "                    pr, ps = align_rgb_to_skel(p_rgb, p_skel_full, max_shift=15)\n",
        "                    vavg, ps_out = pr, ps\n",
        "                else:\n",
        "                    vavg, ps_out = vis\n",
        "                # fuse PoE\n",
        "                pf = fuse_geometric(ps_out, vavg, alpha=float(alpha))\n",
        "                # decode\n",
        "                y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "                # score\n",
        "                seq = [] ; last=-1\n",
        "                for c in y_hat:\n",
        "                    if c==0: continue\n",
        "                    if c!=last: seq.append(int(c)); last=int(c)\n",
        "                seq_true = [] ; last=-1\n",
        "                for c in load_frame_labels(int(sid)):\n",
        "                    if c==0: continue\n",
        "                    if c!=last: seq_true.append(int(c)); last=int(c)\n",
        "                # Levenshtein\n",
        "                n1=len(seq); n2=len(seq_true)\n",
        "                if n1==0: d = n2\n",
        "                elif n2==0: d = n1\n",
        "                else:\n",
        "                    dp=list(range(n2+1))\n",
        "                    for i in range(1,n1+1):\n",
        "                        prev=dp[0]; dp[0]=i; ai=seq[i-1]\n",
        "                        for j in range(1,n2+1):\n",
        "                            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==seq_true[j-1] else 1)); prev=tmp\n",
        "                    d=dp[n2]\n",
        "                dists.append(float(d)); n+=1\n",
        "            mval = float(np.mean(dists)) if dists else 0.0\n",
        "            per_fold.append(mval)\n",
        "            print(f'  fold {fd[\"fold\"]}: mean={mval:.3f} (n={len(dists)})', flush=True)\n",
        "        worst_by[alpha] = max(per_fold); mean_by[alpha] = float(np.mean(per_fold))\n",
        "        print(f'  -> worst={worst_by[alpha]:.3f} mean={mean_by[alpha]:.3f}', flush=True)\n",
        "    print('OOF-VIS alpha tuning summary (lower better):')\n",
        "    for a in alpha_list:\n",
        "        print(f'  alpha={a}: worst={worst_by[a]:.3f} mean={mean_by[a]:.3f}')\n",
        "    best_alpha = min(alpha_list, key=lambda a: (worst_by[a], mean_by[a]))\n",
        "    print('Chosen alpha (VIS by worst then mean):', best_alpha)\n",
        "    return best_alpha, worst_by, mean_by\n",
        "\n",
        "def fuse_decode_test_visual(alpha: float, mult: float = 0.7, smooth_k: int = 5, aba_len: int = 2, aba_ratio: float = 1.04, out_csv: str = 'submission_fused_visualavg.csv'):\n",
        "    # duration stats from all training ids\n",
        "    all_train_ids=[]\n",
        "    for fd in json.load(open('folds_archive_cv.json','r')):\n",
        "        all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "    med, q75 = compute_runlen_stats(sorted(set(all_train_ids))); md = build_min_dur(med, q75, mult=mult)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    rows=[]; ids=[]; n=0; t0=time.time()\n",
        "    for sid in test_ids:\n",
        "        p2 = probs_cache/f\"{sid}_ce.npy\"; p3 = probs_cache/f\"{sid}_ce_v3.npy\"\n",
        "        if not (p2.exists() and p3.exists()):\n",
        "            continue\n",
        "        p_skel_full = load_probs(int(sid)).astype(np.float32)\n",
        "        vis = build_visual_avg_aligned(int(sid), p_skel_full, max_shift=15)\n",
        "        if vis is None:\n",
        "            # fall back to color-only if available; else skeleton-only\n",
        "            prgb = probs_cache/f\"{sid}_rgb.npy\"\n",
        "            if prgb.exists():\n",
        "                p_rgb = np.load(prgb).astype(np.float32)\n",
        "                pr, ps = align_rgb_to_skel(p_rgb, p_skel_full, max_shift=15)\n",
        "                vavg, ps_out = pr, ps\n",
        "            else:\n",
        "                ps_out = p_skel_full; pf = ps_out\n",
        "                y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "                seq_raw=[]; last=-1\n",
        "                for c in y_hat:\n",
        "                    if c==0: continue\n",
        "                    if c!=last: seq_raw.append(int(c)); last=int(c)\n",
        "                seq = make_perm20(seq_raw, pf)\n",
        "                ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "                if (n%20)==0 or n==95:\n",
        "                    print(f'  [VIS] test decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "                continue\n",
        "        else:\n",
        "            vavg, ps_out = vis\n",
        "        pf = fuse_geometric(ps_out, vavg, alpha=float(alpha))\n",
        "        y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "        seq_raw=[]; last=-1\n",
        "        for c in y_hat:\n",
        "            if c==0: continue\n",
        "            if c!=last: seq_raw.append(int(c)); last=int(c)\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95:\n",
        "            print(f'  [VIS] test decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, 'rows=', len(sub), 'head:\\n', sub.head())\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('VIS Step 1: OOF alpha tuning (skeleton vs visual-avg) ...', flush=True)\n",
        "best_alpha_vis, worst_by_vis, mean_by_vis = oof_alpha_tune_visual(alpha_list=[round(a,2) for a in np.linspace(0.10, 0.50, 21)], mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04)\n",
        "print('VIS Step 2: Fuse + decode test with best alpha ...', flush=True)\n",
        "out_csv_vis = f'submission_fused_visualavg_alpha{str(best_alpha_vis).replace(\".\", \"\")}.csv'\n",
        "fuse_decode_test_visual(alpha=best_alpha_vis, mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04, out_csv=out_csv_vis)\n",
        "print('Visual-avg fusion pipeline complete.')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VIS Step 1: OOF alpha tuning (skeleton vs visual-avg) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.000 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.192 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.480 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.480 mean=3.891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.969 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.141 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.520 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.520 mean=3.877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.959 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.182 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.510 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.510 mean=3.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.908 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.202 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.470 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.470 mean=3.860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.888 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.172 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.430 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.430 mean=3.830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.867 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.121 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.490 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.490 mean=3.826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.908 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.162 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.550 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.550 mean=3.873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.929 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.172 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.580 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.580 mean=3.893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.990 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.172 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.510 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.510 mean=3.891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.990 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.131 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.500 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.500 mean=3.874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.051 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.202 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.510 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.510 mean=3.921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.122 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.212 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.540 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.540 mean=3.958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.102 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.253 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.540 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.540 mean=3.965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.133 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.343 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.580 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.580 mean=4.019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.173 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.455 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.580 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.580 mean=4.069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.255 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.545 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.600 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.600 mean=4.134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.286 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.626 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.620 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.620 mean=4.177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.357 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.566 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.590 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.590 mean=4.171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.388 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.667 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.620 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.620 mean=4.225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.429 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.707 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.600 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.600 mean=4.245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-VIS] alpha=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.541 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.788 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.660 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.660 mean=4.330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF-VIS alpha tuning summary (lower better):\n  alpha=0.1: worst=4.480 mean=3.891\n  alpha=0.12: worst=4.520 mean=3.877\n  alpha=0.14: worst=4.510 mean=3.884\n  alpha=0.16: worst=4.470 mean=3.860\n  alpha=0.18: worst=4.430 mean=3.830\n  alpha=0.2: worst=4.490 mean=3.826\n  alpha=0.22: worst=4.550 mean=3.873\n  alpha=0.24: worst=4.580 mean=3.893\n  alpha=0.26: worst=4.510 mean=3.891\n  alpha=0.28: worst=4.500 mean=3.874\n  alpha=0.3: worst=4.510 mean=3.921\n  alpha=0.32: worst=4.540 mean=3.958\n  alpha=0.34: worst=4.540 mean=3.965\n  alpha=0.36: worst=4.580 mean=4.019\n  alpha=0.38: worst=4.580 mean=4.069\n  alpha=0.4: worst=4.600 mean=4.134\n  alpha=0.42: worst=4.620 mean=4.177\n  alpha=0.44: worst=4.590 mean=4.171\n  alpha=0.46: worst=4.620 mean=4.225\n  alpha=0.48: worst=4.600 mean=4.245\n  alpha=0.5: worst=4.660 mean=4.330\nChosen alpha (VIS by worst then mean): 0.18\nVIS Step 2: Fuse + decode test with best alpha ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VIS] test decoded 20/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VIS] test decoded 40/95 elapsed=1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VIS] test decoded 60/95 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VIS] test decoded 80/95 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [VIS] test decoded 95/95 elapsed=2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_fused_visualavg_alpha018.csv rows= 95 head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 12 5 9 19 7 13 20 18 11 3 4 6 8 14 10 ...\n3  303  18 13 4 3 10 14 6 5 19 20 17 7 11 16 9 2 12 8 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 6 17 16 4 15 1...\nsubmission.csv written -> submission_fused_visualavg_alpha018.csv\nVisual-avg fusion pipeline complete.\n"
          ]
        }
      ]
    },
    {
      "id": "e6128dc2-041c-447a-9ad9-e4e752fd98f8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hedge: separate alphas for color/depth/user with constraint sum<=0.5; PoE vs skeleton; OOF select by worst then mean; test decode\n",
        "import numpy as np, json, time, os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "probs_cache = Path('probs_cache')\n",
        "\n",
        "def load_stream_prob(sid: int, stream: str, split: str) -> np.ndarray | None:\n",
        "    # stream keys: 'rgb' (color), 'depth', 'user'\n",
        "    p = probs_cache / f\"{sid}_{stream}.npy\"\n",
        "    if not p.exists():\n",
        "        return None\n",
        "    a = np.load(p).astype(np.float32)\n",
        "    # ensure normalized per frame\n",
        "    a = a / (a.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return a\n",
        "\n",
        "def align_to_skel_stream(p_stream: np.ndarray, p_skel: np.ndarray, max_shift: int = 15):\n",
        "    # re-use align_rgb_to_skel (works for any per-frame prob stream)\n",
        "    return align_rgb_to_skel(p_stream, p_skel, max_shift=max_shift)\n",
        "\n",
        "def fuse_weighted_poe(ps: np.ndarray, streams: list[tuple[np.ndarray, float]]) -> np.ndarray:\n",
        "    # ps: CxT skeleton; streams: list of (p_stream_aligned, alpha_stream)\n",
        "    # Compute normalized weights: skeleton weight = 1 - sum(alphas_present), clamp >= 0\n",
        "    alpha_sum = float(sum(w for _, w in streams))\n",
        "    w_s = max(0.0, 1.0 - alpha_sum)\n",
        "    logp = w_s * np.log(np.clip(ps, 1e-8, 1.0))\n",
        "    for (p, w) in streams:\n",
        "        logp += float(w) * np.log(np.clip(p, 1e-8, 1.0))\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def build_visual_streams_aligned(sid: int, p_skel_full: np.ndarray, max_shift: int = 15):\n",
        "    out = []  # list of (name, p_aligned, ps_cropped)\n",
        "    # color\n",
        "    prgb = load_stream_prob(sid, 'rgb', split='oof')\n",
        "    if prgb is not None:\n",
        "        pr, ps = align_to_skel_stream(prgb, p_skel_full, max_shift=max_shift); out.append(('rgb', pr, ps)); p_skel_full = ps\n",
        "    # depth\n",
        "    pdep = load_stream_prob(sid, 'depth', split='oof')\n",
        "    if pdep is not None:\n",
        "        pr, ps = align_to_skel_stream(pdep, p_skel_full, max_shift=max_shift); out.append(('depth', pr, ps)); p_skel_full = ps\n",
        "    # user\n",
        "    pusr = load_stream_prob(sid, 'user', split='oof')\n",
        "    if pusr is not None:\n",
        "        pr, ps = align_to_skel_stream(pusr, p_skel_full, max_shift=max_shift); out.append(('user', pr, ps)); p_skel_full = ps\n",
        "    if not out:\n",
        "        return None\n",
        "    # crop all to common T and return streams list and cropped skeleton\n",
        "    Tm = min(s[1].shape[1] for s in out)\n",
        "    streams = [(name, p[:, :Tm]) for (name, p, _) in out]\n",
        "    ps_out = out[-1][2][:, :Tm]  # last ps after alignment/crop chain matches Tm\n",
        "    ps_out /= (ps_out.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return streams, ps_out\n",
        "\n",
        "def oof_tune_separate_alphas(alpha_color_list=(0.15,0.20,0.25), alpha_du_list=(0.05,0.10,0.15), mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04, alpha_cap=0.5):\n",
        "    with open('folds_archive_cv.json') as f:\n",
        "        folds_list_local = json.load(f)\n",
        "    candidates = []\n",
        "    for ac in alpha_color_list:\n",
        "        for adu in alpha_du_list:\n",
        "            # enforce sum constraint with both depth and user equal to adu\n",
        "            if (ac + adu + adu) <= alpha_cap:\n",
        "                candidates.append((round(ac, 3), round(adu, 3)))\n",
        "    worst_by={}; mean_by={}\n",
        "    for (ac, adu) in candidates:\n",
        "        per_fold=[]\n",
        "        print(f'[OOF-sep] alpha_color={ac} alpha_depth=alpha_user={adu} (sum={ac+2*adu:.2f})', flush=True)\n",
        "        for fd in folds_list_local:\n",
        "            tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "            med, q75 = compute_runlen_stats(tr_ids); md = build_min_dur(med, q75, mult=mult)\n",
        "            dists=[]; n=0\n",
        "            for sid in va_ids:\n",
        "                p_skel_full = load_probs(int(sid)).astype(np.float32)\n",
        "                built = build_visual_streams_aligned(int(sid), p_skel_full, max_shift=15)\n",
        "                if built is None:\n",
        "                    # Fallback to color-only if exists; else skip\n",
        "                    prgb = load_stream_prob(int(sid), 'rgb', split='oof')\n",
        "                    if prgb is None:\n",
        "                        continue\n",
        "                    pr, ps = align_to_skel_stream(prgb, p_skel_full, max_shift=15)\n",
        "                    pf = fuse_weighted_poe(ps, [(pr, ac)])\n",
        "                else:\n",
        "                    streams_aligned, ps = built  # list of (name, p)\n",
        "                    streams_w = []\n",
        "                    for name, p in streams_aligned:\n",
        "                        w = ac if name=='rgb' else adu\n",
        "                        if w > 0:\n",
        "                            streams_w.append((p, w))\n",
        "                    pf = fuse_weighted_poe(ps, streams_w)\n",
        "                y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "                seq=[]; last=-1\n",
        "                for c in y_hat:\n",
        "                    if c==0: continue\n",
        "                    if c!=last: seq.append(int(c)); last=int(c)\n",
        "                y_true = load_frame_labels(int(sid)); seq_true=[]; last=-1\n",
        "                for c in y_true:\n",
        "                    if c==0: continue\n",
        "                    if c!=last: seq_true.append(int(c)); last=int(c)\n",
        "                # Levenshtein\n",
        "                n1=len(seq); n2=len(seq_true)\n",
        "                if n1==0: d = n2\n",
        "                elif n2==0: d = n1\n",
        "                else:\n",
        "                    dp=list(range(n2+1))\n",
        "                    for i in range(1,n1+1):\n",
        "                        prev=dp[0]; dp[0]=i; ai=seq[i-1]\n",
        "                        for j in range(1,n2+1):\n",
        "                            tmp=dp[j]; dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==seq_true[j-1] else 1)); prev=tmp\n",
        "                    d=dp[n2]\n",
        "                dists.append(float(d)); n+=1\n",
        "            mval = float(np.mean(dists)) if dists else 0.0\n",
        "            per_fold.append(mval)\n",
        "            print(f'  fold {fd[\"fold\"]}: mean={mval:.3f} (n={len(dists)})', flush=True)\n",
        "        worst_by[(ac, adu)] = max(per_fold); mean_by[(ac, adu)] = float(np.mean(per_fold))\n",
        "        print(f'  -> worst={worst_by[(ac,adu)]:.3f} mean={mean_by[(ac,adu)]:.3f}', flush=True)\n",
        "    print('OOF-separate alpha summary (lower better):')\n",
        "    for (ac, adu) in candidates:\n",
        "        print(f'  ac={ac} adu={adu}: worst={worst_by[(ac,adu)]:.3f} mean={mean_by[(ac,adu)]:.3f}')\n",
        "    best = min(candidates, key=lambda k: (worst_by[k], mean_by[k])) if candidates else None\n",
        "    print('Chosen (alpha_color, alpha_depth=user):', best)\n",
        "    return best, worst_by, mean_by\n",
        "\n",
        "def fuse_decode_test_separate_alphas(ac: float, adu: float, mult: float = 0.7, smooth_k: int = 5, aba_len: int = 2, aba_ratio: float = 1.04, out_csv: str = 'submission_fused_sepalphas.csv'):\n",
        "    # duration stats from all training ids\n",
        "    all_train_ids=[]\n",
        "    for fd in json.load(open('folds_archive_cv.json','r')):\n",
        "        all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "    med, q75 = compute_runlen_stats(sorted(set(all_train_ids))); md = build_min_dur(med, q75, mult=mult)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    rows=[]; ids=[]; n=0; t0=time.time()\n",
        "    for sid in test_ids:\n",
        "        p2 = probs_cache/f\"{sid}_ce.npy\"; p3 = probs_cache/f\"{sid}_ce_v3.npy\"\n",
        "        if not (p2.exists() and p3.exists()):\n",
        "            continue\n",
        "        p_skel_full = load_probs(int(sid)).astype(np.float32)\n",
        "        built = build_visual_streams_aligned(int(sid), p_skel_full, max_shift=15)\n",
        "        if built is None:\n",
        "            # fallback: if color exists, use it; else skeleton-only\n",
        "            prgbp = probs_cache/f\"{sid}_rgb.npy\"\n",
        "            if prgbp.exists():\n",
        "                prgb = np.load(prgbp).astype(np.float32); pr, ps = align_to_skel_stream(prgb, p_skel_full, max_shift=15)\n",
        "                pf = fuse_weighted_poe(ps, [(pr, ac)])\n",
        "            else:\n",
        "                pf = p_skel_full\n",
        "        else:\n",
        "            streams_aligned, ps = built\n",
        "            streams_w=[]\n",
        "            for name, p in streams_aligned:\n",
        "                w = ac if name=='rgb' else adu\n",
        "                if w > 0: streams_w.append((p, w))\n",
        "            pf = fuse_weighted_poe(ps, streams_w)\n",
        "        y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "        # perm20\n",
        "        seq_raw=[]; last=-1\n",
        "        for c in y_hat:\n",
        "            if c==0: continue\n",
        "            if c!=last: seq_raw.append(int(c)); last=int(c)\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95:\n",
        "            print(f'  [SEP] test decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, 'rows=', len(sub), 'head:\\n', sub.head())\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('SEP Step 1: OOF tune separate alphas with sum<=0.5 ...', flush=True)\n",
        "best_sep, worst_by_sep, mean_by_sep = oof_tune_separate_alphas(alpha_color_list=(0.15,0.20,0.25), alpha_du_list=(0.05,0.10,0.15), mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04, alpha_cap=0.5)\n",
        "if best_sep is not None:\n",
        "    ac, adu = best_sep\n",
        "    print('SEP Step 2: Fuse + decode test with best separate alphas ...', flush=True)\n",
        "    out_csv_sep = f'submission_fused_sepalphas_ac{str(ac).replace(\".\", \"\")}_adu{str(adu).replace(\".\", \"\")}.csv'\n",
        "    fuse_decode_test_separate_alphas(ac=ac, adu=adu, mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04, out_csv=out_csv_sep)\n",
        "else:\n",
        "    print('No valid alpha combos under constraint; skipping separate-alphas submission.')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEP Step 1: OOF tune separate alphas with sum<=0.5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-sep] alpha_color=0.15 alpha_depth=alpha_user=0.05 (sum=0.25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=3.969 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.162 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.490 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.490 mean=3.874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-sep] alpha_color=0.15 alpha_depth=alpha_user=0.1 (sum=0.35)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.092 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.343 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.470 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.470 mean=3.968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-sep] alpha_color=0.15 alpha_depth=alpha_user=0.15 (sum=0.45)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.306 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.576 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.600 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.600 mean=4.161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-sep] alpha_color=0.2 alpha_depth=alpha_user=0.05 (sum=0.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.020 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.212 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.440 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.440 mean=3.891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-sep] alpha_color=0.2 alpha_depth=alpha_user=0.1 (sum=0.40)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.133 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.455 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.530 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.530 mean=4.039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-sep] alpha_color=0.2 alpha_depth=alpha_user=0.15 (sum=0.50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.418 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.727 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.580 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.580 mean=4.242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-sep] alpha_color=0.25 alpha_depth=alpha_user=0.05 (sum=0.35)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.092 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.242 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.440 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.440 mean=3.925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-sep] alpha_color=0.25 alpha_depth=alpha_user=0.1 (sum=0.45)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=4.367 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=3.586 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=4.520 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.520 mean=4.158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF-separate alpha summary (lower better):\n  ac=0.15 adu=0.05: worst=4.490 mean=3.874\n  ac=0.15 adu=0.1: worst=4.470 mean=3.968\n  ac=0.15 adu=0.15: worst=4.600 mean=4.161\n  ac=0.2 adu=0.05: worst=4.440 mean=3.891\n  ac=0.2 adu=0.1: worst=4.530 mean=4.039\n  ac=0.2 adu=0.15: worst=4.580 mean=4.242\n  ac=0.25 adu=0.05: worst=4.440 mean=3.925\n  ac=0.25 adu=0.1: worst=4.520 mean=4.158\nChosen (alpha_color, alpha_depth=user): (0.2, 0.05)\nSEP Step 2: Fuse + decode test with best separate alphas ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [SEP] test decoded 20/95 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [SEP] test decoded 40/95 elapsed=1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [SEP] test decoded 60/95 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [SEP] test decoded 80/95 elapsed=2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [SEP] test decoded 95/95 elapsed=2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_fused_sepalphas_ac02_adu005.csv rows= 95 head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 12 5 9 19 13 20 18 11 3 4 6 8 14 10 2 ...\n3  303  18 13 4 3 10 14 6 5 19 20 17 7 11 16 9 2 12 1 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 6 17 16 4 12 1...\nsubmission.csv written -> submission_fused_sepalphas_ac02_adu005.csv\n"
          ]
        }
      ]
    },
    {
      "id": "1f48ddce-0479-404a-ba19-0defd1080ade",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Order-only decoder on fused probs (skeleton + color PoE), OOF sweep and test submission\n",
        "import numpy as np, json, time, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "probs_cache = Path('probs_cache')\n",
        "\n",
        "# Reuse: load_probs (aligned v2+v3), align_rgb_to_skel, fuse_geometric, load_frame_labels, compute_runlen_stats etc.\n",
        "\n",
        "def fused_poe_skel_rgb(sid: int, alpha: float = 0.26) -> np.ndarray:\n",
        "    # returns CxT fused probs (aligned RGB->skeleton, PoE with weight alpha); fallback to skeleton-only if RGB missing\n",
        "    p_skel = load_probs(int(sid)).astype(np.float32)\n",
        "    prgb = probs_cache/f\"{sid}_rgb.npy\"\n",
        "    if prgb.exists():\n",
        "        p_rgb = np.load(prgb).astype(np.float32)\n",
        "        pr, ps = align_rgb_to_skel(p_rgb, p_skel, max_shift=15)\n",
        "        pf = fuse_geometric(ps, pr, alpha=float(alpha))\n",
        "        return pf\n",
        "    else:\n",
        "        return p_skel\n",
        "\n",
        "def smooth_probs_time(p: np.ndarray, k: int = 5) -> np.ndarray:\n",
        "    if k <= 1: return p\n",
        "    C,T = p.shape; pad = k//2\n",
        "    x = np.pad(p, ((0,0),(pad,pad)), mode='edge')\n",
        "    y = np.empty_like(p, dtype=np.float32)\n",
        "    for t in range(T):\n",
        "        y[:,t] = x[:, t:t+k].mean(axis=1)\n",
        "    y = np.clip(y, 1e-8, None)\n",
        "    y /= (y.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return y\n",
        "\n",
        "def order_only_perm20(p: np.ndarray, gamma: float = 1.0, smooth_k: int = 5) -> list:\n",
        "    # p: CxT, class 0 is background. Returns a permutation of [1..20] by center-of-mass.\n",
        "    q = smooth_probs_time(p, k=smooth_k) if smooth_k and smooth_k>1 else p\n",
        "    C,T = q.shape\n",
        "    idx = np.arange(T, dtype=np.float32)\n",
        "    stats = []\n",
        "    for c in range(1, min(21, C)):\n",
        "        w = np.power(np.clip(q[c], 1e-8, 1.0), float(gamma))\n",
        "        s = float(w.sum()) + 1e-8\n",
        "        tbar = float((idx * w).sum() / s)\n",
        "        stats.append((tbar, c))\n",
        "    stats.sort(key=lambda x: x[0])\n",
        "    perm = [c for _, c in stats][:20]\n",
        "    # ensure it is exactly a permutation of 1..20 (fill any missed due to C mismatch)\n",
        "    seen = set(perm)\n",
        "    for c in range(1,21):\n",
        "        if c not in seen:\n",
        "            perm.append(c)\n",
        "    return perm[:20]\n",
        "\n",
        "def compress_to_sequence(y_frames):\n",
        "    seq=[]; last=-1\n",
        "    for c in y_frames:\n",
        "        if c==0: continue\n",
        "        if c!=last: seq.append(int(c)); last=int(c)\n",
        "    return seq\n",
        "\n",
        "def levenshtein(a,b):\n",
        "    n,m=len(a),len(b)\n",
        "    if n==0: return m\n",
        "    if m==0: return n\n",
        "    dp=list(range(m+1))\n",
        "    for i in range(1,n+1):\n",
        "        prev=dp[0]; dp[0]=i; ai=a[i-1]\n",
        "        for j in range(1,m+1):\n",
        "            tmp=dp[j]\n",
        "            dp[j]=min(dp[j]+1, dp[j-1]+1, prev + (0 if ai==b[j-1] else 1)); prev=tmp\n",
        "    return dp[m]\n",
        "\n",
        "def oof_sweep_order_only(alpha: float = 0.26, gamma_list=(1.0,1.2,1.5,2.0), smooth_list=(3,5)):\n",
        "    with open('folds_archive_cv.json') as f:\n",
        "        folds_local = json.load(f)\n",
        "    results = []  # list of (worst, mean, gamma, smooth_k)\n",
        "    for g in gamma_list:\n",
        "        for k in smooth_list:\n",
        "            per_fold=[]\n",
        "            print(f'[OOF-ORDER] gamma={g} smooth_k={k}', flush=True)\n",
        "            for fd in folds_local:\n",
        "                va_ids = list(map(int, fd['val_ids']))\n",
        "                dists=[]\n",
        "                for sid in va_ids:\n",
        "                    p = fused_poe_skel_rgb(int(sid), alpha=alpha)\n",
        "                    perm = order_only_perm20(p, gamma=g, smooth_k=k)\n",
        "                    y_true = load_frame_labels(int(sid))\n",
        "                    seq_true = compress_to_sequence(y_true)\n",
        "                    dists.append(levenshtein(perm, seq_true))\n",
        "                mval = float(np.mean(dists)) if dists else 0.0\n",
        "                per_fold.append(mval)\n",
        "                print(f'  fold {fd[\"fold\"]}: mean={mval:.3f} (n={len(dists)})', flush=True)\n",
        "            worst = max(per_fold); mean_v = float(np.mean(per_fold))\n",
        "            results.append((worst, mean_v, g, k))\n",
        "            print(f'  -> worst={worst:.3f} mean={mean_v:.3f}', flush=True)\n",
        "    results.sort(key=lambda x: (x[0], x[1]))\n",
        "    print('OOF-ORDER summary (top 5 by worst then mean):')\n",
        "    for r in results[:5]:\n",
        "        print(r)\n",
        "    best = results[0] if results else None\n",
        "    return best, results\n",
        "\n",
        "def decode_test_order_only(alpha: float, gamma: float, smooth_k: int, out_csv: str = 'submission_order_only.csv'):\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    rows=[]; ids=[]; t0=time.time(); n=0\n",
        "    for sid in test_ids:\n",
        "        # need skeleton probs at least\n",
        "        p2 = probs_cache/f\"{sid}_ce.npy\"; p3 = probs_cache/f\"{sid}_ce_v3.npy\"\n",
        "        if not (p2.exists() and p3.exists()):\n",
        "            continue\n",
        "        p = fused_poe_skel_rgb(int(sid), alpha=alpha)\n",
        "        perm = order_only_perm20(p, gamma=gamma, smooth_k=smooth_k)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, perm))); n+=1\n",
        "        if (n%20)==0 or n==95:\n",
        "            print(f'  [ORDER] test decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, 'rows=', len(sub), 'head:\\n', sub.head())\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    # mirror to submission.csv\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('ORDER Step 1: OOF sweep on gamma and smoothing for PoE(skel+RGB, alpha=0.26)...', flush=True)\n",
        "best_ord, all_ord = oof_sweep_order_only(alpha=0.26, gamma_list=(1.0,1.2,1.5,2.0), smooth_list=(3,5))\n",
        "if best_ord is not None:\n",
        "    worst, mean_v, g_best, k_best = best_ord\n",
        "    print('Chosen (gamma, smooth_k):', g_best, k_best, '-> worst=', worst, 'mean=', mean_v)\n",
        "    print('ORDER Step 2: Decode test with best params ...', flush=True)\n",
        "    out_csv = f'submission_order_only_poe_rgb_a026_g{str(g_best).replace(\".\", \"\")}_k{k_best}.csv'\n",
        "    decode_test_order_only(alpha=0.26, gamma=g_best, smooth_k=k_best, out_csv=out_csv)\n",
        "else:\n",
        "    print('Order-only OOF produced no results; skipping decode.')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORDER Step 1: OOF sweep on gamma and smoothing for PoE(skel+RGB, alpha=0.26)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ORDER] gamma=1.0 smooth_k=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=13.276 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=12.697 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=13.240 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=13.276 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=12.697 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=13.240 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=13.276 mean=13.071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ORDER] gamma=1.2 smooth_k=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=12.653 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=11.980 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=12.550 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=12.653 mean=12.394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ORDER] gamma=1.2 smooth_k=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=12.653 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=11.980 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=12.550 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=12.653 mean=12.394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ORDER] gamma=1.5 smooth_k=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=11.398 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=10.556 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=11.590 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=11.590 mean=11.181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ORDER] gamma=1.5 smooth_k=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=11.398 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=10.545 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=11.570 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=11.570 mean=11.171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ORDER] gamma=2.0 smooth_k=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=9.714 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=8.374 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=9.920 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=9.920 mean=9.336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-ORDER] gamma=2.0 smooth_k=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 0: mean=9.694 (n=98)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 1: mean=8.384 (n=99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  fold 2: mean=9.910 (n=100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=9.910 mean=9.329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF-ORDER summary (top 5 by worst then mean):\n(9.91, 9.329238644952932, 2.0, 5)\n(9.92, 9.336007696007696, 2.0, 3)\n(11.57, 11.171137909709339, 1.5, 5)\n(11.59, 11.181171579743008, 1.5, 3)\n(12.653061224489797, 12.39428640142926, 1.2, 3)\nChosen (gamma, smooth_k): 2.0 5 -> worst= 9.91 mean= 9.329238644952932\nORDER Step 2: Decode test with best params ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [ORDER] test decoded 20/95 elapsed=0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [ORDER] test decoded 40/95 elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 129\u001b[39m\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mORDER Step 2: Decode test with best params ...\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    128\u001b[39m     out_csv = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33msubmission_order_only_poe_rgb_a026_g\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(g_best).replace(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_k\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_best\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[43mdecode_test_order_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.26\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mg_best\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk_best\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mOrder-only OOF produced no results; skipping decode.\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mdecode_test_order_only\u001b[39m\u001b[34m(alpha, gamma, smooth_k, out_csv)\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    109\u001b[39m p = fused_poe_skel_rgb(\u001b[38;5;28mint\u001b[39m(sid), alpha=alpha)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m perm = \u001b[43morder_only_perm20\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmooth_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43msmooth_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m ids.append(sid); rows.append(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, perm))); n+=\u001b[32m1\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (n%\u001b[32m20\u001b[39m)==\u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n==\u001b[32m95\u001b[39m:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36morder_only_perm20\u001b[39m\u001b[34m(p, gamma, smooth_k)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34morder_only_perm20\u001b[39m(p: np.ndarray, gamma: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m1.0\u001b[39m, smooth_k: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# p: CxT, class 0 is background. Returns a permutation of [1..20] by center-of-mass.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     q = \u001b[43msmooth_probs_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43msmooth_k\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m smooth_k \u001b[38;5;129;01mand\u001b[39;00m smooth_k>\u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m p\n\u001b[32m     35\u001b[39m     C,T = q.shape\n\u001b[32m     36\u001b[39m     idx = np.arange(T, dtype=np.float32)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36msmooth_probs_time\u001b[39m\u001b[34m(p, k)\u001b[39m\n\u001b[32m     25\u001b[39m y = np.empty_like(p, dtype=np.float32)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     y[:,t] = \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43mt\u001b[49m\u001b[43m+\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m y = np.clip(y, \u001b[32m1e-8\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     29\u001b[39m y /= (y.sum(axis=\u001b[32m0\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[32m1e-8\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/numpy/core/_methods.py:121\u001b[39m, in \u001b[36m_mean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu.ndarray):\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m         ret = \u001b[43mum\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrue_divide\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m                \u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43munsafe\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_float16_result \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m         ret = arr.dtype.type(ret)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "9b5759b4-5c8f-4962-9865-877abfd7a242",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# RGB temporal head (Dilated TCN) on MobileNet embeddings: train per fold, temp-scale, cache OOF/test, fuse vs skeleton\n",
        "import os, json, time, random\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
        "\n",
        "rgb_emb_dir = Path('rgb_embed')\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "\n",
        "def get_T_train(sid: int) -> int:\n",
        "    return int(np.load(labels_dir / f\"{sid}.npy\").shape[0])\n",
        "\n",
        "def get_T_test(sid: int) -> int:\n",
        "    p3 = probs_cache / f\"{sid}_ce_v3.npy\"\n",
        "    if p3.exists(): return int(np.load(p3, mmap_mode='r').shape[1])\n",
        "    d = np.load(Path('features3d_v3/test')/f\"{sid}.npz\"); X = d['X'] if 'X' in d.files else d[d.files[0]]; return int(X.shape[0])\n",
        "\n",
        "def upsample_to_T_np(E: np.ndarray, T: int) -> np.ndarray:\n",
        "    if E.shape[0] == T: return E.astype(np.float32)\n",
        "    if E.shape[0] == 0: return np.zeros((T, E.shape[1] if E.ndim==2 else 1280), dtype=np.float32)\n",
        "    import torch.nn.functional as Fnn\n",
        "    x = torch.from_numpy(E.astype(np.float32)).unsqueeze(0).transpose(1,2)\n",
        "    y = Fnn.interpolate(x, size=T, mode='linear', align_corners=False).transpose(1,2).squeeze(0).contiguous()\n",
        "    return y.numpy().astype(np.float32)\n",
        "\n",
        "class RGBEmbDataset(Dataset):\n",
        "    def __init__(self, ids: List[int], chunk_len: int = 2048):\n",
        "        self.ids = list(ids); self.chunk_len = chunk_len; self.index=[]\n",
        "        for sid in self.ids:\n",
        "            E = np.load(rgb_emb_dir/'train'/f\"{sid}.npy\", mmap_mode='r')\n",
        "            T = get_T_train(sid); Eu = upsample_to_T_np(np.array(E), T); n = Eu.shape[0]\n",
        "            if n <= chunk_len: self.index.append((sid, 0, n))\n",
        "            else:\n",
        "                s=0\n",
        "                while s < n:\n",
        "                    e = min(n, s+chunk_len); self.index.append((sid, s, e)); s = e\n",
        "        random.shuffle(self.index)\n",
        "    def __len__(self): return len(self.index)\n",
        "    def __getitem__(self, i):\n",
        "        sid, s, e = self.index[i]\n",
        "        E = np.load(rgb_emb_dir/'train'/f\"{sid}.npy\", mmap_mode='r')\n",
        "        T = get_T_train(sid); Eu = upsample_to_T_np(np.array(E), T)\n",
        "        y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "        x = Eu[s:e].astype(np.float32); t = y[s:e]\n",
        "        return torch.from_numpy(x), torch.from_numpy(t)\n",
        "\n",
        "class DilatedResBlock(nn.Module):\n",
        "    def __init__(self, ch, dilation, drop=0.35, groups=8, k=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(ch, ch, k, padding=dilation, dilation=dilation)\n",
        "        self.gn1 = nn.GroupNorm(groups, ch)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.conv2 = nn.Conv1d(ch, ch, 1)\n",
        "        self.gn2 = nn.GroupNorm(groups, ch)\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x); h = self.gn1(h); h = F.relu(h, inplace=True); h = self.drop(h)\n",
        "        h = self.conv2(h); h = self.gn2(h); h = F.relu(h, inplace=True)\n",
        "        return x + h\n",
        "\n",
        "class RGBTCNHead(nn.Module):\n",
        "    def __init__(self, d_in=1280, ch=256, layers=10, n_classes=21, dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Conv1d(d_in, ch, 1)\n",
        "        blocks=[]; dil=1\n",
        "        for _ in range(layers):\n",
        "            blocks.append(DilatedResBlock(ch, dil, drop=dropout, groups=8, k=3));\n",
        "            dil = min(dil*2, 512)\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "        self.head = nn.Conv1d(ch, n_classes, 1)\n",
        "    def forward(self, x_b_t_d):\n",
        "        x = x_b_t_d.transpose(1,2)  # B,T,D -> B,D,T\n",
        "        h = self.inp(x)\n",
        "        for b in self.blocks: h = b(h)\n",
        "        out = self.head(h)  # B,C,T\n",
        "        return out.transpose(1,2)  # B,T,C\n",
        "\n",
        "def train_rgb_tcn_fold(train_ids: List[int], val_ids: List[int], epochs: int = 16, lr: float = 2e-3, wd: float = 1e-4, chunk_len: int = 2048, batch_size: int = 1, patience: int = 4):\n",
        "        model = RGBTCNHead().to(device)\n",
        "        opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "        best = 1e18; bad=0\n",
        "        for ep in range(1, epochs+1):\n",
        "            t0=time.time(); model.train()\n",
        "            ds = RGBEmbDataset(train_ids, chunk_len=chunk_len)\n",
        "            dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "            tr_loss=0.0; n_tok=0\n",
        "            for xb, yb in dl:\n",
        "                xb=xb.to(device, non_blocking=True); yb=yb.to(device, non_blocking=True)\n",
        "                opt.zero_grad(set_to_none=True); logits = model(xb)\n",
        "                loss = F.cross_entropy(logits.reshape(-1, logits.shape[-1]), yb.reshape(-1))\n",
        "                loss.backward(); opt.step()\n",
        "                tr_loss += float(loss.item()) * yb.numel(); n_tok += int(yb.numel())\n",
        "            tr_loss /= max(1, n_tok)\n",
        "            model.eval(); val_loss=0.0; n_tok=0\n",
        "            with torch.no_grad():\n",
        "                for sid in val_ids:\n",
        "                    E = np.load(rgb_emb_dir/'train'/f\"{sid}.npy\", mmap_mode='r')\n",
        "                    T = get_T_train(sid); Eu = upsample_to_T_np(np.array(E), T)\n",
        "                    y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "                    xb = torch.from_numpy(Eu).unsqueeze(0).to(device); logits = model(xb)\n",
        "                    ll = F.cross_entropy(logits.reshape(-1, logits.shape[-1]), torch.from_numpy(y).to(device))\n",
        "                    val_loss += float(ll.item()) * int(T); n_tok += int(T)\n",
        "            val_loss /= max(1, n_tok)\n",
        "            print(f\"[RGB-TCN] ep {ep:02d} tr_nll={tr_loss:.4f} val_nll={val_loss:.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "            if val_loss < best - 1e-4: best = val_loss; bad=0; torch.save(model.state_dict(), 'rgb_tcn_tmp.pth')\n",
        "            else:\n",
        "                bad += 1\n",
        "                if bad >= patience: break\n",
        "        model.load_state_dict(torch.load('rgb_tcn_tmp.pth', map_location=device));\n",
        "        return model\n",
        "\n",
        "def infer_probs_rgb_tcn(model: nn.Module, ids: List[int], split: str, out_suffix: str):\n",
        "    model.eval(); saved=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, sid in enumerate(ids, 1):\n",
        "            if split=='train':\n",
        "                T = get_T_train(sid); emb_path = rgb_emb_dir/'train'/f\"{sid}.npy\"\n",
        "            else:\n",
        "                T = get_T_test(sid); emb_path = rgb_emb_dir/'test'/f\"{sid}.npy\"\n",
        "            if not emb_path.exists():\n",
        "                print(f\"  [RGB-TCN infer] missing emb for id={sid}, skip\"); continue\n",
        "            E = np.load(emb_path, mmap_mode='r'); Eu = upsample_to_T_np(np.array(E), T)\n",
        "            xb = torch.from_numpy(Eu).unsqueeze(0).to(device); logits = model(xb)[0]\n",
        "            p = logits.softmax(dim=-1).cpu().numpy().astype(np.float32).T  # CxT\n",
        "            p /= (p.sum(axis=0, keepdims=True) + 1e-8)\n",
        "            np.save(probs_cache/f\"{sid}{out_suffix}\", p); saved += 1\n",
        "            if (i%20)==0 or i==len(ids): print(f\"  saved {saved}/{len(ids)} split={split} {out_suffix} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "def fit_scalar_temperature_on_val(val_ids: List[int], suffix: str) -> float:\n",
        "    grid = [round(x,2) for x in np.linspace(0.8, 1.5, 15)]\n",
        "    best_T=1.0; best_nll=1e18\n",
        "    for Tval in grid:\n",
        "        nll=0.0; n_tok=0\n",
        "        for sid in val_ids:\n",
        "            p = np.load(probs_cache/f\"{sid}{suffix}\")\n",
        "            y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "            logp = np.log(np.clip(p, 1e-8, 1.0)) / float(Tval)\n",
        "            q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "            idx = (y >= 0) & (y < q.shape[0]); yy = y[idx]\n",
        "            nll += -float(np.log(q[yy, np.nonzero(idx)[0]] + 1e-8).sum()); n_tok += int(idx.sum())\n",
        "        if n_tok>0:\n",
        "            nll /= float(n_tok)\n",
        "            if nll < best_nll: best_nll = nll; best_T = Tval\n",
        "    print(f\"[Temp RGB-TCN] best T={best_T} NLL={best_nll:.4f} on {len(val_ids)} val ids\", flush=True)\n",
        "    return float(best_T)\n",
        "\n",
        "def average_test_rgbt_with_fold_temps():\n",
        "    Ts=[]\n",
        "    for f in range(3):\n",
        "        jf = Path(f'rgbt_temp_fold{f}.json')\n",
        "        if jf.exists():\n",
        "            try: Ts.append(float(json.loads(jf.read_text())['T']))\n",
        "            except Exception: Ts.append(1.0)\n",
        "        else: Ts.append(1.0)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    n_avg=0\n",
        "    for sid in test_ids:\n",
        "        arrs=[]\n",
        "        for f in range(3):\n",
        "            p = probs_cache/f\"{sid}_rgbt_f{f}.npy\"\n",
        "            if p.exists():\n",
        "                a = np.load(p, mmap_mode='r').astype(np.float32)\n",
        "                logp = np.log(np.clip(a, 1e-8, 1.0)) / float(Ts[f])\n",
        "                q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "                arrs.append(q)\n",
        "        if not arrs: continue\n",
        "        Tm = min(a.shape[1] for a in arrs); arrs = [a[:, :Tm] for a in arrs]\n",
        "        m = np.mean(arrs, axis=0); m /= (m.sum(axis=0, keepdims=True) + 1e-8)\n",
        "        np.save(probs_cache/f\"{sid}_rgbt.npy\", m.astype(np.float32)); n_avg+=1\n",
        "    print('Averaged TEST per-fold -> rgbt.npy for', n_avg, 'ids')\n",
        "\n",
        "print('Training RGB-TCN head per fold...', flush=True)\n",
        "folds_list = json.load(open('folds_archive_cv.json','r'))\n",
        "test_ids_list = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "for fd in folds_list:\n",
        "    fidx = int(fd['fold'])\n",
        "    tr_ids = list(map(int, fd['train_ids']))\n",
        "    va_ids = list(map(int, fd['val_ids']))\n",
        "    print(f'Fold {fidx}: train={len(tr_ids)} val={len(va_ids)}', flush=True)\n",
        "    model = train_rgb_tcn_fold(tr_ids, va_ids, epochs=16, lr=2e-3, wd=1e-4, chunk_len=2048, batch_size=1, patience=4)\n",
        "    # OOF (val) -> save {id}_rgbt.npy\n",
        "    infer_probs_rgb_tcn(model, va_ids, split='train', out_suffix='_rgbt.npy')\n",
        "    # TEST per-fold -> save {id}_rgbt_f{f}.npy\n",
        "    infer_probs_rgb_tcn(model, test_ids_list, split='test', out_suffix=f'_rgbt_f{fidx}.npy')\n",
        "    # Fit temp on val and apply to OOF\n",
        "    Tbest = fit_scalar_temperature_on_val(va_ids, suffix='_rgbt.npy')\n",
        "    for sid in va_ids:\n",
        "        p = np.load(probs_cache/f\"{sid}_rgbt.npy\")\n",
        "        logp = np.log(np.clip(p, 1e-8, 1.0)) / float(Tbest)\n",
        "        q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "        np.save(probs_cache/f\"{sid}_rgbt.npy\", q.astype(np.float32))\n",
        "    Path(f'rgbt_temp_fold{fidx}.json').write_text(json.dumps({'T': Tbest}))\n",
        "\n",
        "print('Calibrating TEST per-fold RGB-TCN and averaging...', flush=True)\n",
        "average_test_rgbt_with_fold_temps()\n",
        "\n",
        "# Fusion: use rgbt if available; fallback to rgb\n",
        "def align_stream_to_skel(p_stream: np.ndarray, p_skel: np.ndarray, max_shift: int = 15):\n",
        "    return align_rgb_to_skel(p_stream, p_skel, max_shift=max_shift)\n",
        "\n",
        "def load_rgb_like_for_id(sid: int) -> np.ndarray | None:\n",
        "    p_rgbt = probs_cache/f\"{sid}_rgbt.npy\"\n",
        "    if p_rgbt.exists(): return np.load(p_rgbt).astype(np.float32)\n",
        "    p_rgb = probs_cache/f\"{sid}_rgb.npy\"\n",
        "    if p_rgb.exists(): return np.load(p_rgb).astype(np.float32)\n",
        "    return None\n",
        "\n",
        "def oof_alpha_tune_rgbt(alpha_list=(0.20,0.22,0.24,0.26,0.28), mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04):\n",
        "    folds_list_local = json.load(open('folds_archive_cv.json','r'))\n",
        "    worst_by={}; mean_by={}\n",
        "    for alpha in alpha_list:\n",
        "        per_fold=[]\n",
        "        print(f'[OOF-RGBT] alpha={alpha}', flush=True)\n",
        "        for fd in folds_list_local:\n",
        "            tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "            med, q75 = compute_runlen_stats(tr_ids); md = build_min_dur(med, q75, mult=mult)\n",
        "            dists=[]\n",
        "            for sid in va_ids:\n",
        "                p_rgbx = load_rgb_like_for_id(int(sid))\n",
        "                if p_rgbx is None: continue\n",
        "                p_skel = load_probs(int(sid)).astype(np.float32)\n",
        "                pr, ps = align_stream_to_skel(p_rgbx, p_skel, max_shift=15)\n",
        "                pf = fuse_geometric(ps, pr, alpha=float(alpha))\n",
        "                y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "                seq = compress_to_sequence(y_hat); seq_true = compress_to_sequence(load_frame_labels(int(sid)))\n",
        "                dists.append(levenshtein(seq, seq_true))\n",
        "            per_fold.append(float(np.mean(dists)) if dists else 0.0)\n",
        "        worst_by[alpha] = max(per_fold); mean_by[alpha] = float(np.mean(per_fold))\n",
        "        print(f\"  -> worst={worst_by[alpha]:.3f} mean={mean_by[alpha]:.3f}\", flush=True)\n",
        "    print('OOF-RGBT alpha summary:')\n",
        "    for a in alpha_list: print(f'  alpha={a}: worst={worst_by[a]:.3f} mean={mean_by[a]:.3f}')\n",
        "    best_alpha = min(alpha_list, key=lambda a: (worst_by[a], mean_by[a]))\n",
        "    print('Chosen alpha (RGBT):', best_alpha)\n",
        "    return best_alpha, worst_by, mean_by\n",
        "\n",
        "def fuse_decode_test_rgbt(alpha: float, mult: float = 0.7, smooth_k: int = 5, aba_len: int = 2, aba_ratio: float = 1.04, out_csv: str = 'submission_fused_rgbt.csv'):\n",
        "    all_train_ids=[]\n",
        "    for fd in json.load(open('folds_archive_cv.json','r')): all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "    med, q75 = compute_runlen_stats(sorted(set(all_train_ids))); md = build_min_dur(med, q75, mult=mult)\n",
        "    rows=[]; ids=[]; n=0; t0=time.time()\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    for sid in test_ids:\n",
        "        p2 = probs_cache/f\"{sid}_ce.npy\"; p3 = probs_cache/f\"{sid}_ce_v3.npy\"\n",
        "        if not (p2.exists() and p3.exists()): continue\n",
        "        p_skel = load_probs(int(sid)).astype(np.float32)\n",
        "        p_rgbx = load_rgb_like_for_id(int(sid))\n",
        "        if p_rgbx is not None:\n",
        "            pr, ps = align_stream_to_skel(p_rgbx, p_skel, max_shift=15)\n",
        "            pf = fuse_geometric(ps, pr, alpha=float(alpha))\n",
        "        else:\n",
        "            pf = p_skel\n",
        "        y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "        seq_raw=[]; last=-1\n",
        "        for c in y_hat:\n",
        "            if c==0: continue\n",
        "            if c!=last: seq_raw.append(int(c)); last=int(c)\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'  [RGBT] test fused decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub), 'head:\\n', sub.head())\n",
        "    assert len(sub)==95\n",
        "    sub.to_csv('submission.csv', index=False); print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('Step RGBT-1: OOF tune alpha for RGB-TCN fusion...', flush=True)\n",
        "best_alpha_rgbt, wb_rgbt, mb_rgbt = oof_alpha_tune_rgbt(alpha_list=(0.20,0.22,0.24,0.26,0.28), mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04)\n",
        "print('Step RGBT-2: Fuse + decode test with best alpha ...', flush=True)\n",
        "out_csv = f'submission_fused_rgbt_alpha{str(best_alpha_rgbt).replace(\".\", \"\")}.csv'\n",
        "fuse_decode_test_rgbt(alpha=best_alpha_rgbt, mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04, out_csv=out_csv)\n",
        "print('RGB-TCN fusion pipeline complete.')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RGB-TCN head per fold...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: train=199 val=98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 01 tr_nll=4.1517 val_nll=2.7459 elapsed=22.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 02 tr_nll=2.6981 val_nll=2.7980 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 03 tr_nll=2.4425 val_nll=3.2126 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 04 tr_nll=2.1661 val_nll=2.7739 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 05 tr_nll=1.9418 val_nll=2.6511 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 06 tr_nll=1.7229 val_nll=2.8918 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 07 tr_nll=1.5392 val_nll=3.0362 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 08 tr_nll=1.3920 val_nll=3.4897 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 09 tr_nll=1.2558 val_nll=3.5313 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/98 split=train _rgbt.npy elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_9704/1598535821.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('rgb_tcn_tmp.pth', map_location=device));\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/98 split=train _rgbt.npy elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/98 split=train _rgbt.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/98 split=train _rgbt.npy elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 98/98 split=train _rgbt.npy elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test _rgbt_f0.npy elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test _rgbt_f0.npy elapsed=1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test _rgbt_f0.npy elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test _rgbt_f0.npy elapsed=2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGB-TCN infer] missing emb for id=401, skip\n  [RGB-TCN infer] missing emb for id=402, skip\n  [RGB-TCN infer] missing emb for id=403, skip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp RGB-TCN] best T=1.5 NLL=2.4553 on 98 val ids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: train=198 val=99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 01 tr_nll=4.0053 val_nll=3.1658 elapsed=7.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 02 tr_nll=2.6128 val_nll=2.6917 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 03 tr_nll=2.4170 val_nll=2.9736 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 04 tr_nll=2.1515 val_nll=2.8452 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 05 tr_nll=1.9226 val_nll=2.9184 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 06 tr_nll=1.7267 val_nll=2.9717 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/99 split=train _rgbt.npy elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/99 split=train _rgbt.npy elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/99 split=train _rgbt.npy elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/99 split=train _rgbt.npy elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 99/99 split=train _rgbt.npy elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test _rgbt_f1.npy elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test _rgbt_f1.npy elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test _rgbt_f1.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test _rgbt_f1.npy elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGB-TCN infer] missing emb for id=401, skip\n  [RGB-TCN infer] missing emb for id=402, skip\n  [RGB-TCN infer] missing emb for id=403, skip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp RGB-TCN] best T=1.15 NLL=2.6831 on 99 val ids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: train=197 val=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 01 tr_nll=3.7669 val_nll=4.4986 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 02 tr_nll=2.3747 val_nll=3.8667 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 03 tr_nll=2.0153 val_nll=3.7545 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 04 tr_nll=1.7417 val_nll=4.0578 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 05 tr_nll=1.5132 val_nll=3.6272 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 06 tr_nll=1.3995 val_nll=4.3459 elapsed=4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 07 tr_nll=1.2881 val_nll=4.0081 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 08 tr_nll=1.2012 val_nll=4.2809 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RGB-TCN] ep 09 tr_nll=1.0690 val_nll=3.9608 elapsed=4.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/100 split=train _rgbt.npy elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/100 split=train _rgbt.npy elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/100 split=train _rgbt.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/100 split=train _rgbt.npy elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 100/100 split=train _rgbt.npy elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 20/95 split=test _rgbt_f2.npy elapsed=0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 40/95 split=test _rgbt_f2.npy elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 60/95 split=test _rgbt_f2.npy elapsed=0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  saved 80/95 split=test _rgbt_f2.npy elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGB-TCN infer] missing emb for id=401, skip\n  [RGB-TCN infer] missing emb for id=402, skip\n  [RGB-TCN infer] missing emb for id=403, skip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Temp RGB-TCN] best T=1.5 NLL=3.0840 on 100 val ids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibrating TEST per-fold RGB-TCN and averaging...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averaged TEST per-fold -> rgbt.npy for 92 ids\nStep RGBT-1: OOF tune alpha for RGB-TCN fusion...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT] alpha=0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.520 mean=3.844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT] alpha=0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.560 mean=3.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT] alpha=0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.590 mean=3.907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT] alpha=0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.610 mean=3.921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT] alpha=0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.600 mean=3.938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF-RGBT alpha summary:\n  alpha=0.2: worst=4.520 mean=3.844\n  alpha=0.22: worst=4.560 mean=3.884\n  alpha=0.24: worst=4.590 mean=3.907\n  alpha=0.26: worst=4.610 mean=3.921\n  alpha=0.28: worst=4.600 mean=3.938\nChosen alpha (RGBT): 0.2\nStep RGBT-2: Fuse + decode test with best alpha ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGBT] test fused decoded 20/95 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGBT] test fused decoded 40/95 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGBT] test fused decoded 60/95 elapsed=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGBT] test fused decoded 80/95 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGBT] test fused decoded 95/95 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_fused_rgbt_alpha02.csv rows= 95 head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 19 7 1...\n1  301  10 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 7 1...\n2  302  1 17 16 3 5 9 19 13 20 18 11 4 6 8 14 10 2 7 1...\n3  303  17 13 4 3 10 14 6 5 19 20 2 11 16 18 9 7 15 1 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 6 17 16 4 15 1...\nsubmission.csv written -> submission_fused_rgbt_alpha02.csv\nRGB-TCN fusion pipeline complete.\n"
          ]
        }
      ]
    },
    {
      "id": "b63a6b0e-46a6-4373-b1e3-29833f94a0b3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# RGBT PoE with smoother k=3 and tight alpha grid; fuse+decode test\n",
        "import numpy as np, json, pandas as pd, time\n",
        "from pathlib import Path\n",
        "\n",
        "def oof_alpha_tune_rgbt_s3(alpha_list=(0.18,0.20,0.22,0.24,0.26,0.28,0.30), mult=0.7, smooth_k=3, aba_len=2, aba_ratio=1.04):\n",
        "    folds_list_local = json.load(open('folds_archive_cv.json','r'))\n",
        "    worst_by={}; mean_by={}\n",
        "    for alpha in alpha_list:\n",
        "        per_fold=[]\n",
        "        print(f'[OOF-RGBT-s3] alpha={alpha}', flush=True)\n",
        "        for fd in folds_list_local:\n",
        "            tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "            med, q75 = compute_runlen_stats(tr_ids); md = build_min_dur(med, q75, mult=mult)\n",
        "            dists=[]\n",
        "            for sid in va_ids:\n",
        "                p_rgbx = None\n",
        "                prgbt = Path('probs_cache')/f\"{sid}_rgbt.npy\"\n",
        "                if prgbt.exists(): p_rgbx = np.load(prgbt).astype(np.float32)\n",
        "                elif (Path('probs_cache')/f\"{sid}_rgb.npy\").exists(): p_rgbx = np.load(Path('probs_cache')/f\"{sid}_rgb.npy\").astype(np.float32)\n",
        "                if p_rgbx is None: continue\n",
        "                p_skel = load_probs(int(sid)).astype(np.float32)\n",
        "                pr, ps = align_rgb_to_skel(p_rgbx, p_skel, max_shift=15)\n",
        "                pf = fuse_geometric(ps, pr, alpha=float(alpha))\n",
        "                y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "                seq = compress_to_sequence(y_hat); seq_true = compress_to_sequence(load_frame_labels(int(sid)))\n",
        "                dists.append(levenshtein(seq, seq_true))\n",
        "            per_fold.append(float(np.mean(dists)) if dists else 0.0)\n",
        "        worst_by[alpha] = max(per_fold); mean_by[alpha] = float(np.mean(per_fold))\n",
        "        print(f\"  -> worst={worst_by[alpha]:.3f} mean={mean_by[alpha]:.3f}\", flush=True)\n",
        "    print('OOF-RGBT-s3 alpha summary:')\n",
        "    for a in alpha_list: print(f'  alpha={a}: worst={worst_by[a]:.3f} mean={mean_by[a]:.3f}')\n",
        "    best_alpha = min(alpha_list, key=lambda a: (worst_by[a], mean_by[a]))\n",
        "    print('Chosen alpha (RGBT-s3):', best_alpha)\n",
        "    return best_alpha, worst_by, mean_by\n",
        "\n",
        "def fuse_decode_test_rgbt_s3(alpha: float, mult: float = 0.7, smooth_k: int = 3, aba_len: int = 2, aba_ratio: float = 1.04, out_csv: str = 'submission_fused_rgbt_s3.csv'):\n",
        "    all_train_ids=[]\n",
        "    for fd in json.load(open('folds_archive_cv.json','r')): all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "    med, q75 = compute_runlen_stats(sorted(set(all_train_ids))); md = build_min_dur(med, q75, mult=mult)\n",
        "    rows=[]; ids=[]; n=0; t0=time.time()\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    for sid in test_ids:\n",
        "        p2 = Path('probs_cache')/f\"{sid}_ce.npy\"; p3 = Path('probs_cache')/f\"{sid}_ce_v3.npy\"\n",
        "        if not (p2.exists() and p3.exists()): continue\n",
        "        p_skel = load_probs(int(sid)).astype(np.float32)\n",
        "        p_rgbx = None\n",
        "        prgbt = Path('probs_cache')/f\"{sid}_rgbt.npy\"\n",
        "        if prgbt.exists(): p_rgbx = np.load(prgbt).astype(np.float32)\n",
        "        elif (Path('probs_cache')/f\"{sid}_rgb.npy\").exists(): p_rgbx = np.load(Path('probs_cache')/f\"{sid}_rgb.npy\").astype(np.float32)\n",
        "        if p_rgbx is not None:\n",
        "            pr, ps = align_rgb_to_skel(p_rgbx, p_skel, max_shift=15)\n",
        "            pf = fuse_geometric(ps, pr, alpha=float(alpha))\n",
        "        else:\n",
        "            pf = p_skel\n",
        "        y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "        seq_raw=[]; last=-1\n",
        "        for c in y_hat:\n",
        "            if c==0: continue\n",
        "            if c!=last: seq_raw.append(int(c)); last=int(c)\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'  [RGBT-s3] test fused decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub), 'head:\\n', sub.head())\n",
        "    assert len(sub)==95\n",
        "    sub.to_csv('submission.csv', index=False); print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('RGBT-s3 Step 1: OOF alpha tuning (smooth_k=3)...', flush=True)\n",
        "best_alpha_rgbt_s3, wb_rgbt_s3, mb_rgbt_s3 = oof_alpha_tune_rgbt_s3(alpha_list=(0.18,0.20,0.22,0.24,0.26,0.28,0.30), mult=0.7, smooth_k=3, aba_len=2, aba_ratio=1.04)\n",
        "print('RGBT-s3 Step 2: Fuse + decode test with best alpha ...', flush=True)\n",
        "out_csv = f'submission_fused_rgbt_s3_alpha{str(best_alpha_rgbt_s3).replace(\".\", \"\")}.csv'\n",
        "fuse_decode_test_rgbt_s3(alpha=best_alpha_rgbt_s3, mult=0.7, smooth_k=3, aba_len=2, aba_ratio=1.04, out_csv=out_csv)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RGBT-s3 Step 1: OOF alpha tuning (smooth_k=3)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT-s3] alpha=0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.600 mean=3.921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT-s3] alpha=0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.550 mean=3.884\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT-s3] alpha=0.22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.590 mean=3.941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT-s3] alpha=0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.600 mean=3.972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT-s3] alpha=0.26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.620 mean=3.995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT-s3] alpha=0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.650 mean=4.015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-RGBT-s3] alpha=0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.610 mean=4.080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF-RGBT-s3 alpha summary:\n  alpha=0.18: worst=4.600 mean=3.921\n  alpha=0.2: worst=4.550 mean=3.884\n  alpha=0.22: worst=4.590 mean=3.941\n  alpha=0.24: worst=4.600 mean=3.972\n  alpha=0.26: worst=4.620 mean=3.995\n  alpha=0.28: worst=4.650 mean=4.015\n  alpha=0.3: worst=4.610 mean=4.080\nChosen alpha (RGBT-s3): 0.2\nRGBT-s3 Step 2: Fuse + decode test with best alpha ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGBT-s3] test fused decoded 20/95 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGBT-s3] test fused decoded 40/95 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGBT-s3] test fused decoded 60/95 elapsed=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGBT-s3] test fused decoded 80/95 elapsed=1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [RGBT-s3] test fused decoded 95/95 elapsed=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_fused_rgbt_s3_alpha02.csv rows= 95 head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 3 5 9 19 13 20 18 11 4 6 8 14 10 2 7 1...\n3  303  17 13 4 3 10 14 6 5 19 20 2 11 16 18 9 7 15 1 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 6 17 16 4 15 1...\nsubmission.csv written -> submission_fused_rgbt_s3_alpha02.csv\n"
          ]
        }
      ]
    },
    {
      "id": "482fa351-90b1-41c1-871a-25a342e6a2fe",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Local-Search (LS) decoder on fused PoE(skel+RGB, alpha=0.26): OOF sweep (mult, lambda, max_moves) and test submission\n",
        "import numpy as np, json, time, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "probs_cache = Path('probs_cache')\n",
        "\n",
        "# Reuse helpers: load_probs (aligned v2+v3), align_rgb_to_skel, fuse_geometric, decode_minseg_smooth_aba,\n",
        "# compute_runlen_stats, build_min_dur, load_frame_labels, compress_to_sequence, levenshtein, make_perm20\n",
        "\n",
        "def fused_poe_skel_rgb_fixedalpha(sid: int, alpha: float = 0.26) -> np.ndarray:\n",
        "    p_skel = load_probs(int(sid)).astype(np.float32)\n",
        "    prgb = probs_cache/f\"{sid}_rgb.npy\"\n",
        "    if prgb.exists():\n",
        "        p_rgb = np.load(prgb).astype(np.float32)\n",
        "        pr, ps = align_rgb_to_skel(p_rgb, p_skel, max_shift=15)\n",
        "        pf = fuse_geometric(ps, pr, alpha=float(alpha))\n",
        "        return pf\n",
        "    else:\n",
        "        return p_skel\n",
        "\n",
        "def neglog_prefix(p: np.ndarray) -> np.ndarray:\n",
        "    # p: CxT\n",
        "    nl = -np.log(np.clip(p, 1e-8, 1.0))\n",
        "    return np.cumsum(nl, axis=1).astype(np.float32)\n",
        "\n",
        "def seg_cost_from_prefix(cum: np.ndarray, c: int, t0: int, t1: int) -> float:\n",
        "    if t0 < 0: t0 = 0\n",
        "    if t1 < t0: return 0.0\n",
        "    if t0 == 0: return float(cum[c, t1])\n",
        "    return float(cum[c, t1] - cum[c, t0-1])\n",
        "\n",
        "def build_lmin_lmax(med: np.ndarray, q95: np.ndarray, mult: float) -> tuple:\n",
        "    lmin = np.zeros_like(med, dtype=np.int32); lmax = np.zeros_like(med, dtype=np.int32)\n",
        "    for c in range(21):\n",
        "        if c == 0: lmin[c]=0; lmax[c]=0; continue\n",
        "        m = float(med[c]) if med[c] > 0 else 10.0\n",
        "        q = float(q95[c]) if q95[c] > 0 else (m * 2.0)\n",
        "        lmin[c] = max(3, int(round(mult * m)))\n",
        "        lmax[c] = min(int(max(3, 1.5 * m)), int(q), 150)\n",
        "        if lmax[c] < lmin[c]: lmax[c] = lmin[c]\n",
        "    return lmin, lmax\n",
        "\n",
        "def initial_segments_from_minseg(p: np.ndarray, med: np.ndarray, q95: np.ndarray, mult: float) -> tuple:\n",
        "    # Use minseg+smooth+ABA to get a path; take first occurrence segments for unique classes (up to 20)\n",
        "    lmin_tmp, lmax_tmp = build_lmin_lmax(med, q95, mult)\n",
        "    md = lmin_tmp.copy(); md[0]=0\n",
        "    y = decode_minseg_smooth_aba(p, md, smooth_k=5, aba_len=2, aba_ratio=1.04)\n",
        "    T = len(y)\n",
        "    segments = []  # list of (c, t0, t1)\n",
        "    used = set()\n",
        "    i = 0\n",
        "    while i < T and len(segments) < 20:\n",
        "        c = int(y[i]); j=i+1\n",
        "        while j<T and y[j]==c: j+=1\n",
        "        if c != 0 and c not in used:\n",
        "            segments.append((c, i, j-1))\n",
        "            used.add(c)\n",
        "        i = j\n",
        "    # If fewer than 20 unique, fill remaining with highest-mass missing classes using equal splits\n",
        "    if len(segments) < 20:\n",
        "        missing = [c for c in range(1,21) if c not in used]\n",
        "        # simple equal partition of remaining time at the end\n",
        "        rem = max(0, T - (segments[-1][2] + 1)) if segments else T\n",
        "        chunk = max(3, rem // max(1, len(missing))) if missing else 0\n",
        "        t0 = segments[-1][2]+1 if segments else 0\n",
        "        for c in missing:\n",
        "            t1 = min(T-1, t0 + chunk - 1)\n",
        "            if t1 >= t0: segments.append((c, t0, t1))\n",
        "            t0 = t1 + 1\n",
        "            if len(segments) >= 20 or t0 >= T: break\n",
        "    # Ensure exactly 20 segments by trimming or merging last ones\n",
        "    if len(segments) > 20: segments = segments[:20]\n",
        "    # If still fewer, pad with any remaining classes with 1-frame slots at end\n",
        "    while len(segments) < 20:\n",
        "        c = next((cc for cc in range(1,21) if cc not in {s[0] for s in segments}), 1)\n",
        "        segments.append((c, max(0, T-1), max(0, T-1)))\n",
        "    # Extract order and boundaries\n",
        "    order = [c for (c,_,_) in segments]\n",
        "    bounds = [(t0, t1) for (_,t0,t1) in segments]\n",
        "    return order, bounds, y\n",
        "\n",
        "def seq_cost_with_fixed_bounds(p: np.ndarray, cum: np.ndarray, med: np.ndarray, order: list, bounds: list, lam: float) -> float:\n",
        "    # p: CxT, cum: CxT prefix of neglog, order: length-20, bounds: list of (t0,t1) length-20\n",
        "    total=0.0\n",
        "    for k, c in enumerate(order):\n",
        "        c = int(c)\n",
        "        t0, t1 = bounds[k]\n",
        "        t0 = max(0, int(t0)); t1 = min(p.shape[1]-1, int(t1))\n",
        "        if t1 < t0: continue\n",
        "        total += seg_cost_from_prefix(cum, c, t0, t1)\n",
        "        if lam > 0.0:\n",
        "            L = max(1, t1 - t0 + 1); m = max(1.0, float(med[c]))\n",
        "            total += float(lam) * abs(np.log(float(L)) - np.log(m))\n",
        "    return float(total)\n",
        "\n",
        "def ls_refine_order_fixed_bounds(p: np.ndarray, med: np.ndarray, init_order: list, bounds: list, lam: float, max_moves: int) -> list:\n",
        "    # Precompute prefix sums for fast segment cost\n",
        "    cum = neglog_prefix(p)\n",
        "    order = list(init_order)\n",
        "    best_cost = seq_cost_with_fixed_bounds(p, cum, med, order, bounds, lam)\n",
        "    moves = 0\n",
        "    improved = True\n",
        "    while improved and moves < max_moves:\n",
        "        improved = False\n",
        "        best_delta = 0.0; best_move = None  # ('swap', k) or ('ins', k, d)\n",
        "        # Adjacent swaps\n",
        "        for k in range(19):\n",
        "            a, b = order[k], order[k+1]\n",
        "            # cost only affected at segments k and k+1\n",
        "            c0 = seq_cost_with_fixed_bounds(p, cum, med, [a,b], [bounds[k], bounds[k+1]], lam)\n",
        "            c1 = seq_cost_with_fixed_bounds(p, cum, med, [b,a], [bounds[k], bounds[k+1]], lam)\n",
        "            delta = c0 - c1  # positive if swap improves\n",
        "            if delta > best_delta + 1e-6:\n",
        "                best_delta = delta; best_move = ('swap', k)\n",
        "        # Reinsert (move position by +/-1 or +/-2)\n",
        "        for k in range(20):\n",
        "            for d in (-2, -1, 1, 2):\n",
        "                j = k + d\n",
        "                if j < 0 or j >= 20: continue\n",
        "                if d == 0: continue\n",
        "                new_order = order.copy()\n",
        "                elem = new_order.pop(k)\n",
        "                new_order.insert(j, elem)\n",
        "                # affected range between min(k,j) and max(k,j); compute delta by recomputing only that span\n",
        "                span_lo = min(k,j); span_hi = max(k,j)\n",
        "                c_old = seq_cost_with_fixed_bounds(p, cum, med, order[span_lo:span_hi+1], bounds[span_lo:span_hi+1], lam)\n",
        "                c_new = seq_cost_with_fixed_bounds(p, cum, med, new_order[span_lo:span_hi+1], bounds[span_lo:span_hi+1], lam)\n",
        "                delta = c_old - c_new\n",
        "                if delta > best_delta + 1e-6:\n",
        "                    best_delta = delta; best_move = ('ins', k, j)\n",
        "        if best_move is not None and best_delta > 1e-6:\n",
        "            if best_move[0] == 'swap':\n",
        "                k = best_move[1]; order[k], order[k+1] = order[k+1], order[k]\n",
        "            else:\n",
        "                k, j = best_move[1], best_move[2]\n",
        "                elem = order.pop(k); order.insert(j, elem)\n",
        "            best_cost -= best_delta\n",
        "            moves += 1; improved = True\n",
        "        else:\n",
        "            break\n",
        "    return order\n",
        "\n",
        "def micro_boundary_shift(p: np.ndarray, order: list, bounds: list, med: np.ndarray, lmin: np.ndarray, lmax: np.ndarray, lam: float, max_shift: int = 5) -> list:\n",
        "    # Adjust each internal boundary by +/- up to max_shift frames to reduce cost; keep order fixed\n",
        "    cum = neglog_prefix(p)\n",
        "    K = len(order); T = p.shape[1]\n",
        "    b = [list(x) for x in bounds]\n",
        "    def seg_len(k): return b[k][1] - b[k][0] + 1\n",
        "    changed = True\n",
        "    while changed:\n",
        "        changed = False\n",
        "        for k in range(K-1):\n",
        "            cL = int(order[k]); cR = int(order[k+1])\n",
        "            # current boundary between segments k and k+1\n",
        "            t_split = b[k][1]\n",
        "            best_local = seq_cost_with_fixed_bounds(p, cum, med, [cL, cR], [tuple(b[k]), tuple(b[k+1])], lam)\n",
        "            best_tsplit = t_split\n",
        "            for d in range(-max_shift, max_shift+1):\n",
        "                t_new = t_split + d\n",
        "                # new bounds\n",
        "                t0L = b[k][0]; t1L = t_new\n",
        "                t0R = t_new + 1; t1R = b[k+1][1]\n",
        "                if t0L < 0 or t1R >= T or t1L < t0L or t1R < t0R: continue\n",
        "                Llen = t1L - t0L + 1; Rlen = t1R - t0R + 1\n",
        "                if Llen < lmin[cL] or Llen > lmax[cL]: continue\n",
        "                if Rlen < lmin[cR] or Rlen > lmax[cR]: continue\n",
        "                cst = seg_cost_from_prefix(cum, cL, t0L, t1L) + seg_cost_from_prefix(cum, cR, t0R, t1R)\n",
        "                if lam > 0.0:\n",
        "                    cst += float(lam) * (abs(np.log(max(1, Llen)) - np.log(max(1.0, med[cL]))) + abs(np.log(max(1, Rlen)) - np.log(max(1.0, med[cR]))))\n",
        "                if cst + 1e-6 < best_local:\n",
        "                    best_local = cst; best_tsplit = t_new\n",
        "            if best_tsplit != t_split:\n",
        "                b[k][1] = best_tsplit; b[k+1][0] = best_tsplit + 1; changed = True\n",
        "    return [tuple(x) for x in b]\n",
        "\n",
        "def ls_decode_for_id(p: np.ndarray, med: np.ndarray, q95: np.ndarray, mult: float, lam: float, max_moves: int) -> list:\n",
        "    order0, bounds0, _ = initial_segments_from_minseg(p, med, q95, mult)\n",
        "    lmin, lmax = build_lmin_lmax(med, q95, mult)\n",
        "    order_ls = ls_refine_order_fixed_bounds(p, med, order0, bounds0, lam=lam, max_moves=max_moves)\n",
        "    bounds_ls = micro_boundary_shift(p, order_ls, bounds0, med, lmin, lmax, lam=lam, max_shift=5)\n",
        "    # final permutation is order_ls\n",
        "    return order_ls\n",
        "\n",
        "def oof_sweep_ls(mult_list=(0.65,0.7), lam_list=(0.0, 0.2), max_moves_list=(20,40), alpha: float = 0.26):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    results = []  # (worst, mean, mult, lam, moves)\n",
        "    for mult in mult_list:\n",
        "        for lam in lam_list:\n",
        "            for mv in max_moves_list:\n",
        "                per_fold=[]\n",
        "                print(f'[OOF-LS] mult={mult} lam={lam} max_moves={mv}', flush=True)\n",
        "                for fd in folds:\n",
        "                    tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "                    med, q75 = compute_runlen_stats(tr_ids)\n",
        "                    # approximate q95 via 95th percentile from train (reuse q75 as proxy if q95 not available)\n",
        "                    # build q95 from train using robust method from HSMM cell if available\n",
        "                    try:\n",
        "                        # reuse robust_q95_from_ids if defined\n",
        "                        med_r, q95 = robust_q95_from_ids(tr_ids)\n",
        "                        med = med_r\n",
        "                    except Exception:\n",
        "                        q95 = np.maximum(q75*1.5, med*1.5).astype(np.float32)\n",
        "                    dists=[]\n",
        "                    for sid in va_ids:\n",
        "                        p = fused_poe_skel_rgb_fixedalpha(int(sid), alpha=alpha)\n",
        "                        perm = ls_decode_for_id(p, med, q95, mult=mult, lam=lam, max_moves=mv)\n",
        "                        y_true = load_frame_labels(int(sid))\n",
        "                        seq_true = compress_to_sequence(y_true)\n",
        "                        dists.append(levenshtein(perm, seq_true))\n",
        "                    per_fold.append(float(np.mean(dists)) if dists else 0.0)\n",
        "                worst = max(per_fold); mean_v = float(np.mean(per_fold))\n",
        "                results.append((worst, mean_v, mult, lam, mv))\n",
        "                print(f'  -> worst={worst:.3f} mean={mean_v:.3f}', flush=True)\n",
        "    results.sort(key=lambda x: (x[0], x[1]))\n",
        "    print('OOF-LS summary (top 5):')\n",
        "    for r in results[:5]: print(r)\n",
        "    best = results[0] if results else None\n",
        "    return best, results\n",
        "\n",
        "def decode_test_ls(mult: float, lam: float, max_moves: int, alpha: float = 0.26, out_csv: str = 'submission_ls_poe.csv'):\n",
        "    folds = json.load(open('folds_archive_cv.json','r'))\n",
        "    all_train_ids=[]\n",
        "    for fd in folds: all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "    # durations from all-train (test-safe)\n",
        "    try:\n",
        "        med_all, q95_all = robust_q95_from_ids(sorted(set(all_train_ids)))\n",
        "    except Exception:\n",
        "        med_all, q75_all = compute_runlen_stats(sorted(set(all_train_ids))); q95_all = np.maximum(q75_all*1.5, med_all*1.5).astype(np.float32)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    rows=[]; ids=[]; n=0; t0=time.time()\n",
        "    for sid in test_ids:\n",
        "        p2 = probs_cache/f\"{sid}_ce.npy\"; p3 = probs_cache/f\"{sid}_ce_v3.npy\"\n",
        "        if not (p2.exists() and p3.exists()): continue\n",
        "        p = fused_poe_skel_rgb_fixedalpha(int(sid), alpha=alpha)\n",
        "        perm = ls_decode_for_id(p, med_all, q95_all, mult=mult, lam=lam, max_moves=max_moves)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, perm))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'  [LS] test decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub), 'head:\\n', sub.head())\n",
        "    assert len(sub)==95\n",
        "    sub.to_csv('submission.csv', index=False); print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('LS Step 1: OOF sweep (mult in {0.65,0.7}, lambda in {0,0.2}, max_moves in {20,40})...', flush=True)\n",
        "best_ls, res_ls = oof_sweep_ls(mult_list=(0.65,0.7), lam_list=(0.0,0.2), max_moves_list=(20,40), alpha=0.26)\n",
        "if best_ls is not None:\n",
        "    worst, mean_v, mult_b, lam_b, mv_b = best_ls\n",
        "    print('Chosen LS config:', (mult_b, lam_b, mv_b), '-> worst=', worst, 'mean=', mean_v, flush=True)\n",
        "    print('LS Step 2: Decode test with best config ...', flush=True)\n",
        "    out_csv = f'submission_ls_poe_m{str(mult_b).replace(\".\", \"\")}_l{str(lam_b).replace(\".\", \"\")}_mv{mv_b}.csv'\n",
        "    decode_test_ls(mult=mult_b, lam=lam_b, max_moves=mv_b, alpha=0.26, out_csv=out_csv)\n",
        "else:\n",
        "    print('LS sweep produced no results; skipping decode.')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LS Step 1: OOF sweep (mult in {0.65,0.7}, lambda in {0,0.2}, max_moves in {20,40})...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-LS] mult=0.65 lam=0.0 max_moves=20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=7.670 mean=6.559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-LS] mult=0.65 lam=0.0 max_moves=40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=7.670 mean=6.559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-LS] mult=0.65 lam=0.2 max_moves=20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=7.670 mean=6.559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-LS] mult=0.65 lam=0.2 max_moves=40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=7.670 mean=6.559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-LS] mult=0.7 lam=0.0 max_moves=20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=7.560 mean=6.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-LS] mult=0.7 lam=0.0 max_moves=40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=7.560 mean=6.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-LS] mult=0.7 lam=0.2 max_moves=20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=7.560 mean=6.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-LS] mult=0.7 lam=0.2 max_moves=40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=7.560 mean=6.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF-LS summary (top 5):\n(7.56, 6.691270528413384, 0.7, 0.0, 20)\n(7.56, 6.691270528413384, 0.7, 0.0, 40)\n(7.56, 6.691270528413384, 0.7, 0.2, 20)\n(7.56, 6.691270528413384, 0.7, 0.2, 40)\n(7.67, 6.559002954717241, 0.65, 0.0, 20)\nChosen LS config: (0.7, 0.0, 20) -> worst= 7.56 mean= 6.691270528413384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LS Step 2: Decode test with best config ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [LS] test decoded 20/95 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [LS] test decoded 40/95 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [LS] test decoded 60/95 elapsed=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [LS] test decoded 80/95 elapsed=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [LS] test decoded 95/95 elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_ls_poe_m07_l00_mv20.csv rows= 95 head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 12 5 9 19 13 20 18 11 3 4 6 8 14 10 2 ...\n3  303  18 13 4 3 10 14 6 5 19 20 17 2 11 16 9 1 7 15 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 6 17 16 4 10 1...\nsubmission.csv written -> submission_ls_poe_m07_l00_mv20.csv\n"
          ]
        }
      ]
    },
    {
      "id": "bebc8b02-708b-48da-8c90-fbf3afc837e7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set best PoE fused (alpha=0.26, smooth+ABA) as current submission\n",
        "import shutil, pandas as pd, os\n",
        "src = 'submission_fused_rgb_alpha026.csv'\n",
        "assert os.path.exists(src), f'Missing {src}'\n",
        "shutil.copyfile(src, 'submission.csv')\n",
        "print('submission.csv ->', src)\n",
        "print(pd.read_csv('submission.csv').head())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv -> submission_fused_rgb_alpha026.csv\n    Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 7 3 1 5 4 6 2 11 15 13 19 9 8 18 14 16 17 1...\n2  302  1 17 16 12 5 9 19 13 20 18 11 3 4 6 8 14 10 2 ...\n3  303  18 13 4 3 10 14 6 5 19 20 17 2 11 16 9 7 12 1 ...\n4  304  8 1 7 3 14 18 13 9 2 11 20 19 5 6 17 16 4 12 1...\n"
          ]
        }
      ]
    },
    {
      "id": "eebaeb3b-37a7-48a6-abd3-4788097132dd",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Audio stream: extract wav, build MFCC+delta features, train small 1D-CNN per fold, cache OOF/test probs, fuse with PoE\n",
        "import os, io, time, tarfile, zipfile, shutil, json, random, math\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
        "\n",
        "probs_cache = Path('probs_cache'); probs_cache.mkdir(exist_ok=True)\n",
        "labels_dir = Path('labels3d_v2/train')\n",
        "\n",
        "# Helper: id -> tar mapping (same as video streams)\n",
        "def id_to_tar(sid: int) -> Path | None:\n",
        "    if 1 <= sid <= 99: return Path('training1.tar.gz')\n",
        "    if 101 <= sid <= 199: return Path('training2.tar.gz')\n",
        "    if 200 <= sid <= 299: return Path('training3.tar.gz')\n",
        "    if 300 <= sid <= 399: return Path('test.tar.gz')\n",
        "    return None\n",
        "\n",
        "def split_of_id(sid: int) -> str:\n",
        "    return 'train' if sid < 300 else 'test'\n",
        "\n",
        "# Ensure librosa stack available\n",
        "try:\n",
        "    import librosa, soundfile as sf\n",
        "except Exception:\n",
        "    import subprocess, sys\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-c', 'constraints.txt', 'librosa==0.10.2', 'soundfile==0.12.1', 'numba==0.59.1', 'llvmlite==0.42.0'], check=True)\n",
        "    import librosa, soundfile as sf\n",
        "\n",
        "# Audio cache dirs\n",
        "aud_wav_dir = Path('audio_wav'); (aud_wav_dir/'train').mkdir(parents=True, exist_ok=True); (aud_wav_dir/'test').mkdir(parents=True, exist_ok=True)\n",
        "aud_feat_dir = Path('audio_feat'); (aud_feat_dir/'train').mkdir(parents=True, exist_ok=True); (aud_feat_dir/'test').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def extract_audio_wav_to_cache(sid: int) -> Path | None:\n",
        "    split = split_of_id(sid)\n",
        "    out_path = aud_wav_dir / split / f\"{sid}.wav\"\n",
        "    if out_path.exists():\n",
        "        return out_path\n",
        "    tar_p = id_to_tar(sid)\n",
        "    if tar_p is None or not tar_p.exists():\n",
        "        print(f'[audio] missing tar for id={sid}:', tar_p); return None\n",
        "    zip_name = f\"Sample{sid:05d}.zip\"\n",
        "    wav_member = f\"Sample{sid:05d}_audio.wav\"\n",
        "    try:\n",
        "        with tarfile.open(tar_p, 'r:gz') as tf:\n",
        "            m = next((m for m in tf if m.isreg() and Path(m.name).name == zip_name), None)\n",
        "            if m is None:\n",
        "                print(f'[audio] zip {zip_name} not found in {tar_p}'); return None\n",
        "            data = tf.extractfile(m).read()\n",
        "        with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
        "            names = zf.namelist()\n",
        "            mem = wav_member if wav_member in names else next((n for n in names if n.lower().endswith('_audio.wav')), None)\n",
        "            if mem is None:\n",
        "                print(f'[audio] wav not found for id={sid}')\n",
        "                return None\n",
        "            tmp = out_path.with_suffix('.wav.tmp')\n",
        "            with zf.open(mem) as fsrc, open(tmp, 'wb') as fdst:\n",
        "                shutil.copyfileobj(fsrc, fdst)\n",
        "            tmp.replace(out_path)\n",
        "        return out_path\n",
        "    except Exception as e:\n",
        "        print(f'[audio] error id={sid}:', e); return None\n",
        "\n",
        "# Feature extraction: MFCC (13) + delta (13) -> (T', 26), 16kHz, 25ms window, 10ms hop\n",
        "def extract_mfcc_feat(wav_path: Path, sr_target: int = 16000, n_mfcc: int = 13, win_ms: float = 25.0, hop_ms: float = 10.0) -> np.ndarray:\n",
        "    y, sr = librosa.load(str(wav_path), sr=sr_target, mono=True)\n",
        "    n_fft = int(round(sr_target * (win_ms/1000.0)))\n",
        "    hop_length = int(round(sr_target * (hop_ms/1000.0)))\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr_target, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
        "    d = librosa.feature.delta(mfcc)\n",
        "    feat = np.vstack([mfcc, d]).T.astype(np.float32)  # (T', 26)\n",
        "    return feat\n",
        "\n",
        "def upsample_to_T_np(E: np.ndarray, T: int) -> np.ndarray:\n",
        "    if E.shape[0] == T:\n",
        "        return E.astype(np.float32)\n",
        "    if E.shape[0] == 0:\n",
        "        return np.zeros((T, E.shape[1] if E.ndim==2 else 26), dtype=np.float32)\n",
        "    import torch.nn.functional as Fnn\n",
        "    x = torch.from_numpy(E.astype(np.float32)).unsqueeze(0).transpose(1,2)  # 1,D,T'\n",
        "    y = Fnn.interpolate(x, size=T, mode='linear', align_corners=False).transpose(1,2).squeeze(0).contiguous()\n",
        "    return y.numpy().astype(np.float32)\n",
        "\n",
        "def get_T_train(sid: int) -> int:\n",
        "    return int(np.load(labels_dir / f\"{sid}.npy\").shape[0])\n",
        "\n",
        "def get_T_test(sid: int) -> int:\n",
        "    p3 = probs_cache / f\"{sid}_ce_v3.npy\"\n",
        "    if p3.exists():\n",
        "        return int(np.load(p3, mmap_mode='r').shape[1])\n",
        "    d = np.load(Path('features3d_v3/test')/f\"{sid}.npz\")\n",
        "    X = d['X'] if 'X' in d.files else d[d.files[0]]\n",
        "    return int(X.shape[0])\n",
        "\n",
        "def cache_audio_feat_for_id(sid: int, force: bool = False) -> Path | None:\n",
        "    split = split_of_id(sid); out = aud_feat_dir / split / f\"{sid}.npy\"\n",
        "    if out.exists() and not force:\n",
        "        try:\n",
        "            arr = np.load(out, mmap_mode='r')\n",
        "            if arr.shape[0] > 0: return out\n",
        "        except Exception:\n",
        "            pass\n",
        "    wav_path = extract_audio_wav_to_cache(sid)\n",
        "    if wav_path is None: return None\n",
        "    Fm = extract_mfcc_feat(wav_path)  # (T',26)\n",
        "    np.save(out, Fm.astype(np.float32))\n",
        "    return out\n",
        "\n",
        "def list_ids_from_features(split: str):\n",
        "    base = Path('features3d_v3')/split\n",
        "    return sorted(int(p.stem) for p in base.glob('*.npz'))\n",
        "\n",
        "# Build datasets\n",
        "class AudioSeqDataset(Dataset):\n",
        "    def __init__(self, ids: List[int], split: str = 'train', chunk_len: int = 2048):\n",
        "        self.ids = list(ids); self.split = split; self.chunk_len = chunk_len; self.index = []\n",
        "        for sid in self.ids:\n",
        "            E = np.load(aud_feat_dir/'train'/f\"{sid}.npy\", mmap_mode='r')\n",
        "            T = get_T_train(sid)\n",
        "            Eu = upsample_to_T_np(np.array(E), T); n = Eu.shape[0]\n",
        "            if n <= chunk_len:\n",
        "                self.index.append((sid, 0, n))\n",
        "            else:\n",
        "                s = 0\n",
        "                while s < n:\n",
        "                    e = min(n, s + chunk_len); self.index.append((sid, s, e)); s = e\n",
        "        random.shuffle(self.index)\n",
        "    def __len__(self): return len(self.index)\n",
        "    def __getitem__(self, i):\n",
        "        sid, s, e = self.index[i]\n",
        "        E = np.load(aud_feat_dir/'train'/f\"{sid}.npy\", mmap_mode='r')\n",
        "        T = get_T_train(sid); Eu = upsample_to_T_np(np.array(E), T)\n",
        "        y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "        x = Eu[s:e].astype(np.float32); t = y[s:e]\n",
        "        return torch.from_numpy(x), torch.from_numpy(t)\n",
        "\n",
        "# Simple 1D CNN head\n",
        "class AudioCNN(nn.Module):\n",
        "    def __init__(self, in_dim=26, hidden=128, n_classes=21, drop=0.3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_dim, hidden, 5, padding=2)\n",
        "        self.conv2 = nn.Conv1d(hidden, hidden, 5, padding=2)\n",
        "        self.conv3 = nn.Conv1d(hidden, n_classes, 1)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        self.gn1 = nn.GroupNorm(8, hidden)\n",
        "        self.gn2 = nn.GroupNorm(8, hidden)\n",
        "    def forward(self, x_b_t_d):  # B,T,D\n",
        "        x = x_b_t_d.transpose(1,2)  # B,D,T\n",
        "        h = F.relu(self.gn1(self.conv1(x)))\n",
        "        h = self.drop(F.relu(self.gn2(self.conv2(h))))\n",
        "        out = self.conv3(h)  # B,C,T\n",
        "        return out.transpose(1,2)  # B,T,C\n",
        "\n",
        "def train_audio_fold(train_ids: List[int], val_ids: List[int], epochs: int = 12, lr: float = 1e-3, wd: float = 1e-5, chunk_len: int = 2048, batch_size: int = 1, patience: int = 3):\n",
        "    model = AudioCNN().to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    best = 1e18; bad = 0\n",
        "    for ep in range(1, epochs+1):\n",
        "        t0=time.time(); model.train()\n",
        "        ds = AudioSeqDataset(train_ids, split='train', chunk_len=chunk_len)\n",
        "        dl = DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "        tr_loss=0.0; n_tok=0\n",
        "        for xb, yb in dl:\n",
        "            xb = xb.to(device, non_blocking=True); yb = yb.to(device, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(xb)\n",
        "            loss = F.cross_entropy(logits.reshape(-1, logits.shape[-1]), yb.reshape(-1))\n",
        "            loss.backward(); opt.step()\n",
        "            tr_loss += float(loss.item()) * yb.numel(); n_tok += int(yb.numel())\n",
        "        tr_loss /= max(1, n_tok)\n",
        "        # val\n",
        "        model.eval(); val_loss=0.0; n_tok=0\n",
        "        with torch.no_grad():\n",
        "            for sid in val_ids:\n",
        "                E = np.load(aud_feat_dir/'train'/f\"{sid}.npy\", mmap_mode='r')\n",
        "                T = get_T_train(sid); Eu = upsample_to_T_np(np.array(E), T)\n",
        "                y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "                xb = torch.from_numpy(Eu).unsqueeze(0).to(device)\n",
        "                logits = model(xb)\n",
        "                ll = F.cross_entropy(logits.reshape(-1, logits.shape[-1]), torch.from_numpy(y).to(device))\n",
        "                val_loss += float(ll.item()) * int(T); n_tok += int(T)\n",
        "        val_loss /= max(1, n_tok)\n",
        "        print(f\"[AUDIO fold] ep {ep:02d} tr_nll={tr_loss:.4f} val_nll={val_loss:.4f} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "        if val_loss < best - 1e-4:\n",
        "            best = val_loss; bad=0; torch.save(model.state_dict(), 'audio_head_tmp.pth')\n",
        "        else:\n",
        "            bad += 1\n",
        "            if bad >= patience: break\n",
        "    model.load_state_dict(torch.load('audio_head_tmp.pth', map_location=device))\n",
        "    return model\n",
        "\n",
        "def infer_probs_audio(model: nn.Module, ids: List[int], split: str, out_suffix: str):\n",
        "    model.eval(); saved=0; t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, sid in enumerate(ids, 1):\n",
        "            if split=='train':\n",
        "                T = get_T_train(sid); emb_path = aud_feat_dir/'train'/f\"{sid}.npy\"\n",
        "            else:\n",
        "                T = get_T_test(sid); emb_path = aud_feat_dir/'test'/f\"{sid}.npy\"\n",
        "            if not emb_path.exists():\n",
        "                # on-the-fly feat extraction if missing\n",
        "                cache_audio_feat_for_id(int(sid), force=False)\n",
        "            if not emb_path.exists():\n",
        "                print(f\"  [AUDIO infer] missing feat for id={sid}, skip\"); continue\n",
        "            E = np.load(emb_path, mmap_mode='r')\n",
        "            Eu = upsample_to_T_np(np.array(E), T)\n",
        "            xb = torch.from_numpy(Eu).unsqueeze(0).to(device)\n",
        "            logits = model(xb)[0]  # T,C\n",
        "            p = logits.softmax(dim=-1).cpu().numpy().astype(np.float32).T  # CxT\n",
        "            p /= (p.sum(axis=0, keepdims=True) + 1e-8)\n",
        "            np.save(probs_cache/f\"{sid}{out_suffix}\", p); saved += 1\n",
        "            if (i%20)==0 or i==len(ids):\n",
        "                print(f\"  [AUDIO infer] saved {saved}/{len(ids)} split={split} {out_suffix} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "def fit_scalar_temperature_on_val(val_ids: List[int], suffix: str) -> float:\n",
        "    grid = [round(x,2) for x in np.linspace(0.8, 1.5, 15)]\n",
        "    best_T=1.0; best_nll=1e18\n",
        "    for Tval in grid:\n",
        "        nll=0.0; n_tok=0\n",
        "        for sid in val_ids:\n",
        "            p = np.load(probs_cache/f\"{sid}{suffix}\")  # CxT\n",
        "            y = np.load(labels_dir/f\"{sid}.npy\").astype(np.int64)\n",
        "            logp = np.log(np.clip(p, 1e-8, 1.0)) / float(Tval)\n",
        "            q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "            idx = (y >= 0) & (y < q.shape[0]); yy = y[idx]\n",
        "            nll += -float(np.log(q[yy, np.nonzero(idx)[0]] + 1e-8).sum()); n_tok += int(idx.sum())\n",
        "        if n_tok>0:\n",
        "            nll /= float(n_tok)\n",
        "            if nll < best_nll: best_nll = nll; best_T = Tval\n",
        "    print(f\"[AUDIO Temp] best T={best_T} NLL={best_nll:.4f} on {len(val_ids)} val ids\", flush=True)\n",
        "    return float(best_T)\n",
        "\n",
        "def apply_scalar_temperature(ids: List[int], suffix: str, Tscalar: float):\n",
        "    for sid in ids:\n",
        "        p = np.load(probs_cache/f\"{sid}{suffix}\")\n",
        "        logp = np.log(np.clip(p, 1e-8, 1.0)) / float(Tscalar)\n",
        "        q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "        np.save(probs_cache/f\"{sid}{suffix}\", q.astype(np.float32))\n",
        "\n",
        "def average_test_audio_with_fold_temps():\n",
        "    # temps saved as audio_temp_fold{f}.json\n",
        "    Ts=[]\n",
        "    for f in range(3):\n",
        "        jf = Path(f'audio_temp_fold{f}.json')\n",
        "        if jf.exists():\n",
        "            try: Ts.append(float(json.loads(jf.read_text())['T']))\n",
        "            except Exception: Ts.append(1.0)\n",
        "        else: Ts.append(1.0)\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    n_avg=0\n",
        "    for sid in test_ids:\n",
        "        arrs=[]\n",
        "        for f in range(3):\n",
        "            p = probs_cache/f\"{sid}_aud_f{f}.npy\"\n",
        "            if p.exists():\n",
        "                a = np.load(p, mmap_mode='r').astype(np.float32)\n",
        "                logp = np.log(np.clip(a, 1e-8, 1.0)) / float(Ts[f])\n",
        "                q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "                arrs.append(q)\n",
        "        if not arrs: continue\n",
        "        Tm = min(a.shape[1] for a in arrs); arrs = [a[:, :Tm] for a in arrs]\n",
        "        m = np.mean(arrs, axis=0); m /= (m.sum(axis=0, keepdims=True) + 1e-8)\n",
        "        np.save(probs_cache/f\"{sid}_aud.npy\", m.astype(np.float32)); n_avg+=1\n",
        "    print('Averaged TEST per-fold -> aud.npy for', n_avg, 'ids')\n",
        "\n",
        "# Phase A: Extract audio features for all ids (train/test)\n",
        "def bulk_cache_audio_feats(ids: List[int]):\n",
        "    t0=time.time(); ok=0; skip=0; fail=0\n",
        "    for i, sid in enumerate(ids, 1):\n",
        "        out = aud_feat_dir/split_of_id(sid)/f\"{sid}.npy\"\n",
        "        if out.exists():\n",
        "            try:\n",
        "                arr = np.load(out, mmap_mode='r')\n",
        "                if arr.shape[0] > 0:\n",
        "                    skip += 1\n",
        "                    if (i%20)==0 or i==len(ids):\n",
        "                        print(f'  [audio] skip {i}/{len(ids)} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "                    continue\n",
        "            except Exception:\n",
        "                pass\n",
        "        p = cache_audio_feat_for_id(int(sid), force=False)\n",
        "        if p is None: fail += 1\n",
        "        else: ok += 1\n",
        "        if (i%20)==0 or i==len(ids):\n",
        "            print(f'  [audio] processed {i}/{len(ids)} ok={ok} skip={skip} fail={fail} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    print(f'[audio] Done: ok={ok} skip={skip} fail={fail} total={len(ids)} elapsed={time.time()-t0:.1f}s')\n",
        "\n",
        "train_ids = list_ids_from_features('train')\n",
        "test_ids = list_ids_from_features('test')\n",
        "print('Audio: caching MFCC features for TRAIN...', flush=True)\n",
        "bulk_cache_audio_feats(train_ids)\n",
        "print('Audio: caching MFCC features for TEST...', flush=True)\n",
        "bulk_cache_audio_feats(test_ids)\n",
        "\n",
        "# Phase B: Train per-fold audio head, cache OOF/test probs, fit temps, average test\n",
        "folds_list = json.load(open('folds_archive_cv.json','r'))\n",
        "test_ids_list = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "for fd in folds_list:\n",
        "    fidx = int(fd['fold'])\n",
        "    tr_ids = list(map(int, fd['train_ids']))\n",
        "    va_ids = list(map(int, fd['val_ids']))\n",
        "    print(f'Audio Fold {fidx}: train={len(tr_ids)} val={len(va_ids)}', flush=True)\n",
        "    model = train_audio_fold(tr_ids, va_ids, epochs=10, lr=1e-3, wd=1e-5, chunk_len=2048, batch_size=1, patience=3)\n",
        "    infer_probs_audio(model, va_ids, split='train', out_suffix='_aud.npy')\n",
        "    infer_probs_audio(model, test_ids_list, split='test', out_suffix=f'_aud_f{fidx}.npy')\n",
        "    Tbest = fit_scalar_temperature_on_val(va_ids, suffix='_aud.npy')\n",
        "    apply_scalar_temperature(va_ids, suffix='_aud.npy', Tscalar=Tbest)\n",
        "    Path(f'audio_temp_fold{fidx}.json').write_text(json.dumps({'T': float(Tbest)}))\n",
        "\n",
        "print('Averaging TEST audio per-fold with temps ...', flush=True)\n",
        "average_test_audio_with_fold_temps()\n",
        "\n",
        "# Phase C: Fuse with skeleton + RGB using PoE with audio weight gamma; OOF tune gamma and create submission\n",
        "\n",
        "# Reuse helpers from earlier cells in notebook: load_probs (aligned v2+v3), align_rgb_to_skel as generic align, fuse_geometric,\n",
        "# compute_runlen_stats, build_min_dur, decode_minseg_smooth_aba, load_frame_labels, compress_to_sequence, levenshtein, make_perm20\n",
        "\n",
        "def fuse_poe_triple(ps: np.ndarray, pr: np.ndarray | None, pa: np.ndarray | None, alpha: float, gamma: float) -> np.ndarray:\n",
        "    # ps: skeleton CxT; pr: rgb aligned CxT or None; pa: audio aligned CxT or None\n",
        "    w_s = 1.0 - float(alpha) - float(gamma)\n",
        "    w_s = max(0.0, w_s)\n",
        "    logp = w_s * np.log(np.clip(ps, 1e-8, 1.0))\n",
        "    if pr is not None and alpha > 0.0:\n",
        "        logp += float(alpha) * np.log(np.clip(pr, 1e-8, 1.0))\n",
        "    if pa is not None and gamma > 0.0:\n",
        "        logp += float(gamma) * np.log(np.clip(pa, 1e-8, 1.0))\n",
        "    q = np.exp(logp); q /= (q.sum(axis=0, keepdims=True) + 1e-8)\n",
        "    return q.astype(np.float32)\n",
        "\n",
        "def align_stream_to_skel(p_stream: np.ndarray, p_skel: np.ndarray, max_shift: int = 15):\n",
        "    return align_rgb_to_skel(p_stream, p_skel, max_shift=max_shift)  # reuse\n",
        "\n",
        "def _crop_common_lengths(ps_base: np.ndarray, pr_aligned: np.ndarray | None, pa_aligned: np.ndarray | None):\n",
        "    Tm = ps_base.shape[1]\n",
        "    if pr_aligned is not None: Tm = min(Tm, pr_aligned.shape[1])\n",
        "    if pa_aligned is not None: Tm = min(Tm, pa_aligned.shape[1])\n",
        "    ps_c = ps_base[:, :Tm]\n",
        "    pr_c = pr_aligned[:, :Tm] if pr_aligned is not None else None\n",
        "    pa_c = pa_aligned[:, :Tm] if pa_aligned is not None else None\n",
        "    return ps_c, pr_c, pa_c\n",
        "\n",
        "def oof_tune_audio_gamma(alpha_fixed: float = 0.26, gamma_list=(0.10,0.15,0.20,0.25), mult: float = 0.7, smooth_k: int = 5, aba_len: int = 2, aba_ratio: float = 1.04):\n",
        "    folds_local = json.load(open('folds_archive_cv.json','r'))\n",
        "    worst_by={}; mean_by={}\n",
        "    for gamma in gamma_list:\n",
        "        per_fold=[]\n",
        "        print(f'[OOF-AUDIO] gamma={gamma}', flush=True)\n",
        "        for fd in folds_local:\n",
        "            tr_ids = list(map(int, fd['train_ids'])); va_ids = list(map(int, fd['val_ids']))\n",
        "            med, q75 = compute_runlen_stats(tr_ids); md = build_min_dur(med, q75, mult=mult)\n",
        "            dists=[]\n",
        "            for sid in va_ids:\n",
        "                # skeleton fused v2+v3 aligned\n",
        "                p_skel = load_probs(int(sid)).astype(np.float32)\n",
        "                # RGB optional\n",
        "                prgbp = probs_cache/f\"{sid}_rgb.npy\"\n",
        "                pr_aligned = None\n",
        "                ps_base = p_skel\n",
        "                if prgbp.exists():\n",
        "                    pr = np.load(prgbp).astype(np.float32)\n",
        "                    pr_aligned, ps_base = align_stream_to_skel(pr, p_skel, max_shift=15)\n",
        "                # Audio optional\n",
        "                paudp = probs_cache/f\"{sid}_aud.npy\"\n",
        "                pa_aligned = None\n",
        "                if paudp.exists():\n",
        "                    pa = np.load(paudp).astype(np.float32)\n",
        "                    pa_aligned, ps_base = align_stream_to_skel(pa, ps_base, max_shift=15)\n",
        "                # Ensure common length across ps/pr/pa before fusion\n",
        "                ps_c, pr_c, pa_c = _crop_common_lengths(ps_base, pr_aligned, pa_aligned)\n",
        "                pf = fuse_poe_triple(ps_c, pr_c, pa_c, alpha=alpha_fixed, gamma=gamma)\n",
        "                y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "                seq = compress_to_sequence(y_hat); seq_true = compress_to_sequence(load_frame_labels(int(sid)))\n",
        "                dists.append(levenshtein(seq, seq_true))\n",
        "            per_fold.append(float(np.mean(dists)) if dists else 0.0)\n",
        "        worst_by[gamma] = max(per_fold); mean_by[gamma] = float(np.mean(per_fold))\n",
        "        print(f\"  -> worst={worst_by[gamma]:.3f} mean={mean_by[gamma]:.3f}\", flush=True)\n",
        "    print('OOF-AUDIO gamma summary:')\n",
        "    for g in gamma_list: print(f'  gamma={g}: worst={worst_by[g]:.3f} mean={mean_by[g]:.3f}')\n",
        "    best_gamma = min(gamma_list, key=lambda g: (worst_by[g], mean_by[g]))\n",
        "    print('Chosen gamma (by worst then mean):', best_gamma)\n",
        "    return best_gamma, worst_by, mean_by\n",
        "\n",
        "def fuse_decode_test_with_audio(alpha: float = 0.26, gamma: float = 0.15, mult: float = 0.7, smooth_k: int = 5, aba_len: int = 2, aba_ratio: float = 1.04, out_csv: str = 'submission_fused_rgbt_audio.csv'):\n",
        "    all_train_ids=[]\n",
        "    for fd in json.load(open('folds_archive_cv.json','r')): all_train_ids.extend(list(map(int, fd['train_ids'])))\n",
        "    med, q75 = compute_runlen_stats(sorted(set(all_train_ids))); md = build_min_dur(med, q75, mult=mult)\n",
        "    rows=[]; ids=[]; n=0; t0=time.time()\n",
        "    test_ids = sorted(pd.read_csv('test.csv')['Id'].astype(int).tolist())\n",
        "    for sid in test_ids:\n",
        "        p2 = probs_cache/f\"{sid}_ce.npy\"; p3 = probs_cache/f\"{sid}_ce_v3.npy\"\n",
        "        if not (p2.exists() and p3.exists()):\n",
        "            continue\n",
        "        p_skel = load_probs(int(sid)).astype(np.float32)\n",
        "        # RGB optional\n",
        "        prgbp = probs_cache/f\"{sid}_rgb.npy\"\n",
        "        pr_aligned = None\n",
        "        ps_base = p_skel\n",
        "        if prgbp.exists():\n",
        "            pr = np.load(prgbp).astype(np.float32)\n",
        "            pr_aligned, ps_base = align_stream_to_skel(pr, ps_base, max_shift=15)\n",
        "        # Audio optional\n",
        "        paudp = probs_cache/f\"{sid}_aud.npy\"\n",
        "        pa_aligned = None\n",
        "        if paudp.exists():\n",
        "            pa = np.load(paudp).astype(np.float32)\n",
        "            pa_aligned, ps_base = align_stream_to_skel(pa, ps_base, max_shift=15)\n",
        "        # Ensure common length before fusion\n",
        "        ps_c, pr_c, pa_c = _crop_common_lengths(ps_base, pr_aligned, pa_aligned)\n",
        "        pf = fuse_poe_triple(ps_c, pr_c, pa_c, alpha=alpha, gamma=gamma)\n",
        "        y_hat = decode_minseg_smooth_aba(pf, md, smooth_k=smooth_k, aba_len=aba_len, aba_ratio=aba_ratio)\n",
        "        seq_raw=[]; last=-1\n",
        "        for c in y_hat:\n",
        "            if c==0: continue\n",
        "            if c!=last: seq_raw.append(int(c)); last=int(c)\n",
        "        seq = make_perm20(seq_raw, pf)\n",
        "        ids.append(sid); rows.append(' '.join(map(str, seq))); n+=1\n",
        "        if (n%20)==0 or n==95: print(f'  [AUDIO FUSE] test decoded {n}/95 elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    sub = pd.DataFrame({'Id': ids, 'Sequence': rows}).sort_values('Id')\n",
        "    sub.to_csv(out_csv, index=False); print('Wrote', out_csv, 'rows=', len(sub), 'head:\\n', sub.head())\n",
        "    assert len(sub)==95, f'Expected 95 rows, got {len(sub)}'\n",
        "    sub.to_csv('submission.csv', index=False); print('submission.csv written ->', out_csv)\n",
        "\n",
        "print('Audio OOF: tuning gamma with alpha=0.26 ...', flush=True)\n",
        "best_gamma, wb_g, mb_g = oof_tune_audio_gamma(alpha_fixed=0.26, gamma_list=(0.10,0.15,0.20,0.25), mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04)\n",
        "print('Audio TEST: fuse decode with best gamma ...', flush=True)\n",
        "out_csv = f\"submission_fused_rgb_audio_g{str(best_gamma).replace('.', '')}.csv\"\n",
        "fuse_decode_test_with_audio(alpha=0.26, gamma=best_gamma, mult=0.7, smooth_k=5, aba_len=2, aba_ratio=1.04, out_csv=out_csv)\n",
        "print('Audio fusion pipeline complete.')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio: caching MFCC features for TRAIN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 20/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 40/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 60/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 80/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 100/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 120/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 140/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 160/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 180/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 200/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 220/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 240/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 260/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 280/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 297/297 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[audio] Done: ok=0 skip=297 fail=0 total=297 elapsed=0.0s\nAudio: caching MFCC features for TEST...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 20/95 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 40/95 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 60/95 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [audio] skip 80/95 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[audio] missing tar for id=401: None\n[audio] missing tar for id=402: None\n[audio] missing tar for id=403: None\n  [audio] processed 95/95 ok=0 skip=92 fail=3 elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[audio] Done: ok=0 skip=92 fail=3 total=95 elapsed=0.0s\nAudio Fold 0: train=199 val=98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 01 tr_nll=2.8922 val_nll=2.4531 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 02 tr_nll=2.6610 val_nll=2.3254 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 03 tr_nll=2.5227 val_nll=2.1471 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 04 tr_nll=2.4389 val_nll=2.1655 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 05 tr_nll=2.3682 val_nll=2.2237 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 06 tr_nll=2.3158 val_nll=2.1486 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO Temp] best T=0.85 NLL=2.1252 on 98 val ids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio Fold 1: train=198 val=99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 01 tr_nll=2.8523 val_nll=2.5330 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 02 tr_nll=2.6304 val_nll=2.4371 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 03 tr_nll=2.4659 val_nll=2.4376 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 04 tr_nll=2.3843 val_nll=2.2258 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 05 tr_nll=2.3144 val_nll=2.2373 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 06 tr_nll=2.2890 val_nll=2.2719 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 07 tr_nll=2.2205 val_nll=2.3472 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 20/99 split=train _aud.npy elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 40/99 split=train _aud.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 60/99 split=train _aud.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 80/99 split=train _aud.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 99/99 split=train _aud.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 20/95 split=test _aud_f1.npy elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 40/95 split=test _aud_f1.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 60/95 split=test _aud_f1.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 80/95 split=test _aud_f1.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[audio] missing tar for id=401: None\n  [AUDIO infer] missing feat for id=401, skip\n[audio] missing tar for id=402: None\n  [AUDIO infer] missing feat for id=402, skip\n[audio] missing tar for id=403: None\n  [AUDIO infer] missing feat for id=403, skip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO Temp] best T=0.8 NLL=2.1927 on 99 val ids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio Fold 2: train=197 val=100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 01 tr_nll=2.4829 val_nll=3.1863 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 02 tr_nll=2.2852 val_nll=3.3736 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 03 tr_nll=2.1809 val_nll=3.0701 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 04 tr_nll=2.0983 val_nll=3.0451 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 05 tr_nll=2.0480 val_nll=2.8269 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 06 tr_nll=2.0040 val_nll=3.0366 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 07 tr_nll=1.9670 val_nll=2.9255 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO fold] ep 08 tr_nll=1.9335 val_nll=2.9271 elapsed=0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 20/100 split=train _aud.npy elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 40/100 split=train _aud.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 60/100 split=train _aud.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 80/100 split=train _aud.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 100/100 split=train _aud.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 20/95 split=test _aud_f2.npy elapsed=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 40/95 split=test _aud_f2.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 60/95 split=test _aud_f2.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO infer] saved 80/95 split=test _aud_f2.npy elapsed=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[audio] missing tar for id=401: None\n  [AUDIO infer] missing feat for id=401, skip\n[audio] missing tar for id=402: None\n  [AUDIO infer] missing feat for id=402, skip\n[audio] missing tar for id=403: None\n  [AUDIO infer] missing feat for id=403, skip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUDIO Temp] best T=1.5 NLL=2.7328 on 100 val ids\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averaging TEST audio per-fold with temps ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Averaged TEST per-fold -> aud.npy for 92 ids\nAudio OOF: tuning gamma with alpha=0.26 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-AUDIO] gamma=0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.530 mean=3.758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-AUDIO] gamma=0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.460 mean=3.627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-AUDIO] gamma=0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.420 mean=3.627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-AUDIO] gamma=0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> worst=4.280 mean=3.526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF-AUDIO gamma summary:\n  gamma=0.1: worst=4.530 mean=3.758\n  gamma=0.15: worst=4.460 mean=3.627\n  gamma=0.2: worst=4.420 mean=3.627\n  gamma=0.25: worst=4.280 mean=3.526\nChosen gamma (by worst then mean): 0.25\nAudio TEST: fuse decode with best gamma ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO FUSE] test decoded 20/95 elapsed=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO FUSE] test decoded 40/95 elapsed=0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO FUSE] test decoded 60/95 elapsed=1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO FUSE] test decoded 80/95 elapsed=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [AUDIO FUSE] test decoded 95/95 elapsed=2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_fused_rgb_audio_g025.csv rows= 95 head:\n     Id                                           Sequence\n0  300  5 9 1 2 18 3 8 4 20 13 12 15 14 11 6 16 7 10 1...\n1  301  10 12 1 5 4 6 2 11 15 13 19 9 8 18 14 3 16 17 ...\n2  302  1 17 16 12 5 9 19 7 13 20 18 11 3 4 6 15 8 14 ...\n3  303  18 13 4 3 10 14 6 5 19 20 17 2 11 16 8 9 7 12 ...\n4  304  8 1 7 12 14 18 13 9 2 11 3 20 19 5 6 17 16 4 1...\nsubmission.csv written -> submission_fused_rgb_audio_g025.csv\nAudio fusion pipeline complete.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}