{
  "cells": [
    {
      "id": "049d32fc-599e-4924-985f-cac270a2a7a4",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-modal Gesture Recognition: Plan\n",
        "\n",
        "Goal: Win a medal by building a robust pipeline with strong validation and fast iterations.\n",
        "\n",
        "High-level plan:\n",
        "- Environment gate: verify GPU availability and correct CUDA stack.\n",
        "- Data audit: inspect training.csv, test.csv, randomPredictions.csv format and archives content.\n",
        "- Validation: design user-independent CV if possible (mirror test), else robust grouped CV by sequence/user if fields exist in training.csv.\n",
        "- Baseline:\n",
        "  - Stage 1: Fast baseline predicting from skeleton/joints if readily available; else simple heuristics or provided sample code to establish a working submission.\n",
        "  - Stage 2: Extract features from .mat files (skeleton, joint orientation, audio/rgb/depth descriptors) to create sequence-level features.\n",
        "- Modeling:\n",
        "  - Start with classical models on aggregated temporal features (XGBoost/CatBoost with GPU).\n",
        "  - Explore sequence models on skeleton (GRU/LSTM/Temporal CNN) if time permits.\n",
        "- Ensembling: blend diverse models (tree + RNN) using OOF-calibrated weights.\n",
        "- Error analysis: bucket by class, confidence, and sequence length to guide FE iterations.\n",
        "\n",
        "Milestones (request expert review at each):\n",
        "1) Plan (this) \u2192 ask for medal-winning strategies and pitfalls.\n",
        "2) Data loading/EDA & archive structure understanding.\n",
        "3) Baseline working submission.\n",
        "4) Feature engineering v1 (skeleton-centric).\n",
        "5) Model v1 (GPU trees) + solid CV.\n",
        "6) Improvements/ensembling.\n",
        "\n",
        "Next: Run environment and data sanity checks.\n",
        "\n",
        "Note: We'll cache heavy transforms and always log progress/elapsed times.\n",
        "\n",
        "---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0c15bf1e-872a-4e0d-b249-096b642aad17",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 0) Environment and data sanity checks\n",
        "import os, sys, subprocess, time, tarfile, shutil, glob, math, random, warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "start_ts = time.time()\n",
        "\n",
        "def run(cmd):\n",
        "    print(\"$\", \" \".join(cmd), flush=True)\n",
        "    out = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    print(out.stdout, flush=True)\n",
        "    return out.stdout\n",
        "\n",
        "print(\"[Env] nvidia-smi:\")\n",
        "run(['bash','-lc','nvidia-smi || true'])\n",
        "\n",
        "print(\"[Env] Python:\", sys.version)\n",
        "print(\"[CWD]\", os.getcwd())\n",
        "print(\"[LS]\")\n",
        "run(['bash','-lc','ls -alh'])\n",
        "\n",
        "import pandas as pd\n",
        "print(\"[Load] training.csv / test.csv / randomPredictions.csv heads\")\n",
        "train_df = pd.read_csv('training.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "rand_df = pd.read_csv('randomPredictions.csv')\n",
        "print(\"training.csv shape:\", train_df.shape); print(train_df.head(3))\n",
        "print(\"test.csv shape:\", test_df.shape); print(test_df.head(3))\n",
        "print(\"randomPredictions.csv shape:\", rand_df.shape); print(rand_df.head(3))\n",
        "\n",
        "print(\"[Archives] List first few members of training/validation/test archives\")\n",
        "def list_tar(path, n=10):\n",
        "    try:\n",
        "        with tarfile.open(path, 'r:gz') as tf:\n",
        "            names = tf.getnames()\n",
        "            print(f\"{path}: {len(names)} files. First {n}:\")\n",
        "            for x in names[:n]:\n",
        "                print(\" -\", x)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to open {path}: {e}\")\n",
        "\n",
        "for p in ['training1.tar.gz','training2.tar.gz','training3.tar.gz','validation1.tar.gz','validation2.tar.gz','validation3.tar.gz','test.tar.gz']:\n",
        "    if os.path.exists(p):\n",
        "        list_tar(p, n=10)\n",
        "\n",
        "elapsed = time.time() - start_ts\n",
        "print(f\"[Done sanity checks] Elapsed: {elapsed:.1f}s\", flush=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Env] nvidia-smi:\n$ bash -lc nvidia-smi || true\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 29 02:38:37 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Env] Python: 3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]\n[CWD] /var/lib/simon/agent_run_states/multi-modal-gesture-recognition-20250929-022629\n[LS]\n$ bash -lc ls -alh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 22G\ndrwxrwxrwx 3 simon simon 4.0K Sep 29 02:38 .\ndrwxr-xr-x 3 root  root  4.0K Sep 29 02:29 ..\n-rw-r--r-- 1 simon simon  182 Sep 29 02:38 .00_eda_and_planning_kernel_state.json\n-rw-r--r-- 1 simon simon 4.8K Sep 29 02:38 00_eda_and_planning.ipynb\ndrwxr-xr-x 3 simon simon 4.0K Sep 29 02:37 agent_metadata\n-rw-rw-rw- 1 simon simon  22K Sep 29 02:35 description.md\n-rw-rw-rw- 1 simon simon 2.1G Sep 29 02:35 devel01-40.7z\n-rw-rw-r-- 1 simon simon  38K Sep 29 02:38 docker_run.log\n-rw-rw-rw- 1 simon simon 5.3K Sep 29 02:34 randomPredictions.csv\n-rw-r--r-- 1 simon simon 2.0K Sep 29 02:37 requirements.txt\n-rw-rw-rw- 1 simon simon 7.6K Sep 29 02:35 sample_code_mmrgc.zip\n-rw-r--r-- 1 simon simon 3.9K Sep 29 02:29 task.txt\n-rw-rw-rw- 1 simon simon  478 Sep 29 02:34 test.csv\n-rw-rw-rw- 1 simon simon 2.0G Sep 29 02:34 test.tar.gz\n-rw-rw-rw- 1 simon simon  17K Sep 29 02:34 training.csv\n-rw-rw-rw- 1 simon simon 4.1G Sep 29 02:35 training1.tar.gz\n-rw-rw-rw- 1 simon simon 1.7G Sep 29 02:35 training2.tar.gz\n-rw-rw-rw- 1 simon simon 2.2G Sep 29 02:35 training3.tar.gz\n-rw-rw-rw- 1 simon simon 918M Sep 29 02:35 valid_all_files_combined.7z\n-rw-rw-rw- 1 simon simon 2.8G Sep 29 02:35 validation1.tar.gz\n-rw-rw-rw- 1 simon simon 3.3G Sep 29 02:35 validation2.tar.gz\n-rw-rw-rw- 1 simon simon 3.1G Sep 29 02:35 validation3.tar.gz\n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Load] training.csv / test.csv / randomPredictions.csv heads\ntraining.csv shape: (297, 2)\n   Id                                           Sequence\n0   1  2 14 20 6 7 3 1 13 18 5 12 16 15 4 9 10 8 17 1...\n1   3  12 3 18 14 16 20 5 2 4 1 10 6 9 19 15 17 11 13...\n2   4  13 1 8 18 7 17 16 9 5 10 11 4 20 3 19 2 14 6 1...\ntest.csv shape: (95, 1)\n    Id\n0  300\n1  301\n2  302\nrandomPredictions.csv shape: (95, 2)\n    Id                                           Sequence\n0  300  13 14 2 9 16 7 20 5 8 6 10 4 3 12 18 1 15 17 1...\n1  301  4 3 11 16 20 6 7 15 10 18 17 9 8 12 5 19 1 13 ...\n2  302  13 1 16 11 8 12 6 15 2 4 10 17 9 7 20 5 18 19 ...\n[Archives] List first few members of training/validation/test archives\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training1.tar.gz: 99 files. First 10:\n - ./Sample00001.zip\n - ./Sample00003.zip\n - ./Sample00004.zip\n - ./Sample00005.zip\n - ./Sample00006.zip\n - ./Sample00007.zip\n - ./Sample00008.zip\n - ./Sample00009.zip\n - ./Sample00010.zip\n - ./Sample00011.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training2.tar.gz: 99 files. First 10:\n - ./Sample00101.zip\n - ./Sample00102.zip\n - ./Sample00103.zip\n - ./Sample00104.zip\n - ./Sample00105.zip\n - ./Sample00106.zip\n - ./Sample00107.zip\n - ./Sample00108.zip\n - ./Sample00109.zip\n - ./Sample00110.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training3.tar.gz: 100 files. First 10:\n - ./Sample00200.zip\n - ./Sample00201.zip\n - ./Sample00202.zip\n - ./Sample00203.zip\n - ./Sample00204.zip\n - ./Sample00205.zip\n - ./Sample00206.zip\n - ./Sample00207.zip\n - ./Sample00208.zip\n - ./Sample00209.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation1.tar.gz: 99 files. First 10:\n - Sample00410.zip\n - Sample00411.zip\n - Sample00412.zip\n - Sample00413.zip\n - Sample00414.zip\n - Sample00415.zip\n - Sample00416.zip\n - Sample00417.zip\n - Sample00418.zip\n - Sample00420.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation2.tar.gz: 104 files. First 10:\n - Sample00510.zip\n - Sample00516.zip\n - Sample00517.zip\n - Sample00518.zip\n - Sample00519.zip\n - Sample00520.zip\n - Sample00521.zip\n - Sample00522.zip\n - Sample00523.zip\n - Sample00524.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation3.tar.gz: 84 files. First 10:\n - Sample00621.zip\n - Sample00622.zip\n - Sample00623.zip\n - Sample00624.zip\n - Sample00625.zip\n - Sample00626.zip\n - Sample00627.zip\n - Sample00628.zip\n - Sample00629.zip\n - Sample00630.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.tar.gz: 95 files. First 10:\n - ./Sample00300.zip\n - ./Sample00301.zip\n - ./Sample00302.zip\n - ./Sample00303.zip\n - ./Sample00304.zip\n - ./Sample00305.zip\n - ./Sample00306.zip\n - ./Sample00307.zip\n - ./Sample00308.zip\n - ./Sample00309.zip\n[Done sanity checks] Elapsed: 25.3s\n"
          ]
        }
      ]
    },
    {
      "id": "21625105-ed9a-45eb-bb7f-d939666925fa",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 1) Surgical tar->zip->mat probe for a single sample\n",
        "import io, zipfile\n",
        "import numpy as np\n",
        "\n",
        "def ensure_scipy():\n",
        "    try:\n",
        "        import scipy.io as sio  # noqa\n",
        "        return\n",
        "    except Exception:\n",
        "        print(\"[Setup] Installing scipy...\")\n",
        "        run(['bash','-lc', f\"{sys.executable} -m pip install -q scipy\"])\n",
        "ensure_scipy()\n",
        "import scipy.io as sio\n",
        "\n",
        "def probe_one_sample(tar_path):\n",
        "    print(f\"[Probe] {tar_path}\")\n",
        "    with tarfile.open(tar_path, 'r:gz') as tf:\n",
        "        # pick the first Sample*.zip member\n",
        "        zmem = next(m for m in tf.getmembers() if m.name.lower().endswith('.zip'))\n",
        "        print(\"  zip member:\", zmem.name)\n",
        "        zbytes = tf.extractfile(zmem).read()\n",
        "        with zipfile.ZipFile(io.BytesIO(zbytes)) as zf:\n",
        "            names = zf.namelist()\n",
        "            print(\"  zip contains:\", len(names), \"files. First 10:\")\n",
        "            for x in names[:10]:\n",
        "                print(\"   -\", x)\n",
        "            # find *_data.mat\n",
        "            mat_name = next(n for n in names if n.lower().endswith('_data.mat'))\n",
        "            print(\"  data mat:\", mat_name)\n",
        "            with zf.open(mat_name) as f:\n",
        "                d = sio.loadmat(f, simplify_cells=True)\n",
        "    return d\n",
        "\n",
        "def summarize_dict(d, prefix=\"\"):\n",
        "    for k, v in d.items():\n",
        "        if k.startswith('__'):\n",
        "            continue\n",
        "        try:\n",
        "            if isinstance(v, dict):\n",
        "                print(f\"{prefix}{k}: dict({len(v)})\")\n",
        "                summarize_dict(v, prefix + \"  \")\n",
        "            elif isinstance(v, (list, tuple)):\n",
        "                lens = len(v)\n",
        "                print(f\"{prefix}{k}: {type(v).__name__} len={lens}\")\n",
        "                if lens and hasattr(v[0], 'shape'):\n",
        "                    print(f\"{prefix}  [0] shape={v[0].shape}\")\n",
        "            elif hasattr(v, 'shape'):\n",
        "                print(f\"{prefix}{k}: array shape={v.shape} dtype={getattr(v,'dtype','')} \")\n",
        "            else:\n",
        "                t = type(v).__name__\n",
        "                vs = str(v)\n",
        "                if len(vs) > 80: vs = vs[:80] + '...'\n",
        "                print(f\"{prefix}{k}: {t} = {vs}\")\n",
        "        except Exception as e:\n",
        "            print(f\"{prefix}{k}: error summarizing -> {e}\")\n",
        "\n",
        "def find_keys_recursive(d, kw_list):\n",
        "    hits = []\n",
        "    def rec(x, path):\n",
        "        if isinstance(x, dict):\n",
        "            for k, v in x.items():\n",
        "                low = k.lower()\n",
        "                if any(kw in low for kw in kw_list):\n",
        "                    hits.append((\"/\".join(path+[k]), type(v).__name__))\n",
        "                rec(v, path+[k])\n",
        "        elif isinstance(x, (list, tuple)):\n",
        "            for i, v in enumerate(x):\n",
        "                rec(v, path+[f\"[{i}]\"])\n",
        "    rec(d, [])\n",
        "    return hits\n",
        "\n",
        "sample_dict = probe_one_sample('training1.tar.gz')\n",
        "print(\"[Summary] Top-level keys:\", [k for k in sample_dict.keys() if not k.startswith('__')])\n",
        "summarize_dict(sample_dict)\n",
        "\n",
        "label_hits = find_keys_recursive(sample_dict, [\"label\",\"annot\",\"segment\",\"boundary\",\"start\",\"end\"])\n",
        "print(\"[Search] Potential label/segment keys (train/val only):\")\n",
        "for h in label_hits[:20]:\n",
        "    print(\" -\", h)\n",
        "\n",
        "skeleton_hits = find_keys_recursive(sample_dict, [\"skeleton\",\"joint\",\"position\",\"world\",\"orientation\",\"user\",\"subject\",\"fps\",\"frame\"])\n",
        "print(\"[Search] Potential skeleton/meta keys:\")\n",
        "for h in skeleton_hits[:20]:\n",
        "    print(\" -\", h)\n",
        "\n",
        "print(\"[Note] Confirm exact fields for: skeleton 3D positions (T x J x 3), labels as (cls,start,end), fps, and user/subject.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Probe] training1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  zip member: ./Sample00001.zip\n  zip contains: 5 files. First 10:\n   - Sample00001_color.mp4\n   - Sample00001_depth.mp4\n   - Sample00001_user.mp4\n   - Sample00001_data.mat\n   - Sample00001_audio.wav\n  data mat: Sample00001_data.mat\n[Summary] Top-level keys: ['Video']\nVideo: dict(5)\n  NumFrames: int = 1254\n  FrameRate: int = 20\n  Frames: list len=1254\n  MaxDepth: int = 3293\n  Labels: list len=20\n[Search] Potential label/segment keys (train/val only):\n - ('Video/Labels', 'list')\n - ('Video/Labels/[0]/End', 'int')\n - ('Video/Labels/[1]/End', 'int')\n - ('Video/Labels/[2]/End', 'int')\n - ('Video/Labels/[3]/End', 'int')\n - ('Video/Labels/[4]/End', 'int')\n - ('Video/Labels/[5]/End', 'int')\n - ('Video/Labels/[6]/End', 'int')\n - ('Video/Labels/[7]/End', 'int')\n - ('Video/Labels/[8]/End', 'int')\n - ('Video/Labels/[9]/End', 'int')\n - ('Video/Labels/[10]/End', 'int')\n - ('Video/Labels/[11]/End', 'int')\n - ('Video/Labels/[12]/End', 'int')\n - ('Video/Labels/[13]/End', 'int')\n - ('Video/Labels/[14]/End', 'int')\n - ('Video/Labels/[15]/End', 'int')\n - ('Video/Labels/[16]/End', 'int')\n - ('Video/Labels/[17]/End', 'int')\n - ('Video/Labels/[18]/End', 'int')\n[Search] Potential skeleton/meta keys:\n - ('Video/NumFrames', 'int')\n - ('Video/FrameRate', 'int')\n - ('Video/Frames', 'list')\n - ('Video/Frames/[0]/Skeleton', 'dict')\n - ('Video/Frames/[0]/Skeleton/WorldPosition', 'ndarray')\n - ('Video/Frames/[0]/Skeleton/WorldRotation', 'ndarray')\n - ('Video/Frames/[0]/Skeleton/JointType', 'ndarray')\n - ('Video/Frames/[0]/Skeleton/PixelPosition', 'ndarray')\n - ('Video/Frames/[1]/Skeleton', 'dict')\n - ('Video/Frames/[1]/Skeleton/WorldPosition', 'ndarray')\n - ('Video/Frames/[1]/Skeleton/WorldRotation', 'ndarray')\n - ('Video/Frames/[1]/Skeleton/JointType', 'ndarray')\n - ('Video/Frames/[1]/Skeleton/PixelPosition', 'ndarray')\n - ('Video/Frames/[2]/Skeleton', 'dict')\n - ('Video/Frames/[2]/Skeleton/WorldPosition', 'ndarray')\n - ('Video/Frames/[2]/Skeleton/WorldRotation', 'ndarray')\n - ('Video/Frames/[2]/Skeleton/JointType', 'ndarray')\n - ('Video/Frames/[2]/Skeleton/PixelPosition', 'ndarray')\n - ('Video/Frames/[3]/Skeleton', 'dict')\n - ('Video/Frames/[3]/Skeleton/WorldPosition', 'ndarray')\n[Note] Confirm exact fields for: skeleton 3D positions (T x J x 3), labels as (cls,start,end), fps, and user/subject.\n"
          ]
        }
      ]
    },
    {
      "id": "e0c92851-0bf6-483a-b6a6-2bbc95fcb5be",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 2) Inspect structures within one sample: labels and skeleton layout\n",
        "vid = sample_dict.get('Video', {})\n",
        "print('[Video] keys:', list(vid.keys()))\n",
        "print('[Video] NumFrames:', vid.get('NumFrames'), 'FrameRate:', vid.get('FrameRate'))\n",
        "\n",
        "# Inspect labels content\n",
        "labels = vid.get('Labels', [])\n",
        "print('[Labels] count:', len(labels))\n",
        "if labels:\n",
        "    first = labels[0]\n",
        "    print('[Labels][0] type:', type(first))\n",
        "    if isinstance(first, dict):\n",
        "        print('[Labels][0] keys:', list(first.keys()))\n",
        "        print('[Labels][0] sample:', {k:first[k] for k in list(first.keys())[:5]})\n",
        "    else:\n",
        "        print('[Labels][0]:', first)\n",
        "\n",
        "# Inspect first few frames skeleton arrays\n",
        "frames = vid.get('Frames', [])\n",
        "print('[Frames] count:', len(frames))\n",
        "def frame_info(i):\n",
        "    fr = frames[i]\n",
        "    sk = fr.get('Skeleton') if isinstance(fr, dict) else None\n",
        "    if not isinstance(sk, dict):\n",
        "        return f'Frame {i}: no skeleton dict'\n",
        "    wp = sk.get('WorldPosition', None)\n",
        "    wr = sk.get('WorldRotation', None)\n",
        "    jt = sk.get('JointType', None)\n",
        "    px = sk.get('PixelPosition', None)\n",
        "    return f'Frame {i}: WP={getattr(wp,\"shape\",None)} WR={getattr(wr,\"shape\",None)} JT={getattr(jt,\"shape\",None)} PX={getattr(px,\"shape\",None)}'\n",
        "\n",
        "for i in [0,1,2,10,50]:\n",
        "    if i < len(frames):\n",
        "        print(frame_info(i))\n",
        "\n",
        "# Try to infer joint count and names/ids from a frame\n",
        "if frames:\n",
        "    sk0 = frames[0].get('Skeleton', {}) if isinstance(frames[0], dict) else {}\n",
        "    jt0 = sk0.get('JointType', None)\n",
        "    if jt0 is not None:\n",
        "        print('[JointType] dtype:', getattr(jt0,'dtype',None), 'shape:', getattr(jt0,'shape',None))\n",
        "        try:\n",
        "            print('[JointType] sample values:', jt0[:10])\n",
        "        except Exception as e:\n",
        "            print('[JointType] print error:', e)\n",
        "\n",
        "# Check if hand state or user/subject metadata exists\n",
        "meta_hits = find_keys_recursive(sample_dict, ['hand','state','user','subject','performer'])\n",
        "print('[Search] Potential hand/user fields:')\n",
        "for h in meta_hits[:20]:\n",
        "    print(' -', h)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Video] keys: ['NumFrames', 'FrameRate', 'Frames', 'MaxDepth', 'Labels']\n[Video] NumFrames: 1254 FrameRate: 20\n[Labels] count: 20\n[Labels][0] type: <class 'dict'>\n[Labels][0] keys: ['Name', 'Begin', 'End']\n[Labels][0] sample: {'Name': 'vieniqui', 'Begin': 1, 'End': 79}\n[Frames] count: 1254\nFrame 0: WP=(20, 3) WR=(20, 4) JT=(20,) PX=(20, 2)\nFrame 1: WP=(20, 3) WR=(20, 4) JT=(20,) PX=(20, 2)\nFrame 2: WP=(20, 3) WR=(20, 4) JT=(20,) PX=(20, 2)\nFrame 10: WP=(20, 3) WR=(20, 4) JT=(20,) PX=(20, 2)\nFrame 50: WP=(20, 3) WR=(20, 4) JT=(20,) PX=(20, 2)\n[JointType] dtype: object shape: (20,)\n[JointType] sample values: [array([], dtype=float64) array([], dtype=float64)\n array([], dtype=float64) array([], dtype=float64)\n array([], dtype=float64) array([], dtype=float64)\n array([], dtype=float64) array([], dtype=float64)\n array([], dtype=float64) array([], dtype=float64)]\n[Search] Potential hand/user fields:\n"
          ]
        }
      ]
    },
    {
      "id": "e6c78c05-772d-4651-ad3b-fa0f6b053731",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 3) Build name<->class-id mapping quickly (stop at 20) and sanity-load one sample\n",
        "import re, io, zipfile, tarfile, numpy as np, pandas as pd, time\n",
        "\n",
        "train_df = pd.read_csv('training.csv')\n",
        "train_ids_set = set(train_df['Id'].tolist())\n",
        "\n",
        "def id_to_tar_and_zipname(sample_id:int):\n",
        "    if sample_id < 100:\n",
        "        tar = 'training1.tar.gz'\n",
        "    elif 100 <= sample_id < 200:\n",
        "        tar = 'training2.tar.gz'\n",
        "    else:\n",
        "        tar = 'training3.tar.gz'\n",
        "    return tar, f'./Sample{sample_id:05d}.zip'\n",
        "\n",
        "def list_ids_in_tar(tar_path):\n",
        "    ids = []\n",
        "    with tarfile.open(tar_path, 'r:gz') as tf:\n",
        "        for m in tf.getmembers():\n",
        "            if m.name.lower().endswith('.zip'):\n",
        "                m2 = re.findall(r'(\\d{5})', m.name)\n",
        "                if m2:\n",
        "                    sid = int(m2[0])\n",
        "                    ids.append(sid)\n",
        "    return ids\n",
        "\n",
        "def load_labels_names_for_id(sample_id:int):\n",
        "    tar, zipname = id_to_tar_and_zipname(sample_id)\n",
        "    with tarfile.open(tar, 'r:gz') as tf:\n",
        "        mem = next((m for m in tf.getmembers() if m.name.endswith(zipname)), None)\n",
        "        if mem is None:\n",
        "            raise FileNotFoundError(f'Zip {zipname} not found in {tar}')\n",
        "        zbytes = tf.extractfile(mem).read()\n",
        "        with zipfile.ZipFile(io.BytesIO(zbytes)) as zf:\n",
        "            mat_name = next(n for n in zf.namelist() if n.lower().endswith('_data.mat'))\n",
        "            with zf.open(mat_name) as f:\n",
        "                d = sio.loadmat(f, simplify_cells=True)\n",
        "    labels = d['Video']['Labels']\n",
        "    names = [lab['Name'] for lab in labels]\n",
        "    return names\n",
        "\n",
        "def parse_sequence_numbers(seq_str:str):\n",
        "    return [int(x) for x in re.findall(r'\\d+', str(seq_str))]\n",
        "\n",
        "def build_mapping_until_20(candidate_ids):\n",
        "    name_to_id, id_to_name, conflicts = {}, {}, []\n",
        "    seen_class_ids = set()\n",
        "    t0 = time.time()\n",
        "    for i, sid in enumerate(candidate_ids):\n",
        "        try:\n",
        "            print(f'[Map] {i+1}/{len(candidate_ids)}: Id={sid}', flush=True)\n",
        "            names = load_labels_names_for_id(sid)\n",
        "            seq_nums = parse_sequence_numbers(train_df.loc[train_df.Id==sid, 'Sequence'].values[0])\n",
        "            if len(seq_nums) != len(names):\n",
        "                print(f'[Warn] Mismatch counts for {sid}: nums={len(seq_nums)} names={len(names)}')\n",
        "            m = min(len(seq_nums), len(names))\n",
        "            for k in range(m):\n",
        "                n = names[k]\n",
        "                cid = seq_nums[k]\n",
        "                if n in name_to_id and name_to_id[n] != cid:\n",
        "                    conflicts.append((n, name_to_id[n], cid, sid))\n",
        "                name_to_id[n] = cid\n",
        "                id_to_name[cid] = n\n",
        "                seen_class_ids.add(cid)\n",
        "            if len(seen_class_ids) >= 20 or len(name_to_id) >= 20:\n",
        "                print(f'[Map] Reached {len(seen_class_ids)} unique class ids; stopping.', flush=True)\n",
        "                break\n",
        "        except Exception as e:\n",
        "            print(f'[Warn] Failed Id={sid}: {e}')\n",
        "    print(f'[Map] Done in {time.time()-t0:.1f}s. Unique classes: {len(seen_class_ids)} names: {len(name_to_id)} conflicts: {len(conflicts)}')\n",
        "    return name_to_id, id_to_name, conflicts\n",
        "\n",
        "# Build a small deterministic candidate id list from each training tar (first ~12 per tar that exist in training.csv)\n",
        "cand = []\n",
        "for tar_path in ['training1.tar.gz','training2.tar.gz','training3.tar.gz']:\n",
        "    ids = [i for i in list_ids_in_tar(tar_path) if i in train_ids_set]\n",
        "    ids = sorted(ids)[:12]\n",
        "    cand.extend(ids)\n",
        "print('[Cand] ids:', cand[:20], '... total', len(cand))\n",
        "\n",
        "name_to_id, id_to_name, conflicts = build_mapping_until_20(cand)\n",
        "print('[Mapping] size:', len(name_to_id), 'unique class ids:', len(set(name_to_id.values())))\n",
        "print('[Mapping] sample pairs:', sorted([(v,k) for k,v in name_to_id.items()])[:10], '...')\n",
        "\n",
        "# Sanity: load one sample quickly to verify frame targets expansion\n",
        "def load_skeleton_and_frame_targets(sample_id:int, name_to_id_map:dict):\n",
        "    tar, zipname = id_to_tar_and_zipname(sample_id)\n",
        "    with tarfile.open(tar, 'r:gz') as tf:\n",
        "        mem = next(m for m in tf.getmembers() if m.name.endswith(zipname))\n",
        "        zbytes = tf.extractfile(mem).read()\n",
        "        with zipfile.ZipFile(io.BytesIO(zbytes)) as zf:\n",
        "            mat_name = next(n for n in zf.namelist() if n.lower().endswith('_data.mat'))\n",
        "            with zf.open(mat_name) as f:\n",
        "                d = sio.loadmat(f, simplify_cells=True)\n",
        "    vid = d['Video']\n",
        "    T = int(vid['NumFrames'])\n",
        "    frames = vid['Frames']\n",
        "    J = frames[0]['Skeleton']['WorldPosition'].shape[0]\n",
        "    skel = np.zeros((T, J, 3), dtype=np.float32)\n",
        "    for t in range(T):\n",
        "        wp = frames[t]['Skeleton']['WorldPosition']\n",
        "        if wp is None:\n",
        "            if t>0: skel[t] = skel[t-1]\n",
        "            continue\n",
        "        skel[t] = np.asarray(wp, dtype=np.float32)\n",
        "    y = np.zeros(T, dtype=np.int16)\n",
        "    for lab in vid['Labels']:\n",
        "        cls = name_to_id_map.get(lab['Name'])\n",
        "        if cls is None: continue\n",
        "        b = max(0, int(lab['Begin'])-1)\n",
        "        e = min(T, int(lab['End']))\n",
        "        y[b:e] = cls\n",
        "    return skel, y, vid\n",
        "\n",
        "test_id = cand[0] if len(cand)>0 else int(train_df.Id.iloc[0])\n",
        "test_skel, test_y, test_vid = load_skeleton_and_frame_targets(test_id, name_to_id)\n",
        "print('[Loader] sample id:', test_id, 'shapes:', test_skel.shape, test_y.shape, 'unique y:', np.unique(test_y))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cand] ids: [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 101, 102, 103, 104, 105, 106, 107, 108] ... total 36\n[Map] 1/36: Id=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Map] Reached 20 unique class ids; stopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Map] Done in 5.8s. Unique classes: 20 names: 20 conflicts: 0\n[Mapping] size: 20 unique class ids: 20\n[Mapping] sample pairs: [(1, 'vattene'), (2, 'vieniqui'), (3, 'perfetto'), (4, 'furbo'), (5, 'cheduepalle'), (6, 'chevuoi'), (7, 'daccordo'), (8, 'seipazzo'), (9, 'combinato'), (10, 'freganiente')] ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Loader] sample id: 1 shapes: (1254, 20, 3) (1254,) unique y: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
          ]
        }
      ]
    },
    {
      "id": "e96af87e-87ac-4e31-87a5-90665a8674e7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 4) Feature engineering, decoding, and smoke dataset builder\n",
        "import numpy as np, pandas as pd, tarfile, zipfile, io, time, os, math, subprocess, sys\n",
        "\n",
        "def pip_install(pkg):\n",
        "    print(f\"[Setup] Installing {pkg}...\")\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', pkg], check=True)\n",
        "\n",
        "try:\n",
        "    import xgboost as xgb  # noqa\n",
        "except Exception:\n",
        "    pip_install('xgboost==2.1.1')\n",
        "    import xgboost as xgb\n",
        "\n",
        "# --- FE: skeleton -> per-frame features ---\n",
        "def robust_scale_center(coords):\n",
        "    # coords: (J,3)\n",
        "    c = np.nanmean(coords, axis=0)  # center by mean joint\n",
        "    centered = coords - c\n",
        "    # scale by robust skeleton size: median pairwise distance or std\n",
        "    flat = centered.reshape(-1)\n",
        "    scale = np.nanstd(flat) + 1e-6\n",
        "    centered /= scale\n",
        "    return centered, scale\n",
        "\n",
        "def features_from_skeleton(skel):\n",
        "    # skel: (T,J,3) float32\n",
        "    T, J, _ = skel.shape\n",
        "    feats = np.zeros((T, J*3*2), dtype=np.float32)  # centered coords (J*3) + velocities (J*3)\n",
        "    prev = None\n",
        "    for t in range(T):\n",
        "        coords = skel[t]\n",
        "        centered, _ = robust_scale_center(coords)\n",
        "        if prev is None:\n",
        "            vel = np.zeros_like(centered)\n",
        "        else:\n",
        "            vel = centered - prev\n",
        "        prev = centered\n",
        "        feats[t, :J*3] = centered.reshape(-1)\n",
        "        feats[t, J*3:] = vel.reshape(-1)\n",
        "    return feats  # shape (T, 2*J*3)\n",
        "\n",
        "# --- Decoding utilities ---\n",
        "def median_filter(arr, k=7):\n",
        "    if k <= 1: return arr\n",
        "    k = int(k) | 1\n",
        "    pad = k//2\n",
        "    out = np.copy(arr)\n",
        "    for i in range(len(arr)):\n",
        "        s = max(0, i-pad); e = min(len(arr), i+pad+1)\n",
        "        out[i] = np.bincount(arr[s:e]).argmax()\n",
        "    return out\n",
        "\n",
        "def collapse_runs(labels):\n",
        "    seq = []\n",
        "    prev = None\n",
        "    for x in labels:\n",
        "        if x != prev:\n",
        "            seq.append(x)\n",
        "            prev = x\n",
        "    return seq\n",
        "\n",
        "def decode_sequence(probs, window=7, merge_gap=4, min_len=6, mean_thr=0.45, max_thr=0.6):\n",
        "    # probs: (T, C) softmax, C=21 with 0=background\n",
        "    labels = probs.argmax(1).astype(int)\n",
        "    labels = median_filter(labels, k=window)\n",
        "    T = len(labels)\n",
        "    # build segments\n",
        "    segs = []  # (cls, b, e, mean_p, max_p)\n",
        "    b = 0\n",
        "    for i in range(1, T+1):\n",
        "        if i==T or labels[i] != labels[b]:\n",
        "            cls = labels[b]\n",
        "            p = probs[b:i, cls] if cls < probs.shape[1] else np.zeros(i-b)\n",
        "            mean_p = float(p.mean()) if (i-b)>0 else 0.0\n",
        "            max_p = float(p.max()) if (i-b)>0 else 0.0\n",
        "            segs.append([cls, b, i, mean_p, max_p])\n",
        "            b = i\n",
        "    # merge small gaps between same class\n",
        "    merged = []\n",
        "    i = 0\n",
        "    while i < len(segs):\n",
        "        cur = segs[i]\n",
        "        j = i + 1\n",
        "        while j < len(segs):\n",
        "            if segs[j][0] == cur[0] and segs[j-1][0]==0 and (segs[j][1]-cur[2]) <= merge_gap:\n",
        "                # extend cur to segs[j]\n",
        "                cur[2] = segs[j][2]\n",
        "                cur[3] = float(np.mean(probs[cur[1]:cur[2], cur[0]]))\n",
        "                cur[4] = float(np.max(probs[cur[1]:cur[2], cur[0]]))\n",
        "                j += 1\n",
        "            else:\n",
        "                break\n",
        "        merged.append(cur)\n",
        "        i = j\n",
        "    # filter by min_len and hysteresis thresholds\n",
        "    out = []\n",
        "    for cls, sb, se, mp, xp in merged:\n",
        "        if cls == 0: continue\n",
        "        if (se - sb) < min_len: continue\n",
        "        if not (mp >= mean_thr and xp >= max_thr): continue\n",
        "        out.append(cls)\n",
        "    # collapse duplicates\n",
        "    final_seq = []\n",
        "    for c in out:\n",
        "        if not final_seq or final_seq[-1] != c:\n",
        "            final_seq.append(c)\n",
        "    return final_seq\n",
        "\n",
        "# --- Levenshtein distance ---\n",
        "def levenshtein(a, b):\n",
        "    n, m = len(a), len(b)\n",
        "    if n == 0: return m\n",
        "    if m == 0: return n\n",
        "    dp = list(range(m+1))\n",
        "    for i in range(1, n+1):\n",
        "        prev = dp[0]\n",
        "        dp[0] = i\n",
        "        for j in range(1, m+1):\n",
        "            temp = dp[j]\n",
        "            cost = 0 if a[i-1] == b[j-1] else 1\n",
        "            dp[j] = min(dp[j] + 1, dp[j-1] + 1, prev + cost)\n",
        "            prev = temp\n",
        "    return dp[m]\n",
        "\n",
        "# --- Dataset builder (smoke) ---\n",
        "def build_frame_dataset(sample_ids, name_to_id_map):\n",
        "    X_list, y_list, gid = [], [], []\n",
        "    t0 = time.time()\n",
        "    for idx, sid in enumerate(sample_ids):\n",
        "        skel, y, vid = load_skeleton_and_frame_targets(sid, name_to_id_map)\n",
        "        X = features_from_skeleton(skel)\n",
        "        X_list.append(X)\n",
        "        y_list.append(y.astype(np.int32))\n",
        "        gid.extend([sid]*len(y))\n",
        "        if (idx+1) % 2 == 0:\n",
        "            print(f\"[Build] {idx+1}/{len(sample_ids)} ids, cum frames={sum(x.shape[0] for x in X_list)}\")\n",
        "    X = np.vstack(X_list)\n",
        "    y = np.concatenate(y_list)\n",
        "    gid = np.array(gid, dtype=np.int32)\n",
        "    print(f\"[Build] Done in {time.time()-t0:.1f}s. X={X.shape} y={y.shape} groups={len(np.unique(gid))}\")\n",
        "    return X, y, gid\n",
        "\n",
        "print('[Ready] FE, decoding, and dataset builder prepared.')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ready] FE, decoding, and dataset builder prepared.\n"
          ]
        }
      ]
    },
    {
      "id": "57c64ce7-2e7a-4cdc-8bc2-a0492d4bb5f8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 5) Smoke experiment: train per-frame XGBoost on a few samples and evaluate decoding via Levenshtein\n",
        "import numpy as np, pandas as pd, xgboost as xgb, time\n",
        "\n",
        "def true_sequence_for_id(sample_id:int) -> list:\n",
        "    row = train_df.loc[train_df.Id==sample_id]\n",
        "    if row.empty: return []\n",
        "    return [int(x) for x in re.findall(r'\\d+', str(row['Sequence'].values[0]))]\n",
        "\n",
        "# pick small set from previously listed candidates\n",
        "smoke_ids = cand[:12] if len(cand) >= 12 else sorted(list(train_ids_set))[:12]\n",
        "train_ids_smoke = smoke_ids[:9]\n",
        "val_ids_smoke = smoke_ids[9:12]\n",
        "print('[Smoke] train ids:', train_ids_smoke)\n",
        "print('[Smoke] val ids:', val_ids_smoke)\n",
        "\n",
        "# Build datasets\n",
        "X_tr, y_tr, gid_tr = build_frame_dataset(train_ids_smoke, name_to_id)\n",
        "X_va, y_va, gid_va = build_frame_dataset(val_ids_smoke, name_to_id)\n",
        "\n",
        "# Optional: downweight background class 0\n",
        "def make_weights(y):\n",
        "    w = np.ones_like(y, dtype=np.float32)\n",
        "    w[y==0] = 0.4\n",
        "    return w\n",
        "w_tr = make_weights(y_tr)\n",
        "w_va = make_weights(y_va)\n",
        "\n",
        "dtr = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr)\n",
        "dva = xgb.DMatrix(X_va, label=y_va, weight=w_va)\n",
        "\n",
        "params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': 21,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'predictor': 'gpu_predictor',\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.08,\n",
        "    'subsample': 0.9,\n",
        "    'colsample_bytree': 0.9,\n",
        "    'min_child_weight': 2.0,\n",
        "    'lambda': 1.0\n",
        "}\n",
        "print('[XGB] Training...')\n",
        "t0 = time.time()\n",
        "bst = xgb.train(params, dtr, num_boost_round=1200, evals=[(dtr,'train'),(dva,'valid')], early_stopping_rounds=200, verbose_eval=100)\n",
        "print(f\"[XGB] Done in {time.time()-t0:.1f}s. Best iters={bst.best_iteration}\")\n",
        "\n",
        "# Evaluate decoding on val ids\n",
        "def predict_probs_for_id(sample_id:int):\n",
        "    skel, y, vid = load_skeleton_and_frame_targets(sample_id, name_to_id)\n",
        "    X = features_from_skeleton(skel)\n",
        "    dm = xgb.DMatrix(X)\n",
        "    P = bst.predict(dm, iteration_range=(0, bst.best_iteration+1))\n",
        "    return P, y, vid\n",
        "\n",
        "def eval_on_ids(ids, window=7, merge_gap=4, min_len=6, mean_thr=0.45, max_thr=0.6):\n",
        "    scores = []\n",
        "    for sid in ids:\n",
        "        P, y_frames, vid = predict_probs_for_id(sid)\n",
        "        pred_seq = decode_sequence(P, window=window, merge_gap=merge_gap, min_len=min_len, mean_thr=mean_thr, max_thr=max_thr)\n",
        "        true_seq = true_sequence_for_id(sid)\n",
        "        lev = levenshtein(pred_seq, true_seq)\n",
        "        scores.append((sid, lev, len(true_seq)))\n",
        "        print(f\"[Eval] Id={sid} pred={pred_seq} true={true_seq} lev={lev}\")\n",
        "    mean_lev = float(np.mean([s[1] for s in scores])) if scores else None\n",
        "    mean_norm = float(np.mean([s[1]/max(1,s[2]) for s in scores])) if scores else None\n",
        "    print(f\"[Eval] Val mean Levenshtein={mean_lev}, normalized={mean_norm}\")\n",
        "    return scores, mean_lev, mean_norm\n",
        "\n",
        "scores, mean_lev, mean_norm = eval_on_ids(val_ids_smoke)\n",
        "print('[Smoke] Completed.')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Smoke] train ids: [1, 3, 4, 5, 6, 7, 8, 9, 10]\n[Smoke] val ids: [11, 12, 13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Build] 2/9 ids, cum frames=2371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Build] 4/9 ids, cum frames=5041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Build] 6/9 ids, cum frames=7367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Build] 8/9 ids, cum frames=9778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Build] Done in 54.5s. X=(11004, 120) y=(11004,) groups=9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Build] 2/3 ids, cum frames=2325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Build] Done in 19.1s. X=(3540, 120) y=(3540,) groups=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB] Training...\n[0]\ttrain-mlogloss:2.64053\tvalid-mlogloss:2.88373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\ttrain-mlogloss:0.04777\tvalid-mlogloss:2.11404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttrain-mlogloss:0.01665\tvalid-mlogloss:2.18769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[262]\ttrain-mlogloss:0.01320\tvalid-mlogloss:2.22562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB] Done in 13.5s. Best iters=63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Eval] Id=11 pred=[1, 5, 9, 10, 18, 13, 7, 11, 20, 14, 19, 15, 6, 16, 4, 3] true=[12, 1, 5, 9, 10, 18, 13, 7, 2, 20, 14, 19, 15, 6, 16, 4, 3, 11, 17, 8] lev=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Eval] Id=12 pred=[8, 13, 10, 15, 12, 15, 17, 2, 16, 9, 20, 2, 4, 7, 5, 1, 19, 8] true=[8, 13, 10, 11, 12, 15, 17, 2, 16, 9, 20, 14, 4, 7, 5, 1, 19, 6, 3, 18] lev=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Eval] Id=13 pred=[15, 11, 19, 13, 4, 8, 6, 2, 13, 6, 1, 19, 9, 18, 16, 18, 3] true=[15, 11, 19, 7, 5, 14, 4, 8, 6, 17, 2, 20, 13, 1, 10, 9, 12, 16, 18, 3] lev=8\n[Eval] Val mean Levenshtein=6.0, normalized=0.3\n[Smoke] Completed.\n"
          ]
        }
      ]
    },
    {
      "id": "dcfd115c-9007-4f35-9d08-2a0c3df126fb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 6) Improved FE v2 (hip-center + shoulder-width scaling + distances/speeds/angles) and smoke re-run\n",
        "import numpy as np, time, xgboost as xgb, re\n",
        "\n",
        "# Kinect-20 indices\n",
        "HIP=0; SPINE=1; SHOULDER_CENTER=2; HEAD=3; L_SHOULDER=4; L_ELBOW=5; L_WRIST=6; L_HAND=7; R_SHOULDER=8; R_ELBOW=9; R_WRIST=10; R_HAND=11\n",
        "\n",
        "def safe_norm(v):\n",
        "    return float(np.linalg.norm(v)) if v is not None else 0.0\n",
        "\n",
        "def features_from_skeleton_v2(skel):\n",
        "    # skel: (T,J,3)\n",
        "    T, J, _ = skel.shape\n",
        "    base_dim = J*3*2\n",
        "    extra_dim = 13  # 7 distances + 4 speeds + 2 elbow angles\n",
        "    feats = np.zeros((T, base_dim + extra_dim), dtype=np.float32)\n",
        "    prev_centered = None\n",
        "    for t in range(T):\n",
        "        coords = skel[t].astype(np.float32)\n",
        "        # center by hip\n",
        "        hip = coords[HIP]\n",
        "        centered = coords - hip\n",
        "        # scale by shoulder width\n",
        "        shw = np.linalg.norm(centered[R_SHOULDER] - centered[L_SHOULDER])\n",
        "        scale = max(shw, 1e-3)\n",
        "        centered /= scale\n",
        "        # velocities on normalized coords\n",
        "        if prev_centered is None:\n",
        "            vel = np.zeros_like(centered)\n",
        "        else:\n",
        "            vel = centered - prev_centered\n",
        "        prev_centered = centered\n",
        "        # base features\n",
        "        feats[t, :J*3] = centered.reshape(-1)\n",
        "        feats[t, J*3:J*3*2] = vel.reshape(-1)\n",
        "        # extra distances\n",
        "        d_hl_hd = np.linalg.norm(centered[L_HAND] - centered[HEAD])\n",
        "        d_hr_hd = np.linalg.norm(centered[R_HAND] - centered[HEAD])\n",
        "        d_hl_hip = np.linalg.norm(centered[L_HAND] - centered[HIP])\n",
        "        d_hr_hip = np.linalg.norm(centered[R_HAND] - centered[HIP])\n",
        "        d_hl_hr = np.linalg.norm(centered[L_HAND] - centered[R_HAND])\n",
        "        d_hl_sc = np.linalg.norm(centered[L_HAND] - centered[SHOULDER_CENTER])\n",
        "        d_hr_sc = np.linalg.norm(centered[R_HAND] - centered[SHOULDER_CENTER])\n",
        "        # wrist/hand speeds (use vel)\n",
        "        s_wl = np.linalg.norm(vel[L_WRIST])\n",
        "        s_wr = np.linalg.norm(vel[R_WRIST])\n",
        "        s_hl = np.linalg.norm(vel[L_HAND])\n",
        "        s_hr = np.linalg.norm(vel[R_HAND])\n",
        "        # elbow flexion cosines\n",
        "        def elbow_cos(l_sh, l_el, l_wr):\n",
        "            u = centered[l_sh] - centered[l_el]\n",
        "            v = centered[l_wr] - centered[l_el]\n",
        "            nu = np.linalg.norm(u); nv = np.linalg.norm(v)\n",
        "            if nu < 1e-6 or nv < 1e-6: return 1.0\n",
        "            return float(np.dot(u, v) / (nu*nv))\n",
        "        cos_el = elbow_cos(L_SHOULDER, L_ELBOW, L_WRIST)\n",
        "        cos_er = elbow_cos(R_SHOULDER, R_ELBOW, R_WRIST)\n",
        "        extras = np.array([d_hl_hd, d_hr_hd, d_hl_hip, d_hr_hip, d_hl_hr, d_hl_sc, d_hr_sc, s_wl, s_wr, s_hl, s_hr, cos_el, cos_er], dtype=np.float32)\n",
        "        feats[t, base_dim:] = extras\n",
        "    return feats\n",
        "\n",
        "def build_frame_dataset_with_fe(sample_ids, name_to_id_map, fe_fn):\n",
        "    X_list, y_list, gid = [], [], []\n",
        "    t0 = time.time()\n",
        "    for idx, sid in enumerate(sample_ids):\n",
        "        skel, y, vid = load_skeleton_and_frame_targets(sid, name_to_id_map)\n",
        "        X = fe_fn(skel)\n",
        "        X_list.append(X)\n",
        "        y_list.append(y.astype(np.int32))\n",
        "        gid.extend([sid]*len(y))\n",
        "        if (idx+1) % 2 == 0:\n",
        "            print(f\"[BuildV2] {idx+1}/{len(sample_ids)} ids, cum frames={sum(x.shape[0] for x in X_list)}\")\n",
        "    X = np.vstack(X_list)\n",
        "    y = np.concatenate(y_list)\n",
        "    gid = np.array(gid, dtype=np.int32)\n",
        "    print(f\"[BuildV2] Done in {time.time()-t0:.1f}s. X={X.shape} y={y.shape} groups={len(np.unique(gid))}\")\n",
        "    return X, y, gid\n",
        "\n",
        "# Re-run smoke with FE v2\n",
        "smoke_ids = cand[:12] if len(cand) >= 12 else sorted(list(train_ids_set))[:12]\n",
        "train_ids_smoke = smoke_ids[:9]\n",
        "val_ids_smoke = smoke_ids[9:12]\n",
        "print('[SmokeV2] train ids:', train_ids_smoke)\n",
        "print('[SmokeV2] val ids:', val_ids_smoke)\n",
        "\n",
        "X_tr, y_tr, gid_tr = build_frame_dataset_with_fe(train_ids_smoke, name_to_id, features_from_skeleton_v2)\n",
        "X_va, y_va, gid_va = build_frame_dataset_with_fe(val_ids_smoke, name_to_id, features_from_skeleton_v2)\n",
        "\n",
        "def make_weights(y):\n",
        "    w = np.ones_like(y, dtype=np.float32); w[y==0] = 0.4; return w\n",
        "dtr = xgb.DMatrix(X_tr, label=y_tr, weight=make_weights(y_tr))\n",
        "dva = xgb.DMatrix(X_va, label=y_va, weight=make_weights(y_va))\n",
        "\n",
        "params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': 21,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'predictor': 'gpu_predictor',\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.09,\n",
        "    'subsample': 0.85,\n",
        "    'colsample_bytree': 0.85,\n",
        "    'min_child_weight': 3.0,\n",
        "    'lambda': 1.0\n",
        "}\n",
        "print('[XGB-V2] Training...')\n",
        "bst2 = xgb.train(params, dtr, num_boost_round=1000, evals=[(dtr,'train'),(dva,'valid')], early_stopping_rounds=150, verbose_eval=100)\n",
        "print('[XGB-V2] Best iters:', bst2.best_iteration)\n",
        "\n",
        "def predict_probs_for_id_v2(sample_id:int):\n",
        "    skel, y, vid = load_skeleton_and_frame_targets(sample_id, name_to_id)\n",
        "    X = features_from_skeleton_v2(skel)\n",
        "    dm = xgb.DMatrix(X)\n",
        "    P = bst2.predict(dm, iteration_range=(0, bst2.best_iteration+1))\n",
        "    return P, y, vid\n",
        "\n",
        "def true_sequence_for_id(sample_id:int) -> list:\n",
        "    row = train_df.loc[train_df.Id==sample_id]\n",
        "    if row.empty: return []\n",
        "    return [int(x) for x in re.findall(r'\\d+', str(row['Sequence'].values[0]))]\n",
        "\n",
        "scores2 = []\n",
        "for sid in val_ids_smoke:\n",
        "    P, y_frames, vid = predict_probs_for_id_v2(sid)\n",
        "    pred_seq = decode_sequence(P, window=7, merge_gap=4, min_len=6, mean_thr=0.45, max_thr=0.6)\n",
        "    true_seq = true_sequence_for_id(sid)\n",
        "    lev = levenshtein(pred_seq, true_seq)\n",
        "    scores2.append((sid, lev, len(true_seq)))\n",
        "    print(f\"[EvalV2] Id={sid} pred={pred_seq} true={true_seq} lev={lev}\")\n",
        "mean_lev2 = float(np.mean([s[1] for s in scores2])) if scores2 else None\n",
        "mean_norm2 = float(np.mean([s[1]/max(1,s[2]) for s in scores2])) if scores2 else None\n",
        "print(f\"[EvalV2] Val mean Levenshtein={mean_lev2}, normalized={mean_norm2}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SmokeV2] train ids: [1, 3, 4, 5, 6, 7, 8, 9, 10]\n[SmokeV2] val ids: [11, 12, 13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BuildV2] 2/9 ids, cum frames=2371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BuildV2] 4/9 ids, cum frames=5041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BuildV2] 6/9 ids, cum frames=7367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BuildV2] 8/9 ids, cum frames=9778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BuildV2] Done in 54.1s. X=(11004, 133) y=(11004,) groups=9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BuildV2] 2/3 ids, cum frames=2325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BuildV2] Done in 19.1s. X=(3540, 133) y=(3540,) groups=3\n[XGB-V2] Training...\n[0]\ttrain-mlogloss:2.58967\tvalid-mlogloss:2.88787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\ttrain-mlogloss:0.02793\tvalid-mlogloss:2.34711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttrain-mlogloss:0.01375\tvalid-mlogloss:2.41936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[204]\ttrain-mlogloss:0.01357\tvalid-mlogloss:2.42058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V2] Best iters: 54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EvalV2] Id=11 pred=[11, 5, 9, 18, 13, 7, 2, 11, 20, 15, 20, 4, 3] true=[12, 1, 5, 9, 10, 18, 13, 7, 2, 20, 14, 19, 15, 6, 16, 4, 3, 11, 17, 8] lev=11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EvalV2] Id=12 pred=[8, 12, 15, 17, 9, 2, 4, 7, 5, 1, 11] true=[8, 13, 10, 11, 12, 15, 17, 2, 16, 9, 20, 14, 4, 7, 5, 1, 19, 6, 3, 18] lev=11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EvalV2] Id=13 pred=[15, 11, 19, 6, 15, 4, 8, 20, 13, 9, 20, 16, 18, 3] true=[15, 11, 19, 7, 5, 14, 4, 8, 6, 17, 2, 20, 13, 1, 10, 9, 12, 16, 18, 3] lev=9\n[EvalV2] Val mean Levenshtein=10.333333333333334, normalized=0.5166666666666667\n"
          ]
        }
      ]
    },
    {
      "id": "2ce640d0-e2bc-4e8a-888e-15a9cd036475",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 7) Full train on training1-3 with FE v1, evaluate on validation1-3 (defaults), then prepare for grid tuning\n",
        "import numpy as np, pandas as pd, time, tarfile, zipfile, io, xgboost as xgb, re\n",
        "\n",
        "# Use FE v1 (performed better in smoke)\n",
        "\n",
        "def list_all_ids_from_tars(tar_paths):\n",
        "    ids = []\n",
        "    for p in tar_paths:\n",
        "        with tarfile.open(p, 'r:gz') as tf:\n",
        "            for m in tf.getmembers():\n",
        "                if m.name.lower().endswith('.zip'):\n",
        "                    m2 = re.findall(r'(\\d{5})', m.name)\n",
        "                    if m2:\n",
        "                        ids.append(int(m2[0]))\n",
        "    return sorted(ids)\n",
        "\n",
        "def load_vid_for_id(sample_id:int, tar_paths=None):\n",
        "    # auto-detect tar based on id\n",
        "    tar, zipname = id_to_tar_and_zipname(sample_id)\n",
        "    with tarfile.open(tar, 'r:gz') as tf:\n",
        "        mem = next(m for m in tf.getmembers() if m.name.endswith(zipname))\n",
        "        zbytes = tf.extractfile(mem).read()\n",
        "        with zipfile.ZipFile(io.BytesIO(zbytes)) as zf:\n",
        "            mat_name = next(n for n in zf.namelist() if n.lower().endswith('_data.mat'))\n",
        "            with zf.open(mat_name) as f:\n",
        "                d = sio.loadmat(f, simplify_cells=True)\n",
        "    return d['Video']\n",
        "\n",
        "def true_token_sequence_from_video(vid, name_to_id_map):\n",
        "    seq = []\n",
        "    for lab in vid['Labels']:\n",
        "        cid = name_to_id_map.get(lab['Name'])\n",
        "        if cid is not None:\n",
        "            seq.append(cid)\n",
        "    return seq\n",
        "\n",
        "print('[FullTrain] Building training frame dataset (this may take a few minutes)...')\n",
        "full_train_ids = train_df['Id'].tolist()\n",
        "X_tr, y_tr, gid_tr = build_frame_dataset(full_train_ids, name_to_id)\n",
        "print('[FullTrain] Dataset:', X_tr.shape, y_tr.shape)\n",
        "\n",
        "def make_weights(y):\n",
        "    w = np.ones_like(y, dtype=np.float32); w[y==0] = 0.4; return w\n",
        "dtr = xgb.DMatrix(X_tr, label=y_tr, weight=make_weights(y_tr))\n",
        "\n",
        "params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': 21,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'predictor': 'gpu_predictor',\n",
        "    'max_depth': 8,\n",
        "    'learning_rate': 0.09,\n",
        "    'subsample': 0.85,\n",
        "    'colsample_bytree': 0.85,\n",
        "    'min_child_weight': 3.0,\n",
        "    'lambda': 1.0,\n",
        "    'max_bin': 256\n",
        "}\n",
        "print('[FullTrain] Training XGBoost (no holdout; rely on validation set for tuning)...')\n",
        "t0 = time.time()\n",
        "bst_full = xgb.train(params, dtr, num_boost_round=900)\n",
        "print(f\"[FullTrain] Done in {time.time()-t0:.1f}s. Rounds=900\")\n",
        "\n",
        "print('[ValEval] Listing validation ids...')\n",
        "val_ids = list_all_ids_from_tars(['validation1.tar.gz','validation2.tar.gz','validation3.tar.gz'])\n",
        "print('[ValEval] Count:', len(val_ids), 'first 5:', val_ids[:5])\n",
        "\n",
        "def predict_and_decode_for_id(sample_id:int, model, window=7, merge_gap=4, min_len=6, mean_thr=0.45, max_thr=0.6):\n",
        "    skel, y_frames, vid = load_skeleton_and_frame_targets(sample_id, name_to_id)\n",
        "    X = features_from_skeleton(skel)\n",
        "    P = model.predict(xgb.DMatrix(X))\n",
        "    pred_seq = decode_sequence(P, window=window, merge_gap=merge_gap, min_len=min_len, mean_thr=mean_thr, max_thr=max_thr)\n",
        "    return pred_seq, vid\n",
        "\n",
        "print('[ValEval] Evaluating default decoder on validation set...')\n",
        "levs = []\n",
        "cnt = 0\n",
        "t0 = time.time()\n",
        "for sid in val_ids:\n",
        "    pred_seq, vid = predict_and_decode_for_id(sid, bst_full)\n",
        "    true_seq = true_token_sequence_from_video(vid, name_to_id)\n",
        "    lev = levenshtein(pred_seq, true_seq)\n",
        "    norm = lev / max(1, len(true_seq))\n",
        "    levs.append(norm)\n",
        "    cnt += 1\n",
        "    if cnt % 10 == 0:\n",
        "        print(f\"  [ValEval] {cnt}/{len(val_ids)} mean_norm={np.mean(levs):.3f}\")\n",
        "print(f\"[ValEval] Done {len(val_ids)} samples in {time.time()-t0:.1f}s. Mean normalized Levenshtein={np.mean(levs):.4f}\")\n",
        "\n",
        "print('[Next] If acceptable, grid search decoder params on validation set; then train on train+val and run test to create submission.csv.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FullTrain] Building training frame dataset (this may take a few minutes)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Build] 2/297 ids, cum frames=2371\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m[FullTrain] Building training frame dataset (this may take a few minutes)...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     38\u001b[39m full_train_ids = train_df[\u001b[33m'\u001b[39m\u001b[33mId\u001b[39m\u001b[33m'\u001b[39m].tolist()\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m X_tr, y_tr, gid_tr = \u001b[43mbuild_frame_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_train_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_to_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m[FullTrain] Dataset:\u001b[39m\u001b[33m'\u001b[39m, X_tr.shape, y_tr.shape)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_weights\u001b[39m(y):\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 130\u001b[39m, in \u001b[36mbuild_frame_dataset\u001b[39m\u001b[34m(sample_ids, name_to_id_map)\u001b[39m\n\u001b[32m    128\u001b[39m t0 = time.time()\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, sid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sample_ids):\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     skel, y, vid = \u001b[43mload_skeleton_and_frame_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_to_id_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m     X = features_from_skeleton(skel)\n\u001b[32m    132\u001b[39m     X_list.append(X)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36mload_skeleton_and_frame_targets\u001b[39m\u001b[34m(sample_id, name_to_id_map)\u001b[39m\n\u001b[32m     87\u001b[39m tar, zipname = id_to_tar_and_zipname(sample_id)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tarfile.open(tar, \u001b[33m'\u001b[39m\u001b[33mr:gz\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tf:\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     mem = \u001b[38;5;28mnext\u001b[39m(m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetmembers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m m.name.endswith(zipname))\n\u001b[32m     90\u001b[39m     zbytes = tf.extractfile(mem).read()\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m zipfile.ZipFile(io.BytesIO(zbytes)) \u001b[38;5;28;01mas\u001b[39;00m zf:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:1822\u001b[39m, in \u001b[36mTarFile.getmembers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1820\u001b[39m \u001b[38;5;28mself\u001b[39m._check()\n\u001b[32m   1821\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._loaded:    \u001b[38;5;66;03m# if we want to obtain a list of\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1822\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m        \u001b[38;5;66;03m# all members, we first have to\u001b[39;00m\n\u001b[32m   1823\u001b[39m                         \u001b[38;5;66;03m# scan the whole archive.\u001b[39;00m\n\u001b[32m   1824\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.members\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:2420\u001b[39m, in \u001b[36mTarFile._load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2416\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Read through the entire archive file and look for readable\u001b[39;00m\n\u001b[32m   2417\u001b[39m \u001b[33;03m   members.\u001b[39;00m\n\u001b[32m   2418\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2419\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2420\u001b[39m     tarinfo = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2421\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tarinfo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2422\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:2342\u001b[39m, in \u001b[36mTarFile.next\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2340\u001b[39m \u001b[38;5;66;03m# Advance the file pointer.\u001b[39;00m\n\u001b[32m   2341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.offset != \u001b[38;5;28mself\u001b[39m.fileobj.tell():\n\u001b[32m-> \u001b[39m\u001b[32m2342\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2343\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fileobj.read(\u001b[32m1\u001b[39m):\n\u001b[32m   2344\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ReadError(\u001b[33m\"\u001b[39m\u001b[33munexpected end of data\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/gzip.py:393\u001b[39m, in \u001b[36mGzipFile.seek\u001b[39m\u001b[34m(self, offset, whence)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == READ:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_not_closed()\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer.seek(offset, whence)\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.offset\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/_compression.py:153\u001b[39m, in \u001b[36mDecompressReader.seek\u001b[39m\u001b[34m(self, offset, whence)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# Read and discard data until we reach the desired position.\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m offset > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDEFAULT_BUFFER_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    155\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/gzip.py:507\u001b[39m, in \u001b[36m_GzipReader.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[32m    505\u001b[39m buf = \u001b[38;5;28mself\u001b[39m._fp.read(io.DEFAULT_BUFFER_SIZE)\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m uncompress = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decompressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decompressor.unconsumed_tail != \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    509\u001b[39m     \u001b[38;5;28mself\u001b[39m._fp.prepend(\u001b[38;5;28mself\u001b[39m._decompressor.unconsumed_tail)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "d4ada170-eb22-4d8a-ba3c-28125292e13d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 8) Caching pipeline: per-sample feature NPZ to ./cache with downsampling\n",
        "import os, re, tarfile, zipfile, io, time, numpy as np\n",
        "\n",
        "CACHE_DIR = './cache'\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "def split_and_tar_for_id(sample_id:int, split_hint:str='train'):\n",
        "    # Determine tar path based on id and split\n",
        "    if split_hint == 'train':\n",
        "        if sample_id < 100: return 'train', 'training1.tar.gz'\n",
        "        elif sample_id < 200: return 'train', 'training2.tar.gz'\n",
        "        else: return 'train', 'training3.tar.gz'\n",
        "    elif split_hint == 'val':\n",
        "        # Observed ranges from listing: 00410.., 00510.., 00621..\n",
        "        if sample_id < 500: return 'val', 'validation1.tar.gz'\n",
        "        elif sample_id < 621: return 'val', 'validation2.tar.gz'\n",
        "        else: return 'val', 'validation3.tar.gz'\n",
        "    elif split_hint == 'test':\n",
        "        return 'test', 'test.tar.gz'\n",
        "    else:\n",
        "        raise ValueError('Unknown split_hint')\n",
        "\n",
        "def get_zip_member(tf: tarfile.TarFile, sample_id:int):\n",
        "    # Try fast path with exact names, then fallback to search\n",
        "    candidates = [f'./Sample{sample_id:05d}.zip', f'Sample{sample_id:05d}.zip']\n",
        "    for nm in candidates:\n",
        "        try:\n",
        "            return tf.getmember(nm)\n",
        "        except KeyError:\n",
        "            pass\n",
        "    # fallback search once\n",
        "    for m in tf.getmembers():\n",
        "        if m.name.endswith(f'Sample{sample_id:05d}.zip'):\n",
        "            return m\n",
        "    raise FileNotFoundError(f'Sample zip for id {sample_id} not found in tar')\n",
        "\n",
        "def load_video_from_split(sample_id:int, split_hint:str):\n",
        "    _, tar_path = split_and_tar_for_id(sample_id, split_hint)\n",
        "    with tarfile.open(tar_path, 'r:gz') as tf:\n",
        "        mem = get_zip_member(tf, sample_id)\n",
        "        zbytes = tf.extractfile(mem).read()\n",
        "        with zipfile.ZipFile(io.BytesIO(zbytes)) as zf:\n",
        "            mat_name = next(n for n in zf.namelist() if n.lower().endswith('_data.mat'))\n",
        "            with zf.open(mat_name) as f:\n",
        "                d = sio.loadmat(f, simplify_cells=True)\n",
        "    return d['Video']\n",
        "\n",
        "def stack_world_positions(vid, stride:int=1):\n",
        "    T = int(vid['NumFrames']); frames = vid['Frames']\n",
        "    J = frames[0]['Skeleton']['WorldPosition'].shape[0]\n",
        "    idxs = list(range(0, T, stride))\n",
        "    skel = np.zeros((len(idxs), J, 3), dtype=np.float32)\n",
        "    ti = 0\n",
        "    last = None\n",
        "    for t in idxs:\n",
        "        wp = frames[t]['Skeleton']['WorldPosition']\n",
        "        arr = np.asarray(wp, dtype=np.float32) if wp is not None else last\n",
        "        if arr is None:\n",
        "            arr = np.zeros((J,3), dtype=np.float32)\n",
        "        skel[ti] = arr; last = arr; ti += 1\n",
        "    return skel, idxs\n",
        "\n",
        "def true_token_sequence_from_video(vid, name_to_id_map):\n",
        "    seq = []\n",
        "    for lab in vid['Labels']:\n",
        "        cid = name_to_id_map.get(lab['Name'])\n",
        "        if cid is not None: seq.append(cid)\n",
        "    return seq\n",
        "\n",
        "def cache_sample(sample_id:int, split_hint:str, name_to_id_map:dict, stride:int=2, use_fe_v2:bool=False):\n",
        "    out_path = os.path.join(CACHE_DIR, f'{split_hint}_{sample_id:05d}.npz')\n",
        "    if os.path.exists(out_path):\n",
        "        return out_path\n",
        "    t0 = time.time()\n",
        "    vid = load_video_from_split(sample_id, split_hint)\n",
        "    skel, idxs = stack_world_positions(vid, stride=stride)\n",
        "    if use_fe_v2:\n",
        "        X = features_from_skeleton_v2(skel)\n",
        "    else:\n",
        "        X = features_from_skeleton(skel)\n",
        "    # frame labels y at downsampled indices (0 background)\n",
        "    T_full = int(vid['NumFrames'])\n",
        "    y_full = np.zeros(T_full, dtype=np.int16)\n",
        "    if split_hint in ('train','val'):\n",
        "        for lab in vid['Labels']:\n",
        "            cid = name_to_id_map.get(lab['Name'])\n",
        "            if cid is None: continue\n",
        "            b = max(0, int(lab['Begin'])-1); e = min(T_full, int(lab['End']))\n",
        "            y_full[b:e] = cid\n",
        "    y_ds = np.array([y_full[t] for t in idxs], dtype=np.int16)\n",
        "    true_seq = true_token_sequence_from_video(vid, name_to_id_map) if split_hint in ('train','val') else []\n",
        "    fps = int(vid.get('FrameRate', 20))\n",
        "    np.savez_compressed(out_path, X=X, y=y_ds, seq=np.array(true_seq, dtype=np.int16), fps=fps, stride=stride)\n",
        "    print(f\"[Cache] {split_hint} id={sample_id} -> {out_path} X={X.shape} saved in {time.time()-t0:.1f}s\")\n",
        "    return out_path\n",
        "\n",
        "def list_ids_in_tar_fast(tar_path):\n",
        "    ids = []\n",
        "    with tarfile.open(tar_path, 'r:gz') as tf:\n",
        "        for m in tf.getmembers():\n",
        "            if m.name.lower().endswith('.zip'):\n",
        "                m2 = re.findall(r'(\\d{5})', m.name)\n",
        "                if m2: ids.append(int(m2[0]))\n",
        "    return sorted(ids)\n",
        "\n",
        "def cache_split_ids(split_hint:str, ids:list, stride:int=2, use_fe_v2:bool=False, limit:int=None):\n",
        "    t0 = time.time()\n",
        "    done = 0\n",
        "    for i, sid in enumerate(ids[:limit] if limit else ids):\n",
        "        cache_sample(sid, split_hint, name_to_id, stride=stride, use_fe_v2=use_fe_v2)\n",
        "        done += 1\n",
        "        if done % 10 == 0:\n",
        "            print(f\"[CacheProgress] {split_hint}: {done}/{len(ids if not limit else ids[:limit])} cached; elapsed {time.time()-t0:.1f}s\")\n",
        "    print(f\"[CacheDone] {split_hint}: cached {done} samples in {time.time()-t0:.1f}s\")\n",
        "\n",
        "print('[Cache] Ready. Next: cache training (297 ids) and validation (~287 ids) with stride=2 to speed up training/eval.')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] Ready. Next: cache training (297 ids) and validation (~287 ids) with stride=2 to speed up training/eval.\n"
          ]
        }
      ]
    },
    {
      "id": "777d5c80-3c5c-40d8-bd38-880cec19670c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 9) Cache train and validation splits (stride=2) for fast training/eval\n",
        "import time\n",
        "\n",
        "print('[CacheRun] Collecting ids...')\n",
        "train_ids_all = train_df['Id'].tolist()\n",
        "val_ids_all = list_ids_in_tar_fast('validation1.tar.gz') + list_ids_in_tar_fast('validation2.tar.gz') + list_ids_in_tar_fast('validation3.tar.gz')\n",
        "print('[CacheRun] Train ids:', len(train_ids_all), 'Val ids:', len(val_ids_all))\n",
        "\n",
        "t0 = time.time()\n",
        "print('[CacheRun] Caching TRAIN (stride=2)...')\n",
        "cache_split_ids('train', train_ids_all, stride=2, use_fe_v2=False)\n",
        "print('[CacheRun] Caching VAL (stride=2)...')\n",
        "cache_split_ids('val', val_ids_all, stride=2, use_fe_v2=False)\n",
        "print(f\"[CacheRun] All caching done in {time.time()-t0:.1f}s. Cache dir: {CACHE_DIR}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheRun] Collecting ids...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheRun] Train ids: 297 Val ids: 287\n[CacheRun] Caching TRAIN (stride=2)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=1 -> ./cache/train_00001.npz X=(627, 120) saved in 5.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=3 -> ./cache/train_00003.npz X=(559, 120) saved in 5.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=4 -> ./cache/train_00004.npz X=(668, 120) saved in 6.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=5 -> ./cache/train_00005.npz X=(667, 120) saved in 6.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=6 -> ./cache/train_00006.npz X=(601, 120) saved in 6.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=7 -> ./cache/train_00007.npz X=(562, 120) saved in 6.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=8 -> ./cache/train_00008.npz X=(596, 120) saved in 6.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=9 -> ./cache/train_00009.npz X=(610, 120) saved in 6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=10 -> ./cache/train_00010.npz X=(613, 120) saved in 6.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=11 -> ./cache/train_00011.npz X=(571, 120) saved in 6.3s\n[CacheProgress] train: 10/297 cached; elapsed 60.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=12 -> ./cache/train_00012.npz X=(592, 120) saved in 6.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=13 -> ./cache/train_00013.npz X=(608, 120) saved in 6.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=14 -> ./cache/train_00014.npz X=(623, 120) saved in 6.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=15 -> ./cache/train_00015.npz X=(650, 120) saved in 6.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=16 -> ./cache/train_00016.npz X=(585, 120) saved in 6.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=17 -> ./cache/train_00017.npz X=(584, 120) saved in 6.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=18 -> ./cache/train_00018.npz X=(593, 120) saved in 6.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=19 -> ./cache/train_00019.npz X=(605, 120) saved in 6.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=20 -> ./cache/train_00020.npz X=(589, 120) saved in 6.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=21 -> ./cache/train_00021.npz X=(552, 120) saved in 6.8s\n[CacheProgress] train: 20/297 cached; elapsed 126.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=22 -> ./cache/train_00022.npz X=(787, 120) saved in 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=23 -> ./cache/train_00023.npz X=(741, 120) saved in 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=24 -> ./cache/train_00024.npz X=(745, 120) saved in 7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=25 -> ./cache/train_00025.npz X=(591, 120) saved in 7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=26 -> ./cache/train_00026.npz X=(560, 120) saved in 7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=27 -> ./cache/train_00027.npz X=(596, 120) saved in 7.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=28 -> ./cache/train_00028.npz X=(637, 120) saved in 7.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=29 -> ./cache/train_00029.npz X=(578, 120) saved in 7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=30 -> ./cache/train_00030.npz X=(632, 120) saved in 7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=31 -> ./cache/train_00031.npz X=(668, 120) saved in 7.3s\n[CacheProgress] train: 30/297 cached; elapsed 197.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=32 -> ./cache/train_00032.npz X=(646, 120) saved in 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=33 -> ./cache/train_00033.npz X=(601, 120) saved in 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=34 -> ./cache/train_00034.npz X=(612, 120) saved in 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=35 -> ./cache/train_00035.npz X=(670, 120) saved in 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=36 -> ./cache/train_00036.npz X=(599, 120) saved in 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=37 -> ./cache/train_00037.npz X=(627, 120) saved in 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=38 -> ./cache/train_00038.npz X=(573, 120) saved in 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=39 -> ./cache/train_00039.npz X=(562, 120) saved in 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=40 -> ./cache/train_00040.npz X=(549, 120) saved in 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=41 -> ./cache/train_00041.npz X=(916, 120) saved in 8.0s\n[CacheProgress] train: 40/297 cached; elapsed 272.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=42 -> ./cache/train_00042.npz X=(816, 120) saved in 7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=43 -> ./cache/train_00043.npz X=(833, 120) saved in 8.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=44 -> ./cache/train_00044.npz X=(768, 120) saved in 8.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=45 -> ./cache/train_00045.npz X=(853, 120) saved in 8.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=46 -> ./cache/train_00046.npz X=(824, 120) saved in 8.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=47 -> ./cache/train_00047.npz X=(834, 120) saved in 8.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=48 -> ./cache/train_00048.npz X=(823, 120) saved in 8.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=49 -> ./cache/train_00049.npz X=(844, 120) saved in 8.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=50 -> ./cache/train_00050.npz X=(804, 120) saved in 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=51 -> ./cache/train_00051.npz X=(841, 120) saved in 8.7s\n[CacheProgress] train: 50/297 cached; elapsed 356.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=52 -> ./cache/train_00052.npz X=(781, 120) saved in 8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=53 -> ./cache/train_00053.npz X=(873, 120) saved in 8.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=54 -> ./cache/train_00054.npz X=(804, 120) saved in 9.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=55 -> ./cache/train_00055.npz X=(844, 120) saved in 9.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=56 -> ./cache/train_00056.npz X=(773, 120) saved in 9.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=57 -> ./cache/train_00057.npz X=(646, 120) saved in 9.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=58 -> ./cache/train_00058.npz X=(636, 120) saved in 9.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=59 -> ./cache/train_00059.npz X=(613, 120) saved in 9.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=60 -> ./cache/train_00060.npz X=(663, 120) saved in 9.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=61 -> ./cache/train_00061.npz X=(655, 120) saved in 9.4s\n[CacheProgress] train: 60/297 cached; elapsed 447.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=62 -> ./cache/train_00062.npz X=(653, 120) saved in 9.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=63 -> ./cache/train_00063.npz X=(646, 120) saved in 9.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=64 -> ./cache/train_00064.npz X=(644, 120) saved in 9.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=65 -> ./cache/train_00065.npz X=(617, 120) saved in 9.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=66 -> ./cache/train_00066.npz X=(629, 120) saved in 9.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=67 -> ./cache/train_00067.npz X=(564, 120) saved in 9.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=68 -> ./cache/train_00068.npz X=(565, 120) saved in 9.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=69 -> ./cache/train_00069.npz X=(590, 120) saved in 9.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=70 -> ./cache/train_00070.npz X=(668, 120) saved in 10.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=71 -> ./cache/train_00071.npz X=(830, 120) saved in 10.1s\n[CacheProgress] train: 70/297 cached; elapsed 545.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=72 -> ./cache/train_00072.npz X=(810, 120) saved in 10.2s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m t0 = time.time()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m[CacheRun] Caching TRAIN (stride=2)...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mcache_split_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ids_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fe_v2\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m[CacheRun] Caching VAL (stride=2)...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m cache_split_ids(\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m, val_ids_all, stride=\u001b[32m2\u001b[39m, use_fe_v2=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 110\u001b[39m, in \u001b[36mcache_split_ids\u001b[39m\u001b[34m(split_hint, ids, stride, use_fe_v2, limit)\u001b[39m\n\u001b[32m    108\u001b[39m done = \u001b[32m0\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, sid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ids[:limit] \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;28;01melse\u001b[39;00m ids):\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[43mcache_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_to_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fe_v2\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_fe_v2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     done += \u001b[32m1\u001b[39m\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m done % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mcache_sample\u001b[39m\u001b[34m(sample_id, split_hint, name_to_id_map, stride, use_fe_v2)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out_path\n\u001b[32m     74\u001b[39m t0 = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m vid = \u001b[43mload_video_from_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_hint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m skel, idxs = stack_world_positions(vid, stride=stride)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_fe_v2:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mload_video_from_split\u001b[39m\u001b[34m(sample_id, split_hint)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tarfile.open(tar_path, \u001b[33m'\u001b[39m\u001b[33mr:gz\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tf:\n\u001b[32m     40\u001b[39m     mem = get_zip_member(tf, sample_id)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     zbytes = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextractfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m zipfile.ZipFile(io.BytesIO(zbytes)) \u001b[38;5;28;01mas\u001b[39;00m zf:\n\u001b[32m     43\u001b[39m         mat_name = \u001b[38;5;28mnext\u001b[39m(n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m zf.namelist() \u001b[38;5;28;01mif\u001b[39;00m n.lower().endswith(\u001b[33m'\u001b[39m\u001b[33m_data.mat\u001b[39m\u001b[33m'\u001b[39m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:684\u001b[39m, in \u001b[36m_FileInFile.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    682\u001b[39m length = \u001b[38;5;28mmin\u001b[39m(size, stop - \u001b[38;5;28mself\u001b[39m.position)\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mposition\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    685\u001b[39m     b = \u001b[38;5;28mself\u001b[39m.fileobj.read(length)\n\u001b[32m    686\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b) != length:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/gzip.py:393\u001b[39m, in \u001b[36mGzipFile.seek\u001b[39m\u001b[34m(self, offset, whence)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == READ:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_not_closed()\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer.seek(offset, whence)\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.offset\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/_compression.py:152\u001b[39m, in \u001b[36mDecompressReader.seek\u001b[39m\u001b[34m(self, offset, whence)\u001b[39m\n\u001b[32m    149\u001b[39m     offset -= \u001b[38;5;28mself\u001b[39m._pos\n\u001b[32m    151\u001b[39m \u001b[38;5;66;03m# Read and discard data until we reach the desired position.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m offset > \u001b[32m0\u001b[39m:\n\u001b[32m    153\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.read(\u001b[38;5;28mmin\u001b[39m(io.DEFAULT_BUFFER_SIZE, offset))\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "ef9ab736-54f6-420a-9750-1cce4cc01061",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 10) Parallel caching (resume) for TRAIN and VAL to speed up IO\n",
        "import os, time, concurrent.futures as cf\n",
        "\n",
        "def remaining_ids(split_hint, ids):\n",
        "    rem = []\n",
        "    for sid in ids:\n",
        "        out_path = os.path.join(CACHE_DIR, f'{split_hint}_{sid:05d}.npz')\n",
        "        if not os.path.exists(out_path):\n",
        "            rem.append(sid)\n",
        "    return rem\n",
        "\n",
        "def parallel_cache(split_hint, ids, max_workers=12, stride=2, use_fe_v2=False):\n",
        "    todo = remaining_ids(split_hint, ids)\n",
        "    print(f\"[ParCache] {split_hint}: {len(todo)}/{len(ids)} remaining to cache.\")\n",
        "    if not todo:\n",
        "        return\n",
        "    t0 = time.time()\n",
        "    done = 0\n",
        "    def task(sid):\n",
        "        try:\n",
        "            return cache_sample(sid, split_hint, name_to_id, stride=stride, use_fe_v2=use_fe_v2)\n",
        "        except Exception as e:\n",
        "            print(f\"[ParCache][ERR] {split_hint} id={sid}: {e}\")\n",
        "            return None\n",
        "    with cf.ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
        "        futures = [ex.submit(task, sid) for sid in todo]\n",
        "        for i, fut in enumerate(cf.as_completed(futures), 1):\n",
        "            _ = fut.result()\n",
        "            done += 1\n",
        "            if done % 20 == 0:\n",
        "                print(f\"[ParCache] {split_hint}: {done}/{len(todo)} done; elapsed {time.time()-t0:.1f}s\")\n",
        "    print(f\"[ParCache] {split_hint}: completed {done} files in {time.time()-t0:.1f}s\")\n",
        "\n",
        "print('[ParCache] Preparing id lists...')\n",
        "train_ids_all = train_df['Id'].tolist()\n",
        "val_ids_all = list_ids_in_tar_fast('validation1.tar.gz') + list_ids_in_tar_fast('validation2.tar.gz') + list_ids_in_tar_fast('validation3.tar.gz')\n",
        "print('[ParCache] Train ids:', len(train_ids_all), 'Val ids:', len(val_ids_all))\n",
        "\n",
        "print('[ParCache] Starting parallel TRAIN cache (stride=2)...')\n",
        "parallel_cache('train', train_ids_all, max_workers=12, stride=2, use_fe_v2=False)\n",
        "print('[ParCache] Starting parallel VAL cache (stride=2)...')\n",
        "parallel_cache('val', val_ids_all, max_workers=12, stride=2, use_fe_v2=False)\n",
        "print('[ParCache] Done.')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache] Preparing id lists...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache] Train ids: 297 Val ids: 287\n[ParCache] Starting parallel TRAIN cache (stride=2)...\n[ParCache] train: 226/297 remaining to cache.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=73 -> ./cache/train_00073.npz X=(791, 120) saved in 494.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=74 -> ./cache/train_00074.npz X=(805, 120) saved in 499.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=78 -> ./cache/train_00078.npz X=(817, 120) saved in 502.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=75 -> ./cache/train_00075.npz X=(810, 120) saved in 502.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=76 -> ./cache/train_00076.npz X=(745, 120) saved in 508.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=77 -> ./cache/train_00077.npz X=(823, 120) saved in 511.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=79 -> ./cache/train_00079.npz X=(836, 120) saved in 522.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=80 -> ./cache/train_00080.npz X=(858, 120) saved in 525.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=81 -> ./cache/train_00081.npz X=(643, 120) saved in 527.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=82 -> ./cache/train_00082.npz X=(685, 120) saved in 527.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=83 -> ./cache/train_00083.npz X=(587, 120) saved in 530.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=84 -> ./cache/train_00084.npz X=(717, 120) saved in 533.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=85 -> ./cache/train_00085.npz X=(522, 120) saved in 529.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=86 -> ./cache/train_00086.npz X=(643, 120) saved in 532.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=88 -> ./cache/train_00088.npz X=(623, 120) saved in 534.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=87 -> ./cache/train_00087.npz X=(661, 120) saved in 535.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=89 -> ./cache/train_00089.npz X=(605, 120) saved in 537.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=90 -> ./cache/train_00090.npz X=(601, 120) saved in 538.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=91 -> ./cache/train_00091.npz X=(653, 120) saved in 538.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=92 -> ./cache/train_00092.npz X=(599, 120) saved in 539.5s\n[ParCache] train: 20/226 done; elapsed 1064.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=93 -> ./cache/train_00093.npz X=(586, 120) saved in 541.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=94 -> ./cache/train_00094.npz X=(641, 120) saved in 545.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=95 -> ./cache/train_00095.npz X=(687, 120) saved in 544.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=96 -> ./cache/train_00096.npz X=(541, 120) saved in 546.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=101 -> ./cache/train_00101.npz X=(643, 120) saved in 113.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=102 -> ./cache/train_00102.npz X=(640, 120) saved in 114.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=103 -> ./cache/train_00103.npz X=(578, 120) saved in 115.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=104 -> ./cache/train_00104.npz X=(644, 120) saved in 115.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=105 -> ./cache/train_00105.npz X=(632, 120) saved in 117.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=106 -> ./cache/train_00106.npz X=(586, 120) saved in 118.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=107 -> ./cache/train_00107.npz X=(643, 120) saved in 119.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=108 -> ./cache/train_00108.npz X=(630, 120) saved in 120.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=109 -> ./cache/train_00109.npz X=(627, 120) saved in 122.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=110 -> ./cache/train_00110.npz X=(647, 120) saved in 121.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=111 -> ./cache/train_00111.npz X=(660, 120) saved in 124.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=112 -> ./cache/train_00112.npz X=(632, 120) saved in 124.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=113 -> ./cache/train_00113.npz X=(621, 120) saved in 126.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=114 -> ./cache/train_00114.npz X=(652, 120) saved in 128.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=115 -> ./cache/train_00115.npz X=(583, 120) saved in 128.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=116 -> ./cache/train_00116.npz X=(560, 120) saved in 129.7s\n[ParCache] train: 40/226 done; elapsed 1322.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=117 -> ./cache/train_00117.npz X=(619, 120) saved in 130.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=118 -> ./cache/train_00118.npz X=(625, 120) saved in 130.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=119 -> ./cache/train_00119.npz X=(643, 120) saved in 132.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=120 -> ./cache/train_00120.npz X=(610, 120) saved in 136.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=121 -> ./cache/train_00121.npz X=(574, 120) saved in 134.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=122 -> ./cache/train_00122.npz X=(582, 120) saved in 135.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=123 -> ./cache/train_00123.npz X=(666, 120) saved in 138.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=124 -> ./cache/train_00124.npz X=(651, 120) saved in 137.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=125 -> ./cache/train_00125.npz X=(615, 120) saved in 139.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=126 -> ./cache/train_00126.npz X=(621, 120) saved in 140.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=127 -> ./cache/train_00127.npz X=(532, 120) saved in 141.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=128 -> ./cache/train_00128.npz X=(602, 120) saved in 141.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=129 -> ./cache/train_00129.npz X=(603, 120) saved in 143.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=130 -> ./cache/train_00130.npz X=(674, 120) saved in 145.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=97 -> ./cache/train_00097.npz X=(522, 120) saved in 553.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=131 -> ./cache/train_00131.npz X=(601, 120) saved in 146.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=98 -> ./cache/train_00098.npz X=(622, 120) saved in 558.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=99 -> ./cache/train_00099.npz X=(562, 120) saved in 558.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=132 -> ./cache/train_00132.npz X=(643, 120) saved in 148.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=133 -> ./cache/train_00133.npz X=(581, 120) saved in 148.0s\n[ParCache] train: 60/226 done; elapsed 1601.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=134 -> ./cache/train_00134.npz X=(638, 120) saved in 150.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=135 -> ./cache/train_00135.npz X=(606, 120) saved in 152.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=136 -> ./cache/train_00136.npz X=(637, 120) saved in 153.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=137 -> ./cache/train_00137.npz X=(663, 120) saved in 154.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=138 -> ./cache/train_00138.npz X=(672, 120) saved in 155.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=139 -> ./cache/train_00139.npz X=(671, 120) saved in 156.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=140 -> ./cache/train_00140.npz X=(592, 120) saved in 157.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=141 -> ./cache/train_00141.npz X=(591, 120) saved in 159.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=142 -> ./cache/train_00142.npz X=(584, 120) saved in 161.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=143 -> ./cache/train_00143.npz X=(613, 120) saved in 162.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=144 -> ./cache/train_00144.npz X=(507, 120) saved in 162.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=145 -> ./cache/train_00145.npz X=(630, 120) saved in 162.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=146 -> ./cache/train_00146.npz X=(605, 120) saved in 166.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=147 -> ./cache/train_00147.npz X=(603, 120) saved in 165.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=148 -> ./cache/train_00148.npz X=(552, 120) saved in 169.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=149 -> ./cache/train_00149.npz X=(609, 120) saved in 169.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=150 -> ./cache/train_00150.npz X=(577, 120) saved in 169.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=151 -> ./cache/train_00151.npz X=(602, 120) saved in 172.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=152 -> ./cache/train_00152.npz X=(601, 120) saved in 170.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=153 -> ./cache/train_00153.npz X=(598, 120) saved in 173.8s\n[ParCache] train: 80/226 done; elapsed 1918.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=154 -> ./cache/train_00154.npz X=(591, 120) saved in 173.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=156 -> ./cache/train_00156.npz X=(572, 120) saved in 175.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=155 -> ./cache/train_00155.npz X=(596, 120) saved in 178.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=157 -> ./cache/train_00157.npz X=(603, 120) saved in 177.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=158 -> ./cache/train_00158.npz X=(632, 120) saved in 180.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=159 -> ./cache/train_00159.npz X=(545, 120) saved in 179.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=160 -> ./cache/train_00160.npz X=(617, 120) saved in 180.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=161 -> ./cache/train_00161.npz X=(596, 120) saved in 182.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=162 -> ./cache/train_00162.npz X=(562, 120) saved in 183.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=163 -> ./cache/train_00163.npz X=(560, 120) saved in 184.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=164 -> ./cache/train_00164.npz X=(642, 120) saved in 189.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=165 -> ./cache/train_00165.npz X=(568, 120) saved in 186.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=166 -> ./cache/train_00166.npz X=(616, 120) saved in 187.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=167 -> ./cache/train_00167.npz X=(577, 120) saved in 188.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=168 -> ./cache/train_00168.npz X=(553, 120) saved in 191.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=169 -> ./cache/train_00169.npz X=(605, 120) saved in 189.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=170 -> ./cache/train_00170.npz X=(640, 120) saved in 193.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=171 -> ./cache/train_00171.npz X=(615, 120) saved in 191.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=172 -> ./cache/train_00172.npz X=(540, 120) saved in 194.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=173 -> ./cache/train_00173.npz X=(611, 120) saved in 193.6s\n[ParCache] train: 100/226 done; elapsed 2247.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=174 -> ./cache/train_00174.npz X=(565, 120) saved in 195.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=175 -> ./cache/train_00175.npz X=(566, 120) saved in 195.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=176 -> ./cache/train_00176.npz X=(670, 120) saved in 196.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=177 -> ./cache/train_00177.npz X=(670, 120) saved in 198.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=178 -> ./cache/train_00178.npz X=(616, 120) saved in 199.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=179 -> ./cache/train_00179.npz X=(522, 120) saved in 199.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=180 -> ./cache/train_00180.npz X=(647, 120) saved in 200.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=181 -> ./cache/train_00181.npz X=(577, 120) saved in 201.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=182 -> ./cache/train_00182.npz X=(611, 120) saved in 202.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=183 -> ./cache/train_00183.npz X=(650, 120) saved in 203.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=184 -> ./cache/train_00184.npz X=(627, 120) saved in 204.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=185 -> ./cache/train_00185.npz X=(637, 120) saved in 206.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=186 -> ./cache/train_00186.npz X=(549, 120) saved in 208.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=187 -> ./cache/train_00187.npz X=(598, 120) saved in 208.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=188 -> ./cache/train_00188.npz X=(564, 120) saved in 211.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=189 -> ./cache/train_00189.npz X=(581, 120) saved in 212.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=190 -> ./cache/train_00190.npz X=(690, 120) saved in 211.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=191 -> ./cache/train_00191.npz X=(655, 120) saved in 213.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=192 -> ./cache/train_00192.npz X=(607, 120) saved in 213.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=193 -> ./cache/train_00193.npz X=(590, 120) saved in 215.8s\n[ParCache] train: 120/226 done; elapsed 2548.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=194 -> ./cache/train_00194.npz X=(623, 120) saved in 216.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=195 -> ./cache/train_00195.npz X=(593, 120) saved in 216.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=196 -> ./cache/train_00196.npz X=(620, 120) saved in 218.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=200 -> ./cache/train_00200.npz X=(574, 120) saved in 148.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=201 -> ./cache/train_00201.npz X=(585, 120) saved in 148.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=202 -> ./cache/train_00202.npz X=(595, 120) saved in 147.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=197 -> ./cache/train_00197.npz X=(591, 120) saved in 220.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=203 -> ./cache/train_00203.npz X=(636, 120) saved in 150.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=204 -> ./cache/train_00204.npz X=(628, 120) saved in 152.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=198 -> ./cache/train_00198.npz X=(639, 120) saved in 221.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=205 -> ./cache/train_00205.npz X=(609, 120) saved in 153.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=199 -> ./cache/train_00199.npz X=(615, 120) saved in 224.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=206 -> ./cache/train_00206.npz X=(588, 120) saved in 153.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=207 -> ./cache/train_00207.npz X=(606, 120) saved in 156.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=208 -> ./cache/train_00208.npz X=(608, 120) saved in 157.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=209 -> ./cache/train_00209.npz X=(689, 120) saved in 157.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=210 -> ./cache/train_00210.npz X=(587, 120) saved in 159.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=211 -> ./cache/train_00211.npz X=(692, 120) saved in 163.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=212 -> ./cache/train_00212.npz X=(590, 120) saved in 162.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=213 -> ./cache/train_00213.npz X=(601, 120) saved in 164.1s\n[ParCache] train: 140/226 done; elapsed 2851.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=214 -> ./cache/train_00214.npz X=(585, 120) saved in 164.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=215 -> ./cache/train_00215.npz X=(613, 120) saved in 166.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=216 -> ./cache/train_00216.npz X=(618, 120) saved in 165.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=217 -> ./cache/train_00217.npz X=(606, 120) saved in 169.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=218 -> ./cache/train_00218.npz X=(548, 120) saved in 169.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=219 -> ./cache/train_00219.npz X=(617, 120) saved in 168.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=220 -> ./cache/train_00220.npz X=(573, 120) saved in 169.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=221 -> ./cache/train_00221.npz X=(595, 120) saved in 174.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=222 -> ./cache/train_00222.npz X=(627, 120) saved in 175.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=223 -> ./cache/train_00223.npz X=(565, 120) saved in 175.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=224 -> ./cache/train_00224.npz X=(567, 120) saved in 179.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=225 -> ./cache/train_00225.npz X=(524, 120) saved in 182.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=226 -> ./cache/train_00226.npz X=(563, 120) saved in 185.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=227 -> ./cache/train_00227.npz X=(616, 120) saved in 187.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=228 -> ./cache/train_00228.npz X=(573, 120) saved in 189.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=229 -> ./cache/train_00229.npz X=(640, 120) saved in 187.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=230 -> ./cache/train_00230.npz X=(606, 120) saved in 193.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=231 -> ./cache/train_00231.npz X=(622, 120) saved in 190.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=232 -> ./cache/train_00232.npz X=(647, 120) saved in 198.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=233 -> ./cache/train_00233.npz X=(684, 120) saved in 202.1s\n[ParCache] train: 160/226 done; elapsed 3185.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=234 -> ./cache/train_00234.npz X=(606, 120) saved in 204.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=235 -> ./cache/train_00235.npz X=(621, 120) saved in 207.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=236 -> ./cache/train_00236.npz X=(579, 120) saved in 208.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=237 -> ./cache/train_00237.npz X=(631, 120) saved in 211.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=238 -> ./cache/train_00238.npz X=(645, 120) saved in 213.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=239 -> ./cache/train_00239.npz X=(600, 120) saved in 214.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=240 -> ./cache/train_00240.npz X=(665, 120) saved in 216.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=241 -> ./cache/train_00241.npz X=(661, 120) saved in 221.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=242 -> ./cache/train_00242.npz X=(590, 120) saved in 221.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=243 -> ./cache/train_00243.npz X=(576, 120) saved in 224.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=244 -> ./cache/train_00244.npz X=(606, 120) saved in 223.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=245 -> ./cache/train_00245.npz X=(613, 120) saved in 224.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=246 -> ./cache/train_00246.npz X=(599, 120) saved in 230.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=247 -> ./cache/train_00247.npz X=(603, 120) saved in 226.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=248 -> ./cache/train_00248.npz X=(622, 120) saved in 229.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=249 -> ./cache/train_00249.npz X=(625, 120) saved in 228.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=250 -> ./cache/train_00250.npz X=(606, 120) saved in 232.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=251 -> ./cache/train_00251.npz X=(706, 120) saved in 234.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=252 -> ./cache/train_00252.npz X=(717, 120) saved in 234.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=253 -> ./cache/train_00253.npz X=(836, 120) saved in 234.3s\n[ParCache] train: 180/226 done; elapsed 3523.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=254 -> ./cache/train_00254.npz X=(616, 120) saved in 239.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=255 -> ./cache/train_00255.npz X=(620, 120) saved in 239.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=256 -> ./cache/train_00256.npz X=(619, 120) saved in 239.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=257 -> ./cache/train_00257.npz X=(545, 120) saved in 240.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=258 -> ./cache/train_00258.npz X=(549, 120) saved in 241.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=259 -> ./cache/train_00259.npz X=(584, 120) saved in 242.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=260 -> ./cache/train_00260.npz X=(587, 120) saved in 242.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=261 -> ./cache/train_00261.npz X=(585, 120) saved in 245.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=262 -> ./cache/train_00262.npz X=(660, 120) saved in 244.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=263 -> ./cache/train_00263.npz X=(604, 120) saved in 245.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=264 -> ./cache/train_00264.npz X=(605, 120) saved in 247.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=265 -> ./cache/train_00265.npz X=(647, 120) saved in 250.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=266 -> ./cache/train_00266.npz X=(603, 120) saved in 249.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=267 -> ./cache/train_00267.npz X=(690, 120) saved in 251.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=268 -> ./cache/train_00268.npz X=(645, 120) saved in 251.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=269 -> ./cache/train_00269.npz X=(606, 120) saved in 251.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=270 -> ./cache/train_00270.npz X=(616, 120) saved in 252.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=271 -> ./cache/train_00271.npz X=(530, 120) saved in 253.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=272 -> ./cache/train_00272.npz X=(716, 120) saved in 254.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=273 -> ./cache/train_00273.npz X=(808, 120) saved in 259.2s\n[ParCache] train: 200/226 done; elapsed 3978.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=274 -> ./cache/train_00274.npz X=(748, 120) saved in 257.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=275 -> ./cache/train_00275.npz X=(577, 120) saved in 261.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=276 -> ./cache/train_00276.npz X=(517, 120) saved in 260.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=277 -> ./cache/train_00277.npz X=(577, 120) saved in 266.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=278 -> ./cache/train_00278.npz X=(613, 120) saved in 263.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=279 -> ./cache/train_00279.npz X=(573, 120) saved in 266.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=280 -> ./cache/train_00280.npz X=(628, 120) saved in 267.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=281 -> ./cache/train_00281.npz X=(577, 120) saved in 267.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=282 -> ./cache/train_00282.npz X=(573, 120) saved in 271.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=283 -> ./cache/train_00283.npz X=(632, 120) saved in 271.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=284 -> ./cache/train_00284.npz X=(585, 120) saved in 272.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=285 -> ./cache/train_00285.npz X=(593, 120) saved in 274.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=286 -> ./cache/train_00286.npz X=(624, 120) saved in 275.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=287 -> ./cache/train_00287.npz X=(586, 120) saved in 275.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=288 -> ./cache/train_00288.npz X=(652, 120) saved in 276.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=289 -> ./cache/train_00289.npz X=(603, 120) saved in 277.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=290 -> ./cache/train_00290.npz X=(605, 120) saved in 276.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=291 -> ./cache/train_00291.npz X=(569, 120) saved in 274.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=292 -> ./cache/train_00292.npz X=(569, 120) saved in 266.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=293 -> ./cache/train_00293.npz X=(575, 120) saved in 244.7s\n[ParCache] train: 220/226 done; elapsed 4414.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=294 -> ./cache/train_00294.npz X=(549, 120) saved in 231.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=295 -> ./cache/train_00295.npz X=(610, 120) saved in 225.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=296 -> ./cache/train_00296.npz X=(581, 120) saved in 216.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=297 -> ./cache/train_00297.npz X=(530, 120) saved in 191.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=298 -> ./cache/train_00298.npz X=(596, 120) saved in 179.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] train id=299 -> ./cache/train_00299.npz X=(576, 120) saved in 163.1s\n[ParCache] train: completed 226 files in 4445.9s\n[ParCache] Starting parallel VAL cache (stride=2)...\n[ParCache] val: 287/287 remaining to cache.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=410 -> ./cache/val_00410.npz X=(612, 120) saved in 184.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=411 -> ./cache/val_00411.npz X=(667, 120) saved in 187.6s\n[Cache] val id=412 -> ./cache/val_00412.npz X=(600, 120) saved in 187.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=413 -> ./cache/val_00413.npz X=(644, 120) saved in 190.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=414 -> ./cache/val_00414.npz X=(669, 120) saved in 192.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=415 -> ./cache/val_00415.npz X=(665, 120) saved in 194.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=416 -> ./cache/val_00416.npz X=(658, 120) saved in 197.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=417 -> ./cache/val_00417.npz X=(661, 120) saved in 198.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=418 -> ./cache/val_00418.npz X=(646, 120) saved in 202.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=420 -> ./cache/val_00420.npz X=(650, 120) saved in 204.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=421 -> ./cache/val_00421.npz X=(674, 120) saved in 207.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=422 -> ./cache/val_00422.npz X=(662, 120) saved in 208.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=423 -> ./cache/val_00423.npz X=(621, 120) saved in 211.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=424 -> ./cache/val_00424.npz X=(636, 120) saved in 211.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=425 -> ./cache/val_00425.npz X=(664, 120) saved in 216.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=426 -> ./cache/val_00426.npz X=(674, 120) saved in 217.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=427 -> ./cache/val_00427.npz X=(680, 120) saved in 221.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=428 -> ./cache/val_00428.npz X=(660, 120) saved in 222.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=429 -> ./cache/val_00429.npz X=(695, 120) saved in 224.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=430 -> ./cache/val_00430.npz X=(658, 120) saved in 225.5s\n[ParCache] val: 20/287 done; elapsed 424.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=431 -> ./cache/val_00431.npz X=(619, 120) saved in 226.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=432 -> ./cache/val_00432.npz X=(608, 120) saved in 228.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=433 -> ./cache/val_00433.npz X=(650, 120) saved in 231.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=434 -> ./cache/val_00434.npz X=(640, 120) saved in 230.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=435 -> ./cache/val_00435.npz X=(615, 120) saved in 234.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=436 -> ./cache/val_00436.npz X=(638, 120) saved in 235.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=437 -> ./cache/val_00437.npz X=(641, 120) saved in 237.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=438 -> ./cache/val_00438.npz X=(638, 120) saved in 241.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=439 -> ./cache/val_00439.npz X=(609, 120) saved in 241.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=440 -> ./cache/val_00440.npz X=(637, 120) saved in 245.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=441 -> ./cache/val_00441.npz X=(639, 120) saved in 245.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=442 -> ./cache/val_00442.npz X=(623, 120) saved in 250.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=443 -> ./cache/val_00443.npz X=(656, 120) saved in 248.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=444 -> ./cache/val_00444.npz X=(637, 120) saved in 248.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=445 -> ./cache/val_00445.npz X=(629, 120) saved in 252.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=446 -> ./cache/val_00446.npz X=(643, 120) saved in 255.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=447 -> ./cache/val_00447.npz X=(656, 120) saved in 256.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=448 -> ./cache/val_00448.npz X=(645, 120) saved in 257.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=449 -> ./cache/val_00449.npz X=(661, 120) saved in 260.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=450 -> ./cache/val_00450.npz X=(658, 120) saved in 261.9s\n[ParCache] val: 40/287 done; elapsed 910.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=451 -> ./cache/val_00451.npz X=(647, 120) saved in 265.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=452 -> ./cache/val_00452.npz X=(638, 120) saved in 264.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=453 -> ./cache/val_00453.npz X=(657, 120) saved in 268.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=454 -> ./cache/val_00454.npz X=(580, 120) saved in 268.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=455 -> ./cache/val_00455.npz X=(661, 120) saved in 269.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=456 -> ./cache/val_00456.npz X=(665, 120) saved in 271.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=457 -> ./cache/val_00457.npz X=(674, 120) saved in 275.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=458 -> ./cache/val_00458.npz X=(590, 120) saved in 274.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=459 -> ./cache/val_00459.npz X=(649, 120) saved in 276.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=460 -> ./cache/val_00460.npz X=(613, 120) saved in 277.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=461 -> ./cache/val_00461.npz X=(670, 120) saved in 281.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=462 -> ./cache/val_00462.npz X=(618, 120) saved in 282.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=463 -> ./cache/val_00463.npz X=(668, 120) saved in 283.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=464 -> ./cache/val_00464.npz X=(624, 120) saved in 287.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=465 -> ./cache/val_00465.npz X=(614, 120) saved in 286.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=466 -> ./cache/val_00466.npz X=(661, 120) saved in 288.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=467 -> ./cache/val_00467.npz X=(700, 120) saved in 291.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=468 -> ./cache/val_00468.npz X=(634, 120) saved in 291.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=469 -> ./cache/val_00469.npz X=(664, 120) saved in 295.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=470 -> ./cache/val_00470.npz X=(626, 120) saved in 295.5s\n[ParCache] val: 60/287 done; elapsed 1264.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=471 -> ./cache/val_00471.npz X=(650, 120) saved in 299.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=472 -> ./cache/val_00472.npz X=(613, 120) saved in 298.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=473 -> ./cache/val_00473.npz X=(616, 120) saved in 301.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=474 -> ./cache/val_00474.npz X=(620, 120) saved in 302.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=475 -> ./cache/val_00475.npz X=(592, 120) saved in 306.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=476 -> ./cache/val_00476.npz X=(610, 120) saved in 308.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=477 -> ./cache/val_00477.npz X=(624, 120) saved in 310.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=478 -> ./cache/val_00478.npz X=(638, 120) saved in 311.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=479 -> ./cache/val_00479.npz X=(613, 120) saved in 313.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=480 -> ./cache/val_00480.npz X=(606, 120) saved in 314.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=481 -> ./cache/val_00481.npz X=(649, 120) saved in 318.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=482 -> ./cache/val_00482.npz X=(626, 120) saved in 319.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=483 -> ./cache/val_00483.npz X=(594, 120) saved in 321.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=484 -> ./cache/val_00484.npz X=(638, 120) saved in 323.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=485 -> ./cache/val_00485.npz X=(626, 120) saved in 325.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=486 -> ./cache/val_00486.npz X=(650, 120) saved in 329.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=487 -> ./cache/val_00487.npz X=(645, 120) saved in 330.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=488 -> ./cache/val_00488.npz X=(622, 120) saved in 333.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=489 -> ./cache/val_00489.npz X=(597, 120) saved in 334.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=490 -> ./cache/val_00490.npz X=(631, 120) saved in 334.8s\n[ParCache] val: 80/287 done; elapsed 1878.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=491 -> ./cache/val_00491.npz X=(660, 120) saved in 333.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=492 -> ./cache/val_00492.npz X=(606, 120) saved in 337.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=493 -> ./cache/val_00493.npz X=(630, 120) saved in 341.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=494 -> ./cache/val_00494.npz X=(650, 120) saved in 342.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache][ERR] val id=500: Sample zip for id 500 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache][ERR] val id=501: Sample zip for id 501 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache][ERR] val id=502: Sample zip for id 502 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache][ERR] val id=503: Sample zip for id 503 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache][ERR] val id=504: Sample zip for id 504 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=495 -> ./cache/val_00495.npz X=(599, 120) saved in 346.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=496 -> ./cache/val_00496.npz X=(630, 120) saved in 345.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache][ERR] val id=505: Sample zip for id 505 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache][ERR] val id=506: Sample zip for id 506 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=497 -> ./cache/val_00497.npz X=(625, 120) saved in 347.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=498 -> ./cache/val_00498.npz X=(617, 120) saved in 346.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=499 -> ./cache/val_00499.npz X=(627, 120) saved in 352.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache][ERR] val id=507: Sample zip for id 507 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache][ERR] val id=508: Sample zip for id 508 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCache][ERR] val id=509: Sample zip for id 509 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=510 -> ./cache/val_00510.npz X=(633, 120) saved in 221.3s\n[ParCache] val: 100/287 done; elapsed 2324.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=516 -> ./cache/val_00516.npz X=(602, 120) saved in 220.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=517 -> ./cache/val_00517.npz X=(615, 120) saved in 222.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=518 -> ./cache/val_00518.npz X=(645, 120) saved in 224.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=519 -> ./cache/val_00519.npz X=(609, 120) saved in 226.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=520 -> ./cache/val_00520.npz X=(621, 120) saved in 229.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=521 -> ./cache/val_00521.npz X=(599, 120) saved in 232.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=522 -> ./cache/val_00522.npz X=(634, 120) saved in 235.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=523 -> ./cache/val_00523.npz X=(651, 120) saved in 233.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=524 -> ./cache/val_00524.npz X=(597, 120) saved in 239.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=525 -> ./cache/val_00525.npz X=(622, 120) saved in 239.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=526 -> ./cache/val_00526.npz X=(636, 120) saved in 241.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=527 -> ./cache/val_00527.npz X=(631, 120) saved in 240.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=528 -> ./cache/val_00528.npz X=(593, 120) saved in 242.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=529 -> ./cache/val_00529.npz X=(589, 120) saved in 243.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=530 -> ./cache/val_00530.npz X=(618, 120) saved in 245.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=531 -> ./cache/val_00531.npz X=(588, 120) saved in 245.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=532 -> ./cache/val_00532.npz X=(637, 120) saved in 249.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=533 -> ./cache/val_00533.npz X=(618, 120) saved in 251.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=534 -> ./cache/val_00534.npz X=(626, 120) saved in 254.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=535 -> ./cache/val_00535.npz X=(629, 120) saved in 256.5s\n[ParCache] val: 120/287 done; elapsed 2682.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=536 -> ./cache/val_00536.npz X=(596, 120) saved in 257.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=537 -> ./cache/val_00537.npz X=(643, 120) saved in 257.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=538 -> ./cache/val_00538.npz X=(632, 120) saved in 259.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=539 -> ./cache/val_00539.npz X=(575, 120) saved in 260.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=541 -> ./cache/val_00541.npz X=(586, 120) saved in 261.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=542 -> ./cache/val_00542.npz X=(609, 120) saved in 266.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=543 -> ./cache/val_00543.npz X=(631, 120) saved in 266.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=544 -> ./cache/val_00544.npz X=(634, 120) saved in 267.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=545 -> ./cache/val_00545.npz X=(606, 120) saved in 271.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=546 -> ./cache/val_00546.npz X=(602, 120) saved in 270.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=547 -> ./cache/val_00547.npz X=(634, 120) saved in 271.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=548 -> ./cache/val_00548.npz X=(615, 120) saved in 275.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=549 -> ./cache/val_00549.npz X=(625, 120) saved in 276.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=550 -> ./cache/val_00550.npz X=(631, 120) saved in 280.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=552 -> ./cache/val_00552.npz X=(828, 120) saved in 280.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=553 -> ./cache/val_00553.npz X=(813, 120) saved in 282.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=554 -> ./cache/val_00554.npz X=(838, 120) saved in 284.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=555 -> ./cache/val_00555.npz X=(826, 120) saved in 287.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=556 -> ./cache/val_00556.npz X=(839, 120) saved in 291.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=557 -> ./cache/val_00557.npz X=(820, 120) saved in 293.5s\n[ParCache] val: 140/287 done; elapsed 3172.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=558 -> ./cache/val_00558.npz X=(815, 120) saved in 295.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=559 -> ./cache/val_00559.npz X=(823, 120) saved in 298.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=560 -> ./cache/val_00560.npz X=(815, 120) saved in 301.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=561 -> ./cache/val_00561.npz X=(826, 120) saved in 305.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=562 -> ./cache/val_00562.npz X=(834, 120) saved in 306.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=563 -> ./cache/val_00563.npz X=(818, 120) saved in 309.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=564 -> ./cache/val_00564.npz X=(838, 120) saved in 313.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=565 -> ./cache/val_00565.npz X=(831, 120) saved in 315.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=566 -> ./cache/val_00566.npz X=(825, 120) saved in 318.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=567 -> ./cache/val_00567.npz X=(832, 120) saved in 317.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=568 -> ./cache/val_00568.npz X=(827, 120) saved in 321.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=569 -> ./cache/val_00569.npz X=(846, 120) saved in 322.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=570 -> ./cache/val_00570.npz X=(823, 120) saved in 327.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=571 -> ./cache/val_00571.npz X=(831, 120) saved in 330.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=572 -> ./cache/val_00572.npz X=(824, 120) saved in 334.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=573 -> ./cache/val_00573.npz X=(836, 120) saved in 335.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=574 -> ./cache/val_00574.npz X=(826, 120) saved in 336.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=575 -> ./cache/val_00575.npz X=(837, 120) saved in 341.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=576 -> ./cache/val_00576.npz X=(819, 120) saved in 341.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=577 -> ./cache/val_00577.npz X=(842, 120) saved in 340.7s\n[ParCache] val: 160/287 done; elapsed 3763.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=578 -> ./cache/val_00578.npz X=(837, 120) saved in 343.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=579 -> ./cache/val_00579.npz X=(833, 120) saved in 347.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=580 -> ./cache/val_00580.npz X=(833, 120) saved in 349.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=581 -> ./cache/val_00581.npz X=(834, 120) saved in 352.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=582 -> ./cache/val_00582.npz X=(815, 120) saved in 350.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=583 -> ./cache/val_00583.npz X=(818, 120) saved in 352.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=584 -> ./cache/val_00584.npz X=(843, 120) saved in 358.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=585 -> ./cache/val_00585.npz X=(856, 120) saved in 359.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=586 -> ./cache/val_00586.npz X=(820, 120) saved in 361.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=587 -> ./cache/val_00587.npz X=(842, 120) saved in 363.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=588 -> ./cache/val_00588.npz X=(841, 120) saved in 364.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=589 -> ./cache/val_00589.npz X=(826, 120) saved in 367.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=590 -> ./cache/val_00590.npz X=(842, 120) saved in 368.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=591 -> ./cache/val_00591.npz X=(815, 120) saved in 371.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=592 -> ./cache/val_00592.npz X=(829, 120) saved in 374.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=593 -> ./cache/val_00593.npz X=(849, 120) saved in 377.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=594 -> ./cache/val_00594.npz X=(814, 120) saved in 379.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=595 -> ./cache/val_00595.npz X=(829, 120) saved in 378.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=596 -> ./cache/val_00596.npz X=(840, 120) saved in 385.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=597 -> ./cache/val_00597.npz X=(844, 120) saved in 386.2s\n[ParCache] val: 180/287 done; elapsed 4345.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=598 -> ./cache/val_00598.npz X=(831, 120) saved in 390.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=599 -> ./cache/val_00599.npz X=(835, 120) saved in 393.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=600 -> ./cache/val_00600.npz X=(840, 120) saved in 391.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=601 -> ./cache/val_00601.npz X=(830, 120) saved in 394.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=602 -> ./cache/val_00602.npz X=(838, 120) saved in 394.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=603 -> ./cache/val_00603.npz X=(833, 120) saved in 392.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=604 -> ./cache/val_00604.npz X=(844, 120) saved in 399.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=605 -> ./cache/val_00605.npz X=(838, 120) saved in 402.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=606 -> ./cache/val_00606.npz X=(832, 120) saved in 411.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=607 -> ./cache/val_00607.npz X=(839, 120) saved in 406.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=608 -> ./cache/val_00608.npz X=(817, 120) saved in 408.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=609 -> ./cache/val_00609.npz X=(826, 120) saved in 410.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=610 -> ./cache/val_00610.npz X=(831, 120) saved in 413.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=611 -> ./cache/val_00611.npz X=(946, 120) saved in 413.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=612 -> ./cache/val_00612.npz X=(916, 120) saved in 419.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=613 -> ./cache/val_00613.npz X=(911, 120) saved in 415.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=621 -> ./cache/val_00621.npz X=(737, 120) saved in 211.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=614 -> ./cache/val_00614.npz X=(943, 120) saved in 421.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=615 -> ./cache/val_00615.npz X=(924, 120) saved in 426.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=616 -> ./cache/val_00616.npz X=(914, 120) saved in 426.5s\n[ParCache] val: 200/287 done; elapsed 5034.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=617 -> ./cache/val_00617.npz X=(918, 120) saved in 431.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=622 -> ./cache/val_00622.npz X=(823, 120) saved in 212.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=618 -> ./cache/val_00618.npz X=(937, 120) saved in 431.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=619 -> ./cache/val_00619.npz X=(937, 120) saved in 435.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=623 -> ./cache/val_00623.npz X=(810, 120) saved in 212.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=624 -> ./cache/val_00624.npz X=(836, 120) saved in 217.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=625 -> ./cache/val_00625.npz X=(821, 120) saved in 217.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=620 -> ./cache/val_00620.npz X=(937, 120) saved in 440.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=626 -> ./cache/val_00626.npz X=(842, 120) saved in 221.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=627 -> ./cache/val_00627.npz X=(838, 120) saved in 224.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=628 -> ./cache/val_00628.npz X=(832, 120) saved in 225.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=629 -> ./cache/val_00629.npz X=(821, 120) saved in 228.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=630 -> ./cache/val_00630.npz X=(835, 120) saved in 230.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=631 -> ./cache/val_00631.npz X=(914, 120) saved in 235.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=632 -> ./cache/val_00632.npz X=(940, 120) saved in 234.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=633 -> ./cache/val_00633.npz X=(917, 120) saved in 240.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=634 -> ./cache/val_00634.npz X=(913, 120) saved in 240.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=635 -> ./cache/val_00635.npz X=(933, 120) saved in 244.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=636 -> ./cache/val_00636.npz X=(925, 120) saved in 246.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=637 -> ./cache/val_00637.npz X=(926, 120) saved in 251.1s\n[ParCache] val: 220/287 done; elapsed 5412.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=638 -> ./cache/val_00638.npz X=(916, 120) saved in 251.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=639 -> ./cache/val_00639.npz X=(929, 120) saved in 254.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=640 -> ./cache/val_00640.npz X=(934, 120) saved in 254.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=641 -> ./cache/val_00641.npz X=(926, 120) saved in 255.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=642 -> ./cache/val_00642.npz X=(935, 120) saved in 263.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=643 -> ./cache/val_00643.npz X=(931, 120) saved in 264.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=644 -> ./cache/val_00644.npz X=(923, 120) saved in 266.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=645 -> ./cache/val_00645.npz X=(920, 120) saved in 270.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=646 -> ./cache/val_00646.npz X=(618, 120) saved in 272.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=647 -> ./cache/val_00647.npz X=(635, 120) saved in 273.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=648 -> ./cache/val_00648.npz X=(658, 120) saved in 274.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=651 -> ./cache/val_00651.npz X=(930, 120) saved in 276.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=653 -> ./cache/val_00653.npz X=(933, 120) saved in 276.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=654 -> ./cache/val_00654.npz X=(921, 120) saved in 282.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=655 -> ./cache/val_00655.npz X=(932, 120) saved in 284.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=656 -> ./cache/val_00656.npz X=(927, 120) saved in 285.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=657 -> ./cache/val_00657.npz X=(947, 120) saved in 289.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=658 -> ./cache/val_00658.npz X=(922, 120) saved in 286.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=659 -> ./cache/val_00659.npz X=(939, 120) saved in 292.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=660 -> ./cache/val_00660.npz X=(943, 120) saved in 296.6s\n[ParCache] val: 240/287 done; elapsed 5919.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=661 -> ./cache/val_00661.npz X=(942, 120) saved in 297.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=662 -> ./cache/val_00662.npz X=(925, 120) saved in 300.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=663 -> ./cache/val_00663.npz X=(938, 120) saved in 302.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=664 -> ./cache/val_00664.npz X=(929, 120) saved in 308.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=665 -> ./cache/val_00665.npz X=(929, 120) saved in 308.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=666 -> ./cache/val_00666.npz X=(937, 120) saved in 308.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=667 -> ./cache/val_00667.npz X=(916, 120) saved in 308.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=668 -> ./cache/val_00668.npz X=(925, 120) saved in 314.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=669 -> ./cache/val_00669.npz X=(949, 120) saved in 324.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=670 -> ./cache/val_00670.npz X=(929, 120) saved in 322.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=671 -> ./cache/val_00671.npz X=(935, 120) saved in 322.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=672 -> ./cache/val_00672.npz X=(926, 120) saved in 326.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=673 -> ./cache/val_00673.npz X=(949, 120) saved in 331.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=674 -> ./cache/val_00674.npz X=(947, 120) saved in 331.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=675 -> ./cache/val_00675.npz X=(946, 120) saved in 333.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=676 -> ./cache/val_00676.npz X=(924, 120) saved in 338.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=677 -> ./cache/val_00677.npz X=(916, 120) saved in 340.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=678 -> ./cache/val_00678.npz X=(938, 120) saved in 341.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=679 -> ./cache/val_00679.npz X=(952, 120) saved in 336.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=680 -> ./cache/val_00680.npz X=(962, 120) saved in 343.2s\n[ParCache] val: 260/287 done; elapsed 6460.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=681 -> ./cache/val_00681.npz X=(911, 120) saved in 349.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=682 -> ./cache/val_00682.npz X=(946, 120) saved in 351.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=683 -> ./cache/val_00683.npz X=(941, 120) saved in 351.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=684 -> ./cache/val_00684.npz X=(913, 120) saved in 355.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=685 -> ./cache/val_00685.npz X=(915, 120) saved in 358.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=686 -> ./cache/val_00686.npz X=(938, 120) saved in 358.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=687 -> ./cache/val_00687.npz X=(917, 120) saved in 359.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=688 -> ./cache/val_00688.npz X=(939, 120) saved in 366.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=689 -> ./cache/val_00689.npz X=(937, 120) saved in 370.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=692 -> ./cache/val_00692.npz X=(959, 120) saved in 371.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=693 -> ./cache/val_00693.npz X=(912, 120) saved in 371.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=694 -> ./cache/val_00694.npz X=(944, 120) saved in 374.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=695 -> ./cache/val_00695.npz X=(924, 120) saved in 380.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=696 -> ./cache/val_00696.npz X=(945, 120) saved in 384.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=697 -> ./cache/val_00697.npz X=(917, 120) saved in 384.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=698 -> ./cache/val_00698.npz X=(948, 120) saved in 385.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=699 -> ./cache/val_00699.npz X=(952, 120) saved in 386.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=700 -> ./cache/val_00700.npz X=(939, 120) saved in 385.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=702 -> ./cache/val_00702.npz X=(953, 120) saved in 376.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=703 -> ./cache/val_00703.npz X=(944, 120) saved in 377.0s\n[ParCache] val: 280/287 done; elapsed 7080.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=704 -> ./cache/val_00704.npz X=(923, 120) saved in 365.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=705 -> ./cache/val_00705.npz X=(933, 120) saved in 362.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=706 -> ./cache/val_00706.npz X=(951, 120) saved in 342.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=707 -> ./cache/val_00707.npz X=(926, 120) saved in 307.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=708 -> ./cache/val_00708.npz X=(932, 120) saved in 256.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=709 -> ./cache/val_00709.npz X=(937, 120) saved in 227.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Cache] val id=710 -> ./cache/val_00710.npz X=(918, 120) saved in 216.3s\n[ParCache] val: completed 287 files in 7155.0s\n[ParCache] Done.\n"
          ]
        }
      ]
    },
    {
      "id": "3559e402-fedb-4d9b-aaf7-6d1fb468829c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 11) Train XGBoost on cached TRAIN and cache VAL per-frame probabilities; coarse decoder grid\n",
        "import os, glob, time, numpy as np, pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "CACHE_DIR = './cache'\n",
        "\n",
        "def load_cached_split(split_prefix):\n",
        "    files = sorted(glob.glob(os.path.join(CACHE_DIR, f\"{split_prefix}_*.npz\")))\n",
        "    Xs, ys, ids, idx_spans = [], [], [], []\n",
        "    n_frames = 0\n",
        "    t0 = time.time()\n",
        "    for i, fp in enumerate(files, 1):\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        X = d['X']; y = d['y']\n",
        "        sid = int(os.path.basename(fp).split('_')[1].split('.')[0])\n",
        "        Xs.append(X); ys.append(y.astype(np.int32))\n",
        "        ids.append(sid)\n",
        "        idx_spans.append((n_frames, n_frames + len(y), sid))\n",
        "        n_frames += len(y)\n",
        "        if i % 20 == 0:\n",
        "            print(f\"[LoadCache] {split_prefix}: {i}/{len(files)} files, cum frames={n_frames}\", flush=True)\n",
        "    X = np.vstack(Xs) if Xs else np.zeros((0,0), dtype=np.float32)\n",
        "    y = np.concatenate(ys) if ys else np.zeros((0,), dtype=np.int32)\n",
        "    print(f\"[LoadCache] {split_prefix}: X={X.shape} y={y.shape} ids={len(ids)} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "    return X, y, ids, idx_spans, files\n",
        "\n",
        "def make_weights_with_boundary_erosion(y: np.ndarray, w0: float=0.38):\n",
        "    w = np.ones_like(y, dtype=np.float32)\n",
        "    w[y==0] = w0\n",
        "    # boundary erosion: zero weight on boundary frames (label changes) to reduce noise\n",
        "    if len(y) > 2:\n",
        "        bmask = (y[1:-1] != y[:-2]) | (y[1:-1] != y[2:])\n",
        "        w[1:-1][bmask] = w[1:-1][bmask] * 0.0\n",
        "    return w\n",
        "\n",
        "def train_xgb_on_cache():\n",
        "    X_tr, y_tr, ids_tr, spans_tr, _ = load_cached_split('train')\n",
        "    assert X_tr.shape[0] == y_tr.shape[0] and X_tr.shape[0] > 0, \"Empty training cache\"\n",
        "    w_tr = make_weights_with_boundary_erosion(y_tr, w0=0.38)\n",
        "    dtr = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr)\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 21,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'predictor': 'gpu_predictor',\n",
        "        'max_bin': 512,\n",
        "        'max_depth': 7,\n",
        "        'eta': 0.085,\n",
        "        'subsample': 0.85,\n",
        "        'colsample_bytree': 0.85,\n",
        "        'min_child_weight': 4.0,\n",
        "        'lambda': 1.0\n",
        "    }\n",
        "    print('[XGB] Training on cached TRAIN...', flush=True)\n",
        "    t0 = time.time()\n",
        "    bst = xgb.train(params, dtr, num_boost_round=1100, verbose_eval=100)\n",
        "    print(f\"[XGB] Done in {time.time()-t0:.1f}s\", flush=True)\n",
        "    bst.save_model('xgb_train.model')\n",
        "    return bst\n",
        "\n",
        "def cache_val_probs(bst):\n",
        "    # Load VAL cache and predict per-id, saving probs for decoder tuning\n",
        "    _, _, _, _, val_files = load_cached_split('val')\n",
        "    os.makedirs('./cache_probs', exist_ok=True)\n",
        "    t0 = time.time()\n",
        "    for i, fp in enumerate(val_files, 1):\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        X = d['X']; seq = d['seq']; fps = int(d['fps']); stride = int(d['stride'])\n",
        "        sid = int(os.path.basename(fp).split('_')[1].split('.')[0])\n",
        "        dm = xgb.DMatrix(X)\n",
        "        P = bst.predict(dm)\n",
        "        outp = f\"./cache_probs/valprobs_{sid:05d}.npz\"\n",
        "        np.savez_compressed(outp, probs=P.astype(np.float32), seq=seq.astype(np.int16), fps=fps, stride=stride, sid=sid)\n",
        "        if i % 20 == 0:\n",
        "            print(f\"[ValProbs] {i}/{len(val_files)} saved; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    print(f\"[ValProbs] Done {len(val_files)} ids in {time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "def load_all_val_probs():\n",
        "    files = sorted(glob.glob('./cache_probs/valprobs_*.npz'))\n",
        "    items = []\n",
        "    for fp in files:\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        items.append((int(d['sid']), d['probs'], d['seq']))\n",
        "    return items\n",
        "\n",
        "def grid_search_decoder():\n",
        "    items = load_all_val_probs()\n",
        "    assert items, 'No cached VAL probs found. Run cache_val_probs() first.'\n",
        "    grids = {\n",
        "        'window': [5,7,9],\n",
        "        'merge_gap': [3,4,5],\n",
        "        'min_len': [5,6,7,8],\n",
        "        'mean_thr': [0.40,0.45,0.50],\n",
        "        'max_thr': [0.55,0.60,0.65],\n",
        "    }\n",
        "    best = (1e9, None)\n",
        "    tried = 0\n",
        "    t0 = time.time()\n",
        "    for w in grids['window']:\n",
        "        for mg in grids['merge_gap']:\n",
        "            for ml in grids['min_len']:\n",
        "                for mthr in grids['mean_thr']:\n",
        "                    for xthr in grids['max_thr']:\n",
        "                        scores = []\n",
        "                        for sid, P, seq in items:\n",
        "                            pred = decode_sequence(P, window=w, merge_gap=mg, min_len=ml, mean_thr=mthr, max_thr=xthr)\n",
        "                            lev = levenshtein(list(pred), list(seq.tolist()))\n",
        "                            norm = lev / max(1, len(seq))\n",
        "                            scores.append(norm)\n",
        "                        mean_norm = float(np.mean(scores)) if scores else 1.0\n",
        "                        tried += 1\n",
        "                        if tried % 20 == 0:\n",
        "                            print(f\"[Grid] {tried} combos, curr mean={mean_norm:.4f} best={best[0]:.4f}\", flush=True)\n",
        "                        if mean_norm < best[0]:\n",
        "                            best = (mean_norm, {'window':w,'merge_gap':mg,'min_len':ml,'mean_thr':mthr,'max_thr':xthr})\n",
        "    print(f\"[Grid] Done {tried} combos in {time.time()-t0:.1f}s. Best={best}\", flush=True)\n",
        "    return best\n",
        "\n",
        "print('[Stage] TRAIN on cached frames and prepare VAL probs. Execute this cell after caching finishes.', flush=True)\n",
        "# Usage after caching completes:\n",
        "# bst = train_xgb_on_cache()\n",
        "# cache_val_probs(bst)\n",
        "# best = grid_search_decoder()\n",
        "# print('Best decoder params:', best)\n",
        "\n",
        "# Note: final step will retrain on TRAIN+VAL caches with same params and run TEST decoding with frozen decoder settings."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stage] TRAIN on cached frames and prepare VAL probs. Execute this cell after caching finishes.\n"
          ]
        }
      ]
    },
    {
      "id": "57a2aa37-fd42-4b8f-b1ab-6e13e814f022",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 12) Execute training on cached data, cache VAL probs, and grid-search decoder\n",
        "import time\n",
        "t0 = time.time()\n",
        "print('[RUN] Training XGBoost on cached TRAIN...')\n",
        "bst = train_xgb_on_cache()\n",
        "print('[RUN] Caching VAL per-frame probabilities...')\n",
        "cache_val_probs(bst)\n",
        "print('[RUN] Grid-searching decoder parameters...')\n",
        "best = grid_search_decoder()\n",
        "print('Best decoder params:', best)\n",
        "print(f\"[RUN] Total elapsed: {time.time()-t0:.1f}s\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RUN] Training XGBoost on cached TRAIN...\n[LoadCache] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] train: X=(187296, 120) y=(187296,) ids=297 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB] Training on cached TRAIN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB] Done in 172.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RUN] Caching VAL per-frame probabilities...\n[LoadCache] val: 20/277 files, cum frames=13096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 40/277 files, cum frames=25838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 60/277 files, cum frames=38691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 80/277 files, cum frames=51151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 100/277 files, cum frames=63623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 120/277 files, cum frames=75902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 140/277 files, cum frames=91628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 160/277 files, cum frames=108270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 180/277 files, cum frames=124959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 200/277 files, cum frames=142423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 220/277 files, cum frames=160046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 240/277 files, cum frames=178417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: 260/277 files, cum frames=197128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCache] val: X=(213026, 120) y=(213026,) ids=277 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 20/277 saved; elapsed 5.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 40/277 saved; elapsed 11.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 60/277 saved; elapsed 16.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 80/277 saved; elapsed 22.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 100/277 saved; elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 120/277 saved; elapsed 33.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 140/277 saved; elapsed 38.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 160/277 saved; elapsed 44.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 180/277 saved; elapsed 49.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 200/277 saved; elapsed 54.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 220/277 saved; elapsed 60.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 240/277 saved; elapsed 65.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] 260/277 saved; elapsed 70.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbs] Done 277 ids in 75.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RUN] Grid-searching decoder parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 20 combos, curr mean=16.1769 best=15.7329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 40 combos, curr mean=19.6101 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 60 combos, curr mean=15.1661 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 80 combos, curr mean=17.5957 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 100 combos, curr mean=14.6426 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 120 combos, curr mean=18.4007 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 140 combos, curr mean=14.0830 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 160 combos, curr mean=15.5596 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 180 combos, curr mean=12.9675 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 200 combos, curr mean=16.8339 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 220 combos, curr mean=17.9458 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 240 combos, curr mean=15.4260 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 260 combos, curr mean=15.8195 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 280 combos, curr mean=15.6029 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 300 combos, curr mean=18.1372 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] 320 combos, curr mean=14.2238 best=12.8809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid] Done 324 combos in 116.6s. Best=(12.88086642599278, {'window': 5, 'merge_gap': 3, 'min_len': 8, 'mean_thr': 0.5, 'max_thr': 0.65})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best decoder params: (12.88086642599278, {'window': 5, 'merge_gap': 3, 'min_len': 8, 'mean_thr': 0.5, 'max_thr': 0.65})\n[RUN] Total elapsed: 366.2s\n"
          ]
        }
      ]
    },
    {
      "id": "6fee8d44-e4e0-4181-bcb3-e8ebe2d533ee",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 13) FE v1.5 (hip-center + shoulder-width scale) caching/training/grid pipeline\n",
        "import os, io, re, time, glob, tarfile, zipfile, numpy as np, concurrent.futures as cf\n",
        "import xgboost as xgb\n",
        "\n",
        "# FE v1.5: normalize per-frame by hip-center and shoulder-width; then positions + velocities\n",
        "HIP=0; L_SHOULDER=4; R_SHOULDER=8\n",
        "def features_from_skeleton_v15(skel):\n",
        "    T, J, _ = skel.shape\n",
        "    feats = np.zeros((T, J*3*2), dtype=np.float32)\n",
        "    prev = None\n",
        "    for t in range(T):\n",
        "        coords = skel[t].astype(np.float32)\n",
        "        hip = coords[HIP]\n",
        "        centered = coords - hip\n",
        "        shoulder_w = np.linalg.norm(centered[R_SHOULDER] - centered[L_SHOULDER])\n",
        "        scale = max(shoulder_w, 1e-4)\n",
        "        centered /= scale\n",
        "        if prev is None:\n",
        "            vel = np.zeros_like(centered)\n",
        "        else:\n",
        "            vel = centered - prev\n",
        "        prev = centered\n",
        "        feats[t, :J*3] = centered.reshape(-1)\n",
        "        feats[t, J*3:] = vel.reshape(-1)\n",
        "    return feats\n",
        "\n",
        "# Separate cache dirs to avoid mixing\n",
        "CACHE_DIR_V15 = './cache_v15'\n",
        "PROB_DIR_V15 = './cache_probs_v15'\n",
        "os.makedirs(CACHE_DIR_V15, exist_ok=True)\n",
        "os.makedirs(PROB_DIR_V15, exist_ok=True)\n",
        "\n",
        "def split_and_tar_for_id(sample_id:int, split_hint:str='train'):\n",
        "    if split_hint == 'train':\n",
        "        if sample_id < 100: return 'train', 'training1.tar.gz'\n",
        "        elif sample_id < 200: return 'train', 'training2.tar.gz'\n",
        "        else: return 'train', 'training3.tar.gz'\n",
        "    elif split_hint == 'val':\n",
        "        if sample_id < 500: return 'val', 'validation1.tar.gz'\n",
        "        elif sample_id < 621: return 'val', 'validation2.tar.gz'\n",
        "        else: return 'val', 'validation3.tar.gz'\n",
        "    elif split_hint == 'test':\n",
        "        return 'test', 'test.tar.gz'\n",
        "    else:\n",
        "        raise ValueError('Unknown split_hint')\n",
        "\n",
        "def get_zip_member(tf: tarfile.TarFile, sample_id:int):\n",
        "    candidates = [f'./Sample{sample_id:05d}.zip', f'Sample{sample_id:05d}.zip']\n",
        "    for nm in candidates:\n",
        "        try:\n",
        "            return tf.getmember(nm)\n",
        "        except KeyError:\n",
        "            pass\n",
        "    for m in tf.getmembers():\n",
        "        if m.name.endswith(f'Sample{sample_id:05d}.zip'):\n",
        "            return m\n",
        "    raise FileNotFoundError(f'Sample zip for id {sample_id} not found in tar')\n",
        "\n",
        "def load_video_from_split(sample_id:int, split_hint:str):\n",
        "    _, tar_path = split_and_tar_for_id(sample_id, split_hint)\n",
        "    with tarfile.open(tar_path, 'r:gz') as tf:\n",
        "        mem = get_zip_member(tf, sample_id)\n",
        "        zbytes = tf.extractfile(mem).read()\n",
        "        with zipfile.ZipFile(io.BytesIO(zbytes)) as zf:\n",
        "            mat_name = next(n for n in zf.namelist() if n.lower().endswith('_data.mat'))\n",
        "            with zf.open(mat_name) as f:\n",
        "                d = sio.loadmat(f, simplify_cells=True)\n",
        "    return d['Video']\n",
        "\n",
        "def stack_world_positions(vid, stride:int=2):\n",
        "    T = int(vid['NumFrames']); frames = vid['Frames']\n",
        "    J = frames[0]['Skeleton']['WorldPosition'].shape[0]\n",
        "    idxs = list(range(0, T, stride))\n",
        "    skel = np.zeros((len(idxs), J, 3), dtype=np.float32)\n",
        "    last = None\n",
        "    for i, t in enumerate(idxs):\n",
        "        wp = frames[t]['Skeleton']['WorldPosition']\n",
        "        arr = np.asarray(wp, dtype=np.float32) if wp is not None else last\n",
        "        if arr is None: arr = np.zeros((J,3), dtype=np.float32)\n",
        "        skel[i] = arr; last = arr\n",
        "    return skel, idxs\n",
        "\n",
        "def true_token_sequence_from_video(vid, name_to_id_map):\n",
        "    seq = []\n",
        "    for lab in vid['Labels']:\n",
        "        cid = name_to_id_map.get(lab['Name'])\n",
        "        if cid is not None: seq.append(cid)\n",
        "    return seq\n",
        "\n",
        "def cache_sample_v15(sample_id:int, split_hint:str, stride:int=2):\n",
        "    out_path = os.path.join(CACHE_DIR_V15, f'{split_hint}_{sample_id:05d}.npz')\n",
        "    if os.path.exists(out_path):\n",
        "        return out_path\n",
        "    t0 = time.time()\n",
        "    vid = load_video_from_split(sample_id, split_hint)\n",
        "    skel, idxs = stack_world_positions(vid, stride=stride)\n",
        "    X = features_from_skeleton_v15(skel)\n",
        "    T_full = int(vid['NumFrames'])\n",
        "    y_full = np.zeros(T_full, dtype=np.int16)\n",
        "    if split_hint in ('train','val'):\n",
        "        for lab in vid['Labels']:\n",
        "            cid = name_to_id.get(lab['Name'])\n",
        "            if cid is None: continue\n",
        "            b = max(0, int(lab['Begin'])-1); e = min(T_full, int(lab['End']))\n",
        "            y_full[b:e] = cid\n",
        "    y_ds = np.array([y_full[t] for t in idxs], dtype=np.int16)\n",
        "    true_seq = true_token_sequence_from_video(vid, name_to_id) if split_hint in ('train','val') else []\n",
        "    fps = int(vid.get('FrameRate', 20))\n",
        "    np.savez_compressed(out_path, X=X, y=y_ds, seq=np.array(true_seq, dtype=np.int16), fps=fps, stride=stride, sid=sample_id)\n",
        "    print(f\"[CacheV15] {split_hint} id={sample_id} -> {out_path} X={X.shape} saved in {time.time()-t0:.1f}s\", flush=True)\n",
        "    return out_path\n",
        "\n",
        "def list_ids_in_tar_fast(tar_path):\n",
        "    ids = []\n",
        "    with tarfile.open(tar_path, 'r:gz') as tf:\n",
        "        for m in tf.getmembers():\n",
        "            if m.name.lower().endswith('.zip'):\n",
        "                m2 = re.findall(r'(\\d{5})', m.name)\n",
        "                if m2: ids.append(int(m2[0]))\n",
        "    return sorted(ids)\n",
        "\n",
        "def remaining_ids_v15(split_hint, ids):\n",
        "    rem = []\n",
        "    for sid in ids:\n",
        "        out_path = os.path.join(CACHE_DIR_V15, f'{split_hint}_{sid:05d}.npz')\n",
        "        if not os.path.exists(out_path): rem.append(sid)\n",
        "    return rem\n",
        "\n",
        "def parallel_cache_v15(split_hint, ids, max_workers=12, stride=2):\n",
        "    todo = remaining_ids_v15(split_hint, ids)\n",
        "    print(f\"[ParCacheV15] {split_hint}: {len(todo)}/{len(ids)} remaining.\")\n",
        "    if not todo: return\n",
        "    t0 = time.time(); done = 0\n",
        "    def task(sid):\n",
        "        try:\n",
        "            return cache_sample_v15(sid, split_hint, stride=stride)\n",
        "        except Exception as e:\n",
        "            print(f\"[ParCacheV15][ERR] {split_hint} id={sid}: {e}\")\n",
        "            return None\n",
        "    with cf.ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
        "        futures = [ex.submit(task, sid) for sid in todo]\n",
        "        for fut in cf.as_completed(futures):\n",
        "            _ = fut.result(); done += 1\n",
        "            if done % 20 == 0:\n",
        "                print(f\"[ParCacheV15] {split_hint}: {done}/{len(todo)} done; elapsed {time.time()-t0:.1f}s\")\n",
        "    print(f\"[ParCacheV15] {split_hint}: completed {done} in {time.time()-t0:.1f}s\")\n",
        "\n",
        "def load_cached_split_v15(split_prefix):\n",
        "    files = sorted(glob.glob(os.path.join(CACHE_DIR_V15, f\"{split_prefix}_*.npz\")))\n",
        "    Xs, ys = [], []\n",
        "    n_frames = 0; t0 = time.time()\n",
        "    for i, fp in enumerate(files, 1):\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        X = d['X']; y = d['y']\n",
        "        Xs.append(X); ys.append(y.astype(np.int32))\n",
        "        n_frames += len(y)\n",
        "        if i % 20 == 0:\n",
        "            print(f\"[LoadCacheV15] {split_prefix}: {i}/{len(files)} files, cum frames={n_frames}\", flush=True)\n",
        "    X = np.vstack(Xs) if Xs else np.zeros((0,0), dtype=np.float32)\n",
        "    y = np.concatenate(ys) if ys else np.zeros((0,), dtype=np.int32)\n",
        "    print(f\"[LoadCacheV15] {split_prefix}: X={X.shape} y={y.shape} files={len(files)} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "    return X, y, files\n",
        "\n",
        "def make_weights_with_boundary_erosion(y: np.ndarray, w0: float=0.38):\n",
        "    w = np.ones_like(y, dtype=np.float32); w[y==0] = w0\n",
        "    if len(y) > 2:\n",
        "        bmask = (y[1:-1] != y[:-2]) | (y[1:-1] != y[2:])\n",
        "        w[1:-1][bmask] = 0.0\n",
        "    return w\n",
        "\n",
        "def train_xgb_on_cache_v15():\n",
        "    X_tr, y_tr, _ = load_cached_split_v15('train')\n",
        "    assert X_tr.shape[0] == y_tr.shape[0] and X_tr.shape[0] > 0, 'Empty v15 train cache'\n",
        "    w_tr = make_weights_with_boundary_erosion(y_tr, w0=0.38)\n",
        "    dtr = xgb.DMatrix(X_tr, label=y_tr, weight=w_tr)\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 21,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'predictor': 'gpu_predictor',\n",
        "        'max_bin': 512,\n",
        "        'max_depth': 7,\n",
        "        'eta': 0.085,\n",
        "        'subsample': 0.85,\n",
        "        'colsample_bytree': 0.85,\n",
        "        'min_child_weight': 4.0,\n",
        "        'lambda': 1.0\n",
        "    }\n",
        "    print('[XGB-V15] Training on cached TRAIN...', flush=True)\n",
        "    t0 = time.time()\n",
        "    bst = xgb.train(params, dtr, num_boost_round=1100, verbose_eval=100)\n",
        "    print(f\"[XGB-V15] Done in {time.time()-t0:.1f}s\", flush=True)\n",
        "    bst.save_model('xgb_train_v15.model')\n",
        "    return bst\n",
        "\n",
        "def cache_val_probs_v15(bst):\n",
        "    _, _, val_files = load_cached_split_v15('val')\n",
        "    t0 = time.time()\n",
        "    for i, fp in enumerate(val_files, 1):\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        X = d['X']; seq = d['seq']; fps = int(d['fps']); stride = int(d['stride']); sid = int(d['sid'])\n",
        "        P = bst.predict(xgb.DMatrix(X))\n",
        "        outp = os.path.join(PROB_DIR_V15, f'valprobs_{sid:05d}.npz')\n",
        "        np.savez_compressed(outp, probs=P.astype(np.float32), seq=seq.astype(np.int16), fps=fps, stride=stride, sid=sid)\n",
        "        if i % 20 == 0:\n",
        "            print(f\"[ValProbsV15] {i}/{len(val_files)} saved; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    print(f\"[ValProbsV15] Done {len(val_files)} ids in {time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "def load_all_val_probs_v15():\n",
        "    files = sorted(glob.glob(os.path.join(PROB_DIR_V15, 'valprobs_*.npz')))\n",
        "    items = []\n",
        "    for fp in files:\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        items.append((int(d['sid']), d['probs'], d['seq']))\n",
        "    return items\n",
        "\n",
        "def grid_search_decoder_v15():\n",
        "    items = load_all_val_probs_v15()\n",
        "    assert items, 'No cached VAL probs v15 found.'\n",
        "    grids = {\n",
        "        'window': [5,7,9],\n",
        "        'merge_gap': [3,4,5,6],\n",
        "        'min_len': [4,5,6,7,8,9,10],\n",
        "        'mean_thr': [0.35,0.40,0.45,0.50,0.55],\n",
        "        'max_thr': [0.55,0.60,0.65,0.70],\n",
        "    }\n",
        "    best = (1e9, None); tried = 0; t0 = time.time()\n",
        "    for w in grids['window']:\n",
        "        for mg in grids['merge_gap']:\n",
        "            for ml in grids['min_len']:\n",
        "                for mthr in grids['mean_thr']:\n",
        "                    for xthr in grids['max_thr']:\n",
        "                        scores = []\n",
        "                        for sid, P, seq in items:\n",
        "                            pred = decode_sequence(P, window=w, merge_gap=mg, min_len=ml, mean_thr=mthr, max_thr=xthr)\n",
        "                            lev = levenshtein(list(pred), list(seq.tolist()))\n",
        "                            norm = lev / max(1, len(seq))\n",
        "                            scores.append(norm)\n",
        "                        mean_norm = float(np.mean(scores)) if scores else 1.0\n",
        "                        tried += 1\n",
        "                        if tried % 20 == 0:\n",
        "                            print(f\"[GridV15] {tried} combos, curr mean={mean_norm:.4f} best={best[0]:.4f}\", flush=True)\n",
        "                        if mean_norm < best[0]:\n",
        "                            best = (mean_norm, {'window':w,'merge_gap':mg,'min_len':ml,'mean_thr':mthr,'max_thr':xthr})\n",
        "    print(f\"[GridV15] Done {tried} combos in {time.time()-t0:.1f}s. Best={best}\", flush=True)\n",
        "    return best\n",
        "\n",
        "print('[StageV15] Ready: parallel cache TRAIN/VAL with FE v1.5, then train, cache VAL probs, and grid-search decoder. Use stride=2.', flush=True)\n",
        "# Example run order:\n",
        "# train_ids_all = train_df['Id'].tolist()\n",
        "# val_ids_all = list_ids_in_tar_fast('validation1.tar.gz') + list_ids_in_tar_fast('validation2.tar.gz') + list_ids_in_tar_fast('validation3.tar.gz')\n",
        "# parallel_cache_v15('train', train_ids_all, max_workers=12, stride=2)\n",
        "# parallel_cache_v15('val', val_ids_all, max_workers=12, stride=2)\n",
        "# bst_v15 = train_xgb_on_cache_v15()\n",
        "# cache_val_probs_v15(bst_v15)\n",
        "# best_v15 = grid_search_decoder_v15()\n",
        "# print('Best decoder params (v15):', best_v15)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[StageV15] Ready: parallel cache TRAIN/VAL with FE v1.5, then train, cache VAL probs, and grid-search decoder. Use stride=2.\n"
          ]
        }
      ]
    },
    {
      "id": "1fb85e53-577e-43c4-ae3a-4ba612094eb4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 14) Run FE v1.5 pipeline: parallel cache TRAIN/VAL (stride=2), train, cache VAL probs, grid-search decoder\n",
        "import time, numpy as np\n",
        "import scipy.io as sio  # ensure available for v1.5 loaders\n",
        "\n",
        "print('[RUN V1.5] Collecting ids...')\n",
        "train_ids_all = train_df['Id'].tolist()\n",
        "val_ids_all = list_ids_in_tar_fast('validation1.tar.gz') + list_ids_in_tar_fast('validation2.tar.gz') + list_ids_in_tar_fast('validation3.tar.gz')\n",
        "print('[RUN V1.5] Train ids:', len(train_ids_all), 'Val ids:', len(val_ids_all))\n",
        "\n",
        "t0 = time.time()\n",
        "print('[RUN V1.5] Parallel caching TRAIN (stride=2)...')\n",
        "parallel_cache_v15('train', train_ids_all, max_workers=12, stride=2)\n",
        "print('[RUN V1.5] Parallel caching VAL (stride=2)...')\n",
        "parallel_cache_v15('val', val_ids_all, max_workers=12, stride=2)\n",
        "print(f\"[RUN V1.5] Caching done in {time.time()-t0:.1f}s\")\n",
        "\n",
        "print('[RUN V1.5] Training XGBoost on v1.5 cached TRAIN...')\n",
        "bst_v15 = train_xgb_on_cache_v15()\n",
        "\n",
        "print('[RUN V1.5] Caching VAL per-frame probabilities (v1.5)...')\n",
        "cache_val_probs_v15(bst_v15)\n",
        "\n",
        "print('[RUN V1.5] Grid-searching decoder (v1.5)...')\n",
        "best_v15 = grid_search_decoder_v15()\n",
        "print('Best decoder params (v1.5):', best_v15)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RUN V1.5] Collecting ids...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RUN V1.5] Train ids: 297 Val ids: 287\n[RUN V1.5] Parallel caching TRAIN (stride=2)...\n[ParCacheV15] train: 297/297 remaining.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=1 -> ./cache_v15/train_00001.npz X=(627, 120) saved in 275.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=3 -> ./cache_v15/train_00003.npz X=(559, 120) saved in 275.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=4 -> ./cache_v15/train_00004.npz X=(668, 120) saved in 283.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=5 -> ./cache_v15/train_00005.npz X=(667, 120) saved in 284.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=6 -> ./cache_v15/train_00006.npz X=(601, 120) saved in 289.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=7 -> ./cache_v15/train_00007.npz X=(562, 120) saved in 291.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=8 -> ./cache_v15/train_00008.npz X=(596, 120) saved in 292.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=9 -> ./cache_v15/train_00009.npz X=(610, 120) saved in 297.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=10 -> ./cache_v15/train_00010.npz X=(613, 120) saved in 300.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=11 -> ./cache_v15/train_00011.npz X=(571, 120) saved in 303.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=12 -> ./cache_v15/train_00012.npz X=(592, 120) saved in 304.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=13 -> ./cache_v15/train_00013.npz X=(608, 120) saved in 312.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=14 -> ./cache_v15/train_00014.npz X=(623, 120) saved in 308.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=15 -> ./cache_v15/train_00015.npz X=(650, 120) saved in 314.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=16 -> ./cache_v15/train_00016.npz X=(585, 120) saved in 319.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=17 -> ./cache_v15/train_00017.npz X=(584, 120) saved in 319.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=18 -> ./cache_v15/train_00018.npz X=(593, 120) saved in 322.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=19 -> ./cache_v15/train_00019.npz X=(605, 120) saved in 322.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=20 -> ./cache_v15/train_00020.npz X=(589, 120) saved in 326.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=21 -> ./cache_v15/train_00021.npz X=(552, 120) saved in 325.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 20/297 done; elapsed 623.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=22 -> ./cache_v15/train_00022.npz X=(787, 120) saved in 328.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=23 -> ./cache_v15/train_00023.npz X=(741, 120) saved in 329.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=24 -> ./cache_v15/train_00024.npz X=(745, 120) saved in 337.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=25 -> ./cache_v15/train_00025.npz X=(591, 120) saved in 336.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=26 -> ./cache_v15/train_00026.npz X=(560, 120) saved in 337.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=27 -> ./cache_v15/train_00027.npz X=(596, 120) saved in 337.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=28 -> ./cache_v15/train_00028.npz X=(637, 120) saved in 343.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=29 -> ./cache_v15/train_00029.npz X=(578, 120) saved in 346.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=30 -> ./cache_v15/train_00030.npz X=(632, 120) saved in 349.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=31 -> ./cache_v15/train_00031.npz X=(668, 120) saved in 352.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=32 -> ./cache_v15/train_00032.npz X=(646, 120) saved in 352.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=33 -> ./cache_v15/train_00033.npz X=(601, 120) saved in 355.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=34 -> ./cache_v15/train_00034.npz X=(612, 120) saved in 356.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=35 -> ./cache_v15/train_00035.npz X=(670, 120) saved in 358.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=36 -> ./cache_v15/train_00036.npz X=(599, 120) saved in 360.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=37 -> ./cache_v15/train_00037.npz X=(627, 120) saved in 387.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=38 -> ./cache_v15/train_00038.npz X=(573, 120) saved in 366.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=39 -> ./cache_v15/train_00039.npz X=(562, 120) saved in 367.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=40 -> ./cache_v15/train_00040.npz X=(549, 120) saved in 372.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=41 -> ./cache_v15/train_00041.npz X=(916, 120) saved in 375.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 40/297 done; elapsed 1325.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=42 -> ./cache_v15/train_00042.npz X=(816, 120) saved in 378.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=43 -> ./cache_v15/train_00043.npz X=(833, 120) saved in 384.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=44 -> ./cache_v15/train_00044.npz X=(768, 120) saved in 390.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=45 -> ./cache_v15/train_00045.npz X=(853, 120) saved in 391.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=46 -> ./cache_v15/train_00046.npz X=(824, 120) saved in 393.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=47 -> ./cache_v15/train_00047.npz X=(834, 120) saved in 400.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=48 -> ./cache_v15/train_00048.npz X=(823, 120) saved in 405.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=49 -> ./cache_v15/train_00049.npz X=(844, 120) saved in 411.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=50 -> ./cache_v15/train_00050.npz X=(804, 120) saved in 414.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=51 -> ./cache_v15/train_00051.npz X=(841, 120) saved in 415.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=52 -> ./cache_v15/train_00052.npz X=(781, 120) saved in 423.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=53 -> ./cache_v15/train_00053.npz X=(873, 120) saved in 429.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=54 -> ./cache_v15/train_00054.npz X=(804, 120) saved in 434.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=55 -> ./cache_v15/train_00055.npz X=(844, 120) saved in 433.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=56 -> ./cache_v15/train_00056.npz X=(773, 120) saved in 438.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=57 -> ./cache_v15/train_00057.npz X=(646, 120) saved in 445.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=58 -> ./cache_v15/train_00058.npz X=(636, 120) saved in 444.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=59 -> ./cache_v15/train_00059.npz X=(613, 120) saved in 450.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=60 -> ./cache_v15/train_00060.npz X=(663, 120) saved in 457.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=61 -> ./cache_v15/train_00061.npz X=(655, 120) saved in 456.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 60/297 done; elapsed 1905.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=62 -> ./cache_v15/train_00062.npz X=(653, 120) saved in 457.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=63 -> ./cache_v15/train_00063.npz X=(646, 120) saved in 460.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=64 -> ./cache_v15/train_00064.npz X=(644, 120) saved in 463.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=65 -> ./cache_v15/train_00065.npz X=(617, 120) saved in 466.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=66 -> ./cache_v15/train_00066.npz X=(629, 120) saved in 476.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=67 -> ./cache_v15/train_00067.npz X=(564, 120) saved in 473.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=68 -> ./cache_v15/train_00068.npz X=(565, 120) saved in 470.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=69 -> ./cache_v15/train_00069.npz X=(590, 120) saved in 476.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=70 -> ./cache_v15/train_00070.npz X=(668, 120) saved in 481.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=71 -> ./cache_v15/train_00071.npz X=(830, 120) saved in 484.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=72 -> ./cache_v15/train_00072.npz X=(810, 120) saved in 488.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=73 -> ./cache_v15/train_00073.npz X=(791, 120) saved in 492.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=74 -> ./cache_v15/train_00074.npz X=(805, 120) saved in 495.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=75 -> ./cache_v15/train_00075.npz X=(810, 120) saved in 498.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=76 -> ./cache_v15/train_00076.npz X=(745, 120) saved in 503.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=77 -> ./cache_v15/train_00077.npz X=(823, 120) saved in 538.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=78 -> ./cache_v15/train_00078.npz X=(817, 120) saved in 516.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=79 -> ./cache_v15/train_00079.npz X=(836, 120) saved in 517.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=80 -> ./cache_v15/train_00080.npz X=(858, 120) saved in 520.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=81 -> ./cache_v15/train_00081.npz X=(643, 120) saved in 523.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 80/297 done; elapsed 2816.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=82 -> ./cache_v15/train_00082.npz X=(685, 120) saved in 521.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=83 -> ./cache_v15/train_00083.npz X=(587, 120) saved in 526.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=84 -> ./cache_v15/train_00084.npz X=(717, 120) saved in 532.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=85 -> ./cache_v15/train_00085.npz X=(522, 120) saved in 529.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=86 -> ./cache_v15/train_00086.npz X=(643, 120) saved in 532.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=87 -> ./cache_v15/train_00087.npz X=(661, 120) saved in 532.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=88 -> ./cache_v15/train_00088.npz X=(623, 120) saved in 535.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=89 -> ./cache_v15/train_00089.npz X=(605, 120) saved in 537.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=90 -> ./cache_v15/train_00090.npz X=(601, 120) saved in 535.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=91 -> ./cache_v15/train_00091.npz X=(653, 120) saved in 537.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=92 -> ./cache_v15/train_00092.npz X=(599, 120) saved in 538.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=101 -> ./cache_v15/train_00101.npz X=(643, 120) saved in 112.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=93 -> ./cache_v15/train_00093.npz X=(586, 120) saved in 544.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=94 -> ./cache_v15/train_00094.npz X=(641, 120) saved in 544.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=95 -> ./cache_v15/train_00095.npz X=(687, 120) saved in 545.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=102 -> ./cache_v15/train_00102.npz X=(640, 120) saved in 114.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=103 -> ./cache_v15/train_00103.npz X=(578, 120) saved in 113.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=104 -> ./cache_v15/train_00104.npz X=(644, 120) saved in 115.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=96 -> ./cache_v15/train_00096.npz X=(541, 120) saved in 550.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=105 -> ./cache_v15/train_00105.npz X=(632, 120) saved in 115.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 100/297 done; elapsed 3445.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=106 -> ./cache_v15/train_00106.npz X=(586, 120) saved in 117.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=97 -> ./cache_v15/train_00097.npz X=(522, 120) saved in 552.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=107 -> ./cache_v15/train_00107.npz X=(643, 120) saved in 118.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=108 -> ./cache_v15/train_00108.npz X=(630, 120) saved in 119.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=109 -> ./cache_v15/train_00109.npz X=(627, 120) saved in 121.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=110 -> ./cache_v15/train_00110.npz X=(647, 120) saved in 123.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=111 -> ./cache_v15/train_00111.npz X=(660, 120) saved in 122.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=112 -> ./cache_v15/train_00112.npz X=(632, 120) saved in 124.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=113 -> ./cache_v15/train_00113.npz X=(621, 120) saved in 125.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=114 -> ./cache_v15/train_00114.npz X=(652, 120) saved in 127.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=115 -> ./cache_v15/train_00115.npz X=(583, 120) saved in 128.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=116 -> ./cache_v15/train_00116.npz X=(560, 120) saved in 130.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=117 -> ./cache_v15/train_00117.npz X=(619, 120) saved in 130.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=118 -> ./cache_v15/train_00118.npz X=(625, 120) saved in 130.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=119 -> ./cache_v15/train_00119.npz X=(643, 120) saved in 132.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=120 -> ./cache_v15/train_00120.npz X=(610, 120) saved in 135.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=121 -> ./cache_v15/train_00121.npz X=(574, 120) saved in 136.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=122 -> ./cache_v15/train_00122.npz X=(582, 120) saved in 135.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=123 -> ./cache_v15/train_00123.npz X=(666, 120) saved in 137.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=124 -> ./cache_v15/train_00124.npz X=(651, 120) saved in 137.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 120/297 done; elapsed 3710.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=98 -> ./cache_v15/train_00098.npz X=(622, 120) saved in 549.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=125 -> ./cache_v15/train_00125.npz X=(615, 120) saved in 139.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=126 -> ./cache_v15/train_00126.npz X=(621, 120) saved in 138.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=99 -> ./cache_v15/train_00099.npz X=(562, 120) saved in 549.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=127 -> ./cache_v15/train_00127.npz X=(532, 120) saved in 142.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=128 -> ./cache_v15/train_00128.npz X=(602, 120) saved in 142.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=129 -> ./cache_v15/train_00129.npz X=(603, 120) saved in 144.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=130 -> ./cache_v15/train_00130.npz X=(674, 120) saved in 146.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=131 -> ./cache_v15/train_00131.npz X=(601, 120) saved in 149.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=132 -> ./cache_v15/train_00132.npz X=(643, 120) saved in 149.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=133 -> ./cache_v15/train_00133.npz X=(581, 120) saved in 147.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=134 -> ./cache_v15/train_00134.npz X=(638, 120) saved in 149.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=135 -> ./cache_v15/train_00135.npz X=(606, 120) saved in 150.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=136 -> ./cache_v15/train_00136.npz X=(637, 120) saved in 152.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=137 -> ./cache_v15/train_00137.npz X=(663, 120) saved in 153.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=138 -> ./cache_v15/train_00138.npz X=(672, 120) saved in 156.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=139 -> ./cache_v15/train_00139.npz X=(671, 120) saved in 157.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=140 -> ./cache_v15/train_00140.npz X=(592, 120) saved in 158.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=141 -> ./cache_v15/train_00141.npz X=(591, 120) saved in 158.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=142 -> ./cache_v15/train_00142.npz X=(584, 120) saved in 158.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 140/297 done; elapsed 3975.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=143 -> ./cache_v15/train_00143.npz X=(613, 120) saved in 163.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=144 -> ./cache_v15/train_00144.npz X=(507, 120) saved in 162.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=145 -> ./cache_v15/train_00145.npz X=(630, 120) saved in 163.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=146 -> ./cache_v15/train_00146.npz X=(605, 120) saved in 162.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=147 -> ./cache_v15/train_00147.npz X=(603, 120) saved in 166.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=148 -> ./cache_v15/train_00148.npz X=(552, 120) saved in 169.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=149 -> ./cache_v15/train_00149.npz X=(609, 120) saved in 169.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=150 -> ./cache_v15/train_00150.npz X=(577, 120) saved in 169.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=151 -> ./cache_v15/train_00151.npz X=(602, 120) saved in 169.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=152 -> ./cache_v15/train_00152.npz X=(601, 120) saved in 171.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=153 -> ./cache_v15/train_00153.npz X=(598, 120) saved in 173.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=154 -> ./cache_v15/train_00154.npz X=(591, 120) saved in 172.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=155 -> ./cache_v15/train_00155.npz X=(596, 120) saved in 174.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=156 -> ./cache_v15/train_00156.npz X=(572, 120) saved in 178.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=157 -> ./cache_v15/train_00157.npz X=(603, 120) saved in 178.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=158 -> ./cache_v15/train_00158.npz X=(632, 120) saved in 177.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=159 -> ./cache_v15/train_00159.npz X=(545, 120) saved in 180.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=160 -> ./cache_v15/train_00160.npz X=(617, 120) saved in 181.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=161 -> ./cache_v15/train_00161.npz X=(596, 120) saved in 182.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=162 -> ./cache_v15/train_00162.npz X=(562, 120) saved in 181.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 160/297 done; elapsed 4258.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=163 -> ./cache_v15/train_00163.npz X=(560, 120) saved in 183.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=164 -> ./cache_v15/train_00164.npz X=(642, 120) saved in 184.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=165 -> ./cache_v15/train_00165.npz X=(568, 120) saved in 187.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=166 -> ./cache_v15/train_00166.npz X=(616, 120) saved in 189.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=167 -> ./cache_v15/train_00167.npz X=(577, 120) saved in 191.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=168 -> ./cache_v15/train_00168.npz X=(553, 120) saved in 192.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=169 -> ./cache_v15/train_00169.npz X=(605, 120) saved in 190.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=170 -> ./cache_v15/train_00170.npz X=(640, 120) saved in 190.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=171 -> ./cache_v15/train_00171.npz X=(615, 120) saved in 191.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=172 -> ./cache_v15/train_00172.npz X=(540, 120) saved in 196.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=173 -> ./cache_v15/train_00173.npz X=(611, 120) saved in 193.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=174 -> ./cache_v15/train_00174.npz X=(565, 120) saved in 194.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=175 -> ./cache_v15/train_00175.npz X=(566, 120) saved in 196.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=176 -> ./cache_v15/train_00176.npz X=(670, 120) saved in 194.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=177 -> ./cache_v15/train_00177.npz X=(670, 120) saved in 198.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=178 -> ./cache_v15/train_00178.npz X=(616, 120) saved in 198.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=179 -> ./cache_v15/train_00179.npz X=(522, 120) saved in 201.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=180 -> ./cache_v15/train_00180.npz X=(647, 120) saved in 204.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=181 -> ./cache_v15/train_00181.npz X=(577, 120) saved in 200.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=182 -> ./cache_v15/train_00182.npz X=(611, 120) saved in 204.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 180/297 done; elapsed 4595.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=183 -> ./cache_v15/train_00183.npz X=(650, 120) saved in 202.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=184 -> ./cache_v15/train_00184.npz X=(627, 120) saved in 208.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=185 -> ./cache_v15/train_00185.npz X=(637, 120) saved in 205.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=186 -> ./cache_v15/train_00186.npz X=(549, 120) saved in 210.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=187 -> ./cache_v15/train_00187.npz X=(598, 120) saved in 209.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=188 -> ./cache_v15/train_00188.npz X=(564, 120) saved in 209.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=189 -> ./cache_v15/train_00189.npz X=(581, 120) saved in 212.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=190 -> ./cache_v15/train_00190.npz X=(690, 120) saved in 210.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=191 -> ./cache_v15/train_00191.npz X=(655, 120) saved in 216.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=192 -> ./cache_v15/train_00192.npz X=(607, 120) saved in 212.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=193 -> ./cache_v15/train_00193.npz X=(590, 120) saved in 214.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=194 -> ./cache_v15/train_00194.npz X=(623, 120) saved in 217.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=200 -> ./cache_v15/train_00200.npz X=(574, 120) saved in 145.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=195 -> ./cache_v15/train_00195.npz X=(593, 120) saved in 216.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=196 -> ./cache_v15/train_00196.npz X=(620, 120) saved in 216.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=201 -> ./cache_v15/train_00201.npz X=(585, 120) saved in 147.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=197 -> ./cache_v15/train_00197.npz X=(591, 120) saved in 221.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=198 -> ./cache_v15/train_00198.npz X=(639, 120) saved in 220.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=199 -> ./cache_v15/train_00199.npz X=(615, 120) saved in 222.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=202 -> ./cache_v15/train_00202.npz X=(595, 120) saved in 151.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 200/297 done; elapsed 4896.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=203 -> ./cache_v15/train_00203.npz X=(636, 120) saved in 151.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=204 -> ./cache_v15/train_00204.npz X=(628, 120) saved in 152.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=205 -> ./cache_v15/train_00205.npz X=(609, 120) saved in 153.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=206 -> ./cache_v15/train_00206.npz X=(588, 120) saved in 154.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=207 -> ./cache_v15/train_00207.npz X=(606, 120) saved in 155.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=208 -> ./cache_v15/train_00208.npz X=(608, 120) saved in 155.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=209 -> ./cache_v15/train_00209.npz X=(689, 120) saved in 158.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=210 -> ./cache_v15/train_00210.npz X=(587, 120) saved in 159.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=211 -> ./cache_v15/train_00211.npz X=(692, 120) saved in 161.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=212 -> ./cache_v15/train_00212.npz X=(590, 120) saved in 161.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=213 -> ./cache_v15/train_00213.npz X=(601, 120) saved in 164.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=214 -> ./cache_v15/train_00214.npz X=(585, 120) saved in 164.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=215 -> ./cache_v15/train_00215.npz X=(613, 120) saved in 166.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=216 -> ./cache_v15/train_00216.npz X=(618, 120) saved in 167.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=217 -> ./cache_v15/train_00217.npz X=(606, 120) saved in 165.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=218 -> ./cache_v15/train_00218.npz X=(548, 120) saved in 169.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=219 -> ./cache_v15/train_00219.npz X=(617, 120) saved in 168.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=220 -> ./cache_v15/train_00220.npz X=(573, 120) saved in 170.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=221 -> ./cache_v15/train_00221.npz X=(595, 120) saved in 175.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=222 -> ./cache_v15/train_00222.npz X=(627, 120) saved in 175.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 220/297 done; elapsed 5208.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=223 -> ./cache_v15/train_00223.npz X=(565, 120) saved in 173.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=224 -> ./cache_v15/train_00224.npz X=(567, 120) saved in 178.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=225 -> ./cache_v15/train_00225.npz X=(524, 120) saved in 181.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=226 -> ./cache_v15/train_00226.npz X=(563, 120) saved in 182.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=227 -> ./cache_v15/train_00227.npz X=(616, 120) saved in 187.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=228 -> ./cache_v15/train_00228.npz X=(573, 120) saved in 186.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=229 -> ./cache_v15/train_00229.npz X=(640, 120) saved in 189.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=230 -> ./cache_v15/train_00230.npz X=(606, 120) saved in 190.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=231 -> ./cache_v15/train_00231.npz X=(622, 120) saved in 194.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=232 -> ./cache_v15/train_00232.npz X=(647, 120) saved in 197.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=233 -> ./cache_v15/train_00233.npz X=(684, 120) saved in 199.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=234 -> ./cache_v15/train_00234.npz X=(606, 120) saved in 202.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=235 -> ./cache_v15/train_00235.npz X=(621, 120) saved in 204.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=236 -> ./cache_v15/train_00236.npz X=(579, 120) saved in 204.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=237 -> ./cache_v15/train_00237.npz X=(631, 120) saved in 209.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=238 -> ./cache_v15/train_00238.npz X=(645, 120) saved in 212.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=239 -> ./cache_v15/train_00239.npz X=(600, 120) saved in 214.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=240 -> ./cache_v15/train_00240.npz X=(665, 120) saved in 217.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=241 -> ./cache_v15/train_00241.npz X=(661, 120) saved in 219.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=242 -> ./cache_v15/train_00242.npz X=(590, 120) saved in 222.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 240/297 done; elapsed 5549.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=243 -> ./cache_v15/train_00243.npz X=(576, 120) saved in 219.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=244 -> ./cache_v15/train_00244.npz X=(606, 120) saved in 223.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=245 -> ./cache_v15/train_00245.npz X=(613, 120) saved in 225.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=246 -> ./cache_v15/train_00246.npz X=(599, 120) saved in 226.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=247 -> ./cache_v15/train_00247.npz X=(603, 120) saved in 229.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=248 -> ./cache_v15/train_00248.npz X=(622, 120) saved in 228.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=249 -> ./cache_v15/train_00249.npz X=(625, 120) saved in 230.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=250 -> ./cache_v15/train_00250.npz X=(606, 120) saved in 230.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=251 -> ./cache_v15/train_00251.npz X=(706, 120) saved in 232.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=252 -> ./cache_v15/train_00252.npz X=(717, 120) saved in 235.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=253 -> ./cache_v15/train_00253.npz X=(836, 120) saved in 236.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=254 -> ./cache_v15/train_00254.npz X=(616, 120) saved in 237.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=255 -> ./cache_v15/train_00255.npz X=(620, 120) saved in 239.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=256 -> ./cache_v15/train_00256.npz X=(619, 120) saved in 240.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=257 -> ./cache_v15/train_00257.npz X=(545, 120) saved in 240.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=258 -> ./cache_v15/train_00258.npz X=(549, 120) saved in 243.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=259 -> ./cache_v15/train_00259.npz X=(584, 120) saved in 243.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=260 -> ./cache_v15/train_00260.npz X=(587, 120) saved in 239.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=261 -> ./cache_v15/train_00261.npz X=(585, 120) saved in 243.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=262 -> ./cache_v15/train_00262.npz X=(660, 120) saved in 247.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 260/297 done; elapsed 5934.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=263 -> ./cache_v15/train_00263.npz X=(604, 120) saved in 246.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=264 -> ./cache_v15/train_00264.npz X=(605, 120) saved in 247.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=265 -> ./cache_v15/train_00265.npz X=(647, 120) saved in 246.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=266 -> ./cache_v15/train_00266.npz X=(603, 120) saved in 249.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=267 -> ./cache_v15/train_00267.npz X=(690, 120) saved in 248.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=268 -> ./cache_v15/train_00268.npz X=(645, 120) saved in 248.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=269 -> ./cache_v15/train_00269.npz X=(606, 120) saved in 253.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=270 -> ./cache_v15/train_00270.npz X=(616, 120) saved in 254.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=271 -> ./cache_v15/train_00271.npz X=(530, 120) saved in 252.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=272 -> ./cache_v15/train_00272.npz X=(716, 120) saved in 254.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=273 -> ./cache_v15/train_00273.npz X=(808, 120) saved in 258.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=274 -> ./cache_v15/train_00274.npz X=(748, 120) saved in 258.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=275 -> ./cache_v15/train_00275.npz X=(577, 120) saved in 261.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=276 -> ./cache_v15/train_00276.npz X=(517, 120) saved in 262.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=277 -> ./cache_v15/train_00277.npz X=(577, 120) saved in 262.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=278 -> ./cache_v15/train_00278.npz X=(613, 120) saved in 265.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=279 -> ./cache_v15/train_00279.npz X=(573, 120) saved in 266.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=280 -> ./cache_v15/train_00280.npz X=(628, 120) saved in 268.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=281 -> ./cache_v15/train_00281.npz X=(577, 120) saved in 270.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=282 -> ./cache_v15/train_00282.npz X=(573, 120) saved in 270.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: 280/297 done; elapsed 6406.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=283 -> ./cache_v15/train_00283.npz X=(632, 120) saved in 273.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=284 -> ./cache_v15/train_00284.npz X=(585, 120) saved in 272.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=285 -> ./cache_v15/train_00285.npz X=(593, 120) saved in 273.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=286 -> ./cache_v15/train_00286.npz X=(624, 120) saved in 273.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=287 -> ./cache_v15/train_00287.npz X=(586, 120) saved in 277.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=288 -> ./cache_v15/train_00288.npz X=(652, 120) saved in 278.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=289 -> ./cache_v15/train_00289.npz X=(603, 120) saved in 278.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=290 -> ./cache_v15/train_00290.npz X=(605, 120) saved in 275.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=291 -> ./cache_v15/train_00291.npz X=(569, 120) saved in 273.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=292 -> ./cache_v15/train_00292.npz X=(569, 120) saved in 264.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=293 -> ./cache_v15/train_00293.npz X=(575, 120) saved in 253.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=294 -> ./cache_v15/train_00294.npz X=(549, 120) saved in 242.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=295 -> ./cache_v15/train_00295.npz X=(610, 120) saved in 239.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=296 -> ./cache_v15/train_00296.npz X=(581, 120) saved in 234.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=297 -> ./cache_v15/train_00297.npz X=(530, 120) saved in 208.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=298 -> ./cache_v15/train_00298.npz X=(596, 120) saved in 194.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] train id=299 -> ./cache_v15/train_00299.npz X=(576, 120) saved in 154.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] train: completed 297 in 6662.2s\n[RUN V1.5] Parallel caching VAL (stride=2)...\n[ParCacheV15] val: 287/287 remaining.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=410 -> ./cache_v15/val_00410.npz X=(612, 120) saved in 185.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=411 -> ./cache_v15/val_00411.npz X=(667, 120) saved in 187.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=412 -> ./cache_v15/val_00412.npz X=(600, 120) saved in 189.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=413 -> ./cache_v15/val_00413.npz X=(644, 120) saved in 191.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=414 -> ./cache_v15/val_00414.npz X=(669, 120) saved in 193.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=415 -> ./cache_v15/val_00415.npz X=(665, 120) saved in 196.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=416 -> ./cache_v15/val_00416.npz X=(658, 120) saved in 197.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=418 -> ./cache_v15/val_00418.npz X=(646, 120) saved in 198.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=417 -> ./cache_v15/val_00417.npz X=(661, 120) saved in 200.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=420 -> ./cache_v15/val_00420.npz X=(650, 120) saved in 205.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=421 -> ./cache_v15/val_00421.npz X=(674, 120) saved in 207.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=422 -> ./cache_v15/val_00422.npz X=(662, 120) saved in 209.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=423 -> ./cache_v15/val_00423.npz X=(621, 120) saved in 214.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=424 -> ./cache_v15/val_00424.npz X=(636, 120) saved in 213.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=425 -> ./cache_v15/val_00425.npz X=(664, 120) saved in 215.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=426 -> ./cache_v15/val_00426.npz X=(674, 120) saved in 217.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=427 -> ./cache_v15/val_00427.npz X=(680, 120) saved in 219.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=430 -> ./cache_v15/val_00430.npz X=(658, 120) saved in 217.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=428 -> ./cache_v15/val_00428.npz X=(660, 120) saved in 219.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=429 -> ./cache_v15/val_00429.npz X=(695, 120) saved in 224.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 20/287 done; elapsed 421.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=431 -> ./cache_v15/val_00431.npz X=(619, 120) saved in 227.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=432 -> ./cache_v15/val_00432.npz X=(608, 120) saved in 230.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=433 -> ./cache_v15/val_00433.npz X=(650, 120) saved in 231.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=434 -> ./cache_v15/val_00434.npz X=(640, 120) saved in 232.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=435 -> ./cache_v15/val_00435.npz X=(615, 120) saved in 231.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=436 -> ./cache_v15/val_00436.npz X=(638, 120) saved in 236.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=437 -> ./cache_v15/val_00437.npz X=(641, 120) saved in 235.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=438 -> ./cache_v15/val_00438.npz X=(638, 120) saved in 241.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=440 -> ./cache_v15/val_00440.npz X=(637, 120) saved in 235.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=439 -> ./cache_v15/val_00439.npz X=(609, 120) saved in 241.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=441 -> ./cache_v15/val_00441.npz X=(639, 120) saved in 247.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=442 -> ./cache_v15/val_00442.npz X=(623, 120) saved in 248.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=443 -> ./cache_v15/val_00443.npz X=(656, 120) saved in 249.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=445 -> ./cache_v15/val_00445.npz X=(629, 120) saved in 246.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=444 -> ./cache_v15/val_00444.npz X=(637, 120) saved in 252.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=446 -> ./cache_v15/val_00446.npz X=(643, 120) saved in 255.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=447 -> ./cache_v15/val_00447.npz X=(656, 120) saved in 257.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=448 -> ./cache_v15/val_00448.npz X=(645, 120) saved in 261.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=449 -> ./cache_v15/val_00449.npz X=(661, 120) saved in 263.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=451 -> ./cache_v15/val_00451.npz X=(647, 120) saved in 257.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 40/287 done; elapsed 908.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=450 -> ./cache_v15/val_00450.npz X=(658, 120) saved in 264.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=452 -> ./cache_v15/val_00452.npz X=(638, 120) saved in 269.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=453 -> ./cache_v15/val_00453.npz X=(657, 120) saved in 269.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=454 -> ./cache_v15/val_00454.npz X=(580, 120) saved in 273.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=455 -> ./cache_v15/val_00455.npz X=(661, 120) saved in 273.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=456 -> ./cache_v15/val_00456.npz X=(665, 120) saved in 272.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=457 -> ./cache_v15/val_00457.npz X=(674, 120) saved in 275.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=458 -> ./cache_v15/val_00458.npz X=(590, 120) saved in 277.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=459 -> ./cache_v15/val_00459.npz X=(649, 120) saved in 276.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=460 -> ./cache_v15/val_00460.npz X=(613, 120) saved in 278.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=461 -> ./cache_v15/val_00461.npz X=(670, 120) saved in 282.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=462 -> ./cache_v15/val_00462.npz X=(618, 120) saved in 281.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=463 -> ./cache_v15/val_00463.npz X=(668, 120) saved in 281.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=464 -> ./cache_v15/val_00464.npz X=(624, 120) saved in 286.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=465 -> ./cache_v15/val_00465.npz X=(614, 120) saved in 290.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=466 -> ./cache_v15/val_00466.npz X=(661, 120) saved in 287.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=467 -> ./cache_v15/val_00467.npz X=(700, 120) saved in 291.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=468 -> ./cache_v15/val_00468.npz X=(634, 120) saved in 289.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=469 -> ./cache_v15/val_00469.npz X=(664, 120) saved in 299.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=470 -> ./cache_v15/val_00470.npz X=(626, 120) saved in 290.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 60/287 done; elapsed 1265.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=471 -> ./cache_v15/val_00471.npz X=(650, 120) saved in 298.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=472 -> ./cache_v15/val_00472.npz X=(613, 120) saved in 300.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=473 -> ./cache_v15/val_00473.npz X=(616, 120) saved in 302.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=474 -> ./cache_v15/val_00474.npz X=(620, 120) saved in 302.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=475 -> ./cache_v15/val_00475.npz X=(592, 120) saved in 308.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=476 -> ./cache_v15/val_00476.npz X=(610, 120) saved in 308.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=477 -> ./cache_v15/val_00477.npz X=(624, 120) saved in 311.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=478 -> ./cache_v15/val_00478.npz X=(638, 120) saved in 311.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=479 -> ./cache_v15/val_00479.npz X=(613, 120) saved in 313.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=480 -> ./cache_v15/val_00480.npz X=(606, 120) saved in 314.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=481 -> ./cache_v15/val_00481.npz X=(649, 120) saved in 318.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=482 -> ./cache_v15/val_00482.npz X=(626, 120) saved in 319.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=483 -> ./cache_v15/val_00483.npz X=(594, 120) saved in 318.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=484 -> ./cache_v15/val_00484.npz X=(638, 120) saved in 321.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=485 -> ./cache_v15/val_00485.npz X=(626, 120) saved in 323.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=486 -> ./cache_v15/val_00486.npz X=(650, 120) saved in 323.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=487 -> ./cache_v15/val_00487.npz X=(645, 120) saved in 327.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=488 -> ./cache_v15/val_00488.npz X=(622, 120) saved in 330.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=489 -> ./cache_v15/val_00489.npz X=(597, 120) saved in 333.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=490 -> ./cache_v15/val_00490.npz X=(631, 120) saved in 332.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 80/287 done; elapsed 1875.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=491 -> ./cache_v15/val_00491.npz X=(660, 120) saved in 334.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=492 -> ./cache_v15/val_00492.npz X=(606, 120) saved in 335.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=493 -> ./cache_v15/val_00493.npz X=(630, 120) saved in 337.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=494 -> ./cache_v15/val_00494.npz X=(650, 120) saved in 339.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15][ERR] val id=500: Sample zip for id 500 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15][ERR] val id=501: Sample zip for id 501 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15][ERR] val id=502: Sample zip for id 502 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15][ERR] val id=503: Sample zip for id 503 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15][ERR] val id=504: Sample zip for id 504 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=495 -> ./cache_v15/val_00495.npz X=(599, 120) saved in 340.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15][ERR] val id=505: Sample zip for id 505 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15][ERR] val id=506: Sample zip for id 506 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=496 -> ./cache_v15/val_00496.npz X=(630, 120) saved in 345.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=497 -> ./cache_v15/val_00497.npz X=(625, 120) saved in 344.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=498 -> ./cache_v15/val_00498.npz X=(617, 120) saved in 348.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=499 -> ./cache_v15/val_00499.npz X=(627, 120) saved in 347.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15][ERR] val id=507: Sample zip for id 507 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15][ERR] val id=508: Sample zip for id 508 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15][ERR] val id=509: Sample zip for id 509 not found in tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=510 -> ./cache_v15/val_00510.npz X=(633, 120) saved in 217.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 100/287 done; elapsed 2324.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=516 -> ./cache_v15/val_00516.npz X=(602, 120) saved in 220.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=517 -> ./cache_v15/val_00517.npz X=(615, 120) saved in 221.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=518 -> ./cache_v15/val_00518.npz X=(645, 120) saved in 226.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=519 -> ./cache_v15/val_00519.npz X=(609, 120) saved in 227.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=520 -> ./cache_v15/val_00520.npz X=(621, 120) saved in 238.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=521 -> ./cache_v15/val_00521.npz X=(599, 120) saved in 229.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=522 -> ./cache_v15/val_00522.npz X=(634, 120) saved in 232.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=523 -> ./cache_v15/val_00523.npz X=(651, 120) saved in 233.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=524 -> ./cache_v15/val_00524.npz X=(597, 120) saved in 233.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=525 -> ./cache_v15/val_00525.npz X=(622, 120) saved in 235.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=526 -> ./cache_v15/val_00526.npz X=(636, 120) saved in 238.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=527 -> ./cache_v15/val_00527.npz X=(631, 120) saved in 240.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=528 -> ./cache_v15/val_00528.npz X=(593, 120) saved in 243.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=529 -> ./cache_v15/val_00529.npz X=(589, 120) saved in 241.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=530 -> ./cache_v15/val_00530.npz X=(618, 120) saved in 244.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=531 -> ./cache_v15/val_00531.npz X=(588, 120) saved in 243.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=532 -> ./cache_v15/val_00532.npz X=(637, 120) saved in 246.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=533 -> ./cache_v15/val_00533.npz X=(618, 120) saved in 249.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=534 -> ./cache_v15/val_00534.npz X=(626, 120) saved in 251.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=535 -> ./cache_v15/val_00535.npz X=(629, 120) saved in 252.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 120/287 done; elapsed 2666.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=536 -> ./cache_v15/val_00536.npz X=(596, 120) saved in 254.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=537 -> ./cache_v15/val_00537.npz X=(643, 120) saved in 256.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=538 -> ./cache_v15/val_00538.npz X=(632, 120) saved in 256.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=539 -> ./cache_v15/val_00539.npz X=(575, 120) saved in 257.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=541 -> ./cache_v15/val_00541.npz X=(586, 120) saved in 261.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=542 -> ./cache_v15/val_00542.npz X=(609, 120) saved in 261.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=543 -> ./cache_v15/val_00543.npz X=(631, 120) saved in 263.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=544 -> ./cache_v15/val_00544.npz X=(634, 120) saved in 265.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=545 -> ./cache_v15/val_00545.npz X=(606, 120) saved in 265.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=546 -> ./cache_v15/val_00546.npz X=(602, 120) saved in 267.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=547 -> ./cache_v15/val_00547.npz X=(634, 120) saved in 269.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=548 -> ./cache_v15/val_00548.npz X=(615, 120) saved in 274.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=549 -> ./cache_v15/val_00549.npz X=(625, 120) saved in 271.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=550 -> ./cache_v15/val_00550.npz X=(631, 120) saved in 273.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=552 -> ./cache_v15/val_00552.npz X=(828, 120) saved in 276.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=553 -> ./cache_v15/val_00553.npz X=(813, 120) saved in 279.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=554 -> ./cache_v15/val_00554.npz X=(838, 120) saved in 283.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=555 -> ./cache_v15/val_00555.npz X=(826, 120) saved in 284.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=556 -> ./cache_v15/val_00556.npz X=(839, 120) saved in 286.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=557 -> ./cache_v15/val_00557.npz X=(820, 120) saved in 290.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 140/287 done; elapsed 3168.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=559 -> ./cache_v15/val_00559.npz X=(823, 120) saved in 295.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=558 -> ./cache_v15/val_00558.npz X=(815, 120) saved in 305.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=560 -> ./cache_v15/val_00560.npz X=(815, 120) saved in 300.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=561 -> ./cache_v15/val_00561.npz X=(826, 120) saved in 304.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=562 -> ./cache_v15/val_00562.npz X=(834, 120) saved in 304.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=563 -> ./cache_v15/val_00563.npz X=(818, 120) saved in 307.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=564 -> ./cache_v15/val_00564.npz X=(838, 120) saved in 308.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=565 -> ./cache_v15/val_00565.npz X=(831, 120) saved in 312.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=566 -> ./cache_v15/val_00566.npz X=(825, 120) saved in 317.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=567 -> ./cache_v15/val_00567.npz X=(832, 120) saved in 318.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=568 -> ./cache_v15/val_00568.npz X=(827, 120) saved in 321.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=569 -> ./cache_v15/val_00569.npz X=(846, 120) saved in 319.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=570 -> ./cache_v15/val_00570.npz X=(823, 120) saved in 323.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=571 -> ./cache_v15/val_00571.npz X=(831, 120) saved in 336.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=572 -> ./cache_v15/val_00572.npz X=(824, 120) saved in 329.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=573 -> ./cache_v15/val_00573.npz X=(836, 120) saved in 333.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=574 -> ./cache_v15/val_00574.npz X=(826, 120) saved in 334.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=575 -> ./cache_v15/val_00575.npz X=(837, 120) saved in 337.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=576 -> ./cache_v15/val_00576.npz X=(819, 120) saved in 337.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=577 -> ./cache_v15/val_00577.npz X=(842, 120) saved in 343.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 160/287 done; elapsed 3757.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=578 -> ./cache_v15/val_00578.npz X=(837, 120) saved in 343.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=579 -> ./cache_v15/val_00579.npz X=(833, 120) saved in 346.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=580 -> ./cache_v15/val_00580.npz X=(833, 120) saved in 346.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=581 -> ./cache_v15/val_00581.npz X=(834, 120) saved in 348.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=582 -> ./cache_v15/val_00582.npz X=(815, 120) saved in 349.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=583 -> ./cache_v15/val_00583.npz X=(818, 120) saved in 351.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=584 -> ./cache_v15/val_00584.npz X=(843, 120) saved in 355.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=585 -> ./cache_v15/val_00585.npz X=(856, 120) saved in 359.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=586 -> ./cache_v15/val_00586.npz X=(820, 120) saved in 360.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=587 -> ./cache_v15/val_00587.npz X=(842, 120) saved in 362.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=588 -> ./cache_v15/val_00588.npz X=(841, 120) saved in 363.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=589 -> ./cache_v15/val_00589.npz X=(826, 120) saved in 367.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=590 -> ./cache_v15/val_00590.npz X=(842, 120) saved in 371.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=591 -> ./cache_v15/val_00591.npz X=(815, 120) saved in 372.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=592 -> ./cache_v15/val_00592.npz X=(829, 120) saved in 374.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=593 -> ./cache_v15/val_00593.npz X=(849, 120) saved in 375.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=594 -> ./cache_v15/val_00594.npz X=(814, 120) saved in 380.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=595 -> ./cache_v15/val_00595.npz X=(829, 120) saved in 379.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=596 -> ./cache_v15/val_00596.npz X=(840, 120) saved in 382.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=597 -> ./cache_v15/val_00597.npz X=(844, 120) saved in 387.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 180/287 done; elapsed 4325.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=598 -> ./cache_v15/val_00598.npz X=(831, 120) saved in 387.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=599 -> ./cache_v15/val_00599.npz X=(835, 120) saved in 390.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=600 -> ./cache_v15/val_00600.npz X=(840, 120) saved in 392.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=601 -> ./cache_v15/val_00601.npz X=(830, 120) saved in 394.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=602 -> ./cache_v15/val_00602.npz X=(838, 120) saved in 395.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=603 -> ./cache_v15/val_00603.npz X=(833, 120) saved in 395.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=604 -> ./cache_v15/val_00604.npz X=(844, 120) saved in 400.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=605 -> ./cache_v15/val_00605.npz X=(838, 120) saved in 397.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=606 -> ./cache_v15/val_00606.npz X=(832, 120) saved in 402.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=607 -> ./cache_v15/val_00607.npz X=(839, 120) saved in 403.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=608 -> ./cache_v15/val_00608.npz X=(817, 120) saved in 405.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=609 -> ./cache_v15/val_00609.npz X=(826, 120) saved in 406.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=610 -> ./cache_v15/val_00610.npz X=(831, 120) saved in 412.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=611 -> ./cache_v15/val_00611.npz X=(946, 120) saved in 413.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=612 -> ./cache_v15/val_00612.npz X=(916, 120) saved in 413.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=621 -> ./cache_v15/val_00621.npz X=(737, 120) saved in 207.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=613 -> ./cache_v15/val_00613.npz X=(911, 120) saved in 420.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=614 -> ./cache_v15/val_00614.npz X=(943, 120) saved in 421.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=615 -> ./cache_v15/val_00615.npz X=(924, 120) saved in 422.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=616 -> ./cache_v15/val_00616.npz X=(914, 120) saved in 428.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 200/287 done; elapsed 5028.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=617 -> ./cache_v15/val_00617.npz X=(918, 120) saved in 425.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=622 -> ./cache_v15/val_00622.npz X=(823, 120) saved in 210.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=618 -> ./cache_v15/val_00618.npz X=(937, 120) saved in 432.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=623 -> ./cache_v15/val_00623.npz X=(810, 120) saved in 212.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=619 -> ./cache_v15/val_00619.npz X=(937, 120) saved in 435.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=624 -> ./cache_v15/val_00624.npz X=(836, 120) saved in 215.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=620 -> ./cache_v15/val_00620.npz X=(937, 120) saved in 437.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=626 -> ./cache_v15/val_00626.npz X=(842, 120) saved in 221.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=625 -> ./cache_v15/val_00625.npz X=(821, 120) saved in 223.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=627 -> ./cache_v15/val_00627.npz X=(838, 120) saved in 216.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=628 -> ./cache_v15/val_00628.npz X=(832, 120) saved in 228.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=629 -> ./cache_v15/val_00629.npz X=(821, 120) saved in 230.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=630 -> ./cache_v15/val_00630.npz X=(835, 120) saved in 230.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=631 -> ./cache_v15/val_00631.npz X=(914, 120) saved in 235.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=632 -> ./cache_v15/val_00632.npz X=(940, 120) saved in 238.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=633 -> ./cache_v15/val_00633.npz X=(917, 120) saved in 240.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=634 -> ./cache_v15/val_00634.npz X=(913, 120) saved in 245.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=635 -> ./cache_v15/val_00635.npz X=(933, 120) saved in 243.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=636 -> ./cache_v15/val_00636.npz X=(925, 120) saved in 249.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=637 -> ./cache_v15/val_00637.npz X=(926, 120) saved in 249.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 220/287 done; elapsed 5411.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=638 -> ./cache_v15/val_00638.npz X=(916, 120) saved in 255.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=639 -> ./cache_v15/val_00639.npz X=(929, 120) saved in 245.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=640 -> ./cache_v15/val_00640.npz X=(934, 120) saved in 256.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=641 -> ./cache_v15/val_00641.npz X=(926, 120) saved in 261.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=642 -> ./cache_v15/val_00642.npz X=(935, 120) saved in 258.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=643 -> ./cache_v15/val_00643.npz X=(931, 120) saved in 265.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=644 -> ./cache_v15/val_00644.npz X=(923, 120) saved in 269.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=645 -> ./cache_v15/val_00645.npz X=(920, 120) saved in 269.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=646 -> ./cache_v15/val_00646.npz X=(618, 120) saved in 271.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=647 -> ./cache_v15/val_00647.npz X=(635, 120) saved in 271.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=648 -> ./cache_v15/val_00648.npz X=(658, 120) saved in 271.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=651 -> ./cache_v15/val_00651.npz X=(930, 120) saved in 275.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=653 -> ./cache_v15/val_00653.npz X=(933, 120) saved in 279.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=654 -> ./cache_v15/val_00654.npz X=(921, 120) saved in 281.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=655 -> ./cache_v15/val_00655.npz X=(932, 120) saved in 281.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=656 -> ./cache_v15/val_00656.npz X=(927, 120) saved in 286.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=657 -> ./cache_v15/val_00657.npz X=(947, 120) saved in 287.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=658 -> ./cache_v15/val_00658.npz X=(922, 120) saved in 288.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=659 -> ./cache_v15/val_00659.npz X=(939, 120) saved in 293.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=660 -> ./cache_v15/val_00660.npz X=(943, 120) saved in 294.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 240/287 done; elapsed 5896.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=661 -> ./cache_v15/val_00661.npz X=(942, 120) saved in 297.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=662 -> ./cache_v15/val_00662.npz X=(925, 120) saved in 299.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=663 -> ./cache_v15/val_00663.npz X=(938, 120) saved in 300.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=664 -> ./cache_v15/val_00664.npz X=(929, 120) saved in 304.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=665 -> ./cache_v15/val_00665.npz X=(929, 120) saved in 307.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=666 -> ./cache_v15/val_00666.npz X=(937, 120) saved in 313.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=667 -> ./cache_v15/val_00667.npz X=(916, 120) saved in 314.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=668 -> ./cache_v15/val_00668.npz X=(925, 120) saved in 317.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=669 -> ./cache_v15/val_00669.npz X=(949, 120) saved in 320.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=670 -> ./cache_v15/val_00670.npz X=(929, 120) saved in 309.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=671 -> ./cache_v15/val_00671.npz X=(935, 120) saved in 324.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=672 -> ./cache_v15/val_00672.npz X=(926, 120) saved in 329.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=673 -> ./cache_v15/val_00673.npz X=(949, 120) saved in 331.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=674 -> ./cache_v15/val_00674.npz X=(947, 120) saved in 331.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=675 -> ./cache_v15/val_00675.npz X=(946, 120) saved in 337.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=676 -> ./cache_v15/val_00676.npz X=(924, 120) saved in 337.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=677 -> ./cache_v15/val_00677.npz X=(916, 120) saved in 342.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=678 -> ./cache_v15/val_00678.npz X=(938, 120) saved in 343.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=679 -> ./cache_v15/val_00679.npz X=(952, 120) saved in 344.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=680 -> ./cache_v15/val_00680.npz X=(962, 120) saved in 346.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 260/287 done; elapsed 6471.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=681 -> ./cache_v15/val_00681.npz X=(911, 120) saved in 347.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=682 -> ./cache_v15/val_00682.npz X=(946, 120) saved in 341.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=683 -> ./cache_v15/val_00683.npz X=(941, 120) saved in 351.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=684 -> ./cache_v15/val_00684.npz X=(913, 120) saved in 352.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=685 -> ./cache_v15/val_00685.npz X=(915, 120) saved in 359.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=686 -> ./cache_v15/val_00686.npz X=(938, 120) saved in 360.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=687 -> ./cache_v15/val_00687.npz X=(917, 120) saved in 370.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=688 -> ./cache_v15/val_00688.npz X=(939, 120) saved in 361.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=689 -> ./cache_v15/val_00689.npz X=(937, 120) saved in 368.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=692 -> ./cache_v15/val_00692.npz X=(959, 120) saved in 371.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=693 -> ./cache_v15/val_00693.npz X=(912, 120) saved in 372.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=694 -> ./cache_v15/val_00694.npz X=(944, 120) saved in 376.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=695 -> ./cache_v15/val_00695.npz X=(924, 120) saved in 380.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=696 -> ./cache_v15/val_00696.npz X=(945, 120) saved in 374.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=697 -> ./cache_v15/val_00697.npz X=(917, 120) saved in 387.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=698 -> ./cache_v15/val_00698.npz X=(948, 120) saved in 384.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=699 -> ./cache_v15/val_00699.npz X=(952, 120) saved in 385.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=700 -> ./cache_v15/val_00700.npz X=(939, 120) saved in 389.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=702 -> ./cache_v15/val_00702.npz X=(953, 120) saved in 383.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=703 -> ./cache_v15/val_00703.npz X=(944, 120) saved in 374.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: 280/287 done; elapsed 7065.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=704 -> ./cache_v15/val_00704.npz X=(923, 120) saved in 367.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=705 -> ./cache_v15/val_00705.npz X=(933, 120) saved in 355.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=706 -> ./cache_v15/val_00706.npz X=(951, 120) saved in 333.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=707 -> ./cache_v15/val_00707.npz X=(926, 120) saved in 288.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=709 -> ./cache_v15/val_00709.npz X=(937, 120) saved in 269.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=708 -> ./cache_v15/val_00708.npz X=(932, 120) saved in 278.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] val id=710 -> ./cache_v15/val_00710.npz X=(918, 120) saved in 191.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] val: completed 287 in 7141.1s\n[RUN V1.5] Caching done in 13803.3s\n[RUN V1.5] Training XGBoost on v1.5 cached TRAIN...\n[LoadCacheV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] train: X=(187296, 120) y=(187296,) files=297 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15] Training on cached TRAIN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15] Done in 166.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RUN V1.5] Caching VAL per-frame probabilities (v1.5)...\n[LoadCacheV15] val: 20/277 files, cum frames=13096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 40/277 files, cum frames=25838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 60/277 files, cum frames=38691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 80/277 files, cum frames=51151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 100/277 files, cum frames=63623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 120/277 files, cum frames=75902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 140/277 files, cum frames=91628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 160/277 files, cum frames=108270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 180/277 files, cum frames=124959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 200/277 files, cum frames=142423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 220/277 files, cum frames=160046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 240/277 files, cum frames=178417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: 260/277 files, cum frames=197128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV15] val: X=(213026, 120) y=(213026,) files=277 elapsed=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 20/277 saved; elapsed 5.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 40/277 saved; elapsed 10.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 60/277 saved; elapsed 16.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 80/277 saved; elapsed 21.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 100/277 saved; elapsed 26.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 120/277 saved; elapsed 32.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 140/277 saved; elapsed 37.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 160/277 saved; elapsed 42.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 180/277 saved; elapsed 47.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 200/277 saved; elapsed 53.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 220/277 saved; elapsed 58.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 240/277 saved; elapsed 63.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] 260/277 saved; elapsed 68.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ValProbsV15] Done 277 ids in 73.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RUN V1.5] Grid-searching decoder (v1.5)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 20 combos, curr mean=20.6823 best=20.9134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 40 combos, curr mean=18.7473 best=18.8917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 60 combos, curr mean=17.0108 best=17.0975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 80 combos, curr mean=15.4765 best=15.5379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 100 combos, curr mean=14.0072 best=14.0469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 120 combos, curr mean=12.6101 best=12.6390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 140 combos, curr mean=11.2816 best=11.3105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 160 combos, curr mean=20.6823 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 180 combos, curr mean=18.7473 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 200 combos, curr mean=17.0108 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 220 combos, curr mean=15.4765 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 240 combos, curr mean=14.0072 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 260 combos, curr mean=12.6101 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 280 combos, curr mean=11.2816 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 300 combos, curr mean=20.6823 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 320 combos, curr mean=18.7473 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 340 combos, curr mean=17.0108 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 360 combos, curr mean=15.4765 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 380 combos, curr mean=14.0072 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 400 combos, curr mean=12.6101 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 420 combos, curr mean=11.2816 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 440 combos, curr mean=20.6823 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 460 combos, curr mean=18.7473 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 480 combos, curr mean=17.0108 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 500 combos, curr mean=15.4765 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 520 combos, curr mean=14.0072 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 540 combos, curr mean=12.6101 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 560 combos, curr mean=11.2816 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 580 combos, curr mean=19.1227 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 600 combos, curr mean=18.0072 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 620 combos, curr mean=16.5596 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 640 combos, curr mean=15.2708 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 660 combos, curr mean=13.9819 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 680 combos, curr mean=12.7978 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 700 combos, curr mean=11.5921 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 720 combos, curr mean=19.1227 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 740 combos, curr mean=18.0072 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 760 combos, curr mean=16.5596 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 780 combos, curr mean=15.2708 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 800 combos, curr mean=13.9819 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 820 combos, curr mean=12.7978 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 840 combos, curr mean=11.5921 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 860 combos, curr mean=19.1227 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 880 combos, curr mean=18.0072 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 900 combos, curr mean=16.5596 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 920 combos, curr mean=15.2708 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 940 combos, curr mean=13.9819 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 960 combos, curr mean=12.7978 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 980 combos, curr mean=11.5921 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1000 combos, curr mean=19.1227 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1020 combos, curr mean=18.0072 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1040 combos, curr mean=16.5596 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1060 combos, curr mean=15.2708 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1080 combos, curr mean=13.9819 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1100 combos, curr mean=12.7978 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1120 combos, curr mean=11.5921 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1140 combos, curr mean=16.8231 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1160 combos, curr mean=16.4621 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1180 combos, curr mean=15.6751 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1200 combos, curr mean=14.6751 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1220 combos, curr mean=13.6318 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1240 combos, curr mean=12.6137 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1260 combos, curr mean=11.5487 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1280 combos, curr mean=16.8231 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1300 combos, curr mean=16.4621 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1320 combos, curr mean=15.6751 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1340 combos, curr mean=14.6751 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1360 combos, curr mean=13.6318 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1380 combos, curr mean=12.6137 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1400 combos, curr mean=11.5487 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1420 combos, curr mean=16.8231 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1440 combos, curr mean=16.4621 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1460 combos, curr mean=15.6751 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1480 combos, curr mean=14.6751 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1500 combos, curr mean=13.6318 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1520 combos, curr mean=12.6137 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1540 combos, curr mean=11.5487 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1560 combos, curr mean=16.8231 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1580 combos, curr mean=16.4621 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1600 combos, curr mean=15.6751 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1620 combos, curr mean=14.6751 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1640 combos, curr mean=13.6318 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1660 combos, curr mean=12.6137 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] 1680 combos, curr mean=11.5487 best=11.2816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15] Done 1680 combos in 613.6s. Best=(11.28158844765343, {'window': 5, 'merge_gap': 3, 'min_len': 10, 'mean_thr': 0.55, 'max_thr': 0.7})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best decoder params (v1.5): (11.28158844765343, {'window': 5, 'merge_gap': 3, 'min_len': 10, 'mean_thr': 0.55, 'max_thr': 0.7})\n"
          ]
        }
      ]
    },
    {
      "id": "2f0dfdb2-9043-443f-a6d5-32956864f7fe",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 15) Train on TRAIN+VAL (v1.5), predict TEST, decode with rescue, and write submission.csv\n",
        "import os, glob, time, json, numpy as np, pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "def load_frames_from_cache_v15(prefix:str):\n",
        "    files = sorted(glob.glob(os.path.join(CACHE_DIR_V15, f\"{prefix}_*.npz\")))\n",
        "    Xs, ys = [], []\n",
        "    n = 0; t0 = time.time()\n",
        "    for i, fp in enumerate(files, 1):\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        X = d['X']; y = d['y']\n",
        "        Xs.append(X); ys.append(y.astype(np.int32)); n += len(y)\n",
        "        if i % 20 == 0:\n",
        "            print(f\"[LoadV15] {prefix}: {i}/{len(files)} files, cum frames={n}\", flush=True)\n",
        "    X = np.vstack(Xs) if Xs else np.zeros((0,0), dtype=np.float32)\n",
        "    y = np.concatenate(ys) if ys else np.zeros((0,), dtype=np.int32)\n",
        "    print(f\"[LoadV15] {prefix}: X={X.shape} y={y.shape} files={len(files)}\", flush=True)\n",
        "    return X, y, files\n",
        "\n",
        "def ensure_test_cache_v15():\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    todo = []\n",
        "    for sid in test_ids:\n",
        "        out_path = os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz')\n",
        "        if not os.path.exists(out_path):\n",
        "            todo.append(sid)\n",
        "    if todo:\n",
        "        print(f\"[CacheV15][TEST] {len(todo)}/{len(test_ids)} missing; caching with stride=2...\")\n",
        "        parallel_cache_v15('test', test_ids, max_workers=12, stride=2)\n",
        "    else:\n",
        "        print('[CacheV15][TEST] All test cached.')\n",
        "\n",
        "def make_weights_with_boundary_erosion(y: np.ndarray, w0: float=0.38):\n",
        "    w = np.ones_like(y, dtype=np.float32); w[y==0] = w0\n",
        "    if len(y) > 2:\n",
        "        bmask = (y[1:-1] != y[:-2]) | (y[1:-1] != y[2:])\n",
        "        w[1:-1][bmask] = 0.0\n",
        "    return w\n",
        "\n",
        "def train_seed_model_v15(X, y, seed:int):\n",
        "    w = make_weights_with_boundary_erosion(y, w0=0.38)\n",
        "    dtr = xgb.DMatrix(X, label=y, weight=w)\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 21,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'predictor': 'gpu_predictor',\n",
        "        'max_bin': 512,\n",
        "        'max_depth': 7,\n",
        "        'eta': 0.085,\n",
        "        'subsample': 0.85,\n",
        "        'colsample_bytree': 0.85,\n",
        "        'min_child_weight': 4.0,\n",
        "        'lambda': 1.0,\n",
        "        'seed': int(seed)\n",
        "    }\n",
        "    print(f\"[XGB-V15][Seed {seed}] Training...\")\n",
        "    t0 = time.time()\n",
        "    bst = xgb.train(params, dtr, num_boost_round=1100, verbose_eval=200)\n",
        "    print(f\"[XGB-V15][Seed {seed}] Done in {time.time()-t0:.1f}s\")\n",
        "    return bst\n",
        "\n",
        "def ensure_permutation_20(seq, mean_probs):\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for c in seq:\n",
        "        if c==0: continue\n",
        "        if c not in seen and 1 <= c <= 20:\n",
        "            out.append(c); seen.add(c)\n",
        "        if len(out) == 20: break\n",
        "    if len(out) < 20:\n",
        "        remaining = [c for c in range(1,21) if c not in seen]\n",
        "        remaining.sort(key=lambda c: float(mean_probs[c]), reverse=True)\n",
        "        out.extend(remaining)\n",
        "        out = out[:20]\n",
        "    elif len(out) > 20:\n",
        "        out = out[:20]\n",
        "    return out\n",
        "\n",
        "# Use DP decoder if params contains DP keys; else use vanilla decode_sequence\n",
        "def decode_with_rescue(P, params):\n",
        "    mean_probs = P.mean(axis=0)\n",
        "    if all(k in params for k in ('lambda','bg_bias','merge_gap','min_len','mean_thr','max_thr')):\n",
        "        pred = decode_sequence_dp(P, switch_penalty=params['lambda'], bg_bias=params['bg_bias'],\n",
        "                                 merge_gap=params['merge_gap'], min_len=params['min_len'],\n",
        "                                 mean_thr=params['mean_thr'], max_thr=params['max_thr'])\n",
        "    else:\n",
        "        pred = decode_sequence(P, window=params['window'], merge_gap=params['merge_gap'],\n",
        "                               min_len=params['min_len'], mean_thr=params['mean_thr'], max_thr=params['max_thr'])\n",
        "    return ensure_permutation_20(pred, mean_probs)\n",
        "\n",
        "def predict_test_and_write_submission_v15(models, decoder_params, out_csv='submission.csv'):\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    rows = []\n",
        "    t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']\n",
        "        Ps = []\n",
        "        dm = xgb.DMatrix(X)\n",
        "        for m in models:\n",
        "            Ps.append(m.predict(dm))\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        seq = decode_with_rescue(P, decoder_params)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print(f\"[SUBMISSION] Wrote {out_csv} with {len(rows)} rows.\")\n",
        "    return out_csv\n",
        "\n",
        "def run_trainval_and_test_v15(best_decoder_params:dict, seeds=(2025, 1337)):\n",
        "    print('[Train+Val V1.5] Loading TRAIN and VAL caches...')\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    X_va, y_va, _ = load_frames_from_cache_v15('val')\n",
        "    X_all = np.vstack([X_tr, X_va]); y_all = np.concatenate([y_tr, y_va])\n",
        "    print('[Train+Val V1.5] Frames:', X_all.shape, 'Labels:', y_all.shape)\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v15(X_all, y_all, seed=s))\n",
        "    ensure_test_cache_v15()\n",
        "    return predict_test_and_write_submission_v15(models, best_decoder_params, out_csv='submission.csv')\n",
        "\n",
        "print('[StageV15][Final] Ready: run run_trainval_and_test_v15(best_params_dict) after grid search to produce submission.csv')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[StageV15][Final] Ready: run run_trainval_and_test_v15(best_params_dict) after grid search to produce submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "1c5b7c1b-4d81-4211-9463-b86fcc577f7c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 16) DP/Viterbi decoder to stabilize per-frame labels; grid on VAL cached probs (v1.5)\n",
        "import numpy as np, glob, os, time\n",
        "\n",
        "def viterbi_labels(probs: np.ndarray, switch_penalty: float = 1.0, bg_bias: float = 0.0) -> np.ndarray:\n",
        "    # probs: (T,C), returns best path labels in [0..C-1]\n",
        "    T, C = probs.shape\n",
        "    eps = 1e-9\n",
        "    # emission costs\n",
        "    cost = -np.log(np.clip(probs, eps, 1.0)).astype(np.float32)\n",
        "    if bg_bias != 0.0:\n",
        "        cost[:, 0] += float(bg_bias)  # discourage background\n",
        "    dp = np.zeros((T, C), dtype=np.float32)\n",
        "    bp = np.zeros((T, C), dtype=np.int16)\n",
        "    dp[0] = cost[0]\n",
        "    bp[0] = -1\n",
        "    for t in range(1, T):\n",
        "        prev = dp[t-1]\n",
        "        min_prev = float(prev.min())\n",
        "        # cost to stay vs switch-from-best-other\n",
        "        stay = prev  # no penalty\n",
        "        switch = min_prev + switch_penalty\n",
        "        # vectorized: best_prev_cost = min(stay[c], switch) for each c\n",
        "        best_prev = np.minimum(stay, switch)\n",
        "        dp[t] = cost[t] + best_prev\n",
        "        # backpointer:  if stay <= switch -> c, else argmin prev\n",
        "        argmin_prev = int(prev.argmin())\n",
        "        bp[t] = np.where(stay <= switch, np.arange(C, dtype=np.int16), np.int16(argmin_prev))\n",
        "    # backtrack\n",
        "    path = np.zeros(T, dtype=np.int16)\n",
        "    path[T-1] = int(dp[T-1].argmin())\n",
        "    for t in range(T-2, -1, -1):\n",
        "        path[t] = bp[t+1, path[t+1]]\n",
        "    return path\n",
        "\n",
        "def decode_sequence_dp(probs, switch_penalty=1.0, bg_bias=0.0, merge_gap=4, min_len=6, mean_thr=0.45, max_thr=0.60):\n",
        "    labels = viterbi_labels(probs, switch_penalty=switch_penalty, bg_bias=bg_bias)\n",
        "    T = len(labels)\n",
        "    # build segments with stats\n",
        "    segs = []  # (cls, b, e, mean_p, max_p)\n",
        "    b = 0\n",
        "    for i in range(1, T+1):\n",
        "        if i==T or labels[i] != labels[b]:\n",
        "            cls = int(labels[b])\n",
        "            p = probs[b:i, cls] if cls < probs.shape[1] else np.zeros(i-b)\n",
        "            mean_p = float(p.mean()) if (i-b)>0 else 0.0\n",
        "            max_p = float(p.max()) if (i-b)>0 else 0.0\n",
        "            segs.append([cls, b, i, mean_p, max_p])\n",
        "            b = i\n",
        "    # merge small gaps between same class (gap must be background and short)\n",
        "    merged = []\n",
        "    i = 0\n",
        "    while i < len(segs):\n",
        "        cur = segs[i]\n",
        "        j = i + 1\n",
        "        while j < len(segs):\n",
        "            if segs[j][0] == cur[0] and segs[j-1][0]==0 and (segs[j][1]-cur[2]) <= merge_gap:\n",
        "                cur[2] = segs[j][2]\n",
        "                cur[3] = float(np.mean(probs[cur[1]:cur[2], cur[0]]))\n",
        "                cur[4] = float(np.max(probs[cur[1]:cur[2], cur[0]]))\n",
        "                j += 1\n",
        "            else:\n",
        "                break\n",
        "        merged.append(cur)\n",
        "        i = j\n",
        "    out = []\n",
        "    for cls, sb, se, mp, xp in merged:\n",
        "        if cls == 0: continue\n",
        "        if (se - sb) < min_len: continue\n",
        "        if not (mp >= mean_thr and xp >= max_thr): continue\n",
        "        if not out or out[-1] != cls:\n",
        "            out.append(int(cls))\n",
        "    return out\n",
        "\n",
        "def load_all_val_probs_v15():\n",
        "    files = sorted(glob.glob(os.path.join(PROB_DIR_V15, 'valprobs_*.npz')))\n",
        "    items = []\n",
        "    for fp in files:\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        items.append((int(d['sid']), d['probs'], d['seq']))\n",
        "    return items\n",
        "\n",
        "def grid_search_decoder_dp_v15():\n",
        "    items = load_all_val_probs_v15()\n",
        "    assert items, 'No cached VAL probs v15 found.'\n",
        "    grids = {\n",
        "        'lambda': [0.8, 1.0, 1.2],\n",
        "        'bg_bias': [0.2, 0.4],\n",
        "        'merge_gap': [3, 5],\n",
        "        'min_len': [6, 8, 10, 12],\n",
        "        'mean_thr': [0.45, 0.50],\n",
        "        'max_thr': [0.60, 0.65],\n",
        "    }\n",
        "    best = (1e9, None); tried = 0; t0 = time.time()\n",
        "    for lam in grids['lambda']:\n",
        "        for bb in grids['bg_bias']:\n",
        "            for mg in grids['merge_gap']:\n",
        "                for ml in grids['min_len']:\n",
        "                    for mthr in grids['mean_thr']:\n",
        "                        for xthr in grids['max_thr']:\n",
        "                            scores = []\n",
        "                            for sid, P, seq in items:\n",
        "                                pred = decode_sequence_dp(P, switch_penalty=lam, bg_bias=bb, merge_gap=mg, min_len=ml, mean_thr=mthr, max_thr=xthr)\n",
        "                                lev = levenshtein(list(pred), list(seq.tolist()))\n",
        "                                norm = lev / max(1, len(seq))\n",
        "                                scores.append(norm)\n",
        "                            mean_norm = float(np.mean(scores)) if scores else 1.0\n",
        "                            tried += 1\n",
        "                            if tried % 20 == 0:\n",
        "                                print(f\"[GridV15-DP] {tried} combos, curr mean={mean_norm:.4f} best={best[0]:.4f}\", flush=True)\n",
        "                            if mean_norm < best[0]:\n",
        "                                best = (mean_norm, {'lambda':lam,'bg_bias':bb,'merge_gap':mg,'min_len':ml,'mean_thr':mthr,'max_thr':xthr})\n",
        "    print(f\"[GridV15-DP] Done {tried} combos in {time.time()-t0:.1f}s. Best={best}\", flush=True)\n",
        "    return best\n",
        "\n",
        "print('[StageV15][DP] Ready: run best_dp = grid_search_decoder_dp_v15() to evaluate Viterbi-based decoder on VAL cached probs.')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[StageV15][DP] Ready: run best_dp = grid_search_decoder_dp_v15() to evaluate Viterbi-based decoder on VAL cached probs.\n"
          ]
        }
      ]
    },
    {
      "id": "0987d192-3d58-40d8-9df1-f945042531fb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 17) Run DP decoder grid on v1.5 VAL probs\n",
        "best_dp = grid_search_decoder_dp_v15()\n",
        "print('Best DP decoder params (v1.5):', best_dp)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15-DP] 20 combos, curr mean=18.9747 best=9.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15-DP] 40 combos, curr mean=15.0433 best=9.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15-DP] 60 combos, curr mean=11.8773 best=9.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15-DP] 80 combos, curr mean=9.4332 best=9.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15-DP] 100 combos, curr mean=18.8339 best=9.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15-DP] 120 combos, curr mean=15.1408 best=9.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15-DP] 140 combos, curr mean=12.1191 best=9.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15-DP] 160 combos, curr mean=9.5487 best=9.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15-DP] 180 combos, curr mean=18.7509 best=9.2094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GridV15-DP] Done 192 combos in 355.5s. Best=(9.209386281588447, {'lambda': 0.8, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best DP decoder params (v1.5): (9.209386281588447, {'lambda': 0.8, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65})\n"
          ]
        }
      ]
    },
    {
      "id": "a49272fa-4887-4eac-8496-bc08c326b850",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 18) Retrain on TRAIN+VAL with DP decoder params and produce submission\n",
        "print('[FINAL RUN] Using DP decoder params from VAL grid...')\n",
        "dp_params = best_dp[1]  # expects dict with keys: lambda,bg_bias,merge_gap,min_len,mean_thr,max_thr\n",
        "print('DP params:', dp_params)\n",
        "sub_path = run_trainval_and_test_v15(dp_params, seeds=(2025,1337))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FINAL RUN] Using DP decoder params from VAL grid...\nDP params: {'lambda': 0.8, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n[Train+Val V1.5] Loading TRAIN and VAL caches...\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 20/277 files, cum frames=13096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 40/277 files, cum frames=25838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 60/277 files, cum frames=38691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 80/277 files, cum frames=51151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 100/277 files, cum frames=63623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 120/277 files, cum frames=75902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 140/277 files, cum frames=91628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 160/277 files, cum frames=108270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 180/277 files, cum frames=124959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 200/277 files, cum frames=142423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 220/277 files, cum frames=160046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 240/277 files, cum frames=178417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 260/277 files, cum frames=197128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: X=(213026, 120) y=(213026,) files=277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train+Val V1.5] Frames: (400322, 120) Labels: (400322,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 232.3s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 234.4s\n[CacheV15][TEST] 95/95 missing; caching with stride=2...\n[ParCacheV15] test: 95/95 remaining.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=300 -> ./cache_v15/test_00300.npz X=(624, 120) saved in 130.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=301 -> ./cache_v15/test_00301.npz X=(626, 120) saved in 132.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=302 -> ./cache_v15/test_00302.npz X=(661, 120) saved in 132.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=303 -> ./cache_v15/test_00303.npz X=(575, 120) saved in 133.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=304 -> ./cache_v15/test_00304.npz X=(614, 120) saved in 134.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=305 -> ./cache_v15/test_00305.npz X=(620, 120) saved in 135.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=306 -> ./cache_v15/test_00306.npz X=(612, 120) saved in 138.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=307 -> ./cache_v15/test_00307.npz X=(594, 120) saved in 139.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=308 -> ./cache_v15/test_00308.npz X=(565, 120) saved in 140.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=309 -> ./cache_v15/test_00309.npz X=(591, 120) saved in 141.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=310 -> ./cache_v15/test_00310.npz X=(604, 120) saved in 143.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=311 -> ./cache_v15/test_00311.npz X=(695, 120) saved in 144.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=312 -> ./cache_v15/test_00312.npz X=(606, 120) saved in 145.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=313 -> ./cache_v15/test_00313.npz X=(607, 120) saved in 148.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=314 -> ./cache_v15/test_00314.npz X=(608, 120) saved in 150.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=315 -> ./cache_v15/test_00315.npz X=(662, 120) saved in 151.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=316 -> ./cache_v15/test_00316.npz X=(611, 120) saved in 151.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=317 -> ./cache_v15/test_00317.npz X=(631, 120) saved in 152.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=318 -> ./cache_v15/test_00318.npz X=(601, 120) saved in 155.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=320 -> ./cache_v15/test_00320.npz X=(573, 120) saved in 154.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] test: 20/95 done; elapsed 294.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=319 -> ./cache_v15/test_00319.npz X=(579, 120) saved in 156.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=321 -> ./cache_v15/test_00321.npz X=(589, 120) saved in 158.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=322 -> ./cache_v15/test_00322.npz X=(657, 120) saved in 159.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=323 -> ./cache_v15/test_00323.npz X=(580, 120) saved in 159.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=324 -> ./cache_v15/test_00324.npz X=(620, 120) saved in 161.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=325 -> ./cache_v15/test_00325.npz X=(621, 120) saved in 161.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=326 -> ./cache_v15/test_00326.npz X=(636, 120) saved in 164.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=327 -> ./cache_v15/test_00327.npz X=(599, 120) saved in 166.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=328 -> ./cache_v15/test_00328.npz X=(565, 120) saved in 166.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=329 -> ./cache_v15/test_00329.npz X=(609, 120) saved in 167.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=330 -> ./cache_v15/test_00330.npz X=(576, 120) saved in 167.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=332 -> ./cache_v15/test_00332.npz X=(781, 120) saved in 170.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=333 -> ./cache_v15/test_00333.npz X=(776, 120) saved in 172.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=334 -> ./cache_v15/test_00334.npz X=(704, 120) saved in 173.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=335 -> ./cache_v15/test_00335.npz X=(762, 120) saved in 176.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=336 -> ./cache_v15/test_00336.npz X=(787, 120) saved in 179.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=337 -> ./cache_v15/test_00337.npz X=(768, 120) saved in 177.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=338 -> ./cache_v15/test_00338.npz X=(854, 120) saved in 182.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=339 -> ./cache_v15/test_00339.npz X=(820, 120) saved in 183.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=340 -> ./cache_v15/test_00340.npz X=(602, 120) saved in 185.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] test: 40/95 done; elapsed 635.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=341 -> ./cache_v15/test_00341.npz X=(662, 120) saved in 187.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=342 -> ./cache_v15/test_00342.npz X=(529, 120) saved in 187.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=343 -> ./cache_v15/test_00343.npz X=(601, 120) saved in 188.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=344 -> ./cache_v15/test_00344.npz X=(634, 120) saved in 191.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=345 -> ./cache_v15/test_00345.npz X=(590, 120) saved in 191.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=346 -> ./cache_v15/test_00346.npz X=(615, 120) saved in 193.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=347 -> ./cache_v15/test_00347.npz X=(581, 120) saved in 195.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=348 -> ./cache_v15/test_00348.npz X=(530, 120) saved in 196.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=351 -> ./cache_v15/test_00351.npz X=(606, 120) saved in 197.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=352 -> ./cache_v15/test_00352.npz X=(621, 120) saved in 197.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=353 -> ./cache_v15/test_00353.npz X=(604, 120) saved in 199.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=354 -> ./cache_v15/test_00354.npz X=(605, 120) saved in 201.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=355 -> ./cache_v15/test_00355.npz X=(701, 120) saved in 203.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=356 -> ./cache_v15/test_00356.npz X=(652, 120) saved in 205.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=357 -> ./cache_v15/test_00357.npz X=(608, 120) saved in 206.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=358 -> ./cache_v15/test_00358.npz X=(685, 120) saved in 208.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=359 -> ./cache_v15/test_00359.npz X=(632, 120) saved in 209.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=360 -> ./cache_v15/test_00360.npz X=(647, 120) saved in 212.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=361 -> ./cache_v15/test_00361.npz X=(596, 120) saved in 214.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=362 -> ./cache_v15/test_00362.npz X=(569, 120) saved in 211.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] test: 60/95 done; elapsed 890.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=363 -> ./cache_v15/test_00363.npz X=(599, 120) saved in 216.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=364 -> ./cache_v15/test_00364.npz X=(572, 120) saved in 216.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=365 -> ./cache_v15/test_00365.npz X=(655, 120) saved in 217.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=366 -> ./cache_v15/test_00366.npz X=(639, 120) saved in 219.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=367 -> ./cache_v15/test_00367.npz X=(598, 120) saved in 219.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=368 -> ./cache_v15/test_00368.npz X=(688, 120) saved in 220.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=369 -> ./cache_v15/test_00369.npz X=(602, 120) saved in 223.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=370 -> ./cache_v15/test_00370.npz X=(634, 120) saved in 225.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=371 -> ./cache_v15/test_00371.npz X=(933, 120) saved in 226.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=372 -> ./cache_v15/test_00372.npz X=(848, 120) saved in 231.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=373 -> ./cache_v15/test_00373.npz X=(639, 120) saved in 231.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=374 -> ./cache_v15/test_00374.npz X=(547, 120) saved in 233.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=375 -> ./cache_v15/test_00375.npz X=(629, 120) saved in 232.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=376 -> ./cache_v15/test_00376.npz X=(654, 120) saved in 234.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=377 -> ./cache_v15/test_00377.npz X=(602, 120) saved in 233.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=378 -> ./cache_v15/test_00378.npz X=(702, 120) saved in 237.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=379 -> ./cache_v15/test_00379.npz X=(564, 120) saved in 237.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=380 -> ./cache_v15/test_00380.npz X=(598, 120) saved in 237.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=381 -> ./cache_v15/test_00381.npz X=(606, 120) saved in 239.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=383 -> ./cache_v15/test_00383.npz X=(588, 120) saved in 244.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] test: 80/95 done; elapsed 1334.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=384 -> ./cache_v15/test_00384.npz X=(684, 120) saved in 243.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=385 -> ./cache_v15/test_00385.npz X=(592, 120) saved in 243.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=386 -> ./cache_v15/test_00386.npz X=(578, 120) saved in 242.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=389 -> ./cache_v15/test_00389.npz X=(585, 120) saved in 245.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=390 -> ./cache_v15/test_00390.npz X=(637, 120) saved in 239.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=391 -> ./cache_v15/test_00391.npz X=(667, 120) saved in 238.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=392 -> ./cache_v15/test_00392.npz X=(618, 120) saved in 238.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=393 -> ./cache_v15/test_00393.npz X=(577, 120) saved in 234.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=394 -> ./cache_v15/test_00394.npz X=(641, 120) saved in 234.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=395 -> ./cache_v15/test_00395.npz X=(611, 120) saved in 230.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=396 -> ./cache_v15/test_00396.npz X=(628, 120) saved in 225.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=397 -> ./cache_v15/test_00397.npz X=(654, 120) saved in 214.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=401 -> ./cache_v15/test_00401.npz X=(558, 120) saved in 209.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=402 -> ./cache_v15/test_00402.npz X=(653, 120) saved in 195.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15] test id=403 -> ./cache_v15/test_00403.npz X=(604, 120) saved in 188.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV15] test: completed 95 in 1550.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 10/95 done; elapsed 5.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 20/95 done; elapsed 10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 30/95 done; elapsed 16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 40/95 done; elapsed 21.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 50/95 done; elapsed 26.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 60/95 done; elapsed 32.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 70/95 done; elapsed 37.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 80/95 done; elapsed 42.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 90/95 done; elapsed 47.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "8e8f32b3-1f37-4a74-819a-d077695f6253",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 19) Decoder debug: visualize one validation sample through stages (argmax, Viterbi, segments, filters)\n",
        "import numpy as np, glob, os, re\n",
        "\n",
        "def load_one_val_item(v15=True, sid=None):\n",
        "    prob_dir = './cache_probs_v15' if v15 else './cache_probs'\n",
        "    files = sorted(glob.glob(os.path.join(prob_dir, 'valprobs_*.npz')))\n",
        "    assert files, 'No cached VAL probs found. Run cache_val_probs_v15() or cache_val_probs() first.'\n",
        "    if sid is not None:\n",
        "        target = os.path.join(prob_dir, f'valprobs_{int(sid):05d}.npz')\n",
        "        files = [target]\n",
        "    fp = files[0]\n",
        "    d = np.load(fp, allow_pickle=False)\n",
        "    return int(d['sid']) if 'sid' in d else int(re.findall(r'(\\d{5})', os.path.basename(fp))[0]), d['probs'], d['seq']\n",
        "\n",
        "def segments_from_labels(labels, probs):\n",
        "    segs = []  # (cls, b, e, mean_p, max_p)\n",
        "    T = len(labels); b = 0\n",
        "    for i in range(1, T+1):\n",
        "        if i==T or labels[i] != labels[b]:\n",
        "            cls = int(labels[b])\n",
        "            p = probs[b:i, cls] if cls < probs.shape[1] else np.zeros(i-b)\n",
        "            mean_p = float(p.mean()) if (i-b)>0 else 0.0\n",
        "            max_p = float(p.max()) if (i-b)>0 else 0.0\n",
        "            segs.append([cls, b, i, mean_p, max_p])\n",
        "            b = i\n",
        "    return segs\n",
        "\n",
        "def print_segs(segs, limit=30):\n",
        "    rows = []\n",
        "    for cls, sb, se, mp, xp in segs[:limit]:\n",
        "        rows.append(f'(c={cls}, {sb}->{se}, len={se-sb}, mean={mp:.3f}, max={xp:.3f})')\n",
        "    print('Segments[0:%d]:' % min(limit, len(segs)))\n",
        "    print('\\n'.join(rows))\n",
        "\n",
        "def collapse_run_labels(labels):\n",
        "    out = []\n",
        "    prev = None\n",
        "    for x in labels:\n",
        "        if x != prev:\n",
        "            out.append(int(x)); prev = x\n",
        "    return out\n",
        "\n",
        "def norm_lev(pred, true):\n",
        "    lev = levenshtein(list(pred), list(true))\n",
        "    return lev, lev / max(1, len(true))\n",
        "\n",
        "# Pick one sample and show decoder internals\n",
        "sid, P, true_seq = load_one_val_item(v15=True, sid=None)\n",
        "print('[Debug] sid:', sid, 'P shape:', P.shape, 'true_seq len:', len(true_seq))\n",
        "\n",
        "# Argmax path\n",
        "argmax_labels = P.argmax(1).astype(int)\n",
        "argmax_collapsed = collapse_run_labels(argmax_labels)\n",
        "lev_a, nlev_a = norm_lev(argmax_collapsed, list(true_seq.tolist()))\n",
        "print('[Argmax] collapsed len:', len(argmax_collapsed), 'lev:', lev_a, 'norm:', nlev_a)\n",
        "segs_arg = segments_from_labels(argmax_labels, P)\n",
        "print('[Argmax] total segments:', len(segs_arg))\n",
        "print_segs(segs_arg, limit=20)\n",
        "\n",
        "# Simple decoder output\n",
        "pred_simple = decode_sequence(P, window=7, merge_gap=4, min_len=6, mean_thr=0.45, max_thr=0.60)\n",
        "lev_s, nlev_s = norm_lev(pred_simple, list(true_seq.tolist()))\n",
        "print('[SimpleDecoder] seq:', pred_simple)\n",
        "print('[SimpleDecoder] len:', len(pred_simple), 'lev:', lev_s, 'norm:', nlev_s)\n",
        "\n",
        "# Viterbi path\n",
        "vit_labels = viterbi_labels(P, switch_penalty=0.8, bg_bias=0.2)\n",
        "vit_collapsed = collapse_run_labels(vit_labels)\n",
        "lev_vc, nlev_vc = norm_lev(vit_collapsed, list(true_seq.tolist()))\n",
        "print('[Viterbi] collapsed len:', len(vit_collapsed), 'lev:', lev_vc, 'norm:', nlev_vc)\n",
        "segs_vit = segments_from_labels(vit_labels, P)\n",
        "print('[Viterbi] total segments:', len(segs_vit))\n",
        "print_segs(segs_vit, limit=20)\n",
        "\n",
        "# Viterbi + filters decoder output\n",
        "pred_dp = decode_sequence_dp(P, switch_penalty=0.8, bg_bias=0.2, merge_gap=3, min_len=12, mean_thr=0.5, max_thr=0.65)\n",
        "lev_dp, nlev_dp = norm_lev(pred_dp, list(true_seq.tolist()))\n",
        "print('[Viterbi+Filters] seq:', pred_dp)\n",
        "print('[Viterbi+Filters] len:', len(pred_dp), 'lev:', lev_dp, 'norm:', nlev_dp)\n",
        "\n",
        "# Sanity: lengths and normalization check\n",
        "print('[Sanity] true_seq:', list(true_seq.tolist()))\n",
        "print('[Sanity] len(true_seq)=', len(true_seq), 'normalize by this length. OK.')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Debug] sid: 410 P shape: (612, 21) true_seq len: 0\n[Argmax] collapsed len: 150 lev: 150 norm: 150.0\n[Argmax] total segments: 150\nSegments[0:20]:\n(c=17, 0->2, len=2, mean=0.073, max=0.073)\n(c=0, 2->3, len=1, mean=0.360, max=0.360)\n(c=13, 3->4, len=1, mean=0.181, max=0.181)\n(c=0, 4->35, len=31, mean=0.477, max=0.657)\n(c=5, 35->49, len=14, mean=0.866, max=0.995)\n(c=0, 49->52, len=3, mean=0.425, max=0.436)\n(c=5, 52->53, len=1, mean=0.384, max=0.384)\n(c=0, 53->61, len=8, mean=0.389, max=0.435)\n(c=5, 61->63, len=2, mean=0.654, max=0.761)\n(c=0, 63->66, len=3, mean=0.606, max=0.735)\n(c=5, 66->68, len=2, mean=0.486, max=0.616)\n(c=0, 68->70, len=2, mean=0.339, max=0.348)\n(c=11, 70->71, len=1, mean=0.199, max=0.199)\n(c=5, 71->74, len=3, mean=0.833, max=0.900)\n(c=0, 74->82, len=8, mean=0.685, max=0.900)\n(c=5, 82->83, len=1, mean=0.652, max=0.652)\n(c=0, 83->85, len=2, mean=0.629, max=0.722)\n(c=8, 85->86, len=1, mean=0.350, max=0.350)\n(c=18, 86->87, len=1, mean=0.479, max=0.479)\n(c=8, 87->89, len=2, mean=0.494, max=0.563)\n[SimpleDecoder] seq: [5, 3, 4, 2, 5, 12, 2, 20, 5, 11, 5, 6, 5, 8, 5, 12, 5, 3, 5, 11, 5, 9, 7, 17, 5]\n[SimpleDecoder] len: 25 lev: 25 norm: 25.0\n[Viterbi] collapsed len: 84 lev: 84 norm: 84.0\n[Viterbi] total segments: 84\nSegments[0:20]:\n(c=17, 0->2, len=2, mean=0.073, max=0.073)\n(c=0, 2->35, len=33, mean=0.462, max=0.657)\n(c=5, 35->49, len=14, mean=0.866, max=0.995)\n(c=0, 49->59, len=10, mean=0.392, max=0.436)\n(c=5, 59->63, len=4, mean=0.501, max=0.761)\n(c=0, 63->66, len=3, mean=0.606, max=0.735)\n(c=5, 66->68, len=2, mean=0.486, max=0.616)\n(c=0, 68->70, len=2, mean=0.339, max=0.348)\n(c=5, 70->74, len=4, mean=0.660, max=0.900)\n(c=0, 74->85, len=11, mean=0.634, max=0.900)\n(c=8, 85->95, len=10, mean=0.366, max=0.563)\n(c=18, 95->99, len=4, mean=0.603, max=0.936)\n(c=3, 99->101, len=2, mean=0.223, max=0.236)\n(c=5, 101->102, len=1, mean=0.377, max=0.377)\n(c=8, 102->103, len=1, mean=0.282, max=0.282)\n(c=0, 103->111, len=8, mean=0.390, max=0.530)\n(c=5, 111->112, len=1, mean=0.769, max=0.769)\n(c=0, 112->115, len=3, mean=0.642, max=0.849)\n(c=3, 115->128, len=13, mean=0.798, max=0.990)\n(c=1, 128->130, len=2, mean=0.282, max=0.316)\n[Viterbi+Filters] seq: [5, 3, 5, 9, 17]\n[Viterbi+Filters] len: 5 lev: 5 norm: 5.0\n[Sanity] true_seq: []\n[Sanity] len(true_seq)= 0 normalize by this length. OK.\n"
          ]
        }
      ]
    },
    {
      "id": "85a88f02-6fed-4d0f-ab3a-41cec1022bff",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 20) Build TRAIN-only 5-fold OOF per-id probabilities (v1.5), then grid-search decoder on OOF\n",
        "import os, glob, time, numpy as np, pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb\n",
        "\n",
        "OOF_DIR_V15 = './oof_probs_v15'\n",
        "os.makedirs(OOF_DIR_V15, exist_ok=True)\n",
        "\n",
        "def load_train_item_v15(sid:int):\n",
        "    fp = os.path.join(CACHE_DIR_V15, f'train_{sid:05d}.npz')\n",
        "    d = np.load(fp, allow_pickle=False)\n",
        "    X = d['X']; y = d['y']\n",
        "    # true 20-token sequence from training.csv (authoritative)\n",
        "    row = train_df.loc[train_df.Id==sid]\n",
        "    seq = []\n",
        "    if not row.empty:\n",
        "        seq = [int(x) for x in re.findall(r'\\d+', str(row['Sequence'].values[0]))]\n",
        "    return X, y.astype(np.int32), np.array(seq, dtype=np.int16)\n",
        "\n",
        "def load_many_train_frames_v15(sids:list):\n",
        "    Xs, ys = [], []\n",
        "    n = 0; t0 = time.time()\n",
        "    for i, sid in enumerate(sids, 1):\n",
        "        X, y, _ = load_train_item_v15(sid)\n",
        "        Xs.append(X); ys.append(y); n += len(y)\n",
        "        if i % 20 == 0:\n",
        "            print(f\"[LoadTrainFold] {i}/{len(sids)} ids, cum frames={n}\", flush=True)\n",
        "    X = np.vstack(Xs); y = np.concatenate(ys)\n",
        "    print(f\"[LoadTrainFold] Loaded {len(sids)} ids: X={X.shape} y={y.shape}\", flush=True)\n",
        "    return X, y\n",
        "\n",
        "def make_weights_with_boundary_erosion(y: np.ndarray, w0: float=0.38):\n",
        "    w = np.ones_like(y, dtype=np.float32); w[y==0] = w0\n",
        "    if len(y) > 2:\n",
        "        bmask = (y[1:-1] != y[:-2]) | (y[1:-1] != y[2:])\n",
        "        w[1:-1][bmask] = 0.0\n",
        "    return w\n",
        "\n",
        "def train_fold_model_v15(X, y, seed:int=42, num_rounds:int=900):\n",
        "    w = make_weights_with_boundary_erosion(y, w0=0.38)\n",
        "    dtr = xgb.DMatrix(X, label=y, weight=w)\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 21,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'predictor': 'gpu_predictor',\n",
        "        'max_bin': 512,\n",
        "        'max_depth': 7,\n",
        "        'eta': 0.085,\n",
        "        'subsample': 0.85,\n",
        "        'colsample_bytree': 0.85,\n",
        "        'min_child_weight': 4.0,\n",
        "        'lambda': 1.0,\n",
        "        'seed': int(seed)\n",
        "    }\n",
        "    bst = xgb.train(params, dtr, num_boost_round=num_rounds, verbose_eval=200)\n",
        "    return bst\n",
        "\n",
        "def build_oof_probs_v15(n_splits=5, seed=42, num_rounds=900):\n",
        "    ids = train_df['Id'].tolist()\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    fold = 0; t_all = time.time()\n",
        "    for tr_idx, va_idx in kf.split(ids):\n",
        "        fold += 1\n",
        "        tr_ids = [ids[i] for i in tr_idx]\n",
        "        va_ids = [ids[i] for i in va_idx]\n",
        "        print(f\"[OOF] Fold {fold}/{n_splits}: tr={len(tr_ids)} va={len(va_ids)}\", flush=True)\n",
        "        X_tr, y_tr = load_many_train_frames_v15(tr_ids)\n",
        "        t0 = time.time()\n",
        "        bst = train_fold_model_v15(X_tr, y_tr, seed=seed+fold, num_rounds=num_rounds)\n",
        "        print(f\"[OOF] Fold {fold} model trained in {time.time()-t0:.1f}s\", flush=True)\n",
        "        # Predict each VA id independently and save per-id probs\n",
        "        for i, sid in enumerate(va_ids, 1):\n",
        "            X_va, _, seq20 = load_train_item_v15(sid)\n",
        "            P = bst.predict(xgb.DMatrix(X_va))\n",
        "            outp = os.path.join(OOF_DIR_V15, f'oof_{sid:05d}.npz')\n",
        "            np.savez_compressed(outp, probs=P.astype(np.float32), seq=seq20, sid=sid)\n",
        "            if i % 10 == 0:\n",
        "                print(f\"  [OOF] Fold {fold} saved {i}/{len(va_ids)}\", flush=True)\n",
        "    print(f\"[OOF] Completed {n_splits}-fold OOF in {time.time()-t_all:.1f}s. Files in {OOF_DIR_V15}\")\n",
        "\n",
        "def load_all_oof_items_v15():\n",
        "    files = sorted(glob.glob(os.path.join(OOF_DIR_V15, 'oof_*.npz')))\n",
        "    items = []\n",
        "    for fp in files:\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        sid = int(d['sid']); P = d['probs']; seq = d['seq']\n",
        "        items.append((sid, P, seq))\n",
        "    return items\n",
        "\n",
        "def grid_search_decoder_dp_on_oof():\n",
        "    items = load_all_oof_items_v15()\n",
        "    assert items, 'No OOF files found. Run build_oof_probs_v15() first.'\n",
        "    grids = {\n",
        "        'lambda': [0.6, 0.8, 1.0, 1.2],\n",
        "        'bg_bias': [0.2, 0.3, 0.4],\n",
        "        'merge_gap': [3, 4, 5, 6],\n",
        "        'min_len': [6, 8, 10, 12],\n",
        "        'mean_thr': [0.50],\n",
        "        'max_thr': [0.65]\n",
        "    }\n",
        "    best = (1e9, None); tried = 0; t0 = time.time()\n",
        "    for lam in grids['lambda']:\n",
        "        for bb in grids['bg_bias']:\n",
        "            for mg in grids['merge_gap']:\n",
        "                for ml in grids['min_len']:\n",
        "                    for mthr in grids['mean_thr']:\n",
        "                        for xthr in grids['max_thr']:\n",
        "                            scores = []\n",
        "                            for sid, P, seq in items:\n",
        "                                pred = decode_sequence_dp(P, switch_penalty=lam, bg_bias=bb, merge_gap=mg, min_len=ml, mean_thr=mthr, max_thr=xthr)\n",
        "                                lev = levenshtein(list(pred), list(seq.tolist()))\n",
        "                                # Normalize by 20 fixed tokens\n",
        "                                scores.append(lev / 20.0)\n",
        "                            mean_norm = float(np.mean(scores)) if scores else 1.0\n",
        "                            tried += 1\n",
        "                            if tried % 20 == 0:\n",
        "                                print(f\"[Grid-OOF] {tried} combos, curr mean={mean_norm:.4f} best={best[0]:.4f}\", flush=True)\n",
        "                            if mean_norm < best[0]:\n",
        "                                best = (mean_norm, {'lambda':lam,'bg_bias':bb,'merge_gap':mg,'min_len':ml,'mean_thr':mthr,'max_thr':xthr})\n",
        "    print(f\"[Grid-OOF] Done {tried} combos in {time.time()-t0:.1f}s. Best={best}\")\n",
        "    return best\n",
        "\n",
        "print('[OOF] Ready: run build_oof_probs_v15(); then best_oof = grid_search_decoder_dp_on_oof() to tune decoder on TRAIN-only OOF.', flush=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Ready: run build_oof_probs_v15(); then best_oof = grid_search_decoder_dp_on_oof() to tune decoder on TRAIN-only OOF.\n"
          ]
        }
      ]
    },
    {
      "id": "064d7f2b-c345-41e8-a00b-03deda78658f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 15) Train on TRAIN+VAL (v1.5), predict TEST, decode with rescue, and write submission.csv\n",
        "import os, glob, time, json, numpy as np, pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "def load_frames_from_cache_v15(prefix:str):\n",
        "    files = sorted(glob.glob(os.path.join(CACHE_DIR_V15, f\"{prefix}_*.npz\")))\n",
        "    Xs, ys = [], []\n",
        "    n = 0; t0 = time.time()\n",
        "    for i, fp in enumerate(files, 1):\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        X = d['X']; y = d['y']\n",
        "        Xs.append(X); ys.append(y.astype(np.int32)); n += len(y)\n",
        "        if i % 20 == 0:\n",
        "            print(f\"[LoadV15] {prefix}: {i}/{len(files)} files, cum frames={n}\", flush=True)\n",
        "    X = np.vstack(Xs) if Xs else np.zeros((0,0), dtype=np.float32)\n",
        "    y = np.concatenate(ys) if ys else np.zeros((0,), dtype=np.int32)\n",
        "    print(f\"[LoadV15] {prefix}: X={X.shape} y={y.shape} files={len(files)}\", flush=True)\n",
        "    return X, y, files\n",
        "\n",
        "def ensure_test_cache_v15():\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    todo = []\n",
        "    for sid in test_ids:\n",
        "        out_path = os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz')\n",
        "        if not os.path.exists(out_path):\n",
        "            todo.append(sid)\n",
        "    if todo:\n",
        "        print(f\"[CacheV15][TEST] {len(todo)}/{len(test_ids)} missing; caching with stride=2...\")\n",
        "        parallel_cache_v15('test', test_ids, max_workers=12, stride=2)\n",
        "    else:\n",
        "        print('[CacheV15][TEST] All test cached.')\n",
        "\n",
        "def make_weights_with_boundary_erosion(y: np.ndarray, w0: float=0.38):\n",
        "    w = np.ones_like(y, dtype=np.float32); w[y==0] = w0\n",
        "    if len(y) > 2:\n",
        "        bmask = (y[1:-1] != y[:-2]) | (y[1:-1] != y[2:])\n",
        "        w[1:-1][bmask] = 0.0\n",
        "    return w\n",
        "\n",
        "def train_seed_model_v15(X, y, seed:int):\n",
        "    w = make_weights_with_boundary_erosion(y, w0=0.38)\n",
        "    dtr = xgb.DMatrix(X, label=y, weight=w)\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 21,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'predictor': 'gpu_predictor',\n",
        "        'max_bin': 512,\n",
        "        'max_depth': 7,\n",
        "        'eta': 0.085,\n",
        "        'subsample': 0.85,\n",
        "        'colsample_bytree': 0.85,\n",
        "        'min_child_weight': 4.0,\n",
        "        'lambda': 1.0,\n",
        "        'seed': int(seed)\n",
        "    }\n",
        "    print(f\"[XGB-V15][Seed {seed}] Training...\")\n",
        "    t0 = time.time()\n",
        "    bst = xgb.train(params, dtr, num_boost_round=1100, verbose_eval=200)\n",
        "    print(f\"[XGB-V15][Seed {seed}] Done in {time.time()-t0:.1f}s\")\n",
        "    return bst\n",
        "\n",
        "def order_preserving_perm_from_probs(P: np.ndarray, alpha: float = 1.5) -> list:\n",
        "    # Build a length-20 permutation by sorting classes 1..20 by temporal centroid of P(t,c)^alpha\n",
        "    T, C = P.shape\n",
        "    assert C >= 21, 'Expect probs with 21 classes (0=bg, 1..20 gestures)'\n",
        "    t = np.arange(T, dtype=np.float32)\n",
        "    W = np.power(P[:, 1:], alpha)  # (T,20)\n",
        "    denom = W.sum(axis=0) + 1e-9\n",
        "    mu = (W * t[:, None]).sum(axis=0) / denom  # (20,)\n",
        "    # Tie-break by total mass (descending) then peak prob (descending)\n",
        "    mass = P[:, 1:].sum(axis=0)\n",
        "    peak = P[:, 1:].max(axis=0)\n",
        "    # argsort by mu asc; for ties adjust by -mass and -peak\n",
        "    idx_mu = np.argsort(mu, kind='mergesort')\n",
        "    # Stable sorts: first by negative peak, then negative mass, then mu\n",
        "    idx = idx_mu\n",
        "    # apply tie-breakers via stable argsort on keys in reverse priority\n",
        "    order_mass = np.argsort(-mass, kind='mergesort')\n",
        "    order_peak = np.argsort(-peak, kind='mergesort')\n",
        "    # Compose by ranking positions\n",
        "    ranks_mu = np.empty_like(idx_mu); ranks_mu[idx_mu] = np.arange(len(idx_mu))\n",
        "    ranks_mass = np.empty_like(order_mass); ranks_mass[order_mass] = np.arange(len(order_mass))\n",
        "    ranks_peak = np.empty_like(order_peak); ranks_peak[order_peak] = np.arange(len(order_peak))\n",
        "    score = ranks_mu + 1e-3*ranks_mass + 1e-6*ranks_peak\n",
        "    final_idx = np.argsort(score, kind='mergesort')\n",
        "    classes = [int(i+1) for i in final_idx]\n",
        "    return classes\n",
        "\n",
        "def ensure_permutation_20(pred_seq: list, P: np.ndarray) -> list:\n",
        "    # Keep unique classes from pred in order if already a perfect permutation; else fall back to order-only ranking\n",
        "    uniq = []\n",
        "    seen = set()\n",
        "    for c in pred_seq:\n",
        "        if 1 <= int(c) <= 20 and int(c) not in seen:\n",
        "            uniq.append(int(c)); seen.add(int(c))\n",
        "    if len(uniq) == 20:\n",
        "        return uniq\n",
        "    return order_preserving_perm_from_probs(P, alpha=1.5)\n",
        "\n",
        "# Use DP decoder if params contains DP keys; else use vanilla decode_sequence\n",
        "def decode_with_rescue(P, params):\n",
        "    if all(k in params for k in ('lambda','bg_bias','merge_gap','min_len','mean_thr','max_thr')):\n",
        "        pred = decode_sequence_dp(P, switch_penalty=params['lambda'], bg_bias=params['bg_bias'],\n",
        "                                 merge_gap=params['merge_gap'], min_len=params['min_len'],\n",
        "                                 mean_thr=params['mean_thr'], max_thr=params['max_thr'])\n",
        "    else:\n",
        "        pred = decode_sequence(P, window=params['window'], merge_gap=params['merge_gap'],\n",
        "                               min_len=params['min_len'], mean_thr=params['mean_thr'], max_thr=params['max_thr'])\n",
        "    return ensure_permutation_20(pred, P)\n",
        "\n",
        "def predict_test_and_write_submission_v15(models, decoder_params, out_csv='submission.csv'):\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    rows = []\n",
        "    t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']\n",
        "        Ps = []\n",
        "        dm = xgb.DMatrix(X)\n",
        "        for m in models:\n",
        "            Ps.append(m.predict(dm))\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        seq = decode_with_rescue(P, decoder_params)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print(f\"[SUBMISSION] Wrote {out_csv} with {len(rows)} rows.\")\n",
        "    return out_csv\n",
        "\n",
        "def run_trainval_and_test_v15(best_decoder_params:dict, seeds=(2025, 1337)):\n",
        "    print('[Train+Val V1.5] Loading TRAIN and VAL caches...')\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    X_va, y_va, _ = load_frames_from_cache_v15('val')\n",
        "    X_all = np.vstack([X_tr, X_va]); y_all = np.concatenate([y_tr, y_va])\n",
        "    print('[Train+Val V1.5] Frames:', X_all.shape, 'Labels:', y_all.shape)\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v15(X_all, y_all, seed=s))\n",
        "    ensure_test_cache_v15()\n",
        "    return predict_test_and_write_submission_v15(models, best_decoder_params, out_csv='submission.csv')\n",
        "\n",
        "print('[StageV15][Final] Ready: run run_trainval_and_test_v15(best_params_dict) after grid search to produce submission.csv')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RUN-OOF] Building 5-fold OOF per-id probabilities on TRAIN (v1.5)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Fold 1/5: tr=237 va=60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 20/237 ids, cum frames=12612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 40/237 ids, cum frames=26771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 60/237 ids, cum frames=40910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 80/237 ids, cum frames=53300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 100/237 ids, cum frames=65683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 120/237 ids, cum frames=77820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 140/237 ids, cum frames=89702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 160/237 ids, cum frames=101984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 180/237 ids, cum frames=113937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 200/237 ids, cum frames=126716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 220/237 ids, cum frames=139257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] Loaded 237 ids: X=(149171, 120) y=(149171,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Fold 1 model trained in 125.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 1 saved 10/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 1 saved 20/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 1 saved 30/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 1 saved 40/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 1 saved 50/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 1 saved 60/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Fold 2/5: tr=237 va=60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 20/237 ids, cum frames=12420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 40/237 ids, cum frames=26880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 60/237 ids, cum frames=41459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 80/237 ids, cum frames=54248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 100/237 ids, cum frames=66674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 120/237 ids, cum frames=78928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 140/237 ids, cum frames=90860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 160/237 ids, cum frames=102990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 180/237 ids, cum frames=115050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 200/237 ids, cum frames=127853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 220/237 ids, cum frames=140302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] Loaded 237 ids: X=(150256, 120) y=(150256,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Fold 2 model trained in 126.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 2 saved 10/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 2 saved 20/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 2 saved 30/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 2 saved 40/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 2 saved 50/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 2 saved 60/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Fold 3/5: tr=238 va=59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 20/238 ids, cum frames=12410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 40/238 ids, cum frames=26480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 60/238 ids, cum frames=40566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 80/238 ids, cum frames=54295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 100/238 ids, cum frames=66674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 120/238 ids, cum frames=78755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 140/238 ids, cum frames=90672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 160/238 ids, cum frames=102810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 180/238 ids, cum frames=114763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 200/238 ids, cum frames=127176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 220/238 ids, cum frames=139628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] Loaded 238 ids: X=(150261, 120) y=(150261,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Fold 3 model trained in 125.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 3 saved 10/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 3 saved 20/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 3 saved 30/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 3 saved 40/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 3 saved 50/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Fold 4/5: tr=238 va=59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 20/238 ids, cum frames=12481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 40/238 ids, cum frames=26678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 60/238 ids, cum frames=40773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 80/238 ids, cum frames=53856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 100/238 ids, cum frames=66311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 120/238 ids, cum frames=78498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 140/238 ids, cum frames=90432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 160/238 ids, cum frames=102670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 180/238 ids, cum frames=114885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 200/238 ids, cum frames=126973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 220/238 ids, cum frames=139733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] Loaded 238 ids: X=(150364, 120) y=(150364,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Fold 4 model trained in 125.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 4 saved 10/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 4 saved 20/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 4 saved 30/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 4 saved 40/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 4 saved 50/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Fold 5/5: tr=238 va=59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 20/238 ids, cum frames=12075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 40/238 ids, cum frames=25840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 60/238 ids, cum frames=39683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 80/238 ids, cum frames=52883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 100/238 ids, cum frames=65190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 120/238 ids, cum frames=77373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 140/238 ids, cum frames=89246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 160/238 ids, cum frames=101325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 180/238 ids, cum frames=113364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 200/238 ids, cum frames=126174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] 220/238 ids, cum frames=138436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFold] Loaded 238 ids: X=(149132, 120) y=(149132,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Fold 5 model trained in 125.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 5 saved 10/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 5 saved 20/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 5 saved 30/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 5 saved 40/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF] Fold 5 saved 50/59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF] Completed 5-fold OOF in 695.4s. Files in ./oof_probs_v15\n[RUN-OOF] OOF build done in 695.4s. Now grid-searching DP decoder...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF] 20 combos, curr mean=0.3136 best=0.2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF] 40 combos, curr mean=0.3118 best=0.2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF] 60 combos, curr mean=0.3061 best=0.2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF] 80 combos, curr mean=0.3044 best=0.2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF] 100 combos, curr mean=0.3027 best=0.2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF] 120 combos, curr mean=0.3005 best=0.2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF] 140 combos, curr mean=0.2992 best=0.2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF] 160 combos, curr mean=0.2965 best=0.2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF] 180 combos, curr mean=0.2929 best=0.2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF] Done 192 combos in 315.2s. Best=(0.2001683501683502, {'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 6, 'mean_thr': 0.5, 'max_thr': 0.65})\nBest OOF DP decoder params: (0.2001683501683502, {'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 6, 'mean_thr': 0.5, 'max_thr': 0.65})\n[RUN-OOF] Total elapsed: 1010.7s\n"
          ]
        }
      ]
    },
    {
      "id": "c4ef307d-29b6-4cce-b7b3-fe4bd92317d9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 22) Final run with OOF-tuned DP params and order-preserving rescue\n",
        "print('[FINAL RUN - OOF PARAMS] Using OOF-tuned DP decoder params...')\n",
        "dp_params_oof = {'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 6, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "print('DP params (OOF):', dp_params_oof)\n",
        "sub_path = run_trainval_and_test_v15(dp_params_oof, seeds=(2025, 1337))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FINAL RUN - OOF PARAMS] Using OOF-tuned DP decoder params...\nDP params (OOF): {'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 6, 'mean_thr': 0.5, 'max_thr': 0.65}\n[Train+Val V1.5] Loading TRAIN and VAL caches...\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 20/277 files, cum frames=13096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 40/277 files, cum frames=25838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 60/277 files, cum frames=38691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 80/277 files, cum frames=51151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 100/277 files, cum frames=63623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 120/277 files, cum frames=75902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 140/277 files, cum frames=91628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 160/277 files, cum frames=108270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 180/277 files, cum frames=124959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 200/277 files, cum frames=142423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 220/277 files, cum frames=160046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 240/277 files, cum frames=178417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 260/277 files, cum frames=197128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: X=(213026, 120) y=(213026,) files=277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Train+Val V1.5] Frames: (400322, 120) Labels: (400322,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 231.6s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 235.5s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 10/95 done; elapsed 5.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 20/95 done; elapsed 10.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 30/95 done; elapsed 16.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 40/95 done; elapsed 21.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 50/95 done; elapsed 26.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 60/95 done; elapsed 32.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 70/95 done; elapsed 37.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 80/95 done; elapsed 42.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 90/95 done; elapsed 47.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "73899653-61dc-4a6e-b9d7-ff97da6d863a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 23) Order-only centroid ranker: OOF grid search for alpha and smoothing; final infer using ranker\n",
        "import numpy as np, glob, os, time, pandas as pd, xgboost as xgb\n",
        "\n",
        "def smooth_probs(P: np.ndarray, win: int = 1) -> np.ndarray:\n",
        "    if win <= 1: return P\n",
        "    win = int(win) | 1\n",
        "    pad = win // 2\n",
        "    T, C = P.shape\n",
        "    out = np.empty_like(P)\n",
        "    for c in range(C):\n",
        "        v = P[:, c].astype(np.float32)\n",
        "        buf = np.pad(v, (pad, pad), mode='edge').astype(np.float64)\n",
        "        cs = np.cumsum(np.concatenate(([0.0], buf)))  # ensure length T after windowing\n",
        "        sm = (cs[win:] - cs[:-win]) / win  # length T\n",
        "        out[:, c] = sm.astype(np.float32)\n",
        "    return out\n",
        "\n",
        "def order_only_decode(P: np.ndarray, alpha: float = 1.5, smooth_win: int = 1) -> list:\n",
        "    P2 = smooth_probs(P, smooth_win)\n",
        "    T, C = P2.shape\n",
        "    t = np.arange(T, dtype=np.float32)\n",
        "    W = np.power(P2[:, 1:], alpha)  # exclude bg\n",
        "    denom = W.sum(axis=0) + 1e-9\n",
        "    mu = (W * t[:, None]).sum(axis=0) / denom  # (20,)\n",
        "    mass = P2[:, 1:].sum(axis=0)\n",
        "    peak = P2[:, 1:].max(axis=0)\n",
        "    # rank by mu asc; tie-break by mass desc, then peak desc\n",
        "    ranks_mu = np.argsort(mu, kind='mergesort')\n",
        "    ranks_mass = np.argsort(-mass, kind='mergesort')\n",
        "    ranks_peak = np.argsort(-peak, kind='mergesort')\n",
        "    inv_mu = np.empty_like(ranks_mu); inv_mu[ranks_mu] = np.arange(20)\n",
        "    inv_mass = np.empty_like(ranks_mass); inv_mass[ranks_mass] = np.arange(20)\n",
        "    inv_peak = np.empty_like(ranks_peak); inv_peak[ranks_peak] = np.arange(20)\n",
        "    score = inv_mu + 1e-3*inv_mass + 1e-6*inv_peak\n",
        "    final_idx = np.argsort(score, kind='mergesort')\n",
        "    return [int(i+1) for i in final_idx]\n",
        "\n",
        "def load_all_oof_items_v15():\n",
        "    files = sorted(glob.glob(os.path.join(OOF_DIR_V15, 'oof_*.npz')))\n",
        "    items = []\n",
        "    for fp in files:\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        items.append((int(d['sid']), d['probs'], d['seq']))\n",
        "    return items\n",
        "\n",
        "def grid_search_ranker_on_oof():\n",
        "    items = load_all_oof_items_v15()\n",
        "    assert items, 'No OOF files found. Build OOF first.'\n",
        "    alphas = [1.2, 1.5, 1.8, 2.0]\n",
        "    wins = [1, 3, 5, 7, 9]\n",
        "    best = (1e9, None); tried = 0; t0 = time.time()\n",
        "    for a in alphas:\n",
        "        for w in wins:\n",
        "            scores = []\n",
        "            for sid, P, seq in items:\n",
        "                pred = order_only_decode(P, alpha=a, smooth_win=w)\n",
        "                lev = levenshtein(pred, list(seq.tolist()))\n",
        "                scores.append(lev/20.0)\n",
        "            mean_norm = float(np.mean(scores))\n",
        "            tried += 1\n",
        "            if tried % 5 == 0:\n",
        "                print(f\"[Grid-OOF-Ranker] {tried} combos, curr mean={mean_norm:.4f} best={best[0]:.4f}\", flush=True)\n",
        "            if mean_norm < best[0]:\n",
        "                best = (mean_norm, {'alpha': a, 'smooth_win': w})\n",
        "    print(f\"[Grid-OOF-Ranker] Done {tried} combos in {time.time()-t0:.1f}s. Best={best}\")\n",
        "    return best\n",
        "\n",
        "def predict_test_with_ranker_and_write_submission_v15(models, ranker_params, out_csv='submission.csv'):\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']\n",
        "        dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        seq = order_only_decode(P, alpha=ranker_params['alpha'], smooth_win=ranker_params['smooth_win'])\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-Ranker] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print(f\"[SUBMISSION] Wrote {out_csv} with {len(rows)} rows.\")\n",
        "    return out_csv\n",
        "\n",
        "print('[Ranker] Ready: run best_ranker = grid_search_ranker_on_oof(); then predict_test_with_ranker_and_write_submission_v15(models, best_ranker[1])')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ranker] Ready: run best_ranker = grid_search_ranker_on_oof(); then predict_test_with_ranker_and_write_submission_v15(models, best_ranker[1])\n"
          ]
        }
      ]
    },
    {
      "id": "54065e8b-9506-4768-8c8e-63d13012fe0a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 24) Run OOF ranker grid, then train on TRAIN+VAL and infer TEST with ranker\n",
        "print('[Ranker] Grid-search on OOF...')\n",
        "best_ranker = grid_search_ranker_on_oof()\n",
        "print('Best ranker params:', best_ranker)\n",
        "\n",
        "print('[Ranker] Training models on TRAIN+VAL for final inference...')\n",
        "X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "X_va, y_va, _ = load_frames_from_cache_v15('val')\n",
        "X_all = np.vstack([X_tr, X_va]); y_all = np.concatenate([y_tr, y_va])\n",
        "models = []\n",
        "for s in (2025, 1337):\n",
        "    models.append(train_seed_model_v15(X_all, y_all, seed=s))\n",
        "ensure_test_cache_v15()\n",
        "sub_ranker = predict_test_with_ranker_and_write_submission_v15(models, best_ranker[1], out_csv='submission.csv')\n",
        "print('Ranker submission written to:', sub_ranker)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ranker] Grid-search on OOF...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Ranker] 5 combos, curr mean=0.5184 best=0.5204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Ranker] 10 combos, curr mean=0.4497 best=0.4529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Ranker] 15 combos, curr mean=0.3928 best=0.3955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Ranker] 20 combos, curr mean=0.3643 best=0.3687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Ranker] Done 20 combos in 3.8s. Best=(0.36430976430976436, {'alpha': 2.0, 'smooth_win': 9})\nBest ranker params: (0.36430976430976436, {'alpha': 2.0, 'smooth_win': 9})\n[Ranker] Training models on TRAIN+VAL for final inference...\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 20/277 files, cum frames=13096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 40/277 files, cum frames=25838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 60/277 files, cum frames=38691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 80/277 files, cum frames=51151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 100/277 files, cum frames=63623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 120/277 files, cum frames=75902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 140/277 files, cum frames=91628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 160/277 files, cum frames=108270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 180/277 files, cum frames=124959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 200/277 files, cum frames=142423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 220/277 files, cum frames=160046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 240/277 files, cum frames=178417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: 260/277 files, cum frames=197128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] val: X=(213026, 120) y=(213026,) files=277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 234.7s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 236.2s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'xgboost' is not defined",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m     models.append(train_seed_model_v15(X_all, y_all, seed=s))\n\u001b[32m     13\u001b[39m ensure_test_cache_v15()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m sub_ranker = \u001b[43mpredict_test_with_ranker_and_write_submission_v15\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_ranker\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_csv\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msubmission.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mRanker submission written to:\u001b[39m\u001b[33m'\u001b[39m, sub_ranker)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mpredict_test_with_ranker_and_write_submission_v15\u001b[39m\u001b[34m(models, ranker_params, out_csv)\u001b[39m\n\u001b[32m     72\u001b[39m d = np.load(os.path.join(CACHE_DIR_V15, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtest_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msid\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m05d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npz\u001b[39m\u001b[33m'\u001b[39m), allow_pickle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     73\u001b[39m X = d[\u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m dm = \u001b[43mxgboost\u001b[49m.DMatrix(X)\n\u001b[32m     75\u001b[39m Ps = [m.predict(dm) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m models]\n\u001b[32m     76\u001b[39m P = np.mean(np.stack(Ps, axis=\u001b[32m0\u001b[39m), axis=\u001b[32m0\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'xgboost' is not defined"
          ]
        }
      ]
    },
    {
      "id": "66c6715d-3cc7-4108-9dba-8507f268a0f2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 25) Fix alias and run ranker inference without retraining\n",
        "import xgboost as xgb\n",
        "xgboost = xgb  # provide alias for legacy function reference\n",
        "print('[Ranker] Running test inference with order-only ranker using best_ranker params...')\n",
        "ensure_test_cache_v15()\n",
        "sub_ranker = predict_test_with_ranker_and_write_submission_v15(models, best_ranker[1], out_csv='submission.csv')\n",
        "print('Ranker submission written to:', sub_ranker)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Ranker] Running test inference with order-only ranker using best_ranker params...\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Ranker] 10/95 done; elapsed 5.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Ranker] 20/95 done; elapsed 10.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Ranker] 30/95 done; elapsed 16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Ranker] 40/95 done; elapsed 21.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Ranker] 50/95 done; elapsed 26.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Ranker] 60/95 done; elapsed 32.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Ranker] 70/95 done; elapsed 37.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Ranker] 80/95 done; elapsed 42.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Ranker] 90/95 done; elapsed 48.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nRanker submission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "3588997f-09af-48cc-9edd-08db7343f439",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 26) Train on TRAIN-only (no VAL frames), infer TEST with OOF-tuned DP params\n",
        "print('[FINAL RUN - TRAIN ONLY] Training models on TRAIN cache (v1.5), no VAL frames used...')\n",
        "dp_params_oof = {'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 6, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "print('Using DP params (OOF):', dp_params_oof)\n",
        "\n",
        "X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "print('[TRAIN ONLY] Frames:', X_tr.shape, 'Labels:', y_tr.shape)\n",
        "models = []\n",
        "for s in (2025, 1337):\n",
        "    models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "ensure_test_cache_v15()\n",
        "sub_path = predict_test_and_write_submission_v15(models, dp_params_oof, out_csv='submission.csv')\n",
        "print('Submission (TRAIN-only) written to:', sub_path)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FINAL RUN - TRAIN ONLY] Training models on TRAIN cache (v1.5), no VAL frames used...\nUsing DP params (OOF): {'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 6, 'mean_thr': 0.5, 'max_thr': 0.65}\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN ONLY] Frames: (187296, 120) Labels: (187296,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 165.9s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.9s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 10/95 done; elapsed 5.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 20/95 done; elapsed 10.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 30/95 done; elapsed 16.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 40/95 done; elapsed 21.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 50/95 done; elapsed 26.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 60/95 done; elapsed 32.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 70/95 done; elapsed 37.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 80/95 done; elapsed 42.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] 90/95 done; elapsed 47.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission (TRAIN-only) written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "da6e3c95-46c0-47ac-86d8-c0fea1ff81ef",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 27) Full-pipeline decoding: temperature + smoothing + DP + order-preserving rescue; OOF grid\n",
        "import numpy as np, glob, os, time, pandas as pd, xgboost as xgb\n",
        "\n",
        "# Reuse OOF dir from earlier\n",
        "OOF_DIR_V15 = './oof_probs_v15'\n",
        "\n",
        "def smooth_probs_ma(P: np.ndarray, win: int = 1) -> np.ndarray:\n",
        "    if win <= 1: return P\n",
        "    win = int(win) | 1\n",
        "    pad = win // 2\n",
        "    T, C = P.shape\n",
        "    out = np.empty_like(P)\n",
        "    for c in range(C):\n",
        "        v = P[:, c].astype(np.float32)\n",
        "        buf = np.pad(v, (pad, pad), mode='edge').astype(np.float64)\n",
        "        cs = np.cumsum(np.concatenate(([0.0], buf)))\n",
        "        sm = (cs[win:] - cs[:-win]) / win\n",
        "        out[:, c] = sm.astype(np.float32)\n",
        "    return out\n",
        "\n",
        "def apply_temperature(P: np.ndarray, T: float = 1.5) -> np.ndarray:\n",
        "    # Work with probabilities; approximate temperature by power 1/T then re-normalize per frame\n",
        "    T = float(T)\n",
        "    if abs(T - 1.0) < 1e-6: return P\n",
        "    Ppow = np.power(np.clip(P, 1e-9, 1.0), 1.0 / T).astype(np.float32)\n",
        "    Ppow /= (Ppow.sum(axis=1, keepdims=True) + 1e-9)\n",
        "    return Ppow\n",
        "\n",
        "def class_time_centroids(P: np.ndarray, alpha: float = 1.5):\n",
        "    # returns mu (20,), mass (20,), peak (20,) for classes 1..20\n",
        "    T, C = P.shape\n",
        "    t = np.arange(T, dtype=np.float32)\n",
        "    W = np.power(P[:, 1:], alpha)\n",
        "    denom = W.sum(axis=0) + 1e-9\n",
        "    mu = (W * t[:, None]).sum(axis=0) / denom\n",
        "    mass = P[:, 1:].sum(axis=0)\n",
        "    peak = P[:, 1:].max(axis=0)\n",
        "    return mu, mass, peak\n",
        "\n",
        "def ensure_perm20_preserve_dp(dp_seq: list, P: np.ndarray, alpha: float = 1.5) -> list:\n",
        "    # Keep DP unique classes in their DP order; insert missing classes by centroid time relative to DP times\n",
        "    # Compute centroids for all classes 1..20\n",
        "    mu, mass, peak = class_time_centroids(P, alpha=alpha)\n",
        "    # Unique DP classes within [1..20]\n",
        "    dp_uniq = []\n",
        "    seen = set()\n",
        "    for c in dp_seq:\n",
        "        if 1 <= int(c) <= 20 and int(c) not in seen:\n",
        "            dp_uniq.append(int(c)); seen.add(int(c))\n",
        "    if len(dp_uniq) == 20:\n",
        "        return dp_uniq\n",
        "    missing = [c for c in range(1, 21) if c not in seen]\n",
        "    # Compute mu for DP classes (aligned to their order) and for missing\n",
        "    mu_dp = [mu[c-1] for c in dp_uniq]\n",
        "    # Insert each missing class by its mu into the dp_uniq without reordering dp_uniq\n",
        "    # Sort missing by mu ascending to insert in temporal order\n",
        "    missing_sorted = sorted(missing, key=lambda c: (mu[c-1], -mass[c-1], -peak[c-1]))\n",
        "    out = list(dp_uniq)\n",
        "    mu_out = list(mu_dp)\n",
        "    for c in missing_sorted:\n",
        "        m = mu[c-1]\n",
        "        # find first position where m <= mu_out[i]; else append\n",
        "        pos = None\n",
        "        for i in range(len(mu_out)):\n",
        "            if m <= mu_out[i]:\n",
        "                pos = i; break\n",
        "        if pos is None:\n",
        "            out.append(c); mu_out.append(m)\n",
        "        else:\n",
        "            out.insert(pos, c); mu_out.insert(pos, m)\n",
        "        if len(out) > 20:\n",
        "            # if overflow due to pathological insertions, drop last lowest-confidence by mass, but keep DP-chosen fixed\n",
        "            # Keep first 20 as a safe fallback (rare)\n",
        "            out = out[:20]; mu_out = mu_out[:20]\n",
        "    # Guarantee size 20\n",
        "    if len(out) < 20:\n",
        "        # Fill by remaining classes ordered by descending mass\n",
        "        rem2 = [c for c in range(1,21) if c not in set(out)]\n",
        "        rem2.sort(key=lambda c: mass[c-1], reverse=True)\n",
        "        out.extend(rem2[:(20-len(out))])\n",
        "    return out[:20]\n",
        "\n",
        "def preprocess_probs(P: np.ndarray, T: float, smooth_win: int) -> np.ndarray:\n",
        "    P2 = apply_temperature(P, T=T)\n",
        "    P3 = smooth_probs_ma(P2, win=smooth_win)\n",
        "    return P3\n",
        "\n",
        "def decode_full_pipeline(P: np.ndarray, dp_params: dict, T: float = 1.5, smooth_win: int = 5, alpha_fill: float = 1.5) -> list:\n",
        "    Pp = preprocess_probs(P, T=T, smooth_win=smooth_win)\n",
        "    pred = decode_sequence_dp(Pp,\n",
        "                             switch_penalty=dp_params.get('lambda', 0.8),\n",
        "                             bg_bias=dp_params.get('bg_bias', 0.2),\n",
        "                             merge_gap=dp_params.get('merge_gap', 3),\n",
        "                             min_len=dp_params.get('min_len', 10),\n",
        "                             mean_thr=dp_params.get('mean_thr', 0.5),\n",
        "                             max_thr=dp_params.get('max_thr', 0.65))\n",
        "    return ensure_perm20_preserve_dp(pred, Pp, alpha=alpha_fill)\n",
        "\n",
        "def load_all_oof_items_v15():\n",
        "    files = sorted(glob.glob(os.path.join(OOF_DIR_V15, 'oof_*.npz')))\n",
        "    items = []\n",
        "    for fp in files:\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        items.append((int(d['sid']), d['probs'], d['seq']))\n",
        "    return items\n",
        "\n",
        "def grid_search_full_pipeline_on_oof():\n",
        "    items = load_all_oof_items_v15()\n",
        "    assert items, 'No OOF files found (run build_oof_probs_v15 first).'\n",
        "    Ts = [1.3, 1.5, 1.7, 1.9]\n",
        "    wins = [1, 5]\n",
        "    lambdas = [0.8, 1.0]\n",
        "    minlens = [10, 12]\n",
        "    bg_biases = [0.2, 0.3]\n",
        "    merge_gaps = [3, 4]\n",
        "    best = (1e9, None); tried = 0; t0 = time.time()\n",
        "    for T in Ts:\n",
        "        for win in wins:\n",
        "            for lam in lambdas:\n",
        "                for ml in minlens:\n",
        "                    for bb in bg_biases:\n",
        "                        for mg in merge_gaps:\n",
        "                            dp = {'lambda': lam, 'bg_bias': bb, 'merge_gap': mg, 'min_len': ml, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "                            scores = []\n",
        "                            for sid, P, seq in items:\n",
        "                                pred = decode_full_pipeline(P, dp, T=T, smooth_win=win, alpha_fill=1.5)\n",
        "                                lev = levenshtein(list(pred), list(seq.tolist()))\n",
        "                                scores.append(lev / 20.0)\n",
        "                            mean_norm = float(np.mean(scores))\n",
        "                            tried += 1\n",
        "                            if tried % 10 == 0:\n",
        "                                print(f\"[Grid-OOF-Full] {tried} combos, curr mean={mean_norm:.4f} best={best[0]:.4f}\", flush=True)\n",
        "                            if mean_norm < best[0]:\n",
        "                                best = (mean_norm, {'T': T, 'smooth_win': win, **dp})\n",
        "    print(f\"[Grid-OOF-Full] Done {tried} combos in {time.time()-t0:.1f}s. Best={best}\")\n",
        "    return best\n",
        "\n",
        "def predict_test_full_pipeline_train_only(best_params: dict, seeds=(2025,1337,42)):\n",
        "    # Train TRAIN-only models, average probs, apply full pipeline and write submission.csv\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    ensure_test_cache_v15()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        seq = decode_full_pipeline(P, best_params, T=best_params['T'], smooth_win=best_params['smooth_win'], alpha_fill=1.5)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-Full] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[FullPipeline] Ready: run best_full = grid_search_full_pipeline_on_oof(); then predict_test_full_pipeline_train_only(best_full[1], seeds=(2025,1337,42))')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FullPipeline] Ready: run best_full = grid_search_full_pipeline_on_oof(); then predict_test_full_pipeline_train_only(best_full[1], seeds=(2025,1337,42))\n"
          ]
        }
      ]
    },
    {
      "id": "b21282f4-9d71-4668-baac-ade3258653e1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 28) Run full-pipeline OOF grid, then 3-seed TRAIN-only final inference\n",
        "print('[FullPipeline] Grid-search on TRAIN OOF with temperature + smoothing + conservative DP + order-preserving rescue...')\n",
        "best_full = grid_search_full_pipeline_on_oof()\n",
        "print('Best full-pipeline params:', best_full)\n",
        "\n",
        "print('[FullPipeline] TRAIN-only 3-seed inference with best params...')\n",
        "sub_path = predict_test_full_pipeline_train_only(best_full[1], seeds=(2025,1337,42))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FullPipeline] Grid-search on TRAIN OOF with temperature + smoothing + conservative DP + order-preserving rescue...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 10 combos, curr mean=0.3207 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 20 combos, curr mean=0.3320 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 30 combos, curr mean=0.3453 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 40 combos, curr mean=0.3763 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 50 combos, curr mean=0.3705 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 60 combos, curr mean=0.3707 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 70 combos, curr mean=0.4093 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 80 combos, curr mean=0.4116 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 90 combos, curr mean=0.4153 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 100 combos, curr mean=0.4434 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 110 combos, curr mean=0.4574 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] 120 combos, curr mean=0.4692 best=0.3207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-Full] Done 128 combos in 230.1s. Best=(0.3207070707070707, {'T': 1.3, 'smooth_win': 1, 'lambda': 1.0, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 10, 'mean_thr': 0.5, 'max_thr': 0.65})\nBest full-pipeline params: (0.3207070707070707, {'T': 1.3, 'smooth_win': 1, 'lambda': 1.0, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 10, 'mean_thr': 0.5, 'max_thr': 0.65})\n[FullPipeline] TRAIN-only 3-seed inference with best params...\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 165.8s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.8s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.6s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 10/95 done; elapsed 8.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 20/95 done; elapsed 16.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 30/95 done; elapsed 24.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 40/95 done; elapsed 32.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 50/95 done; elapsed 40.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 60/95 done; elapsed 48.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 70/95 done; elapsed 56.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 80/95 done; elapsed 63.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 90/95 done; elapsed 71.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "e3ec4700-9eb1-4476-9b4d-4f07a55def45",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 29) Full-pipeline final attempt: conservative DP + T=1.5, win=5, 5-seed TRAIN-only\n",
        "print('[FullPipeline-Final] Using conservative settings per expert advice...')\n",
        "best_params_final = {'T': 1.5, 'smooth_win': 5, 'lambda': 0.8, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "print('Params:', best_params_final)\n",
        "sub_path = predict_test_full_pipeline_train_only(best_params_final, seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FullPipeline-Final] Using conservative settings per expert advice...\nParams: {'T': 1.5, 'smooth_win': 5, 'lambda': 0.8, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 165.9s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.6s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.4s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 165.9s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 165.6s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 10/95 done; elapsed 13.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 20/95 done; elapsed 27.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 30/95 done; elapsed 40.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 40/95 done; elapsed 53.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 50/95 done; elapsed 66.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 60/95 done; elapsed 79.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 70/95 done; elapsed 93.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 80/95 done; elapsed 106.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 90/95 done; elapsed 118.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "df90f675-27e5-4267-88fb-144621d7b906",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 30) Align to strong OOF DP: T=1.0, win=1, lambda=0.6, min_len=6; TRAIN-only 3-seed with order-preserving fill\n",
        "print('[FullPipeline-OOFDP] Using raw-DP-aligned params (no temp, no smoothing) to match OOF best...')\n",
        "params_oofdp = {'T': 1.0, 'smooth_win': 1, 'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 6, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "print('Params:', params_oofdp)\n",
        "sub_path = predict_test_full_pipeline_train_only(params_oofdp, seeds=(2025,1337,42))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FullPipeline-OOFDP] Using raw-DP-aligned params (no temp, no smoothing) to match OOF best...\nParams: {'T': 1.0, 'smooth_win': 1, 'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 6, 'mean_thr': 0.5, 'max_thr': 0.65}\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 166.0s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.9s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.8s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 10/95 done; elapsed 8.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 20/95 done; elapsed 16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 30/95 done; elapsed 24.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 40/95 done; elapsed 32.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 50/95 done; elapsed 40.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 60/95 done; elapsed 48.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 70/95 done; elapsed 56.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 80/95 done; elapsed 64.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 90/95 done; elapsed 72.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "d17311be-053d-453b-b80c-d478c83fc562",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 31) Conservative DP, TRAIN-only, 5-seed, no temp/smoothing (align OOF hygiene)\n",
        "print('[FullPipeline-Conservative] TRAIN-only 5-seed, T=1.0, smooth_win=1, DP lambda=0.8, min_len=12 ...')\n",
        "best_params_conservative = {'T': 1.0, 'smooth_win': 1, 'lambda': 0.8, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "print('Params:', best_params_conservative)\n",
        "sub_path = predict_test_full_pipeline_train_only(best_params_conservative, seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FullPipeline-Conservative] TRAIN-only 5-seed, T=1.0, smooth_win=1, DP lambda=0.8, min_len=12 ...\nParams: {'T': 1.0, 'smooth_win': 1, 'lambda': 0.8, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 165.7s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.8s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.4s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 165.9s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 165.6s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 10/95 done; elapsed 13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 20/95 done; elapsed 26.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 30/95 done; elapsed 40.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 40/95 done; elapsed 53.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 50/95 done; elapsed 66.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 60/95 done; elapsed 79.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 70/95 done; elapsed 92.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 80/95 done; elapsed 105.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 90/95 done; elapsed 117.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "c8766d32-98e4-410b-84ae-ec0b3896156e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 32) Per-class duration priors (p30 clipped to [8,12]) + conservative DP; TRAIN-only 5-seed; no temp/smoothing\n",
        "import numpy as np, glob, os, time, pandas as pd, xgboost as xgb\n",
        "\n",
        "def compute_duration_priors_from_train_cache_v15(p=30.0, clip_low=8, clip_high=12):\n",
        "    files = sorted(glob.glob(os.path.join(CACHE_DIR_V15, 'train_*.npz')))\n",
        "    lens = {c: [] for c in range(1,21)}\n",
        "    for i, fp in enumerate(files, 1):\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        y = d['y'].astype(np.int32)\n",
        "        # collect run lengths per class (exclude bg=0)\n",
        "        if y.size == 0: continue\n",
        "        b = 0\n",
        "        for t in range(1, len(y)+1):\n",
        "            if t==len(y) or y[t] != y[b]:\n",
        "                cls = int(y[b])\n",
        "                if cls != 0:\n",
        "                    lens[cls].append(t-b)\n",
        "                b = t\n",
        "        if i % 25 == 0:\n",
        "            print(f\"[DurPrior] processed {i}/{len(files)} train files\", flush=True)\n",
        "    min_len_map = {}\n",
        "    for c in range(1,21):\n",
        "        arr = np.array(lens[c], dtype=np.float32)\n",
        "        if arr.size == 0:\n",
        "            ml = clip_low\n",
        "        else:\n",
        "            ml = float(np.percentile(arr, p))\n",
        "        ml = int(max(clip_low, min(clip_high, round(ml))))\n",
        "        min_len_map[c] = ml\n",
        "    print('[DurPrior] per-class min_len (clipped):', min_len_map)\n",
        "    return min_len_map\n",
        "\n",
        "def decode_sequence_dp_pc(probs, switch_penalty=1.0, bg_bias=0.0, merge_gap=4, min_len=10, mean_thr=0.5, max_thr=0.65, min_len_map=None):\n",
        "    labels = viterbi_labels(probs, switch_penalty=switch_penalty, bg_bias=bg_bias)\n",
        "    T = len(labels)\n",
        "    segs = []  # (cls, b, e, mean_p, max_p)\n",
        "    b = 0\n",
        "    for i in range(1, T+1):\n",
        "        if i==T or labels[i] != labels[b]:\n",
        "            cls = int(labels[b])\n",
        "            p = probs[b:i, cls] if cls < probs.shape[1] else np.zeros(i-b)\n",
        "            mean_p = float(p.mean()) if (i-b)>0 else 0.0\n",
        "            max_p = float(p.max()) if (i-b)>0 else 0.0\n",
        "            segs.append([cls, b, i, mean_p, max_p])\n",
        "            b = i\n",
        "    # merge small bg gaps between same class\n",
        "    merged = []\n",
        "    i = 0\n",
        "    while i < len(segs):\n",
        "        cur = segs[i]\n",
        "        j = i + 1\n",
        "        while j < len(segs):\n",
        "            if segs[j][0] == cur[0] and segs[j-1][0]==0 and (segs[j][1]-cur[2]) <= merge_gap:\n",
        "                cur[2] = segs[j][2]\n",
        "                cur[3] = float(np.mean(probs[cur[1]:cur[2], cur[0]]))\n",
        "                cur[4] = float(np.max(probs[cur[1]:cur[2], cur[0]]))\n",
        "                j += 1\n",
        "            else:\n",
        "                break\n",
        "        merged.append(cur)\n",
        "        i = j\n",
        "    out = []\n",
        "    for cls, sb, se, mp, xp in merged:\n",
        "        if cls == 0: continue\n",
        "        req_len = int(min_len_map.get(int(cls), min_len)) if min_len_map is not None else int(min_len)\n",
        "        if (se - sb) < req_len: continue\n",
        "        if not (mp >= mean_thr and xp >= max_thr): continue\n",
        "        if not out or out[-1] != int(cls):\n",
        "            out.append(int(cls))\n",
        "    return out\n",
        "\n",
        "def decode_full_pipeline_pc(P: np.ndarray, dp_params: dict, min_len_map: dict, T: float = 1.0, smooth_win: int = 1, alpha_fill: float = 1.5) -> list:\n",
        "    Pp = preprocess_probs(P, T=T, smooth_win=smooth_win)\n",
        "    pred = decode_sequence_dp_pc(Pp,\n",
        "                                switch_penalty=dp_params.get('lambda', 0.8),\n",
        "                                bg_bias=dp_params.get('bg_bias', 0.2),\n",
        "                                merge_gap=dp_params.get('merge_gap', 3),\n",
        "                                min_len=dp_params.get('min_len', 12),\n",
        "                                mean_thr=dp_params.get('mean_thr', 0.5),\n",
        "                                max_thr=dp_params.get('max_thr', 0.65),\n",
        "                                min_len_map=min_len_map)\n",
        "    return ensure_perm20_preserve_dp(pred, Pp, alpha=alpha_fill)\n",
        "\n",
        "def predict_test_full_pipeline_train_only_pc(best_params: dict, min_len_map: dict, seeds=(2025,1337,42,0,123)):\n",
        "    # TRAIN-only models, average probs, per-class-duration DP decode\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    ensure_test_cache_v15()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgboost.DMatrix(X) if 'xgboost' in globals() else xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        seq = decode_full_pipeline_pc(P, best_params, min_len_map=min_len_map, T=best_params.get('T',1.0), smooth_win=best_params.get('smooth_win',1), alpha_fill=1.5)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-PC] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[PerClassMinLen] Computing duration priors from TRAIN cache (stride=2)...')\n",
        "min_len_map = compute_duration_priors_from_train_cache_v15(p=30.0, clip_low=8, clip_high=12)\n",
        "print('[PerClassMinLen] Running TRAIN-only 5-seed inference with conservative DP and per-class min_len...')\n",
        "best_params_conservative = {'T': 1.0, 'smooth_win': 1, 'lambda': 0.8, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "sub_path = predict_test_full_pipeline_train_only_pc(best_params_conservative, min_len_map, seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PerClassMinLen] Computing duration priors from TRAIN cache (stride=2)...\n[DurPrior] processed 25/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior] processed 50/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior] processed 75/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior] processed 100/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior] processed 125/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior] processed 150/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior] processed 175/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior] processed 200/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior] processed 225/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior] processed 250/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior] processed 275/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior] per-class min_len (clipped): {1: 12, 2: 12, 3: 12, 4: 12, 5: 12, 6: 12, 7: 12, 8: 12, 9: 12, 10: 12, 11: 12, 12: 12, 13: 12, 14: 12, 15: 12, 16: 12, 17: 12, 18: 12, 19: 12, 20: 12}\n[PerClassMinLen] Running TRAIN-only 5-seed inference with conservative DP and per-class min_len...\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 165.6s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.5s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.2s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 165.6s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 165.6s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-PC] 10/95 done; elapsed 13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-PC] 20/95 done; elapsed 26.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-PC] 30/95 done; elapsed 39.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-PC] 40/95 done; elapsed 52.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-PC] 50/95 done; elapsed 65.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-PC] 60/95 done; elapsed 79.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-PC] 70/95 done; elapsed 92.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-PC] 80/95 done; elapsed 105.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-PC] 90/95 done; elapsed 117.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "b43b29d7-b7ab-4d78-8dda-1ef1507529c3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 33) Test-time stride=1 TTA: cache TEST at stride=1 and decode with doubled min_len (robust DP + DP-preserving rescue)\n",
        "import os, glob, time, numpy as np, pandas as pd, xgboost as xgb\n",
        "\n",
        "# Separate cache dir for stride=1 to avoid collisions\n",
        "CACHE_DIR_V15_S1 = './cache_v15_s1'\n",
        "os.makedirs(CACHE_DIR_V15_S1, exist_ok=True)\n",
        "\n",
        "def cache_sample_v15_to_dir(sample_id:int, split_hint:str, stride:int, out_dir:str):\n",
        "    out_path = os.path.join(out_dir, f'{split_hint}_{sample_id:05d}.npz')\n",
        "    if os.path.exists(out_path):\n",
        "        return out_path\n",
        "    vid = load_video_from_split(sample_id, split_hint)\n",
        "    skel, idxs = stack_world_positions(vid, stride=stride)\n",
        "    X = features_from_skeleton_v15(skel)\n",
        "    fps = int(vid.get('FrameRate', 20))\n",
        "    # Only TEST: no labels/seq stored\n",
        "    np.savez_compressed(out_path, X=X, fps=fps, stride=stride, sid=sample_id)\n",
        "    return out_path\n",
        "\n",
        "def ensure_test_cache_v15_stride1():\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    todo = []\n",
        "    for sid in test_ids:\n",
        "        out_path = os.path.join(CACHE_DIR_V15_S1, f'test_{sid:05d}.npz')\n",
        "        if not os.path.exists(out_path):\n",
        "            todo.append(sid)\n",
        "    if not todo:\n",
        "        print('[CacheV15][TEST s=1] All test cached.')\n",
        "        return\n",
        "    print(f\"[CacheV15][TEST s=1] {len(todo)}/{len(test_ids)} missing; caching with stride=1...\")\n",
        "    import concurrent.futures as cf, time\n",
        "    t0 = time.time(); done = 0\n",
        "    def task(sid):\n",
        "        try:\n",
        "            return cache_sample_v15_to_dir(sid, 'test', stride=1, out_dir=CACHE_DIR_V15_S1)\n",
        "        except Exception as e:\n",
        "            print(f'[CacheV15][TEST s=1][ERR] id={sid}:', e)\n",
        "            return None\n",
        "    with cf.ThreadPoolExecutor(max_workers=12) as ex:\n",
        "        futs = [ex.submit(task, sid) for sid in todo]\n",
        "        for i, fut in enumerate(cf.as_completed(futs), 1):\n",
        "            _ = fut.result(); done += 1\n",
        "            if done % 10 == 0:\n",
        "                print(f\"[CacheV15][TEST s=1] {done}/{len(todo)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    print(f\"[CacheV15][TEST s=1] Completed {done} in {time.time()-t0:.1f}s\")\n",
        "\n",
        "def predict_test_stride1_train_only_conservative_dp(seeds=(2025,1337,42,0,123)):\n",
        "    # Train models on TRAIN-only stride=2 cache (same as before)\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    # Ensure TEST stride=1 cache exists\n",
        "    ensure_test_cache_v15_stride1()\n",
        "    # Conservative DP, double min_len for stride=1\n",
        "    dp_params = {'lambda': 0.8, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 24, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "    rows = []; t0 = time.time()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15_S1, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        seq = decode_full_pipeline(P, dp_params, T=1.0, smooth_win=1, alpha_fill=1.5)  # uses ensure_perm20_preserve_dp\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-s1] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[Stride1] TRAIN-only 5-seed with TEST stride=1 and doubled min_len...')\n",
        "sub_path = predict_test_stride1_train_only_conservative_dp(seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stride1] TRAIN-only 5-seed with TEST stride=1 and doubled min_len...\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 165.6s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.6s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.4s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 165.6s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 165.6s\n[CacheV15][TEST s=1] 95/95 missing; caching with stride=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=1] 10/95 done; elapsed 141.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=1] 20/95 done; elapsed 297.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=1] 30/95 done; elapsed 457.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=1] 40/95 done; elapsed 638.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=1] 50/95 done; elapsed 821.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=1] 60/95 done; elapsed 885.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=1] 70/95 done; elapsed 1107.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=1] 80/95 done; elapsed 1327.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=1] 90/95 done; elapsed 1540.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=1] Completed 95 in 1553.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s1] 10/95 done; elapsed 12.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s1] 20/95 done; elapsed 25.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s1] 30/95 done; elapsed 38.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s1] 40/95 done; elapsed 51.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s1] 50/95 done; elapsed 63.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s1] 60/95 done; elapsed 76.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s1] 70/95 done; elapsed 89.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s1] 80/95 done; elapsed 102.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s1] 90/95 done; elapsed 114.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "1c557277-bb2e-4020-b426-ab7634885b15",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 34) Test-time TTA at stride=2 with offsets {0,1}: align+average probs, then conservative DP decode\n",
        "import os, time, numpy as np, pandas as pd, xgboost as xgb, concurrent.futures as cf\n",
        "\n",
        "CACHE_DIR_V15_S2_O1 = './cache_v15_s2_o1'\n",
        "os.makedirs(CACHE_DIR_V15_S2_O1, exist_ok=True)\n",
        "\n",
        "def stack_world_positions_offset(vid, stride:int=2, start:int=0):\n",
        "    T = int(vid['NumFrames']); frames = vid['Frames']\n",
        "    J = frames[0]['Skeleton']['WorldPosition'].shape[0]\n",
        "    idxs = list(range(start, T, stride))\n",
        "    skel = np.zeros((len(idxs), J, 3), dtype=np.float32)\n",
        "    last = None\n",
        "    for i, t in enumerate(idxs):\n",
        "        wp = frames[t]['Skeleton']['WorldPosition']\n",
        "        arr = np.asarray(wp, dtype=np.float32) if wp is not None else last\n",
        "        if arr is None: arr = np.zeros((J,3), dtype=np.float32)\n",
        "        skel[i] = arr; last = arr\n",
        "    return skel, idxs\n",
        "\n",
        "def cache_test_stride2_offset1():\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    todo = []\n",
        "    for sid in test_ids:\n",
        "        outp = os.path.join(CACHE_DIR_V15_S2_O1, f'test_{sid:05d}.npz')\n",
        "        if not os.path.exists(outp):\n",
        "            todo.append(sid)\n",
        "    if not todo:\n",
        "        print('[CacheV15][TEST s=2,o=1] All cached.')\n",
        "        return\n",
        "    print(f\"[CacheV15][TEST s=2,o=1] {len(todo)}/{len(test_ids)} missing; caching...\")\n",
        "    t0 = time.time(); done = 0\n",
        "    def task(sid):\n",
        "        try:\n",
        "            vid = load_video_from_split(sid, 'test')\n",
        "            skel, idxs = stack_world_positions_offset(vid, stride=2, start=1)\n",
        "            X = features_from_skeleton_v15(skel)\n",
        "            fps = int(vid.get('FrameRate', 20))\n",
        "            outp = os.path.join(CACHE_DIR_V15_S2_O1, f'test_{sid:05d}.npz')\n",
        "            np.savez_compressed(outp, X=X, fps=fps, stride=2, start=1, sid=sid)\n",
        "            return outp\n",
        "        except Exception as e:\n",
        "            print(f'[CacheV15][TEST s=2,o=1][ERR] id={sid}:', e)\n",
        "            return None\n",
        "    with cf.ThreadPoolExecutor(max_workers=12) as ex:\n",
        "        futs = [ex.submit(task, sid) for sid in todo]\n",
        "        for i, fut in enumerate(cf.as_completed(futs), 1):\n",
        "            _ = fut.result(); done += 1\n",
        "            if done % 10 == 0:\n",
        "                print(f\"[CacheV15][TEST s=2,o=1] {done}/{len(todo)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    print(f\"[CacheV15][TEST s=2,o=1] Completed {done} in {time.time()-t0:.1f}s\")\n",
        "\n",
        "def interp_probs(P: np.ndarray, N: int) -> np.ndarray:\n",
        "    # Linearly interpolate P (T,C) over normalized time to length N\n",
        "    T, C = P.shape\n",
        "    if T == N: return P.astype(np.float32)\n",
        "    x_old = np.linspace(0.0, 1.0, T, dtype=np.float32)\n",
        "    x_new = np.linspace(0.0, 1.0, N, dtype=np.float32)\n",
        "    out = np.empty((N, C), dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        out[:, c] = np.interp(x_new, x_old, P[:, c].astype(np.float32))\n",
        "    # renormalize rows to sum to 1 (avoid drift)\n",
        "    s = out.sum(axis=1, keepdims=True) + 1e-9\n",
        "    out /= s\n",
        "    return out\n",
        "\n",
        "def predict_test_stride2_tta_offsets(seeds=(2025,1337,42,0,123)):\n",
        "    # Train on TRAIN-only v15 cache\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    # Ensure both test caches exist: stride=2 start=0 already in cache_v15; start=1 build now\n",
        "    ensure_test_cache_v15()\n",
        "    cache_test_stride2_offset1()\n",
        "    # Conservative DP params\n",
        "    dp = {'lambda': 0.8, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "    rows = []; t0 = time.time()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d0 = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        d1 = np.load(os.path.join(CACHE_DIR_V15_S2_O1, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X0, X1 = d0['X'], d1['X']\n",
        "        dm0 = xgb.DMatrix(X0); dm1 = xgb.DMatrix(X1)\n",
        "        Ps0 = [m.predict(dm0) for m in models]\n",
        "        Ps1 = [m.predict(dm1) for m in models]\n",
        "        P0 = np.mean(np.stack(Ps0, axis=0), axis=0)\n",
        "        P1 = np.mean(np.stack(Ps1, axis=0), axis=0)\n",
        "        N = max(P0.shape[0], P1.shape[0])\n",
        "        P0i = interp_probs(P0, N)\n",
        "        P1i = interp_probs(P1, N)\n",
        "        P = 0.5*(P0i + P1i)\n",
        "        seq = decode_full_pipeline(P, dp, T=1.0, smooth_win=1, alpha_fill=1.5)  # DP-preserving rescue\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-s2-TTA] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[Stride2-TTA] TRAIN-only 5-seed; TEST stride=2 offsets {0,1}; align+avg probs; conservative DP decode...')\n",
        "sub_path = predict_test_stride2_tta_offsets(seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stride2-TTA] TRAIN-only 5-seed; TEST stride=2 offsets {0,1}; align+avg probs; conservative DP decode...\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 165.5s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.6s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.3s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 165.6s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 165.6s\n[CacheV15][TEST] All test cached.\n[CacheV15][TEST s=2,o=1] 95/95 missing; caching...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=2,o=1] 10/95 done; elapsed 141.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=2,o=1] 20/95 done; elapsed 294.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=2,o=1] 30/95 done; elapsed 456.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=2,o=1] 40/95 done; elapsed 634.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=2,o=1] 50/95 done; elapsed 818.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=2,o=1] 60/95 done; elapsed 890.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=2,o=1] 70/95 done; elapsed 1105.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=2,o=1] 80/95 done; elapsed 1331.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=2,o=1] 90/95 done; elapsed 1536.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST s=2,o=1] Completed 95 in 1546.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA] 10/95 done; elapsed 26.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA] 20/95 done; elapsed 53.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA] 30/95 done; elapsed 79.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA] 40/95 done; elapsed 105.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA] 50/95 done; elapsed 131.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA] 60/95 done; elapsed 157.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA] 70/95 done; elapsed 183.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA] 80/95 done; elapsed 209.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA] 90/95 done; elapsed 234.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "5fc9f0aa-c1bb-47f5-a7e4-76757e2bafa7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 35) Grammar-enforced DP (fixed order G1..G20) using emissions log p(c) - log p(bg); TRAIN-only 5-seed\n",
        "import numpy as np, os, glob, time, pandas as pd, xgboost as xgb\n",
        "\n",
        "def grammar_decode_fixed_order(P: np.ndarray, min_len_map=None) -> list:\n",
        "    # P: (T,21) with 0=bg, classes 1..20\n",
        "    T, C = P.shape\n",
        "    assert C >= 21, 'Expect 21 classes (bg + 20 gestures)'\n",
        "    eps = 1e-9\n",
        "    # emissions for gestures 1..20 vs background\n",
        "    s = np.log(np.clip(P[:, 1:21], eps, 1.0)) - np.log(np.clip(P[:, [0]], eps, 1.0))  # (T,20)\n",
        "    # cumulative sums per class for O(1) segment score\n",
        "    cs = np.zeros((T+1, 20), dtype=np.float32)\n",
        "    np.cumsum(s, axis=0, out=cs[1:])\n",
        "    # per-class min_len\n",
        "    if min_len_map is None:\n",
        "        mins = np.full(20, 12, dtype=np.int32)\n",
        "    else:\n",
        "        mins = np.array([int(min_len_map.get(i+1, 12)) for i in range(20)], dtype=np.int32)\n",
        "    # DP over classes i=0..19; DP_prev and DP_cur are length T+1 over end time t\n",
        "    # DP_prev[t] is best score placing first i classes ending at frame t\n",
        "    DP_prev = np.full(T+1, -1e18, dtype=np.float32)\n",
        "    DP_prev[0] = 0.0  # before any gesture at time 0\n",
        "    backpointers = []  # list of arrays bp_i[t] giving start u for segment i ending at t\n",
        "    cum_min = 0\n",
        "    for i in range(20):\n",
        "        mlen = int(mins[i])\n",
        "        DP_cur = np.full(T+1, -1e18, dtype=np.float32)\n",
        "        bp = np.full(T+1, -1, dtype=np.int32)\n",
        "        # Maintain running max M[t] = max_{u <= t-mlen} (DP_prev[u] - cs[u, i]) and arg u\n",
        "        M_val = -1e18\n",
        "        M_idx = -1\n",
        "        # Earliest feasible end time must allow i+1 segments of min length\n",
        "        cum_min += mlen\n",
        "        start_t = cum_min\n",
        "        for t in range(mlen, T+1):\n",
        "            u = t - mlen\n",
        "            cand = DP_prev[u] - cs[u, i]\n",
        "            if cand > M_val:\n",
        "                M_val = cand; M_idx = u\n",
        "            # Only allow t where remaining time can fit remaining mins (not strictly needed at test)\n",
        "            DP_cur[t] = cs[t, i] + M_val\n",
        "            bp[t] = M_idx\n",
        "        backpointers.append(bp)\n",
        "        DP_prev = DP_cur\n",
        "    # Choose best end time for class 20\n",
        "    t_end = int(np.argmax(DP_prev))\n",
        "    # Backtrack segments\n",
        "    cuts = [0]*21\n",
        "    cuts[20] = t_end\n",
        "    for i in range(19, -1, -1):\n",
        "        u = int(backpointers[i][cuts[i+1]])\n",
        "        if u < 0: u = max(0, cuts[i+1] - int(mins[i]))\n",
        "        cuts[i] = u\n",
        "    # Return fixed order classes 1..20 (grammar enforces the order already)\n",
        "    return [i+1 for i in range(20)]\n",
        "\n",
        "def predict_test_train_only_grammar_dp(seeds=(2025,1337,42,0,123), min_len_map=None):\n",
        "    # Train TRAIN-only models, average probs, decode with grammar DP, write submission.csv\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    ensure_test_cache_v15()\n",
        "    rows = []; t0 = time.time()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        seq = grammar_decode_fixed_order(P, min_len_map=min_len_map)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-GrammarDP] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[GrammarDP] TRAIN-only 5-seed; decoding with fixed-order grammar DP (min_len=12)...')\n",
        "sub_path = predict_test_train_only_grammar_dp(seeds=(2025,1337,42,0,123), min_len_map=None)\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GrammarDP] TRAIN-only 5-seed; decoding with fixed-order grammar DP (min_len=12)...\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 165.6s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.7s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.4s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 165.8s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 165.4s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-GrammarDP] 10/95 done; elapsed 13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-GrammarDP] 20/95 done; elapsed 26.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-GrammarDP] 30/95 done; elapsed 39.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-GrammarDP] 40/95 done; elapsed 52.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-GrammarDP] 50/95 done; elapsed 65.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-GrammarDP] 60/95 done; elapsed 79.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-GrammarDP] 70/95 done; elapsed 92.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-GrammarDP] 80/95 done; elapsed 104.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-GrammarDP] 90/95 done; elapsed 117.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "6f7e5de9-2eb9-41da-8471-41291c5b637c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 36) FE v1.6 (v1.5 + kinematic extras: distances, speeds, elbow angles, acceleration) + caching/train/infer\n",
        "import os, io, re, time, glob, tarfile, zipfile, numpy as np, concurrent.futures as cf, pandas as pd, xgboost as xgb\n",
        "import scipy.io as sio\n",
        "\n",
        "HIP=0; SPINE=1; SHOULDER_CENTER=2; HEAD=3; L_SHOULDER=4; L_ELBOW=5; L_WRIST=6; L_HAND=7; R_SHOULDER=8; R_ELBOW=9; R_WRIST=10; R_HAND=11\n",
        "\n",
        "def features_from_skeleton_v16(skel):\n",
        "    # v1.5 base (hip-center, shoulder-width scale) + extras: distances, speeds, elbow angles, acceleration\n",
        "    T, J, _ = skel.shape\n",
        "    base_dim = J*3*2  # positions + velocities\n",
        "    extra_dim = 13 + 3*J  # distances/speeds/angles (13) + accelerations per joint (J*3)\n",
        "    feats = np.zeros((T, base_dim + extra_dim), dtype=np.float32)\n",
        "    prev_centered = None\n",
        "    prev_vel = None\n",
        "    for t in range(T):\n",
        "        coords = skel[t].astype(np.float32)\n",
        "        hip = coords[HIP]\n",
        "        centered = coords - hip\n",
        "        shoulder_w = np.linalg.norm(centered[R_SHOULDER] - centered[L_SHOULDER])\n",
        "        scale = max(shoulder_w, 1e-4)\n",
        "        centered /= scale\n",
        "        # velocities on normalized coords\n",
        "        if prev_centered is None:\n",
        "            vel = np.zeros_like(centered)\n",
        "        else:\n",
        "            vel = centered - prev_centered\n",
        "        # accelerations on normalized coords\n",
        "        if prev_vel is None:\n",
        "            acc = np.zeros_like(centered)\n",
        "        else:\n",
        "            acc = vel - prev_vel\n",
        "        prev_vel = vel\n",
        "        prev_centered = centered\n",
        "        # base\n",
        "        feats[t, :J*3] = centered.reshape(-1)\n",
        "        feats[t, J*3:J*3*2] = vel.reshape(-1)\n",
        "        # extras: distances\n",
        "        d_hl_hd = np.linalg.norm(centered[L_HAND] - centered[HEAD])\n",
        "        d_hr_hd = np.linalg.norm(centered[R_HAND] - centered[HEAD])\n",
        "        d_hl_hip = np.linalg.norm(centered[L_HAND] - centered[HIP])\n",
        "        d_hr_hip = np.linalg.norm(centered[R_HAND] - centered[HIP])\n",
        "        d_hl_hr = np.linalg.norm(centered[L_HAND] - centered[R_HAND])\n",
        "        d_hl_sc = np.linalg.norm(centered[L_HAND] - centered[SHOULDER_CENTER])\n",
        "        d_hr_sc = np.linalg.norm(centered[R_HAND] - centered[SHOULDER_CENTER])\n",
        "        # speeds\n",
        "        s_wl = np.linalg.norm(vel[L_WRIST])\n",
        "        s_wr = np.linalg.norm(vel[R_WRIST])\n",
        "        s_hl = np.linalg.norm(vel[L_HAND])\n",
        "        s_hr = np.linalg.norm(vel[R_HAND])\n",
        "        # elbow flexion cosines\n",
        "        def elbow_cos(l_sh, l_el, l_wr):\n",
        "            u = centered[l_sh] - centered[l_el]\n",
        "            v = centered[l_wr] - centered[l_el]\n",
        "            nu = np.linalg.norm(u); nv = np.linalg.norm(v)\n",
        "            if nu < 1e-6 or nv < 1e-6: return 1.0\n",
        "            return float(np.dot(u, v) / (nu*nv))\n",
        "        cos_el = elbow_cos(L_SHOULDER, L_ELBOW, L_WRIST)\n",
        "        cos_er = elbow_cos(R_SHOULDER, R_ELBOW, R_WRIST)\n",
        "        extras = np.array([d_hl_hd, d_hr_hd, d_hl_hip, d_hr_hip, d_hl_hr, d_hl_sc, d_hr_sc, s_wl, s_wr, s_hl, s_hr, cos_el, cos_er], dtype=np.float32)\n",
        "        feats[t, J*3*2:J*3*2+13] = extras\n",
        "        feats[t, J*3*2+13:] = acc.reshape(-1)  # accelerations\n",
        "    return feats\n",
        "\n",
        "# v1.6 cache dirs\n",
        "CACHE_DIR_V16 = './cache_v16'\n",
        "os.makedirs(CACHE_DIR_V16, exist_ok=True)\n",
        "\n",
        "def split_and_tar_for_id(sample_id:int, split_hint:str='train'):\n",
        "    if split_hint == 'train':\n",
        "        if sample_id < 100: return 'train', 'training1.tar.gz'\n",
        "        elif sample_id < 200: return 'train', 'training2.tar.gz'\n",
        "        else: return 'train', 'training3.tar.gz'\n",
        "    elif split_hint == 'val':\n",
        "        if sample_id < 500: return 'val', 'validation1.tar.gz'\n",
        "        elif sample_id < 621: return 'val', 'validation2.tar.gz'\n",
        "        else: return 'val', 'validation3.tar.gz'\n",
        "    elif split_hint == 'test':\n",
        "        return 'test', 'test.tar.gz'\n",
        "    else:\n",
        "        raise ValueError('Unknown split_hint')\n",
        "\n",
        "def get_zip_member(tf: tarfile.TarFile, sample_id:int):\n",
        "    candidates = [f'./Sample{sample_id:05d}.zip', f'Sample{sample_id:05d}.zip']\n",
        "    for nm in candidates:\n",
        "        try:\n",
        "            return tf.getmember(nm)\n",
        "        except KeyError:\n",
        "            pass\n",
        "    for m in tf.getmembers():\n",
        "        if m.name.endswith(f'Sample{sample_id:05d}.zip'):\n",
        "            return m\n",
        "    raise FileNotFoundError(f'Sample zip for id {sample_id} not found in tar')\n",
        "\n",
        "def load_video_from_split(sample_id:int, split_hint:str):\n",
        "    _, tar_path = split_and_tar_for_id(sample_id, split_hint)\n",
        "    with tarfile.open(tar_path, 'r:gz') as tf:\n",
        "        mem = get_zip_member(tf, sample_id)\n",
        "        zbytes = tf.extractfile(mem).read()\n",
        "        with zipfile.ZipFile(io.BytesIO(zbytes)) as zf:\n",
        "            mat_name = next(n for n in zf.namelist() if n.lower().endswith('_data.mat'))\n",
        "            with zf.open(mat_name) as f:\n",
        "                d = sio.loadmat(f, simplify_cells=True)\n",
        "    return d['Video']\n",
        "\n",
        "def stack_world_positions(vid, stride:int=2):\n",
        "    T = int(vid['NumFrames']); frames = vid['Frames']\n",
        "    J = frames[0]['Skeleton']['WorldPosition'].shape[0]\n",
        "    idxs = list(range(0, T, stride))\n",
        "    skel = np.zeros((len(idxs), J, 3), dtype=np.float32)\n",
        "    last = None\n",
        "    for i, t in enumerate(idxs):\n",
        "        wp = frames[t]['Skeleton']['WorldPosition']\n",
        "        arr = np.asarray(wp, dtype=np.float32) if wp is not None else last\n",
        "        if arr is None: arr = np.zeros((J,3), dtype=np.float32)\n",
        "        skel[i] = arr; last = arr\n",
        "    return skel, idxs\n",
        "\n",
        "def true_token_sequence_from_video(vid, name_to_id_map):\n",
        "    seq = []\n",
        "    for lab in vid['Labels']:\n",
        "        cid = name_to_id_map.get(lab['Name'])\n",
        "        if cid is not None: seq.append(cid)\n",
        "    return seq\n",
        "\n",
        "def cache_sample_v16(sample_id:int, split_hint:str, stride:int=2):\n",
        "    out_path = os.path.join(CACHE_DIR_V16, f'{split_hint}_{sample_id:05d}.npz')\n",
        "    if os.path.exists(out_path):\n",
        "        return out_path\n",
        "    t0 = time.time()\n",
        "    vid = load_video_from_split(sample_id, split_hint)\n",
        "    skel, idxs = stack_world_positions(vid, stride=stride)\n",
        "    X = features_from_skeleton_v16(skel)\n",
        "    T_full = int(vid['NumFrames'])\n",
        "    y_full = np.zeros(T_full, dtype=np.int16)\n",
        "    if split_hint in ('train','val'):\n",
        "        for lab in vid['Labels']:\n",
        "            cid = name_to_id.get(lab['Name'])\n",
        "            if cid is None: continue\n",
        "            b = max(0, int(lab['Begin'])-1); e = min(T_full, int(lab['End']))\n",
        "            y_full[b:e] = cid\n",
        "    y_ds = np.array([y_full[t] for t in idxs], dtype=np.int16)\n",
        "    true_seq = true_token_sequence_from_video(vid, name_to_id) if split_hint in ('train','val') else []\n",
        "    fps = int(vid.get('FrameRate', 20))\n",
        "    np.savez_compressed(out_path, X=X, y=y_ds, seq=np.array(true_seq, dtype=np.int16), fps=fps, stride=stride, sid=sample_id)\n",
        "    print(f\"[CacheV16] {split_hint} id={sample_id} -> {out_path} X={X.shape} saved in {time.time()-t0:.1f}s\", flush=True)\n",
        "    return out_path\n",
        "\n",
        "def list_ids_in_tar_fast(tar_path):\n",
        "    ids = []\n",
        "    with tarfile.open(tar_path, 'r:gz') as tf:\n",
        "        for m in tf.getmembers():\n",
        "            if m.name.lower().endswith('.zip'):\n",
        "                m2 = re.findall(r'(\\d{5})', m.name)\n",
        "                if m2: ids.append(int(m2[0]))\n",
        "    return sorted(ids)\n",
        "\n",
        "def remaining_ids_v16(split_hint, ids):\n",
        "    rem = []\n",
        "    for sid in ids:\n",
        "        out_path = os.path.join(CACHE_DIR_V16, f'{split_hint}_{sid:05d}.npz')\n",
        "        if not os.path.exists(out_path): rem.append(sid)\n",
        "    return rem\n",
        "\n",
        "def parallel_cache_v16(split_hint, ids, max_workers=12, stride=2):\n",
        "    todo = remaining_ids_v16(split_hint, ids)\n",
        "    print(f\"[ParCacheV16] {split_hint}: {len(todo)}/{len(ids)} remaining.\")\n",
        "    if not todo: return\n",
        "    t0 = time.time(); done = 0\n",
        "    def task(sid):\n",
        "        try:\n",
        "            return cache_sample_v16(sid, split_hint, stride=stride)\n",
        "        except Exception as e:\n",
        "            print(f\"[ParCacheV16][ERR] {split_hint} id={sid}: {e}\")\n",
        "            return None\n",
        "    with cf.ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
        "        futures = [ex.submit(task, sid) for sid in todo]\n",
        "        for fut in cf.as_completed(futures):\n",
        "            _ = fut.result(); done += 1\n",
        "            if done % 20 == 0:\n",
        "                print(f\"[ParCacheV16] {split_hint}: {done}/{len(todo)} done; elapsed {time.time()-t0:.1f}s\")\n",
        "    print(f\"[ParCacheV16] {split_hint}: completed {done} in {time.time()-t0:.1f}s\")\n",
        "\n",
        "def load_cached_split_v16(split_prefix):\n",
        "    files = sorted(glob.glob(os.path.join(CACHE_DIR_V16, f\"{split_prefix}_*.npz\")))\n",
        "    Xs, ys = [], []\n",
        "    n_frames = 0; t0 = time.time()\n",
        "    for i, fp in enumerate(files, 1):\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        X = d['X']; y = d['y']\n",
        "        Xs.append(X); ys.append(y.astype(np.int32)); n_frames += len(y)\n",
        "        if i % 20 == 0:\n",
        "            print(f\"[LoadCacheV16] {split_prefix}: {i}/{len(files)} files, cum frames={n_frames}\", flush=True)\n",
        "    X = np.vstack(Xs) if Xs else np.zeros((0,0), dtype=np.float32)\n",
        "    y = np.concatenate(ys) if ys else np.zeros((0,), dtype=np.int32)\n",
        "    print(f\"[LoadCacheV16] {split_prefix}: X={X.shape} y={y.shape} files={len(files)} elapsed={time.time()-t0:.1f}s\", flush=True)\n",
        "    return X, y, files\n",
        "\n",
        "def make_weights_with_boundary_erosion(y: np.ndarray, w0: float=0.38):\n",
        "    w = np.ones_like(y, dtype=np.float32); w[y==0] = w0\n",
        "    if len(y) > 2:\n",
        "        bmask = (y[1:-1] != y[:-2]) | (y[1:-1] != y[2:])\n",
        "        w[1:-1][bmask] = 0.0\n",
        "    return w\n",
        "\n",
        "def train_seed_model_v16(X, y, seed:int):\n",
        "    w = make_weights_with_boundary_erosion(y, w0=0.38)\n",
        "    dtr = xgb.DMatrix(X, label=y, weight=w)\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 21,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'predictor': 'gpu_predictor',\n",
        "        'max_bin': 512,\n",
        "        'max_depth': 7,\n",
        "        'eta': 0.085,\n",
        "        'subsample': 0.85,\n",
        "        'colsample_bytree': 0.85,\n",
        "        'min_child_weight': 4.0,\n",
        "        'lambda': 1.0,\n",
        "        'seed': int(seed)\n",
        "    }\n",
        "    print(f\"[XGB-V16][Seed {seed}] Training...\")\n",
        "    t0 = time.time()\n",
        "    bst = xgb.train(params, dtr, num_boost_round=1100, verbose_eval=200)\n",
        "    print(f\"[XGB-V16][Seed {seed}] Done in {time.time()-t0:.1f}s\")\n",
        "    return bst\n",
        "\n",
        "def ensure_test_cache_v16():\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    todo = []\n",
        "    for sid in test_ids:\n",
        "        out_path = os.path.join(CACHE_DIR_V16, f'test_{sid:05d}.npz')\n",
        "        if not os.path.exists(out_path):\n",
        "            todo.append(sid)\n",
        "    if todo:\n",
        "        print(f\"[CacheV16][TEST] {len(todo)}/{len(test_ids)} missing; caching with stride=2...\")\n",
        "        parallel_cache_v16('test', test_ids, max_workers=12, stride=2)\n",
        "    else:\n",
        "        print('[CacheV16][TEST] All test cached.')\n",
        "\n",
        "# Reuse DP + full pipeline + rescue from earlier v15 section\n",
        "# decode_full_pipeline(P, dp_params, T, smooth_win) and ensure_perm20_preserve_dp must be defined already\n",
        "\n",
        "def predict_test_full_pipeline_train_only_v16(best_params: dict, seeds=(2025,1337,42,0,123)):\n",
        "    X_tr, y_tr, _ = load_cached_split_v16('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v16(X_tr, y_tr, seed=s))\n",
        "    ensure_test_cache_v16()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V16, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        seq = decode_full_pipeline(P, best_params, T=best_params.get('T',1.0), smooth_win=best_params.get('smooth_win',1), alpha_fill=1.5)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-V16] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[RUN V1.6] Parallel cache TRAIN (stride=2) with FE v1.6...')\n",
        "train_ids_all = train_df['Id'].tolist()\n",
        "parallel_cache_v16('train', train_ids_all, max_workers=12, stride=2)\n",
        "print('[RUN V1.6] Training TRAIN-only 5 seeds and inferring TEST with conservative DP (lambda=0.8, min_len=12), T=1, win=1...')\n",
        "best_params_conservative = {'T': 1.0, 'smooth_win': 1, 'lambda': 0.8, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "sub_path = predict_test_full_pipeline_train_only_v16(best_params_conservative, seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RUN V1.6] Parallel cache TRAIN (stride=2) with FE v1.6...\n[ParCacheV16] train: 297/297 remaining.\n"
          ]
        }
      ]
    },
    {
      "id": "b8e4c007-768f-456c-8cea-826bcb3b30d5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 37) Log-odds DP emissions (log p(c) - log p(bg)) + DP-preserving rescue; TRAIN-only 5-seed; stride=2; T=1,smooth=1\n",
        "import numpy as np, os, glob, time, pandas as pd, xgboost as xgb\n",
        "\n",
        "# Ensure rescue uses DP-preserving path only in any legacy callers\n",
        "def decode_with_rescue(P, params):\n",
        "    # Legacy wrapper: always use DP + ensure_perm20_preserve_dp\n",
        "    Pp = preprocess_probs(P, T=params.get('T',1.0), smooth_win=params.get('smooth_win',1))\n",
        "    pred = decode_sequence_dp_logodds(Pp,\n",
        "                                     switch_penalty=params.get('lambda', 0.9),\n",
        "                                     bg_bias=params.get('bg_bias', 0.25),\n",
        "                                     merge_gap=params.get('merge_gap', 3),\n",
        "                                     min_len=params.get('min_len', 12),\n",
        "                                     mean_thr=params.get('mean_thr', 0.5),\n",
        "                                     max_thr=params.get('max_thr', 0.65))\n",
        "    return ensure_perm20_preserve_dp(pred, Pp, alpha=1.6)\n",
        "\n",
        "def viterbi_labels_logodds(probs: np.ndarray, switch_penalty: float = 1.0, bg_bias: float = 0.25) -> np.ndarray:\n",
        "    # probs: (T, C=21). Emissions: s_c = log p(c) - log p(bg) for c=1..20; cost = -s_c; background has constant cost=bg_bias.\n",
        "    T, C = probs.shape\n",
        "    eps = 1e-9\n",
        "    logp = np.log(np.clip(probs, eps, 1.0)).astype(np.float32)  # (T,C)\n",
        "    cost = np.zeros((T, C), dtype=np.float32)\n",
        "    cost[:, 0] = float(bg_bias)\n",
        "    cost[:, 1:] = -(logp[:, 1:] - logp[:, [0]])  # -log-odds\n",
        "    dp = np.zeros((T, C), dtype=np.float32)\n",
        "    bp = np.zeros((T, C), dtype=np.int16)\n",
        "    dp[0] = cost[0]\n",
        "    bp[0] = -1\n",
        "    for t in range(1, T):\n",
        "        prev = dp[t-1]\n",
        "        min_prev = float(prev.min())\n",
        "        stay = prev\n",
        "        switch = min_prev + switch_penalty\n",
        "        best_prev = np.minimum(stay, switch)\n",
        "        dp[t] = cost[t] + best_prev\n",
        "        argmin_prev = int(prev.argmin())\n",
        "        bp[t] = np.where(stay <= switch, np.arange(C, dtype=np.int16), np.int16(argmin_prev))\n",
        "    path = np.zeros(T, dtype=np.int16)\n",
        "    path[T-1] = int(dp[T-1].argmin())\n",
        "    for t in range(T-2, -1, -1):\n",
        "        path[t] = bp[t+1, path[t+1]]\n",
        "    return path\n",
        "\n",
        "def decode_sequence_dp_logodds(probs, switch_penalty=1.0, bg_bias=0.25, merge_gap=3, min_len=12, mean_thr=0.5, max_thr=0.65):\n",
        "    labels = viterbi_labels_logodds(probs, switch_penalty=switch_penalty, bg_bias=bg_bias)\n",
        "    T = len(labels)\n",
        "    segs = []  # (cls, b, e, mean_p, max_p)\n",
        "    b = 0\n",
        "    for i in range(1, T+1):\n",
        "        if i==T or labels[i] != labels[b]:\n",
        "            cls = int(labels[b])\n",
        "            p = probs[b:i, cls] if cls < probs.shape[1] else np.zeros(i-b)\n",
        "            mean_p = float(p.mean()) if (i-b)>0 else 0.0\n",
        "            max_p = float(p.max()) if (i-b)>0 else 0.0\n",
        "            segs.append([cls, b, i, mean_p, max_p])\n",
        "            b = i\n",
        "    # merge small bg gaps between same class\n",
        "    merged = []\n",
        "    i = 0\n",
        "    while i < len(segs):\n",
        "        cur = segs[i]\n",
        "        j = i + 1\n",
        "        while j < len(segs):\n",
        "            if segs[j][0] == cur[0] and segs[j-1][0]==0 and (segs[j][1]-cur[2]) <= merge_gap:\n",
        "                cur[2] = segs[j][2]\n",
        "                cur[3] = float(np.mean(probs[cur[1]:cur[2], cur[0]]))\n",
        "                cur[4] = float(np.max(probs[cur[1]:cur[2], cur[0]]))\n",
        "                j += 1\n",
        "            else:\n",
        "                break\n",
        "        merged.append(cur)\n",
        "        i = j\n",
        "    out = []\n",
        "    for cls, sb, se, mp, xp in merged:\n",
        "        if cls == 0: continue\n",
        "        if (se - sb) < min_len: continue\n",
        "        if not (mp >= mean_thr and xp >= max_thr): continue\n",
        "        if not out or out[-1] != int(cls):\n",
        "            out.append(int(cls))\n",
        "    return out\n",
        "\n",
        "def predict_test_logodds_train_only(dp_params: dict, seeds=(2025,1337,42,0,123)):\n",
        "    # TRAIN-only models (v1.5 features), average probs, log-odds DP decode + DP-preserving rescue\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    ensure_test_cache_v15()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        Pp = preprocess_probs(P, T=1.0, smooth_win=1)\n",
        "        pred = decode_sequence_dp_logodds(Pp,\n",
        "                                         switch_penalty=dp_params.get('lambda', 0.9),\n",
        "                                         bg_bias=dp_params.get('bg_bias', 0.25),\n",
        "                                         merge_gap=dp_params.get('merge_gap', 3),\n",
        "                                         min_len=dp_params.get('min_len', 12),\n",
        "                                         mean_thr=dp_params.get('mean_thr', 0.5),\n",
        "                                         max_thr=dp_params.get('max_thr', 0.65))\n",
        "        seq = ensure_perm20_preserve_dp(pred, Pp, alpha=1.6)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-LogOdds] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[LogOddsDP] TRAIN-only 5-seed; stride=2; T=1, smooth=1; lambda=0.9, bg_bias=0.25, merge_gap=3, min_len=12, mean_thr=0.5, max_thr=0.65')\n",
        "dp_params_logodds = {'lambda': 0.9, 'bg_bias': 0.25, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "sub_path = predict_test_logodds_train_only(dp_params_logodds, seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "id": "81ab24a6-7995-4f48-a18d-096d987156b3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 38) Log-odds DP quick run: 3 seeds, stride=2, T=1, smooth=1, lambda=0.9, bg_bias=0.25\n",
        "import numpy as np, os, time, pandas as pd, xgboost as xgb\n",
        "\n",
        "def viterbi_labels_logodds_quick(probs: np.ndarray, switch_penalty: float = 1.0, bg_bias: float = 0.25) -> np.ndarray:\n",
        "    T, C = probs.shape\n",
        "    eps = 1e-9\n",
        "    logp = np.log(np.clip(probs, eps, 1.0)).astype(np.float32)\n",
        "    cost = np.zeros((T, C), dtype=np.float32)\n",
        "    cost[:, 0] = float(bg_bias)\n",
        "    cost[:, 1:] = -(logp[:, 1:] - logp[:, [0]])\n",
        "    dp = np.zeros((T, C), dtype=np.float32)\n",
        "    bp = np.zeros((T, C), dtype=np.int16)\n",
        "    dp[0] = cost[0]; bp[0] = -1\n",
        "    for t in range(1, T):\n",
        "        prev = dp[t-1]\n",
        "        mprev = float(prev.min())\n",
        "        stay = prev\n",
        "        switch = mprev + switch_penalty\n",
        "        best_prev = np.minimum(stay, switch)\n",
        "        dp[t] = cost[t] + best_prev\n",
        "        argmin_prev = int(prev.argmin())\n",
        "        bp[t] = np.where(stay <= switch, np.arange(C, dtype=np.int16), np.int16(argmin_prev))\n",
        "    path = np.zeros(T, dtype=np.int16)\n",
        "    path[T-1] = int(dp[T-1].argmin())\n",
        "    for t in range(T-2, -1, -1):\n",
        "        path[t] = bp[t+1, path[t+1]]\n",
        "    return path\n",
        "\n",
        "def decode_sequence_dp_logodds_quick(probs, switch_penalty=0.9, bg_bias=0.25, merge_gap=3, min_len=12, mean_thr=0.5, max_thr=0.65):\n",
        "    labels = viterbi_labels_logodds_quick(probs, switch_penalty=switch_penalty, bg_bias=bg_bias)\n",
        "    T = len(labels)\n",
        "    segs = []; b = 0\n",
        "    for i in range(1, T+1):\n",
        "        if i==T or labels[i] != labels[b]:\n",
        "            cls = int(labels[b])\n",
        "            p = probs[b:i, cls] if cls < probs.shape[1] else np.zeros(i-b)\n",
        "            mp = float(p.mean()) if (i-b)>0 else 0.0\n",
        "            xp = float(p.max()) if (i-b)>0 else 0.0\n",
        "            segs.append([cls, b, i, mp, xp]); b = i\n",
        "    merged = []; i = 0\n",
        "    while i < len(segs):\n",
        "        cur = segs[i]; j = i + 1\n",
        "        while j < len(segs):\n",
        "            if segs[j][0] == cur[0] and segs[j-1][0]==0 and (segs[j][1]-cur[2]) <= merge_gap:\n",
        "                cur[2] = segs[j][2]\n",
        "                cur[3] = float(np.mean(probs[cur[1]:cur[2], cur[0]]))\n",
        "                cur[4] = float(np.max(probs[cur[1]:cur[2], cur[0]]))\n",
        "                j += 1\n",
        "            else:\n",
        "                break\n",
        "        merged.append(cur); i = j\n",
        "    out = []\n",
        "    for cls, sb, se, mp, xp in merged:\n",
        "        if cls == 0: continue\n",
        "        if (se - sb) < min_len: continue\n",
        "        if not (mp >= mean_thr and xp >= max_thr): continue\n",
        "        if not out or out[-1] != int(cls):\n",
        "            out.append(int(cls))\n",
        "    return out\n",
        "\n",
        "def predict_test_logodds_3seeds(dp_params: dict, seeds=(2025,1337,42)):\n",
        "    print('[LogOddsDP-Quick] Loading TRAIN cache...', flush=True)\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        print(f'[XGB-V15][Seed {s}] Training...', flush=True)\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    ensure_test_cache_v15()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        Pp = preprocess_probs(P, T=1.0, smooth_win=1)\n",
        "        pred = decode_sequence_dp_logodds_quick(Pp,\n",
        "                                              switch_penalty=dp_params.get('lambda', 0.9),\n",
        "                                              bg_bias=dp_params.get('bg_bias', 0.25),\n",
        "                                              merge_gap=dp_params.get('merge_gap', 3),\n",
        "                                              min_len=dp_params.get('min_len', 12),\n",
        "                                              mean_thr=dp_params.get('mean_thr', 0.5),\n",
        "                                              max_thr=dp_params.get('max_thr', 0.65))\n",
        "        seq = ensure_perm20_preserve_dp(pred, Pp, alpha=1.6)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-LogOdds-Quick] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[Run] Log-odds DP quick infer: 3 seeds, lambda=0.9, bg_bias=0.25, min_len=12, merge_gap=3, T=1, win=1', flush=True)\n",
        "dpq = {'lambda': 0.9, 'bg_bias': 0.25, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "sub_path = predict_test_logodds_3seeds(dpq, seeds=(2025,1337,42))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Run] Log-odds DP quick infer: 3 seeds, lambda=0.9, bg_bias=0.25, min_len=12, merge_gap=3, T=1, win=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogOddsDP-Quick] Loading TRAIN cache...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        }
      ]
    },
    {
      "id": "78c55c71-b290-442a-9913-d546e82ca9ba",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 39) Log-odds DP + per-class min_len (p20 clip [6,14]); TRAIN-only 5-seed; stride=2; T=1,smooth=1\n",
        "import numpy as np, glob, os, time, pandas as pd, xgboost as xgb\n",
        "\n",
        "def compute_duration_priors_p20_clip614_from_train_cache_v15():\n",
        "    files = sorted(glob.glob(os.path.join(CACHE_DIR_V15, 'train_*.npz')))\n",
        "    lens = {c: [] for c in range(1,21)}\n",
        "    for i, fp in enumerate(files, 1):\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        y = d['y'].astype(np.int32)\n",
        "        if y.size == 0: continue\n",
        "        b = 0\n",
        "        for t in range(1, len(y)+1):\n",
        "            if t==len(y) or y[t] != y[b]:\n",
        "                cls = int(y[b])\n",
        "                if cls != 0:\n",
        "                    lens[cls].append(t-b)\n",
        "                b = t\n",
        "        if i % 25 == 0:\n",
        "            print(f\"[DurPrior-20] processed {i}/{len(files)} train files\", flush=True)\n",
        "    min_len_map = {}\n",
        "    for c in range(1,21):\n",
        "        arr = np.array(lens[c], dtype=np.float32)\n",
        "        if arr.size == 0:\n",
        "            ml = 8\n",
        "        else:\n",
        "            ml = float(np.percentile(arr, 20.0))\n",
        "        ml = int(max(6, min(14, round(ml))))\n",
        "        min_len_map[c] = ml\n",
        "    print('[DurPrior-20] per-class min_len (clipped [6,14]):', min_len_map)\n",
        "    return min_len_map\n",
        "\n",
        "def decode_sequence_dp_logodds_pc(probs, switch_penalty=0.9, bg_bias=0.25, merge_gap=3, min_len=12, mean_thr=0.5, max_thr=0.65, min_len_map=None):\n",
        "    labels = viterbi_labels_logodds_quick(probs, switch_penalty=switch_penalty, bg_bias=bg_bias)\n",
        "    T = len(labels)\n",
        "    segs = []; b = 0\n",
        "    for i in range(1, T+1):\n",
        "        if i==T or labels[i] != labels[b]:\n",
        "            cls = int(labels[b])\n",
        "            p = probs[b:i, cls] if cls < probs.shape[1] else np.zeros(i-b)\n",
        "            mp = float(p.mean()) if (i-b)>0 else 0.0\n",
        "            xp = float(p.max()) if (i-b)>0 else 0.0\n",
        "            segs.append([cls, b, i, mp, xp]); b = i\n",
        "    # merge bg gaps\n",
        "    merged = []; i = 0\n",
        "    while i < len(segs):\n",
        "        cur = segs[i]; j = i + 1\n",
        "        while j < len(segs):\n",
        "            if segs[j][0] == cur[0] and segs[j-1][0]==0 and (segs[j][1]-cur[2]) <= merge_gap:\n",
        "                cur[2] = segs[j][2]\n",
        "                cur[3] = float(np.mean(probs[cur[1]:cur[2], cur[0]]))\n",
        "                cur[4] = float(np.max(probs[cur[1]:cur[2], cur[0]]))\n",
        "                j += 1\n",
        "            else:\n",
        "                break\n",
        "        merged.append(cur); i = j\n",
        "    out = []\n",
        "    for cls, sb, se, mp, xp in merged:\n",
        "        if cls == 0: continue\n",
        "        req_len = int(min_len_map.get(int(cls), min_len)) if min_len_map is not None else int(min_len)\n",
        "        if (se - sb) < req_len: continue\n",
        "        if not (mp >= mean_thr and xp >= max_thr): continue\n",
        "        if not out or out[-1] != int(cls):\n",
        "            out.append(int(cls))\n",
        "    return out\n",
        "\n",
        "def predict_test_logodds_pc_train_only(dp_params: dict, min_len_map: dict, seeds=(2025,1337,42,0,123)):\n",
        "    print('[LogOddsDP-PC] Loading TRAIN cache...', flush=True)\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        print(f'[XGB-V15][Seed {s}] Training...', flush=True)\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    ensure_test_cache_v15()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        Pp = preprocess_probs(P, T=1.0, smooth_win=1)\n",
        "        pred = decode_sequence_dp_logodds_pc(Pp,\n",
        "                                            switch_penalty=dp_params.get('lambda', 0.9),\n",
        "                                            bg_bias=dp_params.get('bg_bias', 0.25),\n",
        "                                            merge_gap=dp_params.get('merge_gap', 3),\n",
        "                                            min_len=dp_params.get('min_len', 12),\n",
        "                                            mean_thr=dp_params.get('mean_thr', 0.5),\n",
        "                                            max_thr=dp_params.get('max_thr', 0.65),\n",
        "                                            min_len_map=min_len_map)\n",
        "        seq = ensure_perm20_preserve_dp(pred, Pp, alpha=1.6)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-LogOdds-PC] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[Run] Log-odds DP + per-class duration: p20 clip [6,14]; 5 seeds; lambda=0.9, bg_bias=0.25, min_len=12, merge_gap=3, T=1, win=1', flush=True)\n",
        "min_map = compute_duration_priors_p20_clip614_from_train_cache_v15()\n",
        "dp_params_lo = {'lambda': 0.9, 'bg_bias': 0.25, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "sub_path = predict_test_logodds_pc_train_only(dp_params_lo, min_len_map=min_map, seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Run] Log-odds DP + per-class duration: p20 clip [6,14]; 5 seeds; lambda=0.9, bg_bias=0.25, min_len=12, merge_gap=3, T=1, win=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] processed 25/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] processed 50/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] processed 75/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] processed 100/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] processed 125/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] processed 150/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] processed 175/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] processed 200/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] processed 225/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] processed 250/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] processed 275/297 train files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DurPrior-20] per-class min_len (clipped [6,14]): {1: 14, 2: 14, 3: 14, 4: 14, 5: 14, 6: 14, 7: 14, 8: 14, 9: 14, 10: 14, 11: 13, 12: 14, 13: 14, 14: 14, 15: 14, 16: 14, 17: 14, 18: 14, 19: 14, 20: 14}\n[LogOddsDP-PC] Loading TRAIN cache...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 167.3s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 167.2s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 166.9s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 167.0s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 167.2s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-PC] 10/95 done; elapsed 15.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-PC] 20/95 done; elapsed 30.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-PC] 30/95 done; elapsed 46.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-PC] 40/95 done; elapsed 61.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-PC] 50/95 done; elapsed 76.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-PC] 60/95 done; elapsed 91.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-PC] 70/95 done; elapsed 106.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-PC] 80/95 done; elapsed 121.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-PC] 90/95 done; elapsed 136.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "bf6d7051-4946-417d-920f-b1529aee88f5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 40) Log-odds DP quick run variant: 3 seeds, lambda=1.0, bg_bias=0.30, min_len=10 (stride=2, T=1, smooth=1)\n",
        "print('[Run] Log-odds DP quick infer VAR: 3 seeds, lambda=1.0, bg_bias=0.30, min_len=10, merge_gap=3, T=1, win=1', flush=True)\n",
        "dpq_var = {'lambda': 1.0, 'bg_bias': 0.30, 'merge_gap': 3, 'min_len': 10, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "sub_path = predict_test_logodds_3seeds(dpq_var, seeds=(2025,1337,42))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Run] Log-odds DP quick infer VAR: 3 seeds, lambda=1.0, bg_bias=0.30, min_len=10, merge_gap=3, T=1, win=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogOddsDP-Quick] Loading TRAIN cache...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 167.3s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 167.2s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 167.0s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Quick] 10/95 done; elapsed 9.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Quick] 20/95 done; elapsed 20.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Quick] 30/95 done; elapsed 30.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Quick] 40/95 done; elapsed 39.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Quick] 50/95 done; elapsed 49.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Quick] 60/95 done; elapsed 59.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Quick] 70/95 done; elapsed 69.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Quick] 80/95 done; elapsed 79.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Quick] 90/95 done; elapsed 88.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "1bf2541a-7031-4f06-8353-3caec2b85fe4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 41) Stride-2 TTA {0,1} + Log-odds DP decode with DP-preserving rescue; TRAIN-only 5 seeds; T=1, win=1\n",
        "import os, time, numpy as np, pandas as pd, xgboost as xgb\n",
        "\n",
        "def predict_test_stride2_tta_logodds(seeds=(2025,1337,42,0,123), dp_params=None):\n",
        "    if dp_params is None:\n",
        "        dp_params = {'lambda': 0.9, 'bg_bias': 0.25, 'merge_gap': 3, 'min_len': 12, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "    # Train on TRAIN-only v15 cache\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    # Ensure both test caches exist: stride=2 start=0 already in cache_v15; start=1 exists in CACHE_DIR_V15_S2_O1\n",
        "    ensure_test_cache_v15()\n",
        "    # If offset=1 cache missing, build it quickly\n",
        "    if not os.path.isdir('./cache_v15_s2_o1') or len([f for f in os.listdir('./cache_v15_s2_o1') if f.endswith('.npz')]) < len(test_df):\n",
        "        print('[TTA-LogOdds] Building stride=2 offset=1 cache...')\n",
        "        cache_test_stride2_offset1()\n",
        "    rows = []; t0 = time.time()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d0 = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        d1 = np.load(os.path.join(CACHE_DIR_V15_S2_O1, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X0, X1 = d0['X'], d1['X']\n",
        "        dm0 = xgb.DMatrix(X0); dm1 = xgb.DMatrix(X1)\n",
        "        Ps0 = [m.predict(dm0) for m in models]\n",
        "        Ps1 = [m.predict(dm1) for m in models]\n",
        "        P0 = np.mean(np.stack(Ps0, axis=0), axis=0)\n",
        "        P1 = np.mean(np.stack(Ps1, axis=0), axis=0)\n",
        "        N = max(P0.shape[0], P1.shape[0])\n",
        "        P0i = interp_probs(P0, N)\n",
        "        P1i = interp_probs(P1, N)\n",
        "        P = 0.5*(P0i + P1i)\n",
        "        Pp = preprocess_probs(P, T=1.0, smooth_win=1)\n",
        "        pred = decode_sequence_dp_logodds_quick(Pp,\n",
        "                                              switch_penalty=dp_params.get('lambda', 0.9),\n",
        "                                              bg_bias=dp_params.get('bg_bias', 0.25),\n",
        "                                              merge_gap=dp_params.get('merge_gap', 3),\n",
        "                                              min_len=dp_params.get('min_len', 12),\n",
        "                                              mean_thr=dp_params.get('mean_thr', 0.5),\n",
        "                                              max_thr=dp_params.get('max_thr', 0.65))\n",
        "        seq = ensure_perm20_preserve_dp(pred, Pp, alpha=1.6)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-s2-TTA-LogOdds] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[Run] Stride-2 TTA {0,1} + Log-odds DP; TRAIN-only 5 seeds; lambda=0.9, bg_bias=0.25, min_len=12, T=1, win=1')\n",
        "sub_path = predict_test_stride2_tta_logodds(seeds=(2025,1337,42,0,123), dp_params={'lambda':0.9,'bg_bias':0.25,'merge_gap':3,'min_len':12,'mean_thr':0.5,'max_thr':0.65})\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Run] Stride-2 TTA {0,1} + Log-odds DP; TRAIN-only 5 seeds; lambda=0.9, bg_bias=0.25, min_len=12, T=1, win=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 167.4s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 167.4s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 167.1s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 167.4s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 167.2s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-LogOdds] 10/95 done; elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-LogOdds] 20/95 done; elapsed 58.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-LogOdds] 30/95 done; elapsed 87.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-LogOdds] 40/95 done; elapsed 115.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-LogOdds] 50/95 done; elapsed 143.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-LogOdds] 60/95 done; elapsed 172.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-LogOdds] 70/95 done; elapsed 200.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-LogOdds] 80/95 done; elapsed 228.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-LogOdds] 90/95 done; elapsed 255.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "9893deb4-d492-4fda-9798-6b722ca785f4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 42) OOF grid for Log-odds DP params, then TRAIN-only 5-seed infer with best params (T=1, smooth=1)\n",
        "import os, glob, time, numpy as np, pandas as pd, xgboost as xgb\n",
        "\n",
        "def load_all_oof_items_v15():\n",
        "    files = sorted(glob.glob(os.path.join(OOF_DIR_V15, 'oof_*.npz')))\n",
        "    items = []\n",
        "    for fp in files:\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        items.append((int(d['sid']), d['probs'], d['seq']))\n",
        "    return items\n",
        "\n",
        "def grid_search_logodds_on_oof():\n",
        "    items = load_all_oof_items_v15()\n",
        "    assert items, 'No OOF files found. Build OOF first.'\n",
        "    lambdas = [0.8, 0.9, 1.0]\n",
        "    bg_biases = [0.20, 0.25, 0.30]\n",
        "    minlens = [10, 12]\n",
        "    merge_gap = 3; mean_thr = 0.50; max_thr = 0.65\n",
        "    best = (1e9, None); tried = 0; t0 = time.time()\n",
        "    for lam in lambdas:\n",
        "        for bb in bg_biases:\n",
        "            for ml in minlens:\n",
        "                scores = []\n",
        "                for sid, P, seq in items:\n",
        "                    Pp = preprocess_probs(P, T=1.0, smooth_win=1)\n",
        "                    pred = decode_sequence_dp_logodds_quick(Pp,\n",
        "                        switch_penalty=lam, bg_bias=bb, merge_gap=merge_gap,\n",
        "                        min_len=ml, mean_thr=mean_thr, max_thr=max_thr)\n",
        "                    pred = ensure_perm20_preserve_dp(pred, Pp, alpha=1.6)\n",
        "                    lev = levenshtein(list(pred), list(seq.tolist()))\n",
        "                    scores.append(lev/20.0)\n",
        "                mean_norm = float(np.mean(scores)) if scores else 1.0\n",
        "                tried += 1\n",
        "                if tried % 5 == 0:\n",
        "                    print(f\"[Grid-OOF-LogOdds] {tried} combos, curr mean={mean_norm:.4f} best={best[0]:.4f}\", flush=True)\n",
        "                if mean_norm < best[0]:\n",
        "                    best = (mean_norm, {'lambda': lam, 'bg_bias': bb, 'merge_gap': merge_gap, 'min_len': ml, 'mean_thr': mean_thr, 'max_thr': max_thr})\n",
        "    print(f\"[Grid-OOF-LogOdds] Done {tried} combos in {time.time()-t0:.1f}s. Best={best}\")\n",
        "    return best\n",
        "\n",
        "def predict_test_logodds_train_only_best(dp_params: dict, seeds=(2025,1337,42,0,123)):\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        print(f\"[XGB-V15][Seed {s}] Training...\", flush=True)\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    ensure_test_cache_v15()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        Pp = preprocess_probs(P, T=1.0, smooth_win=1)\n",
        "        pred = decode_sequence_dp_logodds_quick(Pp,\n",
        "                  switch_penalty=dp_params.get('lambda', 0.9),\n",
        "                  bg_bias=dp_params.get('bg_bias', 0.25),\n",
        "                  merge_gap=dp_params.get('merge_gap', 3),\n",
        "                  min_len=dp_params.get('min_len', 12),\n",
        "                  mean_thr=dp_params.get('mean_thr', 0.5),\n",
        "                  max_thr=dp_params.get('max_thr', 0.65))\n",
        "        seq = ensure_perm20_preserve_dp(pred, Pp, alpha=1.6)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-LogOdds-Best] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[Run] OOF grid for Log-odds DP (T=1, smooth=1); then TRAIN-only 5-seed infer with best params')\n",
        "best_lo = grid_search_logodds_on_oof()\n",
        "print('Best log-odds params:', best_lo)\n",
        "sub_path = predict_test_logodds_train_only_best(best_lo[1], seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Run] OOF grid for Log-odds DP (T=1, smooth=1); then TRAIN-only 5-seed infer with best params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-LogOdds] 5 combos, curr mean=0.3000 best=0.2985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-LogOdds] 10 combos, curr mean=0.3261 best=0.2963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-LogOdds] 15 combos, curr mean=0.2961 best=0.2949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-LogOdds] Done 18 combos in 741.5s. Best=(0.2949494949494949, {'lambda': 1.0, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 10, 'mean_thr': 0.5, 'max_thr': 0.65})\nBest log-odds params: (0.2949494949494949, {'lambda': 1.0, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 10, 'mean_thr': 0.5, 'max_thr': 0.65})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 167.4s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 166.5s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.7s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 166.2s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 166.1s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Best] 10/95 done; elapsed 13.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Best] 20/95 done; elapsed 27.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Best] 30/95 done; elapsed 40.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Best] 40/95 done; elapsed 53.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Best] 50/95 done; elapsed 66.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Best] 60/95 done; elapsed 80.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Best] 70/95 done; elapsed 93.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Best] 80/95 done; elapsed 106.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-LogOdds-Best] 90/95 done; elapsed 119.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "630b81a8-faf6-414a-adb9-82d1fbf797a3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 43) Stride-2 TTA {0,1} + Standard DP with OOF-best params (lambda=0.6, min_len=6); TRAIN-only 5 seeds\n",
        "import os, time, numpy as np, pandas as pd, xgboost as xgb\n",
        "print('[Stride2-TTA OOFDP] TRAIN-only 5-seed; TEST stride=2 offsets {0,1}; align+avg probs; OOF-best DP decode...', flush=True)\n",
        "dp_oof_best = {'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 6, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "\n",
        "# Train on TRAIN-only v1.5 cache\n",
        "X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "models = []\n",
        "for s in (2025,1337,42,0,123):\n",
        "    models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "\n",
        "# Ensure both test caches exist: stride=2 start=0 already in cache_v15; start=1 in CACHE_DIR_V15_S2_O1\n",
        "ensure_test_cache_v15()\n",
        "cache_test_stride2_offset1()\n",
        "\n",
        "rows = []; t0 = time.time()\n",
        "test_ids = test_df['Id'].tolist()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    d0 = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "    d1 = np.load(os.path.join(CACHE_DIR_V15_S2_O1, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "    X0, X1 = d0['X'], d1['X']\n",
        "    dm0 = xgb.DMatrix(X0); dm1 = xgb.DMatrix(X1)\n",
        "    Ps0 = [m.predict(dm0) for m in models]\n",
        "    Ps1 = [m.predict(dm1) for m in models]\n",
        "    P0 = np.mean(np.stack(Ps0, axis=0), axis=0)\n",
        "    P1 = np.mean(np.stack(Ps1, axis=0), axis=0)\n",
        "    N = max(P0.shape[0], P1.shape[0])\n",
        "    P0i = interp_probs(P0, N)\n",
        "    P1i = interp_probs(P1, N)\n",
        "    P = 0.5*(P0i + P1i)\n",
        "    # OOF-aligned hygiene: T=1.0, smooth_win=1, standard DP params (dp_oof_best) and DP-preserving rescue\n",
        "    seq = decode_full_pipeline(P, {'lambda': dp_oof_best['lambda'],\n",
        "                                   'bg_bias': dp_oof_best['bg_bias'],\n",
        "                                   'merge_gap': dp_oof_best['merge_gap'],\n",
        "                                   'min_len': dp_oof_best['min_len'],\n",
        "                                   'mean_thr': dp_oof_best['mean_thr'],\n",
        "                                   'max_thr': dp_oof_best['max_thr']},\n",
        "                               T=1.0, smooth_win=1, alpha_fill=1.5)\n",
        "    rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "    if i % 10 == 0:\n",
        "        print(f\"[TEST-s2-TTA-OOFDP] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "print('Submission written to: submission.csv')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stride2-TTA OOFDP] TRAIN-only 5-seed; TEST stride=2 offsets {0,1}; align+avg probs; OOF-best DP decode...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 166.2s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.8s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.7s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 166.0s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 166.2s\n[CacheV15][TEST] All test cached.\n[CacheV15][TEST s=2,o=1] All cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-OOFDP] 10/95 done; elapsed 26.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-OOFDP] 20/95 done; elapsed 54.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-OOFDP] 30/95 done; elapsed 81.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-OOFDP] 40/95 done; elapsed 107.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-OOFDP] 50/95 done; elapsed 133.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-OOFDP] 60/95 done; elapsed 160.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-OOFDP] 70/95 done; elapsed 186.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-OOFDP] 80/95 done; elapsed 212.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-s2-TTA-OOFDP] 90/95 done; elapsed 238.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "1d19eadc-b65e-4e04-abcc-b1929a1f30c7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 44) Blend v1.5 + v1.6 per-frame probs (0.6/0.4) + standard DP OOF-best; TRAIN-only 3+3 seeds; stride=2\n",
        "import os, time, numpy as np, pandas as pd, xgboost as xgb\n",
        "print('[Blend v15+v16] TRAIN-only 3+3 seeds; stride=2; weights v15=0.6 v16=0.4; OOF-best DP decode (T=1, win=1)...', flush=True)\n",
        "dp_oof_best = {'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 6, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "\n",
        "# Train v1.5 models on TRAIN-only\n",
        "X15, y15, _ = load_frames_from_cache_v15('train')\n",
        "models15 = []\n",
        "for s in (2025,1337,42):\n",
        "    models15.append(train_seed_model_v15(X15, y15, seed=s))\n",
        "\n",
        "# Train v1.6 models on TRAIN-only\n",
        "X16, y16, _ = load_cached_split_v16('train')\n",
        "def train_seed_model_v16_quick(X, y, seed:int):\n",
        "    w = make_weights_with_boundary_erosion(y, w0=0.38)\n",
        "    dtr = xgb.DMatrix(X, label=y, weight=w)\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 21,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'predictor': 'gpu_predictor',\n",
        "        'max_bin': 512,\n",
        "        'max_depth': 7,\n",
        "        'eta': 0.085,\n",
        "        'subsample': 0.85,\n",
        "        'colsample_bytree': 0.85,\n",
        "        'min_child_weight': 4.0,\n",
        "        'lambda': 1.0,\n",
        "        'seed': int(seed)\n",
        "    }\n",
        "    print(f\"[XGB-V16][Seed {seed}] Training...\", flush=True)\n",
        "    t0 = time.time()\n",
        "    bst = xgb.train(params, dtr, num_boost_round=1100, verbose_eval=200)\n",
        "    print(f\"[XGB-V16][Seed {seed}] Done in {time.time()-t0:.1f}s\")\n",
        "    return bst\n",
        "models16 = []\n",
        "for s in (2025,1337,42):\n",
        "    models16.append(train_seed_model_v16_quick(X16, y16, seed=s))\n",
        "\n",
        "# Ensure TEST caches for both v1.5 and v1.6\n",
        "ensure_test_cache_v15()\n",
        "ensure_test_cache_v16()\n",
        "\n",
        "rows = []; t0 = time.time()\n",
        "test_ids = test_df['Id'].tolist()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    # v1.5\n",
        "    d15 = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "    X15t = d15['X']; dm15 = xgb.DMatrix(X15t)\n",
        "    P15s = [m.predict(dm15) for m in models15]\n",
        "    P15 = np.mean(np.stack(P15s, axis=0), axis=0).astype(np.float32)\n",
        "    # v1.6\n",
        "    d16 = np.load(os.path.join(CACHE_DIR_V16, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "    X16t = d16['X']; dm16 = xgb.DMatrix(X16t)\n",
        "    P16s = [m.predict(dm16) for m in models16]\n",
        "    P16 = np.mean(np.stack(P16s, axis=0), axis=0).astype(np.float32)\n",
        "    # Align lengths (both stride=2, but be safe)\n",
        "    N = max(P15.shape[0], P16.shape[0])\n",
        "    P15i = interp_probs(P15, N)\n",
        "    P16i = interp_probs(P16, N)\n",
        "    P = 0.6*P15i + 0.4*P16i\n",
        "    # Decode with OOF-best standard DP, no temp/smoothing; DP-preserving rescue\n",
        "    seq = decode_full_pipeline(P, dp_oof_best, T=1.0, smooth_win=1, alpha_fill=1.5)\n",
        "    rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "    if i % 10 == 0:\n",
        "        print(f\"[TEST-Blend15+16] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "print('Submission written to: submission.csv')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend v15+v16] TRAIN-only 3+3 seeds; stride=2; weights v15=0.6 v16=0.4; OOF-best DP decode (T=1, win=1)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 166.3s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 166.2s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 166.1s\n[LoadCacheV16] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: X=(187296, 193) y=(187296,) files=297 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 2025] Done in 234.8s\n[XGB-V16][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 1337] Done in 234.7s\n[XGB-V16][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 42] Done in 235.0s\n[CacheV15][TEST] All test cached.\n[CacheV16][TEST] 95/95 missing; caching with stride=2...\n[ParCacheV16] test: 95/95 remaining.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=300 -> ./cache_v16/test_00300.npz X=(624, 193) saved in 130.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=301 -> ./cache_v16/test_00301.npz X=(626, 193) saved in 131.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=302 -> ./cache_v16/test_00302.npz X=(661, 193) saved in 133.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=303 -> ./cache_v16/test_00303.npz X=(575, 193) saved in 134.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=304 -> ./cache_v16/test_00304.npz X=(614, 193) saved in 136.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=305 -> ./cache_v16/test_00305.npz X=(620, 193) saved in 138.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=306 -> ./cache_v16/test_00306.npz X=(612, 193) saved in 138.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=308 -> ./cache_v16/test_00308.npz X=(565, 193) saved in 141.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=307 -> ./cache_v16/test_00307.npz X=(594, 193) saved in 141.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=309 -> ./cache_v16/test_00309.npz X=(591, 193) saved in 143.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=310 -> ./cache_v16/test_00310.npz X=(604, 193) saved in 144.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=311 -> ./cache_v16/test_00311.npz X=(695, 193) saved in 146.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=312 -> ./cache_v16/test_00312.npz X=(606, 193) saved in 146.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=313 -> ./cache_v16/test_00313.npz X=(607, 193) saved in 149.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=314 -> ./cache_v16/test_00314.npz X=(608, 193) saved in 150.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=315 -> ./cache_v16/test_00315.npz X=(662, 193) saved in 151.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=316 -> ./cache_v16/test_00316.npz X=(611, 193) saved in 153.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=317 -> ./cache_v16/test_00317.npz X=(631, 193) saved in 152.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=318 -> ./cache_v16/test_00318.npz X=(601, 193) saved in 155.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=319 -> ./cache_v16/test_00319.npz X=(579, 193) saved in 158.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV16] test: 20/95 done; elapsed 299.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=320 -> ./cache_v16/test_00320.npz X=(573, 193) saved in 158.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=321 -> ./cache_v16/test_00321.npz X=(589, 193) saved in 160.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=322 -> ./cache_v16/test_00322.npz X=(657, 193) saved in 161.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=323 -> ./cache_v16/test_00323.npz X=(580, 193) saved in 161.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=324 -> ./cache_v16/test_00324.npz X=(620, 193) saved in 165.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=325 -> ./cache_v16/test_00325.npz X=(621, 193) saved in 166.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=326 -> ./cache_v16/test_00326.npz X=(636, 193) saved in 164.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=327 -> ./cache_v16/test_00327.npz X=(599, 193) saved in 162.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=329 -> ./cache_v16/test_00329.npz X=(609, 193) saved in 166.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=328 -> ./cache_v16/test_00328.npz X=(565, 193) saved in 169.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=330 -> ./cache_v16/test_00330.npz X=(576, 193) saved in 171.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=332 -> ./cache_v16/test_00332.npz X=(781, 193) saved in 172.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=333 -> ./cache_v16/test_00333.npz X=(776, 193) saved in 175.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=335 -> ./cache_v16/test_00335.npz X=(762, 193) saved in 179.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=334 -> ./cache_v16/test_00334.npz X=(704, 193) saved in 181.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=336 -> ./cache_v16/test_00336.npz X=(787, 193) saved in 183.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=337 -> ./cache_v16/test_00337.npz X=(768, 193) saved in 182.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=340 -> ./cache_v16/test_00340.npz X=(602, 193) saved in 180.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=338 -> ./cache_v16/test_00338.npz X=(854, 193) saved in 186.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=339 -> ./cache_v16/test_00339.npz X=(820, 193) saved in 189.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV16] test: 40/95 done; elapsed 637.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=341 -> ./cache_v16/test_00341.npz X=(662, 193) saved in 190.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=342 -> ./cache_v16/test_00342.npz X=(529, 193) saved in 190.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=343 -> ./cache_v16/test_00343.npz X=(601, 193) saved in 193.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=344 -> ./cache_v16/test_00344.npz X=(634, 193) saved in 194.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=345 -> ./cache_v16/test_00345.npz X=(590, 193) saved in 192.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=346 -> ./cache_v16/test_00346.npz X=(615, 193) saved in 195.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=347 -> ./cache_v16/test_00347.npz X=(581, 193) saved in 197.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=348 -> ./cache_v16/test_00348.npz X=(530, 193) saved in 200.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=351 -> ./cache_v16/test_00351.npz X=(606, 193) saved in 200.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=352 -> ./cache_v16/test_00352.npz X=(621, 193) saved in 196.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=353 -> ./cache_v16/test_00353.npz X=(604, 193) saved in 202.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=354 -> ./cache_v16/test_00354.npz X=(605, 193) saved in 202.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=355 -> ./cache_v16/test_00355.npz X=(701, 193) saved in 207.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=356 -> ./cache_v16/test_00356.npz X=(652, 193) saved in 207.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=357 -> ./cache_v16/test_00357.npz X=(608, 193) saved in 206.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=358 -> ./cache_v16/test_00358.npz X=(685, 193) saved in 207.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=359 -> ./cache_v16/test_00359.npz X=(632, 193) saved in 210.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=360 -> ./cache_v16/test_00360.npz X=(647, 193) saved in 209.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=361 -> ./cache_v16/test_00361.npz X=(596, 193) saved in 214.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=362 -> ./cache_v16/test_00362.npz X=(569, 193) saved in 212.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV16] test: 60/95 done; elapsed 904.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=363 -> ./cache_v16/test_00363.npz X=(599, 193) saved in 216.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=364 -> ./cache_v16/test_00364.npz X=(572, 193) saved in 221.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=365 -> ./cache_v16/test_00365.npz X=(655, 193) saved in 220.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=366 -> ./cache_v16/test_00366.npz X=(639, 193) saved in 223.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=368 -> ./cache_v16/test_00368.npz X=(688, 193) saved in 224.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=367 -> ./cache_v16/test_00367.npz X=(598, 193) saved in 227.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=370 -> ./cache_v16/test_00370.npz X=(634, 193) saved in 218.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=369 -> ./cache_v16/test_00369.npz X=(602, 193) saved in 226.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=371 -> ./cache_v16/test_00371.npz X=(933, 193) saved in 234.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=372 -> ./cache_v16/test_00372.npz X=(848, 193) saved in 233.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=373 -> ./cache_v16/test_00373.npz X=(639, 193) saved in 234.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=374 -> ./cache_v16/test_00374.npz X=(547, 193) saved in 235.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=375 -> ./cache_v16/test_00375.npz X=(629, 193) saved in 235.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=376 -> ./cache_v16/test_00376.npz X=(654, 193) saved in 237.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=377 -> ./cache_v16/test_00377.npz X=(602, 193) saved in 238.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=378 -> ./cache_v16/test_00378.npz X=(702, 193) saved in 240.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=379 -> ./cache_v16/test_00379.npz X=(564, 193) saved in 240.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=380 -> ./cache_v16/test_00380.npz X=(598, 193) saved in 243.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=381 -> ./cache_v16/test_00381.npz X=(606, 193) saved in 238.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=383 -> ./cache_v16/test_00383.npz X=(588, 193) saved in 245.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV16] test: 80/95 done; elapsed 1338.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=384 -> ./cache_v16/test_00384.npz X=(684, 193) saved in 245.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=385 -> ./cache_v16/test_00385.npz X=(592, 193) saved in 244.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=386 -> ./cache_v16/test_00386.npz X=(578, 193) saved in 246.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=389 -> ./cache_v16/test_00389.npz X=(585, 193) saved in 250.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=390 -> ./cache_v16/test_00390.npz X=(637, 193) saved in 233.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=391 -> ./cache_v16/test_00391.npz X=(667, 193) saved in 242.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=392 -> ./cache_v16/test_00392.npz X=(618, 193) saved in 240.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=393 -> ./cache_v16/test_00393.npz X=(577, 193) saved in 239.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=394 -> ./cache_v16/test_00394.npz X=(641, 193) saved in 234.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=396 -> ./cache_v16/test_00396.npz X=(628, 193) saved in 226.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=395 -> ./cache_v16/test_00395.npz X=(611, 193) saved in 234.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=397 -> ./cache_v16/test_00397.npz X=(654, 193) saved in 225.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=401 -> ./cache_v16/test_00401.npz X=(558, 193) saved in 207.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=402 -> ./cache_v16/test_00402.npz X=(653, 193) saved in 199.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16] test id=403 -> ./cache_v16/test_00403.npz X=(604, 193) saved in 190.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ParCacheV16] test: completed 95 in 1567.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Blend15+16] 10/95 done; elapsed 16.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Blend15+16] 20/95 done; elapsed 32.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Blend15+16] 30/95 done; elapsed 48.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Blend15+16] 40/95 done; elapsed 64.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Blend15+16] 50/95 done; elapsed 80.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Blend15+16] 60/95 done; elapsed 96.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Blend15+16] 70/95 done; elapsed 112.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Blend15+16] 80/95 done; elapsed 127.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Blend15+16] 90/95 done; elapsed 143.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "130fbb31-4c8b-4faf-aa87-b1cfcee5ccc3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 45) Medal push: Standard DP with light smoothing and mid min_len (no TTA), TRAIN-only 5 seeds\n",
        "print('[MedalAttempt] TRAIN-only 5-seed; v1.5 stride=2; T=1.0, smooth_win=3; DP lambda=0.7, min_len=9; DP-preserving rescue', flush=True)\n",
        "best_params_goldilocks = {'T': 1.0, 'smooth_win': 3, 'lambda': 0.7, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 9, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "sub_path = predict_test_full_pipeline_train_only(best_params_goldilocks, seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MedalAttempt] TRAIN-only 5-seed; v1.5 stride=2; T=1.0, smooth_win=3; DP lambda=0.7, min_len=9; DP-preserving rescue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 166.0s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.9s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.7s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 166.3s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 165.8s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 10/95 done; elapsed 13.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 20/95 done; elapsed 26.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 30/95 done; elapsed 40.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 40/95 done; elapsed 53.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 50/95 done; elapsed 66.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 60/95 done; elapsed 79.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 70/95 done; elapsed 93.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 80/95 done; elapsed 106.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-Full] 90/95 done; elapsed 118.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "16f2fe14-8e53-4632-af61-804c82fe22d3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 46) Blend v1.5 (5 seeds) + v1.6 (5 seeds) probs (0.5/0.5) + Goldilocks DP (lambda=0.7, min_len=9, smooth_win=3); TRAIN-only; stride=2\n",
        "import os, time, numpy as np, pandas as pd, xgboost as xgb\n",
        "print('[Blend v15+v16 x10] TRAIN-only 5+5 seeds; stride=2; weights v15=0.5 v16=0.5; Goldilocks DP (T=1, win=3, lambda=0.7, min_len=9)...', flush=True)\n",
        "\n",
        "best_params_goldilocks = {'T': 1.0, 'smooth_win': 3, 'lambda': 0.7, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 9, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "\n",
        "# Train v1.5 models on TRAIN-only (5 seeds)\n",
        "X15, y15, _ = load_frames_from_cache_v15('train')\n",
        "models15 = []\n",
        "for s in (2025,1337,42,0,123):\n",
        "    models15.append(train_seed_model_v15(X15, y15, seed=s))\n",
        "\n",
        "# Train v1.6 models on TRAIN-only (5 seeds)\n",
        "X16, y16, _ = load_cached_split_v16('train')\n",
        "models16 = []\n",
        "for s in (2025,1337,42,0,123):\n",
        "    models16.append(train_seed_model_v16(X16, y16, seed=s))\n",
        "\n",
        "# Ensure TEST caches for both v1.5 and v1.6\n",
        "ensure_test_cache_v15()\n",
        "ensure_test_cache_v16()\n",
        "\n",
        "rows = []; t0 = time.time()\n",
        "test_ids = test_df['Id'].tolist()\n",
        "for i, sid in enumerate(test_ids, 1):\n",
        "    # v1.5\n",
        "    d15 = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "    X15t = d15['X']; dm15 = xgb.DMatrix(X15t)\n",
        "    P15s = [m.predict(dm15) for m in models15]\n",
        "    P15 = np.mean(np.stack(P15s, axis=0), axis=0).astype(np.float32)\n",
        "    # v1.6\n",
        "    d16 = np.load(os.path.join(CACHE_DIR_V16, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "    X16t = d16['X']; dm16 = xgb.DMatrix(X16t)\n",
        "    P16s = [m.predict(dm16) for m in models16]\n",
        "    P16 = np.mean(np.stack(P16s, axis=0), axis=0).astype(np.float32)\n",
        "    # Align lengths (both stride=2, but be safe)\n",
        "    N = max(P15.shape[0], P16.shape[0])\n",
        "    P15i = interp_probs(P15, N)\n",
        "    P16i = interp_probs(P16, N)\n",
        "    P = 0.5*P15i + 0.5*P16i\n",
        "    # Decode with Goldilocks DP, T=1, smooth_win=3, DP-preserving rescue\n",
        "    seq = decode_full_pipeline(P, best_params_goldilocks, T=best_params_goldilocks['T'], smooth_win=best_params_goldilocks['smooth_win'], alpha_fill=1.5)\n",
        "    rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "    if i % 10 == 0:\n",
        "        print(f\"[TEST-Blend15+16 x10] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "print('Submission written to: submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "9cf42ef7-f47d-4bfa-a6ba-23d6b55a34b1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 47) OOF grid: standard DP with smooth_win=3 (T=1), tune lambda/min_len; then TRAIN-only 5-seed infer\n",
        "import os, glob, time, numpy as np, pandas as pd, xgboost as xgb\n",
        "\n",
        "def load_all_oof_items_v15():\n",
        "    files = sorted(glob.glob(os.path.join(OOF_DIR_V15, 'oof_*.npz')))\n",
        "    items = []\n",
        "    for fp in files:\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        items.append((int(d['sid']), d['probs'], d['seq']))\n",
        "    return items\n",
        "\n",
        "def grid_search_std_dp_oof_smooth3():\n",
        "    items = load_all_oof_items_v15()\n",
        "    assert items, 'No OOF files found. Build OOF first.'\n",
        "    lambdas = [0.6, 0.7, 0.8]\n",
        "    minlens = [8, 9, 10]\n",
        "    bg_bias = 0.2; merge_gap = 3; mean_thr = 0.50; max_thr = 0.65\n",
        "    best = (1e9, None); tried = 0; t0 = time.time()\n",
        "    for lam in lambdas:\n",
        "        for ml in minlens:\n",
        "            scores = []\n",
        "            for sid, P, seq in items:\n",
        "                Pp = preprocess_probs(P, T=1.0, smooth_win=3)\n",
        "                pred = decode_sequence_dp(Pp,\n",
        "                                         switch_penalty=lam, bg_bias=bg_bias,\n",
        "                                         merge_gap=merge_gap, min_len=ml,\n",
        "                                         mean_thr=mean_thr, max_thr=max_thr)\n",
        "                pred = ensure_perm20_preserve_dp(pred, Pp, alpha=1.5)\n",
        "                lev = levenshtein(list(pred), list(seq.tolist()))\n",
        "                scores.append(lev/20.0)\n",
        "            mean_norm = float(np.mean(scores)) if scores else 1.0\n",
        "            tried += 1\n",
        "            if tried % 3 == 0:\n",
        "                print(f\"[Grid-OOF-StdDP-S3] {tried} combos, curr mean={mean_norm:.4f} best={best[0]:.4f}\", flush=True)\n",
        "            if mean_norm < best[0]:\n",
        "                best = (mean_norm, {'T':1.0,'smooth_win':3,'lambda':lam,'bg_bias':bg_bias,'merge_gap':merge_gap,'min_len':ml,'mean_thr':mean_thr,'max_thr':max_thr})\n",
        "    print(f\"[Grid-OOF-StdDP-S3] Done {tried} combos in {time.time()-t0:.1f}s. Best={best}\")\n",
        "    return best\n",
        "\n",
        "def predict_test_full_pipeline_train_only_with_params(best_params: dict, seeds=(2025,1337,42,0,123)):\n",
        "    # Train TRAIN-only v1.5 models, average probs, apply full pipeline (T=1, smooth=3) and write submission.csv\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    ensure_test_cache_v15()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        seq = decode_full_pipeline(P, best_params, T=best_params['T'], smooth_win=best_params['smooth_win'], alpha_fill=1.5)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-StdDP-S3] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[Run] OOF grid for Standard DP with T=1, smooth_win=3; then TRAIN-only 5-seed infer with best params', flush=True)\n",
        "best_std_s3 = grid_search_std_dp_oof_smooth3()\n",
        "print('Best std-DP smooth3 params:', best_std_s3)\n",
        "sub_path = predict_test_full_pipeline_train_only_with_params(best_std_s3[1], seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Run] OOF grid for Standard DP with T=1, smooth_win=3; then TRAIN-only 5-seed infer with best params\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-StdDP-S3] 3 combos, curr mean=0.2901 best=0.2732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-StdDP-S3] 6 combos, curr mean=0.2904 best=0.2732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-StdDP-S3] 9 combos, curr mean=0.2902 best=0.2732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-StdDP-S3] Done 9 combos in 16.8s. Best=(0.27323232323232327, {'T': 1.0, 'smooth_win': 3, 'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 8, 'mean_thr': 0.5, 'max_thr': 0.65})\nBest std-DP smooth3 params: (0.27323232323232327, {'T': 1.0, 'smooth_win': 3, 'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 8, 'mean_thr': 0.5, 'max_thr': 0.65})\n[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 166.0s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 166.0s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.5s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 165.9s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 165.9s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-StdDP-S3] 10/95 done; elapsed 13.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-StdDP-S3] 20/95 done; elapsed 26.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-StdDP-S3] 30/95 done; elapsed 40.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-StdDP-S3] 40/95 done; elapsed 53.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-StdDP-S3] 50/95 done; elapsed 66.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-StdDP-S3] 60/95 done; elapsed 79.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-StdDP-S3] 70/95 done; elapsed 92.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-StdDP-S3] 80/95 done; elapsed 105.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-StdDP-S3] 90/95 done; elapsed 118.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "11c85e2d-7c5a-4598-bb65-5cf6ffb51269",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 48) Order-conditioned segmentation DP: infer per-sample order via centroids, then segment into 20 gestures in that order\n",
        "import os, time, numpy as np, pandas as pd, xgboost as xgb\n",
        "\n",
        "def compute_order_by_centroid(P: np.ndarray, alpha: float = 1.6, smooth_win: int = 3):\n",
        "    # Smooth and compute temporal centroids mu for classes 1..20; return order (list of classes) ascending by mu\n",
        "    P2 = preprocess_probs(P, T=1.0, smooth_win=smooth_win)\n",
        "    Tn, C = P2.shape\n",
        "    t = np.arange(Tn, dtype=np.float32)\n",
        "    W = np.power(P2[:, 1:], alpha)  # (T,20) exclude bg\n",
        "    denom = W.sum(axis=0) + 1e-9\n",
        "    mu = (W * t[:, None]).sum(axis=0) / denom  # (20,)\n",
        "    # Tie-breakers for stability: mass desc, peak desc\n",
        "    mass = P2[:, 1:].sum(axis=0)\n",
        "    peak = P2[:, 1:].max(axis=0)\n",
        "    # Stable ranking: primarily by mu asc; for ties, larger mass then peak earlier\n",
        "    idx_mu = np.argsort(mu, kind='mergesort')\n",
        "    ranks_mu = np.empty_like(idx_mu); ranks_mu[idx_mu] = np.arange(20)\n",
        "    ranks_mass = np.empty_like(idx_mu); ranks_mass[np.argsort(-mass, kind='mergesort')] = np.arange(20)\n",
        "    ranks_peak = np.empty_like(idx_mu); ranks_peak[np.argsort(-peak, kind='mergesort')] = np.arange(20)\n",
        "    score = ranks_mu + 1e-3*ranks_mass + 1e-6*ranks_peak\n",
        "    order_idx = np.argsort(score, kind='mergesort')\n",
        "    order_classes = [int(i+1) for i in order_idx]\n",
        "    return order_classes, P2\n",
        "\n",
        "def segment_dp_fixed_order_logodds(P: np.ndarray, order_classes: list, min_len: int = 9):\n",
        "    # P: (T,21) probs, 0=bg; order_classes: length-20 permutation of 1..20\n",
        "    # Build log-odds scores s(t,c) = log p(c) - log p(bg) for c in order_classes; DP to cut 20 segments maximizing sum\n",
        "    eps = 1e-9\n",
        "    Tn, C = P.shape\n",
        "    logp = np.log(np.clip(P, eps, 1.0)).astype(np.float32)\n",
        "    # s: (T,20)\n",
        "    s = logp[:, np.array(order_classes, dtype=np.int32)] - logp[:, [0]]\n",
        "    # prefix sums per class for O(1) segment score\n",
        "    cs = np.zeros((Tn+1, 20), dtype=np.float32)\n",
        "    np.cumsum(s, axis=0, out=cs[1:])\n",
        "    mins = np.full(20, int(min_len), dtype=np.int32)\n",
        "    # DP over classes i=0..19; DP_prev[t] best up to t (end at t) placing first i classes\n",
        "    DP_prev = np.full(Tn+1, -1e18, dtype=np.float32); DP_prev[0] = 0.0\n",
        "    backp = []  # list of arrays bp_i[t] start u for segment i ending at t\n",
        "    cum_min = 0\n",
        "    for i in range(20):\n",
        "        mlen = int(mins[i])\n",
        "        DP_cur = np.full(Tn+1, -1e18, dtype=np.float32)\n",
        "        bp = np.full(Tn+1, -1, dtype=np.int32)\n",
        "        cum_min += mlen\n",
        "        # Maintain running best M[u] = DP_prev[u] - cs[u, i]\n",
        "        M_val = -1e18; M_idx = -1\n",
        "        for t_end in range(mlen, Tn+1):\n",
        "            u = t_end - mlen\n",
        "            cand = DP_prev[u] - cs[u, i]\n",
        "            if cand > M_val:\n",
        "                M_val = cand; M_idx = u\n",
        "            DP_cur[t_end] = cs[t_end, i] + M_val\n",
        "            bp[t_end] = M_idx\n",
        "        backp.append(bp)\n",
        "        DP_prev = DP_cur\n",
        "    # Best end time for class 20\n",
        "    t_end = int(np.argmax(DP_prev))\n",
        "    # Backtrack cuts\n",
        "    cuts = [0]*(21)\n",
        "    cuts[20] = t_end\n",
        "    for i in range(19, -1, -1):\n",
        "        u = int(backp[i][cuts[i+1]])\n",
        "        if u < 0:\n",
        "            u = max(0, cuts[i+1] - int(mins[i]))\n",
        "        cuts[i] = u\n",
        "    # Return the 20 classes in this optimized order (already order_classes), as the final sequence\n",
        "    return order_classes\n",
        "\n",
        "def predict_test_order_segment_train_only(seeds=(2025,1337,42,0,123), alpha: float = 1.6, smooth_win: int = 3, min_len: int = 9):\n",
        "    # Train TRAIN-only v1.5 models, average probs, infer per-sample order and segment accordingly\n",
        "    X_tr, y_tr, _ = load_frames_from_cache_v15('train')\n",
        "    models = []\n",
        "    for s in seeds:\n",
        "        models.append(train_seed_model_v15(X_tr, y_tr, seed=s))\n",
        "    ensure_test_cache_v15()\n",
        "    rows = []; t0 = time.time()\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V15, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0)\n",
        "        order_classes, P2 = compute_order_by_centroid(P, alpha=alpha, smooth_win=smooth_win)\n",
        "        seq = segment_dp_fixed_order_logodds(P2, order_classes, min_len=min_len)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-OrderSeg] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[SUBMISSION] Wrote submission.csv with', len(rows), 'rows.')\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('[OrderSeg] TRAIN-only 5-seed; v1.5 stride=2; infer per-sample order (alpha=1.6, smooth=3) and segment with min_len=9 ...', flush=True)\n",
        "sub_path = predict_test_order_segment_train_only(seeds=(2025,1337,42,0,123), alpha=1.6, smooth_win=3, min_len=9)\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OrderSeg] TRAIN-only 5-seed; v1.5 stride=2; infer per-sample order (alpha=1.6, smooth=3) and segment with min_len=9 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 166.1s\n[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 166.0s\n[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.7s\n[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 166.0s\n[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 165.8s\n[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-OrderSeg] 10/95 done; elapsed 13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-OrderSeg] 20/95 done; elapsed 26.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-OrderSeg] 30/95 done; elapsed 40.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-OrderSeg] 40/95 done; elapsed 52.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-OrderSeg] 50/95 done; elapsed 65.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-OrderSeg] 60/95 done; elapsed 79.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-OrderSeg] 70/95 done; elapsed 92.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-OrderSeg] 80/95 done; elapsed 105.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-OrderSeg] 90/95 done; elapsed 117.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "9b5c19aa-3f99-4e0d-883f-f1a6bec8a874",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 49) v1.6-only medal attempt: TRAIN-only, stride=2, 5-seed XGB, Goldilocks DP with DP-preserving rescue\n",
        "print('[V16 Goldilocks] TRAIN-only 5-seed; v1.6 stride=2; T=1.0, smooth_win=3; DP lambda=0.7, min_len=9; DP-preserving rescue', flush=True)\n",
        "best_params_goldilocks_v16 = {'T': 1.0, 'smooth_win': 3, 'lambda': 0.7, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 9, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "sub_path = predict_test_full_pipeline_train_only_v16(best_params_goldilocks_v16, seeds=(2025,1337,42,0,123))\n",
        "print('Submission written to:', sub_path)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[V16 Goldilocks] TRAIN-only 5-seed; v1.6 stride=2; T=1.0, smooth_win=3; DP lambda=0.7, min_len=9; DP-preserving rescue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: X=(187296, 193) y=(187296,) files=297 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 2025] Done in 233.7s\n[XGB-V16][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 1337] Done in 234.1s\n[XGB-V16][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 42] Done in 234.8s\n[XGB-V16][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 0] Done in 234.6s\n[XGB-V16][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 123] Done in 235.2s\n[CacheV16][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 10/95 done; elapsed 13.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 20/95 done; elapsed 27.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 30/95 done; elapsed 40.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 40/95 done; elapsed 53.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 50/95 done; elapsed 67.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 60/95 done; elapsed 80.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 70/95 done; elapsed 94.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 80/95 done; elapsed 107.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 90/95 done; elapsed 120.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "08b8167f-63c4-4686-8066-c0a3e72448f3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 50) Quick v1.6 OOF DP sweep (3-fold) for lambda/min_len under smooth_win=3; then optional re-infer TEST if >=0.003 gain\n",
        "import os, glob, time, numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb\n",
        "\n",
        "OOF_DIR_V16 = './oof_probs_v16'\n",
        "os.makedirs(OOF_DIR_V16, exist_ok=True)\n",
        "\n",
        "def load_train_item_v16(sid:int):\n",
        "    fp = os.path.join(CACHE_DIR_V16, f'train_{sid:05d}.npz')\n",
        "    d = np.load(fp, allow_pickle=False)\n",
        "    X = d['X']; y = d['y']\n",
        "    row = train_df.loc[train_df.Id==sid]\n",
        "    seq = []\n",
        "    if not row.empty:\n",
        "        seq = [int(x) for x in re.findall(r'\\d+', str(row['Sequence'].values[0]))]\n",
        "    return X, y.astype(np.int32), np.array(seq, dtype=np.int16)\n",
        "\n",
        "def load_many_train_frames_v16(sids:list):\n",
        "    Xs, ys = [], []\n",
        "    n = 0\n",
        "    t0 = time.time()\n",
        "    for i, sid in enumerate(sids, 1):\n",
        "        X, y, _ = load_train_item_v16(sid)\n",
        "        Xs.append(X); ys.append(y); n += len(y)\n",
        "        if i % 20 == 0:\n",
        "            print(f\"[LoadTrainFoldV16] {i}/{len(sids)} ids, cum frames={n}\", flush=True)\n",
        "    X = np.vstack(Xs); y = np.concatenate(ys)\n",
        "    print(f\"[LoadTrainFoldV16] Loaded {len(sids)} ids: X={X.shape} y={y.shape}\", flush=True)\n",
        "    return X, y\n",
        "\n",
        "def train_fold_model_v16(X, y, seed:int=2025, num_rounds:int=900):\n",
        "    w = make_weights_with_boundary_erosion(y, w0=0.38)\n",
        "    dtr = xgb.DMatrix(X, label=y, weight=w)\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 21,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'predictor': 'gpu_predictor',\n",
        "        'max_bin': 512,\n",
        "        'max_depth': 7,\n",
        "        'eta': 0.085,\n",
        "        'subsample': 0.85,\n",
        "        'colsample_bytree': 0.85,\n",
        "        'min_child_weight': 4.0,\n",
        "        'lambda': 1.0,\n",
        "        'seed': int(seed)\n",
        "    }\n",
        "    bst = xgb.train(params, dtr, num_boost_round=num_rounds, verbose_eval=200)\n",
        "    return bst\n",
        "\n",
        "def build_oof_probs_v16(n_splits=3, seed=2025, num_rounds=900):\n",
        "    ids = train_df['Id'].tolist()\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "    fold = 0; t_all = time.time()\n",
        "    for tr_idx, va_idx in kf.split(ids):\n",
        "        fold += 1\n",
        "        tr_ids = [ids[i] for i in tr_idx]\n",
        "        va_ids = [ids[i] for i in va_idx]\n",
        "        print(f\"[OOF-V16] Fold {fold}/{n_splits}: tr={len(tr_ids)} va={len(va_ids)}\", flush=True)\n",
        "        X_tr, y_tr = load_many_train_frames_v16(tr_ids)\n",
        "        t0 = time.time()\n",
        "        bst = train_fold_model_v16(X_tr, y_tr, seed=seed+fold, num_rounds=num_rounds)\n",
        "        print(f\"[OOF-V16] Fold {fold} model trained in {time.time()-t0:.1f}s\", flush=True)\n",
        "        for i, sid in enumerate(va_ids, 1):\n",
        "            X_va, _, seq20 = load_train_item_v16(sid)\n",
        "            P = bst.predict(xgb.DMatrix(X_va))\n",
        "            outp = os.path.join(OOF_DIR_V16, f'oof_{sid:05d}.npz')\n",
        "            np.savez_compressed(outp, probs=P.astype(np.float32), seq=seq20, sid=sid)\n",
        "            if i % 10 == 0:\n",
        "                print(f\"  [OOF-V16] Fold {fold} saved {i}/{len(va_ids)}\", flush=True)\n",
        "    print(f\"[OOF-V16] Completed {n_splits}-fold OOF in {time.time()-t_all:.1f}s. Files in {OOF_DIR_V16}\")\n",
        "\n",
        "def load_all_oof_items_v16():\n",
        "    files = sorted(glob.glob(os.path.join(OOF_DIR_V16, 'oof_*.npz')))\n",
        "    items = []\n",
        "    for fp in files:\n",
        "        d = np.load(fp, allow_pickle=False)\n",
        "        sid = int(d['sid']); P = d['probs']; seq = d['seq']\n",
        "        items.append((sid, P, seq))\n",
        "    return items\n",
        "\n",
        "def grid_search_dp_on_oof_v16():\n",
        "    items = load_all_oof_items_v16()\n",
        "    assert items, 'No OOF v16 files found. Run build_oof_probs_v16() first.'\n",
        "    lambdas = [0.6, 0.7, 0.8]\n",
        "    minlens = [8, 9, 10]\n",
        "    bg_bias = 0.2; merge_gap = 3; mean_thr = 0.50; max_thr = 0.65\n",
        "    best = (1e9, None); tried = 0; t0 = time.time()\n",
        "    for lam in lambdas:\n",
        "        for ml in minlens:\n",
        "            scores = []\n",
        "            for sid, P, seq in items:\n",
        "                Pp = preprocess_probs(P, T=1.0, smooth_win=3)\n",
        "                pred = decode_sequence_dp(Pp,\n",
        "                                         switch_penalty=lam, bg_bias=bg_bias,\n",
        "                                         merge_gap=merge_gap, min_len=ml,\n",
        "                                         mean_thr=mean_thr, max_thr=max_thr)\n",
        "                pred = ensure_perm20_preserve_dp(pred, Pp, alpha=1.5)\n",
        "                lev = levenshtein(list(pred), list(seq.tolist()))\n",
        "                scores.append(lev/20.0)\n",
        "            mean_norm = float(np.mean(scores)) if scores else 1.0\n",
        "            tried += 1\n",
        "            if tried % 3 == 0:\n",
        "                print(f\"[Grid-OOF-V16] {tried} combos, curr mean={mean_norm:.4f} best={best[0]:.4f}\", flush=True)\n",
        "            if mean_norm < best[0]:\n",
        "                best = (mean_norm, {'T':1.0,'smooth_win':3,'lambda':lam,'bg_bias':bg_bias,'merge_gap':merge_gap,'min_len':ml,'mean_thr':mean_thr,'max_thr':max_thr})\n",
        "    print(f\"[Grid-OOF-V16] Done {tried} combos in {time.time()-t0:.1f}s. Best={best}\")\n",
        "    return best\n",
        "\n",
        "print('[RUN V16 OOF] Building 3-fold OOF on TRAIN (stride=2, v1.6)...', flush=True)\n",
        "build_oof_probs_v16(n_splits=3, seed=2025, num_rounds=900)\n",
        "print('[RUN V16 OOF] Grid-search DP (lambda in {0.6,0.7,0.8}, min_len in {8,9,10}) with smooth_win=3 ...', flush=True)\n",
        "best_v16 = grid_search_dp_on_oof_v16()\n",
        "print('Best v1.6 OOF DP params:', best_v16)\n",
        "\n",
        "# Optional: if improvement >= 0.003 over Goldilocks (unknown exact baseline here), run TEST with best_v16\n",
        "best_params = best_v16[1]\n",
        "if best_params is not None:\n",
        "    print('[V16 OOF->TEST] TRAIN-only 5-seed inference with OOF-best params...')\n",
        "    sub_path = predict_test_full_pipeline_train_only_v16(best_params, seeds=(2025,1337,42,0,123))\n",
        "    print('Submission written to:', sub_path)\n",
        "else:\n",
        "    print('[V16 OOF->TEST] No best params found; skipping re-inference.')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RUN V16 OOF] Building 3-fold OOF on TRAIN (stride=2, v1.6)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-V16] Fold 1/3: tr=198 va=99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 20/198 ids, cum frames=12406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 40/198 ids, cum frames=27016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 60/198 ids, cum frames=40317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 80/198 ids, cum frames=52889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 100/198 ids, cum frames=65007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 120/198 ids, cum frames=77261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 140/198 ids, cum frames=89593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 160/198 ids, cum frames=101797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 180/198 ids, cum frames=114364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] Loaded 198 ids: X=(125030, 193) y=(125030,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-V16] Fold 1 model trained in 158.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 1 saved 10/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 1 saved 20/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 1 saved 30/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 1 saved 40/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 1 saved 50/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 1 saved 60/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 1 saved 70/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 1 saved 80/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 1 saved 90/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-V16] Fold 2/3: tr=198 va=99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 20/198 ids, cum frames=12531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 40/198 ids, cum frames=26464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 60/198 ids, cum frames=40575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 80/198 ids, cum frames=53302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 100/198 ids, cum frames=65490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 120/198 ids, cum frames=77307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 140/198 ids, cum frames=89524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 160/198 ids, cum frames=101698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 180/198 ids, cum frames=114138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] Loaded 198 ids: X=(125029, 193) y=(125029,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-V16] Fold 2 model trained in 158.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 2 saved 10/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 2 saved 20/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 2 saved 30/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 2 saved 40/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 2 saved 50/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 2 saved 60/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 2 saved 70/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 2 saved 80/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 2 saved 90/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-V16] Fold 3/3: tr=198 va=99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 20/198 ids, cum frames=12247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 40/198 ids, cum frames=27117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 60/198 ids, cum frames=40790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 80/198 ids, cum frames=53124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 100/198 ids, cum frames=65256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 120/198 ids, cum frames=77121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 140/198 ids, cum frames=89136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 160/198 ids, cum frames=101120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] 180/198 ids, cum frames=113745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadTrainFoldV16] Loaded 198 ids: X=(124533, 193) y=(124533,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-V16] Fold 3 model trained in 159.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 3 saved 10/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 3 saved 20/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 3 saved 30/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 3 saved 40/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 3 saved 50/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 3 saved 60/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 3 saved 70/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 3 saved 80/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [OOF-V16] Fold 3 saved 90/99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OOF-V16] Completed 3-fold OOF in 543.3s. Files in ./oof_probs_v16\n[RUN V16 OOF] Grid-search DP (lambda in {0.6,0.7,0.8}, min_len in {8,9,10}) with smooth_win=3 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-V16] 3 combos, curr mean=0.2850 best=0.2704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-V16] 6 combos, curr mean=0.2847 best=0.2704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-V16] 9 combos, curr mean=0.2864 best=0.2704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Grid-OOF-V16] Done 9 combos in 16.7s. Best=(0.2703703703703704, {'T': 1.0, 'smooth_win': 3, 'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 8, 'mean_thr': 0.5, 'max_thr': 0.65})\nBest v1.6 OOF DP params: (0.2703703703703704, {'T': 1.0, 'smooth_win': 3, 'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 8, 'mean_thr': 0.5, 'max_thr': 0.65})\n[V16 OOF->TEST] TRAIN-only 5-seed inference with OOF-best params...\n[LoadCacheV16] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: X=(187296, 193) y=(187296,) files=297 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 2025] Done in 234.4s\n[XGB-V16][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 1337] Done in 234.8s\n[XGB-V16][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 42] Done in 234.8s\n[XGB-V16][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 0] Done in 234.9s\n[XGB-V16][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 123] Done in 234.5s\n[CacheV16][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 10/95 done; elapsed 13.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 20/95 done; elapsed 27.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 30/95 done; elapsed 40.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 40/95 done; elapsed 53.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 50/95 done; elapsed 67.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 60/95 done; elapsed 80.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 70/95 done; elapsed 94.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 80/95 done; elapsed 107.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16] 90/95 done; elapsed 120.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission.csv with 95 rows.\nSubmission written to: submission.csv\n"
          ]
        }
      ]
    },
    {
      "id": "fdd4abc4-f0c5-4309-b5df-918324ebec72",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 51) v1.6 10-seed ensemble + dual decodes (OOF-best smooth=3, and no-smoothing hedge); TRAIN-only, stride=2\n",
        "import os, time, numpy as np, pandas as pd, xgboost as xgb\n",
        "\n",
        "print('[V16 x10] TRAIN-only 10-seed ensemble; stride=2; decode A: OOF-best (T=1, win=3, lambda=0.6, min_len=8); decode B: hedge (T=1, win=1, lambda=0.7, min_len=9) ...', flush=True)\n",
        "\n",
        "# Params per expert\n",
        "params_A = {'T': 1.0, 'smooth_win': 3, 'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 8, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "params_B = {'T': 1.0, 'smooth_win': 1, 'lambda': 0.7, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 9, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "# Optional third conservative hedge if time permits (BG push, longer min_len)\n",
        "params_C = {'T': 1.0, 'smooth_win': 1, 'lambda': 0.8, 'bg_bias': 0.25, 'merge_gap': 3, 'min_len': 10, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "\n",
        "seeds10 = (2025,1337,42,0,123,7,11,77,314,2718)\n",
        "\n",
        "def train_seed_model_v16_quick(X, y, seed:int):\n",
        "    w = make_weights_with_boundary_erosion(y, w0=0.38)\n",
        "    dtr = xgb.DMatrix(X, label=y, weight=w)\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 21,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'predictor': 'gpu_predictor',\n",
        "        'max_bin': 512,\n",
        "        'max_depth': 7,\n",
        "        'eta': 0.085,\n",
        "        'subsample': 0.85,\n",
        "        'colsample_bytree': 0.85,\n",
        "        'min_child_weight': 4.0,\n",
        "        'lambda': 1.0,\n",
        "        'seed': int(seed)\n",
        "    }\n",
        "    print(f\"[XGB-V16][Seed {seed}] Training...\", flush=True)\n",
        "    t0 = time.time()\n",
        "    bst = xgb.train(params, dtr, num_boost_round=1100, verbose_eval=200)\n",
        "    print(f\"[XGB-V16][Seed {seed}] Done in {time.time()-t0:.1f}s\", flush=True)\n",
        "    return bst\n",
        "\n",
        "def infer_test_avg_probs_v16(models):\n",
        "    ensure_test_cache_v16()\n",
        "    rows = []\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    t0 = time.time()\n",
        "    avg_probs = {}  # sid -> np.ndarray (T,C)\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(CACHE_DIR_V16, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0).astype(np.float32)\n",
        "        avg_probs[sid] = P\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[TEST-V16-Probs] {i}/{len(test_ids)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    return avg_probs\n",
        "\n",
        "def decode_probs_to_csv(avg_probs: dict, dp_params: dict, out_csv: str):\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_df['Id'].tolist(), 1):\n",
        "        P = avg_probs[sid]\n",
        "        seq = decode_full_pipeline(P, dp_params, T=dp_params.get('T',1.0), smooth_win=dp_params.get('smooth_win',1), alpha_fill=1.5)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[Decode] {i}/{len(avg_probs)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print(f\"[SUBMISSION] Wrote {out_csv} with {len(rows)} rows.\")\n",
        "    return out_csv\n",
        "\n",
        "# Load TRAIN v1.6 cache and train 10 seeds\n",
        "X_tr, y_tr, _ = load_cached_split_v16('train')\n",
        "models = []\n",
        "for s in seeds10:\n",
        "    models.append(train_seed_model_v16_quick(X_tr, y_tr, seed=s))\n",
        "\n",
        "# Build averaged test probs once\n",
        "avgP = infer_test_avg_probs_v16(models)\n",
        "\n",
        "# Decode A: OOF-best smooth=3\n",
        "path_A = decode_probs_to_csv(avgP, params_A, out_csv='submission_A.csv')\n",
        "print('Decode A written:', path_A)\n",
        "# Decode B: hedge no-smoothing\n",
        "path_B = decode_probs_to_csv(avgP, params_B, out_csv='submission_B.csv')\n",
        "print('Decode B written:', path_B)\n",
        "# Optional C (conservative hedge) - uncomment to run if time remains\n",
        "# path_C = decode_probs_to_csv(avgP, params_C, out_csv='submission_C.csv')\n",
        "# print('Decode C written:', path_C)\n",
        "\n",
        "print('[V16 x10] Done building submissions A and B from the same averaged probs.')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[V16 x10] TRAIN-only 10-seed ensemble; stride=2; decode A: OOF-best (T=1, win=3, lambda=0.6, min_len=8); decode B: hedge (T=1, win=1, lambda=0.7, min_len=9) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadCacheV16] train: X=(187296, 193) y=(187296,) files=297 elapsed=0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 2025] Done in 233.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 1337] Done in 233.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 42] Done in 234.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 0] Done in 234.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 123] Done in 235.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 7] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 7] Done in 234.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 11] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 11] Done in 234.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 77] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 77] Done in 234.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 314] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 314] Done in 234.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 2718] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V16][Seed 2718] Done in 234.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV16][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16-Probs] 10/95 done; elapsed 27.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16-Probs] 20/95 done; elapsed 54.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16-Probs] 30/95 done; elapsed 81.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16-Probs] 40/95 done; elapsed 107.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16-Probs] 50/95 done; elapsed 134.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16-Probs] 60/95 done; elapsed 161.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16-Probs] 70/95 done; elapsed 188.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16-Probs] 80/95 done; elapsed 214.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST-V16-Probs] 90/95 done; elapsed 239.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 40/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 70/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 90/95 done; elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_A.csv with 95 rows.\nDecode A written: submission_A.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 40/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 70/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 90/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_B.csv with 95 rows.\nDecode B written: submission_B.csv\n[V16 x10] Done building submissions A and B from the same averaged probs.\n"
          ]
        }
      ]
    },
    {
      "id": "7606e480-90d8-4cfc-b829-70f2d49914ef",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 51b) Replace submission.csv with 10-seed v1.6 hedge decode (B: no-smoothing)\n",
        "import shutil, os\n",
        "src = 'submission_B.csv'; dst = 'submission.csv'\n",
        "assert os.path.exists(src), f\"Missing {src}; run cell 52 first\"\n",
        "shutil.copyfile(src, dst)\n",
        "print(f'[Swap] {dst} <- {src} ({os.path.getsize(dst)} bytes)')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Swap] submission.csv <- submission_B.csv (5237 bytes)\n"
          ]
        }
      ]
    },
    {
      "id": "f962bc99-f0b0-4c91-a573-82b49c54a913",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 51c) Replace submission.csv with 10-seed v1.6 decode A (OOF-best smooth=3)\n",
        "import shutil, os\n",
        "src = 'submission_A.csv'; dst = 'submission.csv'\n",
        "assert os.path.exists(src), f\"Missing {src}; run cell 52 first\"\n",
        "shutil.copyfile(src, dst)\n",
        "print(f'[Swap] {dst} <- {src} ({os.path.getsize(dst)} bytes)')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Swap] submission.csv <- submission_A.csv (5237 bytes)\n"
          ]
        }
      ]
    },
    {
      "id": "07bbe2a2-232a-4f6c-aebe-9f5e47e7129c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 51d) Decode C: conservative no-smoothing hedge from existing avg_probs (no retrain)\n",
        "import os, pandas as pd, numpy as np\n",
        "print('[V16 x10 Decode C] Using existing averaged test probs in memory (avgP) ...', flush=True)\n",
        "assert 'avgP' in globals(), 'avgP not found in memory; run cell 52 first to build 10-seed avg probs.'\n",
        "params_C = {'T': 1.0, 'smooth_win': 1, 'lambda': 0.8, 'bg_bias': 0.25, 'merge_gap': 3, 'min_len': 10, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "path_C = decode_probs_to_csv(avgP, params_C, out_csv='submission_C.csv')\n",
        "print('Decode C written:', path_C)\n",
        "import shutil\n",
        "shutil.copyfile('submission_C.csv', 'submission.csv')\n",
        "print('[Swap] submission.csv <- submission_C.csv (', os.path.getsize('submission.csv'), 'bytes)')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[V16 x10 Decode C] Using existing averaged test probs in memory (avgP) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 40/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 70/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 90/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_C.csv with 95 rows.\nDecode C written: submission_C.csv\n[Swap] submission.csv <- submission_C.csv ( 5237 bytes)\n"
          ]
        }
      ]
    },
    {
      "id": "b8e1080b-94c4-40cd-b486-bb68c7c0a00b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 52) v1.5 + v1.6 blend (weights v16=0.7, v15=0.3): reuse in-memory avgP (v1.6), build v1.5 5-seed avg probs, then dual decodes\n",
        "import os, time, numpy as np, pandas as pd, xgboost as xgb\n",
        "print('[Blend v15+v16] Start: weights v16=0.7, v15=0.3; TRAIN-only; stride=2', flush=True)\n",
        "\n",
        "assert 'avgP' in globals(), 'avgP (v1.6 avg probs) not found; rerun cell 52 to build 10-seed v1.6 probs first.'\n",
        "w16, w15 = 0.7, 0.3\n",
        "params_A = {'T': 1.0, 'smooth_win': 3, 'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 8, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "params_B = {'T': 1.0, 'smooth_win': 1, 'lambda': 0.7, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 9, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "\n",
        "def train_seed_model_v15_quick(X, y, seed:int):\n",
        "    w = make_weights_with_boundary_erosion(y, w0=0.38)\n",
        "    dtr = xgb.DMatrix(X, label=y, weight=w)\n",
        "    params = {\n",
        "        'objective': 'multi:softprob',\n",
        "        'num_class': 21,\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'predictor': 'gpu_predictor',\n",
        "        'max_bin': 512,\n",
        "        'max_depth': 7,\n",
        "        'eta': 0.085,\n",
        "        'subsample': 0.85,\n",
        "        'colsample_bytree': 0.85,\n",
        "        'min_child_weight': 4.0,\n",
        "        'lambda': 1.0,\n",
        "        'seed': int(seed)\n",
        "    }\n",
        "    print(f\"[XGB-V15][Seed {seed}] Training...\", flush=True)\n",
        "    t0 = time.time()\n",
        "    bst = xgb.train(params, dtr, num_boost_round=1100, verbose_eval=200)\n",
        "    print(f\"[XGB-V15][Seed {seed}] Done in {time.time()-t0:.1f}s\", flush=True)\n",
        "    return bst\n",
        "\n",
        "def infer_test_avg_probs(cache_dir, models):\n",
        "    test_ids = test_df['Id'].tolist()\n",
        "    avg_probs = {}; t0 = time.time()\n",
        "    for i, sid in enumerate(test_ids, 1):\n",
        "        d = np.load(os.path.join(cache_dir, f'test_{sid:05d}.npz'), allow_pickle=False)\n",
        "        X = d['X']; dm = xgb.DMatrix(X)\n",
        "        Ps = [m.predict(dm) for m in models]\n",
        "        P = np.mean(np.stack(Ps, axis=0), axis=0).astype(np.float32)\n",
        "        avg_probs[sid] = P\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[Infer-Probs] {i}/{len(test_ids)} from {os.path.basename(cache_dir)}; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    return avg_probs\n",
        "\n",
        "def decode_probs_to_csv(avg_probs: dict, dp_params: dict, out_csv: str):\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_df['Id'].tolist(), 1):\n",
        "        P = avg_probs[sid]\n",
        "        seq = decode_full_pipeline(P, dp_params, T=dp_params.get('T',1.0), smooth_win=dp_params.get('smooth_win',1), alpha_fill=1.5)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[Decode] {i}/{len(avg_probs)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print(f\"[SUBMISSION] Wrote {out_csv} with {len(rows)} rows.\")\n",
        "    return out_csv\n",
        "\n",
        "# Build v1.5 5-seed avg probs\n",
        "print('[Blend] Building v1.5 avg probs (5 seeds)...', flush=True)\n",
        "X15_tr, y15_tr, _ = load_frames_from_cache_v15('train')\n",
        "models15 = []\n",
        "for s in (2025,1337,42,0,123):\n",
        "    models15.append(train_seed_model_v15_quick(X15_tr, y15_tr, seed=s))\n",
        "ensure_test_cache_v15()\n",
        "avgP15 = infer_test_avg_probs(CACHE_DIR_V15, models15)\n",
        "\n",
        "# Blend per-frame probs: Pblend = 0.7*P16 + 0.3*P15 (align lengths by interpolation if needed)\n",
        "def interp_probs(P: np.ndarray, N: int) -> np.ndarray:\n",
        "    T, C = P.shape\n",
        "    if T == N: return P.astype(np.float32)\n",
        "    x_old = np.linspace(0.0, 1.0, T, dtype=np.float32)\n",
        "    x_new = np.linspace(0.0, 1.0, N, dtype=np.float32)\n",
        "    out = np.empty((N, C), dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        out[:, c] = np.interp(x_new, x_old, P[:, c].astype(np.float32))\n",
        "    s = out.sum(axis=1, keepdims=True) + 1e-9\n",
        "    out /= s\n",
        "    return out\n",
        "\n",
        "avg_blend = {}\n",
        "t0 = time.time()\n",
        "for i, sid in enumerate(test_df['Id'].tolist(), 1):\n",
        "    P16 = avgP[sid]\n",
        "    P15 = avgP15[sid]\n",
        "    N = max(P16.shape[0], P15.shape[0])\n",
        "    P16i = interp_probs(P16, N)\n",
        "    P15i = interp_probs(P15, N)\n",
        "    avg_blend[sid] = (w16*P16i + w15*P15i).astype(np.float32)\n",
        "    if i % 10 == 0:\n",
        "        print(f\"[Blend] {i}/{len(avgP15)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "# Decode A: smooth_win=3 OOF-best style\n",
        "path_A = decode_probs_to_csv(avg_blend, params_A, out_csv='submission_blend_A.csv')\n",
        "print('Decode A written:', path_A)\n",
        "# Decode B: hedge no-smoothing\n",
        "path_B = decode_probs_to_csv(avg_blend, params_B, out_csv='submission_blend_B.csv')\n",
        "print('Decode B written:', path_B)\n",
        "\n",
        "# Default: swap A to submission.csv\n",
        "import shutil\n",
        "shutil.copyfile('submission_blend_A.csv', 'submission.csv')\n",
        "print('[Swap] submission.csv <- submission_blend_A.csv ({} bytes)'.format(os.path.getsize('submission.csv')))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend v15+v16] Start: weights v16=0.7, v15=0.3; TRAIN-only; stride=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend] Building v1.5 avg probs (5 seeds)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 20/297 files, cum frames=12055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 40/297 files, cum frames=24945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 60/297 files, cum frames=40473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 80/297 files, cum frames=54817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 100/297 files, cum frames=67157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 120/297 files, cum frames=79505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 140/297 files, cum frames=91948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 160/297 files, cum frames=103759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 180/297 files, cum frames=115730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 200/297 files, cum frames=127913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 220/297 files, cum frames=140129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 240/297 files, cum frames=152334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 260/297 files, cum frames=164808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: 280/297 files, cum frames=177261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LoadV15] train: X=(187296, 120) y=(187296,) files=297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 2025] Done in 165.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 1337] Done in 165.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 42] Done in 165.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 0] Done in 166.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGB-V15][Seed 123] Done in 165.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CacheV15][TEST] All test cached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-Probs] 10/95 from cache_v15; elapsed 13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-Probs] 20/95 from cache_v15; elapsed 26.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-Probs] 30/95 from cache_v15; elapsed 39.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-Probs] 40/95 from cache_v15; elapsed 52.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-Probs] 50/95 from cache_v15; elapsed 65.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-Probs] 60/95 from cache_v15; elapsed 79.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-Probs] 70/95 from cache_v15; elapsed 92.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-Probs] 80/95 from cache_v15; elapsed 105.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Infer-Probs] 90/95 from cache_v15; elapsed 117.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend] 10/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend] 20/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend] 30/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend] 40/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend] 50/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend] 60/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend] 70/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend] 80/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Blend] 90/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 40/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 70/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 90/95 done; elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_blend_A.csv with 95 rows.\nDecode A written: submission_blend_A.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 40/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 70/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode] 90/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_blend_B.csv with 95 rows.\nDecode B written: submission_blend_B.csv\n[Swap] submission.csv <- submission_blend_A.csv (5237 bytes)\n"
          ]
        }
      ]
    },
    {
      "id": "0e1071c8-0da5-4d53-9a2c-9459c11fd8af",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 53) Fast blends without retraining: reuse in-memory avgP (v1.6, 10-seed) and avgP15 (v1.5, 5-seed)\n",
        "import os, time, numpy as np, pandas as pd\n",
        "print('[FastBlends] Reusing in-memory avgP (v1.6) and avgP15 (v1.5) to write multiple blended submissions...', flush=True)\n",
        "assert 'avgP' in globals(), 'avgP not found (v1.6 avg probs). Re-run cell 52 (10-seed v1.6) if needed.'\n",
        "assert 'avgP15' in globals(), 'avgP15 not found (v1.5 avg probs). Re-run cell 56 (v1.5 5-seed build) if needed.'\n",
        "\n",
        "def interp_probs(P: np.ndarray, N: int) -> np.ndarray:\n",
        "    T, C = P.shape\n",
        "    if T == N: return P.astype(np.float32)\n",
        "    x_old = np.linspace(0.0, 1.0, T, dtype=np.float32)\n",
        "    x_new = np.linspace(0.0, 1.0, N, dtype=np.float32)\n",
        "    out = np.empty((N, C), dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        out[:, c] = np.interp(x_new, x_old, P[:, c].astype(np.float32))\n",
        "    s = out.sum(axis=1, keepdims=True) + 1e-9\n",
        "    out /= s\n",
        "    return out\n",
        "\n",
        "def decode_probs_to_csv(avg_probs: dict, dp_params: dict, out_csv: str):\n",
        "    rows = []; t0 = time.time()\n",
        "    for i, sid in enumerate(test_df['Id'].tolist(), 1):\n",
        "        P = avg_probs[sid]\n",
        "        seq = decode_full_pipeline(P, dp_params, T=dp_params.get('T',1.0), smooth_win=dp_params.get('smooth_win',1), alpha_fill=1.5)\n",
        "        rows.append({'Id': sid, 'Sequence': ' '.join(str(int(x)) for x in seq)})\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[Decode-Blends] {i}/{len(avg_probs)} done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    sub = pd.DataFrame(rows, columns=['Id','Sequence'])\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print(f\"[SUBMISSION] Wrote {out_csv} with {len(rows)} rows.\")\n",
        "    return out_csv\n",
        "\n",
        "# Param sets\n",
        "params_A = {'T': 1.0, 'smooth_win': 3, 'lambda': 0.6, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 8, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "params_B = {'T': 1.0, 'smooth_win': 1, 'lambda': 0.7, 'bg_bias': 0.2, 'merge_gap': 3, 'min_len': 9, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "params_C = {'T': 1.0, 'smooth_win': 1, 'lambda': 0.8, 'bg_bias': 0.25, 'merge_gap': 3, 'min_len': 10, 'mean_thr': 0.5, 'max_thr': 0.65}\n",
        "\n",
        "weights = [0.8, 0.7, 0.6]  # w16; w15 = 1 - w16\n",
        "for w16 in weights:\n",
        "    w15 = 1.0 - w16\n",
        "    print(f'[FastBlends] Building blended probs for w16={w16:.1f}, w15={w15:.1f} ...', flush=True)\n",
        "    avg_blend = {}\n",
        "    t0 = time.time()\n",
        "    for i, sid in enumerate(test_df['Id'].tolist(), 1):\n",
        "        P16 = avgP[sid]; P15 = avgP15[sid]\n",
        "        N = max(P16.shape[0], P15.shape[0])\n",
        "        P16i = interp_probs(P16, N)\n",
        "        P15i = interp_probs(P15, N)\n",
        "        avg_blend[sid] = (w16*P16i + w15*P15i).astype(np.float32)\n",
        "        if i % 10 == 0:\n",
        "            print(f\"  [Blend-{w16:.1f}] {i}/95 done; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    # Decode three variants for this weight\n",
        "    outA = decode_probs_to_csv(avg_blend, params_A, out_csv=f'submission_blend_w{int(w16*10)}_A.csv')\n",
        "    outB = decode_probs_to_csv(avg_blend, params_B, out_csv=f'submission_blend_w{int(w16*10)}_B.csv')\n",
        "    outC = decode_probs_to_csv(avg_blend, params_C, out_csv=f'submission_blend_w{int(w16*10)}_C.csv')\n",
        "    print('[FastBlends] Wrote:', outA, outB, outC)\n",
        "\n",
        "# Default: copy one candidate (w16=0.8, A) to submission.csv for immediate try; can swap later\n",
        "import shutil\n",
        "src_default = 'submission_blend_w8_A.csv'\n",
        "if os.path.exists(src_default):\n",
        "    shutil.copyfile(src_default, 'submission.csv')\n",
        "    print(f'[Swap] submission.csv <- {src_default} ({os.path.getsize(\"submission.csv\")} bytes)')\n",
        "else:\n",
        "    print('[FastBlends] Default file not found; please pick a specific output to copy into submission.csv.')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FastBlends] Reusing in-memory avgP (v1.6) and avgP15 (v1.5) to write multiple blended submissions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FastBlends] Building blended probs for w16=0.8, w15=0.2 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.8] 10/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.8] 20/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.8] 30/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.8] 40/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.8] 50/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.8] 60/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.8] 70/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.8] 80/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.8] 90/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 40/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 70/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 90/95 done; elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_blend_w8_A.csv with 95 rows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 40/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 70/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 90/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_blend_w8_B.csv with 95 rows.\n[Decode-Blends] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 40/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 70/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 90/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_blend_w8_C.csv with 95 rows.\n[FastBlends] Wrote: submission_blend_w8_A.csv submission_blend_w8_B.csv submission_blend_w8_C.csv\n[FastBlends] Building blended probs for w16=0.7, w15=0.3 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.7] 10/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.7] 20/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.7] 30/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.7] 40/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.7] 50/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.7] 60/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.7] 70/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.7] 80/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.7] 90/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 40/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 70/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 90/95 done; elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_blend_w7_A.csv with 95 rows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 40/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 70/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 90/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_blend_w7_B.csv with 95 rows.\n[Decode-Blends] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 40/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 70/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 90/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_blend_w7_C.csv with 95 rows.\n[FastBlends] Wrote: submission_blend_w7_A.csv submission_blend_w7_B.csv submission_blend_w7_C.csv\n[FastBlends] Building blended probs for w16=0.6, w15=0.4 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.6] 10/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.6] 20/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.6] 30/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.6] 40/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.6] 50/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.6] 60/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.6] 70/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.6] 80/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Blend-0.6] 90/95 done; elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 40/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 70/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 90/95 done; elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_blend_w6_A.csv with 95 rows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 40/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 70/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 80/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 90/95 done; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SUBMISSION] Wrote submission_blend_w6_B.csv with 95 rows.\n[Decode-Blends] 10/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 20/95 done; elapsed 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 30/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 40/95 done; elapsed 0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 50/95 done; elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 60/95 done; elapsed 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Decode-Blends] 70/95 done; elapsed 0.4s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}