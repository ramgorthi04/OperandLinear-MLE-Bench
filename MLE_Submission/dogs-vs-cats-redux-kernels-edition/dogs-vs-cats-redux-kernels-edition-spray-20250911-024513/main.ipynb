{
  "cells": [
    {
      "id": "d360adbd-8ba6-4364-95a6-a9ecbf2c30c1",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan to Medal: Dogs vs. Cats Redux (log-loss)\n",
        "\n",
        "Objectives:\n",
        "- Achieve \u2264 0.061 log-loss (bronze) quickly; iterate to \u2264 0.050 (silver) with enhancements.\n",
        "\n",
        "Approach:\n",
        "1) Setup & Data\n",
        "- Verify folders, counts, and sample_submission format.\n",
        "- Parse labels from train filenames (cat./dog.).\n",
        "- Stratified train/val split; prefer 5-fold CV for robust OOF and model selection.\n",
        "\n",
        "2) Modeling (fast baseline \u2192 strong model)\n",
        "- Baseline: Pretrained ResNet50/EfficientNet-B0 with transfer learning.\n",
        "- Loss: BCEWithLogitsLoss with label smoothing.\n",
        "- Optimizer: AdamW; Scheduler: cosine with warmup.\n",
        "- Augmentations: flips, random resize/crop, color jitter; apply normalization for ImageNet.\n",
        "- Hyperparams (baseline): img_size 224, bs ~64 (fit to GPU), epochs 5-8 for sanity.\n",
        "\n",
        "3) Improve\n",
        "- Progressive resizing (224\u2192299/320), TTA (horizontal flip, multi-crops), EMA.\n",
        "- Mixup/CutMix (light), stronger augmentations.\n",
        "- 5-fold CV ensembling; average logits across folds.\n",
        "\n",
        "4) Inference\n",
        "- TTA on test; sigmoid to probabilities; ensure correct id sorting.\n",
        "- Save submission.csv with columns: id,label.\n",
        "\n",
        "5) Efficiency & Logging\n",
        "- Print fold indices, epoch timings, and metrics.\n",
        "- Early stop if overfitting or plateau; keep runs short and iterative.\n",
        "\n",
        "6) Stretch\n",
        "- Pseudo-labeling if time permits.\n",
        "\n",
        "Next:\n",
        "- Inspect data layout, counts, and GPU; then implement baseline dataloaders + quick single-fold baseline to validate pipeline before expanding to CV."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "bdae6c9f-a3b2-4589-94d7-4ab8d753c6ff",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install required packages (CUDA 12.1 builds for PyTorch)\n",
        "import sys, subprocess, pkgutil\n",
        "\n",
        "def pip_install(pkgs, index_url=None):\n",
        "    cmd = [sys.executable, '-m', 'pip', 'install', '-q'] + pkgs\n",
        "    if index_url:\n",
        "        cmd += ['--index-url', index_url]\n",
        "    print('Running:', ' '.join(cmd));\n",
        "    subprocess.check_call(cmd)\n",
        "\n",
        "# Install PyTorch with CUDA 12.1 if not present\n",
        "if pkgutil.find_loader('torch') is None:\n",
        "    pip_install(['torch', 'torchvision', 'torchaudio'], index_url='https://download.pytorch.org/whl/cu121')\n",
        "else:\n",
        "    import torch\n",
        "    print('Torch already installed:', torch.__version__)\n",
        "\n",
        "# timm and albumentations for models/augs\n",
        "for pkg in ['timm', 'albumentations', 'opencv-python-headless']:\n",
        "    if pkgutil.find_loader(pkg) is None:\n",
        "        pip_install([pkg])\n",
        "    else:\n",
        "        print(pkg, 'already installed')\n",
        "\n",
        "print('Package installation complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "64a565ed-98bf-42ff-9f02-4cd7b6782325",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup & quick data audit\n",
        "import os, sys, random, re, time, math, json, gc\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# Ensure pip-target site-packages are importable (pip installed to /app/.pip-target)\n",
        "PIP_TARGET = os.environ.get('PIP_TARGET', '/app/.pip-target')\n",
        "if PIP_TARGET and PIP_TARGET not in sys.path:\n",
        "    sys.path.insert(0, PIP_TARGET)\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "except Exception as e:\n",
        "    torch = None\n",
        "    print('Torch import failed:', e)\n",
        "\n",
        "random.seed(42)\n",
        "os.environ['PYTHONHASHSEED'] = '42'\n",
        "\n",
        "DATA_DIR = Path('.')\n",
        "TRAIN_DIR = DATA_DIR / 'train'\n",
        "TEST_DIR = DATA_DIR / 'test'\n",
        "SAMPLE_SUB = DATA_DIR / 'sample_submission.csv'\n",
        "\n",
        "print('Paths exist:', TRAIN_DIR.exists(), TEST_DIR.exists(), SAMPLE_SUB.exists()); sys.stdout.flush()\n",
        "\n",
        "# List files\n",
        "train_files = sorted([p for p in TRAIN_DIR.glob('*.jpg')])\n",
        "test_files = sorted([p for p in TEST_DIR.glob('*.jpg')], key=lambda p: int(p.stem))\n",
        "print(f'Train files: {len(train_files):,} | Test files: {len(test_files):,}')\n",
        "\n",
        "# Parse labels from filenames: cat.* -> 0, dog.* -> 1\n",
        "def parse_label(p: Path):\n",
        "    name = p.name\n",
        "    if name.startswith('cat.'):\n",
        "        return 0\n",
        "    if name.startswith('dog.'):\n",
        "        return 1\n",
        "    raise ValueError(f'Unexpected train filename: {name}')\n",
        "\n",
        "labels = [parse_label(p) for p in train_files]\n",
        "num_cats = sum(1 for v in labels if v==0)\n",
        "num_dogs = sum(1 for v in labels if v==1)\n",
        "print(f'Class balance -> cats: {num_cats:,}, dogs: {num_dogs:,}')\n",
        "\n",
        "# Inspect sample_submission\n",
        "ss = pd.read_csv(SAMPLE_SUB)\n",
        "print('Sample submission head:')\n",
        "print(ss.head())\n",
        "print('Sample columns:', list(ss.columns))\n",
        "print('Sample len:', len(ss))\n",
        "\n",
        "# GPU / Torch info\n",
        "if torch is not None:\n",
        "    print('Torch version:', torch.__version__)\n",
        "    cuda_ok = torch.cuda.is_available()\n",
        "    print('CUDA available:', cuda_ok)\n",
        "    if cuda_ok:\n",
        "        print('Device count:', torch.cuda.device_count())\n",
        "        print('Device 0:', torch.cuda.get_device_name(0))\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "else:\n",
        "    print('Torch not available yet. Will install or fix path and retry later.')\n",
        "\n",
        "# Quick corruption check on a small sample\n",
        "def safe_open(img_path: Path):\n",
        "    try:\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert('RGB')\n",
        "            return True, im.size\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "sample_check = random.sample(train_files, k=min(20, len(train_files))) + random.sample(test_files, k=min(20, len(test_files)))\n",
        "bad = []\n",
        "sizes = []\n",
        "for p in sample_check:\n",
        "    ok, info = safe_open(p)\n",
        "    if not ok:\n",
        "        bad.append((p.name, info))\n",
        "    else:\n",
        "        sizes.append(info)\n",
        "print(f'Checked {len(sample_check)} images. Bad: {len(bad)}')\n",
        "if bad:\n",
        "    print('Examples of bad files:', bad[:5])\n",
        "if sizes:\n",
        "    # show a few size samples\n",
        "    print('Example image sizes (first 5):', sizes[:5])\n",
        "\n",
        "# Verify test id parsing and sort numerically\n",
        "test_ids = [int(p.stem) for p in test_files]\n",
        "assert test_ids == sorted(test_ids), 'Test files are not sorted numerically as expected'\n",
        "print('Test IDs numeric sort verified. First/last IDs:', test_ids[0], test_ids[-1])\n",
        "\n",
        "print('Audit complete.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "5e419e21-fbaf-4610-a21d-71f475532c25",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Single-fold baseline: EfficientNet-B0 @256 with EMA, LS, hflip TTA\n",
        "import os, math, time, random, warnings\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Ensure model weight caches are writable (avoid /app/.cache read-only)\n",
        "CACHE_ROOT = Path('./.cache')\n",
        "os.environ.setdefault('XDG_CACHE_HOME', str(CACHE_ROOT))\n",
        "os.environ.setdefault('HF_HOME', str(CACHE_ROOT / 'huggingface'))\n",
        "os.environ.setdefault('HF_HUB_CACHE', str(CACHE_ROOT / 'huggingface' / 'hub'))\n",
        "os.environ.setdefault('TORCH_HOME', str(CACHE_ROOT / 'torch'))\n",
        "os.environ.setdefault('TIMM_CACHE_DIR', str(CACHE_ROOT / 'timm'))\n",
        "for p in [CACHE_ROOT, Path(os.environ['HF_HUB_CACHE']), Path(os.environ['TORCH_HOME']), Path(os.environ['TIMM_CACHE_DIR'])]:\n",
        "    Path(p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Reproducibility\n",
        "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
        "if torch.cuda.is_available(): torch.cuda.manual_seed_all(42)\n",
        "\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 96\n",
        "EPOCHS = 3  # sanity run to validate pipeline\n",
        "LR_HEAD = 5e-4\n",
        "LR_BACKBONE = 1e-4\n",
        "WD = 0.03\n",
        "LS_EPS = 0.0  # turn off for sanity\n",
        "MIXUP_ALPHA = 0.2\n",
        "MIXUP_P = 0.0  # off for sanity\n",
        "EMA_DECAY = 0.99  # faster tracking\n",
        "NUM_WORKERS = min(8, os.cpu_count() or 2)\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "\n",
        "# Deterministic val/test transforms; train with RRC + HFlip\n",
        "train_tfms = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "eval_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=T.InterpolationMode.BILINEAR),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "class CatDogDataset(Dataset):\n",
        "    def __init__(self, files, labels=None, transform=None):\n",
        "        self.files = files\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.files[idx]\n",
        "        try:\n",
        "            with Image.open(p) as im:\n",
        "                im = im.convert('RGB')\n",
        "        except Exception:\n",
        "            im = Image.new('RGB', (IMG_SIZE, IMG_SIZE), (0,0,0))\n",
        "        img = self.transform(im) if self.transform else T.ToTensor()(im)\n",
        "        if self.labels is None:\n",
        "            return img, -1.0\n",
        "        return img, float(self.labels[idx])\n",
        "\n",
        "def make_stratified_split(files, labels, val_frac=0.2, seed=42):\n",
        "    idx = np.arange(len(files))\n",
        "    y = np.array(labels)\n",
        "    cats = idx[y==0]; dogs = idx[y==1]\n",
        "    rng = np.random.RandomState(seed)\n",
        "    rng.shuffle(cats); rng.shuffle(dogs)\n",
        "    n_val_c = int(len(cats)*val_frac); n_val_d = int(len(dogs)*val_frac)\n",
        "    val_idx = np.concatenate([cats[:n_val_c], dogs[:n_val_d]])\n",
        "    trn_idx = np.concatenate([cats[n_val_c:], dogs[n_val_d:]])\n",
        "    rng.shuffle(trn_idx); rng.shuffle(val_idx)\n",
        "    return trn_idx, val_idx\n",
        "\n",
        "def smooth_targets(y, eps=0.1):\n",
        "    return y*(1.0 - eps) + 0.5*eps\n",
        "\n",
        "def get_model():\n",
        "    model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=1, drop_rate=0.2, cache_dir=str(CACHE_ROOT))\n",
        "    return model\n",
        "\n",
        "def mixup_batch(x, y, alpha):\n",
        "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1.0\n",
        "    bs = x.size(0)\n",
        "    index = torch.randperm(bs, device=x.device)\n",
        "    x_m = lam * x + (1 - lam) * x[index]\n",
        "    y_m = lam * y + (1 - lam) * y[index]\n",
        "    return x_m, y_m\n",
        "\n",
        "# Prepare data\n",
        "train_dir = Path('train')\n",
        "test_dir = Path('test')\n",
        "train_files = sorted([p for p in train_dir.glob('*.jpg')])\n",
        "labels = [0 if p.name.startswith('cat.') else 1 for p in train_files]\n",
        "trn_idx, val_idx = make_stratified_split(train_files, labels, val_frac=0.2, seed=42)\n",
        "trn_files = [train_files[i] for i in trn_idx]\n",
        "val_files = [train_files[i] for i in val_idx]\n",
        "y_trn = [labels[i] for i in trn_idx]\n",
        "y_val = [labels[i] for i in val_idx]\n",
        "print(f'Train/Val sizes: {len(trn_files)} / {len(val_files)}');\n",
        "\n",
        "ds_trn = CatDogDataset(trn_files, y_trn, transform=train_tfms)\n",
        "ds_val = CatDogDataset(val_files, y_val, transform=eval_tfms)\n",
        "dl_trn = DataLoader(ds_trn, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True, persistent_workers=(NUM_WORKERS>0))\n",
        "dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=(NUM_WORKERS>0))\n",
        "\n",
        "# Model, optimizer, EMA, OneCycleLR\n",
        "model = get_model().to(device)\n",
        "\n",
        "# Build param groups with wd/no-wd split using names + ids\n",
        "named_params = list(model.named_parameters())\n",
        "head_ids = {id(p) for p in model.get_classifier().parameters()}\n",
        "backbone = [(n,p) for n,p in named_params if p.requires_grad and id(p) not in head_ids]\n",
        "head = [(n,p) for n,p in named_params if p.requires_grad and id(p) in head_ids]\n",
        "def no_wd(n,p):\n",
        "    return (p.ndim == 1) or n.endswith('.bias')\n",
        "pg = [\n",
        "    {'params': [p for n,p in backbone if not no_wd(n,p)], 'lr': LR_BACKBONE, 'weight_decay': WD},\n",
        "    {'params': [p for n,p in backbone if     no_wd(n,p)], 'lr': LR_BACKBONE, 'weight_decay': 0.0},\n",
        "    {'params': [p for n,p in head     if not no_wd(n,p)], 'lr': LR_HEAD,     'weight_decay': WD},\n",
        "    {'params': [p for n,p in head     if     no_wd(n,p)], 'lr': LR_HEAD,     'weight_decay': 0.0},\n",
        "]\n",
        "optimizer = torch.optim.AdamW(pg)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=device.type=='cuda')\n",
        "ema = ModelEmaV2(model, decay=EMA_DECAY)\n",
        "\n",
        "# OneCycleLR per-batch\n",
        "total_steps = EPOCHS * len(dl_trn)\n",
        "max_lrs = [group['lr'] for group in optimizer.param_groups]\n",
        "sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lrs, total_steps=total_steps, pct_start=1.0/max(1,EPOCHS), anneal_strategy='cos')\n",
        "\n",
        "def bce_logits_loss(logits, targets, eps=0.0):\n",
        "    targets = smooth_targets(targets, eps) if eps>0 else targets\n",
        "    return nn.functional.binary_cross_entropy_with_logits(logits.view(-1), targets)\n",
        "\n",
        "def sigmoid_numpy(x):\n",
        "    return 1.0/(1.0+np.exp(-x))\n",
        "\n",
        "def evaluate(model_eval, loader):\n",
        "    model_eval.eval()\n",
        "    total_loss = 0.0\n",
        "    n = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            logits = model_eval(xb)\n",
        "            loss = bce_logits_loss(logits, yb, eps=0.0)\n",
        "            total_loss += loss.item()*xb.size(0)\n",
        "            n += xb.size(0)\n",
        "    return total_loss/max(1,n)\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_state = None\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    t0 = time.time()\n",
        "    model.train()\n",
        "    running = 0.0; seen = 0\n",
        "    for i, (xb, yb) in enumerate(dl_trn):\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "        use_mix = (epoch > 0) and (random.random() < MIXUP_P)\n",
        "        if use_mix:\n",
        "            xb, yb = mixup_batch(xb, yb.unsqueeze(1), MIXUP_ALPHA)\n",
        "            yb = yb.view(-1)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=device.type=='cuda'):\n",
        "            logits = model(xb)\n",
        "            loss = bce_logits_loss(logits, yb, eps=LS_EPS)\n",
        "        if epoch == 0 and i == 0:\n",
        "            l = logits.detach()\n",
        "            print('logits stats e1b1 -> mean/std/min/max:', float(l.mean()), float(l.std()), float(l.min()), float(l.max()))\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        sched.step()\n",
        "        ema.update(model)\n",
        "        running += loss.item()*xb.size(0)\n",
        "        seen += xb.size(0)\n",
        "        if (i+1)%50==0:\n",
        "            print(f'Epoch {epoch+1}/{EPOCHS} | Step {i+1}/{len(dl_trn)} | Loss {(running/seen):.4f} | Elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "    # evaluate using the current model (not EMA) for sanity\n",
        "    val_loss = evaluate(model, dl_val)\n",
        "    print(f'Epoch {epoch+1} done in {time.time()-t0:.1f}s | Val log-loss: {val_loss:.5f}')\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        best_state = { 'model': model.state_dict() }\n",
        "print(f'Training finished in {(time.time()-start_time)/60:.1f} min. Best val log-loss: {best_loss:.5f}')\n",
        "\n",
        "# Inference on test with hflip TTA; average logits then sigmoid\n",
        "test_files = sorted([p for p in test_dir.glob('*.jpg')], key=lambda p: int(p.stem))\n",
        "ds_test = CatDogDataset(test_files, labels=None, transform=eval_tfms)\n",
        "dl_test = DataLoader(ds_test, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=(NUM_WORKERS>0))\n",
        "model = get_model().to(device)\n",
        "model.load_state_dict(best_state['model'], strict=True)\n",
        "model.eval()\n",
        "probs = []\n",
        "with torch.no_grad():\n",
        "    for xb, _ in dl_test:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        logits1 = model(xb)\n",
        "        xb_flip = torch.flip(xb, dims=[3])\n",
        "        logits2 = model(xb_flip)\n",
        "        logits = 0.5*(logits1.view(-1) + logits2.view(-1))\n",
        "        probs.append(sigmoid_numpy(logits.detach().cpu().numpy()))\n",
        "probs = np.concatenate(probs)\n",
        "probs = np.clip(probs, 1e-5, 1-1e-5)\n",
        "sub = pd.DataFrame({'id': [int(p.stem) for p in test_files], 'label': probs})\n",
        "sub = sub.sort_values('id')\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv. Head:')\n",
        "print(sub.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Val sizes: 18001 / 4499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits stats e1b1 -> mean/std/min/max: 3.96484375 6.484375 -10.75 19.40625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 | Step 50/187 | Loss 2.4171 | Elapsed 15.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 | Step 100/187 | Loss 1.4484 | Elapsed 29.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 | Step 150/187 | Loss 1.0406 | Elapsed 44.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 done in 63.2s | Val log-loss: 0.10856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 | Step 50/187 | Loss 0.0745 | Elapsed 15.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 | Step 100/187 | Loss 0.0709 | Elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3 | Step 150/187 | Loss 0.0705 | Elapsed 43.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 done in 61.9s | Val log-loss: 0.08079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 | Step 50/187 | Loss 0.0237 | Elapsed 15.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 | Step 100/187 | Loss 0.0219 | Elapsed 29.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3 | Step 150/187 | Loss 0.0239 | Elapsed 44.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 done in 62.4s | Val log-loss: 0.07866\nTraining finished in 3.1 min. Best val log-loss: 0.07866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv. Head:\n   id     label\n0   1  0.999990\n1   2  0.000010\n2   3  0.999990\n3   4  0.003428\n4   5  0.000013\n"
          ]
        }
      ]
    },
    {
      "id": "a93c3019-6198-49cb-bebd-0036927bb27f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Debug: small overfit test on 200 images (no aug, no LS, no Mixup, no EMA)\n",
        "import random, gc, torch, numpy as np\n",
        "from pathlib import Path\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "random.seed(123); np.random.seed(123); torch.manual_seed(123);\n",
        "if torch.cuda.is_available(): torch.cuda.manual_seed_all(123)\n",
        "\n",
        "IMG_SIZE = 256\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "LR_HEAD = 1e-3\n",
        "LR_BACKBONE = 1e-4\n",
        "WD = 0.0\n",
        "\n",
        "simple_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=T.InterpolationMode.BILINEAR),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "class SimpleDS(Dataset):\n",
        "    def __init__(self, files, labels, tfm):\n",
        "        self.files, self.labels, self.tfm = files, labels, tfm\n",
        "    def __len__(self): return len(self.files)\n",
        "    def __getitem__(self, i):\n",
        "        p = self.files[i]\n",
        "        try:\n",
        "            with Image.open(p) as im:\n",
        "                im = im.convert('RGB')\n",
        "        except:\n",
        "            im = Image.new('RGB', (IMG_SIZE, IMG_SIZE), (0,0,0))\n",
        "        x = self.tfm(im)\n",
        "        y = float(self.labels[i])\n",
        "        return x, y\n",
        "\n",
        "# Build small balanced subset of 200 (100 cats, 100 dogs)\n",
        "all_files = sorted(list(Path('train').glob('*.jpg')))\n",
        "labels_all = [0 if p.name.startswith('cat.') else 1 for p in all_files]\n",
        "idx_c = [i for i,l in enumerate(labels_all) if l==0][:100]\n",
        "idx_d = [i for i,l in enumerate(labels_all) if l==1][:100]\n",
        "idx_small = idx_c + idx_d\n",
        "random.shuffle(idx_small)\n",
        "files_small = [all_files[i] for i in idx_small]\n",
        "labels_small = [labels_all[i] for i in idx_small]\n",
        "\n",
        "# Split 160 train / 40 val\n",
        "trn_idx = list(range(160)); val_idx = list(range(160,200))\n",
        "trn_files = [files_small[i] for i in trn_idx]\n",
        "val_files = [files_small[i] for i in val_idx]\n",
        "y_trn = [labels_small[i] for i in trn_idx]\n",
        "y_val = [labels_small[i] for i in val_idx]\n",
        "print('Debug subset sizes:', len(trn_files), len(val_files))\n",
        "\n",
        "ds_trn = SimpleDS(trn_files, y_trn, simple_tfms)\n",
        "ds_val = SimpleDS(val_files, y_val, simple_tfms)\n",
        "dl_trn = DataLoader(ds_trn, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n",
        "dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "def get_model():\n",
        "    return timm.create_model('efficientnet_b0', pretrained=True, num_classes=1, drop_rate=0.0)\n",
        "\n",
        "model = get_model().to(device)\n",
        "# Param groups: head vs backbone (no wd split to keep simple here)\n",
        "head_ids = {id(p) for p in model.get_classifier().parameters()}\n",
        "backbone_params = [p for p in model.parameters() if p.requires_grad and id(p) not in head_ids]\n",
        "head_params = [p for p in model.parameters() if p.requires_grad and id(p) in head_ids]\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': backbone_params, 'lr': LR_BACKBONE, 'weight_decay': WD},\n",
        "    {'params': head_params,     'lr': LR_HEAD,     'weight_decay': WD},\n",
        "])\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=device.type=='cuda')\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def eval_loss(m, dl):\n",
        "    m.eval(); tot=0; n=0\n",
        "    with torch.no_grad():\n",
        "        for xb,yb in dl:\n",
        "            xb=xb.to(device); yb=yb.to(device)\n",
        "            logits = m(xb).view(-1)\n",
        "            loss = loss_fn(logits, yb)\n",
        "            tot += loss.item()*xb.size(0); n+=xb.size(0)\n",
        "    return tot/max(1,n)\n",
        "\n",
        "best_val=float('inf')\n",
        "for ep in range(EPOCHS):\n",
        "    model.train(); run=0; seen=0\n",
        "    for xb,yb in dl_trn:\n",
        "        xb=xb.to(device); yb=yb.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=device.type=='cuda'):\n",
        "            logits = model(xb).view(-1)\n",
        "            loss = loss_fn(logits, yb)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer); scaler.update()\n",
        "        run += loss.item()*xb.size(0); seen += xb.size(0)\n",
        "    trn_loss = run/seen\n",
        "    val_loss = eval_loss(model, dl_val)\n",
        "    print(f'[Overfit] Epoch {ep+1}/{EPOCHS} | train {trn_loss:.4f} | val {val_loss:.4f}')\n",
        "    best_val=min(best_val,val_loss)\n",
        "print('Overfit debug best val:', best_val)\n",
        "gc.collect();\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Debug subset sizes: 160 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overfit] Epoch 1/5 | train 1.3989 | val 0.9735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overfit] Epoch 2/5 | train 0.3547 | val 0.3880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overfit] Epoch 3/5 | train 0.0396 | val 0.2940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overfit] Epoch 4/5 | train 0.0056 | val 0.3071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Overfit] Epoch 5/5 | train 0.0070 | val 0.3122\nOverfit debug best val: 0.29400813585774976\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}