{
  "cells": [
    {
      "id": "d008fcb5-ce6e-4b75-b2d7-a45462f510ad",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dogs vs. Cats Redux: Plan & Experiment Log\n",
        "\n",
        "Objective: Achieve a medal (log-loss \u2264 0.061) using strong transfer learning with efficient training and robust validation.\n",
        "\n",
        "Performance targets:\n",
        "- Gold \u2264 0.0388\n",
        "- Silver \u2264 0.0504\n",
        "- Bronze \u2264 0.0613\n",
        "\n",
        "High-level plan:\n",
        "1. Sanity-check data and environment; create training dataframe from filenames.\n",
        "2. Baseline model: pretrained ImageNet CNN (timm EfficientNet-B0/ResNet50d), 5-fold Stratified KFold, 224\u2013320px, BCEWithLogitsLoss, label smoothing, MixUp/CutMix off initially, simple aug.\n",
        "3. Optimize: image size 320, strong augs (HorizontalFlip, RandomResizedCrop), cosine schedule, EMA, AMP.\n",
        "4. Ensembling: optionally 2 backbones (EffNet + ResNet) or TTA at inference.\n",
        "5. Generate submission.csv; iterate to reduce log-loss.\n",
        "\n",
        "Experiment Log:\n",
        "- [T0] Setup, data inspection.\n",
        "- [T1] Create dataset + 5-fold CV split.\n",
        "- [T2] Train baseline model (EffNet-B0, 224, 3\u20135 epochs).\n",
        "- [T3] Evaluate CV log-loss; submit if \u2264 0.06. If not, increase size/epochs/backbone.\n",
        "- [T4] TTA / second model blend.\n",
        "\n",
        "We will request expert reviews at major milestones (plan, after data prep/EDA, after baseline training, and if score underperforms)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "bd9ee060-86e2-4bb6-a953-ff4e634e4a38",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup: installs, environment check, data discovery, and CV split\n",
        "import os, sys, subprocess, json, math, random, time, gc, re, glob, shutil\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def pip_install(pkgs):\n",
        "    print(\"Installing:\", pkgs, flush=True)\n",
        "    cmd = [sys.executable, '-m', 'pip', 'install', '--quiet'] + pkgs\n",
        "    res = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if res.returncode != 0:\n",
        "        print(res.stdout)\n",
        "        raise RuntimeError(\"pip install failed\")\n",
        "    else:\n",
        "        print(res.stdout[-1000:])\n",
        "\n",
        "# Install required packages if missing\n",
        "required = ['torch', 'torchvision', 'timm', 'albumentations', 'opencv-python']\n",
        "to_install = []\n",
        "import importlib\n",
        "for pkg in required:\n",
        "    try:\n",
        "        importlib.import_module(pkg if pkg != 'opencv-python' else 'cv2')\n",
        "    except Exception:\n",
        "        to_install.append(pkg)\n",
        "if to_install:\n",
        "    pip_install(to_install)\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "print(f\"Torch: {torch.__version__}, Torchvision: {torchvision.__version__}\")\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# Paths\n",
        "CWD = Path.cwd()\n",
        "TRAIN_DIR = CWD / 'train'\n",
        "TEST_DIR = CWD / 'test'\n",
        "assert TRAIN_DIR.exists() and TEST_DIR.exists(), \"Train/Test directories not found\"\n",
        "\n",
        "# List few files\n",
        "train_files = sorted(glob.glob(str(TRAIN_DIR / '*.jpg')))[:5]\n",
        "test_files = sorted(glob.glob(str(TEST_DIR / '*.jpg')))[:5]\n",
        "print(\"Sample train files:\", train_files)\n",
        "print(\"Sample test files:\", test_files)\n",
        "\n",
        "# Build training dataframe\n",
        "def parse_label_from_filename(fp):\n",
        "    name = Path(fp).name\n",
        "    # filenames like 'cat.123.jpg' or 'dog.456.jpg'\n",
        "    if name.startswith('cat.'):\n",
        "        return 0\n",
        "    elif name.startswith('dog.'):\n",
        "        return 1\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown label in filename: {name}\")\n",
        "\n",
        "train_paths = sorted(glob.glob(str(TRAIN_DIR / '*.jpg')))\n",
        "test_paths = sorted(glob.glob(str(TEST_DIR / '*.jpg')), key=lambda p: int(Path(p).stem))\n",
        "train_labels = [parse_label_from_filename(p) for p in train_paths]\n",
        "df = pd.DataFrame({\n",
        "    'filepath': train_paths,\n",
        "    'label': train_labels\n",
        "})\n",
        "print(\"Train samples:\", len(df), \"Pos (dog):\", df['label'].sum(), \"Neg (cat):\", (1-df['label']).sum())\n",
        "\n",
        "# Create stratified KFold splits\n",
        "N_FOLDS = 5\n",
        "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "df['fold'] = -1\n",
        "for fold, (_, val_idx) in enumerate(skf.split(df['filepath'], df['label'])):\n",
        "    df.loc[val_idx, 'fold'] = fold\n",
        "\n",
        "assert (df['fold'] >= 0).all()\n",
        "df.to_csv('train_folds.csv', index=False)\n",
        "pd.DataFrame({'filepath': test_paths}).to_csv('test_files.csv', index=False)\n",
        "print(df['fold'].value_counts().sort_index())\n",
        "print(\"Saved train_folds.csv and test_files.csv\")\n",
        "\n",
        "# Log\n",
        "print(\"[T0] Data prepared and CV split created.\", flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c65b60b5-e9a6-40dd-ba7f-32b7276f3fcf",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training pipeline: EfficientNet-B0 baseline, 3-fold, AMP, TTA(hflip), submission.csv (cv2-free, local cache)\n",
        "import os, time, math, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from sklearn.metrics import log_loss\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure writable cache directory for pretrained weights (avoid read-only /app/.cache)\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'\n",
        "LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "FOLDS_TO_RUN = [0,1,2]  # fast baseline\n",
        "LABEL_SMOOTH = 0.05\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-2\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "df = pd.read_csv('train_folds.csv')\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "\n",
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, df, aug):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['label'].values if 'label' in df.columns else None\n",
        "        self.aug = aug\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        if self.aug is not None:\n",
        "            img = self.aug(img)\n",
        "        if self.labels is None:\n",
        "            return img, Path(fp).stem  # id for test\n",
        "        label = np.float32(self.labels[idx])\n",
        "        return img, label\n",
        "\n",
        "train_aug = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0), ratio=(0.75, 1.3333)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "valid_aug = T.Compose([\n",
        "    T.Resize(IMG_SIZE),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "def build_model():\n",
        "    model = timm.create_model('efficientnet_b0', pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE))\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_loader(model, loader):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    for imgs, _ in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            logits = model(imgs).squeeze(1)\n",
        "            probs = torch.sigmoid(logits).float().cpu().numpy()\n",
        "        preds.append(probs)\n",
        "    return np.concatenate(preds)\n",
        "\n",
        "def train_fold(fold):\n",
        "    print(f\"\\n===== Fold {fold} =====\", flush=True)\n",
        "    trn_df = df[df.fold != fold].reset_index(drop=True)\n",
        "    val_df = df[df.fold == fold].reset_index(drop=True)\n",
        "    trn_ds = DogCatDataset(trn_df, train_aug)\n",
        "    val_ds = DogCatDataset(val_df, valid_aug)\n",
        "    trn_loader = DataLoader(trn_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "    best_ll = 1e9\n",
        "    best_path = f'model_fold{fold}.pt'\n",
        "    start = time.time()\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        n_samples = 0\n",
        "        t0 = time.time()\n",
        "        for step, (imgs, labels) in enumerate(trn_loader):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            targets = labels * (1.0 - LABEL_SMOOTH) + (1.0 - labels) * LABEL_SMOOTH\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "                logits = model(imgs).squeeze(1)\n",
        "                loss_vec = criterion(logits, targets)\n",
        "                loss = loss_vec.mean()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            running_loss += loss.item() * imgs.size(0)\n",
        "            n_samples += imgs.size(0)\n",
        "            if (step+1) % 50 == 0:\n",
        "                elapsed = time.time()-t0\n",
        "                print(f\"Fold {fold} Epoch {epoch} Step {step+1}/{len(trn_loader)} Loss {running_loss/n_samples:.4f} Elapsed {elapsed:.1f}s\", flush=True)\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_probs = []\n",
        "        val_targets = []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs = imgs.to(device)\n",
        "                with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "                    logits = model(imgs).squeeze(1)\n",
        "                    probs = torch.sigmoid(logits)\n",
        "                val_probs.append(probs.float().cpu().numpy())\n",
        "                val_targets.append(labels.numpy())\n",
        "        val_probs = np.concatenate(val_probs)\n",
        "        val_targets = np.concatenate(val_targets)\n",
        "        ll = log_loss(val_targets, np.clip(val_probs, 1e-6, 1-1e-6))\n",
        "        print(f\"Epoch {epoch}: train_loss={running_loss/max(1,n_samples):.4f} val_logloss={ll:.5f} epoch_time={time.time()-t0:.1f}s total_elapsed={time.time()-start:.1f}s\", flush=True)\n",
        "        if ll < best_ll:\n",
        "            best_ll = ll\n",
        "            torch.save({'state_dict': model.state_dict(), 'val_logloss': best_ll}, best_path)\n",
        "            print(f\"  Saved best model to {best_path} (val_logloss={best_ll:.5f})\", flush=True)\n",
        "    # Load best\n",
        "    ckpt = torch.load(best_path, map_location='cpu')\n",
        "    model.load_state_dict(ckpt['state_dict'])\n",
        "    model = model.to(device)\n",
        "    # OOF predictions\n",
        "    val_probs = predict_loader(model, val_loader)\n",
        "    return best_ll, val_df.index.values, val_probs, model\n",
        "\n",
        "# Run folds\n",
        "oof = np.zeros(len(df), dtype=np.float32)\n",
        "fold_scores = {}\n",
        "models = {}\n",
        "total_start = time.time()\n",
        "for fold in FOLDS_TO_RUN:\n",
        "    best_ll, val_idx, val_probs, model = train_fold(fold)\n",
        "    oof[val_idx] = val_probs\n",
        "    fold_scores[fold] = best_ll\n",
        "    models[fold] = model  # keep in memory for fast test pred\n",
        "    print(f\"Fold {fold} best val_logloss: {best_ll:.5f}\", flush=True)\n",
        "print(\"Fold scores:\", fold_scores, flush=True)\n",
        "oof_ll = log_loss(df['label'].values, np.clip(oof, 1e-6, 1-1e-6))\n",
        "print(f\"OOF log-loss (partial folds): {oof_ll:.5f}\")\n",
        "\n",
        "# Test inference with TTA (original + hflip)\n",
        "test_ds = DogCatDataset(test_df, valid_aug)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_tta(models_dict, loader):\n",
        "    # average across folds and TTA\n",
        "    all_probs = []\n",
        "    for imgs, ids in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        # TTA: original\n",
        "        probs_accum = None\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            for m in models_dict.values():\n",
        "                m.eval()\n",
        "                logits = m(imgs).squeeze(1)\n",
        "                p = torch.sigmoid(logits)\n",
        "                probs_accum = p if probs_accum is None else probs_accum + p\n",
        "        # TTA: horizontal flip\n",
        "        imgs_flipped = torch.flip(imgs, dims=[3])\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            for m in models_dict.values():\n",
        "                logits = m(imgs_flipped).squeeze(1)\n",
        "                p = torch.sigmoid(logits)\n",
        "                probs_accum = probs_accum + p\n",
        "        probs_avg = (probs_accum / (len(models_dict)*2)).float().cpu().numpy()\n",
        "        all_probs.append(probs_avg)\n",
        "    return np.concatenate(all_probs)\n",
        "\n",
        "print(\"Predicting test...\", flush=True)\n",
        "test_probs = predict_tta(models, test_loader)\n",
        "test_ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'label': np.clip(test_probs, 1e-6, 1-1e-6)\n",
        "})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print(\"Saved submission.csv. Head:\\n\", sub.head())\n",
        "print(f\"Total elapsed: {(time.time()-total_start)/60:.1f} min\", flush=True)\n",
        "\n",
        "# Save OOF and fold metrics\n",
        "pd.DataFrame({'filepath': df['filepath'], 'label': df['label'], 'oof': oof}).to_csv('oof_partial.csv', index=False)\n",
        "pd.Series(fold_scores).to_csv('fold_scores.csv')\n",
        "print(\"Artifacts saved: submission.csv, oof_partial.csv, fold_scores.csv\", flush=True)\n",
        "\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "81d9cba5-6798-4c55-8a6d-76d073e54d88",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Upgrade: train folds 3 & 4 with larger image size (320) and more epochs; then ensemble 5 folds\n",
        "import os, time, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from sklearn.metrics import log_loss\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Ensure cache dir\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'\n",
        "LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "\n",
        "# Settings for improved training\n",
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 7\n",
        "FOLDS_TO_RUN = [3,4]\n",
        "LABEL_SMOOTH = 0.05\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-2\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "df = pd.read_csv('train_folds.csv')\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "\n",
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, df, aug):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['label'].values if 'label' in df.columns else None\n",
        "        self.aug = aug\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        if self.aug is not None:\n",
        "            img = self.aug(img)\n",
        "        if self.labels is None:\n",
        "            return img, Path(fp).stem\n",
        "        return img, np.float32(self.labels[idx])\n",
        "\n",
        "train_aug = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0), ratio=(0.75, 1.3333)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "valid_aug = T.Compose([\n",
        "    T.Resize(IMG_SIZE),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "def build_model():\n",
        "    return timm.create_model('efficientnet_b0', pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE))\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_loader(model, loader):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    for imgs, _ in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            logits = model(imgs).squeeze(1)\n",
        "            probs = torch.sigmoid(logits).float().cpu().numpy()\n",
        "        preds.append(probs)\n",
        "    return np.concatenate(preds)\n",
        "\n",
        "def train_fold(fold):\n",
        "    print(f\"\\n===== (v2) Fold {fold} @ {IMG_SIZE}px =====\", flush=True)\n",
        "    trn_df = df[df.fold != fold].reset_index(drop=True)\n",
        "    val_df = df[df.fold == fold].reset_index(drop=True)\n",
        "    trn_loader = DataLoader(DogCatDataset(trn_df, train_aug), batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    model = build_model().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type=='cuda'))\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "    best_ll, best_path = 1e9, f'model_fold{fold}.pt'\n",
        "    start = time.time()\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        run_loss, n = 0.0, 0\n",
        "        t0 = time.time()\n",
        "        for step, (imgs, labels) in enumerate(trn_loader):\n",
        "            imgs = imgs.to(device); labels = labels.to(device)\n",
        "            targets = labels * (1.0 - LABEL_SMOOTH) + (1.0 - labels) * LABEL_SMOOTH\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                logits = model(imgs).squeeze(1)\n",
        "                loss = criterion(logits, targets).mean()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            run_loss += loss.item() * imgs.size(0); n += imgs.size(0)\n",
        "            if (step+1) % 50 == 0:\n",
        "                print(f\"Fold {fold} Epoch {epoch} Step {step+1}/{len(trn_loader)} Loss {run_loss/max(1,n):.4f}\", flush=True)\n",
        "        # validate\n",
        "        model.eval(); val_probs=[]; val_targets=[]\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs = imgs.to(device)\n",
        "                with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                    logits = model(imgs).squeeze(1)\n",
        "                    probs = torch.sigmoid(logits)\n",
        "                val_probs.append(probs.float().cpu().numpy()); val_targets.append(labels.numpy())\n",
        "        val_probs = np.concatenate(val_probs); val_targets = np.concatenate(val_targets)\n",
        "        ll = log_loss(val_targets, np.clip(val_probs, 1e-6, 1-1e-6))\n",
        "        print(f\"Epoch {epoch}: train_loss={run_loss/max(1,n):.4f} val_logloss={ll:.5f} epoch_time={time.time()-t0:.1f}s total_elapsed={time.time()-start:.1f}s\", flush=True)\n",
        "        if ll < best_ll:\n",
        "            best_ll = ll\n",
        "            torch.save({'state_dict': model.state_dict(), 'val_logloss': best_ll}, best_path)\n",
        "            print(f\"  Saved best model to {best_path} (val_logloss={best_ll:.5f})\", flush=True)\n",
        "    # load best & oof\n",
        "    ckpt = torch.load(best_path, map_location='cpu'); model.load_state_dict(ckpt['state_dict']); model = model.to(device)\n",
        "    val_loader = DataLoader(DogCatDataset(df[df.fold == fold].reset_index(drop=True), valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    oof_probs = predict_loader(model, val_loader)\n",
        "    return best_ll, (df[df.fold == fold].index.values), oof_probs\n",
        "\n",
        "# Train remaining folds\n",
        "oof_prev = pd.read_csv('oof_partial.csv') if Path('oof_partial.csv').exists() else None\n",
        "oof = np.zeros(len(df), dtype=np.float32)\n",
        "if oof_prev is not None:\n",
        "    # load existing oof for folds 0-2\n",
        "    oof = oof_prev['oof'].values.astype(np.float32)\n",
        "\n",
        "fold_scores = {}\n",
        "for fold in FOLDS_TO_RUN:\n",
        "    best_ll, val_idx, val_probs = train_fold(fold)\n",
        "    oof[val_idx] = val_probs\n",
        "    fold_scores[fold] = best_ll\n",
        "    print(f\"(v2) Fold {fold} best val_logloss: {best_ll:.5f}\", flush=True)\n",
        "\n",
        "pd.Series(fold_scores).to_csv('fold_scores_v2_additional.csv')\n",
        "pd.DataFrame({'filepath': df['filepath'], 'label': df['label'], 'oof': oof}).to_csv('oof_merged.csv', index=False)\n",
        "oof_ll = log_loss(df['label'].values, np.clip(oof, 1e-6, 1-1e-6))\n",
        "print(f\"Merged OOF log-loss (5 folds, mixed settings): {oof_ll:.5f}\")\n",
        "\n",
        "# Build models dict for inference from saved checkpoints for all 5 folds\n",
        "@torch.no_grad()\n",
        "def load_model_for_fold(fold):\n",
        "    m = build_model().to(device)\n",
        "    ckpt = torch.load(f'model_fold{fold}.pt', map_location='cpu')\n",
        "    m.load_state_dict(ckpt['state_dict']); m.eval()\n",
        "    return m\n",
        "\n",
        "models = {f: load_model_for_fold(f) for f in [0,1,2,3,4] if Path(f'model_fold{f}.pt').exists()}\n",
        "\n",
        "# Test inference with TTA (original + hflip) averaging across all available folds\n",
        "test_ds = DogCatDataset(test_df, valid_aug)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_tta(models_dict, loader):\n",
        "    all_probs = []\n",
        "    for imgs, ids in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            probs_sum = None\n",
        "            for m in models_dict.values():\n",
        "                p = torch.sigmoid(m(imgs).squeeze(1))\n",
        "                probs_sum = p if probs_sum is None else probs_sum + p\n",
        "        imgs_f = torch.flip(imgs, dims=[3])\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            for m in models_dict.values():\n",
        "                p = torch.sigmoid(m(imgs_f).squeeze(1))\n",
        "                probs_sum = probs_sum + p\n",
        "        probs_avg = (probs_sum / (len(models_dict)*2)).float().cpu().numpy()\n",
        "        all_probs.append(probs_avg)\n",
        "    return np.concatenate(all_probs)\n",
        "\n",
        "print(\"Predicting test with 5-fold ensemble...\", flush=True)\n",
        "test_probs = predict_tta(models, test_loader)\n",
        "test_ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({'id': test_ids, 'label': np.clip(test_probs, 1e-6, 1-1e-6)})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print(\"Saved updated submission.csv. Head:\\n\", sub.head())\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "813818b3-2daa-4ca9-aad5-aa3b75d31e74",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Second backbone: ResNet50d 5-fold @224 for fast boost; blend with EfficientNet-B0\n",
        "import os, time, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# cache dir\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'; LOCAL_CACHE.mkdir(exist_ok=True, parents=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "\n",
        "# settings\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 3\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-2\n",
        "LABEL_SMOOTH = 0.05\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "df = pd.read_csv('train_folds.csv')\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "\n",
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, df, aug):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['label'].values if 'label' in df.columns else None\n",
        "        self.aug = aug\n",
        "    def __len__(self): return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        if self.aug is not None: img = self.aug(img)\n",
        "        if self.labels is None: return img, Path(fp).stem\n",
        "        return img, np.float32(self.labels[idx])\n",
        "\n",
        "train_aug = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0), ratio=(0.75, 1.3333)),\n",
        "    T.RandomHorizontalFlip(0.5),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "valid_aug = T.Compose([\n",
        "    T.Resize(IMG_SIZE),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "def build_resnet():\n",
        "    return timm.create_model('resnet50d', pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE))\n",
        "\n",
        "def train_fold_resnet(fold):\n",
        "    print(f\"\\n[ResNet50d] Fold {fold}\", flush=True)\n",
        "    trn_df = df[df.fold != fold].reset_index(drop=True)\n",
        "    val_df = df[df.fold == fold].reset_index(drop=True)\n",
        "    trn_loader = DataLoader(DogCatDataset(trn_df, train_aug), batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    model = build_resnet().to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type=='cuda'))\n",
        "    crit = nn.BCEWithLogitsLoss(reduction='none')\n",
        "    best_ll = 1e9; best_path = f'model_resnet_fold{fold}.pt'\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        model.train(); run_loss=0.0; n=0; t0=time.time()\n",
        "        for i,(imgs,labels) in enumerate(trn_loader):\n",
        "            imgs=imgs.to(device); labels=labels.to(device)\n",
        "            targets = labels*(1-LABEL_SMOOTH)+(1-labels)*LABEL_SMOOTH\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                logits = model(imgs).squeeze(1)\n",
        "                loss = crit(logits, targets).mean()\n",
        "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "            run_loss += loss.item()*imgs.size(0); n += imgs.size(0)\n",
        "            if (i+1)%50==0:\n",
        "                print(f\"Fold {fold} Ep{epoch} {i+1}/{len(trn_loader)} loss {run_loss/max(1,n):.4f}\", flush=True)\n",
        "        # val\n",
        "        model.eval(); probs_all=[]; targs_all=[]\n",
        "        with torch.no_grad():\n",
        "            for imgs,labels in val_loader:\n",
        "                imgs=imgs.to(device)\n",
        "                with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                    p = torch.sigmoid(model(imgs).squeeze(1))\n",
        "                probs_all.append(p.float().cpu().numpy()); targs_all.append(labels.numpy())\n",
        "        probs_all = np.concatenate(probs_all); targs_all = np.concatenate(targs_all)\n",
        "        ll = log_loss(targs_all, np.clip(probs_all, 1e-6, 1-1e-6))\n",
        "        print(f\"Epoch {epoch}: train_loss={run_loss/max(1,n):.4f} val_logloss={ll:.5f} time={time.time()-t0:.1f}s\", flush=True)\n",
        "        if ll < best_ll:\n",
        "            best_ll = ll; torch.save({'state_dict': model.state_dict(), 'val_logloss': best_ll}, best_path)\n",
        "            print(f\"  Saved {best_path} ({best_ll:.5f})\", flush=True)\n",
        "    return best_ll\n",
        "\n",
        "# Train 5 folds\n",
        "fold_scores = {}\n",
        "for f in range(5):\n",
        "    fold_scores[f] = train_fold_resnet(f)\n",
        "print('ResNet fold scores:', fold_scores)\n",
        "\n",
        "# Blend EfficientNet-B0 (existing 5 folds) + ResNet50d (new 5 folds) with HFlip TTA\n",
        "@torch.no_grad()\n",
        "def load_eff_fold(fold):\n",
        "    import timm\n",
        "    m = timm.create_model('efficientnet_b0', pretrained=False, num_classes=1, cache_dir=str(LOCAL_CACHE)).to(device)\n",
        "    ckpt = torch.load(f'model_fold{fold}.pt', map_location='cpu'); m.load_state_dict(ckpt['state_dict']); m.eval(); return m\n",
        "\n",
        "@torch.no_grad()\n",
        "def load_resnet_fold(fold):\n",
        "    m = build_resnet().to(device)\n",
        "    ckpt = torch.load(f'model_resnet_fold{fold}.pt', map_location='cpu'); m.load_state_dict(ckpt['state_dict']); m.eval(); return m\n",
        "\n",
        "eff_models = {f: load_eff_fold(f) for f in range(5) if Path(f'model_fold{f}.pt').exists()}\n",
        "res_models = {f: load_resnet_fold(f) for f in range(5)}\n",
        "\n",
        "test_ds = DogCatDataset(test_df, valid_aug)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_blend(eff, res, loader):\n",
        "    all_probs = []\n",
        "    for imgs, ids in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            pe = None\n",
        "            for m in eff.values():\n",
        "                p = torch.sigmoid(m(imgs).squeeze(1))\n",
        "                pe = p if pe is None else pe + p\n",
        "            pr = None\n",
        "            for m in res.values():\n",
        "                p = torch.sigmoid(m(imgs).squeeze(1))\n",
        "                pr = p if pr is None else pr + p\n",
        "            # HFlip\n",
        "            imgs_f = torch.flip(imgs, dims=[3])\n",
        "            for m in eff.values():\n",
        "                pe += torch.sigmoid(m(imgs_f).squeeze(1))\n",
        "            for m in res.values():\n",
        "                pr += torch.sigmoid(m(imgs_f).squeeze(1))\n",
        "            pe = pe / (len(eff)*2); pr = pr / (len(res)*2)\n",
        "            probs = (pe + pr) / 2.0\n",
        "        all_probs.append(probs.float().cpu().numpy())\n",
        "    return np.concatenate(all_probs)\n",
        "\n",
        "print('Predicting test with blended ensemble...', flush=True)\n",
        "test_probs = predict_blend(eff_models, res_models, test_loader)\n",
        "test_ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({'id': test_ids, 'label': np.clip(test_probs, 1e-6, 1-1e-6)})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved blended submission.csv. Head:\\n', sub.head(), flush=True)\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7647ebed-7555-4fe1-995c-267a0ba35845",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Strong model: ConvNeXt-Tiny 5-fold @320 with EMA, Cosine LR; disable MixUp (previous run stuck at ~0.69)\n",
        "import os, time, math, gc, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from sklearn.metrics import log_loss\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Cache dir\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'\n",
        "LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "\n",
        "# Config (stabilized):\n",
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 6\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 0.01\n",
        "LABEL_SMOOTH = 0.05\n",
        "MIXUP_ALPHA = 0.0  # disabled to recover learning\n",
        "EMA_DECAY = 0.9997\n",
        "WARMUP_EPOCHS = 1\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "df = pd.read_csv('train_folds.csv')\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "\n",
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, df, aug):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['label'].values if 'label' in df.columns else None\n",
        "        self.aug = aug\n",
        "    def __len__(self): return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        if self.aug is not None:\n",
        "            img = self.aug(img)\n",
        "        if self.labels is None:\n",
        "            return img, Path(fp).stem\n",
        "        return img, np.float32(self.labels[idx])\n",
        "\n",
        "train_aug = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0), ratio=(0.75, 1.3333)),\n",
        "    T.RandomHorizontalFlip(0.5),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "valid_aug = T.Compose([\n",
        "    T.Resize(IMG_SIZE),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "def build_model():\n",
        "    return timm.create_model('convnext_tiny', pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE))\n",
        "\n",
        "def mixup_batch(x, y, alpha=MIXUP_ALPHA):\n",
        "    if alpha is None or alpha <= 0:\n",
        "        return x, y\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "    x_m = lam * x + (1 - lam) * x[idx]\n",
        "    y = y.view(-1, 1)\n",
        "    y_m = lam * y + (1 - lam) * y[idx]\n",
        "    return x_m, y_m.squeeze(1)\n",
        "\n",
        "def train_one_fold(fold):\n",
        "    print(f\"\\n[ConvNeXt-Tiny] Fold {fold} @ {IMG_SIZE}px\", flush=True)\n",
        "    trn_idx = df.index[df.fold != fold].values\n",
        "    val_idx = df.index[df.fold == fold].values\n",
        "    trn_df = df.loc[trn_idx]\n",
        "    val_df = df.loc[val_idx]\n",
        "    trn_loader = DataLoader(DogCatDataset(trn_df, train_aug), batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(device)\n",
        "    ema = ModelEmaV2(model, decay=EMA_DECAY, device=device if device.type=='cuda' else None)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS - WARMUP_EPOCHS)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type=='cuda'))\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "    best_ll = 1e9\n",
        "    best_path = f'model_convnext_fold{fold}_ema.pt'\n",
        "\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        t0 = time.time(); run_loss = 0.0; n = 0\n",
        "        # Warmup\n",
        "        if epoch <= WARMUP_EPOCHS:\n",
        "            for pg in optimizer.param_groups:\n",
        "                pg['lr'] = LR * epoch / max(1, WARMUP_EPOCHS)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "        for step, (imgs, labels) in enumerate(trn_loader):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            labels_sm = labels * (1 - LABEL_SMOOTH) + (1 - labels) * LABEL_SMOOTH\n",
        "            imgs_mu, labels_mu = mixup_batch(imgs, labels_sm, alpha=MIXUP_ALPHA)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                logits = model(imgs_mu).squeeze(1)\n",
        "                loss = criterion(logits, labels_mu).mean()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            ema.update(model)\n",
        "            run_loss += loss.item() * imgs.size(0); n += imgs.size(0)\n",
        "            if (step+1) % 100 == 0:\n",
        "                cur_lr = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Fold {fold} Ep{epoch} {step+1}/{len(trn_loader)} loss {run_loss/max(1,n):.4f} lr {cur_lr:.2e}\", flush=True)\n",
        "\n",
        "        # Validation with EMA weights\n",
        "        model.eval()\n",
        "        val_probs = []; val_targets = []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs = imgs.to(device)\n",
        "                with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                    logits = ema.module(imgs).squeeze(1)\n",
        "                    probs = torch.sigmoid(logits)\n",
        "                val_probs.append(probs.float().cpu().numpy())\n",
        "                val_targets.append(labels.numpy())\n",
        "        val_probs = np.concatenate(val_probs); val_targets = np.concatenate(val_targets)\n",
        "        ll = log_loss(val_targets, np.clip(val_probs, 1e-6, 1-1e-6))\n",
        "        print(f\"Epoch {epoch}: tr_loss={run_loss/max(1,n):.4f} val_logloss={ll:.5f} time={time.time()-t0:.1f}s\", flush=True)\n",
        "        if ll < best_ll:\n",
        "            best_ll = ll\n",
        "            torch.save({'state_dict': ema.module.state_dict(), 'val_logloss': best_ll}, best_path)\n",
        "            print(f\"  Saved EMA model -> {best_path} ({best_ll:.5f})\", flush=True)\n",
        "\n",
        "    # Load best EMA for OOF\n",
        "    ckpt = torch.load(best_path, map_location='cpu')\n",
        "    ema_model = build_model().to(device)\n",
        "    ema_model.load_state_dict(ckpt['state_dict'])\n",
        "    ema_model.eval()\n",
        "    # OOF preds\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in val_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                p = torch.sigmoid(ema_model(imgs).squeeze(1))\n",
        "            preds.append(p.float().cpu().numpy())\n",
        "    preds = np.concatenate(preds)\n",
        "    return val_idx, preds, best_ll\n",
        "\n",
        "# Train all folds with consistent settings\n",
        "oof = np.zeros(len(df), dtype=np.float32)\n",
        "fold_scores = {}\n",
        "for f in range(5):\n",
        "    val_idx, preds, best_ll = train_one_fold(f)\n",
        "    oof[val_idx] = preds\n",
        "    fold_scores[f] = best_ll\n",
        "    print(f\"[ConvNeXt-Tiny] Fold {f} best val_logloss: {best_ll:.5f}\", flush=True)\n",
        "\n",
        "pd.Series(fold_scores).to_csv('fold_scores_convnext.csv')\n",
        "pd.DataFrame({'filepath': df['filepath'], 'label': df['label'], 'oof': oof}).to_csv('oof_convnext.csv', index=False)\n",
        "oof_ll = log_loss(df['label'].values, np.clip(oof, 1e-6, 1-1e-6))\n",
        "print(f\"ConvNeXt-Tiny OOF log-loss (5 folds): {oof_ll:.5f}\")\n",
        "\n",
        "# Inference with EMA checkpoints + HFlip TTA\n",
        "@torch.no_grad()\n",
        "def load_convnext_fold(fold):\n",
        "    m = build_model().to(device)\n",
        "    ckpt = torch.load(f'model_convnext_fold{fold}_ema.pt', map_location='cpu')\n",
        "    m.load_state_dict(ckpt['state_dict']); m.eval()\n",
        "    return m\n",
        "models = {f: load_convnext_fold(f) for f in range(5)}\n",
        "\n",
        "test_ds = DogCatDataset(test_df, valid_aug)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_tta(models_dict, loader):\n",
        "    out = []\n",
        "    for imgs, ids in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            p_sum = None\n",
        "            for m in models_dict.values():\n",
        "                p = torch.sigmoid(m(imgs).squeeze(1))\n",
        "                p_sum = p if p_sum is None else p_sum + p\n",
        "            imgs_f = torch.flip(imgs, dims=[3])\n",
        "            for m in models_dict.values():\n",
        "                p_sum += torch.sigmoid(m(imgs_f).squeeze(1))\n",
        "        p_avg = (p_sum / (len(models_dict)*2)).float().cpu().numpy()\n",
        "        out.append(p_avg)\n",
        "    return np.concatenate(out)\n",
        "\n",
        "print(\"Predicting test with ConvNeXt-Tiny 5-fold EMA ensemble...\", flush=True)\n",
        "test_probs = predict_tta(models, test_loader)\n",
        "test_ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({'id': test_ids, 'label': np.clip(test_probs, 1e-6, 1-1e-6)})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (ConvNeXt). Head:\\n', sub.head(), flush=True)\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "90132784-954b-43d3-9488-6a0735bcefc5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Clean, consistent 5-fold pipeline: EfficientNet-B3 (ra_in1k) @320 with EMA, cosine LR, LS=0.05, MixUp(0.1), AMP, fixed OOF\n",
        "import os, time, math, gc, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from sklearn.metrics import log_loss\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Cache for pretrained weights\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'\n",
        "LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'\n",
        "\n",
        "# Config per expert recipe (Plan A: reliable RA weights)\n",
        "MODEL_NAME = 'efficientnet_b3.ra_in1k'\n",
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10  # per directive\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-2\n",
        "LABEL_SMOOTH = 0.05\n",
        "MIXUP_ALPHA = 0.1  # will auto-disable if unstable\n",
        "EMA_DECAY = 0.9997\n",
        "WARMUP_EPOCHS = 1\n",
        "NUM_WORKERS = 0  # stability safeguard\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "df = pd.read_csv('train_folds.csv')\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "\n",
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, df, aug):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['label'].values if 'label' in df.columns else None\n",
        "        self.aug = aug\n",
        "    def __len__(self): return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        if self.aug is not None:\n",
        "            img = self.aug(img)\n",
        "        if self.labels is None:\n",
        "            return img, Path(fp).stem\n",
        "        return img, np.float32(self.labels[idx])\n",
        "\n",
        "train_aug = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0), ratio=(0.75, 1.3333)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "valid_aug = T.Compose([\n",
        "    T.Resize(IMG_SIZE),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "def build_model():\n",
        "    return timm.create_model(MODEL_NAME, pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE))\n",
        "\n",
        "# Pre-download/initialize once to avoid hang inside training loop\n",
        "print(f\"Pre-initializing model '{MODEL_NAME}' (pretrained=True) to populate cache...\", flush=True)\n",
        "try:\n",
        "    _tmp_m = build_model()\n",
        "    del _tmp_m\n",
        "    print(\"Model init OK.\", flush=True)\n",
        "    # lock to offline after successful fetch to prevent further network calls\n",
        "    os.environ['HF_HUB_OFFLINE'] = '1'\n",
        "except Exception as e:\n",
        "    print(f\"Model init failed: {e}\", flush=True)\n",
        "\n",
        "def mixup_batch(x, y, alpha):\n",
        "    if alpha is None or alpha <= 0:\n",
        "        return x, y\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "    x_m = lam * x + (1 - lam) * x[idx]\n",
        "    y = y.view(-1, 1)\n",
        "    y_m = lam * y + (1 - lam) * y[idx]\n",
        "    return x_m, y_m.squeeze(1)\n",
        "\n",
        "def train_one_fold(fold):\n",
        "    print(f\"\\n[EffB3-RA] Fold {fold} @ {IMG_SIZE}px\", flush=True)\n",
        "    trn_idx = df.index[df.fold != fold].values\n",
        "    val_idx = df.index[df.fold == fold].values\n",
        "    trn_df = df.loc[trn_idx]\n",
        "    val_df = df.loc[val_idx]\n",
        "    trn_loader = DataLoader(DogCatDataset(trn_df, train_aug), batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(device)\n",
        "    ema = ModelEmaV2(model, decay=EMA_DECAY, device=device if device.type=='cuda' else None)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS - WARMUP_EPOCHS)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type=='cuda'))\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "    best_ll = 1e9\n",
        "    best_path = f'model_b3_fold{fold}_ema.pt'\n",
        "    mixup_enabled = True if (MIXUP_ALPHA is not None and MIXUP_ALPHA > 0) else False\n",
        "\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        t0 = time.time(); run_loss = 0.0; n = 0\n",
        "        # Warmup or cosine\n",
        "        if epoch <= WARMUP_EPOCHS:\n",
        "            for pg in optimizer.param_groups:\n",
        "                pg['lr'] = LR * epoch / max(1, WARMUP_EPOCHS)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "        for step, (imgs, labels) in enumerate(trn_loader):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            targets = labels * (1 - LABEL_SMOOTH) + (1 - labels) * LABEL_SMOOTH\n",
        "            if mixup_enabled:\n",
        "                imgs, targets = mixup_batch(imgs, targets, alpha=MIXUP_ALPHA)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                logits = model(imgs).squeeze(1)\n",
        "                loss = criterion(logits, targets).mean()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            ema.update(model)\n",
        "            run_loss += loss.item() * imgs.size(0); n += imgs.size(0)\n",
        "            if (step+1) % 100 == 0:\n",
        "                cur_lr = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Fold {fold} Ep{epoch} {step+1}/{len(trn_loader)} loss {run_loss/max(1,n):.4f} lr {cur_lr:.2e}\", flush=True)\n",
        "\n",
        "        # Simple instability safeguard: if first-epoch loss > 0.69, disable MixUp from next epoch\n",
        "        if epoch == 1 and mixup_enabled and (run_loss/max(1,n) > 0.69):\n",
        "            mixup_enabled = False\n",
        "            print(\"  Disabling MixUp due to unstable first-epoch loss.\", flush=True)\n",
        "\n",
        "        # Validation with EMA weights\n",
        "        model.eval()\n",
        "        val_probs = []; val_targets = []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs = imgs.to(device)\n",
        "                with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                    logits = ema.module(imgs).squeeze(1)\n",
        "                    probs = torch.sigmoid(logits)\n",
        "                val_probs.append(probs.float().cpu().numpy())\n",
        "                val_targets.append(labels.numpy())\n",
        "        val_probs = np.concatenate(val_probs); val_targets = np.concatenate(val_targets)\n",
        "        ll = log_loss(val_targets, np.clip(val_probs, 1e-6, 1-1e-6))\n",
        "        print(f\"Epoch {epoch}: tr_loss={run_loss/max(1,n):.4f} val_logloss={ll:.5f} time={time.time()-t0:.1f}s\", flush=True)\n",
        "        if ll < best_ll:\n",
        "            best_ll = ll\n",
        "            torch.save({'state_dict': ema.module.state_dict(), 'val_logloss': best_ll}, best_path)\n",
        "            print(f\"  Saved EMA -> {best_path} ({best_ll:.5f})\", flush=True)\n",
        "\n",
        "    # Load best EMA and produce fold OOF\n",
        "    ckpt = torch.load(best_path, map_location='cpu')\n",
        "    ema_model = build_model().to(device)\n",
        "    ema_model.load_state_dict(ckpt['state_dict'])\n",
        "    ema_model.eval()\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in val_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                p = torch.sigmoid(ema_model(imgs).squeeze(1))\n",
        "            preds.append(p.float().cpu().numpy())\n",
        "    preds = np.concatenate(preds)\n",
        "    return val_idx, preds, best_ll\n",
        "\n",
        "# Train all 5 folds consistently\n",
        "oof = np.zeros(len(df), dtype=np.float32)\n",
        "fold_scores = {}\n",
        "total_start = time.time()\n",
        "for f in range(5):\n",
        "    print(f\"==== Start Fold {f} ====\", flush=True)\n",
        "    val_idx, preds, best_ll = train_one_fold(f)\n",
        "    oof[val_idx] = preds  # fixed OOF indexing by original df index\n",
        "    fold_scores[f] = best_ll\n",
        "    print(f\"[EffB3-RA] Fold {f} best val_logloss: {best_ll:.5f}\", flush=True)\n",
        "\n",
        "oof_ll = log_loss(df['label'].values, np.clip(oof, 1e-6, 1-1e-6))\n",
        "print(f\"EffB3-RA OOF log-loss (5 folds): {oof_ll:.5f}\", flush=True)\n",
        "pd.Series(fold_scores).to_csv('fold_scores_b3.csv')\n",
        "pd.DataFrame({'filepath': df['filepath'], 'label': df['label'], 'oof': oof}).to_csv('oof_b3.csv', index=False)\n",
        "\n",
        "# Inference with 5 EMA checkpoints + HFlip TTA\n",
        "@torch.no_grad()\n",
        "def load_b3_fold(fold):\n",
        "    m = build_model().to(device)\n",
        "    ckpt = torch.load(f'model_b3_fold{fold}_ema.pt', map_location='cpu')\n",
        "    m.load_state_dict(ckpt['state_dict']); m.eval()\n",
        "    return m\n",
        "\n",
        "models = {f: load_b3_fold(f) for f in range(5)}\n",
        "test_ds = DogCatDataset(test_df, valid_aug)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_tta(models_dict, loader):\n",
        "    out = []\n",
        "    for imgs, ids in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            p_sum = None\n",
        "            for m in models_dict.values():\n",
        "                p = torch.sigmoid(m(imgs).squeeze(1))\n",
        "                p_sum = p if p_sum is None else p_sum + p\n",
        "            imgs_f = torch.flip(imgs, dims=[3])\n",
        "            for m in models_dict.values():\n",
        "                p_sum += torch.sigmoid(m(imgs_f).squeeze(1))\n",
        "        p_avg = (p_sum / (len(models_dict)*2)).float().cpu().numpy()\n",
        "        out.append(p_avg)\n",
        "    return np.concatenate(out)\n",
        "\n",
        "print(\"Predicting test with 5-fold EMA ensemble (EffB3-RA)...\", flush=True)\n",
        "test_probs = predict_tta(models, test_loader)\n",
        "test_ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({'id': test_ids, 'label': np.clip(test_probs, 1e-6, 1-1e-6)})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (EffB3-RA). Head:\\n', sub.head(), flush=True)\n",
        "print(f\"Total elapsed: {(time.time()-total_start)/60:.1f} min\", flush=True)\n",
        "\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "83c433a8-080c-496d-af2f-bf17be627c13",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plan C: ResNet50d.ra2_in1k @384, 5-fold, EMA, Cosine LR, LS=0.05, MixUp=0.1, AMP, fixed OOF, HFlip TTA\n",
        "import os, time, gc, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from sklearn.metrics import log_loss\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "print(\"[Plan C] Starting cell: ResNet50d-RA2 @384\", flush=True)\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "os.environ['PYTHONUNBUFFERED'] = '1'\n",
        "\n",
        "# Cache\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'\n",
        "LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "\n",
        "# Config\n",
        "MODEL_NAME = 'resnet50d.ra2_in1k'\n",
        "IMG_SIZE = 384\n",
        "BATCH_SIZE = 24\n",
        "EPOCHS = 10\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-2\n",
        "LABEL_SMOOTH = 0.05\n",
        "MIXUP_ALPHA = 0.1\n",
        "EMA_DECAY = 0.9997\n",
        "WARMUP_EPOCHS = 1\n",
        "NUM_WORKERS = 0  # set 0 to avoid potential multiprocessing hang\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "df = pd.read_csv('train_folds.csv')\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "\n",
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, df, aug):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['label'].values if 'label' in df.columns else None\n",
        "        self.aug = aug\n",
        "    def __len__(self): return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        if self.aug is not None:\n",
        "            img = self.aug(img)\n",
        "        if self.labels is None:\n",
        "            return img, Path(fp).stem\n",
        "        return img, np.float32(self.labels[idx])\n",
        "\n",
        "train_aug = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0), ratio=(0.75, 1.3333)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "valid_aug = T.Compose([\n",
        "    T.Resize(IMG_SIZE),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "def build_model():\n",
        "    return timm.create_model(MODEL_NAME, pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE))\n",
        "\n",
        "# Pre-init to ensure weights are cached and avoid silent hangs\n",
        "print(f\"Pre-initializing '{MODEL_NAME}' ...\", flush=True)\n",
        "try:\n",
        "    _m = build_model()\n",
        "    del _m\n",
        "    print(\"Model pre-init OK.\", flush=True)\n",
        "except Exception as e:\n",
        "    print(f\"Model pre-init failed: {e}\", flush=True)\n",
        "\n",
        "def mixup_batch(x, y, alpha):\n",
        "    if alpha is None or alpha <= 0:\n",
        "        return x, y\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "    x_m = lam * x + (1 - lam) * x[idx]\n",
        "    y = y.view(-1, 1)\n",
        "    y_m = lam * y + (1 - lam) * y[idx]\n",
        "    return x_m, y_m.squeeze(1)\n",
        "\n",
        "def train_one_fold(fold):\n",
        "    print(f\"\\n[ResNet50d-RA2] Fold {fold} @ {IMG_SIZE}px\", flush=True)\n",
        "    trn_idx = df.index[df.fold != fold].values\n",
        "    val_idx = df.index[df.fold == fold].values\n",
        "    trn_df = df.loc[trn_idx]\n",
        "    val_df = df.loc[val_idx]\n",
        "    trn_loader = DataLoader(DogCatDataset(trn_df, train_aug), batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(device)\n",
        "    ema = ModelEmaV2(model, decay=EMA_DECAY, device=device if device.type=='cuda' else None)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS - WARMUP_EPOCHS)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type=='cuda'))\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "    best_ll = 1e9\n",
        "    best_path = f'model_resnet384_fold{fold}_ema.pt'\n",
        "    mixup_enabled = True if (MIXUP_ALPHA is not None and MIXUP_ALPHA > 0) else False\n",
        "\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        t0 = time.time(); run_loss = 0.0; n = 0\n",
        "        # Warmup or cosine\n",
        "        if epoch <= WARMUP_EPOCHS:\n",
        "            for pg in optimizer.param_groups:\n",
        "                pg['lr'] = LR * epoch / max(1, WARMUP_EPOCHS)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "        for step, (imgs, labels) in enumerate(trn_loader):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            targets = labels * (1 - LABEL_SMOOTH) + (1 - labels) * LABEL_SMOOTH\n",
        "            if mixup_enabled:\n",
        "                imgs, targets = mixup_batch(imgs, targets, alpha=MIXUP_ALPHA)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                logits = model(imgs).squeeze(1)\n",
        "                loss = criterion(logits, targets).mean()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            ema.update(model)\n",
        "            run_loss += loss.item() * imgs.size(0); n += imgs.size(0)\n",
        "            if (step+1) % 80 == 0:\n",
        "                cur_lr = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Fold {fold} Ep{epoch} {step+1}/{len(trn_loader)} loss {run_loss/max(1,n):.4f} lr {cur_lr:.2e}\", flush=True)\n",
        "\n",
        "        if epoch == 1 and mixup_enabled and (run_loss/max(1,n) > 0.69):\n",
        "            mixup_enabled = False\n",
        "            print(\"  Disabling MixUp due to unstable first-epoch loss.\", flush=True)\n",
        "\n",
        "        # Validation (EMA)\n",
        "        model.eval()\n",
        "        val_probs = []; val_targets = []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs = imgs.to(device)\n",
        "                with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                    logits = ema.module(imgs).squeeze(1)\n",
        "                    probs = torch.sigmoid(logits)\n",
        "                val_probs.append(probs.float().cpu().numpy())\n",
        "                val_targets.append(labels.numpy())\n",
        "        val_probs = np.concatenate(val_probs); val_targets = np.concatenate(val_targets)\n",
        "        ll = log_loss(val_targets, np.clip(val_probs, 1e-6, 1-1e-6))\n",
        "        print(f\"Epoch {epoch}: tr_loss={run_loss/max(1,n):.4f} val_logloss={ll:.5f} time={time.time()-t0:.1f}s\", flush=True)\n",
        "        if ll < best_ll:\n",
        "            best_ll = ll\n",
        "            torch.save({'state_dict': ema.module.state_dict(), 'val_logloss': best_ll}, best_path)\n",
        "            print(f\"  Saved EMA -> {best_path} ({best_ll:.5f})\", flush=True)\n",
        "\n",
        "    # Best EMA OOF\n",
        "    ckpt = torch.load(best_path, map_location='cpu')\n",
        "    ema_model = build_model().to(device)\n",
        "    ema_model.load_state_dict(ckpt['state_dict'])\n",
        "    ema_model.eval()\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in val_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                p = torch.sigmoid(ema_model(imgs).squeeze(1))\n",
        "            preds.append(p.float().cpu().numpy())\n",
        "    preds = np.concatenate(preds)\n",
        "    return val_idx, preds, best_ll\n",
        "\n",
        "# Train 5 folds\n",
        "print(\"==== Begin 5-fold training (ResNet50d-RA2 384px) ====\", flush=True)\n",
        "oof = np.zeros(len(df), dtype=np.float32)\n",
        "fold_scores = {}\n",
        "total_start = time.time()\n",
        "for f in range(5):\n",
        "    print(f\"==== Start Fold {f} ====\", flush=True)\n",
        "    val_idx, preds, best_ll = train_one_fold(f)\n",
        "    oof[val_idx] = preds\n",
        "    fold_scores[f] = best_ll\n",
        "    print(f\"[ResNet50d-RA2] Fold {f} best val_logloss: {best_ll:.5f}\", flush=True)\n",
        "\n",
        "oof_ll = log_loss(df['label'].values, np.clip(oof, 1e-6, 1-1e-6))\n",
        "print(f\"ResNet50d-RA2 OOF log-loss (5 folds): {oof_ll:.5f}\", flush=True)\n",
        "pd.Series(fold_scores).to_csv('fold_scores_resnet384.csv')\n",
        "pd.DataFrame({'filepath': df['filepath'], 'label': df['label'], 'oof': oof}).to_csv('oof_resnet384.csv', index=False)\n",
        "\n",
        "# Inference: 5 EMA checkpoints + HFlip TTA\n",
        "@torch.no_grad()\n",
        "def load_fold(fold):\n",
        "    m = build_model().to(device)\n",
        "    ckpt = torch.load(f'model_resnet384_fold{fold}_ema.pt', map_location='cpu')\n",
        "    m.load_state_dict(ckpt['state_dict']); m.eval()\n",
        "    return m\n",
        "\n",
        "models = {f: load_fold(f) for f in range(5)}\n",
        "test_ds = DogCatDataset(test_df, valid_aug)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_tta(models_dict, loader):\n",
        "    out = []\n",
        "    for imgs, ids in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            p_sum = None\n",
        "            for m in models_dict.values():\n",
        "                p = torch.sigmoid(m(imgs).squeeze(1))\n",
        "                p_sum = p if p_sum is None else p_sum + p\n",
        "            imgs_f = torch.flip(imgs, dims=[3])\n",
        "            for m in models_dict.values():\n",
        "                p_sum += torch.sigmoid(m(imgs_f).squeeze(1))\n",
        "        p_avg = (p_sum / (len(models_dict)*2)).float().cpu().numpy()\n",
        "        out.append(p_avg)\n",
        "    return np.concatenate(out)\n",
        "\n",
        "print(\"Predicting test with 5-fold EMA ensemble (ResNet50d-RA2 384px)...\", flush=True)\n",
        "test_probs = predict_tta(models, test_loader)\n",
        "test_ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({'id': test_ids, 'label': np.clip(test_probs, 1e-6, 1-1e-6)})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (ResNet50d-RA2 384). Head:\\n', sub.head(), flush=True)\n",
        "print(f\"Total elapsed: {(time.time()-total_start)/60:.1f} min\", flush=True)\n",
        "\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b29f6982-d0d8-4d79-b539-80067db382f3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Debug cell: verify kernel stdout, filesystem, timm import, and quick model instantiation (no download)\n",
        "import os, glob\n",
        "from pathlib import Path\n",
        "import torch, timm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "print(\"[DEBUG] Cell start\", flush=True)\n",
        "print(\"Torch:\", torch.__version__, \"CUDA:\", torch.cuda.is_available(), flush=True)\n",
        "print(\"timm:\", timm.__version__, flush=True)\n",
        "print(\"CWD:\", Path.cwd(), flush=True)\n",
        "print(\"Cache dirs:\", [p.name for p in Path('model_cache').glob('*')], flush=True)\n",
        "print(\"ResNet50d-RA2 cache exists:\", Path('model_cache/models--timm--resnet50d.ra2_in1k').exists(), flush=True)\n",
        "df_dbg = pd.read_csv('train_folds.csv')\n",
        "print(\"train_folds rows:\", len(df_dbg), \"fold counts:\", df_dbg['fold'].value_counts().to_dict(), flush=True)\n",
        "sample_train = sorted(glob.glob('train/*.jpg'))[:1]\n",
        "print(\"Sample train file:\", sample_train, flush=True)\n",
        "if sample_train:\n",
        "    try:\n",
        "        img = Image.open(sample_train[0]).convert('RGB')\n",
        "        print(\"PIL open OK, size:\", img.size, flush=True)\n",
        "    except Exception as e:\n",
        "        print(\"PIL open failed:\", e, flush=True)\n",
        "try:\n",
        "    m = timm.create_model('resnet50d.ra2_in1k', pretrained=False, num_classes=1)\n",
        "    _ = sum(p.numel() for p in m.parameters())\n",
        "    print(\"timm model instantiate OK (pretrained=False). Params:\", _, flush=True)\n",
        "    del m\n",
        "except Exception as e:\n",
        "    print(\"timm model instantiate failed:\", e, flush=True)\n",
        "print(\"[DEBUG] Cell end\", flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "63aa0c61-5f05-4d63-b419-38480faa69d5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plan B: tf_efficientnet_b2_ns @320, 5-fold, EMA, Cosine LR, LS=0.05, MixUp=0.1, AMP, fixed OOF, HFlip TTA\n",
        "import os, time, gc, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from sklearn.metrics import log_loss\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "print(\"[Plan B] Starting cell: tf_efficientnet_b2_ns @320\", flush=True)\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "os.environ['PYTHONUNBUFFERED'] = '1'\n",
        "\n",
        "# Cache\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'\n",
        "LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '1'\n",
        "\n",
        "# Config\n",
        "MODEL_NAME = 'tf_efficientnet_b2_ns'\n",
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-2\n",
        "LABEL_SMOOTH = 0.05\n",
        "MIXUP_ALPHA = 0.1\n",
        "EMA_DECAY = 0.9997\n",
        "WARMUP_EPOCHS = 1\n",
        "NUM_WORKERS = 0\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "df = pd.read_csv('train_folds.csv')\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "\n",
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, df, aug):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['label'].values if 'label' in df.columns else None\n",
        "        self.aug = aug\n",
        "    def __len__(self): return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        if self.aug is not None:\n",
        "            img = self.aug(img)\n",
        "        if self.labels is None:\n",
        "            return img, Path(fp).stem\n",
        "        return img, np.float32(self.labels[idx])\n",
        "\n",
        "train_aug = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0), ratio=(0.75, 1.3333)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "valid_aug = T.Compose([\n",
        "    T.Resize(IMG_SIZE),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "def build_model():\n",
        "    return timm.create_model(MODEL_NAME, pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE))\n",
        "\n",
        "# Pre-init to ensure weights are cached and avoid silent hangs\n",
        "print(f\"Pre-initializing '{MODEL_NAME}' ...\", flush=True)\n",
        "try:\n",
        "    _m = build_model()\n",
        "    del _m\n",
        "    print(\"Model pre-init OK.\", flush=True)\n",
        "    os.environ['HF_HUB_OFFLINE'] = '1'\n",
        "except Exception as e:\n",
        "    print(f\"Model pre-init failed: {e}\", flush=True)\n",
        "\n",
        "def mixup_batch(x, y, alpha):\n",
        "    if alpha is None or alpha <= 0:\n",
        "        return x, y\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "    x_m = lam * x + (1 - lam) * x[idx]\n",
        "    y = y.view(-1, 1)\n",
        "    y_m = lam * y + (1 - lam) * y[idx]\n",
        "    return x_m, y_m.squeeze(1)\n",
        "\n",
        "def train_one_fold(fold):\n",
        "    print(f\"\\n[EffB2-NS] Fold {fold} @ {IMG_SIZE}px\", flush=True)\n",
        "    trn_idx = df.index[df.fold != fold].values\n",
        "    val_idx = df.index[df.fold == fold].values\n",
        "    trn_df = df.loc[trn_idx]\n",
        "    val_df = df.loc[val_idx]\n",
        "    trn_loader = DataLoader(DogCatDataset(trn_df, train_aug), batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(device)\n",
        "    ema = ModelEmaV2(model, decay=EMA_DECAY, device=device if device.type=='cuda' else None)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS - WARMUP_EPOCHS)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type=='cuda'))\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "    best_ll = 1e9\n",
        "    best_path = f'model_b2_fold{fold}_ema.pt'\n",
        "    mixup_enabled = True if (MIXUP_ALPHA is not None and MIXUP_ALPHA > 0) else False\n",
        "\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        t0 = time.time(); run_loss = 0.0; n = 0\n",
        "        if epoch <= WARMUP_EPOCHS:\n",
        "            for pg in optimizer.param_groups:\n",
        "                pg['lr'] = LR * epoch / max(1, WARMUP_EPOCHS)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "        for step, (imgs, labels) in enumerate(trn_loader):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            targets = labels * (1 - LABEL_SMOOTH) + (1 - labels) * LABEL_SMOOTH\n",
        "            if mixup_enabled:\n",
        "                imgs, targets = mixup_batch(imgs, targets, alpha=MIXUP_ALPHA)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                logits = model(imgs).squeeze(1)\n",
        "                loss = criterion(logits, targets).mean()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            ema.update(model)\n",
        "            run_loss += loss.item() * imgs.size(0); n += imgs.size(0)\n",
        "            if (step+1) % 100 == 0:\n",
        "                cur_lr = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Fold {fold} Ep{epoch} {step+1}/{len(trn_loader)} loss {run_loss/max(1,n):.4f} lr {cur_lr:.2e}\", flush=True)\n",
        "\n",
        "        if epoch == 1 and mixup_enabled and (run_loss/max(1,n) > 0.69):\n",
        "            mixup_enabled = False\n",
        "            print(\"  Disabling MixUp due to unstable first-epoch loss.\", flush=True)\n",
        "\n",
        "        # Validation with EMA weights\n",
        "        model.eval()\n",
        "        val_probs = []; val_targets = []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs = imgs.to(device)\n",
        "                with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                    logits = ema.module(imgs).squeeze(1)\n",
        "                    probs = torch.sigmoid(logits)\n",
        "                val_probs.append(probs.float().cpu().numpy())\n",
        "                val_targets.append(labels.numpy())\n",
        "        val_probs = np.concatenate(val_probs); val_targets = np.concatenate(val_targets)\n",
        "        ll = log_loss(val_targets, np.clip(val_probs, 1e-6, 1-1e-6))\n",
        "        print(f\"Epoch {epoch}: tr_loss={run_loss/max(1,n):.4f} val_logloss={ll:.5f} time={time.time()-t0:.1f}s\", flush=True)\n",
        "        if ll < best_ll:\n",
        "            best_ll = ll\n",
        "            torch.save({'state_dict': ema.module.state_dict(), 'val_logloss': best_ll}, best_path)\n",
        "            print(f\"  Saved EMA -> {best_path} ({best_ll:.5f})\", flush=True)\n",
        "\n",
        "    # Best EMA OOF\n",
        "    ckpt = torch.load(best_path, map_location='cpu')\n",
        "    ema_model = build_model().to(device)\n",
        "    ema_model.load_state_dict(ckpt['state_dict'])\n",
        "    ema_model.eval()\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in val_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                p = torch.sigmoid(ema_model(imgs).squeeze(1))\n",
        "            preds.append(p.float().cpu().numpy())\n",
        "    preds = np.concatenate(preds)\n",
        "    return val_idx, preds, best_ll\n",
        "\n",
        "# Train 5 folds\n",
        "print(\"==== Begin 5-fold training (EffB2-NS 320px) ====\", flush=True)\n",
        "oof = np.zeros(len(df), dtype=np.float32)\n",
        "fold_scores = {}\n",
        "total_start = time.time()\n",
        "for f in range(5):\n",
        "    print(f\"==== Start Fold {f} ====\", flush=True)\n",
        "    val_idx, preds, best_ll = train_one_fold(f)\n",
        "    oof[val_idx] = preds\n",
        "    fold_scores[f] = best_ll\n",
        "    print(f\"[EffB2-NS] Fold {f} best val_logloss: {best_ll:.5f}\", flush=True)\n",
        "\n",
        "oof_ll = log_loss(df['label'].values, np.clip(oof, 1e-6, 1-1e-6))\n",
        "print(f\"EffB2-NS OOF log-loss (5 folds): {oof_ll:.5f}\", flush=True)\n",
        "pd.Series(fold_scores).to_csv('fold_scores_b2.csv')\n",
        "pd.DataFrame({'filepath': df['filepath'], 'label': df['label'], 'oof': oof}).to_csv('oof_b2.csv', index=False)\n",
        "\n",
        "# Inference: 5 EMA checkpoints + HFlip TTA\n",
        "@torch.no_grad()\n",
        "def load_fold(fold):\n",
        "    m = build_model().to(device)\n",
        "    ckpt = torch.load(f'model_b2_fold{fold}_ema.pt', map_location='cpu')\n",
        "    m.load_state_dict(ckpt['state_dict']); m.eval()\n",
        "    return m\n",
        "\n",
        "models = {f: load_fold(f) for f in range(5)}\n",
        "test_ds = DogCatDataset(test_df, valid_aug)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_tta(models_dict, loader):\n",
        "    out = []\n",
        "    for imgs, ids in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            p_sum = None\n",
        "            for m in models_dict.values():\n",
        "                p = torch.sigmoid(m(imgs).squeeze(1))\n",
        "                p_sum = p if p_sum is None else p_sum + p\n",
        "            imgs_f = torch.flip(imgs, dims=[3])\n",
        "            for m in models_dict.values():\n",
        "                p_sum += torch.sigmoid(m(imgs_f).squeeze(1))\n",
        "        p_avg = (p_sum / (len(models_dict)*2)).float().cpu().numpy()\n",
        "        out.append(p_avg)\n",
        "    return np.concatenate(out)\n",
        "\n",
        "print(\"Predicting test with 5-fold EMA ensemble (EffB2-NS 320px)...\", flush=True)\n",
        "test_probs = predict_tta(models, test_loader)\n",
        "test_ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({'id': test_ids, 'label': np.clip(test_probs, 1e-6, 1-1e-6)})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (EffB2-NS 320). Head:\\n', sub.head(), flush=True)\n",
        "print(f\"Total elapsed: {(time.time()-total_start)/60:.1f} min\", flush=True)\n",
        "\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7817d4f1-7baa-4612-8451-a18155830ee5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plan D: EfficientNet-B0.ra_in1k @320, 5-fold, EMA, Cosine LR, LS=0.05, MixUp=0.1, AMP, fixed OOF, HFlip TTA (cached weights)\n",
        "import os, time, gc, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from sklearn.metrics import log_loss\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "print(\"[Plan D] Starting cell: efficientnet_b0.ra_in1k @320 (cached)\", flush=True)\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "os.environ['PYTHONUNBUFFERED'] = '1'\n",
        "\n",
        "# Cache\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'\n",
        "LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HF_HUB_OFFLINE'] = '1'\n",
        "\n",
        "# Config\n",
        "MODEL_NAME = 'efficientnet_b0.ra_in1k'\n",
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-2\n",
        "LABEL_SMOOTH = 0.05\n",
        "MIXUP_ALPHA = 0.1\n",
        "EMA_DECAY = 0.9997\n",
        "WARMUP_EPOCHS = 1\n",
        "NUM_WORKERS = 0\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "df = pd.read_csv('train_folds.csv')\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "\n",
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, df, aug):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['label'].values if 'label' in df.columns else None\n",
        "        self.aug = aug\n",
        "    def __len__(self): return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        if self.aug is not None:\n",
        "            img = self.aug(img)\n",
        "        if self.labels is None:\n",
        "            return img, Path(fp).stem\n",
        "        return img, np.float32(self.labels[idx])\n",
        "\n",
        "train_aug = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0), ratio=(0.75, 1.3333)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "valid_aug = T.Compose([\n",
        "    T.Resize(IMG_SIZE),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "def build_model():\n",
        "    return timm.create_model(MODEL_NAME, pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE))\n",
        "\n",
        "# Pre-init (cached)\n",
        "print(f\"Pre-initializing '{MODEL_NAME}' (cached)...\", flush=True)\n",
        "try:\n",
        "    _m = build_model()\n",
        "    del _m\n",
        "    print(\"Model pre-init OK.\", flush=True)\n",
        "except Exception as e:\n",
        "    print(f\"Model pre-init failed: {e}\", flush=True)\n",
        "\n",
        "def mixup_batch(x, y, alpha):\n",
        "    if alpha is None or alpha <= 0:\n",
        "        return x, y\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "    x_m = lam * x + (1 - lam) * x[idx]\n",
        "    y = y.view(-1, 1)\n",
        "    y_m = lam * y + (1 - lam) * y[idx]\n",
        "    return x_m, y_m.squeeze(1)\n",
        "\n",
        "def train_one_fold(fold):\n",
        "    print(f\"\\n[EffB0-RA] Fold {fold} @ {IMG_SIZE}px\", flush=True)\n",
        "    trn_idx = df.index[df.fold != fold].values\n",
        "    val_idx = df.index[df.fold == fold].values\n",
        "    trn_df = df.loc[trn_idx]\n",
        "    val_df = df.loc[val_idx]\n",
        "    trn_loader = DataLoader(DogCatDataset(trn_df, train_aug), batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(device)\n",
        "    ema = ModelEmaV2(model, decay=EMA_DECAY, device=device if device.type=='cuda' else None)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS - WARMUP_EPOCHS)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type=='cuda'))\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "    best_ll = 1e9\n",
        "    best_path = f'model_b0_fold{fold}_ema.pt'\n",
        "    mixup_enabled = True if (MIXUP_ALPHA is not None and MIXUP_ALPHA > 0) else False\n",
        "\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        t0 = time.time(); run_loss = 0.0; n = 0\n",
        "        if epoch <= WARMUP_EPOCHS:\n",
        "            for pg in optimizer.param_groups:\n",
        "                pg['lr'] = LR * epoch / max(1, WARMUP_EPOCHS)\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "        for step, (imgs, labels) in enumerate(trn_loader):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            targets = labels * (1 - LABEL_SMOOTH) + (1 - labels) * LABEL_SMOOTH\n",
        "            if mixup_enabled:\n",
        "                imgs, targets = mixup_batch(imgs, targets, alpha=MIXUP_ALPHA)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                logits = model(imgs).squeeze(1)\n",
        "                loss = criterion(logits, targets).mean()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            ema.update(model)\n",
        "            run_loss += loss.item() * imgs.size(0); n += imgs.size(0)\n",
        "            if (step+1) % 100 == 0:\n",
        "                cur_lr = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Fold {fold} Ep{epoch} {step+1}/{len(trn_loader)} loss {run_loss/max(1,n):.4f} lr {cur_lr:.2e}\", flush=True)\n",
        "\n",
        "        if epoch == 1 and mixup_enabled and (run_loss/max(1,n) > 0.69):\n",
        "            mixup_enabled = False\n",
        "            print(\"  Disabling MixUp due to unstable first-epoch loss.\", flush=True)\n",
        "\n",
        "        model.eval()\n",
        "        val_probs = []; val_targets = []\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs = imgs.to(device)\n",
        "                with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                    logits = ema.module(imgs).squeeze(1)\n",
        "                    probs = torch.sigmoid(logits)\n",
        "                val_probs.append(probs.float().cpu().numpy())\n",
        "                val_targets.append(labels.numpy())\n",
        "        val_probs = np.concatenate(val_probs); val_targets = np.concatenate(val_targets)\n",
        "        ll = log_loss(val_targets, np.clip(val_probs, 1e-6, 1-1e-6))\n",
        "        print(f\"Epoch {epoch}: tr_loss={run_loss/max(1,n):.4f} val_logloss={ll:.5f} time={time.time()-t0:.1f}s\", flush=True)\n",
        "        if ll < best_ll:\n",
        "            best_ll = ll\n",
        "            torch.save({'state_dict': ema.module.state_dict(), 'val_logloss': best_ll}, best_path)\n",
        "            print(f\"  Saved EMA -> {best_path} ({best_ll:.5f})\", flush=True)\n",
        "\n",
        "    ckpt = torch.load(best_path, map_location='cpu')\n",
        "    ema_model = build_model().to(device)\n",
        "    ema_model.load_state_dict(ckpt['state_dict'])\n",
        "    ema_model.eval()\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, valid_aug), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in val_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                p = torch.sigmoid(ema_model(imgs).squeeze(1))\n",
        "            preds.append(p.float().cpu().numpy())\n",
        "    preds = np.concatenate(preds)\n",
        "    return val_idx, preds, best_ll\n",
        "\n",
        "print(\"==== Begin 5-fold training (EffB0-RA 320px) ====\", flush=True)\n",
        "oof = np.zeros(len(df), dtype=np.float32)\n",
        "fold_scores = {}\n",
        "total_start = time.time()\n",
        "for f in range(5):\n",
        "    print(f\"==== Start Fold {f} ====\", flush=True)\n",
        "    val_idx, preds, best_ll = train_one_fold(f)\n",
        "    oof[val_idx] = preds\n",
        "    fold_scores[f] = best_ll\n",
        "    print(f\"[EffB0-RA] Fold {f} best val_logloss: {best_ll:.5f}\", flush=True)\n",
        "\n",
        "oof_ll = log_loss(df['label'].values, np.clip(oof, 1e-6, 1-1e-6))\n",
        "print(f\"EffB0-RA OOF log-loss (5 folds): {oof_ll:.5f}\", flush=True)\n",
        "pd.Series(fold_scores).to_csv('fold_scores_b0_ra.csv')\n",
        "pd.DataFrame({'filepath': df['filepath'], 'label': df['label'], 'oof': oof}).to_csv('oof_b0_ra.csv', index=False)\n",
        "\n",
        "@torch.no_grad()\n",
        "def load_fold(fold):\n",
        "    m = build_model().to(device)\n",
        "    ckpt = torch.load(f'model_b0_fold{fold}_ema.pt', map_location='cpu')\n",
        "    m.load_state_dict(ckpt['state_dict']); m.eval()\n",
        "    return m\n",
        "\n",
        "models = {f: load_fold(f) for f in range(5)}\n",
        "test_ds = DogCatDataset(test_df, valid_aug)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_tta(models_dict, loader):\n",
        "    out = []\n",
        "    for imgs, ids in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            p_sum = None\n",
        "            for m in models_dict.values():\n",
        "                p = torch.sigmoid(m(imgs).squeeze(1))\n",
        "                p_sum = p if p_sum is None else p_sum + p\n",
        "            imgs_f = torch.flip(imgs, dims=[3])\n",
        "            for m in models_dict.values():\n",
        "                p_sum += torch.sigmoid(m(imgs_f).squeeze(1))\n",
        "        p_avg = (p_sum / (len(models_dict)*2)).float().cpu().numpy()\n",
        "        out.append(p_avg)\n",
        "    return np.concatenate(out)\n",
        "\n",
        "print(\"Predicting test with 5-fold EMA ensemble (EffB0-RA 320px)...\", flush=True)\n",
        "test_probs = predict_tta(models, test_loader)\n",
        "test_ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({'id': test_ids, 'label': np.clip(test_probs, 1e-6, 1-1e-6)})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (EffB0-RA 320). Head:\\n', sub.head(), flush=True)\n",
        "print(f\"Total elapsed: {(time.time()-total_start)/60:.1f} min\", flush=True)\n",
        "\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "1b7889de-5611-4b77-90bf-763ba6e274ce",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Debug Plan D imports/model init (cached, offline) to pinpoint hang\n",
        "import os, time\n",
        "from pathlib import Path\n",
        "print(\"[DEBUG D] start\", flush=True)\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HF_HUB_OFFLINE'] = '1'\n",
        "t0 = time.time()\n",
        "print(\"[DEBUG D] importing torch,timm...\", flush=True)\n",
        "import torch, timm\n",
        "print(\"[DEBUG D] torch\", torch.__version__, \"cuda\", torch.cuda.is_available(), flush=True)\n",
        "print(\"[DEBUG D] timm\", timm.__version__, flush=True)\n",
        "print(\"[DEBUG D] building efficientnet_b0.ra_in1k pretrained=True from cache...\", flush=True)\n",
        "m = timm.create_model('efficientnet_b0.ra_in1k', pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE))\n",
        "n_params = sum(p.numel() for p in m.parameters())\n",
        "print(f\"[DEBUG D] model ok, params={n_params}, elapsed={time.time()-t0:.2f}s\", flush=True)\n",
        "del m\n",
        "print(\"[DEBUG D] end\", flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "3f831f60-3d9a-4981-8bec-c89057a855f6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Debug 2: minimal timm usage without accessing __version__; test pretrained=False then True (cached)\n",
        "import os, time\n",
        "from pathlib import Path\n",
        "print('[DEBUG D2] start', flush=True)\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HF_HUB_OFFLINE'] = '1'\n",
        "t0 = time.time()\n",
        "import torch, timm\n",
        "print('[DEBUG D2] imports ok; cuda:', torch.cuda.is_available(), flush=True)\n",
        "print('[DEBUG D2] creating model pretrained=False...', flush=True)\n",
        "m = timm.create_model('efficientnet_b0.ra_in1k', pretrained=False, num_classes=1, scriptable=False)\n",
        "n_params = sum(p.numel() for p in m.parameters())\n",
        "print(f'[DEBUG D2] model (pretrained=False) ok, params={n_params}', flush=True)\n",
        "del m\n",
        "print('[DEBUG D2] creating model pretrained=True (from cache)...', flush=True)\n",
        "t1 = time.time()\n",
        "m2 = timm.create_model('efficientnet_b0.ra_in1k', pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE), scriptable=False)\n",
        "print(f'[DEBUG D2] pretrained=True model ok, elapsed={time.time()-t1:.2f}s total={time.time()-t0:.2f}s', flush=True)\n",
        "del m2\n",
        "print('[DEBUG D2] end', flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "52076245-90c0-4fe5-8621-1cc012dbc12c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plan E (Fixes): EffNet-B0.ra_in1k with timm default transforms (bicubic), no MixUp, low LS, optional EMA vs raw eval, drop_rate=0.2\n",
        "import os, time, gc, random, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import log_loss\n",
        "from PIL import Image\n",
        "\n",
        "print('[Plan E] Starting: EffB0-RA fixed preprocessing @384, MixUp OFF, LS low, EMA vs RAW', flush=True)\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "os.environ['PYTHONUNBUFFERED'] = '1'\n",
        "\n",
        "# Cache / Offline\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'; LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HF_HUB_OFFLINE'] = '1'\n",
        "\n",
        "# Config per expert guidance\n",
        "MODEL_NAME = 'efficientnet_b0.ra_in1k'\n",
        "IMG_SIZE = 384\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 18\n",
        "LR = 2e-4\n",
        "WEIGHT_DECAY = 5e-3\n",
        "LABEL_SMOOTH = 0.02  # 0.0..0.05 recommended\n",
        "MIXUP_ALPHA = 0.0     # OFF\n",
        "EMA_DECAY = 0.9997\n",
        "WARMUP_EPOCHS = 1\n",
        "NUM_WORKERS = 0\n",
        "DROP_RATE = 0.2\n",
        "\n",
        "df = pd.read_csv('train_folds.csv')\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "\n",
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['label'].values if 'label' in df.columns else None\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        img = self.transform(img) if self.transform is not None else img\n",
        "        if self.labels is None:\n",
        "            return img, Path(fp).stem\n",
        "        return img, np.float32(self.labels[idx])\n",
        "\n",
        "def build_model():\n",
        "    import timm\n",
        "    # drop_rate for head regularization; num_classes=1 for BCE\n",
        "    m = timm.create_model(MODEL_NAME, pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE), drop_rate=DROP_RATE)\n",
        "    return m\n",
        "\n",
        "def build_transforms():\n",
        "    # Use timm default cfg (ensures bicubic, mean/std, crop_pct, etc.)\n",
        "    import timm\n",
        "    from timm.data import resolve_data_config, create_transform\n",
        "    tmp = timm.create_model(MODEL_NAME, pretrained=False, num_classes=1)\n",
        "    cfg = resolve_data_config({}, model=tmp)  # start from model defaults\n",
        "    # Override input size to requested IMG_SIZE while keeping other defaults\n",
        "    cfg['input_size'] = (3, IMG_SIZE, IMG_SIZE)\n",
        "    tfm_train = create_transform(is_training=True, **cfg)\n",
        "    tfm_valid = create_transform(is_training=False, **cfg)\n",
        "    del tmp\n",
        "    return tfm_train, tfm_valid\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    probs_all, targs_all = [], []\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            logits = model(imgs).squeeze(1)\n",
        "            probs = torch.sigmoid(logits)\n",
        "        probs_all.append(probs.float().cpu().numpy())\n",
        "        targs_all.append(labels.numpy())\n",
        "    probs_all = np.concatenate(probs_all)\n",
        "    targs_all = np.concatenate(targs_all)\n",
        "    ll = log_loss(targs_all, np.clip(probs_all, 1e-6, 1-1e-6))\n",
        "    return ll, probs_all\n",
        "\n",
        "def train_one_fold(fold, tfm_train, tfm_valid):\n",
        "    print(f\"\\n[Plan E] Fold {fold} @ {IMG_SIZE}px\", flush=True)\n",
        "    from timm.utils import ModelEmaV2  # lazy import to avoid early timm import\n",
        "    trn_df = df[df.fold != fold].reset_index(drop=True)\n",
        "    val_df = df[df.fold == fold].reset_index(drop=True)\n",
        "    trn_loader = DataLoader(DogCatDataset(trn_df, tfm_train), batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, tfm_valid), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(device)\n",
        "    ema = ModelEmaV2(model, decay=EMA_DECAY, device=device if device.type=='cuda' else None)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n",
        "    criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "    # Cosine with warmup\n",
        "    def lr_lambda(epoch):\n",
        "        if epoch < WARMUP_EPOCHS:\n",
        "            return float(epoch + 1) / float(max(1, WARMUP_EPOCHS))\n",
        "        progress = (epoch - WARMUP_EPOCHS) / float(max(1, EPOCHS - WARMUP_EPOCHS))\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "    best_ll = 1e9\n",
        "    best_variant = 'raw'\n",
        "    best_path = f'model_b0e_fold{fold}.pt'\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        run_loss, n = 0.0, 0\n",
        "        t0 = time.time()\n",
        "        for step, (imgs, labels) in enumerate(trn_loader):\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # label smoothing\n",
        "            targets = labels * (1.0 - LABEL_SMOOTH) + (1.0 - labels) * LABEL_SMOOTH\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "                logits = model(imgs).squeeze(1)\n",
        "                loss = criterion(logits, targets).mean()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            ema.update(model)\n",
        "            run_loss += loss.item() * imgs.size(0)\n",
        "            n += imgs.size(0)\n",
        "            if (step + 1) % 100 == 0:\n",
        "                cur_lr = optimizer.param_groups[0]['lr']\n",
        "                print(f\"Fold {fold} Ep{epoch+1} {step+1}/{len(trn_loader)} loss {run_loss/max(1,n):.4f} lr {cur_lr:.2e}\", flush=True)\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validate RAW\n",
        "        ll_raw, _ = evaluate_model(model, val_loader)\n",
        "        # Validate EMA\n",
        "        ll_ema, _ = evaluate_model(ema.module, val_loader)\n",
        "        cur_ll = min(ll_raw, ll_ema)\n",
        "        variant = 'raw' if ll_raw <= ll_ema else 'ema'\n",
        "        print(f\"Epoch {epoch+1}: tr_loss={run_loss/max(1,n):.4f} val_raw={ll_raw:.5f} val_ema={ll_ema:.5f} -> best_this_epoch={cur_ll:.5f} ({variant}) time={time.time()-t0:.1f}s\", flush=True)\n",
        "        if cur_ll < best_ll:\n",
        "            best_ll = cur_ll\n",
        "            best_variant = variant\n",
        "            if variant == 'raw':\n",
        "                torch.save({'state_dict': model.state_dict(), 'val_logloss': best_ll, 'variant': 'raw'}, best_path)\n",
        "            else:\n",
        "                torch.save({'state_dict': ema.module.state_dict(), 'val_logloss': best_ll, 'variant': 'ema'}, best_path)\n",
        "            print(f\"  Saved best ({best_variant}) -> {best_path} ({best_ll:.5f})\", flush=True)\n",
        "\n",
        "    # Load best and compute OOF\n",
        "    ckpt = torch.load(best_path, map_location='cpu')\n",
        "    best_model = build_model().to(device)\n",
        "    best_model.load_state_dict(ckpt['state_dict'])\n",
        "    best_model.eval()\n",
        "    val_loader = DataLoader(DogCatDataset(val_df, tfm_valid), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "    _, oof_probs = evaluate_model(best_model, val_loader)\n",
        "    return (df[df.fold == fold].index.values), oof_probs, best_ll\n",
        "\n",
        "# Build transforms once (fixed to model defaults with IMG_SIZE override)\n",
        "print('[Plan E] Building transforms with timm default_cfg (bicubic, mean/std, crop_pct)...', flush=True)\n",
        "tfm_train, tfm_valid = build_transforms()\n",
        "print('[Plan E] Transforms built. Starting training...', flush=True)\n",
        "\n",
        "# Train 5 folds\n",
        "print('==== Begin 5-fold training (EffB0-RA 384px, fixed) ====', flush=True)\n",
        "oof = np.zeros(len(df), dtype=np.float32)\n",
        "fold_scores = {}\n",
        "total_start = time.time()\n",
        "for f in range(5):\n",
        "    print(f'==== Start Fold {f} ====')\n",
        "    val_idx, preds, best_ll = train_one_fold(f, tfm_train, tfm_valid)\n",
        "    oof[val_idx] = preds  # correct OOF indexing\n",
        "    fold_scores[f] = best_ll\n",
        "    print(f\"[Plan E] Fold {f} best val_logloss: {best_ll:.5f}\", flush=True)\n",
        "\n",
        "oof_ll = log_loss(df['label'].values, np.clip(oof, 1e-6, 1-1e-6))\n",
        "print(f\"Plan E OOF log-loss (5 folds): {oof_ll:.5f}\", flush=True)\n",
        "pd.Series(fold_scores).to_csv('fold_scores_b0_e.csv')\n",
        "pd.DataFrame({'filepath': df['filepath'], 'label': df['label'], 'oof': oof}).to_csv('oof_b0_e.csv', index=False)\n",
        "\n",
        "# Inference with best checkpoints + simple HFlip TTA\n",
        "@torch.no_grad()\n",
        "def load_best_fold(fold):\n",
        "    m = build_model().to(device)\n",
        "    ckpt = torch.load(f'model_b0e_fold{fold}.pt', map_location='cpu')\n",
        "    m.load_state_dict(ckpt['state_dict']); m.eval()\n",
        "    return m\n",
        "\n",
        "models = {f: load_best_fold(f) for f in range(5)}\n",
        "test_tfm = tfm_valid  # use validation (center-crop) transform\n",
        "test_ds = DogCatDataset(test_df, test_tfm)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_tta(models_dict, loader):\n",
        "    out = []\n",
        "    for imgs, ids in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            p_sum = None\n",
        "            for m in models_dict.values():\n",
        "                p = torch.sigmoid(m(imgs).squeeze(1))\n",
        "                p_sum = p if p_sum is None else p_sum + p\n",
        "            imgs_f = torch.flip(imgs, dims=[3])\n",
        "            for m in models_dict.values():\n",
        "                p_sum += torch.sigmoid(m(imgs_f).squeeze(1))\n",
        "        p_avg = (p_sum / (len(models_dict)*2)).float().cpu().numpy()\n",
        "        out.append(p_avg)\n",
        "    return np.concatenate(out)\n",
        "\n",
        "print('Predicting test with 5-fold best (raw/ema) + HFlip TTA...', flush=True)\n",
        "test_probs = predict_tta(models, test_loader)\n",
        "test_ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({'id': test_ids, 'label': np.clip(test_probs, 1e-6, 1-1e-6)})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (Plan E). Head:\\n', sub.head(), flush=True)\n",
        "print(f'Total elapsed: {(time.time()-total_start)/60:.1f} min', flush=True)\n",
        "\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "id": "b9e7e48b-ad8c-48aa-899e-fcd18c020f3e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity check: verify kernel stdout responsiveness (no heavy imports)\n",
        "import time\n",
        "print('[SANITY] Kernel alive and printing. Timestamp:', time.time(), flush=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SANITY] Kernel alive and printing. Timestamp: 1757331351.3687549\n"
          ]
        }
      ]
    },
    {
      "id": "9451c0f6-cb2e-4a5d-817a-593af782d857",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Debug 3: verify timm.data transforms creation (bicubic cfg) works offline\n",
        "import os, time\n",
        "from pathlib import Path\n",
        "print('[DEBUG TFM] start', flush=True)\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HF_HUB_OFFLINE'] = '1'\n",
        "import torch, timm\n",
        "from timm.data import resolve_data_config, create_transform\n",
        "MODEL_NAME = 'efficientnet_b0.ra_in1k'; IMG_SIZE = 384\n",
        "print('[DEBUG TFM] imports ok; cuda:', torch.cuda.is_available(), flush=True)\n",
        "print('[DEBUG TFM] creating tmp model (pretrained=False)...', flush=True)\n",
        "tmp = timm.create_model(MODEL_NAME, pretrained=False, num_classes=1)\n",
        "cfg = resolve_data_config({}, model=tmp)\n",
        "print('[DEBUG TFM] cfg interp before:', cfg.get('interpolation'), 'input_size before:', cfg.get('input_size'), flush=True)\n",
        "cfg['input_size'] = (3, IMG_SIZE, IMG_SIZE)\n",
        "tfm_train = create_transform(is_training=True, **cfg)\n",
        "tfm_valid = create_transform(is_training=False, **cfg)\n",
        "del tmp\n",
        "print('[DEBUG TFM] transforms created OK; interp:', cfg.get('interpolation'), 'input_size:', cfg.get('input_size'), flush=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG TFM] start\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG TFM] imports ok; cuda: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG TFM] creating tmp model (pretrained=False)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG TFM] cfg interp before: bicubic input_size before: (3, 224, 224)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG TFM] transforms created OK; interp: bicubic input_size: (3, 384, 384)\n"
          ]
        }
      ]
    },
    {
      "id": "29f376e3-8e6a-4b54-81ca-347e5f1e758f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plan E-mini: run a quick Fold 0 sanity (5 epochs) with fixed preprocessing to verify val_logloss trajectory\n",
        "import os, time, math, random, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import log_loss\n",
        "from PIL import Image\n",
        "\n",
        "print('[Plan E-mini] Start Fold 0 sanity run', flush=True)\n",
        "SEED=42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'; LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HF_HUB_OFFLINE'] = '1'\n",
        "\n",
        "MODEL_NAME = 'efficientnet_b0.ra_in1k'\n",
        "IMG_SIZE = 384\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "LR = 2e-4\n",
        "WEIGHT_DECAY = 5e-3\n",
        "LABEL_SMOOTH = 0.02\n",
        "EMA_DECAY = 0.9997\n",
        "NUM_WORKERS = 0\n",
        "DROP_RATE = 0.2\n",
        "\n",
        "df = pd.read_csv('train_folds.csv')\n",
        "\n",
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['label'].values if 'label' in df.columns else None\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        img = self.transform(img) if self.transform is not None else img\n",
        "        if self.labels is None: return img, Path(fp).stem\n",
        "        return img, np.float32(self.labels[idx])\n",
        "\n",
        "print('[Plan E-mini] Building transforms (timm default cfg, bicubic)...', flush=True)\n",
        "import timm\n",
        "from timm.data import resolve_data_config, create_transform\n",
        "tmp = timm.create_model(MODEL_NAME, pretrained=False, num_classes=1)\n",
        "cfg = resolve_data_config({}, model=tmp)\n",
        "cfg['input_size'] = (3, IMG_SIZE, IMG_SIZE)\n",
        "tfm_train = create_transform(is_training=True, **cfg)\n",
        "tfm_valid = create_transform(is_training=False, **cfg)\n",
        "del tmp\n",
        "print('[Plan E-mini] Transforms ready', flush=True)\n",
        "\n",
        "def build_model():\n",
        "    import timm\n",
        "    return timm.create_model(MODEL_NAME, pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE), drop_rate=DROP_RATE)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    probs_all, targs_all = [], []\n",
        "    for imgs, labels in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            logits = model(imgs).squeeze(1)\n",
        "            probs = torch.sigmoid(logits)\n",
        "        probs_all.append(probs.float().cpu().numpy())\n",
        "        targs_all.append(labels.numpy())\n",
        "    probs_all = np.concatenate(probs_all)\n",
        "    targs_all = np.concatenate(targs_all)\n",
        "    ll = log_loss(targs_all, np.clip(probs_all, 1e-6, 1-1e-6))\n",
        "    return ll\n",
        "\n",
        "from timm.utils import ModelEmaV2\n",
        "fold = 0\n",
        "trn_df = df[df.fold != fold].reset_index(drop=True)\n",
        "val_df = df[df.fold == fold].reset_index(drop=True)\n",
        "trn_loader = DataLoader(DogCatDataset(trn_df, tfm_train), batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "val_loader = DataLoader(DogCatDataset(val_df, tfm_valid), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "model = build_model().to(device)\n",
        "ema = ModelEmaV2(model, decay=EMA_DECAY, device=device if device.type=='cuda' else None)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n",
        "criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "def lr_lambda(epoch):\n",
        "    if epoch < 1: return float(epoch + 1)\n",
        "    progress = (epoch - 1) / float(max(1, EPOCHS - 1))\n",
        "    return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
        "\n",
        "best_ll = 1e9; best_variant='raw'\n",
        "print(f\"[Plan E-mini] Training Fold {fold} for {EPOCHS} epochs...\", flush=True)\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    run_loss, n = 0.0, 0\n",
        "    t0 = time.time()\n",
        "    for step, (imgs, labels) in enumerate(trn_loader):\n",
        "        imgs = imgs.to(device); labels = labels.to(device)\n",
        "        targets = labels * (1.0 - LABEL_SMOOTH) + (1.0 - labels) * LABEL_SMOOTH\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            logits = model(imgs).squeeze(1)\n",
        "            loss = criterion(logits, targets).mean()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer); scaler.update()\n",
        "        ema.update(model)\n",
        "        run_loss += loss.item() * imgs.size(0); n += imgs.size(0)\n",
        "        if (step+1) % 100 == 0:\n",
        "            print(f\"Ep{epoch+1} {step+1}/{len(trn_loader)} loss {run_loss/max(1,n):.4f}\", flush=True)\n",
        "    scheduler.step()\n",
        "    # Validate RAW vs EMA\n",
        "    ll_raw = evaluate_model(model, val_loader)\n",
        "    ll_ema = evaluate_model(ema.module, val_loader)\n",
        "    cur_ll = min(ll_raw, ll_ema)\n",
        "    variant = 'raw' if ll_raw <= ll_ema else 'ema'\n",
        "    print(f\"Epoch {epoch+1}: tr_loss={run_loss/max(1,n):.4f} val_raw={ll_raw:.5f} val_ema={ll_ema:.5f} -> {cur_ll:.5f} ({variant}) time={time.time()-t0:.1f}s\", flush=True)\n",
        "    best_ll = min(best_ll, cur_ll)\n",
        "\n",
        "print(f\"[Plan E-mini] Fold {fold} best val_logloss (5 epochs): {best_ll:.5f}\", flush=True)\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Plan E-mini] Start Fold 0 sanity run\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Plan E-mini] Building transforms (timm default cfg, bicubic)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Plan E-mini] Transforms ready\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Plan E-mini] Training Fold 0 for 5 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:93: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep1 100/562 loss 0.8230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep1 200/562 loss 0.6540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep1 300/562 loss 0.5712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep1 400/562 loss 0.5216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep1 500/562 loss 0.4874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: tr_loss=0.4723 val_raw=0.05012 val_ema=1.58407 -> 0.05012 (raw) time=458.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep2 100/562 loss 0.3138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep2 200/562 loss 0.3059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep2 300/562 loss 0.3011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep2 400/562 loss 0.2894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep2 500/562 loss 0.2858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: tr_loss=0.2828 val_raw=0.03360 val_ema=0.54930 -> 0.03360 (raw) time=397.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep3 100/562 loss 0.2528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep3 200/562 loss 0.2500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep3 300/562 loss 0.2400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep3 400/562 loss 0.2373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep3 500/562 loss 0.2365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: tr_loss=0.2339 val_raw=0.05277 val_ema=0.17513 -> 0.05277 (raw) time=397.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep4 100/562 loss 0.2044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep4 200/562 loss 0.2064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep4 300/562 loss 0.2050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep4 400/562 loss 0.2002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep4 500/562 loss 0.2009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: tr_loss=0.2002 val_raw=0.03691 val_ema=0.07385 -> 0.03691 (raw) time=398.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:112: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep5 100/562 loss 0.1857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep5 200/562 loss 0.1819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep5 300/562 loss 0.1828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep5 400/562 loss 0.1836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep5 500/562 loss 0.1826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/3197232839.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: tr_loss=0.1823 val_raw=0.03505 val_ema=0.04446 -> 0.03505 (raw) time=397.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Plan E-mini] Fold 0 best val_logloss (5 epochs): 0.03360\n"
          ]
        }
      ]
    },
    {
      "id": "6f3837a5-a1c2-49cb-82f9-45192cec7a45",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Temperature scaling for Plan E (EffB0-RA @384); optimize T on OOF and apply to test\n",
        "import os, math, time, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import log_loss\n",
        "from PIL import Image\n",
        "\n",
        "print('[TempScale] Starting temperature scaling for Plan E...', flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Constants (must match Plan E)\n",
        "MODEL_NAME = 'efficientnet_b0.ra_in1k'\n",
        "IMG_SIZE = 384\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 0\n",
        "DROP_RATE = 0.2\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'; LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HF_HUB_OFFLINE'] = '1'\n",
        "\n",
        "def build_model():\n",
        "    import timm\n",
        "    m = timm.create_model(MODEL_NAME, pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE), drop_rate=DROP_RATE)\n",
        "    return m\n",
        "\n",
        "def build_transforms():\n",
        "    import timm\n",
        "    from timm.data import resolve_data_config, create_transform\n",
        "    tmp = timm.create_model(MODEL_NAME, pretrained=False, num_classes=1)\n",
        "    cfg = resolve_data_config({}, model=tmp)\n",
        "    cfg['input_size'] = (3, IMG_SIZE, IMG_SIZE)\n",
        "    tfm_valid = create_transform(is_training=False, **cfg)\n",
        "    del tmp\n",
        "    return tfm_valid\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        img = self.transform(img) if self.transform is not None else img\n",
        "        return img, Path(fp).stem\n",
        "\n",
        "# 1) Load OOF and optimize T\n",
        "oof_path = Path('oof_b0_e.csv')\n",
        "assert oof_path.exists(), 'oof_b0_e.csv not found; run Plan E training first.'\n",
        "oof_df = pd.read_csv(oof_path)\n",
        "# Safety checks\n",
        "assert len(oof_df) > 0, 'Empty OOF file'\n",
        "assert oof_df[['label','oof']].notna().all().all(), 'NaNs found in OOF file'\n",
        "y_true = oof_df['label'].values.astype(np.float64)\n",
        "p = np.clip(oof_df['oof'].values.astype(np.float64), 1e-7, 1-1e-7)\n",
        "logits = np.log(p/(1.0-p))  # float64 by construction\n",
        "base_ll = log_loss(y_true, p)\n",
        "print(f\"[TempScale] Base OOF logloss={base_ll:.6f} (rows={len(oof_df)})\", flush=True)\n",
        "\n",
        "def loss_for_T(T):\n",
        "    if T <= 1e-4 or T > 100.0:\n",
        "        return np.inf\n",
        "    ps = 1.0 / (1.0 + np.exp(-logits / T))\n",
        "    ps = np.clip(ps, 1e-7, 1-1e-7)\n",
        "    return log_loss(y_true, ps)\n",
        "\n",
        "# Coarse-to-fine search on T (expanded range 0.3..5.0)\n",
        "grid1 = np.exp(np.linspace(np.log(0.3), np.log(5.0), 401))\n",
        "vals1 = [loss_for_T(t) for t in grid1]\n",
        "best_idx = int(np.argmin(vals1)); T_best = float(grid1[best_idx]); ll_best = float(vals1[best_idx])\n",
        "lo, hi = T_best*0.8, T_best*1.2\n",
        "grid2 = np.exp(np.linspace(np.log(max(0.1, lo)), np.log(min(10.0, hi)), 201))\n",
        "vals2 = [loss_for_T(t) for t in grid2]\n",
        "best2 = int(np.argmin(vals2)); T_best = float(grid2[best2]); ll_best = float(vals2[best2])\n",
        "\n",
        "print(f\"[TempScale] Calibrated (T={T_best:.6f}) OOF logloss={ll_best:.6f}\", flush=True)\n",
        "with open('temperature.txt', 'w') as f: f.write(f\"{T_best}\\n\")\n",
        "\n",
        "# 2) Re-run test inference with temperature scaling applied to logits before sigmoid\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "tfm_valid = build_transforms()\n",
        "test_ds = ImageDataset(test_df, tfm_valid)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def load_best_fold(fold):\n",
        "    m = build_model().to(device)\n",
        "    ckpt = torch.load(f'model_b0e_fold{fold}.pt', map_location='cpu')\n",
        "    m.load_state_dict(ckpt['state_dict']); m.eval()\n",
        "    return m\n",
        "\n",
        "# Ensure all checkpoints exist before loading\n",
        "for f in range(5):\n",
        "    ck = Path(f'model_b0e_fold{f}.pt')\n",
        "    assert ck.exists(), f'Missing checkpoint: {ck}'\n",
        "\n",
        "models = {f: load_best_fold(f) for f in range(5)}\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_tta_temp(models_dict, loader, T_temp):\n",
        "    all_probs = []\n",
        "    for imgs, ids in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            probs_sum = None\n",
        "            for m in models_dict.values():\n",
        "                logits_b = m(imgs).squeeze(1)\n",
        "                p_b = torch.sigmoid(logits_b / T_temp)\n",
        "                probs_sum = p_b if probs_sum is None else probs_sum + p_b\n",
        "            imgs_f = torch.flip(imgs, dims=[3])\n",
        "            for m in models_dict.values():\n",
        "                logits_f = m(imgs_f).squeeze(1)\n",
        "                probs_sum = probs_sum + torch.sigmoid(logits_f / T_temp)\n",
        "        probs_avg = (probs_sum / (len(models_dict)*2)).float().cpu().numpy()\n",
        "        all_probs.append(probs_avg)\n",
        "    return np.concatenate(all_probs)\n",
        "\n",
        "print('[TempScale] Predicting test with temperature scaling...', flush=True)\n",
        "t0 = time.time()\n",
        "test_probs = predict_tta_temp(models, test_loader, T_best)\n",
        "ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({'id': ids, 'label': np.clip(test_probs, 1e-7, 1-1e-7)})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print(f\"[TempScale] Saved submission.csv with T={T_best:.6f}. Inference time: {time.time()-t0:.1f}s\", flush=True)\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "id": "d7f873c4-a92d-44b1-98bf-c548551f6d0b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plan E Finalization: Build OOF from saved checkpoints, temperature scale, and generate submission\n",
        "import os, time, gc, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import log_loss\n",
        "from PIL import Image\n",
        "\n",
        "print('[Finalize] Starting OOF rebuild + TempScale + Submission for Plan E...', flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Constants (match Plan E)\n",
        "MODEL_NAME = 'efficientnet_b0.ra_in1k'\n",
        "IMG_SIZE = 384\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 0\n",
        "DROP_RATE = 0.2\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'; LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HF_HUB_OFFLINE'] = '1'\n",
        "\n",
        "df = pd.read_csv('train_folds.csv')\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "\n",
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.labels = df['label'].values if 'label' in df.columns else None\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        img = self.transform(img) if self.transform is not None else img\n",
        "        if self.labels is None:\n",
        "            return img, Path(fp).stem\n",
        "        return img, np.float32(self.labels[idx])\n",
        "\n",
        "def build_model():\n",
        "    import timm\n",
        "    return timm.create_model(MODEL_NAME, pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE), drop_rate=DROP_RATE)\n",
        "\n",
        "def build_tfm_valid():\n",
        "    import timm\n",
        "    from timm.data import resolve_data_config, create_transform\n",
        "    tmp = timm.create_model(MODEL_NAME, pretrained=False, num_classes=1)\n",
        "    cfg = resolve_data_config({}, model=tmp)\n",
        "    cfg['input_size'] = (3, IMG_SIZE, IMG_SIZE)\n",
        "    tfm_valid = create_transform(is_training=False, **cfg)\n",
        "    del tmp\n",
        "    return tfm_valid\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    probs_all, targs_all = [], []\n",
        "    for i,(imgs, labels) in enumerate(loader):\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            logits = model(imgs).squeeze(1)\n",
        "            probs = torch.sigmoid(logits)\n",
        "        probs_all.append(probs.float().cpu().numpy())\n",
        "        targs_all.append(labels.numpy())\n",
        "        if (i+1) % 50 == 0:\n",
        "            print(f'[Finalize] OOF eval batch {i+1}/{len(loader)}', flush=True)\n",
        "    probs_all = np.concatenate(probs_all)\n",
        "    targs_all = np.concatenate(targs_all)\n",
        "    ll = log_loss(targs_all, np.clip(probs_all, 1e-7, 1-1e-7))\n",
        "    return ll, probs_all\n",
        "\n",
        "@torch.no_grad()\n",
        "def load_best_fold(fold):\n",
        "    m = build_model().to(device)\n",
        "    ckpt = torch.load(f'model_b0e_fold{fold}.pt', map_location='cpu')\n",
        "    m.load_state_dict(ckpt['state_dict']); m.eval()\n",
        "    return m\n",
        "\n",
        "# Ensure checkpoints exist\n",
        "for f in range(5):\n",
        "    assert Path(f'model_b0e_fold{f}.pt').exists(), f'Missing model_b0e_fold{f}.pt'\n",
        "print('[Finalize] All 5 checkpoints present.', flush=True)\n",
        "\n",
        "# 1) Rebuild OOF if missing\n",
        "oof_path = Path('oof_b0_e.csv')\n",
        "tfm_valid = build_tfm_valid()\n",
        "if not oof_path.exists():\n",
        "    print('[Finalize] oof_b0_e.csv not found. Rebuilding OOF from checkpoints...', flush=True)\n",
        "    oof = np.zeros(len(df), dtype=np.float32)\n",
        "    fold_scores = {}\n",
        "    for fold in range(5):\n",
        "        val_df = df[df.fold == fold].reset_index(drop=True)\n",
        "        val_loader = DataLoader(DogCatDataset(val_df, tfm_valid), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "        model = load_best_fold(fold)\n",
        "        ll, preds = evaluate_model(model, val_loader)\n",
        "        oof[df.index[df.fold == fold].values] = preds\n",
        "        fold_scores[fold] = ll\n",
        "        print(f'[Finalize] Fold {fold} OOF val_logloss={ll:.6f}', flush=True)\n",
        "        del model; gc.collect(); torch.cuda.empty_cache()\n",
        "    oof_ll = log_loss(df['label'].values, np.clip(oof, 1e-7, 1-1e-7))\n",
        "    pd.Series(fold_scores).to_csv('fold_scores_b0_e.csv')\n",
        "    pd.DataFrame({'filepath': df['filepath'], 'label': df['label'], 'oof': oof}).to_csv('oof_b0_e.csv', index=False)\n",
        "    print(f'[Finalize] Saved OOF (oof_b0_e.csv). OOF logloss={oof_ll:.6f}', flush=True)\n",
        "else:\n",
        "    print('[Finalize] Found existing oof_b0_e.csv; skipping OOF rebuild.', flush=True)\n",
        "\n",
        "# 2) Temperature scaling on OOF\n",
        "oof_df = pd.read_csv('oof_b0_e.csv')\n",
        "assert len(oof_df) == len(df) and oof_df[['label','oof']].notna().all().all(), 'OOF integrity failed'\n",
        "y_true = oof_df['label'].values.astype(np.float64)\n",
        "p = np.clip(oof_df['oof'].values.astype(np.float64), 1e-7, 1-1e-7)\n",
        "logits = np.log(p/(1.0-p))\n",
        "base_ll = log_loss(y_true, p)\n",
        "print(f'[Finalize] Base OOF logloss={base_ll:.6f}', flush=True)\n",
        "\n",
        "def loss_for_T(T):\n",
        "    if T <= 1e-4 or T > 100.0: return np.inf\n",
        "    ps = 1.0 / (1.0 + np.exp(-logits / T))\n",
        "    ps = np.clip(ps, 1e-7, 1-1e-7)\n",
        "    return log_loss(y_true, ps)\n",
        "\n",
        "grid1 = np.exp(np.linspace(np.log(0.3), np.log(5.0), 401))\n",
        "vals1 = [loss_for_T(t) for t in grid1]\n",
        "T_best = float(grid1[int(np.argmin(vals1))])\n",
        "lo, hi = T_best*0.8, T_best*1.2\n",
        "grid2 = np.exp(np.linspace(np.log(max(0.1, lo)), np.log(min(10.0, hi)), 201))\n",
        "vals2 = [loss_for_T(t) for t in grid2]\n",
        "T_best = float(grid2[int(np.argmin(vals2))])\n",
        "ll_best = float(min(vals2))\n",
        "print(f'[Finalize] Calibrated T={T_best:.6f} | OOF logloss={ll_best:.6f}', flush=True)\n",
        "with open('temperature.txt', 'w') as f: f.write(f\"{T_best}\\n\")\n",
        "\n",
        "# 3) Test inference with TTA + temperature scaling\n",
        "@torch.no_grad()\n",
        "def predict_tta_temp(models_dict, loader, T_temp):\n",
        "    all_probs = []\n",
        "    for i,(imgs, ids) in enumerate(loader):\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            probs_sum = None\n",
        "            for m in models_dict.values():\n",
        "                logits_b = m(imgs).squeeze(1)\n",
        "                p_b = torch.sigmoid(logits_b / T_temp)\n",
        "                probs_sum = p_b if probs_sum is None else probs_sum + p_b\n",
        "            imgs_f = torch.flip(imgs, dims=[3])\n",
        "            for m in models_dict.values():\n",
        "                logits_f = m(imgs_f).squeeze(1)\n",
        "                probs_sum = probs_sum + torch.sigmoid(logits_f / T_temp)\n",
        "        probs_avg = (probs_sum / (len(models_dict)*2)).float().cpu().numpy()\n",
        "        all_probs.append(probs_avg)\n",
        "        if (i+1) % 50 == 0:\n",
        "            print(f'[Finalize] Test infer batch {i+1}/{len(loader)}', flush=True)\n",
        "    return np.concatenate(all_probs)\n",
        "\n",
        "print('[Finalize] Loading models for inference...', flush=True)\n",
        "models = {f: load_best_fold(f) for f in range(5)}\n",
        "test_tfm = build_tfm_valid()\n",
        "test_loader = DataLoader(DogCatDataset(test_df, test_tfm), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "print('[Finalize] Predicting test with TTA + temperature scaling...', flush=True)\n",
        "t0 = time.time()\n",
        "test_probs = predict_tta_temp(models, test_loader, T_best)\n",
        "ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({'id': ids, 'label': np.clip(test_probs, 1e-7, 1-1e-7)})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print(f'[Finalize] Saved submission.csv (T={T_best:.6f}). Inference time: {time.time()-t0:.1f}s', flush=True)\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "print('[Finalize] Done.', flush=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "id": "5285414d-5185-4e6c-a660-9401b24bfe43",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Minimal final inference (Plan E checkpoints, unscaled) with HFlip TTA to produce submission.csv\n",
        "import os, time, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "print('[QuickInfer] Starting minimal inference...', flush=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "MODEL_NAME = 'efficientnet_b0.ra_in1k'\n",
        "IMG_SIZE = 384\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 0\n",
        "DROP_RATE = 0.2\n",
        "LOCAL_CACHE = Path.cwd() / 'model_cache'; LOCAL_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['HF_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HUGGINGFACE_HUB_CACHE'] = str(LOCAL_CACHE)\n",
        "os.environ['XDG_CACHE_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TORCH_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['TIMM_HOME'] = str(LOCAL_CACHE)\n",
        "os.environ['HF_HUB_OFFLINE'] = '1'\n",
        "\n",
        "test_df = pd.read_csv('test_files.csv')\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.transform = transform\n",
        "    def __len__(self): return len(self.filepaths)\n",
        "    def __getitem__(self, idx):\n",
        "        fp = self.filepaths[idx]\n",
        "        img = Image.open(fp).convert('RGB')\n",
        "        img = self.transform(img) if self.transform is not None else img\n",
        "        return img, Path(fp).stem\n",
        "\n",
        "def build_model():\n",
        "    import timm\n",
        "    return timm.create_model(MODEL_NAME, pretrained=True, num_classes=1, cache_dir=str(LOCAL_CACHE), drop_rate=DROP_RATE)\n",
        "\n",
        "def build_valid_tfm():\n",
        "    import timm\n",
        "    from timm.data import resolve_data_config, create_transform\n",
        "    tmp = timm.create_model(MODEL_NAME, pretrained=False, num_classes=1)\n",
        "    cfg = resolve_data_config({}, model=tmp)\n",
        "    cfg['input_size'] = (3, IMG_SIZE, IMG_SIZE)\n",
        "    tfm = create_transform(is_training=False, **cfg)\n",
        "    del tmp\n",
        "    return tfm\n",
        "\n",
        "@torch.no_grad()\n",
        "def load_best_fold(fold):\n",
        "    m = build_model().to(device)\n",
        "    ckpt = torch.load(f'model_b0e_fold{fold}.pt', map_location='cpu')\n",
        "    m.load_state_dict(ckpt['state_dict']); m.eval()\n",
        "    return m\n",
        "\n",
        "# Checkpoints presence\n",
        "for f in range(5):\n",
        "    assert Path(f'model_b0e_fold{f}.pt').exists(), f'Missing model_b0e_fold{f}.pt'\n",
        "print('[QuickInfer] All checkpoints present.', flush=True)\n",
        "\n",
        "print('[QuickInfer] Loading models...', flush=True)\n",
        "models = {f: load_best_fold(f) for f in range(5)}\n",
        "tfm = build_valid_tfm()\n",
        "loader = DataLoader(TestDataset(test_df, tfm), batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(models_dict, loader):\n",
        "    out = []\n",
        "    for i, (imgs, ids) in enumerate(loader):\n",
        "        imgs = imgs.to(device)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "            p_sum = None\n",
        "            for m in models_dict.values():\n",
        "                p = torch.sigmoid(m(imgs).squeeze(1))\n",
        "                p_sum = p if p_sum is None else p_sum + p\n",
        "            imgs_f = torch.flip(imgs, dims=[3])\n",
        "            for m in models_dict.values():\n",
        "                p_sum = p_sum + torch.sigmoid(m(imgs_f).squeeze(1))\n",
        "        p_avg = (p_sum / (len(models_dict)*2)).float().cpu().numpy()\n",
        "        out.append(p_avg)\n",
        "        if (i+1) % 50 == 0:\n",
        "            print(f'[QuickInfer] Batch {i+1}/{len(loader)}', flush=True)\n",
        "    return np.concatenate(out)\n",
        "\n",
        "print('[QuickInfer] Predicting test...', flush=True)\n",
        "t0 = time.time()\n",
        "probs = predict(models, loader)\n",
        "ids = test_df['filepath'].apply(lambda p: int(Path(p).stem)).values\n",
        "sub = pd.DataFrame({'id': ids, 'label': np.clip(probs, 1e-7, 1-1e-7)})\n",
        "sub = sub.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print(f'[QuickInfer] Saved submission.csv. Inference time: {time.time()-t0:.1f}s', flush=True)\n",
        "gc.collect(); torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QuickInfer] Starting minimal inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QuickInfer] All checkpoints present.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QuickInfer] Loading models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QuickInfer] Predicting test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2569/765814410.py:76: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QuickInfer] Batch 50/79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QuickInfer] Saved submission.csv. Inference time: 63.1s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}