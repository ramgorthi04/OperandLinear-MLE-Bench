{
  "cells": [
    {
      "id": "dff7cbb1-b8c1-44fd-a551-3f32da615fad",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import subprocess\n",
        "import sys\n",
        "result = subprocess.run(['bash', '-lc', 'nvidia-smi || true'], capture_output=True, text=True)\n",
        "print(result.stdout)\n",
        "print(result.stderr)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 28 16:20:36 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     128MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n\n"
          ]
        }
      ]
    },
    {
      "id": "6117d0ad-07de-4dc9-ad82-9456e1439e08",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Initial Plan for Google QUEST Q&A Labeling Competition\n",
        "\n",
        "## Objective\n",
        "Predict multiple subjective quality aspects of question-answer pairs using column-wise Spearman correlation. Target columns include 'question_type_definition' and likely others (need to confirm from data). Aim for Gold medal: >=0.42278\n",
        "\n",
        "## Step 1: Environment Setup\n",
        "- GPU confirmed available (NVIDIA A10-24Q, CUDA 12.4).\n",
        "- Install necessary packages if needed (e.g., PyTorch with cu121, transformers for NLP).\n",
        "\n",
        "## Step 2: Data Loading and EDA\n",
        "- Load train.csv and test.csv.\n",
        "- Explore shapes, columns, missing values, distributions of targets.\n",
        "- Since it's text data (questions, answers), analyze text lengths, types, etc.\n",
        "- Identify all target columns (likely 30+ subjective labels).\n",
        "\n",
        "## Step 3: Feature Engineering\n",
        "- Text features: TF-IDF, word counts, sentiment, etc.\n",
        "- Advanced: Pre-trained embeddings (BERT, RoBERTa) fine-tuned for this task.\n",
        "- Metadata features if any (e.g., url, product).\n",
        "\n",
        "## Step 4: Modeling\n",
        "- Baselines: Ridge regression on TF-IDF.\n",
        "- Advanced: Neural networks with transformers, multi-task learning since multiple targets.\n",
        "- Cross-validation: 5-fold stratified or group KF (by qid?).\n",
        "- Metric: Column-wise Spearman.\n",
        "\n",
        "## Step 5: Ensembling and Submission\n",
        "- Blend models.\n",
        "- Generate submission.csv with all target columns.\n",
        "\n",
        "## Milestones for Expert Review\n",
        "- After EDA.\n",
        "- After baseline model.\n",
        "- After feature engineering.\n",
        "- Before final submission.\n",
        "\n",
        "Next: Load data and perform initial EDA."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "33d13dc6-40ed-477c-8285-b51c2928f5cc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "print('Train shape:', train.shape)\n",
        "print('\\nColumns:', train.columns.tolist())\n",
        "print('\\nHead:')\n",
        "print(train.head())\n",
        "print('\\nMissing values:')\n",
        "print(train.isnull().sum())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (5471, 41)\n\nColumns: ['qa_id', 'question_title', 'question_body', 'question_user_name', 'question_user_page', 'answer', 'answer_user_name', 'answer_user_page', 'url', 'category', 'host', 'question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n\nHead:\n   qa_id                                     question_title  \\\n0   9622  Which parts of fresh Fenugreek am I supposed t...   \n1   3515  Is decoherence even possible in anti de Sitter...   \n2   2012  How to show the integers have same cardinality...   \n3   5460  how to pass value from visual force page (Inpu...   \n4   2046  How to set precision and format labeled Slider...   \n\n                                       question_body question_user_name  \\\n0  The fresh Fenugreek which I bought contains:\\n...      Aquarius_Girl   \n1  Is decoherence even possible in anti de Sitter...           theorist   \n2  How would I show the following have a bijectio...  Fernando Martinez   \n3  I have created a Vf page from which i need to ...               jack   \n4  For my calculations, I need increased precisio...              Cendo   \n\n                                 question_user_page  \\\n0      https://cooking.stackexchange.com/users/6168   \n1      https://physics.stackexchange.com/users/6788   \n2        https://math.stackexchange.com/users/37244   \n3   https://salesforce.stackexchange.com/users/8706   \n4  https://mathematica.stackexchange.com/users/1290   \n\n                                              answer answer_user_name  \\\n0  I would just pull off all the little stems wit...     spiceyokooko   \n1  Your question is not about AdS at all, it is a...       Ron Maimon   \n2  I like the one that snake around, $0, -1, 1, -...      Adam Hughes   \n3  When you submit the page, Visualforce will upd...          Keith C   \n4  Two, now three, ways:  I think I'd recommend t...       Michael E2   \n\n                                   answer_user_page  \\\n0     https://cooking.stackexchange.com/users/14539   \n1      https://physics.stackexchange.com/users/4864   \n2        https://math.stackexchange.com/users/58831   \n3    https://salesforce.stackexchange.com/users/887   \n4  https://mathematica.stackexchange.com/users/4999   \n\n                                                 url    category  ...  \\\n0  http://cooking.stackexchange.com/questions/292...   LIFE_ARTS  ...   \n1  http://physics.stackexchange.com/questions/185...     SCIENCE  ...   \n2  http://math.stackexchange.com/questions/873927...     SCIENCE  ...   \n3  http://salesforce.stackexchange.com/questions/...  TECHNOLOGY  ...   \n4  http://mathematica.stackexchange.com/questions...  TECHNOLOGY  ...   \n\n  question_well_written  answer_helpful  answer_level_of_information  \\\n0              1.000000        1.000000                     0.666667   \n1              1.000000        1.000000                     1.000000   \n2              0.777778        0.888889                     0.666667   \n3              0.888889        1.000000                     0.666667   \n4              1.000000        0.888889                     0.833333   \n\n   answer_plausible  answer_relevance  answer_satisfaction  \\\n0          1.000000          1.000000             1.000000   \n1          1.000000          1.000000             1.000000   \n2          1.000000          0.888889             0.866667   \n3          1.000000          1.000000             0.933333   \n4          0.888889          1.000000             1.000000   \n\n   answer_type_instructions  answer_type_procedure  \\\n0                  0.666667               0.333333   \n1                  0.000000               0.000000   \n2                  0.666667               0.666667   \n3                  1.000000               0.000000   \n4                  1.000000               0.000000   \n\n   answer_type_reason_explanation  answer_well_written  \n0                        0.000000             1.000000  \n1                        0.000000             1.000000  \n2                        0.333333             0.777778  \n3                        0.000000             0.888889  \n4                        0.000000             1.000000  \n\n[5 rows x 41 columns]\n\nMissing values:\nqa_id                                    0\nquestion_title                           0\nquestion_body                            0\nquestion_user_name                       0\nquestion_user_page                       0\nanswer                                   0\nanswer_user_name                         0\nanswer_user_page                         0\nurl                                      0\ncategory                                 0\nhost                                     0\nquestion_asker_intent_understanding      0\nquestion_body_critical                   0\nquestion_conversational                  0\nquestion_expect_short_answer             0\nquestion_fact_seeking                    0\nquestion_has_commonly_accepted_answer    0\nquestion_interestingness_others          0\nquestion_interestingness_self            0\nquestion_multi_intent                    0\nquestion_not_really_a_question           0\nquestion_opinion_seeking                 0\nquestion_type_choice                     0\nquestion_type_compare                    0\nquestion_type_consequence                0\nquestion_type_definition                 0\nquestion_type_entity                     0\nquestion_type_instructions               0\nquestion_type_procedure                  0\nquestion_type_reason_explanation         0\nquestion_type_spelling                   0\nquestion_well_written                    0\nanswer_helpful                           0\nanswer_level_of_information              0\nanswer_plausible                         0\nanswer_relevance                         0\nanswer_satisfaction                      0\nanswer_type_instructions                 0\nanswer_type_procedure                    0\nanswer_type_reason_explanation           0\nanswer_well_written                      0\ndtype: int64\n"
          ]
        }
      ]
    },
    {
      "id": "a27bca9b-14fd-4b30-9320-0dce23873a27",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Deeper EDA\n",
        "test = pd.read_csv('test.csv')\n",
        "print('Test shape:', test.shape)\n",
        "print('\\nTest columns:', test.columns.tolist())\n",
        "\n",
        "# Target columns\n",
        "target_cols = [col for col in train.columns if col not in ['qa_id', 'question_title', 'question_body', 'question_user_name', 'question_user_page', 'answer', 'answer_user_name', 'answer_user_page', 'url', 'category', 'host']]\n",
        "print('\\nTarget columns (30):', len(target_cols))\n",
        "print(target_cols)\n",
        "\n",
        "# Target distributions\n",
        "print('\\nTarget min/max:')\n",
        "for col in target_cols:\n",
        "    print(f'{col}: {train[col].min():.3f} - {train[col].max():.3f}, mean: {train[col].mean():.3f}')\n",
        "\n",
        "# Text features\n",
        "train['question_text'] = train['question_title'] + ' ' + train['question_body']\n",
        "train['answer_text'] = train['answer']\n",
        "train['full_text'] = train['question_text'] + ' ' + train['answer_text']\n",
        "\n",
        "print('\\nText lengths:')\n",
        "print('Question title len - mean:', train['question_title'].str.len().mean())\n",
        "print('Question body len - mean:', train['question_body'].str.len().mean())\n",
        "print('Answer len - mean:', train['answer'].str.len().mean())\n",
        "print('Full text len - mean:', train['full_text'].str.len().mean())\n",
        "\n",
        "# Categories\n",
        "print('\\nCategories:')\n",
        "print(train['category'].value_counts())\n",
        "\n",
        "# Hosts\n",
        "print('\\nHosts:')\n",
        "print(train['host'].value_counts().head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test shape: (608, 11)\n\nTest columns: ['qa_id', 'question_title', 'question_body', 'question_user_name', 'question_user_page', 'answer', 'answer_user_name', 'answer_user_page', 'url', 'category', 'host']\n\nTarget columns (30): 30\n['question_asker_intent_understanding', 'question_body_critical', 'question_conversational', 'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer', 'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent', 'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice', 'question_type_compare', 'question_type_consequence', 'question_type_definition', 'question_type_entity', 'question_type_instructions', 'question_type_procedure', 'question_type_reason_explanation', 'question_type_spelling', 'question_well_written', 'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance', 'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure', 'answer_type_reason_explanation', 'answer_well_written']\n\nTarget min/max:\nquestion_asker_intent_understanding: 0.333 - 1.000, mean: 0.893\nquestion_body_critical: 0.333 - 1.000, mean: 0.596\nquestion_conversational: 0.000 - 1.000, mean: 0.057\nquestion_expect_short_answer: 0.000 - 1.000, mean: 0.697\nquestion_fact_seeking: 0.000 - 1.000, mean: 0.776\nquestion_has_commonly_accepted_answer: 0.000 - 1.000, mean: 0.792\nquestion_interestingness_others: 0.333 - 1.000, mean: 0.588\nquestion_interestingness_self: 0.333 - 1.000, mean: 0.508\nquestion_multi_intent: 0.000 - 1.000, mean: 0.238\nquestion_not_really_a_question: 0.000 - 1.000, mean: 0.004\nquestion_opinion_seeking: 0.000 - 1.000, mean: 0.428\nquestion_type_choice: 0.000 - 1.000, mean: 0.284\nquestion_type_compare: 0.000 - 1.000, mean: 0.038\nquestion_type_consequence: 0.000 - 1.000, mean: 0.010\nquestion_type_definition: 0.000 - 1.000, mean: 0.030\nquestion_type_entity: 0.000 - 1.000, mean: 0.065\nquestion_type_instructions: 0.000 - 1.000, mean: 0.497\nquestion_type_procedure: 0.000 - 1.000, mean: 0.168\nquestion_type_reason_explanation: 0.000 - 1.000, mean: 0.386\nquestion_type_spelling: 0.000 - 0.667, mean: 0.001\nquestion_well_written: 0.333 - 1.000, mean: 0.801\nanswer_helpful: 0.333 - 1.000, mean: 0.925\nanswer_level_of_information: 0.333 - 1.000, mean: 0.655\nanswer_plausible: 0.333 - 1.000, mean: 0.960\nanswer_relevance: 0.333 - 1.000, mean: 0.969\nanswer_satisfaction: 0.200 - 1.000, mean: 0.855\nanswer_type_instructions: 0.000 - 1.000, mean: 0.478\nanswer_type_procedure: 0.000 - 1.000, mean: 0.132\nanswer_type_reason_explanation: 0.000 - 1.000, mean: 0.501\nanswer_well_written: 0.333 - 1.000, mean: 0.909\n\nText lengths:\nQuestion title len - mean: 53.47431913726924\nQuestion body len - mean: 823.362456589289\nAnswer len - mean: 833.53993785414\nFull text len - mean: 1712.3767135806982\n\nCategories:\ncategory\nTECHNOLOGY       2205\nSTACKOVERFLOW    1132\nCULTURE           856\nLIFE_ARTS         644\nSCIENCE           634\nName: count, dtype: int64\n\nHosts:\nhost\nstackoverflow.com                1132\nenglish.stackexchange.com         207\nsuperuser.com                     202\nserverfault.com                   193\nelectronics.stackexchange.com     191\nName: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "id": "235dd4b9-7f4c-4b85-bc3f-2748e7e29290",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Updated Plan Based on Expert Review\n",
        "\n",
        "## Key Insights from Experts\n",
        "- Multi-task prediction for 30 targets (0-1 scales, some skewed like question_type_definition mean=0.03).\n",
        "- Medal winners: Fine-tuned transformers (RoBERTa/DeBERTa) with shared encoder + 30-regression head, GroupKFold CV by url/host, TF-IDF Ridge baseline blended in.\n",
        "- Pitfalls: Leakage (use GroupKFold by url or host), metric (column-wise Spearman), truncation, no random KFold.\n",
        "\n",
        "## Immediate Next Steps: TF-IDF Baseline (Aim CV >=0.34)\n",
        "1. Imports: sklearn, scipy for Spearman.\n",
        "2. Define targets, create GroupKFold (groups by host, mapped to int).\n",
        "3. Features: Separate TF-IDF (word 1-2g, char 3-5g) for title/body/answer; hstack; add one-hot category/host, lengths (title/body/answer/full), counts (questions marks, exclamations, code blocks via ```).\n",
        "4. Model: MultiOutputRegressor(Ridge(alpha=1)) or per-target Ridge; fit per fold.\n",
        "5. OOF predictions, clip [0,1], compute mean column-wise Spearman on OOF vs train targets.\n",
        "6. Generate test predictions, save submission.csv, submit to check LB.\n",
        "\n",
        "## Then: Transformer Baseline\n",
        "- Install PyTorch cu121, transformers.\n",
        "- RoBERTa-base, input: [CLS] title [SEP] body [SEP] answer, max_len=512 with truncation budget.\n",
        "- Multi-task MSE loss, 5-fold GroupKFold, 3-5 epochs, lr=2e-5, batch=16, FP16.\n",
        "- Blend with TF-IDF (e.g., 0.85 trans + 0.15 TFIDF).\n",
        "\n",
        "For rare targets (e.g., type_* with low mean), consider logistic for binary (y>0) + calibration, blend with Ridge.\n",
        "Track CV Spearman per column to identify weak ones.\n",
        "After baseline execution, request expert review on CV score and pipeline."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "9f2d6946-4579-41de-bd2f-a711c13e3dbb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TF-IDF Baseline Setup (Multi-Target: 30 columns)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from scipy.stats import spearmanr\n",
        "from scipy import sparse\n",
        "\n",
        "# Define all 30 targets\n",
        "target_cols = [\n",
        "    'question_asker_intent_understanding', 'question_body_critical', 'question_conversational',\n",
        "    'question_expect_short_answer', 'question_fact_seeking', 'question_has_commonly_accepted_answer',\n",
        "    'question_interestingness_others', 'question_interestingness_self', 'question_multi_intent',\n",
        "    'question_not_really_a_question', 'question_opinion_seeking', 'question_type_choice',\n",
        "    'question_type_compare', 'question_type_consequence', 'question_type_definition',\n",
        "    'question_type_entity', 'question_type_instructions', 'question_type_procedure',\n",
        "    'question_type_reason_explanation', 'question_type_spelling', 'question_well_written',\n",
        "    'answer_helpful', 'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
        "    'answer_satisfaction', 'answer_type_instructions', 'answer_type_procedure',\n",
        "    'answer_type_reason_explanation', 'answer_well_written'\n",
        "]\n",
        "\n",
        "# Prepare data\n",
        "X_train = train.drop(columns=target_cols + ['qa_id'])\n",
        "y_train = train[target_cols]\n",
        "\n",
        "# Create groups by host (63 unique for proper GroupKFold)\n",
        "host_to_id = {host: idx for idx, host in enumerate(X_train['host'].unique())}\n",
        "groups = X_train['host'].map(host_to_id).values\n",
        "\n",
        "print('Number of groups:', len(np.unique(groups)))\n",
        "print('Target shape:', y_train.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of groups: 63\nTarget shape: (5471, 30)\n"
          ]
        }
      ]
    },
    {
      "id": "22cd0fdb-97a5-444a-98b5-f217caa175bf",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Feature Engineering for TF-IDF Baseline\n",
        "\n",
        "# Prepare test data similarly\n",
        "X_test = test.drop(columns=['qa_id'])\n",
        "\n",
        "# Text fields (already in train from EDA)\n",
        "X_train['question_title'] = X_train['question_title'].fillna('')\n",
        "X_train['question_body'] = X_train['question_body'].fillna('')\n",
        "X_train['answer'] = X_train['answer'].fillna('')\n",
        "X_test['question_title'] = X_test['question_title'].fillna('')\n",
        "X_test['question_body'] = X_test['question_body'].fillna('')\n",
        "X_test['answer'] = X_test['answer'].fillna('')\n",
        "\n",
        "# Metadata features: lengths and counts\n",
        "def get_metadata_features(df):\n",
        "    df = df.copy()\n",
        "    df['title_len'] = df['question_title'].str.len()\n",
        "    df['body_len'] = df['question_body'].str.len()\n",
        "    df['answer_len'] = df['answer'].str.len()\n",
        "    df['full_len'] = df['title_len'] + df['body_len'] + df['answer_len']\n",
        "    df['title_qmarks'] = df['question_title'].str.count(r'\\?')\n",
        "    df['body_qmarks'] = df['question_body'].str.count(r'\\?')\n",
        "    df['answer_qmarks'] = df['answer'].str.count(r'\\?')\n",
        "    df['title_excl'] = df['question_title'].str.count(r'!')\n",
        "    df['body_excl'] = df['question_body'].str.count(r'!')\n",
        "    df['answer_excl'] = df['answer'].str.count(r'!')\n",
        "    df['code_blocks'] = df['question_body'].str.count('```') + df['answer'].str.count('```')\n",
        "    # Regex features for definition questions (general for multi-task)\n",
        "    definition_pattern = r'(?i)(what is|what are|define|definition|meaning|means|stand for|acronym)'\n",
        "    df['title_definition'] = df['question_title'].str.contains(definition_pattern, na=False).astype(int)\n",
        "    df['body_definition'] = df['question_body'].str.contains(definition_pattern, na=False).astype(int)\n",
        "    return df\n",
        "\n",
        "X_train = get_metadata_features(X_train)\n",
        "X_test = get_metadata_features(X_test)\n",
        "\n",
        "# One-hot encoding for category only (drop host to avoid leakage with grouping)\n",
        "cat_ohe_train = pd.get_dummies(X_train['category'], prefix='cat')\n",
        "cat_ohe_test = pd.get_dummies(X_test['category'], prefix='cat').reindex(columns=cat_ohe_train.columns, fill_value=0)\n",
        "\n",
        "# Metadata columns to include (added regex)\n",
        "meta_cols = ['title_len', 'body_len', 'answer_len', 'full_len', 'title_qmarks', 'body_qmarks', 'answer_qmarks',\n",
        "             'title_excl', 'body_excl', 'answer_excl', 'code_blocks', 'title_definition', 'body_definition']\n",
        "\n",
        "print('Metadata shape:', X_train[meta_cols].shape)\n",
        "print('Category OHE shape:', cat_ohe_train.shape)\n",
        "\n",
        "# TF-IDF Vectorizers (will fit per fold)\n",
        "word_vectorizer = TfidfVectorizer(max_features=50000, ngram_range=(1,2), sublinear_tf=True, min_df=2)\n",
        "char_vectorizer = TfidfVectorizer(max_features=100000, ngram_range=(3,5), sublinear_tf=True, min_df=2, analyzer='char_wb')\n",
        "\n",
        "# Function to get TF-IDF features per fold (title, body, answer)\n",
        "def get_tfidf_features(X_fold):\n",
        "    title_word = word_vectorizer.fit_transform(X_fold['question_title'])\n",
        "    body_word = word_vectorizer.fit_transform(X_fold['question_body'])\n",
        "    answer_word = word_vectorizer.fit_transform(X_fold['answer'])\n",
        "    title_char = char_vectorizer.fit_transform(X_fold['question_title'])\n",
        "    body_char = char_vectorizer.fit_transform(X_fold['question_body'])\n",
        "    answer_char = char_vectorizer.fit_transform(X_fold['answer'])\n",
        "    tfidf_features = sparse.hstack([\n",
        "        title_word, body_word, answer_word,\n",
        "        title_char, body_char, answer_char\n",
        "    ]).tocsr()\n",
        "    return tfidf_features\n",
        "\n",
        "# Function to combine all features (TF-IDF + metadata + cat OHE only)\n",
        "def get_full_features(tfidf_feat, meta, cat_ohe):\n",
        "    meta_sparse = sparse.csr_matrix(meta.values.astype(float))\n",
        "    cat_sparse = sparse.csr_matrix(cat_ohe.values.astype(float))\n",
        "    full_feat = sparse.hstack([tfidf_feat, meta_sparse, cat_sparse]).tocsr()\n",
        "    return full_feat"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_93/944362761.py:30: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n  df['title_definition'] = df['question_title'].str.contains(definition_pattern, na=False).astype(int)\n/tmp/ipykernel_93/944362761.py:31: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n  df['body_definition'] = df['question_body'].str.contains(definition_pattern, na=False).astype(int)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata shape: (5471, 13)\nCategory OHE shape: (5471, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_93/944362761.py:30: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n  df['title_definition'] = df['question_title'].str.contains(definition_pattern, na=False).astype(int)\n/tmp/ipykernel_93/944362761.py:31: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n  df['body_definition'] = df['question_body'].str.contains(definition_pattern, na=False).astype(int)\n"
          ]
        }
      ]
    },
    {
      "id": "aa9b2a65-d3f1-4a8d-a270-25e12f788f29",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CV Loop for Improved TF-IDF Baseline (Multi-Target, 30 columns)\n",
        "\n",
        "# Custom scorer for column-wise Spearman (NaN-safe)\n",
        "def column_spearman_scorer(y_true, y_pred):\n",
        "    spearman_scores = []\n",
        "    for i in range(y_true.shape[1]):\n",
        "        score, _ = spearmanr(y_true[:, i], y_pred[:, i])\n",
        "        spearman_scores.append(0.0 if np.isnan(score) else score)\n",
        "    return np.mean(spearman_scores)\n",
        "\n",
        "# Initialize OOF and test predictions (n, 30)\n",
        "n_splits = 5\n",
        "oof_preds = np.zeros((len(X_train), len(target_cols)))\n",
        "test_preds = np.zeros((len(X_test), len(target_cols)))\n",
        "\n",
        "# GroupKFold by url (stricter, consistent with transformer)\n",
        "url_groups = pd.factorize(train['url'])[0]\n",
        "gkf = GroupKFold(n_splits=n_splits)\n",
        "\n",
        "for fold, (tr_idx, val_idx) in enumerate(gkf.split(X_train, y_train, url_groups)):\n",
        "    print(f'Fold {fold+1}/{n_splits}')\n",
        "    X_tr_fold = X_train.iloc[tr_idx]\n",
        "    X_val_fold = X_train.iloc[val_idx]\n",
        "    y_tr_fold = y_train.iloc[tr_idx]\n",
        "    y_val_fold = y_train.iloc[val_idx]\n",
        "    \n",
        "    # Separate vectorizers per field inside fold (increased max_features for better fit)\n",
        "    word_title = TfidfVectorizer(max_features=50000, ngram_range=(1,2), sublinear_tf=True, min_df=2)\n",
        "    word_body = TfidfVectorizer(max_features=50000, ngram_range=(1,2), sublinear_tf=True, min_df=2)\n",
        "    word_answer = TfidfVectorizer(max_features=50000, ngram_range=(1,2), sublinear_tf=True, min_df=2)\n",
        "    char_title = TfidfVectorizer(max_features=100000, ngram_range=(3,5), sublinear_tf=True, min_df=2, analyzer='char_wb')\n",
        "    char_body = TfidfVectorizer(max_features=100000, ngram_range=(3,5), sublinear_tf=True, min_df=2, analyzer='char_wb')\n",
        "    char_answer = TfidfVectorizer(max_features=100000, ngram_range=(3,5), sublinear_tf=True, min_df=2, analyzer='char_wb')\n",
        "    \n",
        "    # Fit and transform train fold\n",
        "    title_word_tr = word_title.fit_transform(X_tr_fold['question_title'])\n",
        "    body_word_tr = word_body.fit_transform(X_tr_fold['question_body'])\n",
        "    answer_word_tr = word_answer.fit_transform(X_tr_fold['answer'])\n",
        "    title_char_tr = char_title.fit_transform(X_tr_fold['question_title'])\n",
        "    body_char_tr = char_body.fit_transform(X_tr_fold['question_body'])\n",
        "    answer_char_tr = char_answer.fit_transform(X_tr_fold['answer'])\n",
        "    tfidf_tr = sparse.hstack([title_word_tr, body_word_tr, answer_word_tr, title_char_tr, body_char_tr, answer_char_tr]).tocsr()\n",
        "    \n",
        "    # Transform val fold\n",
        "    title_word_val = word_title.transform(X_val_fold['question_title'])\n",
        "    body_word_val = word_body.transform(X_val_fold['question_body'])\n",
        "    answer_word_val = word_answer.transform(X_val_fold['answer'])\n",
        "    title_char_val = char_title.transform(X_val_fold['question_title'])\n",
        "    body_char_val = char_body.transform(X_val_fold['question_body'])\n",
        "    answer_char_val = char_answer.transform(X_val_fold['answer'])\n",
        "    tfidf_val = sparse.hstack([title_word_val, body_word_val, answer_word_val, title_char_val, body_char_val, answer_char_val]).tocsr()\n",
        "    \n",
        "    # Full features for train and val\n",
        "    meta_tr = X_tr_fold[meta_cols]\n",
        "    meta_val = X_val_fold[meta_cols]\n",
        "    full_tr = get_full_features(tfidf_tr, meta_tr, cat_ohe_train.iloc[tr_idx])\n",
        "    full_val = get_full_features(tfidf_val, meta_val, cat_ohe_train.iloc[val_idx])\n",
        "    \n",
        "    # Model (MultiOutput Ridge, lower alpha=1.0, sparse_cg solver for better fit on sparse data)\n",
        "    model = MultiOutputRegressor(Ridge(alpha=1.0, fit_intercept=True, solver='sparse_cg'))\n",
        "    model.fit(full_tr, y_tr_fold)\n",
        "    \n",
        "    # OOF pred\n",
        "    oof_fold = model.predict(full_val)\n",
        "    oof_fold = np.clip(oof_fold, 0, 1)\n",
        "    oof_preds[val_idx] = oof_fold\n",
        "    \n",
        "    # Test pred\n",
        "    title_word_test = word_title.transform(X_test['question_title'])\n",
        "    body_word_test = word_body.transform(X_test['question_body'])\n",
        "    answer_word_test = word_answer.transform(X_test['answer'])\n",
        "    title_char_test = char_title.transform(X_test['question_title'])\n",
        "    body_char_test = char_body.transform(X_test['question_body'])\n",
        "    answer_char_test = char_answer.transform(X_test['answer'])\n",
        "    tfidf_test = sparse.hstack([title_word_test, body_word_test, answer_word_test, title_char_test, body_char_test, answer_char_test]).tocsr()\n",
        "    full_test = get_full_features(tfidf_test, X_test[meta_cols], cat_ohe_test)\n",
        "    test_fold = model.predict(full_test)\n",
        "    test_preds += test_fold / n_splits\n",
        "    \n",
        "    # Fold score\n",
        "    fold_score = column_spearman_scorer(y_val_fold.values, oof_fold)\n",
        "    print(f'Fold {fold+1} Spearman: {fold_score:.4f}')\n",
        "\n",
        "# Overall CV score\n",
        "cv_score = column_spearman_scorer(y_train.values, oof_preds)\n",
        "print(f'\\nMean CV Spearman: {cv_score:.4f}')\n",
        "\n",
        "# Save OOF and test preds for blending (v2)\n",
        "np.save('tfidf_oof_v2.npy', oof_preds)\n",
        "np.save('tfidf_test_v2.npy', test_preds)\n",
        "\n",
        "# Clip test preds\n",
        "test_preds = np.clip(test_preds, 0, 1)\n",
        "\n",
        "# Submission (30 columns)\n",
        "sub_df = pd.DataFrame(test_preds, columns=target_cols)\n",
        "sub_df.insert(0, 'qa_id', test['qa_id'])\n",
        "sub_df.to_csv('submission_tfidf_v2.csv', index=False)\n",
        "print('\\nSubmission saved (v2). Shape:', sub_df.shape)\n",
        "print('Head:')\n",
        "print(sub_df.head())\n",
        "\n",
        "# Per-column scores (NaN-safe)\n",
        "per_col_scores = [spearmanr(y_train.iloc[:, i], oof_preds[:, i])[0] if not np.isnan(spearmanr(y_train.iloc[:, i], oof_preds[:, i])[0]) else 0.0 for i in range(len(target_cols))]\n",
        "print('\\nPer-column Spearman mean:', np.mean(per_col_scores))\n",
        "print('Low scoring columns:')\n",
        "for col, score in zip(target_cols, per_col_scores):\n",
        "    if score < 0.2:\n",
        "        print(f'{col}: {score:.4f}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Spearman: 0.2977\nFold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Spearman: 0.2981\nFold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Spearman: 0.2960\nFold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Spearman: 0.2981\nFold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Spearman: 0.3001\n\nMean CV Spearman: 0.2984\n\nSubmission saved (v2). Shape: (608, 31)\nHead:\n   qa_id  question_asker_intent_understanding  question_body_critical  \\\n0   6516                             0.950378                0.523153   \n1   6168                             0.858214                0.484438   \n2   8575                             0.955203                0.732544   \n3    618                             0.818749                0.675022   \n4   3471                             0.973680                0.615796   \n\n   question_conversational  question_expect_short_answer  \\\n0                 0.024698                      0.853590   \n1                 0.009032                      0.692637   \n2                 0.086021                      0.894099   \n3                 0.000000                      0.749484   \n4                 0.140890                      0.978866   \n\n   question_fact_seeking  question_has_commonly_accepted_answer  \\\n0               0.855309                               0.876753   \n1               0.735161                               0.936123   \n2               0.764504                               0.439161   \n3               0.758451                               0.583225   \n4               0.602406                               0.768467   \n\n   question_interestingness_others  question_interestingness_self  \\\n0                         0.615426                       0.647366   \n1                         0.492944                       0.369103   \n2                         0.614507                       0.697851   \n3                         0.549280                       0.346669   \n4                         0.672411                       0.524303   \n\n   question_multi_intent  ...  question_well_written  answer_helpful  \\\n0               0.045250  ...               0.661682        0.974575   \n1               0.077759  ...               0.589503        0.936619   \n2               0.074299  ...               0.934301        0.918876   \n3               0.359592  ...               0.751382        0.965386   \n4               0.192986  ...               0.957799        0.920977   \n\n   answer_level_of_information  answer_plausible  answer_relevance  \\\n0                     0.668834          1.000000          1.000000   \n1                     0.610084          0.970823          0.978762   \n2                     0.676533          0.958753          0.959024   \n3                     0.570170          0.973318          0.986007   \n4                     0.637945          0.978985          0.927563   \n\n   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n0             0.924863                  0.189135               0.000000   \n1             0.894606                  0.983611               0.031946   \n2             0.772992                  0.000000               0.067954   \n3             0.803739                  0.401757               0.067471   \n4             0.846139                  0.575118               0.099420   \n\n   answer_type_reason_explanation  answer_well_written  \n0                        0.691917             0.910178  \n1                        0.000000             0.825309  \n2                        0.295881             0.952651  \n3                        0.362837             0.809953  \n4                        0.519832             0.990006  \n\n[5 rows x 31 columns]\n\nPer-column Spearman mean: 0.2984449307431737\nLow scoring columns:\nquestion_expect_short_answer: 0.1563\nquestion_fact_seeking: 0.1889\nquestion_not_really_a_question: 0.0228\nquestion_type_consequence: 0.0823\nquestion_type_spelling: 0.0627\nanswer_helpful: 0.1130\nanswer_plausible: 0.0692\nanswer_relevance: 0.0724\nanswer_satisfaction: 0.1984\nanswer_type_procedure: 0.1669\nanswer_well_written: 0.1012\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}