{
  "cells": [
    {
      "id": "cce91983-1c6c-4878-b835-9d836510f8a7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# DeBERTa-v3-large multitask (30 targets) per expert plan\n",
        "# - Weighted SmoothL1Loss: answer_*=1.5x, answer_helpful=2.0x\n",
        "# - lr=1.5e-5, batch_size=6, grad_accum=6, epochs=4 (add 5th if improving)\n",
        "# - WeightedLayerPooling + masked mean pooling\n",
        "# - EMA (decay=0.99) with warmup delay; dual eval (plain vs EMA)\n",
        "# - Eval/Test-time MC dropout T=5\n",
        "# - Quota-based packing to protect Answer tokens\n",
        "# - GroupKFold via precomputed folds.npy; robust logging\n",
        "\n",
        "import os, time, math, gc, random, sys\n",
        "import numpy as np, pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel, get_cosine_schedule_with_warmup\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "# Mitigate CUDA fragmentation\n",
        "os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "assert torch.cuda.is_available(), 'CUDA is required for this run'\n",
        "\n",
        "# Load data and schema\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "sample_sub = pd.read_csv('sample_submission.csv')\n",
        "id_col = sample_sub.columns[0]\n",
        "target_cols = [c for c in sample_sub.columns if c != id_col]\n",
        "assert target_cols == list(sample_sub.columns[1:])\n",
        "assert all(c in train.columns for c in target_cols)\n",
        "folds = np.load('folds.npy')\n",
        "\n",
        "# Text fields\n",
        "TITLE, BODY, ANSWER = 'question_title','question_body','answer'\n",
        "assert all(c in train.columns for c in [TITLE, BODY, ANSWER])\n",
        "\n",
        "# Loss weights: boost all answer_* targets by 1.5x; answer_helpful 2.0x\n",
        "loss_weights = np.ones(len(target_cols), dtype=np.float32)\n",
        "for i, col in enumerate(target_cols):\n",
        "    if col.startswith('answer_'):\n",
        "        loss_weights[i] = 1.5\n",
        "    if col == 'answer_helpful':\n",
        "        loss_weights[i] = 2.0\n",
        "print('Loss weights summary:', float(loss_weights.min()), float(loss_weights.max()), 'answer_* boosted, helpful=2.0x')\n",
        "\n",
        "# Model/Tokenizer\n",
        "model_name = 'microsoft/deberta-v3-large'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "MAX_LEN = 512\n",
        "CLS_ID = tokenizer.cls_token_id\n",
        "SEP_ID = tokenizer.sep_token_id\n",
        "PAD_ID = tokenizer.pad_token_id\n",
        "assert CLS_ID is not None and SEP_ID is not None and PAD_ID is not None, 'Tokenizer missing special tokens'\n",
        "\n",
        "def _encode_no_specials(text: str):\n",
        "    return tokenizer.encode(text, add_special_tokens=False)\n",
        "\n",
        "def _trim_to(ids, lim):\n",
        "    if len(ids) <= lim: return ids\n",
        "    return ids[:max(0, lim)]\n",
        "\n",
        "def pack_inputs(title, body, answer):\n",
        "    # Quota-based manual packing: [CLS] title [SEP] body [SEP] answer [SEP]\n",
        "    # Base quotas under 512 (reserve 4 specials): title 48, body 256, answer 196 (sum=500)\n",
        "    q_title, q_body, q_answer = 48, 256, 196\n",
        "    content_budget = MAX_LEN - 4\n",
        "    # Tokenize without specials\n",
        "    t_ids = _encode_no_specials(f\"Title: {title}\")\n",
        "    b_ids = _encode_no_specials(f\"Body: {body}\")\n",
        "    a_ids = _encode_no_specials(f\"Answer: {answer}\")\n",
        "    # Initial trims\n",
        "    t_used = min(q_title, len(t_ids))\n",
        "    b_used = min(q_body, len(b_ids))\n",
        "    a_used = min(q_answer, len(a_ids))\n",
        "    used = t_used + b_used + a_used\n",
        "    # Enforce Answer minimum cap (>=200) by borrowing from Body down to 100, then Title down to 50\n",
        "    if a_used < 200:\n",
        "        need = 200 - a_used\n",
        "        take = min(need, max(0, b_used - 100))\n",
        "        b_used -= take; a_used += take; need -= take\n",
        "        if need > 0:\n",
        "            take2 = min(need, max(0, t_used - 50))\n",
        "            t_used -= take2; a_used += take2; need -= take2\n",
        "    used = t_used + b_used + a_used\n",
        "    # Redistribute leftover budget in Answer -> Body -> Title order\n",
        "    if used < content_budget:\n",
        "        leftover = content_budget - used\n",
        "        t_room = max(0, len(t_ids) - t_used)\n",
        "        b_room = max(0, len(b_ids) - b_used)\n",
        "        a_room = max(0, len(a_ids) - a_used)\n",
        "        while leftover > 0 and (t_room + b_room + a_room) > 0:\n",
        "            if a_room > 0 and leftover > 0:\n",
        "                add = min(8, min(leftover, a_room))\n",
        "                a_used += add; leftover -= add; a_room -= add\n",
        "            if b_room > 0 and leftover > 0:\n",
        "                add = min(8, min(leftover, b_room))\n",
        "                b_used += add; leftover -= add; b_room -= add\n",
        "            if t_room > 0 and leftover > 0:\n",
        "                add = min(4, min(leftover, t_room))\n",
        "                t_used += add; leftover -= add; t_room -= add\n",
        "    # Final trims\n",
        "    t_ids = _trim_to(t_ids, t_used)\n",
        "    b_ids = _trim_to(b_ids, b_used)\n",
        "    a_ids = _trim_to(a_ids, a_used)\n",
        "    # Assemble\n",
        "    input_ids = [CLS_ID] + t_ids + [SEP_ID] + b_ids + [SEP_ID] + a_ids + [SEP_ID]\n",
        "    if len(input_ids) > MAX_LEN:\n",
        "        input_ids = input_ids[:MAX_LEN]\n",
        "        input_ids[-1] = SEP_ID\n",
        "    attn_mask = [1] * len(input_ids)\n",
        "    # Pad\n",
        "    pad_len = MAX_LEN - len(input_ids)\n",
        "    if pad_len > 0:\n",
        "        input_ids = input_ids + [PAD_ID] * pad_len\n",
        "        attn_mask = attn_mask + [0] * pad_len\n",
        "    return {\n",
        "        'input_ids': torch.tensor(input_ids, dtype=torch.long).unsqueeze(0),\n",
        "        'attention_mask': torch.tensor(attn_mask, dtype=torch.long).unsqueeze(0),\n",
        "    }\n",
        "\n",
        "class QADataset(Dataset):\n",
        "    def __init__(self, df, targets=None):\n",
        "        self.t = df[TITLE].fillna('').astype(str).values\n",
        "        self.b = df[BODY].fillna('').astype(str).values\n",
        "        self.a = df[ANSWER].fillna('').astype(str).values\n",
        "        self.targets = None if targets is None else np.asarray(targets, dtype=np.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.t)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = pack_inputs(self.t[idx], self.b[idx], self.a[idx])\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        if self.targets is not None:\n",
        "            item['labels'] = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
        "        return item\n",
        "\n",
        "def spearman_cols(y_pred: np.ndarray, y_true: np.ndarray):\n",
        "    rhos = []\n",
        "    for i in range(y_pred.shape[1]):\n",
        "        r = spearmanr(y_pred[:, i], y_true[:, i]).correlation\n",
        "        rhos.append(0.0 if (r is None or np.isnan(r)) else float(r))\n",
        "    return float(np.mean(rhos)), rhos\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.99):\n",
        "        self.decay = decay\n",
        "        self.shadow = {n: p.detach().clone() for n,p in model.named_parameters() if p.requires_grad}\n",
        "        self.backup = {}\n",
        "    @torch.no_grad()\n",
        "    def update(self, model):\n",
        "        for n,p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[n].mul_((self.decay)).add_(p.detach(), alpha=1.0-self.decay)\n",
        "    def apply_to(self, model):\n",
        "        self.backup = {}\n",
        "        for n,p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.backup[n] = p.detach().clone()\n",
        "                p.data.copy_(self.shadow[n].data)\n",
        "    def restore(self, model):\n",
        "        for n,p in model.named_parameters():\n",
        "            if p.requires_grad and n in self.backup:\n",
        "                p.data.copy_(self.backup[n])\n",
        "        self.backup = {}\n",
        "\n",
        "def masked_mean_pooling(last_hidden_state, attention_mask):\n",
        "    mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "    return (last_hidden_state * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
        "\n",
        "class WeightedLayerPooling(nn.Module):\n",
        "    def __init__(self, num_layers: int, layer_start: int = -4):\n",
        "        super().__init__()\n",
        "        self.layer_start = layer_start\n",
        "        n = -layer_start\n",
        "        self.weights = nn.Parameter(torch.ones(n) / n)\n",
        "    def forward(self, all_hidden_states):\n",
        "        selected = all_hidden_states[self.layer_start:]\n",
        "        stacked = torch.stack(selected, dim=0)  # [n, bs, seq, hid]\n",
        "        w = torch.softmax(self.weights, dim=0).view(-1,1,1,1)\n",
        "        return (w * stacked).sum(dim=0)\n",
        "\n",
        "class DebertaMT(nn.Module):\n",
        "    def __init__(self, name, out_dim=30, dropout_p=0.2, msd_k=1, loss_weights=None):\n",
        "        super().__init__()\n",
        "        self.backbone = AutoModel.from_pretrained(name)\n",
        "        # Optional AMP stability tweak\n",
        "        if hasattr(self.backbone, 'config'):\n",
        "            setattr(self.backbone.config, 'layer_norm_eps', 1e-5)\n",
        "        if hasattr(self.backbone, 'gradient_checkpointing_enable'):\n",
        "            self.backbone.gradient_checkpointing_enable()\n",
        "        hidden = self.backbone.config.hidden_size\n",
        "        self.layer_pool = WeightedLayerPooling(getattr(self.backbone.config, 'num_hidden_layers', 24), layer_start=-4)\n",
        "        self.msd_k = msd_k\n",
        "        self.dropouts = nn.ModuleList([nn.Dropout(dropout_p) for _ in range(msd_k)])\n",
        "        self.head = nn.Linear(hidden, out_dim)\n",
        "        self.register_buffer('loss_w', torch.tensor(loss_weights if loss_weights is not None else np.ones(out_dim, dtype=np.float32)))\n",
        "        self.l1 = nn.SmoothL1Loss(reduction='none')\n",
        "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
        "        out = self.backbone(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "        pooled_seq = self.layer_pool(out.hidden_states)\n",
        "        feat = masked_mean_pooling(pooled_seq, attention_mask)\n",
        "        logits_accum = 0\n",
        "        for dp in self.dropouts:\n",
        "            logits_accum = logits_accum + self.head(dp(feat))\n",
        "        logits = logits_accum / self.msd_k\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            per_elem = self.l1(logits, labels)  # [bs, C]\n",
        "            loss = (per_elem * self.loss_w).mean()\n",
        "        return logits, loss\n",
        "\n",
        "def predict_msd(model, loader, T=5, use_ema=False, ema_obj=None):\n",
        "    # Temporarily disable gradient checkpointing for inference to avoid warnings/overhead\n",
        "    gc_supported = hasattr(model.backbone, 'gradient_checkpointing_disable') and hasattr(model.backbone, 'gradient_checkpointing_enable')\n",
        "    if gc_supported:\n",
        "        model.backbone.gradient_checkpointing_disable()\n",
        "    if use_ema and ema_obj is not None:\n",
        "        ema_obj.apply_to(model)\n",
        "    # Enable dropout but keep no_grad\n",
        "    model.train()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            inputs = {k: v.to(device, non_blocking=True) for k,v in batch.items() if k not in ('labels','token_type_ids')}\n",
        "            logits_sum = 0\n",
        "            for _ in range(T):\n",
        "                logits_sum = logits_sum + model(**inputs, labels=None)[0]\n",
        "            preds.append((logits_sum / T).float().cpu().numpy())\n",
        "    if use_ema and ema_obj is not None:\n",
        "        ema_obj.restore(model)\n",
        "    if gc_supported:\n",
        "        model.backbone.gradient_checkpointing_enable()\n",
        "    return np.concatenate(preds, axis=0)\n",
        "\n",
        "def run_fold(fold, train_idx, val_idx):\n",
        "    print(f'Fold {fold} start: tr={len(train_idx)} va={len(val_idx)}')\n",
        "    df_tr = train.iloc[train_idx].reset_index(drop=True)\n",
        "    df_va = train.iloc[val_idx].reset_index(drop=True)\n",
        "    y_tr = df_tr[target_cols].astype(np.float32).values\n",
        "    y_va = df_va[target_cols].astype(np.float32).values\n",
        "\n",
        "    ds_tr = QADataset(df_tr, y_tr)\n",
        "    ds_va = QADataset(df_va, y_va)\n",
        "    ds_te = QADataset(test, None)\n",
        "\n",
        "    train_loader = DataLoader(ds_tr, batch_size=6, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "    val_loader   = DataLoader(ds_va, batch_size=16, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "    test_loader  = DataLoader(ds_te, batch_size=16, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "    model = DebertaMT(model_name, out_dim=len(target_cols), dropout_p=0.2, msd_k=1, loss_weights=loss_weights).to(device)\n",
        "    # Initialize head bias to target means for stability\n",
        "    with torch.no_grad():\n",
        "        if hasattr(model.head, 'bias') and model.head.bias is not None:\n",
        "            means = train[target_cols].mean().values.astype(np.float32)\n",
        "            model.head.bias.copy_(torch.tensor(means, device=device))\n",
        "\n",
        "    # Optimizer with no_decay groups (no WD on bias/LayerNorm)\n",
        "    no_decay = ['bias', 'LayerNorm.weight']\n",
        "    decay_params = []\n",
        "    nodecay_params = []\n",
        "    for n, p in model.named_parameters():\n",
        "        if not p.requires_grad: continue\n",
        "        if any(nd in n for nd in no_decay):\n",
        "            nodecay_params.append(p)\n",
        "        else:\n",
        "            decay_params.append(p)\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': decay_params, 'weight_decay': 0.01},\n",
        "        {'params': nodecay_params, 'weight_decay': 0.0},\n",
        "    ], lr=1.5e-5, betas=(0.9,0.999), eps=1e-6)\n",
        "\n",
        "    num_epochs = 4\n",
        "    grad_accum = 6  # effective batch 36\n",
        "    steps_per_epoch = math.ceil(len(train_loader) / grad_accum)\n",
        "    num_training_steps = steps_per_epoch * num_epochs\n",
        "    warmup_steps = max(10, int(0.1 * num_training_steps))\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=num_training_steps)\n",
        "\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
        "    ema = EMA(model, decay=0.99)\n",
        "\n",
        "    best_score = -1.0\n",
        "    best_val_preds = None\n",
        "\n",
        "    global_step = 0\n",
        "    t0 = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        tr_loss = 0.0\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        for step, batch in enumerate(train_loader):\n",
        "            inputs = {k: v.to(device, non_blocking=True) for k,v in batch.items() if k not in ('labels','token_type_ids')}\n",
        "            labels = batch['labels'].to(device, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda', enabled=True):\n",
        "                logits, loss = model(**inputs, labels=labels)\n",
        "                loss = loss / grad_accum\n",
        "            scaler.scale(loss).backward()\n",
        "            if (step + 1) % grad_accum == 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                scheduler.step()\n",
        "                if global_step >= warmup_steps:\n",
        "                    ema.update(model)\n",
        "                global_step += 1\n",
        "            tr_loss += loss.item() * grad_accum\n",
        "            if (step+1) % 100 == 0:\n",
        "                print(f'  Epoch {epoch+1} step {step+1}/{len(train_loader)} loss={tr_loss/(step+1):.4f}', flush=True)\n",
        "\n",
        "        # Validation: plain vs EMA with MC dropout T=5\n",
        "        def evaluate():\n",
        "            preds_plain = predict_msd(model, val_loader, T=5, use_ema=False, ema_obj=None)\n",
        "            preds_ema   = predict_msd(model, val_loader, T=5, use_ema=True, ema_obj=ema)\n",
        "            tgts = df_va[target_cols].to_numpy(dtype=np.float32)\n",
        "            s_plain, per_plain = spearman_cols(preds_plain, tgts)\n",
        "            s_ema,   per_ema   = spearman_cols(preds_ema, tgts)\n",
        "            return (s_plain, per_plain, preds_plain), (s_ema, per_ema, preds_ema)\n",
        "\n",
        "        (s_plain, per_plain, vp_plain), (s_ema, per_ema, vp_ema) = evaluate()\n",
        "        print(f'  Epoch {epoch+1} mean-30 Spearman plain/EMA: {s_plain:.5f}/{s_ema:.5f} | time {(time.time()-t0):.1f}s')\n",
        "        score = s_plain if s_plain >= s_ema else s_ema\n",
        "        val_preds = vp_plain if s_plain >= s_ema else vp_ema\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_val_preds = val_preds.copy()\n",
        "\n",
        "    # Test inference with EMA weights + MC dropout\n",
        "    test_preds = predict_msd(model, test_loader, T=5, use_ema=True, ema_obj=ema)\n",
        "\n",
        "    del model, optimizer, scheduler, scaler, train_loader, val_loader, test_loader, ds_tr, ds_va, ds_te\n",
        "    torch.cuda.empty_cache(); gc.collect()\n",
        "    return best_val_preds, test_preds, best_score\n",
        "\n",
        "# Run CV\n",
        "unique_folds = np.unique(folds)\n",
        "oof = np.zeros((len(train), len(target_cols)), dtype=np.float32)\n",
        "test_accum = np.zeros((len(unique_folds), len(test), len(target_cols)), dtype=np.float32)\n",
        "fold_scores = []\n",
        "\n",
        "overall_t0 = time.time()\n",
        "for i, fold in enumerate(unique_folds):\n",
        "    tr_idx = np.where(folds != fold)[0]\n",
        "    va_idx = np.where(folds == fold)[0]\n",
        "    start = time.time()\n",
        "    va_pred, te_pred, score = run_fold(fold, tr_idx, va_idx)\n",
        "    oof[va_idx] = va_pred\n",
        "    test_accum[i] = te_pred\n",
        "    fold_scores.append(float(score))\n",
        "    print(f'Fold {fold} best mean-30 Spearman: {score:.5f} | fold time {time.time()-start:.1f}s', flush=True)\n",
        "\n",
        "oof_mean_score, _ = spearman_cols(oof, train[target_cols].astype(np.float32).values)\n",
        "print('Fold Spearmans:', [round(s,5) for s in fold_scores])\n",
        "print(f'OOF mean-30 Spearman (deberta-v3-large): {oof_mean_score:.5f}')\n",
        "\n",
        "# Save OOF/test\n",
        "np.save('oof_all_targets_deberta_large.npy', np.clip(oof, 0, 1).astype(np.float32))\n",
        "test_pred = test_accum.mean(axis=0).astype(np.float32)\n",
        "test_pred = np.clip(test_pred, 0.0, 1.0).astype(np.float32)\n",
        "np.save('test_all_targets_deberta_large.npy', test_pred)\n",
        "\n",
        "# Build submission (separate file to avoid clobbering base run)\n",
        "sub = sample_sub.copy()\n",
        "sub[id_col] = test[id_col].values\n",
        "for i, col in enumerate(target_cols):\n",
        "    sub[col] = test_pred[:, i]\n",
        "sub.to_csv('submission_deberta_large.csv', index=False)\n",
        "print('Saved submission_deberta_large.csv. Total time:', round(time.time()-overall_t0,1),'s')\n",
        "\n",
        "print('Done.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\nLoss weights summary: 1.0 2.0 answer_* boosted, helpful=2.0x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/app/.pip-target/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 start: tr=4376 va=1095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 100/730 loss=0.1273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 200/730 loss=0.0927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 300/730 loss=0.0768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 400/730 loss=0.0669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 500/730 loss=0.0605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 600/730 loss=0.0560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 700/730 loss=0.0522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 mean-30 Spearman plain/EMA: 0.27724/0.12023 | time 1046.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 100/730 loss=0.0294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 200/730 loss=0.0292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 300/730 loss=0.0283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 400/730 loss=0.0279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 500/730 loss=0.0275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 600/730 loss=0.0272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 700/730 loss=0.0270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 mean-30 Spearman plain/EMA: 0.33093/0.28088 | time 2097.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 100/730 loss=0.0230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 200/730 loss=0.0234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 300/730 loss=0.0236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 400/730 loss=0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 500/730 loss=0.0234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 600/730 loss=0.0233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 700/730 loss=0.0233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 mean-30 Spearman plain/EMA: 0.34667/0.33658 | time 3147.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 100/730 loss=0.0223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 200/730 loss=0.0218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 300/730 loss=0.0219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 400/730 loss=0.0219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 500/730 loss=0.0220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 600/730 loss=0.0220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 700/730 loss=0.0218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 mean-30 Spearman plain/EMA: 0.35203/0.34818 | time 4198.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 best mean-30 Spearman: 0.35203 | fold time 4347.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 start: tr=4377 va=1094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 100/730 loss=0.1463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 200/730 loss=0.1034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 300/730 loss=0.0846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 400/730 loss=0.0735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 500/730 loss=0.0657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 600/730 loss=0.0604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 700/730 loss=0.0564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 mean-30 Spearman plain/EMA: 0.25704/0.11161 | time 1049.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 100/730 loss=0.0291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 200/730 loss=0.0288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 300/730 loss=0.0283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 400/730 loss=0.0279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 500/730 loss=0.0277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 600/730 loss=0.0275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 700/730 loss=0.0272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 mean-30 Spearman plain/EMA: 0.31470/0.26542 | time 2100.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 100/730 loss=0.0241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 200/730 loss=0.0244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 300/730 loss=0.0239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 400/730 loss=0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 500/730 loss=0.0236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 600/730 loss=0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 700/730 loss=0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 mean-30 Spearman plain/EMA: 0.33425/0.31958 | time 3150.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 100/730 loss=0.0232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 200/730 loss=0.0225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 300/730 loss=0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 400/730 loss=0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 500/730 loss=0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 600/730 loss=0.0224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 700/730 loss=0.0224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 mean-30 Spearman plain/EMA: 0.33211/0.33107 | time 4201.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 best mean-30 Spearman: 0.33425 | fold time 4349.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 start: tr=4377 va=1094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 100/730 loss=0.1156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 200/730 loss=0.0867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 300/730 loss=0.0731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 400/730 loss=0.0646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 500/730 loss=0.0586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 600/730 loss=0.0544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 700/730 loss=0.0511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 mean-30 Spearman plain/EMA: 0.25433/0.12583 | time 1050.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 100/730 loss=0.0287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 200/730 loss=0.0288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 300/730 loss=0.0285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 400/730 loss=0.0279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 500/730 loss=0.0275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 600/730 loss=0.0272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 700/730 loss=0.0270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 mean-30 Spearman plain/EMA: 0.32238/0.26444 | time 2100.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 100/730 loss=0.0239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 200/730 loss=0.0241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 300/730 loss=0.0241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 400/730 loss=0.0240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 500/730 loss=0.0238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 600/730 loss=0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 700/730 loss=0.0236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 mean-30 Spearman plain/EMA: 0.34019/0.32707 | time 3151.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 100/730 loss=0.0219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 200/730 loss=0.0220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 300/730 loss=0.0221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 400/730 loss=0.0221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 500/730 loss=0.0220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 600/730 loss=0.0220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 700/730 loss=0.0219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 mean-30 Spearman plain/EMA: 0.34624/0.33698 | time 4201.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 best mean-30 Spearman: 0.34624 | fold time 4349.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 start: tr=4377 va=1094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 100/730 loss=0.1290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 200/730 loss=0.0944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 300/730 loss=0.0772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 400/730 loss=0.0675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 500/730 loss=0.0612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 600/730 loss=0.0564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 700/730 loss=0.0530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 mean-30 Spearman plain/EMA: 0.26634/0.13801 | time 1049.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 100/730 loss=0.0291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 200/730 loss=0.0283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 300/730 loss=0.0281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 400/730 loss=0.0279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 500/730 loss=0.0276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 600/730 loss=0.0273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 700/730 loss=0.0272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 mean-30 Spearman plain/EMA: 0.32646/0.27800 | time 2100.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 100/730 loss=0.0238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 200/730 loss=0.0242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 300/730 loss=0.0242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 400/730 loss=0.0241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 500/730 loss=0.0240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 600/730 loss=0.0239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 700/730 loss=0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 mean-30 Spearman plain/EMA: 0.34080/0.32305 | time 3150.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 100/730 loss=0.0223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 200/730 loss=0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 300/730 loss=0.0225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 400/730 loss=0.0223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 500/730 loss=0.0224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 600/730 loss=0.0223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 700/730 loss=0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 mean-30 Spearman plain/EMA: 0.34791/0.33907 | time 4201.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 best mean-30 Spearman: 0.34791 | fold time 4349.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 start: tr=4377 va=1094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 100/730 loss=0.1093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 200/730 loss=0.0822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 300/730 loss=0.0691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 400/730 loss=0.0611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 500/730 loss=0.0557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 600/730 loss=0.0517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 step 700/730 loss=0.0485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 1 mean-30 Spearman plain/EMA: 0.27393/0.14426 | time 1049.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 100/730 loss=0.0289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 200/730 loss=0.0281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 300/730 loss=0.0277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 400/730 loss=0.0274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 500/730 loss=0.0272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 600/730 loss=0.0269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 step 700/730 loss=0.0267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 2 mean-30 Spearman plain/EMA: 0.32082/0.28410 | time 2100.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 100/730 loss=0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 200/730 loss=0.0235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 300/730 loss=0.0239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 400/730 loss=0.0237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 500/730 loss=0.0235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 600/730 loss=0.0234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 step 700/730 loss=0.0234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 3 mean-30 Spearman plain/EMA: 0.33726/0.32118 | time 3150.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 100/730 loss=0.0226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 200/730 loss=0.0223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 300/730 loss=0.0225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 400/730 loss=0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 500/730 loss=0.0221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 600/730 loss=0.0220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 step 700/730 loss=0.0219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Epoch 4 mean-30 Spearman plain/EMA: 0.33786/0.33662 | time 4201.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 best mean-30 Spearman: 0.33786 | fold time 4350.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold Spearmans: [0.35203, 0.33425, 0.34624, 0.34791, 0.33786]\nOOF mean-30 Spearman (deberta-v3-large): 0.34303\nSaved submission_deberta_large.csv. Total time: 21746.1 s\nDone.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}