{
  "cells": [
    {
      "id": "a36a355a-8006-4fb3-a6c8-4edd2076c305",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## -1. Emergency Process Cleanup\n",
        "# The environment has zombie processes consuming GPU memory.\n",
        "# This cell attempts to forcefully terminate them using their PIDs from the last OOM error.\n",
        "import os\n",
        "import signal\n",
        "\n",
        "# PIDs from the last OutOfMemoryError traceback\n",
        "pids_to_kill = [65870, 160892, 202112, 414196, 454240]\n",
        "\n",
        "print(\"Attempting to terminate zombie processes...\")\n",
        "for pid in pids_to_kill:\n",
        "    try:\n",
        "        os.kill(pid, signal.SIGKILL) # SIGKILL is a forceful way to terminate\n",
        "        print(f\"Successfully sent SIGKILL to PID {pid}\")\n",
        "    except ProcessLookupError:\n",
        "        print(f\"Process with PID {pid} not found. It may have already terminated.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error killing PID {pid}: {e}\")\n",
        "\n",
        "print(\"Process termination attempt finished.\")\n",
        "\n",
        "# Run nvidia-smi to check GPU memory status after the cleanup attempt.\n",
        "print(\"\\n--- Running nvidia-smi to check GPU status ---\")\n",
        "os.system('nvidia-smi')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to terminate zombie processes...\nProcess with PID 65870 not found. It may have already terminated.\nProcess with PID 160892 not found. It may have already terminated.\nProcess with PID 202112 not found. It may have already terminated.\nProcess with PID 414196 not found. It may have already terminated.\nProcess with PID 454240 not found. It may have already terminated.\nProcess termination attempt finished.\n\n--- Running nvidia-smi to check GPU status ---\nFri Sep 26 23:20:27 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |    9472MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "id": "ecc4d745-99c8-4e79-aa7c-19a7ef44d72c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## 0. Environment Cleanup\n",
        "# Attempt to clear GPU memory from stale processes before starting.\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(f\"Initial GPU Memory reserved: {torch.cuda.memory_reserved() / 1E9:.2f} GB\")\n",
        "    print(f\"Initial GPU Memory allocated: {torch.cuda.memory_allocated() / 1E9:.2f} GB\")\n",
        "\n",
        "gc.collect()\n",
        "print(\"CUDA cache and garbage collection cleanup attempted.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "343eb7ac-8b6e-4dfd-9748-4695756e2c63",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## 1. Imports & Configuration\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm.auto import tqdm\n",
        "import gc\n",
        "import random\n",
        "\n",
        "# --- Centralized Preprocessing Function ---\n",
        "# This should be identical to the one used in training.\n",
        "def asinh_transform(x):\n",
        "    return np.arcsinh(x)\n",
        "\n",
        "def clip_and_normalize(x, clip_percentiles=(0.1, 99.9)):\n",
        "    lower, upper = np.percentile(x, clip_percentiles)\n",
        "    x_clipped = np.clip(x, lower, upper)\n",
        "    x_normalized = (x_clipped - x_clipped.min()) / (x_clipped.max() - x_clipped.min())\n",
        "    return x_normalized\n",
        "\n",
        "def load_and_preprocess(file_path, transform_type='asinh', clip_percentiles=(0.1, 99.9)):\n",
        "    x = np.load(file_path).astype(np.float32)\n",
        "    \n",
        "    # The data has 6 signals, but the model expects 3 channels.\n",
        "    # A common strategy is to use the first 3 (on-target).\n",
        "    # This must match the preprocessing used in training.\n",
        "    x = x[:3] # Select the first 3 signals -> shape (3, H, W)\n",
        "    \n",
        "    # Apply transform if specified\n",
        "    if transform_type == 'asinh':\n",
        "        x = asinh_transform(x)\n",
        "    \n",
        "    # Normalize each of the 3 channels independently\n",
        "    channels = []\n",
        "    for i in range(x.shape[0]):\n",
        "        ch_normalized = clip_and_normalize(x[i], clip_percentiles)\n",
        "        channels.append(ch_normalized)\n",
        "    x = np.stack(channels, axis=0)\n",
        "    \n",
        "    # Reshape to (H, W, C) for albumentations\n",
        "    x = np.transpose(x, (1, 2, 0))\n",
        "    return x\n",
        "\n",
        "# --- Determinism ---\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class CFG:\n",
        "    # General\n",
        "    seed = 42\n",
        "    \n",
        "    # Paths\n",
        "    data_dir = '.'\n",
        "    test_path = os.path.join(data_dir, 'test')\n",
        "    sample_submission_path = os.path.join(data_dir, 'sample_submission.csv')\n",
        "    model_dir = '.'\n",
        "    \n",
        "    # Preprocessing (must match training)\n",
        "    preprocess_transform_type = 'asinh'\n",
        "    clip_percentiles = (0.1, 99.9)\n",
        "    \n",
        "    # Model (must match training)\n",
        "    model_name = 'tf_efficientnet_b3_ns'\n",
        "    img_size = 256\n",
        "    in_channels = 3\n",
        "    num_classes = 1\n",
        "    \n",
        "    # Inference\n",
        "    batch_size = 16 # <-- AGGRESSIVELY REDUCED BATCH SIZE TO PREVENT OOM\n",
        "    n_folds = 2\n",
        "    use_tta = False # <-- DISABLED TTA TO PREVENT OOM\n",
        "    \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- Apply Seed ---\n",
        "seed_everything(CFG.seed)\n",
        "\n",
        "print(f\"Using device: {CFG.device}\")\n",
        "print(f\"TTA Enabled: {CFG.use_tta}\")\n",
        "print(f\"Model: {CFG.model_name}\")\n",
        "print(f\"Ensembling {CFG.n_folds} folds.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "3741979e-df0f-4b37-9ee6-9ee7d85be881",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## 2. Dataset, Model, and Inference Functions\n",
        "\n",
        "# --- Test Dataset ---\n",
        "# This is a simplified version of the training dataset, without labels.\n",
        "class SETITestDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.file_paths = df['file_path'].values\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        \n",
        "        # Use the centralized preprocessing function from the first cell\n",
        "        image = load_and_preprocess(\n",
        "            file_path,\n",
        "            transform_type=CFG.preprocess_transform_type,\n",
        "            clip_percentiles=CFG.clip_percentiles\n",
        "        )\n",
        "        \n",
        "        # Ensure image is HWC for Albumentations\n",
        "        if image.ndim == 3 and image.shape[0] == 3:\n",
        "            image = np.transpose(image, (1, 2, 0))\n",
        "        \n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "            \n",
        "        return image\n",
        "\n",
        "# --- Model Definition (must match training) ---\n",
        "class SETIModel(nn.Module):\n",
        "    def __init__(self, model_name=CFG.model_name, pretrained=False): # Set pretrained=False for inference\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=CFG.in_channels, num_classes=CFG.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "# --- Inference Function ---\n",
        "def inference_fn(test_loader, model, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    pbar = tqdm(test_loader, desc='Inferring')\n",
        "    with torch.no_grad():\n",
        "        for images in pbar:\n",
        "            images = images.to(device)\n",
        "            y_preds = model(images)\n",
        "            preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
        "    \n",
        "    predictions = np.concatenate(preds).flatten()\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "3c42f7b9-2e29-48a2-89bd-8bbdf8172484",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## 3. Main Inference Loop\n",
        "\n",
        "# --- Define Transforms ---\n",
        "# Base transform (no augmentation)\n",
        "def get_base_transforms():\n",
        "    return A.Compose([\n",
        "        A.Resize(CFG.img_size, CFG.img_size),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "# TTA transform (with horizontal flip)\n",
        "def get_tta_transforms():\n",
        "    return A.Compose([\n",
        "        A.Resize(CFG.img_size, CFG.img_size),\n",
        "        A.HorizontalFlip(p=1.0), # Always apply for TTA\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "# --- Prepare Test Data ---\n",
        "test_df = pd.read_csv(CFG.sample_submission_path)\n",
        "\n",
        "def get_test_file_path(image_id):\n",
        "    return f\"{CFG.test_path}/{image_id[0]}/{image_id}.npy\"\n",
        "\n",
        "test_df['file_path'] = test_df['id'].apply(get_test_file_path)\n",
        "print(f\"Test dataframe shape: {test_df.shape}\")\n",
        "print(test_df.head())\n",
        "\n",
        "# --- Run Inference ---\n",
        "final_preds = np.zeros(len(test_df))\n",
        "\n",
        "for fold in range(CFG.n_folds):\n",
        "    print(f\"\\n========== INFERRING FOLD {fold} ==========\")\n",
        "    \n",
        "    # --- Load Model ---\n",
        "    model_path = os.path.join(CFG.model_dir, f'{CFG.model_name}_fold{fold}_best.pth')\n",
        "    model = SETIModel(pretrained=False)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.to(CFG.device)\n",
        "    \n",
        "    # --- Base Inference ---\n",
        "    test_dataset = SETITestDataset(test_df, transform=get_base_transforms())\n",
        "    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "    fold_preds = inference_fn(test_loader, model, CFG.device)\n",
        "    \n",
        "    # --- TTA Inference ---\n",
        "    if CFG.use_tta:\n",
        "        print(\"Running TTA (Horizontal Flip)...\")\n",
        "        tta_dataset = SETITestDataset(test_df, transform=get_tta_transforms())\n",
        "        tta_loader = DataLoader(tta_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "        tta_preds = inference_fn(tta_loader, model, CFG.device)\n",
        "        # Average base and TTA predictions for this fold\n",
        "        fold_preds = (fold_preds + tta_preds) / 2.0\n",
        "    \n",
        "    # Accumulate predictions (ensembled by averaging)\n",
        "    final_preds += fold_preds / CFG.n_folds\n",
        "    \n",
        "    del model, test_dataset, test_loader\n",
        "    if CFG.use_tta:\n",
        "        del tta_dataset, tta_loader\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# --- Create Submission File ---\n",
        "submission = test_df[['id']].copy()\n",
        "submission['target'] = final_preds\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\nInference complete.\")\n",
        "print(\"Submission file created: submission.csv\")\n",
        "print(submission.head())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}