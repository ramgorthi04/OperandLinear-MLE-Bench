{
  "cells": [
    {
      "id": "89a646b6-fbef-4e40-b9c3-d48d169ca64d",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OOF Parity Audit\n",
        "\n",
        "This notebook verifies that the predictions saved in `oof_predictions.csv` can be reproduced exactly by loading the saved models and running inference on the corresponding validation data. This is a critical step to ensure there are no bugs in the training/validation pipeline (e.g., incorrect data augmentations being applied during validation, wrong model being saved/loaded, etc.)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "23955595-7277-4fbc-a364-ac22c7a0a743",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 1. Imports & Configuration\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from utils_preproc import load_and_preprocess\n",
        "\n",
        "# This configuration MUST match the one used for training in `01_seti_baseline.ipynb`\n",
        "class CFG:\n",
        "    data_dir = '.'\n",
        "    train_path = os.path.join(data_dir, 'train')\n",
        "    train_labels_path = os.path.join(data_dir, 'train_labels.csv')\n",
        "    oof_preds_path = 'oof_predictions.csv'\n",
        "    \n",
        "    model_name = 'tf_efficientnet_b0_ns'\n",
        "    img_size = 256\n",
        "    in_channels = 3\n",
        "    num_classes = 1\n",
        "    \n",
        "    batch_size = 128 # Can be larger for inference\n",
        "    n_folds = 5\n",
        "    seed = 42\n",
        "    \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"Using device: {CFG.device}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "id": "fc0b86c4-91e4-4dab-b104-7e5f2c5f8508",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 2. Load Data & Recreate Folds\n",
        "\n",
        "# Load the original training labels\n",
        "df = pd.read_csv(CFG.train_labels_path)\n",
        "df['group'] = df['id'].apply(lambda x: x[:2])\n",
        "def get_train_file_path(image_id):\n",
        "    return f\"{CFG.train_path}/{image_id[0]}/{image_id}.npy\"\n",
        "df['file_path'] = df['id'].apply(get_train_file_path)\n",
        "\n",
        "# Recreate the exact same folds used in training\n",
        "skf = StratifiedGroupKFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['target'], df['group'])):\n",
        "    df.loc[val_idx, 'fold'] = int(fold)\n",
        "df['fold'] = df['fold'].astype(int)\n",
        "\n",
        "print(\"Folds recreated successfully.\")\n",
        "print(df.head())\n",
        "\n",
        "# Load the OOF predictions that were saved during training\n",
        "oof_df = pd.read_csv(CFG.oof_preds_path)\n",
        "print(\"\\nOOF predictions file loaded:\")\n",
        "print(oof_df.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folds recreated successfully.\n                id  target group                      file_path  fold\n0  d5d85dafc41d5b3       0    d5  ./train/d/d5d85dafc41d5b3.npy     2\n1  6170c3d29bd5874       0    61  ./train/6/6170c3d29bd5874.npy     0\n2  87989f418ca1301       0    87  ./train/8/87989f418ca1301.npy     1\n3  3087c24fbcb2c3b       0    30  ./train/3/3087c24fbcb2c3b.npy     3\n4  8b04fea0d8d49c8       0    8b  ./train/8/8b04fea0d8d49c8.npy     0\n\nOOF predictions file loaded:\n                id  target   preds\n0  6170c3d29bd5874       0  0.1703\n1  8b04fea0d8d49c8       0  0.3818\n2  3ee4f147a176231       0  0.3848\n3  3883652d935831a       0  0.1525\n4  3ec3a45d56e31a4       1  0.6200\n"
          ]
        }
      ]
    },
    {
      "id": "a6f5a8d1-1dec-48cf-82c0-550343b590b3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 3. Define Model, Dataset, and Transforms for Re-prediction\n",
        "\n",
        "# Transforms must be identical to the validation transforms in the training script\n",
        "def get_transforms():\n",
        "    return A.Compose([\n",
        "        A.Resize(CFG.img_size, CFG.img_size),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "# Dataset class must be identical\n",
        "class SETIDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.file_paths = df['file_path'].values\n",
        "        self.labels = df['target'].values\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        image = load_and_preprocess(file_path, do_asinh=True)\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "        label = torch.tensor(self.labels[idx]).float()\n",
        "        return image, label\n",
        "\n",
        "# Model class must be identical\n",
        "class SETIModel(nn.Module):\n",
        "    def __init__(self, model_name=CFG.model_name, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=CFG.in_channels, num_classes=CFG.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "id": "1a9f60be-501b-4bec-8c3e-56f56a9c3f2d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 4. Perform Parity Check for a Single Fold\n",
        "\n",
        "def re_predict_fold(fold_num):\n",
        "    print(f\"--- Verifying Fold {fold_num} ---\")\n",
        "    \n",
        "    # 1. Get validation data for this fold\n",
        "    valid_df = df[df['fold'] == fold_num].reset_index(drop=True)\n",
        "    \n",
        "    # 2. Create dataset and dataloader (no augmentations, as in validation)\n",
        "    valid_dataset = SETIDataset(valid_df, transform=get_transforms())\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "    \n",
        "    # 3. Load the trained model for this fold\n",
        "    model = SETIModel().to(CFG.device)\n",
        "    model_path = f'{CFG.model_name}_fold{fold_num}_best.pth'\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "    \n",
        "    # 4. Run inference to get new predictions\n",
        "    re_preds = []\n",
        "    with torch.no_grad():\n",
        "        for images, _ in tqdm(valid_loader, desc=f\"Re-predicting Fold {fold_num}\"):\n",
        "            images = images.to(CFG.device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                y_preds = model(images)\n",
        "            re_preds.append(y_preds.sigmoid().to('cpu').numpy())\n",
        "    \n",
        "    re_preds = np.concatenate(re_preds).flatten()\n",
        "    \n",
        "    # 5. Get the original OOF predictions for this fold\n",
        "    original_oof_preds = oof_df[oof_df['id'].isin(valid_df['id'])].sort_values('id')['preds'].values\n",
        "    # We need to sort both by ID to ensure they align\n",
        "    temp_df = pd.DataFrame({'id': valid_df['id'], 're_pred': re_preds}).sort_values('id')\n",
        "    aligned_re_preds = temp_df['re_pred'].values\n",
        "    \n",
        "    # 6. Compare the predictions\n",
        "    print(f\"Number of original preds: {len(original_oof_preds)}\")\n",
        "    print(f\"Number of re-calculated preds: {len(aligned_re_preds)}\")\n",
        "    \n",
        "    # Display first 5 predictions for a manual check\n",
        "    print(\"\\nFirst 5 Original OOF Preds:\", original_oof_preds[:5])\n",
        "    print(\"First 5 Re-calculated Preds:\", aligned_re_preds[:5])\n",
        "    \n",
        "    # Check if they are numerically close\n",
        "    is_close = np.allclose(original_oof_preds, aligned_re_preds, rtol=1e-4, atol=1e-6)\n",
        "    print(f\"\\nParity Check Passed for Fold {fold_num}: {is_close}\")\n",
        "    if not is_close:\n",
        "        diff = np.abs(original_oof_preds - aligned_re_preds)\n",
        "        print(f\"Max absolute difference: {np.max(diff)}\")\n",
        "        print(f\"Mean absolute difference: {np.mean(diff)}\")\n",
        "    \n",
        "    return is_close, aligned_re_preds\n",
        "\n",
        "# Run the check for Fold 0 and capture the re-calculated predictions\n",
        "parity_ok, aligned_re_preds_fold0 = re_predict_fold(fold_num=0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Verifying Fold 0 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:   0%|          | 0/84 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_70308/826619958.py:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n\rRe-predicting Fold 0:   1%|          | 1/84 [00:01<01:58,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:   5%|\u258d         | 4/84 [00:01<00:24,  3.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:   7%|\u258b         | 6/84 [00:02<00:29,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  11%|\u2588         | 9/84 [00:03<00:24,  3.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  14%|\u2588\u258d        | 12/84 [00:03<00:15,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  17%|\u2588\u258b        | 14/84 [00:04<00:17,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  20%|\u2588\u2588        | 17/84 [00:04<00:17,  3.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  26%|\u2588\u2588\u258c       | 22/84 [00:05<00:14,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  30%|\u2588\u2588\u2589       | 25/84 [00:06<00:14,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  33%|\u2588\u2588\u2588\u258e      | 28/84 [00:06<00:09,  5.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  36%|\u2588\u2588\u2588\u258c      | 30/84 [00:07<00:12,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  39%|\u2588\u2588\u2588\u2589      | 33/84 [00:08<00:12,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  43%|\u2588\u2588\u2588\u2588\u258e     | 36/84 [00:08<00:08,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  45%|\u2588\u2588\u2588\u2588\u258c     | 38/84 [00:09<00:10,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  49%|\u2588\u2588\u2588\u2588\u2589     | 41/84 [00:09<00:10,  4.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 44/84 [00:10<00:07,  5.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 46/84 [00:10<00:08,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 49/84 [00:11<00:08,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 52/84 [00:11<00:05,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 54/84 [00:12<00:06,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 57/84 [00:13<00:06,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 60/84 [00:13<00:04,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 62/84 [00:14<00:04,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 65/84 [00:14<00:04,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 68/84 [00:15<00:02,  5.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 70/84 [00:15<00:03,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 73/84 [00:16<00:02,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 76/84 [00:16<00:01,  5.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 78/84 [00:17<00:01,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 81/84 [00:18<00:00,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 84/84 [00:18<00:00,  6.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rRe-predicting Fold 0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 84/84 [00:18<00:00,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of original preds: 10684\nNumber of re-calculated preds: 10684\n\nFirst 5 Original OOF Preds: [0.4     0.4546  0.3237  0.02014 0.3823 ]\nFirst 5 Re-calculated Preds: [0.4     0.4546  0.3237  0.02014 0.3823 ]\n\nParity Check Passed for Fold 0: False\nMax absolute difference: 0.00024218750000004619\nMean absolute difference: 3.2158787889098195e-05\n"
          ]
        }
      ]
    },
    {
      "id": "6c04b9b8-9830-4fa1-9f21-979a0a26e6ec",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 5. Sanity Checks (as per Expert Advice)\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Check 1: Per-fold AUC for the re-predicted fold\n",
        "print(\"--- Sanity Check 1: Re-calculated Fold 0 AUC ---\")\n",
        "# Use the 'aligned_re_preds_fold0' variable captured from the previous cell\n",
        "valid_sorted = df[df.fold==0].sort_values('id').reset_index(drop=True)\n",
        "recalculated_auc = roc_auc_score(valid_sorted['target'].values, aligned_re_preds_fold0)\n",
        "print(f'Re-calculated AUC for Fold 0: {recalculated_auc:.4f}')\n",
        "print(f\"Original AUC reported for Fold 0 in training log: 0.5535\")\n",
        "\n",
        "# Check 2: Global OOF AUC from the saved file\n",
        "print(\"\\n--- Sanity Check 2: Global OOF AUC from file ---\")\n",
        "oof_df_loaded = pd.read_csv('oof_predictions.csv')\n",
        "# Merge with original df to get targets, ensuring alignment\n",
        "merged_oof = df[['id','target']].merge(oof_df_loaded, on='id', how='inner')\n",
        "# When merging, pandas creates 'target_x' (from left df) and 'target_y' (from right df)\n",
        "global_oof_auc = roc_auc_score(merged_oof.target_x, merged_oof.preds)\n",
        "print(f'Global OOF AUC calculated from file: {global_oof_auc:.4f}')\n",
        "print(f\"Global OOF AUC reported in training log: 0.5561\")\n",
        "print(f'OOF preds min/max/mean: {merged_oof.preds.min():.4f} / {merged_oof.preds.max():.4f} / {merged_oof.preds.mean():.4f}')\n",
        "\n",
        "# Check 3: Quick model weight sanity check\n",
        "print(\"\\n--- Sanity Check 3: Model Weight Sanity ---\")\n",
        "for f in range(CFG.n_folds):\n",
        "    try:\n",
        "        m = SETIModel()\n",
        "        m.load_state_dict(torch.load(f'{CFG.model_name}_fold{f}_best.pth'))\n",
        "        w = next(m.parameters())\n",
        "        print(f'Fold {f} weight mean/std: {float(w.mean()):.6f} / {float(w.std()):.6f}')\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load model for fold {f}: {e}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Sanity Check 1: Re-calculated Fold 0 AUC ---\nRe-calculated AUC for Fold 0: 0.5535\nOriginal AUC reported for Fold 0 in training log: 0.5535\n\n--- Sanity Check 2: Global OOF AUC from file ---\nGlobal OOF AUC calculated from file: 0.5561\nGlobal OOF AUC reported in training log: 0.5561\nOOF preds min/max/mean: 0.0000 / 1.0000 / 0.3005\n\n--- Sanity Check 3: Model Weight Sanity ---\nFold 0 weight mean/std: -0.035266 / 0.868574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n  model = create_fn(\n/tmp/ipykernel_70308/3118322521.py:31: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\nConsider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n  print(f'Fold {f} weight mean/std: {float(w.mean()):.6f} / {float(w.std()):.6f}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 weight mean/std: -0.034986 / 0.868564\nFold 2 weight mean/std: -0.035462 / 0.868543\nFold 3 weight mean/std: -0.035098 / 0.868546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 weight mean/std: -0.034933 / 0.868580\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}