{
  "cells": [
    {
      "id": "643de9a3-bcff-491d-9f44-4496e02d8efc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 1. Setup & Configuration\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm.auto import tqdm\n",
        "import gc\n",
        "\n",
        "# Configuration - should match the training notebook\n",
        "class CFG:\n",
        "    data_dir = '.'\n",
        "    test_path = os.path.join(data_dir, 'test')\n",
        "    sample_submission_path = os.path.join(data_dir, 'sample_submission.csv')\n",
        "    model_paths = [f'tf_efficientnet_b0_ns_fold{i}_best.pth' for i in range(5)]\n",
        "    \n",
        "    model_name = 'tf_efficientnet_b0_ns'\n",
        "    img_size = 256\n",
        "    in_channels = 3\n",
        "    num_classes = 1\n",
        "    \n",
        "    batch_size = 128 # Can be larger for inference\n",
        "    n_folds = 5\n",
        "    \n",
        "    tta = True # Enable Test-Time Augmentation\n",
        "    \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"Using device: {CFG.device}\")\n",
        "print(f\"TTA enabled: {CFG.tta}\")\n",
        "print(f\"Models to load: {CFG.model_paths}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\nTTA enabled: True\nModels to load: ['tf_efficientnet_b0_ns_fold0_best.pth', 'tf_efficientnet_b0_ns_fold1_best.pth', 'tf_efficientnet_b0_ns_fold2_best.pth', 'tf_efficientnet_b0_ns_fold3_best.pth', 'tf_efficientnet_b0_ns_fold4_best.pth']\n"
          ]
        }
      ]
    },
    {
      "id": "49d07e08-ca64-4c12-9e0b-5b3e63a6d1d9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 2. Data Loading & Preprocessing\n",
        "\n",
        "from utils_preproc import load_and_preprocess # Import shared preprocessing\n",
        "\n",
        "def get_test_file_path(image_id):\n",
        "    return f\"{CFG.test_path}/{image_id[0]}/{image_id}.npy\"\n",
        "\n",
        "test_df = pd.read_csv(CFG.sample_submission_path)\n",
        "test_df['file_path'] = test_df['id'].apply(get_test_file_path)\n",
        "\n",
        "print(\"Test dataframe:\")\n",
        "print(test_df.head())\n",
        "\n",
        "# TTA transforms - only no-flip and h-flip, as per expert advice\n",
        "def get_transforms(h_flip=False):\n",
        "    transforms = [A.Resize(CFG.img_size, CFG.img_size)]\n",
        "    if h_flip:\n",
        "        transforms.append(A.HorizontalFlip(p=1.0))\n",
        "    transforms.append(ToTensorV2())\n",
        "    return A.Compose(transforms)\n",
        "\n",
        "class SETITestDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.file_paths = df['file_path'].values\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.file_paths[idx]\n",
        "        \n",
        "        # Use the centralized preprocessing function to ensure consistency\n",
        "        image = load_and_preprocess(file_path, do_asinh=True)\n",
        "        \n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "            \n",
        "        return image"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataframe:\n                id  target                     file_path\n0  0cee567456cd304     0.5  ./test/0/0cee567456cd304.npy\n1  5451b45281c65a7     0.5  ./test/5/5451b45281c65a7.npy\n2  f8cc6cea820282d     0.5  ./test/f/f8cc6cea820282d.npy\n3  25e21ba81a64742     0.5  ./test/2/25e21ba81a64742.npy\n4  aafa910406b1db2     0.5  ./test/a/aafa910406b1db2.npy\n"
          ]
        }
      ]
    },
    {
      "id": "d0755b4b-38de-43ad-b621-1525288f546f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 3. Model Definition\n",
        "\n",
        "class SETIModel(nn.Module):\n",
        "    def __init__(self, model_name=CFG.model_name, pretrained=False): # Set pretrained=False for loading local weights\n",
        "        super().__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=CFG.in_channels, num_classes=CFG.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "id": "c28f757f-0f62-4a92-b07b-ff9f5e9b578a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 4. Inference Function\n",
        "\n",
        "def inference(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    \n",
        "    pbar = tqdm(test_loader, desc='Inference')\n",
        "    with torch.no_grad():\n",
        "        for images in pbar:\n",
        "            images = images.to(device)\n",
        "            \n",
        "            # Use AMP for inference as well for consistency and speed\n",
        "            with torch.cuda.amp.autocast():\n",
        "                y_preds = model(images)\n",
        "            \n",
        "            predictions.append(y_preds.sigmoid().to('cpu').numpy())\n",
        "            \n",
        "    return np.concatenate(predictions).flatten()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "id": "02a5ee07-1127-4dff-9d0a-427f69c82265",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 5. Main Inference & Submission Generation\n",
        "\n",
        "all_preds = []\n",
        "\n",
        "for model_path in CFG.model_paths:\n",
        "    print(f\"--- Inferring with {model_path} ---\")\n",
        "    model = SETIModel()\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    \n",
        "    fold_preds = []\n",
        "    \n",
        "    if CFG.tta:\n",
        "        # TTA: no flip, h-flip (as per expert advice and training setup)\n",
        "        tta_transforms = [\n",
        "            get_transforms(h_flip=False),\n",
        "            get_transforms(h_flip=True),\n",
        "        ]\n",
        "        \n",
        "        tta_preds = []\n",
        "        for i, transform in enumerate(tta_transforms):\n",
        "            print(f\"  > TTA pass {i+1}/{len(tta_transforms)}\")\n",
        "            test_dataset = SETITestDataset(test_df, transform=transform)\n",
        "            test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "            \n",
        "            preds = inference(model, test_loader, CFG.device)\n",
        "            tta_preds.append(preds)\n",
        "            \n",
        "        # Average TTA predictions\n",
        "        fold_preds = np.mean(tta_preds, axis=0)\n",
        "        \n",
        "    else:\n",
        "        # No TTA\n",
        "        test_dataset = SETITestDataset(test_df, transform=get_transforms())\n",
        "        test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "        fold_preds = inference(model, test_loader, CFG.device)\n",
        "        \n",
        "    all_preds.append(fold_preds)\n",
        "    \n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Ensemble by averaging predictions across folds\n",
        "final_preds = np.mean(all_preds, axis=0)\n",
        "\n",
        "# Create submission file\n",
        "submission = pd.DataFrame({'id': test_df['id'], 'target': final_preds})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\nSubmission file created: submission.csv\")\n",
        "print(submission.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Inferring with tf_efficientnet_b0_ns_fold0_best.pth ---\n  > TTA pass 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   0%|          | 0/47 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_19643/4095927241.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n\rInference:   2%|\u258f         | 1/47 [00:01<01:01,  1.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   6%|\u258b         | 3/47 [00:01<00:17,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  11%|\u2588         | 5/47 [00:02<00:18,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  17%|\u2588\u258b        | 8/47 [00:02<00:09,  4.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  21%|\u2588\u2588\u258f       | 10/47 [00:03<00:10,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  28%|\u2588\u2588\u258a       | 13/47 [00:04<00:09,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  34%|\u2588\u2588\u2588\u258d      | 16/47 [00:04<00:05,  5.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  38%|\u2588\u2588\u2588\u258a      | 18/47 [00:04<00:06,  4.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  45%|\u2588\u2588\u2588\u2588\u258d     | 21/47 [00:05<00:06,  4.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  51%|\u2588\u2588\u2588\u2588\u2588     | 24/47 [00:05<00:04,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 26/47 [00:06<00:04,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 29/47 [00:07<00:04,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 32/47 [00:07<00:02,  5.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 34/47 [00:08<00:02,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 36/47 [00:08<00:01,  5.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 38/47 [00:09<00:02,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 41/47 [00:09<00:01,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 44/47 [00:10<00:00,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 46/47 [00:10<00:00,  4.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [00:10<00:00,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  > TTA pass 2/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   0%|          | 0/47 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   2%|\u258f         | 1/47 [00:01<00:58,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   6%|\u258b         | 3/47 [00:01<00:16,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  11%|\u2588         | 5/47 [00:02<00:17,  2.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  15%|\u2588\u258d        | 7/47 [00:02<00:10,  3.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  19%|\u2588\u2589        | 9/47 [00:03<00:11,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  23%|\u2588\u2588\u258e       | 11/47 [00:03<00:07,  4.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  28%|\u2588\u2588\u258a       | 13/47 [00:03<00:08,  3.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  30%|\u2588\u2588\u2589       | 14/47 [00:04<00:07,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  36%|\u2588\u2588\u2588\u258c      | 17/47 [00:04<00:06,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  38%|\u2588\u2588\u2588\u258a      | 18/47 [00:04<00:06,  4.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  45%|\u2588\u2588\u2588\u2588\u258d     | 21/47 [00:05<00:05,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  47%|\u2588\u2588\u2588\u2588\u258b     | 22/47 [00:05<00:05,  5.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 25/47 [00:06<00:04,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 26/47 [00:06<00:04,  4.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 29/47 [00:07<00:03,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 30/47 [00:07<00:03,  4.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 33/47 [00:07<00:02,  4.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 34/47 [00:08<00:02,  4.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 37/47 [00:08<00:02,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 38/47 [00:08<00:01,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 41/47 [00:09<00:01,  4.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 42/47 [00:09<00:01,  4.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 45/47 [00:10<00:00,  5.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 46/47 [00:10<00:00,  5.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [00:10<00:00,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Inferring with tf_efficientnet_b0_ns_fold1_best.pth ---\n  > TTA pass 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   0%|          | 0/47 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   2%|\u258f         | 1/47 [00:01<00:58,  1.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   6%|\u258b         | 3/47 [00:01<00:16,  2.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  11%|\u2588         | 5/47 [00:02<00:17,  2.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  13%|\u2588\u258e        | 6/47 [00:02<00:13,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  19%|\u2588\u2589        | 9/47 [00:03<00:10,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  21%|\u2588\u2588\u258f       | 10/47 [00:03<00:09,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  28%|\u2588\u2588\u258a       | 13/47 [00:03<00:08,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  32%|\u2588\u2588\u2588\u258f      | 15/47 [00:04<00:06,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  36%|\u2588\u2588\u2588\u258c      | 17/47 [00:04<00:07,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  40%|\u2588\u2588\u2588\u2588      | 19/47 [00:04<00:05,  5.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  45%|\u2588\u2588\u2588\u2588\u258d     | 21/47 [00:05<00:06,  4.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  51%|\u2588\u2588\u2588\u2588\u2588     | 24/47 [00:05<00:03,  5.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 26/47 [00:06<00:04,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 29/47 [00:07<00:04,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 31/47 [00:07<00:02,  5.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 33/47 [00:08<00:03,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 36/47 [00:08<00:01,  6.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 38/47 [00:08<00:01,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 41/47 [00:09<00:01,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 44/47 [00:09<00:00,  5.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 46/47 [00:10<00:00,  4.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [00:10<00:00,  4.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  > TTA pass 2/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   0%|          | 0/47 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   2%|\u258f         | 1/47 [00:01<01:00,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   6%|\u258b         | 3/47 [00:01<00:17,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  11%|\u2588         | 5/47 [00:02<00:17,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  17%|\u2588\u258b        | 8/47 [00:02<00:08,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  21%|\u2588\u2588\u258f       | 10/47 [00:03<00:10,  3.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  28%|\u2588\u2588\u258a       | 13/47 [00:03<00:09,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  34%|\u2588\u2588\u2588\u258d      | 16/47 [00:04<00:05,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  38%|\u2588\u2588\u2588\u258a      | 18/47 [00:04<00:06,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  45%|\u2588\u2588\u2588\u2588\u258d     | 21/47 [00:05<00:06,  4.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  51%|\u2588\u2588\u2588\u2588\u2588     | 24/47 [00:05<00:04,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 26/47 [00:06<00:04,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 28/47 [00:06<00:03,  5.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 30/47 [00:07<00:03,  4.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 33/47 [00:08<00:03,  4.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 36/47 [00:08<00:01,  5.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 38/47 [00:08<00:01,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 41/47 [00:09<00:01,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 44/47 [00:09<00:00,  5.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 46/47 [00:10<00:00,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [00:10<00:00,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Inferring with tf_efficientnet_b0_ns_fold2_best.pth ---\n  > TTA pass 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   0%|          | 0/47 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   2%|\u258f         | 1/47 [00:01<01:04,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   6%|\u258b         | 3/47 [00:01<00:17,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  11%|\u2588         | 5/47 [00:02<00:17,  2.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  17%|\u2588\u258b        | 8/47 [00:02<00:08,  4.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  21%|\u2588\u2588\u258f       | 10/47 [00:03<00:09,  3.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  28%|\u2588\u2588\u258a       | 13/47 [00:03<00:08,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  34%|\u2588\u2588\u2588\u258d      | 16/47 [00:04<00:05,  5.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  38%|\u2588\u2588\u2588\u258a      | 18/47 [00:04<00:06,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  45%|\u2588\u2588\u2588\u2588\u258d     | 21/47 [00:05<00:06,  4.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  51%|\u2588\u2588\u2588\u2588\u2588     | 24/47 [00:05<00:04,  5.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 26/47 [00:06<00:04,  4.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 29/47 [00:07<00:04,  4.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 32/47 [00:07<00:02,  5.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 34/47 [00:08<00:02,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 37/47 [00:08<00:02,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 40/47 [00:09<00:01,  5.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 42/47 [00:09<00:01,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 45/47 [00:10<00:00,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [00:10<00:00,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  > TTA pass 2/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   0%|          | 0/47 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   2%|\u258f         | 1/47 [00:01<00:59,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   6%|\u258b         | 3/47 [00:01<00:16,  2.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  11%|\u2588         | 5/47 [00:02<00:17,  2.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  15%|\u2588\u258d        | 7/47 [00:02<00:10,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  19%|\u2588\u2589        | 9/47 [00:03<00:11,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  23%|\u2588\u2588\u258e       | 11/47 [00:03<00:07,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  28%|\u2588\u2588\u258a       | 13/47 [00:03<00:08,  3.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  32%|\u2588\u2588\u2588\u258f      | 15/47 [00:04<00:06,  5.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  36%|\u2588\u2588\u2588\u258c      | 17/47 [00:04<00:07,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  40%|\u2588\u2588\u2588\u2588      | 19/47 [00:04<00:05,  5.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  45%|\u2588\u2588\u2588\u2588\u258d     | 21/47 [00:05<00:06,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  49%|\u2588\u2588\u2588\u2588\u2589     | 23/47 [00:05<00:04,  5.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 25/47 [00:06<00:05,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 27/47 [00:06<00:03,  5.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 29/47 [00:07<00:04,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 32/47 [00:07<00:02,  6.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 34/47 [00:08<00:02,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 37/47 [00:08<00:02,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 39/47 [00:08<00:01,  5.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 41/47 [00:09<00:01,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 44/47 [00:09<00:00,  6.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 46/47 [00:10<00:00,  4.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [00:10<00:00,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Inferring with tf_efficientnet_b0_ns_fold3_best.pth ---\n  > TTA pass 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   0%|          | 0/47 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   2%|\u258f         | 1/47 [00:01<01:05,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   6%|\u258b         | 3/47 [00:01<00:17,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  11%|\u2588         | 5/47 [00:02<00:18,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  17%|\u2588\u258b        | 8/47 [00:02<00:09,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  21%|\u2588\u2588\u258f       | 10/47 [00:03<00:10,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  28%|\u2588\u2588\u258a       | 13/47 [00:04<00:08,  3.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  32%|\u2588\u2588\u2588\u258f      | 15/47 [00:04<00:06,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  36%|\u2588\u2588\u2588\u258c      | 17/47 [00:04<00:07,  4.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  43%|\u2588\u2588\u2588\u2588\u258e     | 20/47 [00:04<00:04,  5.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  47%|\u2588\u2588\u2588\u2588\u258b     | 22/47 [00:05<00:05,  4.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 25/47 [00:06<00:05,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 28/47 [00:06<00:03,  5.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 30/47 [00:07<00:03,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 33/47 [00:08<00:03,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 35/47 [00:08<00:02,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 37/47 [00:08<00:02,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 39/47 [00:09<00:01,  5.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 41/47 [00:09<00:01,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 43/47 [00:09<00:00,  5.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 45/47 [00:10<00:00,  4.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [00:10<00:00,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  > TTA pass 2/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   0%|          | 0/47 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   2%|\u258f         | 1/47 [00:01<01:02,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   6%|\u258b         | 3/47 [00:01<00:17,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  11%|\u2588         | 5/47 [00:02<00:18,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  17%|\u2588\u258b        | 8/47 [00:02<00:09,  4.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  21%|\u2588\u2588\u258f       | 10/47 [00:03<00:10,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  28%|\u2588\u2588\u258a       | 13/47 [00:04<00:09,  3.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  34%|\u2588\u2588\u2588\u258d      | 16/47 [00:04<00:05,  5.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  38%|\u2588\u2588\u2588\u258a      | 18/47 [00:05<00:06,  4.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  45%|\u2588\u2588\u2588\u2588\u258d     | 21/47 [00:05<00:06,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  49%|\u2588\u2588\u2588\u2588\u2589     | 23/47 [00:05<00:04,  5.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 25/47 [00:06<00:05,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 26/47 [00:06<00:04,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 29/47 [00:07<00:03,  4.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 32/47 [00:07<00:02,  6.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 34/47 [00:08<00:02,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 37/47 [00:08<00:02,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 40/47 [00:09<00:01,  5.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 42/47 [00:09<00:01,  4.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 45/47 [00:10<00:00,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [00:10<00:00,  4.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Inferring with tf_efficientnet_b0_ns_fold4_best.pth ---\n  > TTA pass 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   0%|          | 0/47 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   2%|\u258f         | 1/47 [00:01<01:00,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   6%|\u258b         | 3/47 [00:01<00:16,  2.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  11%|\u2588         | 5/47 [00:02<00:18,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  15%|\u2588\u258d        | 7/47 [00:02<00:10,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  19%|\u2588\u2589        | 9/47 [00:03<00:11,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  26%|\u2588\u2588\u258c       | 12/47 [00:03<00:06,  5.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  30%|\u2588\u2588\u2589       | 14/47 [00:04<00:08,  4.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  36%|\u2588\u2588\u2588\u258c      | 17/47 [00:04<00:07,  4.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  43%|\u2588\u2588\u2588\u2588\u258e     | 20/47 [00:04<00:04,  5.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  47%|\u2588\u2588\u2588\u2588\u258b     | 22/47 [00:05<00:05,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 25/47 [00:06<00:05,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 27/47 [00:06<00:03,  5.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 29/47 [00:07<00:04,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 32/47 [00:07<00:02,  5.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 34/47 [00:08<00:02,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 37/47 [00:08<00:02,  4.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 39/47 [00:09<00:01,  5.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 41/47 [00:09<00:01,  4.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 44/47 [00:09<00:00,  5.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 46/47 [00:10<00:00,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [00:10<00:00,  4.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  > TTA pass 2/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   0%|          | 0/47 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   2%|\u258f         | 1/47 [00:01<00:59,  1.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:   6%|\u258b         | 3/47 [00:01<00:16,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  11%|\u2588         | 5/47 [00:02<00:17,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  15%|\u2588\u258d        | 7/47 [00:02<00:10,  3.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  19%|\u2588\u2589        | 9/47 [00:03<00:11,  3.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  23%|\u2588\u2588\u258e       | 11/47 [00:03<00:07,  4.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  28%|\u2588\u2588\u258a       | 13/47 [00:03<00:08,  3.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  32%|\u2588\u2588\u2588\u258f      | 15/47 [00:04<00:06,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  36%|\u2588\u2588\u2588\u258c      | 17/47 [00:04<00:07,  4.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  40%|\u2588\u2588\u2588\u2588      | 19/47 [00:04<00:05,  5.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  45%|\u2588\u2588\u2588\u2588\u258d     | 21/47 [00:05<00:06,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  49%|\u2588\u2588\u2588\u2588\u2589     | 23/47 [00:05<00:04,  5.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 25/47 [00:06<00:05,  4.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 26/47 [00:06<00:04,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 29/47 [00:07<00:03,  4.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 30/47 [00:07<00:03,  4.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 33/47 [00:08<00:03,  4.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 35/47 [00:08<00:02,  5.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 37/47 [00:08<00:02,  4.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 39/47 [00:08<00:01,  5.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 41/47 [00:09<00:01,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 43/47 [00:09<00:00,  5.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 45/47 [00:10<00:00,  4.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rInference: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [00:10<00:00,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nSubmission file created: submission.csv\n                id    target\n0  0cee567456cd304  0.079834\n1  5451b45281c65a7  0.229614\n2  f8cc6cea820282d  0.112366\n3  25e21ba81a64742  0.179443\n4  aafa910406b1db2  0.157227\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}