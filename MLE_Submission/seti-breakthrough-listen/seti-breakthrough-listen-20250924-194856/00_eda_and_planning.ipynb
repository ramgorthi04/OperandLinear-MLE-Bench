{
  "cells": [
    {
      "id": "49182882-a749-493d-9dbb-4124d1a56ad1",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan: SETI Breakthrough Listen (MLE-Benchmark) \u2014 Medal-Oriented Workflow\n",
        "\n",
        "Objectives:\n",
        "- Establish a fast, correct baseline and robust CV that mirrors test.\n",
        "- Leverage GPU for modeling (likely CNN/1D-CNN on waterfall/spectrogram .npy, and/or fast GBMs on engineered features).\n",
        "- Iterate with OOF-driven improvements and simple ensembling.\n",
        "\n",
        "Data understanding (expected):\n",
        "- train/: signal files (likely .npy per id).\n",
        "- test/: same format without labels.\n",
        "- train_labels.csv: id,label mapping.\n",
        "- sample_submission.csv: required submission format.\n",
        "- old_leaky_data/: ignore for leakage safety unless validated by experts.\n",
        "\n",
        "Validation strategy:\n",
        "- Stratified KFold by label (5 folds) with deterministic seed.\n",
        "- No leakage from file ordering/neighboring samples. Fit transforms within fold only.\n",
        "\n",
        "Baseline roadmap:\n",
        "1) Environment & GPU check; torch install (CUDA 12.1 wheels), or use XGBoost/CatBoost GPU.\n",
        "2) EDA: verify counts, file presence per id, shapes/dtypes; quick visualization of a few signals.\n",
        "3) Fast baseline A: Simple feature extraction from arrays (stats across axes, spectrum bands) \u2192 XGBoost GPU. Target: achieve >0.74 AUC quickly.\n",
        "4) Baseline B: Lightweight CNN on downsampled spectrograms (PyTorch, mixed precision). Target: >0.76 AUC.\n",
        "5) Improve features: domain-inspired features (band energies, slopes, peaks, kurtosis, Hough-like line strength proxies).\n",
        "6) Tune and ensemble: blend GBM + CNN logits; calibrate if needed. Target: \u22650.775 (bronze) then push towards \u22650.781 (silver).\n",
        "\n",
        "Operational rules:\n",
        "- Subsample first (e.g., 10k rows, 2 folds) for smoke tests. Log elapsed times.\n",
        "- Cache features and OOF/test logits in .npy. Reuse for blends.\n",
        "- One change per run; track deltas.\n",
        "- Avoid old_leaky_data unless experts confirm a safe use.\n",
        "\n",
        "Next steps this notebook:\n",
        "A) Run GPU and repo sanity checks; list files.\n",
        "B) Load labels, verify id\u2194file mapping.\n",
        "C) Implement minimal feature extractor v0 and XGBoost GPU baseline with 5-fold CV.\n",
        "D) Save OOF/test preds; create submission.csv and verify format.\n",
        "\n",
        "Checkpoints for expert review:\n",
        "- After this plan (now).\n",
        "- After data loading/EDA and CV setup.\n",
        "- After baseline GBM OOF results.\n",
        "- After CNN baseline.\n",
        "- Before final blend and submission."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b686e4c6-6632-4ad2-b1b3-fdc217bd7948",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment and data sanity checks\n",
        "import os, sys, time, json, glob, random, math, shutil, subprocess, textwrap, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "start_time = time.time()\n",
        "def log(msg):\n",
        "    print(f\"[{time.strftime('%H:%M:%S')}] {msg}\", flush=True)\n",
        "\n",
        "# 1) GPU check\n",
        "log('Checking GPU with nvidia-smi...')\n",
        "try:\n",
        "    out = subprocess.run(['bash','-lc','nvidia-smi || true'], capture_output=True, text=True, check=False)\n",
        "    print(out.stdout)\n",
        "except Exception as e:\n",
        "    log(f'GPU check failed: {e}')\n",
        "\n",
        "# 2) List files\n",
        "base = Path('.')\n",
        "log('Listing key files...')\n",
        "print('CWD:', base.resolve())\n",
        "for p in ['train_labels.csv','sample_submission.csv','train','test','old_leaky_data']:\n",
        "    pp = base / p\n",
        "    print(f\"- {p} exists? {pp.exists()} type: {'dir' if pp.is_dir() else 'file' if pp.exists() else 'NA'}\")\n",
        "\n",
        "# 3) Load labels and sample submission\n",
        "lbl_path = base/'train_labels.csv'\n",
        "sub_path = base/'sample_submission.csv'\n",
        "assert lbl_path.exists(), 'train_labels.csv missing'\n",
        "assert sub_path.exists(), 'sample_submission.csv missing'\n",
        "\n",
        "train_labels = pd.read_csv(lbl_path)\n",
        "sample_sub = pd.read_csv(sub_path)\n",
        "log('train_labels head:')\n",
        "print(train_labels.head())\n",
        "log('sample_submission head:')\n",
        "print(sample_sub.head())\n",
        "\n",
        "# Basic label stats\n",
        "log('Label distribution:')\n",
        "print(train_labels['target'].value_counts(normalize=False).to_string())\n",
        "print(train_labels['target'].value_counts(normalize=True).round(4).to_string())\n",
        "\n",
        "# 4) Discover npy files\n",
        "train_dir = base/'train'\n",
        "test_dir = base/'test'\n",
        "train_files = sorted(glob.glob(str(train_dir/'**'/'*.npy'), recursive=True))\n",
        "test_files = sorted(glob.glob(str(test_dir/'**'/'*.npy'), recursive=True))\n",
        "log(f'Found {len(train_files)} train npy files and {len(test_files)} test npy files')\n",
        "print('First 5 train files:', train_files[:5])\n",
        "print('First 5 test files:', test_files[:5])\n",
        "\n",
        "# 5) Verify id<->file mapping (assumes filename stem is id)\n",
        "def stem(p):\n",
        "    return Path(p).stem\n",
        "train_stems = set(map(stem, train_files))\n",
        "test_stems = set(map(stem, test_files))\n",
        "ids_in_labels = set(train_labels['id'].astype(str).values)\n",
        "missing_files = ids_in_labels - train_stems\n",
        "extra_files = train_stems - ids_in_labels\n",
        "log(f'IDs in labels: {len(ids_in_labels)} | unique train file stems: {len(train_stems)}')\n",
        "log(f'Missing file for {len(missing_files)} ids (show up to 5): {list(sorted(missing_files))[:5]}')\n",
        "log(f'Extra train files without labels: {len(extra_files)} (show up to 5): {list(sorted(extra_files))[:5]}')\n",
        "\n",
        "# 6) Inspect shape/dtype of a few files\n",
        "def inspect_file(fp):\n",
        "    arr = np.load(fp, allow_pickle=False, mmap_mode=None)\n",
        "    return arr.shape, arr.dtype, np.nanmin(arr), np.nanmax(arr), np.nanmean(arr)\n",
        "\n",
        "for fp in random.sample(train_files, k=min(3, len(train_files))):\n",
        "    try:\n",
        "        shape, dtype, vmin, vmax, vmean = inspect_file(fp)\n",
        "        log(f'Inspect {Path(fp).name}: shape={shape}, dtype={dtype}, min={vmin:.4f}, max={vmax:.4f}, mean={vmean:.4f}')\n",
        "    except Exception as e:\n",
        "        log(f'Failed to load {fp}: {e}')\n",
        "\n",
        "# 7) Quick check: ensure sample_submission ids match test stems\n",
        "sub_ids = set(sample_sub['id'].astype(str).values)\n",
        "missing_test_for_sub = sub_ids - test_stems\n",
        "log(f'sample_submission ids: {len(sub_ids)}; test stems: {len(test_stems)}; missing in test for sub: {len(missing_test_for_sub)}')\n",
        "if missing_test_for_sub:\n",
        "    print('Example missing ids:', list(sorted(missing_test_for_sub))[:5])\n",
        "\n",
        "log(f'Done in {time.time()-start_time:.2f}s')\n",
        "\n",
        "# Notes for next steps:\n",
        "# - If shapes are (6,H,W), proceed with 6-ch pipeline (diffs + off channels).\n",
        "# - Save discovered mapping and stats for reuse.\n",
        "\n",
        "with open('data_discovery.json','w') as f:\n",
        "    json.dump({\n",
        "        'n_train_files': len(train_files),\n",
        "        'n_test_files': len(test_files),\n",
        "        'n_label_ids': len(ids_in_labels),\n",
        "        'missing_files_count': len(missing_files),\n",
        "        'extra_files_count': len(extra_files)\n",
        "    }, f, indent=2)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23:32:35] Checking GPU with nvidia-smi...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 24 23:32:35 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n[23:32:35] Listing key files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CWD: /var/lib/simon/agent_run_states/seti-breakthrough-listen-20250924-194856\n- train_labels.csv exists? True type: file\n- sample_submission.csv exists? True type: file\n- train exists? True type: dir\n- test exists? True type: dir\n- old_leaky_data exists? True type: dir\n[23:32:35] train_labels head:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                id  target\n0  d5d85dafc41d5b3       0\n1  6170c3d29bd5874       0\n2  87989f418ca1301       0\n3  3087c24fbcb2c3b       0\n4  8b04fea0d8d49c8       0\n[23:32:35] sample_submission head:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                id  target\n0  0cee567456cd304     0.5\n1  5451b45281c65a7     0.5\n2  f8cc6cea820282d     0.5\n3  25e21ba81a64742     0.5\n4  aafa910406b1db2     0.5\n[23:32:35] Label distribution:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target\n0    48634\n1     5366\ntarget\n0    0.9006\n1    0.0994\n[23:32:35] Found 54000 train npy files and 6000 test npy files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 train files: ['train/0/0000799a2b2c42d.npy', 'train/0/00042890562ff68.npy', 'train/0/0005364cdcb8e5b.npy', 'train/0/0007a5a46901c56.npy', 'train/0/0009283e145448e.npy']\nFirst 5 test files: ['test/0/0016fd6c09d476d.npy', 'test/0/0017643c1c5c254.npy', 'test/0/0024012d1431fbc.npy', 'test/0/0031e823c133be2.npy', 'test/0/0044e4104dffb33.npy']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23:32:35] IDs in labels: 54000 | unique train file stems: 54000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23:32:35] Missing file for 0 ids (show up to 5): []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23:32:35] Extra train files without labels: 0 (show up to 5): []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23:32:35] Inspect 2870a66a0120636.npy: shape=(6, 273, 256), dtype=float16, min=-0.6470, max=15.8984, mean=-0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23:32:35] Inspect 540cb12920f8d8b.npy: shape=(6, 273, 256), dtype=float16, min=-0.7539, max=15.9219, mean=0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23:32:35] Inspect 13a464f77b72d52.npy: shape=(6, 273, 256), dtype=float16, min=-0.7764, max=16.0000, mean=-0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23:32:35] sample_submission ids: 6000; test stems: 6000; missing in test for sub: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[23:32:35] Done in 0.29s\n"
          ]
        }
      ]
    },
    {
      "id": "91d1e009-a502-4b59-b6ed-1c4a4a71af31",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install PyTorch cu121 stack and deps, then sanity-check GPU\n",
        "import os, sys, subprocess, shutil, time\n",
        "from pathlib import Path\n",
        "\n",
        "start = time.time()\n",
        "def pip(*args):\n",
        "    print('> pip', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# 0) Uninstall any pre-existing torch stacks to avoid conflicts\n",
        "for pkg in ('torch','torchvision','torchaudio'):\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "\n",
        "# Clean stray site dirs that can shadow correct wheels (idempotent)\n",
        "for d in (\n",
        "    '/app/.pip-target/torch',\n",
        "    '/app/.pip-target/torch-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torch-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchvision',\n",
        "    '/app/.pip-target/torchvision-0.23.0.dist-info',\n",
        "    '/app/.pip-target/torchvision-0.19.1.dist-info',\n",
        "    '/app/.pip-target/torchaudio',\n",
        "    '/app/.pip-target/torchaudio-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torchaudio-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchgen',\n",
        "    '/app/.pip-target/functorch',\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d); shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# 1) Install EXACT cu121 torch stack\n",
        "pip('install',\n",
        "    '--index-url', 'https://download.pytorch.org/whl/cu121',\n",
        "    '--extra-index-url', 'https://pypi.org/simple',\n",
        "    'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1')\n",
        "\n",
        "# 2) Freeze torch versions for later installs\n",
        "Path('constraints.txt').write_text('torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n')\n",
        "\n",
        "# 3) Install non-torch deps honoring constraints\n",
        "pip('install', '-c', 'constraints.txt',\n",
        "    'timm==1.0.9', 'scikit-learn', 'numpy', 'pandas',\n",
        "    '--upgrade-strategy', 'only-if-needed')\n",
        "\n",
        "# 4) Sanity gate\n",
        "import torch\n",
        "print('torch:', torch.__version__, 'built CUDA:', getattr(torch.version, 'cuda', None))\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f'Wrong CUDA build: {torch.version.cuda}'\n",
        "assert torch.cuda.is_available(), 'CUDA not available'\n",
        "print('GPU:', torch.cuda.get_device_name(0))\n",
        "torch.backends.cudnn.benchmark = True\n",
        "print(f'Install+sanity completed in {time.time()-start:.1f}s')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchvision as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install --index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.org/simple torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 282.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 391.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 535.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 244.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 305.6 MB/s eta 0:00:00\nCollecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 345.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 185.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 201.6 MB/s eta 0:00:00\nCollecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 474.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 144.7 MB/s eta 0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 186.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 151.0 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 437.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 166.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 294.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 476.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 418.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 425.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 505.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 178.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 450.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 348.6 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 185.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 487.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install -c constraints.txt timm==1.0.9 scikit-learn numpy pandas --upgrade-strategy only-if-needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==1.0.9\n  Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.3/2.3 MB 62.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 9.7/9.7 MB 42.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 228.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas\n  Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12.4/12.4 MB 440.2 MB/s eta 0:00:00\nCollecting torchvision\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.0/7.0 MB 25.2 MB/s eta 0:00:00\nCollecting safetensors\n  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 485.8/485.8 KB 275.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_hub\n  Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 563.3/563.3 KB 303.0 MB/s eta 0:00:00\nCollecting pyyaml\n  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 763.0/763.0 KB 395.4 MB/s eta 0:00:00\nCollecting torch\n  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 797.1/797.1 MB 114.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting threadpoolctl>=3.1.0\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nCollecting scipy>=1.8.0\n  Downloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35.9/35.9 MB 501.5 MB/s eta 0:00:00\nCollecting joblib>=1.2.0\n  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 308.4/308.4 KB 160.9 MB/s eta 0:00:00\nCollecting tzdata>=2022.7\n  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 347.8/347.8 KB 508.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytz>=2020.1\n  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 509.2/509.2 KB 435.1 MB/s eta 0:00:00\nCollecting python-dateutil>=2.8.2\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 229.9/229.9 KB 492.1 MB/s eta 0:00:00\nCollecting six>=1.5\n  Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tqdm>=4.42.1\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 78.5/78.5 KB 400.6 MB/s eta 0:00:00\nCollecting hf-xet<2.0.0,>=1.1.3\n  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.2/3.2 MB 438.7 MB/s eta 0:00:00\nCollecting packaging>=20.9\n  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 66.5/66.5 KB 366.0 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting fsspec>=2023.5.0\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 506.7 MB/s eta 0:00:00\nCollecting requests\n  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.7/64.7 KB 375.9 MB/s eta 0:00:00\nCollecting typing-extensions>=3.7.4.3\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 361.5 MB/s eta 0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 229.4 MB/s eta 0:00:00\nCollecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 267.8 MB/s eta 0:00:00\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 39.9 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 274.5 MB/s eta 0:00:00\nCollecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 472.6 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 153.1 MB/s eta 0:00:00\nCollecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 73.0 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 159.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 116.1 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 191.0 MB/s eta 0:00:00\nCollecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 435.8 MB/s eta 0:00:00\nCollecting nvidia-cusolver-cu12==11.4.5.107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 143.5 MB/s eta 0:00:00\nCollecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 248.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 500.4 MB/s eta 0:00:00\nCollecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 147.6 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 468.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 226.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nCollecting charset_normalizer<4,>=2\n  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 150.3/150.3 KB 500.5 MB/s eta 0:00:00\nCollecting certifi>=2017.4.17\n  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.2/161.2 KB 462.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting urllib3<3,>=1.21.1\n  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129.8/129.8 KB 480.6 MB/s eta 0:00:00\nCollecting idna<4,>=2.5\n  Downloading idna-3.10-py3-none-any.whl (70 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 70.4/70.4 KB 451.5 MB/s eta 0:00:00\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 242.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: pytz, mpmath, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, six, safetensors, pyyaml, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, joblib, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, triton, scipy, requests, python-dateutil, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, scikit-learn, pandas, nvidia-cusolver-cu12, huggingface_hub, torch, torchvision, timm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 certifi-2025.8.3 charset_normalizer-3.4.3 filelock-3.19.1 fsspec-2025.9.0 hf-xet-1.1.10 huggingface_hub-0.35.1 idna-3.10 jinja2-3.1.6 joblib-1.5.2 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 packaging-25.0 pandas-2.3.2 pillow-11.3.0 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 requests-2.32.5 safetensors-0.6.2 scikit-learn-1.7.2 scipy-1.16.2 six-1.17.0 sympy-1.14.0 threadpoolctl-3.6.0 timm-1.0.9 torch-2.4.1 torchvision-0.19.1 tqdm-4.67.1 triton-3.0.0 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 built CUDA: 12.1\nCUDA available: True\nGPU: NVIDIA A10-24Q\nInstall+sanity completed in 132.5s\n"
          ]
        }
      ]
    },
    {
      "id": "40efbb9e-6bf3-43c8-84ee-407aaf6c3586",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install xgboost GPU and run GBM feature baseline\n",
        "import sys, subprocess, time, json\n",
        "from pathlib import Path\n",
        "\n",
        "def run(cmd):\n",
        "    print('> ', ' '.join(cmd), flush=True)\n",
        "    return subprocess.run(cmd, check=True)\n",
        "\n",
        "t0 = time.time()\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    print('xgboost already installed:', xgb.__version__)\n",
        "except Exception:\n",
        "    run([sys.executable, '-m', 'pip', 'install', 'xgboost==2.1.1'])\n",
        "    import xgboost as xgb\n",
        "    print('xgboost installed:', xgb.__version__)\n",
        "\n",
        "# Launch XGB training (features + 5-fold CV). Logs progress every 1000 rows.\n",
        "print('Starting XGBoost v0 features run...', flush=True)\n",
        "ret = subprocess.run([sys.executable, 'train_xgb.py', '--out_dir', 'outputs_xgb', '--folds', '5', '--seed', '42'])\n",
        "print('XGB run return code:', ret.returncode, 'elapsed:', round(time.time()-t0,1), 's', flush=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xgboost already installed: 2.1.4\nStarting XGBoost v0 features run...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found train files: 54000, test files: 6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Featurizing train...\n  featurizing 1000/54000 elapsed 48.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 2000/54000 elapsed 98.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 3000/54000 elapsed 147.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 4000/54000 elapsed 196.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 5000/54000 elapsed 246.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 6000/54000 elapsed 295.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 7000/54000 elapsed 344.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 8000/54000 elapsed 393.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 9000/54000 elapsed 442.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 10000/54000 elapsed 491.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 11000/54000 elapsed 541.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 12000/54000 elapsed 590.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 13000/54000 elapsed 639.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 14000/54000 elapsed 688.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 15000/54000 elapsed 736.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 16000/54000 elapsed 786.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 17000/54000 elapsed 835.3s\n"
          ]
        }
      ]
    },
    {
      "id": "4df53850-0235-4d9b-91d7-f18225328785",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run CNN sanity check: overfit_small with forced pairing B\n",
        "import sys, subprocess, time\n",
        "\n",
        "cmd = [sys.executable, 'train_cnn.py',\n",
        "       '--overfit_small',\n",
        "       '--force_pairing', 'B',\n",
        "       '--batch_size', '96',\n",
        "       '--epochs', '8',\n",
        "       '--image_size', '256',\n",
        "       '--num_workers', '8',\n",
        "       '--out_dir', 'outputs_cnn',\n",
        "       '--seed', '42']\n",
        "print('> ', ' '.join(cmd), flush=True)\n",
        "t0 = time.time()\n",
        "ret = subprocess.run(cmd)\n",
        "print('Return code:', ret.returncode, 'elapsed:', round(time.time()-t0,1), 's', flush=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  /usr/bin/python3.11 train_cnn.py --overfit_small --force_pairing B --batch_size 96 --epochs 8 --image_size 256 --num_workers 8 --out_dir outputs_cnn --seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found train files: 54000, test files: 6000\nUsing force_pairing=B\n--- Fold 1/1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1/8 lr=0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1: train_loss=0.6942 val_auc=0.53194\nFold 0 Epoch 2/8 lr=0.000951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2: train_loss=0.6629 val_auc=0.67880\nFold 0 Epoch 3/8 lr=0.000814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3: train_loss=0.6089 val_auc=0.85631\nFold 0 Epoch 4/8 lr=0.000615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4: train_loss=0.5341 val_auc=0.94839\nFold 0 Epoch 5/8 lr=0.000395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5: train_loss=0.4557 val_auc=0.98599\nFold 0 Epoch 6/8 lr=0.000196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6: train_loss=0.4029 val_auc=0.99809\nFold 0 Epoch 7/8 lr=0.000059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7: train_loss=0.3633 val_auc=0.99931\nFold 0 Epoch 8/8 lr=0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8: train_loss=0.3540 val_auc=0.99953\nFold 0 best AUC: 0.99953 saved to outputs_cnn/model_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n  File \"/var/lib/simon/agent_run_states/seti-breakthrough-listen-20250924-194856/train_cnn.py\", line 442, in <module>\n    main()\n  File \"/var/lib/simon/agent_run_states/seti-breakthrough-listen-20250924-194856/train_cnn.py\", line 417, in main\n    oof[val_idx] = val_preds.astype(np.float32)\n    ~~~^^^^^^^^^\nValueError: shape mismatch: value array of shape (512,) could not be broadcast to indexing result of shape (54000,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Return code: 1 elapsed: 102.1 s\n"
          ]
        }
      ]
    },
    {
      "id": "6dced42d-ea76-48b8-b832-cfc9341508d4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run full 5-fold CNN CV with forced pairing B\n",
        "import sys, subprocess, time\n",
        "\n",
        "cmd = [sys.executable, 'train_cnn.py',\n",
        "       '--batch_size', '96',\n",
        "       '--epochs', '12',\n",
        "       '--image_size', '256',\n",
        "       '--num_workers', '8',\n",
        "       '--out_dir', 'outputs_cnn_full',\n",
        "       '--seed', '42',\n",
        "       '--force_pairing', 'B']\n",
        "print('> ', ' '.join(cmd), flush=True)\n",
        "t0 = time.time()\n",
        "ret = subprocess.run(cmd)\n",
        "print('Return code:', ret.returncode, 'elapsed:', round(time.time()-t0,1), 's', flush=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  /usr/bin/python3.11 train_cnn.py --batch_size 96 --epochs 12 --image_size 256 --num_workers 8 --out_dir outputs_cnn_full --seed 42 --force_pairing B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found train files: 54000, test files: 6000\nUsing force_pairing=B\n--- Fold 1/5 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1/12 lr=0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/450 loss=0.5756 elapsed=13.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/450 loss=0.5667 elapsed=7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/450 loss=0.5642 elapsed=7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/450 loss=0.5633 elapsed=7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1: train_loss=0.5623 val_auc=0.50746\nFold 0 Epoch 2/12 lr=0.000980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/450 loss=0.5705 elapsed=8.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/450 loss=0.5646 elapsed=7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/450 loss=0.5610 elapsed=7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/450 loss=0.5593 elapsed=7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2: train_loss=0.5582 val_auc=0.48138\nFold 0 Epoch 3/12 lr=0.000921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/450 loss=0.5507 elapsed=8.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/450 loss=0.5507 elapsed=7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/450 loss=0.5511 elapsed=7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/450 loss=0.5491 elapsed=7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3: train_loss=0.5486 val_auc=0.49187\nFold 0 Epoch 4/12 lr=0.000829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/450 loss=0.5449 elapsed=8.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/450 loss=0.5348 elapsed=7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/450 loss=0.5295 elapsed=7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/450 loss=0.5273 elapsed=7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4: train_loss=0.5254 val_auc=0.48535\nEarly stopping at epoch 4\nFold 0 best AUC: 0.50746 saved to outputs_cnn_full/model_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n  File \"/var/lib/simon/agent_run_states/seti-breakthrough-listen-20250924-194856/train_cnn.py\", line 448, in <module>\n    main()\n  File \"/var/lib/simon/agent_run_states/seti-breakthrough-listen-20250924-194856/train_cnn.py\", line 418, in main\n    _, val_preds, _ = valid_one_epoch(model, valid_loader, device)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/lib/simon/agent_run_states/seti-breakthrough-listen-20250924-194856/train_cnn.py\", line 200, in valid_one_epoch\n    for x, y in loader:\n  File \"/app/.pip-target/torch/utils/data/dataloader.py\", line 630, in __next__\n    data = self._next_data()\n           ^^^^^^^^^^^^^^^^^\n  File \"/app/.pip-target/torch/utils/data/dataloader.py\", line 1327, in _next_data\n    idx, data = self._get_data()\n                ^^^^^^^^^^^^^^^^\n  File \"/app/.pip-target/torch/utils/data/dataloader.py\", line 1283, in _get_data\n    success, data = self._try_get_data()\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"/app/.pip-target/torch/utils/data/dataloader.py\", line 1131, in _try_get_data\n    data = self._data_queue.get(timeout=timeout)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/queue.py\", line 180, in get\n    self.not_empty.wait(remaining)\n  File \"/usr/lib/python3.11/threading.py\", line 324, in wait\n    gotit = waiter.acquire(True, timeout)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m> \u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(cmd), flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     13\u001b[39m t0 = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m ret = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mReturn code:\u001b[39m\u001b[33m'\u001b[39m, ret.returncode, \u001b[33m'\u001b[39m\u001b[33melapsed:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mround\u001b[39m(time.time()-t0,\u001b[32m1\u001b[39m), \u001b[33m'\u001b[39m\u001b[33ms\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/subprocess.py:548\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    547\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    550\u001b[39m         process.kill()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/subprocess.py:1197\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1195\u001b[39m         stderr = \u001b[38;5;28mself\u001b[39m.stderr.read()\n\u001b[32m   1196\u001b[39m         \u001b[38;5;28mself\u001b[39m.stderr.close()\n\u001b[32m-> \u001b[39m\u001b[32m1197\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1199\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/subprocess.py:1260\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1258\u001b[39m     endtime = _time() + timeout\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1260\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1262\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1263\u001b[39m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[32m   1264\u001b[39m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[32m   1265\u001b[39m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[32m   1266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/subprocess.py:1995\u001b[39m, in \u001b[36mPopen._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1994\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1995\u001b[39m (pid, sts) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[32m   1997\u001b[39m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[32m   1998\u001b[39m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[32m   1999\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pid == \u001b[38;5;28mself\u001b[39m.pid:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/subprocess.py:1953\u001b[39m, in \u001b[36mPopen._try_wait\u001b[39m\u001b[34m(self, wait_flags)\u001b[39m\n\u001b[32m   1951\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[32m   1952\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1953\u001b[39m     (pid, sts) = os.waitpid(\u001b[38;5;28mself\u001b[39m.pid, wait_flags)\n\u001b[32m   1954\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[32m   1955\u001b[39m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[32m   1956\u001b[39m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[32m   1957\u001b[39m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[32m   1958\u001b[39m     pid = \u001b[38;5;28mself\u001b[39m.pid\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "4e92a5c8-683f-40cb-9718-c7a64696952b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run parallel XGB FE+CV on CPU while CNN trains\n",
        "import sys, subprocess, time, os\n",
        "\n",
        "cmd = [sys.executable, 'train_xgb.py',\n",
        "       '--out_dir', 'outputs_xgb_v2',\n",
        "       '--folds', '5',\n",
        "       '--seed', '42',\n",
        "       '--n_jobs', str(max(1, (os.cpu_count() or 36) - 4)),\n",
        "       '--chunksize', '64']\n",
        "print('> ', ' '.join(cmd), flush=True)\n",
        "t0 = time.time()\n",
        "ret = subprocess.run(cmd)\n",
        "print('XGB return code:', ret.returncode, 'elapsed:', round(time.time()-t0,1), 's', flush=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  /usr/bin/python3.11 train_xgb.py --out_dir outputs_xgb_v2 --folds 5 --seed 42 --n_jobs 32 --chunksize 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found train files: 54000, test files: 6000\nFeaturizing train...\n  Parallel FE: n_jobs=32 chunksize=64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 5000/54000 elapsed 14.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 10000/54000 elapsed 24.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 15000/54000 elapsed 36.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 20000/54000 elapsed 46.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 25000/54000 elapsed 57.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 30000/54000 elapsed 68.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 35000/54000 elapsed 79.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 40000/54000 elapsed 90.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 45000/54000 elapsed 101.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 50000/54000 elapsed 112.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features shape: (54000, 94) time: 120.9s\nFeaturizing test...\n  Parallel FE: n_jobs=32 chunksize=64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 2000/6000 elapsed 4.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 4000/6000 elapsed 9.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  featurizing 6000/6000 elapsed 13.0s\nTest features shape: (6000, 94)\nXGB Fold 1/5 train=43200 val=10800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-auc:0.55983\tvalid-auc:0.50909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[75]\ttrain-auc:0.88650\tvalid-auc:0.50055\n  Fold 0 best_iteration=0 best_score=0.509089619108656\nXGB Fold 2/5 train=43200 val=10800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-auc:0.55382\tvalid-auc:0.50089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[90]\ttrain-auc:0.90142\tvalid-auc:0.49711\n  Fold 1 best_iteration=15 best_score=0.5105546853135329\nXGB Fold 3/5 train=43200 val=10800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-auc:0.56355\tvalid-auc:0.49654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\ttrain-auc:0.91325\tvalid-auc:0.50761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttrain-auc:0.96978\tvalid-auc:0.50627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[212]\ttrain-auc:0.97358\tvalid-auc:0.50676\n  Fold 2 best_iteration=137 best_score=0.5105648893257505\nXGB Fold 4/5 train=43200 val=10800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-auc:0.56695\tvalid-auc:0.49176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\ttrain-auc:0.91931\tvalid-auc:0.50443\n[101]\ttrain-auc:0.92035\tvalid-auc:0.50444\n  Fold 3 best_iteration=27 best_score=0.5099395223046772\nXGB Fold 5/5 train=43200 val=10800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttrain-auc:0.56854\tvalid-auc:0.51142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[79]\ttrain-auc:0.90176\tvalid-auc:0.50585\n  Fold 4 best_iteration=5 best_score=0.5229832800483719\nXGB OOF AUC: 0.511798\nWrote submission_xgb.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGB return code: 0 elapsed: 150.2 s\n"
          ]
        }
      ]
    },
    {
      "id": "5b0e7064-e645-428b-bb06-4a0111399623",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Single-fold CNN sanity check (3ch diffs, pairing B, no aug)\n",
        "import sys, subprocess, time\n",
        "\n",
        "cmd = [sys.executable, 'train_cnn.py',\n",
        "       '--folds', '1',\n",
        "       '--force_pairing', 'B',\n",
        "       '--disable_aug',\n",
        "       '--channels', '3ch',\n",
        "       '--model_name', 'resnet18',\n",
        "       '--batch_size', '160',\n",
        "       '--epochs', '12',\n",
        "       '--image_size', '256',\n",
        "       '--num_workers', '8',\n",
        "       '--lr', '3e-4',\n",
        "       '--weight_decay', '1e-4',\n",
        "       '--out_dir', 'outputs_cnn_sanity',\n",
        "       '--seed', '42']\n",
        "print('> ', ' '.join(cmd), flush=True)\n",
        "t0 = time.time()\n",
        "ret = subprocess.run(cmd)\n",
        "print('Return code:', ret.returncode, 'elapsed:', round(time.time()-t0,1), 's', flush=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  /usr/bin/python3.11 train_cnn.py --folds 1 --force_pairing B --disable_aug --channels 3ch --model_name resnet18 --batch_size 160 --epochs 12 --image_size 256 --num_workers 8 --lr 3e-4 --weight_decay 1e-4 --out_dir outputs_cnn_sanity --seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found train files: 54000, test files: 6000\nUsing force_pairing=B\n--- Fold 1/1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1/12 lr=0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/270 loss=0.6910 elapsed=15.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/270 loss=0.6859 elapsed=11.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1: train_loss=0.6813 val_auc=0.54685\nFold 0 Epoch 2/12 lr=0.000294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/270 loss=0.6326 elapsed=11.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/270 loss=0.5844 elapsed=11.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2: train_loss=0.5376 val_auc=0.57617\nFold 0 Epoch 3/12 lr=0.000277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/270 loss=0.2444 elapsed=11.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/270 loss=0.2027 elapsed=11.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3: train_loss=0.1806 val_auc=0.57294\nFold 0 Epoch 4/12 lr=0.000250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/270 loss=0.0663 elapsed=11.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/270 loss=0.0579 elapsed=11.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4: train_loss=0.0555 val_auc=0.56816\nFold 0 Epoch 5/12 lr=0.000215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/270 loss=0.0310 elapsed=12.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/270 loss=0.0274 elapsed=11.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5: train_loss=0.0265 val_auc=0.55573\nEarly stopping at epoch 5\nFold 0 best AUC: 0.57617 saved to outputs_cnn_sanity/model_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 done in 213.3s\nOOF AUC: 0.503025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Return code: 0 elapsed: 218.3 s\n"
          ]
        }
      ]
    },
    {
      "id": "90cf88ed-cf9d-43a4-8261-650f7a9bbe79",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Single-fold CNN sanity check (6ch, pairing B, no aug, no detrend, EMA+clip active in script)\n",
        "import sys, subprocess, time\n",
        "\n",
        "cmd = [sys.executable, 'train_cnn.py',\n",
        "       '--folds', '1',\n",
        "       '--force_pairing', 'B',\n",
        "       '--disable_aug',\n",
        "       '--channels', '6ch',\n",
        "       '--model_name', 'resnet18',\n",
        "       '--batch_size', '192',\n",
        "       '--epochs', '12',\n",
        "       '--image_size', '256',\n",
        "       '--num_workers', '8',\n",
        "       '--lr', '3e-4',\n",
        "       '--weight_decay', '1e-4',\n",
        "       '--detrend', 'none',\n",
        "       '--out_dir', 'outputs_cnn_sanity_6ch_nodetrend',\n",
        "       '--seed', '42']\n",
        "print('> ', ' '.join(cmd), flush=True)\n",
        "t0 = time.time()\n",
        "ret = subprocess.run(cmd)\n",
        "print('Return code:', ret.returncode, 'elapsed:', round(time.time()-t0,1), 's', flush=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  /usr/bin/python3.11 train_cnn.py --folds 1 --force_pairing B --disable_aug --channels 6ch --model_name resnet18 --batch_size 192 --epochs 12 --image_size 256 --num_workers 8 --lr 3e-4 --weight_decay 1e-4 --detrend none --out_dir outputs_cnn_sanity_6ch_nodetrend --seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found train files: 54000, test files: 6000\nUsing force_pairing=B\n--- Fold 1/1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1/12 lr=0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.6911 elapsed=26.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.6865 elapsed=15.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1: train_loss=0.6850 val_auc=0.52470\nFold 0 Epoch 2/12 lr=0.000294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.6614 elapsed=16.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.6278 elapsed=15.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2: train_loss=0.6166 val_auc=0.52965\nFold 0 Epoch 3/12 lr=0.000277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.4111 elapsed=17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.3579 elapsed=15.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3: train_loss=0.3457 val_auc=0.53528\nFold 0 Epoch 4/12 lr=0.000250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.1735 elapsed=17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.1543 elapsed=15.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4: train_loss=0.1499 val_auc=0.54269\nFold 0 Epoch 5/12 lr=0.000215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.0786 elapsed=17.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.0710 elapsed=15.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5: train_loss=0.0700 val_auc=0.54834\nFold 0 Epoch 6/12 lr=0.000176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.0400 elapsed=17.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.0368 elapsed=15.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6: train_loss=0.0367 val_auc=0.55102\nFold 0 Epoch 7/12 lr=0.000134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.0202 elapsed=17.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.0180 elapsed=15.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7: train_loss=0.0183 val_auc=0.55341\nFold 0 Epoch 8/12 lr=0.000095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.0095 elapsed=17.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.0089 elapsed=15.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8: train_loss=0.0087 val_auc=0.55676\nFold 0 Epoch 9/12 lr=0.000060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.0046 elapsed=17.2s\n"
          ]
        }
      ]
    },
    {
      "id": "c97712e0-3882-456d-adc4-a1f91847635e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CNN detrending ablation: single-fold, short runs (3-4 epochs), no aug\n",
        "import sys, subprocess, time\n",
        "\n",
        "def run_cmd(cmd):\n",
        "    print('> ', ' '.join(cmd), flush=True)\n",
        "    t0 = time.time()\n",
        "    ret = subprocess.run(cmd)\n",
        "    print('Return code:', ret.returncode, 'elapsed:', round(time.time()-t0,1), 's', flush=True)\n",
        "\n",
        "# Run 1: detrend=col\n",
        "cmd_col = [sys.executable, 'train_cnn.py',\n",
        "           '--folds', '1',\n",
        "           '--force_pairing', 'B',\n",
        "           '--disable_aug',\n",
        "           '--channels', '6ch',\n",
        "           '--model_name', 'resnet18',\n",
        "           '--batch_size', '192',\n",
        "           '--epochs', '4',\n",
        "           '--image_size', '256',\n",
        "           '--num_workers', '8',\n",
        "           '--lr', '3e-4',\n",
        "           '--weight_decay', '1e-4',\n",
        "           '--detrend', 'col',\n",
        "           '--out_dir', 'outputs_cnn_sanity_6ch_col',\n",
        "           '--seed', '42']\n",
        "run_cmd(cmd_col)\n",
        "\n",
        "# Run 2: detrend=row\n",
        "cmd_row = [sys.executable, 'train_cnn.py',\n",
        "           '--folds', '1',\n",
        "           '--force_pairing', 'B',\n",
        "           '--disable_aug',\n",
        "           '--channels', '6ch',\n",
        "           '--model_name', 'resnet18',\n",
        "           '--batch_size', '192',\n",
        "           '--epochs', '4',\n",
        "           '--image_size', '256',\n",
        "           '--num_workers', '8',\n",
        "           '--lr', '3e-4',\n",
        "           '--weight_decay', '1e-4',\n",
        "           '--detrend', 'row',\n",
        "           '--out_dir', 'outputs_cnn_sanity_6ch_row',\n",
        "           '--seed', '42']\n",
        "run_cmd(cmd_row)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  /usr/bin/python3.11 train_cnn.py --folds 1 --force_pairing B --disable_aug --channels 6ch --model_name resnet18 --batch_size 192 --epochs 4 --image_size 256 --num_workers 8 --lr 3e-4 --weight_decay 1e-4 --detrend col --out_dir outputs_cnn_sanity_6ch_col --seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found train files: 54000, test files: 6000\nUsing force_pairing=B\n--- Fold 1/1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1/4 lr=0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.6900 elapsed=27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.6827 elapsed=23.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1: train_loss=0.6800 val_auc=0.52294\nFold 0 Epoch 2/4 lr=0.000227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.6292 elapsed=25.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.5985 elapsed=23.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2: train_loss=0.5888 val_auc=0.54225\nFold 0 Epoch 3/4 lr=0.000083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.4328 elapsed=25.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.4012 elapsed=23.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3: train_loss=0.3935 val_auc=0.55454\nFold 0 Epoch 4/4 lr=0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.3057 elapsed=25.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.2992 elapsed=23.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4: train_loss=0.2974 val_auc=0.56338\nFold 0 best AUC: 0.56338 saved to outputs_cnn_sanity_6ch_col/model_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 done in 319.3s\nOOF AUC: 0.502514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Return code: 0 elapsed: 327.0 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  /usr/bin/python3.11 train_cnn.py --folds 1 --force_pairing B --disable_aug --channels 6ch --model_name resnet18 --batch_size 192 --epochs 4 --image_size 256 --num_workers 8 --lr 3e-4 --weight_decay 1e-4 --detrend row --out_dir outputs_cnn_sanity_6ch_row --seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found train files: 54000, test files: 6000\nUsing force_pairing=B\n--- Fold 1/1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1/4 lr=0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.6904 elapsed=26.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.6844 elapsed=20.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1: train_loss=0.6828 val_auc=0.51142\nFold 0 Epoch 2/4 lr=0.000227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.6422 elapsed=22.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.5959 elapsed=20.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2: train_loss=0.5837 val_auc=0.52037\nFold 0 Epoch 3/4 lr=0.000083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.3724 elapsed=22.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.3390 elapsed=20.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3: train_loss=0.3319 val_auc=0.52558\nFold 0 Epoch 4/4 lr=0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n  iter 100/225 loss=0.2382 elapsed=22.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n  iter 200/225 loss=0.2327 elapsed=20.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4: train_loss=0.2316 val_auc=0.53096\nFold 0 best AUC: 0.53096 saved to outputs_cnn_sanity_6ch_row/model_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 done in 285.0s\nOOF AUC: 0.501217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Return code: 0 elapsed: 292.8 s\n"
          ]
        }
      ]
    },
    {
      "id": "f9e416d1-ed3d-4c07-9fd1-266297307122",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity: EfficientNet-B0 6ch, percentile norm, no aug, detrend=none\n",
        "import sys, subprocess, time\n",
        "cmd = [sys.executable, 'train_cnn.py',\n",
        "       '--folds', '1',\n",
        "       '--force_pairing', 'B',\n",
        "       '--disable_aug',\n",
        "       '--channels', '6ch',\n",
        "       '--model_name', 'tf_efficientnet_b0_ns',\n",
        "       '--batch_size', '192',\n",
        "       '--epochs', '4',\n",
        "       '--image_size', '256',\n",
        "       '--num_workers', '8',\n",
        "       '--lr', '1e-3',\n",
        "       '--weight_decay', '1e-4',\n",
        "       '--detrend', 'none',\n",
        "       '--use_percentile_norm',\n",
        "       '--out_dir', 'outputs_cnn_effb0_sanity',\n",
        "       '--seed', '42']\n",
        "print('> ', ' '.join(cmd), flush=True)\n",
        "t0 = time.time()\n",
        "ret = subprocess.run(cmd)\n",
        "print('Return code:', ret.returncode, 'elapsed:', round(time.time()-t0,1), 's', flush=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  /usr/bin/python3.11 train_cnn.py --folds 1 --force_pairing B --disable_aug --channels 6ch --model_name tf_efficientnet_b0_ns --batch_size 192 --epochs 4 --image_size 256 --num_workers 8 --lr 1e-3 --weight_decay 1e-4 --detrend none --use_percentile_norm --out_dir outputs_cnn_effb0_sanity --seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found train files: 54000, test files: 6000\nUsing force_pairing=B\n--- Fold 1/1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1/4 lr=0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/225 loss=0.9628 elapsed=46.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/225 loss=0.6944 elapsed=29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1: train_loss=0.6511 val_auc=0.50456\nFold 0 Epoch 2/4 lr=0.000753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/225 loss=0.4832 elapsed=30.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/225 loss=0.4282 elapsed=29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2: train_loss=0.4170 val_auc=0.49709\nFold 0 Epoch 3/4 lr=0.000258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/225 loss=0.0974 elapsed=30.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/225 loss=0.0690 elapsed=29.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3: train_loss=0.0656 val_auc=0.49568\nFold 0 Epoch 4/4 lr=0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/225 loss=0.0196 elapsed=30.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/225 loss=0.0168 elapsed=29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4: train_loss=0.0162 val_auc=0.50120\nEarly stopping at epoch 4\nFold 0 best AUC: 0.50456 saved to outputs_cnn_effb0_sanity/model_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 done in 355.4s\nOOF AUC: 0.500162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Return code: 0 elapsed: 363.9 s\n"
          ]
        }
      ]
    },
    {
      "id": "2c1c4e15-16cf-4999-a860-c80a1e254f5e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity: EffNet-B0 6ch, per-image std norm, no aug, detrend=none\n",
        "import sys, subprocess, time\n",
        "cmd = [sys.executable, 'train_cnn.py',\n",
        "       '--folds', '1',\n",
        "       '--force_pairing', 'B',\n",
        "       '--disable_aug',\n",
        "       '--channels', '6ch',\n",
        "       '--model_name', 'tf_efficientnet_b0_ns',\n",
        "       '--batch_size', '192',\n",
        "       '--epochs', '4',\n",
        "       '--image_size', '256',\n",
        "       '--num_workers', '8',\n",
        "       '--lr', '1e-3',\n",
        "       '--weight_decay', '1e-4',\n",
        "       '--detrend', 'none',\n",
        "       '--per_image_std',\n",
        "       '--out_dir', 'outputs_cnn_effb0_perimgstd_sanity',\n",
        "       '--seed', '42']\n",
        "print('> ', ' '.join(cmd), flush=True)\n",
        "t0 = time.time()\n",
        "ret = subprocess.run(cmd)\n",
        "print('Return code:', ret.returncode, 'elapsed:', round(time.time()-t0,1), 's', flush=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  /usr/bin/python3.11 train_cnn.py --folds 1 --force_pairing B --disable_aug --channels 6ch --model_name tf_efficientnet_b0_ns --batch_size 192 --epochs 4 --image_size 256 --num_workers 8 --lr 1e-3 --weight_decay 1e-4 --detrend none --per_image_std --out_dir outputs_cnn_effb0_perimgstd_sanity --seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found train files: 54000, test files: 6000\nUsing force_pairing=B\n--- Fold 1/1 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1/4 lr=0.000200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/225 loss=0.9117 elapsed=46.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/225 loss=0.6572 elapsed=29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1: train_loss=0.6152 val_auc=0.48835\nFold 0 Epoch 2/4 lr=0.000753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/225 loss=0.4468 elapsed=30.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/225 loss=0.4045 elapsed=29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2: train_loss=0.3928 val_auc=0.49051\nFold 0 Epoch 3/4 lr=0.000258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/225 loss=0.0938 elapsed=30.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/225 loss=0.0654 elapsed=29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3: train_loss=0.0624 val_auc=0.49972\nFold 0 Epoch 4/4 lr=0.000010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 1: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 100: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/225 loss=0.0158 elapsed=30.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  batch 200: running pos ratio=0.500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/225 loss=0.0144 elapsed=29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4: train_loss=0.0140 val_auc=0.51599\nFold 0 best AUC: 0.51599 saved to outputs_cnn_effb0_perimgstd_sanity/model_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 done in 340.9s\nOOF AUC: 0.500619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Return code: 0 elapsed: 349.8 s\n"
          ]
        }
      ]
    },
    {
      "id": "a3e68a57-65df-43f3-b0be-18a1cb4d4d1a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity: ConvNeXt-Tiny 6ch, percentile norm, no aug, detrend=none, no EMA\n",
        "import sys, subprocess, time\n",
        "cmd = [sys.executable, 'train_cnn.py',\n",
        "       '--folds', '1',\n",
        "       '--force_pairing', 'B',\n",
        "       '--disable_aug',\n",
        "       '--channels', '6ch',\n",
        "       '--model_name', 'convnext_tiny',\n",
        "       '--batch_size', '160',\n",
        "       '--epochs', '4',\n",
        "       '--image_size', '256',\n",
        "       '--num_workers', '8',\n",
        "       '--lr', '5e-4',\n",
        "       '--weight_decay', '1e-4',\n",
        "       '--detrend', 'none',\n",
        "       '--use_percentile_norm',\n",
        "       '--no_ema',\n",
        "       '--out_dir', 'outputs_cnn_convnext_tiny_sanity',\n",
        "       '--seed', '42']\n",
        "print('> ', ' '.join(cmd), flush=True)\n",
        "t0 = time.time()\n",
        "ret = subprocess.run(cmd)\n",
        "print('Return code:', ret.returncode, 'elapsed:', round(time.time()-t0,1), 's', flush=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  /usr/bin/python3.11 train_cnn.py --folds 1 --force_pairing B --disable_aug --channels 6ch --model_name convnext_tiny --batch_size 160 --epochs 4 --image_size 256 --num_workers 8 --lr 5e-4 --weight_decay 1e-4 --detrend none --use_percentile_norm --no_ema --out_dir outputs_cnn_convnext_tiny_sanity --seed 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found train files: 54000, test files: 6000\nUsing force_pairing=B\n--- Fold 1/1 ---\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}