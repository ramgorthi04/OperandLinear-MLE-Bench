{
  "cells": [
    {
      "id": "32be8f02-db54-414f-8c27-114b08b8c0f5",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Herbarium 2021 FGVC8 - Plan\n",
        "\n",
        "Goal: Build a GPU-accelerated image classification pipeline to achieve a medal-worthy macro-F1 on the leaderboard.\n",
        "\n",
        "Plan:\n",
        "- Env check: verify GPU availability and correct CUDA stack.\n",
        "- Data audit: load train/test metadata.json, inspect fields, class counts, image-path mapping, and sample_submission format.\n",
        "- CV protocol: stratified K-fold by label; ensure deterministic seeds.\n",
        "- Baseline model: torchvision pretrained backbone (e.g., convnext_tiny / efficientnet_v2_s) fine-tune with mixed precision.\n",
        "- Augmentations: standard image aug (resize, crop, color jitter, flips); class-balanced sampling.\n",
        "- Training loop: early stopping, lr scheduling (OneCycle/Step), label smoothing; log progress by epoch/fold.\n",
        "- Inference: TTA, save predictions to submission.csv in required format.\n",
        "- Iteration: cache OOF and test logits; analyze errors; consider higher res or stronger backbones; blend if time.\n",
        "\n",
        "Checkpoints requiring expert review:\n",
        "- After this plan and environment/data audit\n",
        "- After baseline CV setup\n",
        "- After first baseline training results\n",
        "- After improvements/ensembling decisions\n",
        "\n",
        "Notes:\n",
        "- Keep jobs fast; subsample for smoke tests first.\n",
        "- Always print timing per fold and verify artifacts exist."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f93f207e-186e-4b52-afe0-f886ffb92bc3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, json, sys, subprocess, time, textwrap, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def run(cmd):\n",
        "    print('> ', ' '.join(cmd), flush=True)\n",
        "    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True).stdout\n",
        "\n",
        "print('Env check: nvidia-smi')\n",
        "print(run(['bash','-lc','nvidia-smi || true']))\n",
        "print('Python:', sys.version)\n",
        "\n",
        "base = Path('.')\n",
        "train_dir = base/'train'\n",
        "test_dir = base/'test'\n",
        "ss_path = base/'sample_submission.csv'\n",
        "\n",
        "print('List dir train/test:')\n",
        "print('train exists:', train_dir.exists(), 'test exists:', test_dir.exists())\n",
        "print('train/images dirs:', len(list((train_dir/'images').glob('*'))))\n",
        "print('test/images dirs:', len(list((test_dir/'images').glob('*'))))\n",
        "\n",
        "def load_json(p):\n",
        "    with open(p, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "train_meta = load_json(train_dir/'metadata.json')\n",
        "test_meta = load_json(test_dir/'metadata.json')\n",
        "print('train_meta keys:', list(train_meta.keys()))\n",
        "print('test_meta keys:', list(test_meta.keys()))\n",
        "\n",
        "# Inspect a few entries\n",
        "def head_dict(d, n=3):\n",
        "    # if dict of lists or dict with key 'images', try to summarize\n",
        "    if isinstance(d, dict) and 'images' in d:\n",
        "        imgs = d['images'][:n]\n",
        "        print('images sample:', imgs)\n",
        "    elif isinstance(d, dict) and 'annotations' in d:\n",
        "        print('annotations sample:', d['annotations'][:n])\n",
        "    else:\n",
        "        # print first n key:val pairs\n",
        "        for i, (k,v) in enumerate(d.items()):\n",
        "            if i>=n: break\n",
        "            print(k, type(v), (v if isinstance(v,(int,str,float)) else '...'))\n",
        "\n",
        "print('Train meta head:')\n",
        "head_dict(train_meta)\n",
        "print('Test meta head:')\n",
        "head_dict(test_meta)\n",
        "\n",
        "# Try to infer schema commonly used in Herbarium competitions\n",
        "# Expect fields like: images (list of dicts with file_name, id), annotations (list with image_id, category_id), categories (list with id, name)\n",
        "images = train_meta.get('images', [])\n",
        "ann = train_meta.get('annotations', [])\n",
        "cats = train_meta.get('categories', [])\n",
        "print(f'Counts - images: {len(images)}, annotations: {len(ann)}, categories: {len(cats)}')\n",
        "\n",
        "if images and ann and cats:\n",
        "    import pandas as pd\n",
        "    df_img = pd.DataFrame(images)\n",
        "    df_anno = pd.DataFrame(ann)\n",
        "    df_cat = pd.DataFrame(cats)\n",
        "    print('df_img columns:', df_img.columns.tolist())\n",
        "    print('df_anno columns:', df_anno.columns.tolist())\n",
        "    print('df_cat columns:', df_cat.columns.tolist())\n",
        "    # Merge labels\n",
        "    if 'id' in df_img.columns and 'image_id' in df_anno.columns:\n",
        "        df = df_anno.merge(df_img, left_on='image_id', right_on='id', how='left')\n",
        "        if 'category_id' in df.columns:\n",
        "            print('Train rows:', len(df))\n",
        "            print('Unique classes:', df['category_id'].nunique())\n",
        "            print('Label distribution (head):')\n",
        "            print(df['category_id'].value_counts().head(10))\n",
        "            # Build relative image path\n",
        "            # Expect file_name in images and path under train/images/\n",
        "            if 'file_name' in df_img.columns:\n",
        "                pass\n",
        "\n",
        "if ss_path.exists():\n",
        "    ss = pd.read_csv(ss_path)\n",
        "    print('sample_submission head:')\n",
        "    print(ss.head())\n",
        "else:\n",
        "    print('sample_submission.csv missing')\n",
        "\n",
        "print('Done audit at', time.strftime('%Y-%m-%d %H:%M:%S'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Env check: nvidia-smi\n>  bash -lc nvidia-smi || true\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep 27 04:39:42 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\nPython: 3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]\nList dir train/test:\ntrain exists: True test exists: True\ntrain/images dirs: 645\ntest/images dirs: 478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_meta keys: ['annotations', 'categories', 'images', 'info', 'institutions', 'licenses']\ntest_meta keys: ['images', 'info', 'licenses']\nTrain meta head:\nimages sample: [{'file_name': 'images/604/92/1608432.jpg', 'height': 1000, 'id': 1608432, 'license': 0, 'width': 671}, {'file_name': 'images/604/92/796948.jpg', 'height': 1000, 'id': 796948, 'license': 0, 'width': 678}, {'file_name': 'images/604/92/994447.jpg', 'height': 1000, 'id': 994447, 'license': 0, 'width': 671}]\nTest meta head:\nimages sample: [{'file_name': 'images/000/0.jpg', 'height': 1000, 'id': '0', 'license': 0, 'width': 666}, {'file_name': 'images/000/1.jpg', 'height': 1000, 'id': '1', 'license': 0, 'width': 672}, {'file_name': 'images/000/2.jpg', 'height': 1000, 'id': '2', 'license': 0, 'width': 669}]\nCounts - images: 1779953, annotations: 1779953, categories: 64500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_img columns: ['file_name', 'height', 'id', 'license', 'width']\ndf_anno columns: ['category_id', 'id', 'image_id', 'institution_id']\ndf_cat columns: ['family', 'id', 'name', 'order']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rows: 1779953\nUnique classes: 64500\nLabel distribution (head):\ncategory_id\n42811    2647\n25229    1713\n48372    1630\n42843    1324\n22344    1260\n42580    1152\n11117    1091\n56357    1058\n26119    1007\n58922     987\nName: count, dtype: int64\nsample_submission head:\n   Id  Predicted\n0   0          0\n1   1          0\n2   2          0\n3   3          0\n4   4          0\nDone audit at 2025-09-27 04:39:49\n"
          ]
        }
      ]
    },
    {
      "id": "97b7a404-c27a-4ea3-91c5-c30989de85d8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Safety-net baseline: Global majority-class submission\n",
        "import json, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "base = Path('.')\n",
        "train_meta = json.load(open(base/'train'/'metadata.json','r'))\n",
        "test_meta = json.load(open(base/'test'/'metadata.json','r'))\n",
        "\n",
        "df_img = pd.DataFrame(train_meta['images'])\n",
        "df_anno = pd.DataFrame(train_meta['annotations'])\n",
        "df = df_anno.merge(df_img, left_on='image_id', right_on='id', how='left')\n",
        "mode_label = int(df['category_id'].mode().iloc[0])\n",
        "print('Global mode category_id:', mode_label)\n",
        "\n",
        "ss = pd.read_csv(base/'sample_submission.csv')\n",
        "print('Sample submission shape:', ss.shape)\n",
        "sub = ss.copy()\n",
        "sub['Predicted'] = mode_label\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv with global majority class. Head:')\n",
        "print(sub.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global mode category_id: 42811\nSample submission shape: (477806, 2)\nWrote submission.csv with global majority class. Head:\n   Id  Predicted\n0   0      42811\n1   1      42811\n2   2      42811\n3   3      42811\n4   4      42811\n"
          ]
        }
      ]
    },
    {
      "id": "89c3799e-f8e3-4b5b-a0a3-ab501ed51ac6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Metadata-only F0-conditioned baseline\n",
        "import json, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "base = Path('.')\n",
        "train_meta = json.load(open(base/'train'/'metadata.json','r'))\n",
        "test_meta = json.load(open(base/'test'/'metadata.json','r'))\n",
        "ss = pd.read_csv(base/'sample_submission.csv')\n",
        "\n",
        "df_img = pd.DataFrame(train_meta['images'])[['file_name','width','height','id']]\n",
        "df_anno = pd.DataFrame(train_meta['annotations'])[['image_id','category_id']]\n",
        "df_tr = df_anno.merge(df_img, left_on='image_id', right_on='id', how='left')\n",
        "\n",
        "def parse_F0_F1(s):\n",
        "    # s like 'images/604/92/1608432.jpg'\n",
        "    parts = s.split('/')\n",
        "    f0 = parts[1] if len(parts) > 1 else ''\n",
        "    f1 = parts[2] if len(parts) > 2 else ''\n",
        "    return f0, f1\n",
        "\n",
        "F0_F1 = df_tr['file_name'].map(parse_F0_F1)\n",
        "df_tr['F0'] = [t[0] for t in F0_F1]\n",
        "df_tr['F1'] = [t[1] for t in F0_F1]\n",
        "df_tr['aspect'] = (df_tr['width'] / df_tr['height']).astype(float)\n",
        "width_bins = [0, 600, 700, 800, 900, 1000, 1100, 2000]\n",
        "height_bins = [0, 600, 700, 800, 900, 1000, 1100, 2000]\n",
        "df_tr['wb'] = pd.cut(df_tr['width'], bins=width_bins, include_lowest=True).astype(str)\n",
        "df_tr['hb'] = pd.cut(df_tr['height'], bins=height_bins, include_lowest=True).astype(str)\n",
        "\n",
        "global_mode = int(df_tr['category_id'].mode().iloc[0])\n",
        "print('Global mode:', global_mode)\n",
        "\n",
        "def mode_map(df, keys):\n",
        "    # returns dict mapping tuple(keys) -> modal category_id\n",
        "    grp = df.groupby(keys)['category_id'].agg(lambda x: x.value_counts().idxmax())\n",
        "    return grp.to_dict()\n",
        "\n",
        "m_F0_wb_hb = mode_map(df_tr, ['F0','wb','hb'])\n",
        "m_F0_wb = mode_map(df_tr, ['F0','wb'])\n",
        "m_F0_hb = mode_map(df_tr, ['F0','hb'])\n",
        "m_F0 = mode_map(df_tr, ['F0'])\n",
        "\n",
        "# Build test features\n",
        "df_te = pd.DataFrame(test_meta['images'])[['id','file_name','width','height']].copy()\n",
        "F0_F1_te = df_te['file_name'].map(parse_F0_F1)\n",
        "df_te['F0'] = [t[0] for t in F0_F1_te]\n",
        "df_te['F1'] = [t[1] for t in F0_F1_te]\n",
        "df_te['wb'] = pd.cut(df_te['width'], bins=width_bins, include_lowest=True).astype(str)\n",
        "df_te['hb'] = pd.cut(df_te['height'], bins=height_bins, include_lowest=True).astype(str)\n",
        "\n",
        "def predict_row(r):\n",
        "    k3 = (r['F0'], r['wb'], r['hb'])\n",
        "    if k3 in m_F0_wb_hb: return int(m_F0_wb_hb[k3])\n",
        "    k2 = (r['F0'], r['wb'])\n",
        "    if k2 in m_F0_wb: return int(m_F0_wb[k2])\n",
        "    k2b = (r['F0'], r['hb'])\n",
        "    if k2b in m_F0_hb: return int(m_F0_hb[k2b])\n",
        "    k1 = (r['F0'],)\n",
        "    if k1 in m_F0: return int(m_F0[r['F0']])\n",
        "    return global_mode\n",
        "\n",
        "t0 = pd.Timestamp.now()\n",
        "preds = df_te.apply(predict_row, axis=1)\n",
        "elapsed = (pd.Timestamp.now() - t0).total_seconds()\n",
        "print(f'Predicted {len(preds)} rows in {elapsed:.2f}s')\n",
        "\n",
        "# Align to sample submission order\n",
        "sub = ss.copy()\n",
        "id2pred = dict(zip(df_te['id'].astype(str), preds))\n",
        "sub['Predicted'] = sub['Id'].astype(str).map(id2pred).fillna(global_mode).astype(int)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "sub.to_csv('submission_f0.csv', index=False)\n",
        "print('Wrote submission.csv and submission_f0.csv. Head:')\n",
        "print(sub.head())\n",
        "print('Coverage check:')\n",
        "covered = (sub['Predicted'] != global_mode).mean()\n",
        "print('Fraction not falling back to global:', f'{covered:.3f}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global mode: 42811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 477806 rows in 2.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv and submission_f0.csv. Head:\n   Id  Predicted\n0   0         23\n1   1         23\n2   2         23\n3   3         23\n4   4         23\nCoverage check:\nFraction not falling back to global: 0.998\n"
          ]
        }
      ]
    },
    {
      "id": "7ebb6996-e023-4081-b2b8-394d1a16e150",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Enhanced metadata baseline: add F1 and aspect bins to fallback chain\n",
        "import json, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "base = Path('.')\n",
        "train_meta = json.load(open(base/'train'/'metadata.json','r'))\n",
        "test_meta = json.load(open(base/'test'/'metadata.json','r'))\n",
        "ss = pd.read_csv(base/'sample_submission.csv')\n",
        "\n",
        "df_img = pd.DataFrame(train_meta['images'])[['file_name','width','height','id']]\n",
        "df_anno = pd.DataFrame(train_meta['annotations'])[['image_id','category_id']]\n",
        "df_tr = df_anno.merge(df_img, left_on='image_id', right_on='id', how='left')\n",
        "\n",
        "def parse_F0_F1(s):\n",
        "    parts = s.split('/')\n",
        "    f0 = parts[1] if len(parts) > 1 else ''\n",
        "    f1 = parts[2] if len(parts) > 2 else ''\n",
        "    return f0, f1\n",
        "\n",
        "F0_F1 = df_tr['file_name'].map(parse_F0_F1)\n",
        "df_tr['F0'] = [t[0] for t in F0_F1]\n",
        "df_tr['F1'] = [t[1] for t in F0_F1]\n",
        "df_tr['aspect'] = (df_tr['width'] / df_tr['height']).astype(float)\n",
        "width_bins = [0, 600, 700, 800, 900, 1000, 1100, 2000]\n",
        "height_bins = [0, 600, 700, 800, 900, 1000, 1100, 2000]\n",
        "aspect_bins = [0, 0.6, 0.75, 0.9, 1.0, 1.1, 1.3, 2.5]\n",
        "df_tr['wb'] = pd.cut(df_tr['width'], bins=width_bins, include_lowest=True).astype(str)\n",
        "df_tr['hb'] = pd.cut(df_tr['height'], bins=height_bins, include_lowest=True).astype(str)\n",
        "df_tr['ab'] = pd.cut(df_tr['aspect'], bins=aspect_bins, include_lowest=True).astype(str)\n",
        "\n",
        "global_mode = int(df_tr['category_id'].mode().iloc[0])\n",
        "print('Global mode:', global_mode)\n",
        "\n",
        "def mode_map(df, keys):\n",
        "    grp = df.groupby(keys)['category_id'].agg(lambda x: x.value_counts().idxmax())\n",
        "    return grp.to_dict()\n",
        "\n",
        "# Build maps with increasing specificity\n",
        "m_F0_F1_wb_hb = mode_map(df_tr, ['F0','F1','wb','hb'])\n",
        "m_F0_F1_ab   = mode_map(df_tr, ['F0','F1','ab'])\n",
        "m_F0_wb_hb   = mode_map(df_tr, ['F0','wb','hb'])\n",
        "m_F0_ab      = mode_map(df_tr, ['F0','ab'])\n",
        "m_F0_F1      = mode_map(df_tr, ['F0','F1'])\n",
        "m_F0_wb      = mode_map(df_tr, ['F0','wb'])\n",
        "m_F0_hb      = mode_map(df_tr, ['F0','hb'])\n",
        "m_F0         = mode_map(df_tr, ['F0'])\n",
        "\n",
        "# Test features\n",
        "df_te = pd.DataFrame(test_meta['images'])[['id','file_name','width','height']].copy()\n",
        "F0_F1_te = df_te['file_name'].map(parse_F0_F1)\n",
        "df_te['F0'] = [t[0] for t in F0_F1_te]\n",
        "df_te['F1'] = [t[1] for t in F0_F1_te]\n",
        "df_te['aspect'] = (df_te['width'] / df_te['height']).astype(float)\n",
        "df_te['wb'] = pd.cut(df_te['width'], bins=width_bins, include_lowest=True).astype(str)\n",
        "df_te['hb'] = pd.cut(df_te['height'], bins=height_bins, include_lowest=True).astype(str)\n",
        "df_te['ab'] = pd.cut(df_te['aspect'], bins=aspect_bins, include_lowest=True).astype(str)\n",
        "\n",
        "levels = [\n",
        "    ('F0_F1_wb_hb', lambda r: m_F0_F1_wb_hb.get((r['F0'], r['F1'], r['wb'], r['hb']))),\n",
        "    ('F0_F1_ab',    lambda r: m_F0_F1_ab.get((r['F0'], r['F1'], r['ab']))),\n",
        "    ('F0_wb_hb',    lambda r: m_F0_wb_hb.get((r['F0'], r['wb'], r['hb']))),\n",
        "    ('F0_ab',       lambda r: m_F0_ab.get((r['F0'], r['ab']))),\n",
        "    ('F0_F1',       lambda r: m_F0_F1.get((r['F0'], r['F1']))),\n",
        "    ('F0_wb',       lambda r: m_F0_wb.get((r['F0'], r['wb']))),\n",
        "    ('F0_hb',       lambda r: m_F0_hb.get((r['F0'], r['hb']))),\n",
        "    ('F0',          lambda r: m_F0.get((r['F0'],)))\n",
        "]\n",
        "\n",
        "pred = np.full(len(df_te), global_mode, dtype=np.int64)\n",
        "covered = np.zeros(len(df_te), dtype=bool)\n",
        "\n",
        "for name, fn in levels:\n",
        "    if covered.all():\n",
        "        break\n",
        "    idx = np.where(~covered)[0]\n",
        "    # vectorized-ish apply on remaining subset\n",
        "    vals = [fn(df_te.iloc[i]) for i in idx]\n",
        "    take = [v is not None for v in vals]\n",
        "    if any(take):\n",
        "        pred_idx = np.array(idx)[np.array(take)]\n",
        "        pred_vals = np.array([int(v) for v in np.array(vals, dtype=object)[np.array(take)]])\n",
        "        pred[pred_idx] = pred_vals\n",
        "        covered[pred_idx] = True\n",
        "    print(f'Level {name}: newly covered {covered.mean():.3f} cumul.')\n",
        "\n",
        "sub = ss.copy()\n",
        "id2pred = dict(zip(df_te['id'].astype(str), pred.tolist()))\n",
        "sub['Predicted'] = sub['Id'].astype(str).map(id2pred).fillna(global_mode).astype(int)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "sub.to_csv('submission_f0_ext.csv', index=False)\n",
        "print('Wrote submission.csv and submission_f0_ext.csv. Head:')\n",
        "print(sub.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global mode: 42811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level F0_F1_wb_hb: newly covered 0.000 cumul.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level F0_F1_ab: newly covered 0.000 cumul.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level F0_wb_hb: newly covered 0.994 cumul.\nLevel F0_ab: newly covered 0.994 cumul.\nLevel F0_F1: newly covered 0.994 cumul.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level F0_wb: newly covered 0.994 cumul.\nLevel F0_hb: newly covered 1.000 cumul.\nLevel F0: newly covered 1.000 cumul.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv and submission_f0_ext.csv. Head:\n   Id  Predicted\n0   0         23\n1   1         23\n2   2         23\n3   3         23\n4   4         23\n"
          ]
        }
      ]
    },
    {
      "id": "13ed9c6d-ce46-4cd6-a41f-e73b08457e14",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install Torch cu121 stack and vision deps; verify GPU\n",
        "import os, sys, subprocess, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def pip(*args):\n",
        "    print('> pip', ' '.join(args), flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "for pkg in ('torch','torchvision','torchaudio'):\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "\n",
        "for d in (\n",
        "    '/app/.pip-target/torch',\n",
        "    '/app/.pip-target/torchvision',\n",
        "    '/app/.pip-target/torchaudio',\n",
        "    '/app/.pip-target/torch-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchvision-0.19.1.dist-info',\n",
        "    '/app/.pip-target/torchaudio-2.4.1.dist-info',\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d)\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "pip('install', '--no-cache-dir', '--index-url', 'https://download.pytorch.org/whl/cu121', 'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1')\n",
        "Path('constraints.txt').write_text('torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n')\n",
        "pip('install', '-c', 'constraints.txt', 'timm==1.0.9', 'albumentations==1.4.10', 'opencv-python-headless==4.10.0.84', '--upgrade-strategy', 'only-if-needed')\n",
        "\n",
        "import torch, torchvision\n",
        "print('torch:', torch.__version__, 'cuda build:', getattr(torch.version,'cuda', None), 'CUDA available:', torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    raise SystemExit('CUDA not available; cannot proceed to CNN training')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchvision as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cu121 torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 403.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 446.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 89.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 246.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nccl-cu12==2.20.5\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 330.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filelock\n  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy\n  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.2/6.2 MB 531.1 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 416.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 285.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 177.6/177.6 KB 476.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 313.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 193.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 374.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 502.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.8.0\n  Downloading https://download.pytorch.org/whl/typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 454.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 133.3/133.3 KB 457.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 193.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx\n  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.7/1.7 MB 266.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 449.0 MB/s eta 0:00:00\nCollecting nvidia-curand-cu12==10.3.2.106\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 317.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 341.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 4.4/4.4 MB 275.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvjitlink-cu12\n  Downloading https://download.pytorch.org/whl/nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 381.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpmath<1.4,>=1.1.0\n  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 539.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-1.26.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.0.0 sympy-1.13.3 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.12.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install -c constraints.txt timm==1.0.9 albumentations==1.4.10 opencv-python-headless==4.10.0.84 --upgrade-strategy only-if-needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==1.0.9\n  Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.3/2.3 MB 58.5 MB/s eta 0:00:00\nCollecting albumentations==1.4.10\n  Downloading albumentations-1.4.10-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.9/161.9 KB 423.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.10.0.84\n  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 49.9/49.9 MB 188.8 MB/s eta 0:00:00\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 563.3/563.3 KB 522.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting safetensors\n  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 485.8/485.8 KB 431.1 MB/s eta 0:00:00\nCollecting pyyaml\n  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 806.6/806.6 KB 514.0 MB/s eta 0:00:00\nCollecting torch\n  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 797.1/797.1 MB 208.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.0/7.0 MB 234.1 MB/s eta 0:00:00\nCollecting typing-extensions>=4.9.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 382.0 MB/s eta 0:00:00\nCollecting scikit-image>=0.21.0\n  Downloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.8/14.8 MB 141.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic>=2.7.0\n  Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 444.9/444.9 KB 495.6 MB/s eta 0:00:00\nCollecting albucore>=0.0.11\n  Downloading albucore-0.0.33-py3-none-any.whl (18 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn>=1.3.2\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 9.7/9.7 MB 159.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<2,>=1.24.4\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 114.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy>=1.10.0\n  Downloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35.9/35.9 MB 197.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stringzilla>=3.10.4\n  Downloading stringzilla-4.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (496 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 496.5/496.5 KB 528.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting simsimd>=5.9.2\n  Downloading simsimd-6.5.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.1/1.1 MB 135.3 MB/s eta 0:00:00\nCollecting typing-inspection>=0.4.0\n  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic-core==2.33.2\n  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 398.1 MB/s eta 0:00:00\nCollecting lazy-loader>=0.4\n  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\nCollecting tifffile>=2022.8.12\n  Downloading tifffile-2025.9.20-py3-none-any.whl (230 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 230.1/230.1 KB 368.6 MB/s eta 0:00:00\nCollecting imageio!=2.35.0,>=2.33\n  Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 315.8/315.8 KB 411.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting packaging>=21\n  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 66.5/66.5 KB 368.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow>=10.1\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 239.1 MB/s eta 0:00:00\nCollecting networkx>=3.0\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 506.4 MB/s eta 0:00:00\nCollecting threadpoolctl>=3.1.0\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nCollecting joblib>=1.2.0\n  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 308.4/308.4 KB 482.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tqdm>=4.42.1\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 78.5/78.5 KB 447.9 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting requests\n  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.7/64.7 KB 398.4 MB/s eta 0:00:00\nCollecting hf-xet<2.0.0,>=1.1.3\n  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.2/3.2 MB 222.6 MB/s eta 0:00:00\nCollecting fsspec>=2023.5.0\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 508.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 206.5 MB/s eta 0:00:00\nCollecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 140.4 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 467.9 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 197.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 224.5 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 191.4 MB/s eta 0:00:00\nCollecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 133.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 156.7 MB/s eta 0:00:00\nCollecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 186.1 MB/s eta 0:00:00\nCollecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 445.0 MB/s eta 0:00:00\nCollecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 468.1 MB/s eta 0:00:00\nCollecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 257.0 MB/s eta 0:00:00\nCollecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 221.6 MB/s eta 0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 206.1 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 148.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.10-py3-none-any.whl (70 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 70.4/70.4 KB 438.8 MB/s eta 0:00:00\nCollecting urllib3<3,>=1.21.1\n  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129.8/129.8 KB 485.0 MB/s eta 0:00:00\nCollecting certifi>=2017.4.17\n  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.2/161.2 KB 472.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting charset_normalizer<4,>=2\n  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 150.3/150.3 KB 162.5 MB/s eta 0:00:00\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 486.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: simsimd, mpmath, urllib3, typing-extensions, tqdm, threadpoolctl, sympy, stringzilla, safetensors, pyyaml, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, joblib, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, annotated-types, typing-inspection, triton, tifffile, scipy, requests, pydantic-core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lazy-loader, jinja2, imageio, scikit-learn, scikit-image, pydantic, nvidia-cusolver-cu12, huggingface_hub, albucore, torch, albumentations, torchvision, timm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 albucore-0.0.33 albumentations-1.4.10 annotated-types-0.7.0 certifi-2025.8.3 charset_normalizer-3.4.3 filelock-3.19.1 fsspec-2025.9.0 hf-xet-1.1.10 huggingface_hub-0.35.1 idna-3.10 imageio-2.37.0 jinja2-3.1.6 joblib-1.5.2 lazy-loader-0.4 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 opencv-python-headless-4.10.0.84 packaging-25.0 pillow-11.3.0 pydantic-2.11.9 pydantic-core-2.33.2 pyyaml-6.0.3 requests-2.32.5 safetensors-0.6.2 scikit-image-0.25.2 scikit-learn-1.7.2 scipy-1.16.2 simsimd-6.5.3 stringzilla-4.0.14 sympy-1.14.0 threadpoolctl-3.6.0 tifffile-2025.9.20 timm-1.0.9 torch-2.4.1 torchvision-0.19.1 tqdm-4.67.1 triton-3.0.0 typing-extensions-4.15.0 typing-inspection-0.4.1 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 cuda build: 12.1 CUDA available: True\nGPU: NVIDIA A10-24Q\n"
          ]
        }
      ]
    },
    {
      "id": "632693a6-f958-4d30-a80a-df2a3775db2f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dummy-ready CNN pipeline scaffold (hot-swap to real images when available)\n",
        "import os, json, math, random, time, gc\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import timm\n",
        "\n",
        "base = Path('.')\n",
        "train_dir = base/'train'\n",
        "test_dir = base/'test'\n",
        "\n",
        "# Build train/test DataFrames\n",
        "train_meta = json.load(open(train_dir/'metadata.json','r'))\n",
        "test_meta = json.load(open(test_dir/'metadata.json','r'))\n",
        "df_img = pd.DataFrame(train_meta['images'])[['id','file_name','width','height']]\n",
        "df_anno = pd.DataFrame(train_meta['annotations'])[['image_id','category_id']]\n",
        "df_cat = pd.DataFrame(train_meta['categories'])[['id','name','family','order']]\n",
        "df_train = df_anno.merge(df_img, left_on='image_id', right_on='id', how='left')\n",
        "df_train['path'] = df_train['file_name'].apply(lambda s: str(train_dir / s))\n",
        "df_test = pd.DataFrame(test_meta['images'])[['id','file_name','width','height']].copy()\n",
        "df_test['path'] = df_test['file_name'].apply(lambda s: str(test_dir / s))\n",
        "\n",
        "# Label encoding\n",
        "unique_cids = sorted(df_train['category_id'].unique())\n",
        "cid2idx = {c:i for i,c in enumerate(unique_cids)}\n",
        "idx2cid = np.array(unique_cids, dtype=np.int64)\n",
        "df_train['label'] = df_train['category_id'].map(cid2idx).astype(np.int64)\n",
        "num_classes = len(unique_cids)\n",
        "print('Train rows:', len(df_train), 'Num classes:', num_classes)\n",
        "\n",
        "def count_jpgs():\n",
        "    # quick diagnostics for image availability\n",
        "    import subprocess\n",
        "    cmd = \"bash -lc 'shopt -s nullglob; arr=(train/images/*/*/*.jpg); echo ${#arr[@]}; arr=(test/images/*/*.jpg); echo ${#arr[@]}'\"\n",
        "    out = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True).stdout.strip().splitlines()\n",
        "    if len(out)>=2:\n",
        "        print(f'jpg counts \\u2192 train: {out[0]}, test: {out[1]}')\n",
        "    else:\n",
        "        print('jpg count check unavailable')\n",
        "count_jpgs()\n",
        "\n",
        "class HerbariumDataset(Dataset):\n",
        "    def __init__(self, df, mode='train', img_size=384):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.mode = mode\n",
        "        self.img_size = img_size\n",
        "        self.tf_train = T.Compose([\n",
        "            T.RandomResizedCrop(img_size, scale=(0.7,1.0), ratio=(0.75,1.33)),\n",
        "            T.RandomHorizontalFlip(p=0.5),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ])\n",
        "        self.tf_test = T.Compose([\n",
        "            T.Resize(img_size, interpolation=T.InterpolationMode.BICUBIC),\n",
        "            T.CenterCrop(img_size),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def _load_image(self, path):\n",
        "        try:\n",
        "            if os.path.exists(path):\n",
        "                with Image.open(path) as im:\n",
        "                    return im.convert('RGB')\n",
        "        except Exception as e:\n",
        "            pass\n",
        "        # Fallback dummy if file missing/unreadable\n",
        "        return Image.new('RGB', (self.img_size, self.img_size), (0,0,0))\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]\n",
        "        img = self._load_image(r['path'])\n",
        "        if self.mode == 'train':\n",
        "            img = self.tf_train(img)\n",
        "            label = int(r['label'])\n",
        "            return img, label\n",
        "        else:\n",
        "            img = self.tf_test(img)\n",
        "            return img, str(r['id'])\n",
        "\n",
        "def make_model(backbone='convnext_tiny', num_classes=1):\n",
        "        model = timm.create_model(backbone, pretrained=True, num_classes=num_classes)\n",
        "        model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        return model\n",
        "\n",
        "def make_sampler(labels, power=0.5):\n",
        "    # inverse sqrt frequency weights by default\n",
        "    vals, counts = np.unique(labels, return_counts=True)\n",
        "    freq = np.zeros(labels.max()+1, dtype=np.float64)\n",
        "    freq[vals] = counts\n",
        "    w = 1.0 / np.clip(freq, 1, None)**power\n",
        "    weights = w[labels]\n",
        "    return WeightedRandomSampler(weights=torch.as_tensor(weights, dtype=torch.float32), num_samples=len(labels), replacement=True)\n",
        "\n",
        "def train_smoke(df_train, epochs=1, batch_size=32, img_size=384, max_rows=4096):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    df_small = df_train.sample(n=min(max_rows, len(df_train)), random_state=42) if len(df_train) > max_rows else df_train.copy()\n",
        "    ds = HerbariumDataset(df_small, mode='train', img_size=img_size)\n",
        "    sampler = make_sampler(df_small['label'].values)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "    model = make_model('convnext_tiny', num_classes=num_classes)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.02)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "    model.train()\n",
        "    t0 = time.time()\n",
        "    for ep in range(epochs):\n",
        "        running = 0.0\n",
        "        n = 0\n",
        "        for bi, (x,y) in enumerate(dl):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = torch.as_tensor(y, device=device)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y)\n",
        "            scaler.scale(loss).step(optimizer)\n",
        "            scaler.update()\n",
        "            running += loss.item()*x.size(0)\n",
        "            n += x.size(0)\n",
        "            if (bi+1) % 50 == 0:\n",
        "                elapsed = time.time()-t0\n",
        "                print(f'Epoch {ep} Batch {bi+1}/{len(dl)} loss {running/max(n,1):.4f} elapsed {elapsed:.1f}s', flush=True)\n",
        "        print(f'Epoch {ep} done. Avg loss {running/max(n,1):.4f}')\n",
        "    return model\n",
        "\n",
        "def infer_test(model, df_test, batch_size=64, img_size=384):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    ds = HerbariumDataset(df_test, mode='test', img_size=img_size)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    ids = []\n",
        "    t0 = time.time()\n",
        "    with torch.no_grad():\n",
        "        for bi, (x, id_batch) in enumerate(dl):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                logits = model(x)\n",
        "            pred_idx = torch.argmax(logits, dim=1).detach().cpu().numpy()\n",
        "            preds.append(pred_idx)\n",
        "            ids.extend(list(id_batch))\n",
        "            if (bi+1) % 50 == 0:\n",
        "                print(f'Infer batch {bi+1}/{len(dl)} elapsed {time.time()-t0:.1f}s')\n",
        "    preds = np.concatenate(preds) if preds else np.array([], dtype=np.int64)\n",
        "    pred_cids = idx2cid[preds] if len(preds)>0 else np.array([], dtype=np.int64)\n",
        "    sub = pd.read_csv(base/'sample_submission.csv')\n",
        "    id2pred = dict(zip(ids, pred_cids.tolist()))\n",
        "    sub['Predicted'] = sub['Id'].astype(str).map(id2pred).fillna(int(df_train['category_id'].mode().iloc[0])).astype(int)\n",
        "    return sub\n",
        "\n",
        "print('CNN scaffold ready (PIL + torchvision transforms). Functions: train_smoke(), infer_test(). No training executed by default.')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rows: 1779953 Num classes: 64500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jpg counts \u2192 train: 1779953, test: 477806\nCNN scaffold ready (torchvision transforms). Functions: train_smoke(), infer_test(). No training executed by default.\n"
          ]
        }
      ]
    },
    {
      "id": "e0f286a2-452d-49f2-bc94-5f8e62a8423a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Smoke-run CNN scaffold (no training) and write submission_dummy.csv (small test subset)\n",
        "print('Starting CNN smoke run (no training) ...')\n",
        "model = train_smoke(df_train, epochs=0, batch_size=8, img_size=224, max_rows=64)\n",
        "\n",
        "# Use a tiny subset of test to avoid heavy inference; fill rest with global mode\n",
        "df_te_small = df_test.sample(n=min(256, len(df_test)), random_state=42).copy()\n",
        "sub_dummy = infer_test(model, df_te_small, batch_size=64, img_size=224)\n",
        "sub_dummy.to_csv('submission_dummy.csv', index=False)\n",
        "print('Wrote submission_dummy.csv (from small test subset + global mode fallback). Head:')\n",
        "print(sub_dummy.head())\n",
        "print('Done.')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting CNN smoke run (no training) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/convnext_tiny.in12k_ft_in1k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._hub:[timm/convnext_tiny.in12k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._builder:Missing keys (head.fc.weight, head.fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_94/654275732.py:100: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_94/654275732.py:134: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_dummy.csv (from small test subset + global mode fallback). Head:\n   Id  Predicted\n0   0      42811\n1   1      42811\n2   2      42811\n3   3      42811\n4   4      42811\nDone.\n"
          ]
        }
      ]
    },
    {
      "id": "8e1019bd-1af8-47fc-a346-80e2b5f4b894",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Smoothed metadata baseline: min-count gating on fallback chain\n",
        "import json, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "base = Path('.')\n",
        "train_meta = json.load(open(base/'train'/'metadata.json','r'))\n",
        "test_meta = json.load(open(base/'test'/'metadata.json','r'))\n",
        "ss = pd.read_csv(base/'sample_submission.csv')\n",
        "\n",
        "df_img = pd.DataFrame(train_meta['images'])[['file_name','width','height','id']]\n",
        "df_anno = pd.DataFrame(train_meta['annotations'])[['image_id','category_id']]\n",
        "df_tr = df_anno.merge(df_img, left_on='image_id', right_on='id', how='left')\n",
        "\n",
        "def parse_F0_F1(s):\n",
        "    parts = s.split('/')\n",
        "    f0 = parts[1] if len(parts) > 1 else ''\n",
        "    f1 = parts[2] if len(parts) > 2 else ''\n",
        "    return f0, f1\n",
        "\n",
        "F0_F1 = df_tr['file_name'].map(parse_F0_F1)\n",
        "df_tr['F0'] = [t[0] for t in F0_F1]\n",
        "df_tr['F1'] = [t[1] for t in F0_F1]\n",
        "df_tr['aspect'] = (df_tr['width'] / df_tr['height']).astype(float)\n",
        "width_bins = [0, 600, 700, 800, 900, 1000, 1100, 2000]\n",
        "height_bins = [0, 600, 700, 800, 900, 1000, 1100, 2000]\n",
        "aspect_bins = [0, 0.6, 0.75, 0.9, 1.0, 1.1, 1.3, 2.5]\n",
        "df_tr['wb'] = pd.cut(df_tr['width'], bins=width_bins, include_lowest=True).astype(str)\n",
        "df_tr['hb'] = pd.cut(df_tr['height'], bins=height_bins, include_lowest=True).astype(str)\n",
        "df_tr['ab'] = pd.cut(df_tr['aspect'], bins=aspect_bins, include_lowest=True).astype(str)\n",
        "\n",
        "global_mode = int(df_tr['category_id'].mode().iloc[0])\n",
        "print('Global mode:', global_mode)\n",
        "\n",
        "def mode_map_thresh(df, keys, min_count=10):\n",
        "    grp = df.groupby(keys)['category_id']\n",
        "    counts = grp.size().rename('n')\n",
        "    modal = grp.agg(lambda x: x.value_counts().idxmax())\n",
        "    m = pd.concat([modal, counts], axis=1).reset_index()\n",
        "    m = m[m['n'] >= min_count]\n",
        "    # build dict: key_tuple -> modal category\n",
        "    keycols = keys.copy()\n",
        "    m['key'] = list(map(tuple, m[keycols].values.tolist()))\n",
        "    return dict(zip(m['key'], m['category_id']))\n",
        "\n",
        "min_n = 10\n",
        "m_F0_F1_wb_hb = mode_map_thresh(df_tr, ['F0','F1','wb','hb'], min_n)\n",
        "m_F0_F1_ab   = mode_map_thresh(df_tr, ['F0','F1','ab'], min_n)\n",
        "m_F0_wb_hb   = mode_map_thresh(df_tr, ['F0','wb','hb'], min_n)\n",
        "m_F0_ab      = mode_map_thresh(df_tr, ['F0','ab'], min_n)\n",
        "m_F0_F1      = mode_map_thresh(df_tr, ['F0','F1'], min_n)\n",
        "m_F0_wb      = mode_map_thresh(df_tr, ['F0','wb'], min_n)\n",
        "m_F0_hb      = mode_map_thresh(df_tr, ['F0','hb'], min_n)\n",
        "m_F0         = mode_map_thresh(df_tr, ['F0'], min_n)\n",
        "\n",
        "df_te = pd.DataFrame(test_meta['images'])[['id','file_name','width','height']].copy()\n",
        "F0_F1_te = df_te['file_name'].map(parse_F0_F1)\n",
        "df_te['F0'] = [t[0] for t in F0_F1_te]\n",
        "df_te['F1'] = [t[1] for t in F0_F1_te]\n",
        "df_te['aspect'] = (df_te['width'] / df_te['height']).astype(float)\n",
        "df_te['wb'] = pd.cut(df_te['width'], bins=width_bins, include_lowest=True).astype(str)\n",
        "df_te['hb'] = pd.cut(df_te['height'], bins=height_bins, include_lowest=True).astype(str)\n",
        "df_te['ab'] = pd.cut(df_te['aspect'], bins=aspect_bins, include_lowest=True).astype(str)\n",
        "\n",
        "levels = [\n",
        "    ('F0_F1_wb_hb', lambda r: m_F0_F1_wb_hb.get((r['F0'], r['F1'], r['wb'], r['hb']))),\n",
        "    ('F0_F1_ab',    lambda r: m_F0_F1_ab.get((r['F0'], r['F1'], r['ab']))),\n",
        "    ('F0_wb_hb',    lambda r: m_F0_wb_hb.get((r['F0'], r['wb'], r['hb']))),\n",
        "    ('F0_ab',       lambda r: m_F0_ab.get((r['F0'], r['ab']))),\n",
        "    ('F0_F1',       lambda r: m_F0_F1.get((r['F0'], r['F1']))),\n",
        "    ('F0_wb',       lambda r: m_F0_wb.get((r['F0'], r['wb']))),\n",
        "    ('F0_hb',       lambda r: m_F0_hb.get((r['F0'], r['hb']))),\n",
        "    ('F0',          lambda r: m_F0.get((r['F0'],)))\n",
        "]\n",
        "\n",
        "pred = np.full(len(df_te), global_mode, dtype=np.int64)\n",
        "covered = np.zeros(len(df_te), dtype=bool)\n",
        "\n",
        "for name, fn in levels:\n",
        "    if covered.all():\n",
        "        break\n",
        "    idx = np.where(~covered)[0]\n",
        "    vals = [fn(df_te.iloc[i]) for i in idx]\n",
        "    take = [v is not None for v in vals]\n",
        "    if any(take):\n",
        "        pred_idx = np.array(idx)[np.array(take)]\n",
        "        pred_vals = np.array([int(v) for v in np.array(vals, dtype=object)[np.array(take)]])\n",
        "        pred[pred_idx] = pred_vals\n",
        "        covered[pred_idx] = True\n",
        "    print(f'Level {name}: covered {covered.mean():.3f}')\n",
        "\n",
        "sub = ss.copy()\n",
        "id2pred = dict(zip(df_te['id'].astype(str), pred.tolist()))\n",
        "sub['Predicted'] = sub['Id'].astype(str).map(id2pred).fillna(global_mode).astype(int)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "sub.to_csv('submission_f0_smoothed.csv', index=False)\n",
        "print('Wrote submission.csv and submission_f0_smoothed.csv. Head:')\n",
        "print(sub.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global mode: 42811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level F0_F1_wb_hb: covered 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level F0_F1_ab: covered 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level F0_wb_hb: covered 0.990\nLevel F0_ab: covered 0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level F0_F1: covered 0.991\nLevel F0_wb: covered 0.991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level F0_hb: covered 1.000\nLevel F0: covered 1.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv and submission_f0_smoothed.csv. Head:\n   Id  Predicted\n0   0         23\n1   1         23\n2   2         23\n3   3         23\n4   4         23\n"
          ]
        }
      ]
    },
    {
      "id": "9b32a1db-5c1e-413c-b622-71883a75e48b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Per-F0 Naive Bayes baseline with Laplace smoothing and top-K classes\n",
        "import json, pandas as pd, numpy as np, time\n",
        "from pathlib import Path\n",
        "\n",
        "base = Path('.')\n",
        "train_meta = json.load(open(base/'train'/'metadata.json','r'))\n",
        "test_meta = json.load(open(base/'test'/'metadata.json','r'))\n",
        "ss = pd.read_csv(base/'sample_submission.csv')\n",
        "\n",
        "# Prepare train features\n",
        "df_img = pd.DataFrame(train_meta['images'])[['file_name','width','height','id']]\n",
        "df_anno = pd.DataFrame(train_meta['annotations'])[['image_id','category_id']]\n",
        "df_tr = df_anno.merge(df_img, left_on='image_id', right_on='id', how='left')\n",
        "\n",
        "def parse_F0_F1(s):\n",
        "    parts = s.split('/')\n",
        "    f0 = parts[1] if len(parts) > 1 else ''\n",
        "    f1 = parts[2] if len(parts) > 2 else ''\n",
        "    return f0, f1\n",
        "\n",
        "F0_F1 = df_tr['file_name'].map(parse_F0_F1)\n",
        "df_tr['F0'] = [t[0] for t in F0_F1]\n",
        "df_tr['F1'] = [t[1] for t in F0_F1]\n",
        "df_tr['aspect'] = (df_tr['width'] / df_tr['height']).astype(float)\n",
        "width_bins = [0, 600, 700, 800, 900, 1000, 1100, 2000]\n",
        "height_bins = [0, 600, 700, 800, 900, 1000, 1100, 2000]\n",
        "aspect_bins = [0, 0.6, 0.75, 0.9, 1.0, 1.1, 1.3, 2.5]\n",
        "df_tr['wb'] = pd.cut(df_tr['width'], bins=width_bins, include_lowest=True).astype(str)\n",
        "df_tr['hb'] = pd.cut(df_tr['height'], bins=height_bins, include_lowest=True).astype(str)\n",
        "df_tr['ab'] = pd.cut(df_tr['aspect'], bins=aspect_bins, include_lowest=True).astype(str)\n",
        "\n",
        "# Fixed bin label universes (consistent mapping train/test)\n",
        "wb_labels = pd.cut(pd.Series(width_bins[:-1]) + 1e-6, bins=width_bins, include_lowest=True).astype(str).unique().tolist()\n",
        "hb_labels = pd.cut(pd.Series(height_bins[:-1]) + 1e-6, bins=height_bins, include_lowest=True).astype(str).unique().tolist()\n",
        "ab_labels = pd.cut(pd.Series(aspect_bins[:-1]) + 1e-6, bins=aspect_bins, include_lowest=True).astype(str).unique().tolist()\n",
        "wb2i = {l:i for i,l in enumerate(wb_labels)}\n",
        "hb2i = {l:i for i,l in enumerate(hb_labels)}\n",
        "ab2i = {l:i for i,l in enumerate(ab_labels)}\n",
        "Bwb, Bhb, Bab = len(wb2i), len(hb2i), len(ab2i)\n",
        "\n",
        "global_mode = int(df_tr['category_id'].mode().iloc[0])\n",
        "print('Global mode:', global_mode)\n",
        "\n",
        "# Build per-F0 NB parameters\n",
        "alpha = 1.0\n",
        "topK = 200\n",
        "models = {}  # F0 -> dict with classes, log_prior, logPwb[Bwb,K], logPhb[Bhb,K], logPab[Bab,K]\n",
        "t0 = time.time()\n",
        "for f0, g in df_tr.groupby('F0', sort=False):\n",
        "    cls_counts = g['category_id'].value_counts()\n",
        "    classes = cls_counts.head(topK).index.values.astype(np.int64)\n",
        "    counts = cls_counts.head(topK).values.astype(np.float64)\n",
        "    C = len(classes)\n",
        "    if C == 0:\n",
        "        continue\n",
        "    prior = (counts + alpha) / (counts.sum() + alpha * C)\n",
        "    # Initialize count matrices with alpha for smoothing\n",
        "    Cwb = np.full((Bwb, C), alpha, dtype=np.float64)\n",
        "    Chb = np.full((Bhb, C), alpha, dtype=np.float64)\n",
        "    Cab = np.full((Bab, C), alpha, dtype=np.float64)\n",
        "    # Precompute bin indices for group\n",
        "    gi_wb = g['wb'].map(wb2i).fillna(-1).astype(int).values\n",
        "    gi_hb = g['hb'].map(hb2i).fillna(-1).astype(int).values\n",
        "    gi_ab = g['ab'].map(ab2i).fillna(-1).astype(int).values\n",
        "    gi_cls = g['category_id'].values\n",
        "    # For each candidate class, accumulate bin counts\n",
        "    cls2pos = {c:i for i,c in enumerate(classes)}\n",
        "    for idx_row in range(len(g)):\n",
        "        c = gi_cls[idx_row]\n",
        "        j = cls2pos.get(c, None)\n",
        "        if j is None:\n",
        "            continue\n",
        "        iw, ih, ia = gi_wb[idx_row], gi_hb[idx_row], gi_ab[idx_row]\n",
        "        if iw >= 0: Cwb[iw, j] += 1.0\n",
        "        if ih >= 0: Chb[ih, j] += 1.0\n",
        "        if ia >= 0: Cab[ia, j] += 1.0\n",
        "    # Normalize to probabilities and take logs\n",
        "    log_prior = np.log(prior + 1e-12)\n",
        "    logPwb = np.log(Cwb / Cwb.sum(axis=0, keepdims=True))\n",
        "    logPhb = np.log(Chb / Chb.sum(axis=0, keepdims=True))\n",
        "    logPab = np.log(Cab / Cab.sum(axis=0, keepdims=True))\n",
        "    models[f0] = dict(classes=classes, log_prior=log_prior, logPwb=logPwb, logPhb=logPhb, logPab=logPab)\n",
        "    if len(models) % 50 == 0:\n",
        "        print(f'Built NB for {len(models)} F0 shards, elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "print(f'Total F0 shards modeled: {len(models)} in {time.time()-t0:.1f}s')\n",
        "\n",
        "# Prepare test features\n",
        "df_te = pd.DataFrame(test_meta['images'])[['id','file_name','width','height']].copy()\n",
        "F0_F1_te = df_te['file_name'].map(parse_F0_F1)\n",
        "df_te['F0'] = [t[0] for t in F0_F1_te]\n",
        "df_te['aspect'] = (df_te['width'] / df_te['height']).astype(float)\n",
        "df_te['wb'] = pd.cut(df_te['width'], bins=width_bins, include_lowest=True).astype(str)\n",
        "df_te['hb'] = pd.cut(df_te['height'], bins=height_bins, include_lowest=True).astype(str)\n",
        "df_te['ab'] = pd.cut(df_te['aspect'], bins=aspect_bins, include_lowest=True).astype(str)\n",
        "\n",
        "# Inference per F0\n",
        "preds = np.full(len(df_te), global_mode, dtype=np.int64)\n",
        "t1 = time.time()\n",
        "for f0, g in df_te.groupby('F0', sort=False):\n",
        "    idx = g.index.values\n",
        "    m = models.get(f0, None)\n",
        "    if m is None:\n",
        "        continue\n",
        "    classes = m['classes']  # (K,)\n",
        "    K = classes.shape[0]\n",
        "    logp = np.tile(m['log_prior'][None, :], (len(g), 1))  # (n,K)\n",
        "    iw = g['wb'].map(wb2i).fillna(-1).astype(int).values\n",
        "    ih = g['hb'].map(hb2i).fillna(-1).astype(int).values\n",
        "    ia = g['ab'].map(ab2i).fillna(-1).astype(int).values\n",
        "    # Add likelihood terms where bins are known\n",
        "    sel = iw >= 0\n",
        "    if sel.any():\n",
        "        logp[sel] += m['logPwb'][iw[sel], :]\n",
        "    sel = ih >= 0\n",
        "    if sel.any():\n",
        "        logp[sel] += m['logPhb'][ih[sel], :]\n",
        "    sel = ia >= 0\n",
        "    if sel.any():\n",
        "        logp[sel] += 0.5 * m['logPab'][ia[sel], :]\n",
        "    jj = np.argmax(logp, axis=1)\n",
        "    preds[idx] = classes[jj]\n",
        "    if len(models) >= 1 and (len(idx) >= 20000):\n",
        "        print(f'F0 {f0}: predicted {len(idx)} rows', flush=True)\n",
        "print(f'Inference done in {time.time()-t1:.1f}s')\n",
        "\n",
        "# Build submission\n",
        "sub = ss.copy()\n",
        "id2pred = dict(zip(df_te['id'].astype(str), preds.tolist()))\n",
        "sub['Predicted'] = sub['Id'].astype(str).map(id2pred).fillna(global_mode).astype(int)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "sub.to_csv('submission_nb_f0.csv', index=False)\n",
        "print('Wrote submission.csv and submission_nb_f0.csv. Head:')\n",
        "print(sub.head())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global mode: 42811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 50 F0 shards, elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 100 F0 shards, elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 150 F0 shards, elapsed 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 200 F0 shards, elapsed 1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 250 F0 shards, elapsed 1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 300 F0 shards, elapsed 1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 350 F0 shards, elapsed 2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 400 F0 shards, elapsed 2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 450 F0 shards, elapsed 2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 500 F0 shards, elapsed 2.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 550 F0 shards, elapsed 3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built NB for 600 F0 shards, elapsed 3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total F0 shards modeled: 645 in 3.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference done in 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv and submission_nb_f0.csv. Head:\n   Id  Predicted\n0   0         23\n1   1         23\n2   2         23\n3   3         23\n4   4         23\n"
          ]
        }
      ]
    },
    {
      "id": "20ba189d-0205-4b45-85c8-42a2b6d7b207",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Tuned per-F0 Naive Bayes (topK=500, prior alpha=0.5, likelihood alpha=1.5, wb=1.0, hb=1.0, ab=0.3)\n",
        "import json, pandas as pd, numpy as np, time\n",
        "from pathlib import Path\n",
        "\n",
        "base = Path('.')\n",
        "train_meta = json.load(open(base/'train'/'metadata.json','r'))\n",
        "test_meta = json.load(open(base/'test'/'metadata.json','r'))\n",
        "ss = pd.read_csv(base/'sample_submission.csv')\n",
        "\n",
        "df_img = pd.DataFrame(train_meta['images'])[['file_name','width','height','id']]\n",
        "df_anno = pd.DataFrame(train_meta['annotations'])[['image_id','category_id']]\n",
        "df_tr = df_anno.merge(df_img, left_on='image_id', right_on='id', how='left')\n",
        "\n",
        "def parse_F0_F1(s):\n",
        "    parts = s.split('/')\n",
        "    f0 = parts[1] if len(parts) > 1 else ''\n",
        "    f1 = parts[2] if len(parts) > 2 else ''\n",
        "    return f0, f1\n",
        "\n",
        "F0_F1 = df_tr['file_name'].map(parse_F0_F1)\n",
        "df_tr['F0'] = [t[0] for t in F0_F1]\n",
        "df_tr['aspect'] = (df_tr['width'] / df_tr['height']).astype(float)\n",
        "width_bins = [0, 600, 700, 800, 900, 1000, 1100, 2000]\n",
        "height_bins = [0, 600, 700, 800, 900, 1000, 1100, 2000]\n",
        "aspect_bins = [0, 0.6, 0.75, 0.9, 1.0, 1.1, 1.3, 2.5]\n",
        "df_tr['wb'] = pd.cut(df_tr['width'], bins=width_bins, include_lowest=True).astype(str)\n",
        "df_tr['hb'] = pd.cut(df_tr['height'], bins=height_bins, include_lowest=True).astype(str)\n",
        "df_tr['ab'] = pd.cut(df_tr['aspect'], bins=aspect_bins, include_lowest=True).astype(str)\n",
        "\n",
        "wb_labels = pd.cut(pd.Series(width_bins[:-1]) + 1e-6, bins=width_bins, include_lowest=True).astype(str).unique().tolist()\n",
        "hb_labels = pd.cut(pd.Series(height_bins[:-1]) + 1e-6, bins=height_bins, include_lowest=True).astype(str).unique().tolist()\n",
        "ab_labels = pd.cut(pd.Series(aspect_bins[:-1]) + 1e-6, bins=aspect_bins, include_lowest=True).astype(str).unique().tolist()\n",
        "wb2i = {l:i for i,l in enumerate(wb_labels)}\n",
        "hb2i = {l:i for i,l in enumerate(hb_labels)}\n",
        "ab2i = {l:i for i,l in enumerate(ab_labels)}\n",
        "Bwb, Bhb, Bab = len(wb2i), len(hb2i), len(ab2i)\n",
        "\n",
        "global_mode = int(df_tr['category_id'].mode().iloc[0])\n",
        "print('Global mode:', global_mode)\n",
        "\n",
        "alpha_prior = 0.5\n",
        "alpha_like = 1.5\n",
        "topK = 500\n",
        "w_wb, w_hb, w_ab = 1.0, 1.0, 0.3\n",
        "\n",
        "models = {}\n",
        "t0 = time.time()\n",
        "for f0, g in df_tr.groupby('F0', sort=False):\n",
        "    cls_counts = g['category_id'].value_counts()\n",
        "    classes = cls_counts.head(topK).index.values.astype(np.int64)\n",
        "    counts = cls_counts.head(topK).values.astype(np.float64)\n",
        "    C = len(classes)\n",
        "    if C == 0:\n",
        "        continue\n",
        "    prior = (counts + alpha_prior) / (counts.sum() + alpha_prior * C)\n",
        "    Cwb = np.full((Bwb, C), alpha_like, dtype=np.float64)\n",
        "    Chb = np.full((Bhb, C), alpha_like, dtype=np.float64)\n",
        "    Cab = np.full((Bab, C), alpha_like, dtype=np.float64)\n",
        "    gi_wb = g['wb'].map(wb2i).fillna(-1).astype(int).values\n",
        "    gi_hb = g['hb'].map(hb2i).fillna(-1).astype(int).values\n",
        "    gi_ab = g['ab'].map(ab2i).fillna(-1).astype(int).values\n",
        "    gi_cls = g['category_id'].values\n",
        "    cls2pos = {c:i for i,c in enumerate(classes)}\n",
        "    for idx_row in range(len(g)):\n",
        "        j = cls2pos.get(gi_cls[idx_row], None)\n",
        "        if j is None:\n",
        "            continue\n",
        "        iw, ih, ia = gi_wb[idx_row], gi_hb[idx_row], gi_ab[idx_row]\n",
        "        if iw >= 0: Cwb[iw, j] += 1.0\n",
        "        if ih >= 0: Chb[ih, j] += 1.0\n",
        "        if ia >= 0: Cab[ia, j] += 1.0\n",
        "    log_prior = np.log(prior + 1e-12)\n",
        "    logPwb = np.log(Cwb / Cwb.sum(axis=0, keepdims=True))\n",
        "    logPhb = np.log(Chb / Chb.sum(axis=0, keepdims=True))\n",
        "    logPab = np.log(Cab / Cab.sum(axis=0, keepdims=True))\n",
        "    models[f0] = dict(classes=classes, log_prior=log_prior, logPwb=logPwb, logPhb=logPhb, logPab=logPab)\n",
        "    if len(models) % 50 == 0:\n",
        "        print(f'Built tuned NB for {len(models)} F0 shards, elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "print(f'Total F0 shards modeled (tuned): {len(models)} in {time.time()-t0:.1f}s')\n",
        "\n",
        "df_te = pd.DataFrame(test_meta['images'])[['id','file_name','width','height']].copy()\n",
        "F0_F1_te = df_te['file_name'].map(parse_F0_F1)\n",
        "df_te['F0'] = [t[0] for t in F0_F1_te]\n",
        "df_te['aspect'] = (df_te['width'] / df_te['height']).astype(float)\n",
        "df_te['wb'] = pd.cut(df_te['width'], bins=width_bins, include_lowest=True).astype(str)\n",
        "df_te['hb'] = pd.cut(df_te['height'], bins=height_bins, include_lowest=True).astype(str)\n",
        "df_te['ab'] = pd.cut(df_te['aspect'], bins=aspect_bins, include_lowest=True).astype(str)\n",
        "\n",
        "preds = np.full(len(df_te), global_mode, dtype=np.int64)\n",
        "t1 = time.time()\n",
        "for f0, g in df_te.groupby('F0', sort=False):\n",
        "    idx = g.index.values\n",
        "    m = models.get(f0, None)\n",
        "    if m is None:\n",
        "        continue\n",
        "    classes = m['classes']\n",
        "    K = classes.shape[0]\n",
        "    logp = np.tile(m['log_prior'][None, :], (len(g), 1))\n",
        "    iw = g['wb'].map(wb2i).fillna(-1).astype(int).values\n",
        "    ih = g['hb'].map(hb2i).fillna(-1).astype(int).values\n",
        "    ia = g['ab'].map(ab2i).fillna(-1).astype(int).values\n",
        "    sel = iw >= 0\n",
        "    if sel.any():\n",
        "        logp[sel] += w_wb * m['logPwb'][iw[sel], :]\n",
        "    sel = ih >= 0\n",
        "    if sel.any():\n",
        "        logp[sel] += w_hb * m['logPhb'][ih[sel], :]\n",
        "    sel = ia >= 0\n",
        "    if sel.any():\n",
        "        logp[sel] += w_ab * m['logPab'][ia[sel], :]\n",
        "    jj = np.argmax(logp, axis=1)\n",
        "    preds[idx] = classes[jj]\n",
        "print(f'Tuned NB inference done in {time.time()-t1:.1f}s')\n",
        "\n",
        "sub = ss.copy()\n",
        "id2pred = dict(zip(df_te['id'].astype(str), preds.tolist()))\n",
        "sub['Predicted'] = sub['Id'].astype(str).map(id2pred).fillna(global_mode).astype(int)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "sub.to_csv('submission_nb_f0_tuned.csv', index=False)\n",
        "print('Wrote submission.csv and submission_nb_f0_tuned.csv. Head:')\n",
        "print(sub.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global mode: 42811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 50 F0 shards, elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 100 F0 shards, elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 150 F0 shards, elapsed 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 200 F0 shards, elapsed 1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 250 F0 shards, elapsed 1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 300 F0 shards, elapsed 1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 350 F0 shards, elapsed 2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 400 F0 shards, elapsed 2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 450 F0 shards, elapsed 2.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 500 F0 shards, elapsed 2.8s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 550 F0 shards, elapsed 3.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built tuned NB for 600 F0 shards, elapsed 3.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total F0 shards modeled (tuned): 645 in 3.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuned NB inference done in 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv and submission_nb_f0_tuned.csv. Head:\n   Id  Predicted\n0   0         23\n1   1         23\n2   2         23\n3   3         23\n4   4         23\n"
          ]
        }
      ]
    },
    {
      "id": "75c8a7c8-2b78-43a4-b4b0-eb0fb1e0146b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Blend NB(tuned) with smoothed fallback using per-F0 class prior as tie-break\n",
        "import json, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "base = Path('.')\n",
        "train_meta = json.load(open(base/'train'/'metadata.json','r'))\n",
        "test_meta = json.load(open(base/'test'/'metadata.json','r'))\n",
        "\n",
        "# Load candidate submissions\n",
        "sub_nb = pd.read_csv('submission_nb_f0_tuned.csv') if Path('submission_nb_f0_tuned.csv').exists() else pd.read_csv('submission_nb_f0.csv')\n",
        "sub_sm = pd.read_csv('submission_f0_smoothed.csv') if Path('submission_f0_smoothed.csv').exists() else pd.read_csv('submission_f0_ext.csv')\n",
        "\n",
        "# Build per-F0 class prior from train\n",
        "df_img = pd.DataFrame(train_meta['images'])[['file_name','width','height','id']]\n",
        "df_anno = pd.DataFrame(train_meta['annotations'])[['image_id','category_id']]\n",
        "df_tr = df_anno.merge(df_img, left_on='image_id', right_on='id', how='left')\n",
        "def parse_F0(s):\n",
        "    parts = s.split('/')\n",
        "    return parts[1] if len(parts) > 1 else ''\n",
        "df_tr['F0'] = df_tr['file_name'].map(parse_F0)\n",
        "prior_f0 = df_tr.groupby(['F0','category_id']).size().rename('cnt').reset_index()\n",
        "prior_f0['key'] = list(zip(prior_f0['F0'], prior_f0['category_id']))\n",
        "prior_map = prior_f0.set_index('key')['cnt'].to_dict()\n",
        "\n",
        "# Test F0 per Id\n",
        "df_te = pd.DataFrame(test_meta['images'])[['id','file_name']].copy()\n",
        "df_te['F0'] = df_te['file_name'].map(parse_F0)\n",
        "id2f0 = dict(zip(df_te['id'].astype(str), df_te['F0']))\n",
        "\n",
        "# Align and blend\n",
        "sub = sub_nb.merge(sub_sm, on='Id', how='left', suffixes=('_nb','_sm'))\n",
        "sub['Predicted_sm'].fillna(sub['Predicted_nb'], inplace=True)\n",
        "def choose_row(r):\n",
        "    f0 = id2f0.get(str(r['Id']), '')\n",
        "    c_nb = int(r['Predicted_nb'])\n",
        "    c_sm = int(r['Predicted_sm'])\n",
        "    if c_nb == c_sm:\n",
        "        return c_nb\n",
        "    cnt_nb = prior_map.get((f0, c_nb), 0)\n",
        "    cnt_sm = prior_map.get((f0, c_sm), 0)\n",
        "    # prefer higher prior within F0; tie -> NB\n",
        "    return c_nb if cnt_nb >= cnt_sm else c_sm\n",
        "\n",
        "sub['Predicted'] = sub.apply(choose_row, axis=1).astype(int)\n",
        "out = sub[['Id','Predicted']].copy()\n",
        "out.to_csv('submission.csv', index=False)\n",
        "out.to_csv('submission_blend_nb_smoothed.csv', index=False)\n",
        "print('Wrote submission.csv and submission_blend_nb_smoothed.csv. Head:')\n",
        "print(out.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "574e0b2b-aff2-436b-b6b7-14d0aead3fce",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Main CNN training run per expert plan (ConvNeXtV2-Base @384, steps-based, EMA, AMP, class-balanced sampler) - updates-based scheduler\n",
        "import os, math, time, random, json, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from timm.data.mixup import Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy\n",
        "\n",
        "base = Path('.')\n",
        "train_dir = base/'train'\n",
        "test_dir = base/'test'\n",
        "\n",
        "# Reuse df_train, df_test, idx2cid, cid2idx, num_classes from earlier cell if present; otherwise, build them\n",
        "try:\n",
        "    df_train\n",
        "    df_test\n",
        "    idx2cid\n",
        "    cid2idx\n",
        "    num_classes\n",
        "except NameError:\n",
        "    train_meta = json.load(open(train_dir/'metadata.json','r'))\n",
        "    test_meta = json.load(open(test_dir/'metadata.json','r'))\n",
        "    df_img = pd.DataFrame(train_meta['images'])[['id','file_name','width','height']]\n",
        "    df_anno = pd.DataFrame(train_meta['annotations'])[['image_id','category_id']]\n",
        "    df_train = df_anno.merge(df_img, left_on='image_id', right_on='id', how='left')\n",
        "    df_train['path'] = df_train['file_name'].apply(lambda s: str(train_dir / s))\n",
        "    df_test = pd.DataFrame(test_meta['images'])[['id','file_name','width','height']].copy()\n",
        "    df_test['path'] = df_test['file_name'].apply(lambda s: str(test_dir / s))\n",
        "    unique_cids = sorted(df_train['category_id'].unique())\n",
        "    cid2idx = {c:i for i,c in enumerate(unique_cids)}\n",
        "    idx2cid = np.array(unique_cids, dtype=np.int64)\n",
        "    df_train['label'] = df_train['category_id'].map(cid2idx).astype(np.int64)\n",
        "    num_classes = len(unique_cids)\n",
        "print('Train rows:', len(df_train), 'Num classes:', num_classes)\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "class HerbariumDataset(Dataset):\n",
        "    def __init__(self, df, mode='train', img_size=384):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.mode = mode\n",
        "        self.img_size = img_size\n",
        "        self.tf_train = T.Compose([\n",
        "            T.RandomResizedCrop(img_size, scale=(0.7,1.0), ratio=(0.75,1.33)),\n",
        "            T.RandomHorizontalFlip(p=0.5),\n",
        "            T.ColorJitter(0.1,0.1,0.1,0.05),\n",
        "            T.RandomRotation(degrees=15),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ])\n",
        "        self.tf_val = T.Compose([\n",
        "            T.Resize(img_size, interpolation=T.InterpolationMode.BICUBIC),\n",
        "            T.CenterCrop(img_size),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def _load_image(self, path):\n",
        "        try:\n",
        "            if os.path.exists(path):\n",
        "                with Image.open(path) as im:\n",
        "                    return im.convert('RGB')\n",
        "        except Exception:\n",
        "            pass\n",
        "        return Image.new('RGB', (self.img_size, self.img_size), (0,0,0))\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]\n",
        "        img = self._load_image(r['path'])\n",
        "        if self.mode == 'train':\n",
        "            img = self.tf_train(img)\n",
        "            return img, int(r['label'])\n",
        "        elif self.mode == 'val':\n",
        "            img = self.tf_val(img)\n",
        "            return img, int(r['label'])\n",
        "        else:\n",
        "            img = self.tf_val(img)\n",
        "            return img, str(r['id'])\n",
        "\n",
        "def make_sampler(labels, power=0.5):\n",
        "    vals, counts = np.unique(labels, return_counts=True)\n",
        "    max_label = int(labels.max()) if len(labels)>0 else 0\n",
        "    freq = np.zeros(max_label+1, dtype=np.float64)\n",
        "    freq[vals] = counts\n",
        "    w = 1.0 / np.clip(freq, 1, None)**power\n",
        "    weights = w[labels]\n",
        "    return WeightedRandomSampler(weights=torch.as_tensor(weights, dtype=torch.float32), num_samples=len(labels), replacement=True)\n",
        "\n",
        "def macro_f1_from_logits(logits, y_true):\n",
        "    y_pred = logits.argmax(1)\n",
        "    return f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "def top1_acc_from_logits(logits, y_true):\n",
        "    with torch.no_grad():\n",
        "        pred = logits.argmax(1)\n",
        "        return (pred == y_true).float().mean().item()\n",
        "\n",
        "def make_val_split_min1_train(df, val_frac=0.05, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    by_class = df.groupby('label').indices\n",
        "    val_indices = []\n",
        "    p = val_frac\n",
        "    for lbl, idxs in by_class.items():\n",
        "        idxs = np.array(list(idxs))\n",
        "        n = idxs.size\n",
        "        if n <= 1:\n",
        "            continue\n",
        "        if rng.random() < p:\n",
        "            choice = int(rng.choice(idxs))\n",
        "            val_indices.append(choice)\n",
        "    target_val = int(len(df) * val_frac)\n",
        "    if len(val_indices) < target_val:\n",
        "        need = target_val - len(val_indices)\n",
        "        candidates = []\n",
        "        for lbl, idxs in by_class.items():\n",
        "            idxs = np.array(list(idxs))\n",
        "            if idxs.size >= 3:\n",
        "                candidates.append(int(idxs[0]))\n",
        "        if candidates:\n",
        "            extra = rng.choice(candidates, size=min(need, len(candidates)), replace=False)\n",
        "            val_indices.extend(list(map(int, extra)))\n",
        "    val_set = set(val_indices)\n",
        "    va_idx = np.array([i for i in range(len(df)) if i in val_set], dtype=np.int64)\n",
        "    tr_idx = np.array([i for i in range(len(df)) if i not in val_set], dtype=np.int64)\n",
        "    tr_labels = set(df.iloc[tr_idx]['label'].unique().tolist())\n",
        "    for lbl, idxs in by_class.items():\n",
        "        if lbl not in tr_labels:\n",
        "            idxs = list(idxs)\n",
        "            moved = False\n",
        "            for j in idxs:\n",
        "                if j in val_set:\n",
        "                    val_set.remove(j)\n",
        "                    moved = True\n",
        "                    break\n",
        "            if moved:\n",
        "                tr_labels.add(lbl)\n",
        "    va_idx = np.array(sorted(list(val_set)), dtype=np.int64)\n",
        "    tr_idx = np.array([i for i in range(len(df)) if i not in val_set], dtype=np.int64)\n",
        "    return tr_idx, va_idx\n",
        "\n",
        "def freeze_backbone_unfreeze_head(model):\n",
        "    for n, p in model.named_parameters():\n",
        "        p.requires_grad = ('head' in n)\n",
        "\n",
        "def unfreeze_all(model):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def train_main(\n",
        "    backbone='convnextv2_base',\n",
        "    img_size=384,\n",
        "    batch_size=32,\n",
        "    eff_batch=128,\n",
        "    updates_total=8_000,\n",
        "    warmup_updates=300,\n",
        "    lr_base=3e-4,\n",
        "    weight_decay=0.02,\n",
        "    seed=42,\n",
        "    mixup_alpha=0.2,\n",
        "    cutmix_alpha=0.2,\n",
        "    mix_prob=0.8,\n",
        "    val_frac=0.05,\n",
        "    ckpt_dir='ckpts_main',\n",
        "    head_warmup_updates=600,\n",
        "    lr_head=3e-3\n",
        "):\n",
        "    seed_everything(seed)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "    # Split\n",
        "    tr_idx, va_idx = make_val_split_min1_train(df_train, val_frac=val_frac, seed=seed)\n",
        "    dtr = df_train.iloc[tr_idx].reset_index(drop=True)\n",
        "    dva = df_train.iloc[va_idx].reset_index(drop=True)\n",
        "    print(f'Train/Val sizes: {len(dtr)}/{len(dva)} | classes in train: {dtr.label.nunique()}')\n",
        "\n",
        "    ds_tr = HerbariumDataset(dtr, mode='train', img_size=img_size)\n",
        "    ds_va = HerbariumDataset(dva, mode='val', img_size=img_size)\n",
        "    sampler = make_sampler(dtr['label'].values, power=0.5)\n",
        "    num_workers = 8\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, sampler=sampler, pin_memory=True, num_workers=num_workers, persistent_workers=True, prefetch_factor=2)\n",
        "    dl_va = DataLoader(ds_va, batch_size=max(64, batch_size), shuffle=False, pin_memory=True, num_workers=num_workers, persistent_workers=True, prefetch_factor=2)\n",
        "\n",
        "    model = timm.create_model(backbone, pretrained=True, num_classes=num_classes)\n",
        "    if hasattr(model, 'set_grad_checkpointing'):\n",
        "        try:\n",
        "            model.set_grad_checkpointing(True)\n",
        "        except Exception:\n",
        "            pass\n",
        "    model.to(device)\n",
        "    model.to(memory_format=torch.channels_last)\n",
        "\n",
        "    ema = ModelEmaV2(model, decay=0.999, device=device)\n",
        "\n",
        "    accum_steps = max(1, eff_batch // batch_size)\n",
        "    scaled_lr = lr_base * ((batch_size * accum_steps) / 256.0)\n",
        "\n",
        "    # Optimizers: start with head-only\n",
        "    freeze_backbone_unfreeze_head(model)\n",
        "    head_params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.AdamW(head_params, lr=lr_head, weight_decay=weight_decay)\n",
        "\n",
        "    def cosine_lr(u):\n",
        "        if u < warmup_updates:\n",
        "            return (u + 1) / max(1, warmup_updates)\n",
        "        t = (u - warmup_updates) / max(1, updates_total - warmup_updates)\n",
        "        t = min(1.0, max(0.0, t))\n",
        "        return 0.5 * (1 + math.cos(math.pi * t))\n",
        "\n",
        "    mixup_fn = Mixup(mixup_alpha=mixup_alpha, cutmix_alpha=cutmix_alpha, prob=mix_prob, switch_prob=0.5, mode='batch', label_smoothing=0.1, num_classes=num_classes)\n",
        "    criterion_soft = SoftTargetCrossEntropy()\n",
        "    criterion_hard = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    criterion_val = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
        "\n",
        "    best_f1 = -1.0\n",
        "    best_path = None\n",
        "    micro_step = 0\n",
        "    global_step = 0\n",
        "    running_loss = 0.0\n",
        "    samples_seen = 0\n",
        "    last_train_top1 = 0.0\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.train()\n",
        "    while global_step < updates_total:\n",
        "        for it, (x, y) in enumerate(dl_tr):\n",
        "            if global_step >= updates_total:\n",
        "                break\n",
        "\n",
        "            # Unfreeze and switch optimizer after head warmup\n",
        "            if global_step == head_warmup_updates:\n",
        "                unfreeze_all(model)\n",
        "                optimizer = torch.optim.AdamW(model.parameters(), lr=scaled_lr, weight_decay=weight_decay)\n",
        "\n",
        "                # Reset EMA to keep tracking post-unfreeze weights smoothly\n",
        "                # Note: EMA state continues; no reset of ema needed.\n",
        "\n",
        "            x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "\n",
        "            # LR policy: head phase uses fixed lr_head; after unfreeze use cosine schedule\n",
        "            if global_step >= head_warmup_updates:\n",
        "                cur_lr = scaled_lr * cosine_lr(global_step)\n",
        "                for pg in optimizer.param_groups:\n",
        "                    pg['lr'] = cur_lr\n",
        "            else:\n",
        "                for pg in optimizer.param_groups:\n",
        "                    pg['lr'] = lr_head\n",
        "\n",
        "            # Mixup OFF during head-only phase and during last ~1500 updates\n",
        "            use_mix = (mixup_fn is not None) and (global_step >= head_warmup_updates) and (global_step < max(0, updates_total - 1_500))\n",
        "            if use_mix:\n",
        "                x, y_mix = mixup_fn(x, y)\n",
        "\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                logits = model(x)\n",
        "                loss = criterion_soft(logits, y_mix) if use_mix else criterion_hard(logits, y)\n",
        "\n",
        "            # Train mini-batch top-1 (sanity); compute against hard labels\n",
        "            last_train_top1 = top1_acc_from_logits(logits.detach(), y)\n",
        "\n",
        "            loss = loss / accum_steps\n",
        "            scaler.scale(loss).backward()\n",
        "            micro_step += 1\n",
        "\n",
        "            if (micro_step % accum_steps) == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                ema.update(model)\n",
        "                global_step += 1\n",
        "\n",
        "            running_loss += loss.item() * x.size(0) * accum_steps\n",
        "            samples_seen += x.size(0)\n",
        "\n",
        "            if (micro_step % 200) == 0:\n",
        "                elapsed = time.time() - t0\n",
        "                avg_loss = running_loss / max(1, samples_seen)\n",
        "                cur_lr_print = optimizer.param_groups[0]['lr']\n",
        "                print(f'update {global_step}/{updates_total} | micro {micro_step} | avg_loss {avg_loss:.4f} | lr {cur_lr_print:.2e} | train_top1 {last_train_top1*100:.2f}% | elapsed {elapsed/60:.1f}m', flush=True)\n",
        "\n",
        "            # Validation cadence: every 500 updates until 2k, then every 1k\n",
        "            need_val = False\n",
        "            if global_step > 0 and global_step < 2000 and (global_step % 500 == 0):\n",
        "                need_val = True\n",
        "            elif global_step >= 2000 and (global_step % 1000 == 0):\n",
        "                need_val = True\n",
        "            if need_val or global_step >= updates_total:\n",
        "                val_f1, val_top1, val_loss = evaluate(model, ema, dl_va, device, criterion_val)\n",
        "                is_best = val_f1 > best_f1\n",
        "                best_f1 = max(best_f1, val_f1)\n",
        "                ckpt_path = Path(ckpt_dir)/f'model_upd{global_step}_f1{val_f1:.5f}.pt'\n",
        "                save_checkpoint(model, ema, optimizer, global_step, best_f1, ckpt_path)\n",
        "                if is_best:\n",
        "                    best_path = ckpt_path\n",
        "                print(f'Validation @update {global_step}: macro-F1={val_f1:.5f} | top1={val_top1*100:.2f}% | loss={val_loss:.4f} | best={best_f1:.5f} | saved={ckpt_path.name}', flush=True)\n",
        "\n",
        "    print('Training done. Best ckpt:', best_path)\n",
        "    return dict(best_ckpt=str(best_path) if best_path else None, best_f1=best_f1)\n",
        "\n",
        "def evaluate(model, ema, dl_va, device, criterion_val):\n",
        "    # Use EMA model directly, compute F1, top1, and CE loss\n",
        "    ema_model = ema.module\n",
        "    was_training = ema_model.training\n",
        "    ema_model.eval()\n",
        "    y_preds = []\n",
        "    y_trues = []\n",
        "    running_loss = 0.0\n",
        "    n_items = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dl_va:\n",
        "            x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                logits = ema_model(x)\n",
        "                loss = criterion_val(logits, y)\n",
        "            running_loss += loss.item() * x.size(0)\n",
        "            n_items += x.size(0)\n",
        "            y_preds.append(torch.argmax(logits, dim=1).detach().cpu().numpy())\n",
        "            y_trues.append(y.detach().cpu().numpy())\n",
        "    y_pred = np.concatenate(y_preds) if y_preds else np.array([], dtype=np.int64)\n",
        "    y_true = np.concatenate(y_trues) if y_trues else np.array([], dtype=np.int64)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0) if len(y_true) else 0.0\n",
        "    top1 = (y_pred == y_true).mean() if len(y_true) else 0.0\n",
        "    val_loss = running_loss / max(1, n_items)\n",
        "    if was_training:\n",
        "        ema_model.train()\n",
        "    return float(f1), float(top1), float(val_loss)\n",
        "\n",
        "def save_checkpoint(model, ema, optimizer, step, best_f1, path):\n",
        "    state = {\n",
        "        'model': model.state_dict(),\n",
        "        'ema': ema.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'step': step,\n",
        "        'best_f1': best_f1,\n",
        "    }\n",
        "    torch.save(state, path)\n",
        "\n",
        "print('Launching updates-based training with head-only warmup: convnextv2_base @384 | eff_batch=128 | updates_total=8k ...')\n",
        "train_summary = train_main(\n",
        "    backbone='convnextv2_base',\n",
        "    img_size=384,\n",
        "    batch_size=32,\n",
        "    eff_batch=128,\n",
        "    updates_total=8_000,\n",
        "    warmup_updates=300,\n",
        "    lr_base=3e-4,\n",
        "    weight_decay=0.02,\n",
        "    seed=42,\n",
        "    mixup_alpha=0.2,\n",
        "    cutmix_alpha=0.2,\n",
        "    mix_prob=0.8,\n",
        "    val_frac=0.05,\n",
        "    ckpt_dir='ckpts_main',\n",
        "    head_warmup_updates=600,\n",
        "    lr_head=3e-3\n",
        ")\n",
        "print('Train summary:', train_summary)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rows: 1779953 Num classes: 64500\nLaunching updates-based training with head-only warmup: convnextv2_base @384 | eff_batch=128 | updates_total=8k ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Val sizes: 1726076/53877 | classes in train: 64500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/convnextv2_base.fcmae_ft_in22k_in1k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._hub:[timm/convnextv2_base.fcmae_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._builder:Missing keys (head.fc.weight, head.fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 50/8000 | micro 200 | avg_loss 12.9173 | lr 3.00e-03 | train_top1 0.00% | elapsed 0.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 100/8000 | micro 400 | avg_loss 12.4533 | lr 3.00e-03 | train_top1 6.25% | elapsed 1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 150/8000 | micro 600 | avg_loss 12.0611 | lr 3.00e-03 | train_top1 0.00% | elapsed 2.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 200/8000 | micro 800 | avg_loss 11.7077 | lr 3.00e-03 | train_top1 0.00% | elapsed 3.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 250/8000 | micro 1000 | avg_loss 11.4349 | lr 3.00e-03 | train_top1 6.25% | elapsed 4.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 300/8000 | micro 1200 | avg_loss 11.2187 | lr 3.00e-03 | train_top1 0.00% | elapsed 4.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 350/8000 | micro 1400 | avg_loss 11.0438 | lr 3.00e-03 | train_top1 0.00% | elapsed 5.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 400/8000 | micro 1600 | avg_loss 10.8962 | lr 3.00e-03 | train_top1 3.12% | elapsed 6.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 450/8000 | micro 1800 | avg_loss 10.7662 | lr 3.00e-03 | train_top1 3.12% | elapsed 7.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 500/8000 | micro 2000 | avg_loss 10.6565 | lr 3.00e-03 | train_top1 3.12% | elapsed 8.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 500: macro-F1=0.00132 | top1=0.48% | loss=10.9631 | best=0.00132 | saved=model_upd500_f10.00132.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 500: macro-F1=0.00132 | top1=0.48% | loss=10.9631 | best=0.00132 | saved=model_upd500_f10.00132.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 500: macro-F1=0.00132 | top1=0.48% | loss=10.9631 | best=0.00132 | saved=model_upd500_f10.00132.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 500: macro-F1=0.00132 | top1=0.48% | loss=10.9631 | best=0.00132 | saved=model_upd500_f10.00132.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 550/8000 | micro 2200 | avg_loss 10.5535 | lr 3.00e-03 | train_top1 0.00% | elapsed 35.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 600/8000 | micro 2400 | avg_loss 10.4588 | lr 3.00e-03 | train_top1 9.38% | elapsed 36.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 650/8000 | micro 2600 | avg_loss 10.3896 | lr 1.49e-04 | train_top1 6.25% | elapsed 39.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 700/8000 | micro 2800 | avg_loss 10.3086 | lr 1.49e-04 | train_top1 0.00% | elapsed 43.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 750/8000 | micro 3000 | avg_loss 10.2387 | lr 1.49e-04 | train_top1 0.00% | elapsed 47.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 800/8000 | micro 3200 | avg_loss 10.1705 | lr 1.48e-04 | train_top1 0.00% | elapsed 51.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 850/8000 | micro 3400 | avg_loss 10.1133 | lr 1.48e-04 | train_top1 9.38% | elapsed 54.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 900/8000 | micro 3600 | avg_loss 10.0528 | lr 1.48e-04 | train_top1 3.12% | elapsed 58.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 950/8000 | micro 3800 | avg_loss 10.0004 | lr 1.47e-04 | train_top1 0.00% | elapsed 62.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1000/8000 | micro 4000 | avg_loss 9.9518 | lr 1.47e-04 | train_top1 6.25% | elapsed 65.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 1000: macro-F1=0.00612 | top1=1.66% | loss=10.1875 | best=0.00612 | saved=model_upd1000_f10.00612.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 1000: macro-F1=0.00612 | top1=1.66% | loss=10.1875 | best=0.00612 | saved=model_upd1000_f10.00612.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 1000: macro-F1=0.00612 | top1=1.66% | loss=10.1875 | best=0.00612 | saved=model_upd1000_f10.00612.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 1000: macro-F1=0.00612 | top1=1.66% | loss=10.1875 | best=0.00612 | saved=model_upd1000_f10.00612.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1050/8000 | micro 4200 | avg_loss 9.9080 | lr 1.47e-04 | train_top1 9.38% | elapsed 96.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1100/8000 | micro 4400 | avg_loss 9.8630 | lr 1.46e-04 | train_top1 0.00% | elapsed 99.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1150/8000 | micro 4600 | avg_loss 9.8216 | lr 1.46e-04 | train_top1 12.50% | elapsed 103.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1200/8000 | micro 4800 | avg_loss 9.7828 | lr 1.45e-04 | train_top1 9.38% | elapsed 107.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1250/8000 | micro 5000 | avg_loss 9.7440 | lr 1.44e-04 | train_top1 3.12% | elapsed 111.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1300/8000 | micro 5200 | avg_loss 9.7068 | lr 1.44e-04 | train_top1 15.62% | elapsed 114.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1350/8000 | micro 5400 | avg_loss 9.6664 | lr 1.43e-04 | train_top1 9.38% | elapsed 118.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1400/8000 | micro 5600 | avg_loss 9.6344 | lr 1.43e-04 | train_top1 9.38% | elapsed 122.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1450/8000 | micro 5800 | avg_loss 9.5995 | lr 1.42e-04 | train_top1 0.00% | elapsed 125.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1500/8000 | micro 6000 | avg_loss 9.5683 | lr 1.41e-04 | train_top1 0.00% | elapsed 129.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 1500: macro-F1=0.01169 | top1=3.04% | loss=9.5558 | best=0.01169 | saved=model_upd1500_f10.01169.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 1500: macro-F1=0.01169 | top1=3.04% | loss=9.5558 | best=0.01169 | saved=model_upd1500_f10.01169.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 1500: macro-F1=0.01169 | top1=3.04% | loss=9.5558 | best=0.01169 | saved=model_upd1500_f10.01169.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 1500: macro-F1=0.01169 | top1=3.04% | loss=9.5558 | best=0.01169 | saved=model_upd1500_f10.01169.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1550/8000 | micro 6200 | avg_loss 9.5353 | lr 1.40e-04 | train_top1 18.75% | elapsed 159.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1600/8000 | micro 6400 | avg_loss 9.5044 | lr 1.40e-04 | train_top1 0.00% | elapsed 163.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1650/8000 | micro 6600 | avg_loss 9.4724 | lr 1.39e-04 | train_top1 15.62% | elapsed 167.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1700/8000 | micro 6800 | avg_loss 9.4426 | lr 1.38e-04 | train_top1 0.00% | elapsed 170.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1750/8000 | micro 7000 | avg_loss 9.4134 | lr 1.37e-04 | train_top1 6.25% | elapsed 174.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1800/8000 | micro 7200 | avg_loss 9.3826 | lr 1.36e-04 | train_top1 0.00% | elapsed 178.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1850/8000 | micro 7400 | avg_loss 9.3544 | lr 1.36e-04 | train_top1 18.75% | elapsed 182.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1900/8000 | micro 7600 | avg_loss 9.3272 | lr 1.35e-04 | train_top1 9.38% | elapsed 185.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 1950/8000 | micro 7800 | avg_loss 9.2960 | lr 1.34e-04 | train_top1 0.00% | elapsed 189.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2000/8000 | micro 8000 | avg_loss 9.2693 | lr 1.33e-04 | train_top1 9.38% | elapsed 193.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 2000: macro-F1=0.01775 | top1=4.53% | loss=9.1338 | best=0.01775 | saved=model_upd2000_f10.01775.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 2000: macro-F1=0.01775 | top1=4.53% | loss=9.1338 | best=0.01775 | saved=model_upd2000_f10.01775.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 2000: macro-F1=0.01775 | top1=4.53% | loss=9.1338 | best=0.01775 | saved=model_upd2000_f10.01775.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 2000: macro-F1=0.01775 | top1=4.53% | loss=9.1338 | best=0.01775 | saved=model_upd2000_f10.01775.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2050/8000 | micro 8200 | avg_loss 9.2415 | lr 1.32e-04 | train_top1 3.12% | elapsed 223.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2100/8000 | micro 8400 | avg_loss 9.2144 | lr 1.31e-04 | train_top1 12.50% | elapsed 227.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2150/8000 | micro 8600 | avg_loss 9.1859 | lr 1.30e-04 | train_top1 15.62% | elapsed 230.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2200/8000 | micro 8800 | avg_loss 9.1601 | lr 1.29e-04 | train_top1 0.00% | elapsed 234.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2250/8000 | micro 9000 | avg_loss 9.1343 | lr 1.28e-04 | train_top1 15.62% | elapsed 238.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2300/8000 | micro 9200 | avg_loss 9.1094 | lr 1.26e-04 | train_top1 0.00% | elapsed 241.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2350/8000 | micro 9400 | avg_loss 9.0836 | lr 1.25e-04 | train_top1 25.00% | elapsed 245.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2400/8000 | micro 9600 | avg_loss 9.0590 | lr 1.24e-04 | train_top1 18.75% | elapsed 249.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2450/8000 | micro 9800 | avg_loss 9.0342 | lr 1.23e-04 | train_top1 25.00% | elapsed 252.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2500/8000 | micro 10000 | avg_loss 9.0075 | lr 1.22e-04 | train_top1 12.50% | elapsed 256.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2550/8000 | micro 10200 | avg_loss 8.9843 | lr 1.21e-04 | train_top1 6.25% | elapsed 260.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2600/8000 | micro 10400 | avg_loss 8.9610 | lr 1.19e-04 | train_top1 21.88% | elapsed 264.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2650/8000 | micro 10600 | avg_loss 8.9359 | lr 1.18e-04 | train_top1 15.62% | elapsed 267.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2700/8000 | micro 10800 | avg_loss 8.9130 | lr 1.17e-04 | train_top1 15.62% | elapsed 271.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2750/8000 | micro 11000 | avg_loss 8.8886 | lr 1.16e-04 | train_top1 3.12% | elapsed 275.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2800/8000 | micro 11200 | avg_loss 8.8640 | lr 1.14e-04 | train_top1 12.50% | elapsed 278.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2850/8000 | micro 11400 | avg_loss 8.8406 | lr 1.13e-04 | train_top1 18.75% | elapsed 282.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2900/8000 | micro 11600 | avg_loss 8.8161 | lr 1.12e-04 | train_top1 0.00% | elapsed 286.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 2950/8000 | micro 11800 | avg_loss 8.7916 | lr 1.10e-04 | train_top1 12.50% | elapsed 289.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3000/8000 | micro 12000 | avg_loss 8.7681 | lr 1.09e-04 | train_top1 3.12% | elapsed 293.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 3000: macro-F1=0.03439 | top1=7.88% | loss=8.4459 | best=0.03439 | saved=model_upd3000_f10.03439.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 3000: macro-F1=0.03439 | top1=7.88% | loss=8.4459 | best=0.03439 | saved=model_upd3000_f10.03439.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 3000: macro-F1=0.03439 | top1=7.88% | loss=8.4459 | best=0.03439 | saved=model_upd3000_f10.03439.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 3000: macro-F1=0.03439 | top1=7.88% | loss=8.4459 | best=0.03439 | saved=model_upd3000_f10.03439.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3050/8000 | micro 12200 | avg_loss 8.7439 | lr 1.08e-04 | train_top1 21.88% | elapsed 323.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3100/8000 | micro 12400 | avg_loss 8.7223 | lr 1.06e-04 | train_top1 9.38% | elapsed 327.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3150/8000 | micro 12600 | avg_loss 8.6994 | lr 1.05e-04 | train_top1 34.38% | elapsed 331.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3200/8000 | micro 12800 | avg_loss 8.6766 | lr 1.03e-04 | train_top1 25.00% | elapsed 335.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3250/8000 | micro 13000 | avg_loss 8.6538 | lr 1.02e-04 | train_top1 0.00% | elapsed 338.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3300/8000 | micro 13200 | avg_loss 8.6331 | lr 1.01e-04 | train_top1 0.00% | elapsed 342.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3350/8000 | micro 13400 | avg_loss 8.6123 | lr 9.91e-05 | train_top1 18.75% | elapsed 346.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3400/8000 | micro 13600 | avg_loss 8.5919 | lr 9.76e-05 | train_top1 21.88% | elapsed 349.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3450/8000 | micro 13800 | avg_loss 8.5698 | lr 9.62e-05 | train_top1 12.50% | elapsed 353.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3500/8000 | micro 14000 | avg_loss 8.5483 | lr 9.47e-05 | train_top1 0.00% | elapsed 357.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3550/8000 | micro 14200 | avg_loss 8.5275 | lr 9.32e-05 | train_top1 25.00% | elapsed 360.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3600/8000 | micro 14400 | avg_loss 8.5062 | lr 9.17e-05 | train_top1 34.38% | elapsed 364.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3650/8000 | micro 14600 | avg_loss 8.4857 | lr 9.02e-05 | train_top1 21.88% | elapsed 368.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3700/8000 | micro 14800 | avg_loss 8.4632 | lr 8.87e-05 | train_top1 18.75% | elapsed 372.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3750/8000 | micro 15000 | avg_loss 8.4435 | lr 8.72e-05 | train_top1 12.50% | elapsed 375.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3800/8000 | micro 15200 | avg_loss 8.4226 | lr 8.57e-05 | train_top1 25.00% | elapsed 379.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3850/8000 | micro 15400 | avg_loss 8.4015 | lr 8.42e-05 | train_top1 21.88% | elapsed 383.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3900/8000 | micro 15600 | avg_loss 8.3813 | lr 8.27e-05 | train_top1 25.00% | elapsed 386.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 3950/8000 | micro 15800 | avg_loss 8.3615 | lr 8.11e-05 | train_top1 25.00% | elapsed 390.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4000/8000 | micro 16000 | avg_loss 8.3425 | lr 7.96e-05 | train_top1 31.25% | elapsed 394.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 4000: macro-F1=0.05524 | top1=11.27% | loss=7.7639 | best=0.05524 | saved=model_upd4000_f10.05524.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 4000: macro-F1=0.05524 | top1=11.27% | loss=7.7639 | best=0.05524 | saved=model_upd4000_f10.05524.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 4000: macro-F1=0.05524 | top1=11.27% | loss=7.7639 | best=0.05524 | saved=model_upd4000_f10.05524.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 4000: macro-F1=0.05524 | top1=11.27% | loss=7.7639 | best=0.05524 | saved=model_upd4000_f10.05524.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4050/8000 | micro 16200 | avg_loss 8.3230 | lr 7.81e-05 | train_top1 37.50% | elapsed 424.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4100/8000 | micro 16400 | avg_loss 8.3037 | lr 7.66e-05 | train_top1 25.00% | elapsed 428.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4150/8000 | micro 16600 | avg_loss 8.2855 | lr 7.50e-05 | train_top1 3.12% | elapsed 431.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4200/8000 | micro 16800 | avg_loss 8.2684 | lr 7.35e-05 | train_top1 18.75% | elapsed 435.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4250/8000 | micro 17000 | avg_loss 8.2495 | lr 7.20e-05 | train_top1 0.00% | elapsed 439.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4300/8000 | micro 17200 | avg_loss 8.2306 | lr 7.04e-05 | train_top1 0.00% | elapsed 443.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4350/8000 | micro 17400 | avg_loss 8.2130 | lr 6.89e-05 | train_top1 0.00% | elapsed 446.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4400/8000 | micro 17600 | avg_loss 8.1958 | lr 6.74e-05 | train_top1 18.75% | elapsed 450.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4450/8000 | micro 17800 | avg_loss 8.1775 | lr 6.59e-05 | train_top1 18.75% | elapsed 454.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4500/8000 | micro 18000 | avg_loss 8.1590 | lr 6.44e-05 | train_top1 12.50% | elapsed 457.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4550/8000 | micro 18200 | avg_loss 8.1409 | lr 6.28e-05 | train_top1 0.00% | elapsed 461.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4600/8000 | micro 18400 | avg_loss 8.1236 | lr 6.13e-05 | train_top1 0.00% | elapsed 465.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4650/8000 | micro 18600 | avg_loss 8.1042 | lr 5.98e-05 | train_top1 0.00% | elapsed 468.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4700/8000 | micro 18800 | avg_loss 8.0856 | lr 5.83e-05 | train_top1 43.75% | elapsed 472.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4750/8000 | micro 19000 | avg_loss 8.0685 | lr 5.69e-05 | train_top1 40.62% | elapsed 476.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4800/8000 | micro 19200 | avg_loss 8.0518 | lr 5.54e-05 | train_top1 18.75% | elapsed 480.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4850/8000 | micro 19400 | avg_loss 8.0347 | lr 5.39e-05 | train_top1 31.25% | elapsed 483.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4900/8000 | micro 19600 | avg_loss 8.0169 | lr 5.24e-05 | train_top1 31.25% | elapsed 487.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 4950/8000 | micro 19800 | avg_loss 7.9999 | lr 5.10e-05 | train_top1 6.25% | elapsed 491.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5000/8000 | micro 20000 | avg_loss 7.9832 | lr 4.95e-05 | train_top1 0.00% | elapsed 494.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 5000: macro-F1=0.07740 | top1=14.51% | loss=7.1650 | best=0.07740 | saved=model_upd5000_f10.07740.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 5000: macro-F1=0.07740 | top1=14.51% | loss=7.1650 | best=0.07740 | saved=model_upd5000_f10.07740.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "id": "6420b3dc-f849-4f8a-9514-5c50ff43197d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference with optional 2x TTA (orig + hflip) and dual-tau outputs; adds optional per-F0 masking and per-F0 prior adjustment\n",
        "import os, re, math, time, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms.functional as TF\n",
        "import timm\n",
        "\n",
        "def find_best_ckpt(ckpt_dir='ckpts_main'):\n",
        "    ckpt_dir = Path(ckpt_dir)\n",
        "    files = sorted(ckpt_dir.glob('model_upd*_f1*.pt'))\n",
        "    if not files:\n",
        "        print('No checkpoints found in', ckpt_dir)\n",
        "        return None\n",
        "    def parse_f1(p):\n",
        "        m = re.search(r'_f1([0-9]+\\.[0-9]+)\\.pt$', p.name)\n",
        "        return float(m.group(1)) if m else -1.0\n",
        "    files = sorted(files, key=parse_f1, reverse=True)\n",
        "    best = files[0]\n",
        "    print('Selected best ckpt by filename f1:', best.name)\n",
        "    return best\n",
        "\n",
        "def load_model_from_ckpt(ckpt_path, backbone='convnextv2_base', num_classes=64500, device='cuda'):\n",
        "    model = timm.create_model(backbone, pretrained=False, num_classes=num_classes)\n",
        "    state = torch.load(ckpt_path, map_location='cpu')\n",
        "    # Load base model weights first (non-strict to allow head adaptation)\n",
        "    model.load_state_dict(state.get('model', {}), strict=False)\n",
        "    # If EMA is present, load EMA and then copy its weights into the model\n",
        "    try:\n",
        "        if 'ema' in state:\n",
        "            from timm.utils import ModelEmaV2\n",
        "            ema = ModelEmaV2(model, decay=0.999)\n",
        "            ema.load_state_dict(state['ema'], strict=False)\n",
        "            model.load_state_dict(ema.module.state_dict(), strict=True)\n",
        "            print('Loaded EMA weights into model')\n",
        "    except Exception as e:\n",
        "        print('EMA load skipped:', e)\n",
        "    model.to(device)\n",
        "    model.to(memory_format=torch.channels_last)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def class_log_prior(labels, num_classes):\n",
        "    counts = np.bincount(labels.astype(int), minlength=num_classes).astype(np.float64)\n",
        "    return np.log(counts + 1.0)\n",
        "\n",
        "def build_f0_maps(df_train, num_classes):\n",
        "    # Parse F0 from file_name\n",
        "    def parse_f0(s):\n",
        "        parts = str(s).split('/')\n",
        "        return parts[1] if len(parts) > 1 else ''\n",
        "    f0 = df_train['file_name'].map(parse_f0)\n",
        "    labels = df_train['label'].astype(int).values\n",
        "    df_tmp = pd.DataFrame({'f0': f0, 'label': labels})\n",
        "    # Per-F0 allowed classes\n",
        "    mask_f0 = {}  # f0 -> (num_classes,) tensor with 0 for allowed and -inf for disallowed\n",
        "    prior_f0 = {} # f0 -> (num_classes,) tensor of log prior\n",
        "    for key, g in df_tmp.groupby('f0', sort=False):\n",
        "        counts = np.bincount(g['label'].values, minlength=num_classes).astype(np.float64)\n",
        "        allowed = (counts > 0).astype(np.float32)\n",
        "        m = torch.full((num_classes,), -1e9, dtype=torch.float32)\n",
        "        m[torch.from_numpy(allowed.astype(bool))] = 0.0\n",
        "        mask_f0[key] = m\n",
        "        prior = np.log(counts + 1.0)\n",
        "        prior_f0[key] = torch.from_numpy(prior.astype(np.float32))\n",
        "    return mask_f0, prior_f0\n",
        "\n",
        "def tta2_logits(model, x):\n",
        "    # 2x TTA: original + horizontal flip\n",
        "    logits_list = []\n",
        "    logits_list.append(model(x))\n",
        "    logits_list.append(model(torch.flip(x, dims=[3])))\n",
        "    return sum(logits_list) / len(logits_list)\n",
        "\n",
        "def infer_test(\n",
        "    df_test, idx2cid,\n",
        "    backbone='convnextv2_base', img_size=384, batch_size=128, num_workers=6, ckpt_dir='ckpts_main',\n",
        "    use_tta=False, tau_list=(None, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8), out_prefix='submission_cnn',\n",
        "    use_f0_mask=False, use_per_f0_prior=False\n",
        "):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    ckpt = find_best_ckpt(ckpt_dir)\n",
        "    assert ckpt is not None, 'No checkpoint to load'\n",
        "    num_classes = len(idx2cid)\n",
        "    model = load_model_from_ckpt(ckpt, backbone=backbone, num_classes=num_classes, device=device)\n",
        "\n",
        "    # Optional F0 maps\n",
        "    mask_f0 = None\n",
        "    prior_f0 = None\n",
        "    if use_f0_mask or use_per_f0_prior:\n",
        "        mask_f0, prior_f0 = build_f0_maps(df_train, num_classes)\n",
        "\n",
        "    # id -> f0 map from df_test\n",
        "    def parse_f0_from_path(s):\n",
        "        parts = str(s).split('/')\n",
        "        return parts[1] if len(parts) > 1 else ''\n",
        "    id2f0 = dict(zip(df_test['id'].astype(str), df_test['file_name'].map(parse_f0_from_path)))\n",
        "\n",
        "    ds = HerbariumDataset(df_test, mode='test', img_size=img_size)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=False, prefetch_factor=2)\n",
        "\n",
        "    # Global adjustment once (fallback when not per-F0)\n",
        "    base_adj_global = class_log_prior(df_train['label'].values, num_classes)\n",
        "    base_adj_global = torch.from_numpy(base_adj_global).to(device=device, dtype=torch.float32)\n",
        "\n",
        "    id_list = []\n",
        "    pred_buffers = {tau: [] for tau in tau_list}\n",
        "\n",
        "    t0 = time.time()\n",
        "    with torch.no_grad():\n",
        "        for bi, (x, ids) in enumerate(dl):\n",
        "            x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                logits = tta2_logits(model, x) if use_tta else model(x)\n",
        "            # Per-sample F0 mask/prior stacks if enabled\n",
        "            if use_f0_mask or use_per_f0_prior:\n",
        "                f0_list = [id2f0.get(str(i), '') for i in ids]\n",
        "            # Apply F0 mask (add large negative to disallowed classes)\n",
        "            if use_f0_mask:\n",
        "                m_list = [mask_f0.get(f0, None) for f0 in f0_list]\n",
        "                m_stack = torch.stack([m if m is not None else torch.zeros(num_classes, dtype=torch.float32) for m in m_list], dim=0).to(device)\n",
        "                logits = logits + m_stack\n",
        "            # For each tau, adjust and argmax\n",
        "            for tau in tau_list:\n",
        "                if tau is None:\n",
        "                    logits_adj = logits\n",
        "                else:\n",
        "                    if use_per_f0_prior:\n",
        "                        adj_list = [prior_f0.get(f0, base_adj_global.cpu()).to(device) for f0 in (f0_list if (use_f0_mask or use_per_f0_prior) else [])]\n",
        "                        if adj_list:\n",
        "                            adj_stack = torch.stack(adj_list, dim=0).to(device)\n",
        "                            logits_adj = logits - float(tau) * adj_stack\n",
        "                        else:\n",
        "                            logits_adj = logits - float(tau) * base_adj_global[None, :]\n",
        "                    else:\n",
        "                        logits_adj = logits - float(tau) * base_adj_global[None, :]\n",
        "                pred_idx = torch.argmax(logits_adj, dim=1).detach().cpu().numpy()\n",
        "                pred_buffers[tau].append(pred_idx)\n",
        "            id_list.extend(list(ids))\n",
        "            if (bi+1) % 50 == 0:\n",
        "                print(f'Infer batch {bi+1}/{len(dl)} | elapsed {(time.time()-t0)/60:.1f}m', flush=True)\n",
        "\n",
        "    outs = {}\n",
        "    for tau in tau_list:\n",
        "        pred_idx = np.concatenate(pred_buffers[tau]) if pred_buffers[tau] else np.array([], dtype=np.int64)\n",
        "        pred_cids = idx2cid[pred_idx] if len(pred_idx)>0 else np.array([], dtype=np.int64)\n",
        "        sub = pd.read_csv('sample_submission.csv')\n",
        "        id2pred = dict(zip(id_list, pred_cids.tolist()))\n",
        "        default_fill = int(sub['Predicted'].mode().iloc[0]) if 'Predicted' in sub.columns else 0\n",
        "        sub['Predicted'] = sub['Id'].astype(str).map(id2pred).fillna(default_fill).astype(int)\n",
        "        suffix = 'tauNone' if tau is None else 'tau' + str(tau).replace('.', '_')\n",
        "        out_path = f'{out_prefix}_{suffix}.csv'\n",
        "        sub.to_csv(out_path, index=False)\n",
        "        print('Wrote', out_path, 'rows:', len(sub))\n",
        "        outs[tau] = out_path\n",
        "    return outs\n",
        "\n",
        "print('Inference ready. Fast safety (no TTA, dual tau):')\n",
        "print(\"infer_test(df_test, idx2cid, backbone='convnextv2_base', img_size=384, batch_size=128, num_workers=6, ckpt_dir='ckpts_main', use_tta=False, tau_list=(None,0.5), out_prefix='submission_cnn', use_f0_mask=False, use_per_f0_prior=False)\")\n",
        "print('For stronger run later, set use_tta=True (2x), use_per_f0_prior=True, and sweep tau in (None,0.2..0.8). Ensure you see: Loaded EMA weights into model.')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference ready. Fast safety (no TTA, dual tau):\ninfer_test(df_test, idx2cid, backbone='convnextv2_base', img_size=384, batch_size=128, num_workers=6, ckpt_dir='ckpts_main', use_tta=False, tau_list=(None,0.5), out_prefix='submission_cnn', use_f0_mask=False, use_per_f0_prior=False)\nFor stronger run later, set use_tta=True (2x), use_per_f0_prior=True, and sweep tau in (None,0.2..0.8). Ensure you see: Loaded EMA weights into model.\n"
          ]
        }
      ]
    },
    {
      "id": "dea4cde2-4b8f-4f52-801e-4f1a18a28f09",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Resume-capable training utilities (non-executing until called). Safe to add while main cell runs.\n",
        "import os, math, time, json, random, numpy as np, torch, torch.nn as nn\n",
        "from pathlib import Path\n",
        "\n",
        "def load_resume_state(resume_path, model, ema, optimizer):\n",
        "    start_step, best_f1 = 0, -1.0\n",
        "    if resume_path is None or not os.path.exists(str(resume_path)):\n",
        "        return start_step, best_f1, optimizer\n",
        "    state = torch.load(resume_path, map_location='cpu')\n",
        "    # Load model and EMA regardless of optimizer issues\n",
        "    model.load_state_dict(state.get('model', {}), strict=False)\n",
        "    if state.get('ema', None) is not None:\n",
        "        try:\n",
        "            ema.load_state_dict(state['ema'], strict=False)\n",
        "        except Exception as e:\n",
        "            print('EMA resume load skipped:', e)\n",
        "    # Set resume metadata first\n",
        "    start_step = int(state.get('step', 0))\n",
        "    best_f1 = float(state.get('best_f1', -1.0))\n",
        "    # Try optimizer resume; if it fails, keep training without it (do NOT reset step/best_f1)\n",
        "    if 'optimizer' in state and optimizer is not None:\n",
        "        try:\n",
        "            optimizer.load_state_dict(state['optimizer'])\n",
        "        except Exception as e:\n",
        "            print('Optimizer state load failed; continuing without optimizer state:', e)\n",
        "    print(f'Resumed from {resume_path} at step {start_step}, best_f1={best_f1:.5f}')\n",
        "    return start_step, best_f1, optimizer\n",
        "\n",
        "def train_main(\n",
        "    backbone='convnextv2_base',\n",
        "    img_size=384,\n",
        "    batch_size=32,\n",
        "    eff_batch=128,\n",
        "    updates_total=8_000,\n",
        "    warmup_updates=300,\n",
        "    lr_base=3e-4,\n",
        "    weight_decay=0.02,\n",
        "    seed=42,\n",
        "    mixup_alpha=0.2,\n",
        "    cutmix_alpha=0.2,\n",
        "    mix_prob=0.8,\n",
        "    val_frac=0.05,\n",
        "    ckpt_dir='ckpts_main',\n",
        "    head_warmup_updates=600,\n",
        "    lr_head=3e-3,\n",
        "    resume_path=None\n",
        "):\n",
        "    # Reuse objects from earlier cells: df_train, HerbariumDataset, make_sampler, top1_acc_from_logits, evaluate, save_checkpoint, seed_everything\n",
        "    seed_everything(seed)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "    tr_idx, va_idx = make_val_split_min1_train(df_train, val_frac=val_frac, seed=seed)\n",
        "    dtr = df_train.iloc[tr_idx].reset_index(drop=True)\n",
        "    dva = df_train.iloc[va_idx].reset_index(drop=True)\n",
        "    print(f'Train/Val sizes: {len(dtr)}/{len(dva)} | classes in train: {dtr.label.nunique()}')\n",
        "\n",
        "    ds_tr = HerbariumDataset(dtr, mode='train', img_size=img_size)\n",
        "    ds_va = HerbariumDataset(dva, mode='val', img_size=img_size)\n",
        "    sampler = make_sampler(dtr['label'].values, power=0.5)\n",
        "    num_workers = 8\n",
        "    dl_tr = torch.utils.data.DataLoader(ds_tr, batch_size=batch_size, sampler=sampler, pin_memory=True, num_workers=num_workers, persistent_workers=True, prefetch_factor=2)\n",
        "    dl_va = torch.utils.data.DataLoader(ds_va, batch_size=max(64, batch_size), shuffle=False, pin_memory=True, num_workers=num_workers, persistent_workers=True, prefetch_factor=2)\n",
        "\n",
        "    model = timm.create_model(backbone, pretrained=True, num_classes=len(idx2cid))\n",
        "    if hasattr(model, 'set_grad_checkpointing'):\n",
        "        try: model.set_grad_checkpointing(True)\n",
        "        except Exception: pass\n",
        "    model.to(device)\n",
        "    model.to(memory_format=torch.channels_last)\n",
        "\n",
        "    ema = ModelEmaV2(model, decay=0.999, device=device)\n",
        "\n",
        "    accum_steps = max(1, eff_batch // batch_size)\n",
        "    scaled_lr = lr_base * ((batch_size * accum_steps) / 256.0)\n",
        "\n",
        "    # Phase-aware optimizer init\n",
        "    def freeze_backbone_unfreeze_head(m):\n",
        "        for n, p in m.named_parameters():\n",
        "            p.requires_grad = ('head' in n)\n",
        "    def unfreeze_all(m):\n",
        "        for p in m.parameters():\n",
        "            p.requires_grad = True\n",
        "\n",
        "    optimizer = None\n",
        "    start_step = 0\n",
        "    best_f1 = -1.0\n",
        "\n",
        "    # Tentatively start in head-only mode; may be replaced after resume load\n",
        "    freeze_backbone_unfreeze_head(model)\n",
        "    head_params = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.AdamW(head_params, lr=lr_head, weight_decay=weight_decay)\n",
        "\n",
        "    # Try to resume\n",
        "    start_step, best_f1, optimizer = load_resume_state(resume_path, model, ema, optimizer)\n",
        "\n",
        "    # If we've passed warmup, switch to full optimizer\n",
        "    if start_step >= head_warmup_updates:\n",
        "        unfreeze_all(model)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=scaled_lr, weight_decay=weight_decay)\n",
        "\n",
        "    def cosine_lr(u):\n",
        "        if u < warmup_updates:\n",
        "            return (u + 1) / max(1, warmup_updates)\n",
        "        t = (u - warmup_updates) / max(1, updates_total - warmup_updates)\n",
        "        t = min(1.0, max(0.0, t))\n",
        "        return 0.5 * (1 + math.cos(math.pi * t))\n",
        "\n",
        "    mixup_fn = Mixup(mixup_alpha=mixup_alpha, cutmix_alpha=cutmix_alpha, prob=mix_prob, switch_prob=0.5, mode='batch', label_smoothing=0.1, num_classes=len(idx2cid))\n",
        "    criterion_soft = SoftTargetCrossEntropy()\n",
        "    criterion_hard = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    criterion_val = nn.CrossEntropyLoss(reduction='mean')\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
        "\n",
        "    best_path = None\n",
        "    micro_step = start_step * accum_steps\n",
        "    global_step = start_step\n",
        "    running_loss = 0.0\n",
        "    samples_seen = 0\n",
        "    last_train_top1 = 0.0\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.train()\n",
        "    while global_step < updates_total:\n",
        "        for it, (x, y) in enumerate(dl_tr):\n",
        "            if global_step >= updates_total:\n",
        "                break\n",
        "\n",
        "            if (global_step == head_warmup_updates) and any(not p.requires_grad for p in model.parameters()):\n",
        "                unfreeze_all(model)\n",
        "                optimizer = torch.optim.AdamW(model.parameters(), lr=scaled_lr, weight_decay=weight_decay)\n",
        "\n",
        "            x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "\n",
        "            if global_step >= head_warmup_updates:\n",
        "                cur_lr = scaled_lr * cosine_lr(global_step)\n",
        "                for pg in optimizer.param_groups: pg['lr'] = cur_lr\n",
        "            else:\n",
        "                for pg in optimizer.param_groups: pg['lr'] = lr_head\n",
        "\n",
        "            use_mix = (mixup_fn is not None) and (global_step >= head_warmup_updates) and (global_step < max(0, updates_total - 1500))\n",
        "            if use_mix:\n",
        "                x, y_mix = mixup_fn(x, y)\n",
        "\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                logits = model(x)\n",
        "                loss = criterion_soft(logits, y_mix) if use_mix else criterion_hard(logits, y)\n",
        "\n",
        "            last_train_top1 = top1_acc_from_logits(logits.detach(), y)\n",
        "            loss = loss / accum_steps\n",
        "            scaler.scale(loss).backward()\n",
        "            micro_step += 1\n",
        "\n",
        "            if (micro_step % accum_steps) == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                ema.update(model)\n",
        "                global_step += 1\n",
        "\n",
        "            running_loss += loss.item() * x.size(0) * accum_steps\n",
        "            samples_seen += x.size(0)\n",
        "\n",
        "            if (micro_step % 200) == 0:\n",
        "                elapsed = time.time() - t0\n",
        "                avg_loss = running_loss / max(1, samples_seen)\n",
        "                cur_lr_print = optimizer.param_groups[0]['lr']\n",
        "                print(f'update {global_step}/{updates_total} | micro {micro_step} | avg_loss {avg_loss:.4f} | lr {cur_lr_print:.2e} | train_top1 {last_train_top1*100:.2f}% | elapsed {elapsed/60:.1f}m', flush=True)\n",
        "\n",
        "            need_val = False\n",
        "            if global_step > 0 and global_step < 2000 and (global_step % 500 == 0):\n",
        "                need_val = True\n",
        "            elif global_step >= 2000 and (global_step % 1000 == 0):\n",
        "                need_val = True\n",
        "            if need_val or global_step >= updates_total:\n",
        "                val_f1, val_top1, val_loss = evaluate(model, ema, dl_va, device, criterion_val)\n",
        "                is_best = val_f1 > best_f1\n",
        "                best_f1 = max(best_f1, val_f1)\n",
        "                ckpt_path = Path(ckpt_dir)/f'model_upd{global_step}_f1{val_f1:.5f}.pt'\n",
        "                save_checkpoint(model, ema, optimizer, global_step, best_f1, ckpt_path)\n",
        "                if is_best:\n",
        "                    best_path = ckpt_path\n",
        "                print(f'Validation @update {global_step}: macro-F1={val_f1:.5f} | top1={val_top1*100:.2f}% | loss={val_loss:.4f} | best={best_f1:.5f} | saved={ckpt_path.name}', flush=True)\n",
        "\n",
        "    print('Training done. Best ckpt:', best_path)\n",
        "    return dict(best_ckpt=str(best_path) if best_path else None, best_f1=best_f1)\n",
        "\n",
        "print('Resume-capable train_main(resume_path=...) defined. Use after pausing to safely resume from a saved ckpt.')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resume-capable train_main(resume_path=...) defined. Use after pausing to safely resume from a saved ckpt.\n"
          ]
        }
      ]
    },
    {
      "id": "dd6476f1-5302-4d08-a3f4-d977a76c686a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Safety submission inference: no TTA, dual tau\n",
        "print('Running safety inference with best ckpt (no TTA, tau=None and 0.5) ...', flush=True)\n",
        "outs = infer_test(\n",
        "    df_test, idx2cid,\n",
        "    backbone='convnextv2_base', img_size=384, batch_size=128, num_workers=6, ckpt_dir='ckpts_main',\n",
        "    use_tta=False, tau_list=(None, 0.5), out_prefix='submission_cnn',\n",
        "    use_f0_mask=False, use_per_f0_prior=False\n",
        ")\n",
        "print('Inference outputs:', outs, flush=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running safety inference with best ckpt (no TTA, tau=None and 0.5) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected best ckpt by filename f1: model_upd5000_f10.07740.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_94/3039361667.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EMA load skipped: 'ModelEmaV2' object has no attribute 'copy_to'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 50/3733 | elapsed 0.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 100/3733 | elapsed 1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 150/3733 | elapsed 2.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 200/3733 | elapsed 3.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 250/3733 | elapsed 3.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 300/3733 | elapsed 4.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 350/3733 | elapsed 5.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 400/3733 | elapsed 6.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 450/3733 | elapsed 7.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 500/3733 | elapsed 7.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 550/3733 | elapsed 8.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 600/3733 | elapsed 9.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 650/3733 | elapsed 10.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 700/3733 | elapsed 10.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 750/3733 | elapsed 11.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 800/3733 | elapsed 12.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 850/3733 | elapsed 13.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 900/3733 | elapsed 13.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 950/3733 | elapsed 14.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1000/3733 | elapsed 15.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1050/3733 | elapsed 16.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1100/3733 | elapsed 17.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1150/3733 | elapsed 17.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1200/3733 | elapsed 18.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1250/3733 | elapsed 19.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1300/3733 | elapsed 20.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1350/3733 | elapsed 20.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1400/3733 | elapsed 21.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1450/3733 | elapsed 22.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1500/3733 | elapsed 23.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1550/3733 | elapsed 23.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1600/3733 | elapsed 24.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1650/3733 | elapsed 25.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1700/3733 | elapsed 26.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1750/3733 | elapsed 27.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1800/3733 | elapsed 27.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1850/3733 | elapsed 28.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1900/3733 | elapsed 29.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1950/3733 | elapsed 30.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2000/3733 | elapsed 30.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2050/3733 | elapsed 31.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2100/3733 | elapsed 32.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2150/3733 | elapsed 33.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2200/3733 | elapsed 33.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2250/3733 | elapsed 34.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2300/3733 | elapsed 35.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2350/3733 | elapsed 36.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2400/3733 | elapsed 37.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2450/3733 | elapsed 37.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2500/3733 | elapsed 38.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2550/3733 | elapsed 39.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2600/3733 | elapsed 40.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2650/3733 | elapsed 40.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2700/3733 | elapsed 41.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2750/3733 | elapsed 42.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2800/3733 | elapsed 43.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2850/3733 | elapsed 43.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2900/3733 | elapsed 44.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2950/3733 | elapsed 45.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3000/3733 | elapsed 46.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3050/3733 | elapsed 47.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3100/3733 | elapsed 47.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3150/3733 | elapsed 48.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3200/3733 | elapsed 49.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3250/3733 | elapsed 50.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3300/3733 | elapsed 50.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3350/3733 | elapsed 51.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3400/3733 | elapsed 52.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3450/3733 | elapsed 53.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3500/3733 | elapsed 53.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3550/3733 | elapsed 54.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3600/3733 | elapsed 55.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3650/3733 | elapsed 56.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3700/3733 | elapsed 56.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_cnn_tauNone.csv rows: 477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_cnn_tau0_5.csv rows: 477806\nInference outputs: {None: 'submission_cnn_tauNone.csv', 0.5: 'submission_cnn_tau0_5.csv'}\n"
          ]
        }
      ]
    },
    {
      "id": "832a5f12-d5f3-43c8-b7b0-17dcffc14d71",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Safety: set current best CNN submission as fallback, then resume training to 10k updates\n",
        "import shutil, os, pandas as pd\n",
        "best_fast_sub = 'submission_cnn_tau0_5.csv' if os.path.exists('submission_cnn_tau0_5.csv') else 'submission_cnn_tauNone.csv'\n",
        "if os.path.exists(best_fast_sub):\n",
        "    shutil.copyfile(best_fast_sub, 'submission.csv')\n",
        "    print(f'Copied {best_fast_sub} -> submission.csv')\n",
        "    try:\n",
        "        print(pd.read_csv('submission.csv').head())\n",
        "    except Exception as e:\n",
        "        print('Readback head failed:', e)\n",
        "else:\n",
        "    print('No CNN submission found to copy as safety.')\n",
        "\n",
        "print('Resuming training from upd5000 to 10k updates ...', flush=True)\n",
        "train_summary = train_main(\n",
        "  backbone='convnextv2_base', img_size=384,\n",
        "  batch_size=32, eff_batch=128,\n",
        "  updates_total=10_000, warmup_updates=300, lr_base=3e-4, weight_decay=0.02, seed=42,\n",
        "  mixup_alpha=0.2, cutmix_alpha=0.2, mix_prob=0.8,\n",
        "  val_frac=0.05, ckpt_dir='ckpts_main',\n",
        "  head_warmup_updates=600, lr_head=3e-3,\n",
        "  resume_path='ckpts_main/model_upd5000_f10.07740.pt'\n",
        ")\n",
        "print('Train summary:', train_summary)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied submission_cnn_tau0_5.csv -> submission.csv\n   Id  Predicted\n0   0      18454\n1   1       5434\n2   2      21267\n3   3      10029\n4   4      33711\nResuming training from upd5000 to 10k updates ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Val sizes: 1726076/53877 | classes in train: 64500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/convnextv2_base.fcmae_ft_in22k_in1k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._hub:[timm/convnextv2_base.fcmae_ft_in22k_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._builder:Missing keys (head.fc.weight, head.fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_94/643980742.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(resume_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer state load failed; continuing without optimizer state: loaded state dict contains a parameter group that doesn't match the size of optimizer's group\nResumed from ckpts_main/model_upd5000_f10.07740.pt at step 5000, best_f1=0.07740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 5000: macro-F1=0.07740 | top1=14.51% | loss=7.1650 | best=0.07740 | saved=model_upd5000_f10.07740.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 5000: macro-F1=0.07740 | top1=14.51% | loss=7.1650 | best=0.07740 | saved=model_upd5000_f10.07740.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 5000: macro-F1=0.07740 | top1=14.51% | loss=7.1650 | best=0.07740 | saved=model_upd5000_f10.07740.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5050/10000 | micro 20200 | avg_loss 4.5682 | lr 7.75e-05 | train_top1 68.75% | elapsed 23.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5100/10000 | micro 20400 | avg_loss 4.3496 | lr 7.62e-05 | train_top1 0.00% | elapsed 27.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5150/10000 | micro 20600 | avg_loss 4.2186 | lr 7.50e-05 | train_top1 3.12% | elapsed 30.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5200/10000 | micro 20800 | avg_loss 4.0455 | lr 7.38e-05 | train_top1 0.00% | elapsed 34.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5250/10000 | micro 21000 | avg_loss 3.9238 | lr 7.26e-05 | train_top1 34.38% | elapsed 38.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5300/10000 | micro 21200 | avg_loss 3.7959 | lr 7.14e-05 | train_top1 90.62% | elapsed 42.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5350/10000 | micro 21400 | avg_loss 3.7272 | lr 7.02e-05 | train_top1 0.00% | elapsed 45.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5400/10000 | micro 21600 | avg_loss 3.6619 | lr 6.90e-05 | train_top1 90.62% | elapsed 49.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5450/10000 | micro 21800 | avg_loss 3.6131 | lr 6.77e-05 | train_top1 84.38% | elapsed 53.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5500/10000 | micro 22000 | avg_loss 3.5598 | lr 6.65e-05 | train_top1 18.75% | elapsed 56.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5550/10000 | micro 22200 | avg_loss 3.5171 | lr 6.53e-05 | train_top1 87.50% | elapsed 60.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5600/10000 | micro 22400 | avg_loss 3.5182 | lr 6.41e-05 | train_top1 34.38% | elapsed 64.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5650/10000 | micro 22600 | avg_loss 3.7013 | lr 6.29e-05 | train_top1 18.75% | elapsed 67.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5700/10000 | micro 22800 | avg_loss 3.8471 | lr 6.17e-05 | train_top1 37.50% | elapsed 71.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5750/10000 | micro 23000 | avg_loss 3.9767 | lr 6.05e-05 | train_top1 40.62% | elapsed 75.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5800/10000 | micro 23200 | avg_loss 4.0983 | lr 5.94e-05 | train_top1 59.38% | elapsed 79.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5850/10000 | micro 23400 | avg_loss 4.2039 | lr 5.82e-05 | train_top1 6.25% | elapsed 82.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5900/10000 | micro 23600 | avg_loss 4.2987 | lr 5.70e-05 | train_top1 3.12% | elapsed 86.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 5950/10000 | micro 23800 | avg_loss 4.3812 | lr 5.58e-05 | train_top1 40.62% | elapsed 90.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6000/10000 | micro 24000 | avg_loss 4.4598 | lr 5.46e-05 | train_top1 0.00% | elapsed 93.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 6000: macro-F1=0.08185 | top1=14.76% | loss=7.2555 | best=0.08185 | saved=model_upd6000_f10.08185.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 6000: macro-F1=0.08185 | top1=14.76% | loss=7.2555 | best=0.08185 | saved=model_upd6000_f10.08185.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 6000: macro-F1=0.08185 | top1=14.76% | loss=7.2555 | best=0.08185 | saved=model_upd6000_f10.08185.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 6000: macro-F1=0.08185 | top1=14.76% | loss=7.2555 | best=0.08185 | saved=model_upd6000_f10.08185.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6050/10000 | micro 24200 | avg_loss 4.5308 | lr 5.35e-05 | train_top1 43.75% | elapsed 124.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6100/10000 | micro 24400 | avg_loss 4.5992 | lr 5.23e-05 | train_top1 0.00% | elapsed 127.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6150/10000 | micro 24600 | avg_loss 4.6607 | lr 5.12e-05 | train_top1 15.62% | elapsed 131.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6200/10000 | micro 24800 | avg_loss 4.7139 | lr 5.00e-05 | train_top1 15.62% | elapsed 135.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6250/10000 | micro 25000 | avg_loss 4.7657 | lr 4.89e-05 | train_top1 43.75% | elapsed 138.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6300/10000 | micro 25200 | avg_loss 4.8159 | lr 4.77e-05 | train_top1 40.62% | elapsed 142.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6350/10000 | micro 25400 | avg_loss 4.8525 | lr 4.66e-05 | train_top1 0.00% | elapsed 146.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6400/10000 | micro 25600 | avg_loss 4.8938 | lr 4.55e-05 | train_top1 28.12% | elapsed 150.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6450/10000 | micro 25800 | avg_loss 4.9288 | lr 4.44e-05 | train_top1 18.75% | elapsed 153.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6500/10000 | micro 26000 | avg_loss 4.9624 | lr 4.33e-05 | train_top1 34.38% | elapsed 157.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6550/10000 | micro 26200 | avg_loss 4.9923 | lr 4.22e-05 | train_top1 50.00% | elapsed 161.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6600/10000 | micro 26400 | avg_loss 5.0242 | lr 4.11e-05 | train_top1 0.00% | elapsed 164.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6650/10000 | micro 26600 | avg_loss 5.0526 | lr 4.00e-05 | train_top1 62.50% | elapsed 168.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6700/10000 | micro 26800 | avg_loss 5.0799 | lr 3.89e-05 | train_top1 0.00% | elapsed 172.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6750/10000 | micro 27000 | avg_loss 5.1028 | lr 3.79e-05 | train_top1 43.75% | elapsed 175.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6800/10000 | micro 27200 | avg_loss 5.1245 | lr 3.68e-05 | train_top1 18.75% | elapsed 179.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6850/10000 | micro 27400 | avg_loss 5.1436 | lr 3.58e-05 | train_top1 28.12% | elapsed 183.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6900/10000 | micro 27600 | avg_loss 5.1598 | lr 3.48e-05 | train_top1 53.12% | elapsed 187.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 6950/10000 | micro 27800 | avg_loss 5.1765 | lr 3.37e-05 | train_top1 21.88% | elapsed 190.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7000/10000 | micro 28000 | avg_loss 5.1941 | lr 3.27e-05 | train_top1 37.50% | elapsed 194.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 7000: macro-F1=0.09592 | top1=16.78% | loss=7.1565 | best=0.09592 | saved=model_upd7000_f10.09592.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 7000: macro-F1=0.09592 | top1=16.78% | loss=7.1565 | best=0.09592 | saved=model_upd7000_f10.09592.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 7000: macro-F1=0.09592 | top1=16.78% | loss=7.1565 | best=0.09592 | saved=model_upd7000_f10.09592.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 7000: macro-F1=0.09592 | top1=16.78% | loss=7.1565 | best=0.09592 | saved=model_upd7000_f10.09592.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7050/10000 | micro 28200 | avg_loss 5.2081 | lr 3.17e-05 | train_top1 37.50% | elapsed 224.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7100/10000 | micro 28400 | avg_loss 5.2251 | lr 3.07e-05 | train_top1 59.38% | elapsed 228.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7150/10000 | micro 28600 | avg_loss 5.2375 | lr 2.98e-05 | train_top1 6.25% | elapsed 232.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7200/10000 | micro 28800 | avg_loss 5.2478 | lr 2.88e-05 | train_top1 25.00% | elapsed 235.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7250/10000 | micro 29000 | avg_loss 5.2580 | lr 2.79e-05 | train_top1 43.75% | elapsed 239.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7300/10000 | micro 29200 | avg_loss 5.2686 | lr 2.69e-05 | train_top1 0.00% | elapsed 243.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7350/10000 | micro 29400 | avg_loss 5.2760 | lr 2.60e-05 | train_top1 53.12% | elapsed 246.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7400/10000 | micro 29600 | avg_loss 5.2848 | lr 2.51e-05 | train_top1 6.25% | elapsed 250.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7450/10000 | micro 29800 | avg_loss 5.2925 | lr 2.42e-05 | train_top1 50.00% | elapsed 254.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7500/10000 | micro 30000 | avg_loss 5.3012 | lr 2.33e-05 | train_top1 50.00% | elapsed 258.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7550/10000 | micro 30200 | avg_loss 5.3103 | lr 2.24e-05 | train_top1 53.12% | elapsed 261.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7600/10000 | micro 30400 | avg_loss 5.3177 | lr 2.16e-05 | train_top1 56.25% | elapsed 265.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7650/10000 | micro 30600 | avg_loss 5.3225 | lr 2.07e-05 | train_top1 3.12% | elapsed 269.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7700/10000 | micro 30800 | avg_loss 5.3293 | lr 1.99e-05 | train_top1 6.25% | elapsed 272.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7750/10000 | micro 31000 | avg_loss 5.3346 | lr 1.91e-05 | train_top1 43.75% | elapsed 276.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7800/10000 | micro 31200 | avg_loss 5.3406 | lr 1.83e-05 | train_top1 40.62% | elapsed 280.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7850/10000 | micro 31400 | avg_loss 5.3468 | lr 1.75e-05 | train_top1 50.00% | elapsed 284.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7900/10000 | micro 31600 | avg_loss 5.3508 | lr 1.67e-05 | train_top1 0.00% | elapsed 287.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 7950/10000 | micro 31800 | avg_loss 5.3569 | lr 1.59e-05 | train_top1 40.62% | elapsed 291.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8000/10000 | micro 32000 | avg_loss 5.3616 | lr 1.52e-05 | train_top1 37.50% | elapsed 295.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 8000: macro-F1=0.10895 | top1=18.48% | loss=6.9769 | best=0.10895 | saved=model_upd8000_f10.10895.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 8000: macro-F1=0.10895 | top1=18.48% | loss=6.9769 | best=0.10895 | saved=model_upd8000_f10.10895.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 8000: macro-F1=0.10895 | top1=18.48% | loss=6.9769 | best=0.10895 | saved=model_upd8000_f10.10895.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 8000: macro-F1=0.10895 | top1=18.48% | loss=6.9769 | best=0.10895 | saved=model_upd8000_f10.10895.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8050/10000 | micro 32200 | avg_loss 5.3660 | lr 1.45e-05 | train_top1 18.75% | elapsed 325.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8100/10000 | micro 32400 | avg_loss 5.3683 | lr 1.38e-05 | train_top1 50.00% | elapsed 329.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8150/10000 | micro 32600 | avg_loss 5.3723 | lr 1.31e-05 | train_top1 31.25% | elapsed 332.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8200/10000 | micro 32800 | avg_loss 5.3751 | lr 1.24e-05 | train_top1 46.88% | elapsed 336.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8250/10000 | micro 33000 | avg_loss 5.3773 | lr 1.17e-05 | train_top1 40.62% | elapsed 340.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8300/10000 | micro 33200 | avg_loss 5.3810 | lr 1.11e-05 | train_top1 50.00% | elapsed 343.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8350/10000 | micro 33400 | avg_loss 5.3852 | lr 1.05e-05 | train_top1 46.88% | elapsed 347.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8400/10000 | micro 33600 | avg_loss 5.3907 | lr 9.86e-06 | train_top1 43.75% | elapsed 351.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8450/10000 | micro 33800 | avg_loss 5.3949 | lr 9.27e-06 | train_top1 37.50% | elapsed 355.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8500/10000 | micro 34000 | avg_loss 5.3980 | lr 8.69e-06 | train_top1 56.25% | elapsed 358.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8550/10000 | micro 34200 | avg_loss 5.3906 | lr 8.13e-06 | train_top1 37.50% | elapsed 362.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8600/10000 | micro 34400 | avg_loss 5.3830 | lr 7.59e-06 | train_top1 62.50% | elapsed 366.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8650/10000 | micro 34600 | avg_loss 5.3770 | lr 7.07e-06 | train_top1 50.00% | elapsed 369.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8700/10000 | micro 34800 | avg_loss 5.3704 | lr 6.56e-06 | train_top1 56.25% | elapsed 373.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8750/10000 | micro 35000 | avg_loss 5.3643 | lr 6.07e-06 | train_top1 50.00% | elapsed 377.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8800/10000 | micro 35200 | avg_loss 5.3585 | lr 5.60e-06 | train_top1 50.00% | elapsed 380.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8850/10000 | micro 35400 | avg_loss 5.3526 | lr 5.15e-06 | train_top1 46.88% | elapsed 384.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8900/10000 | micro 35600 | avg_loss 5.3467 | lr 4.72e-06 | train_top1 62.50% | elapsed 388.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 8950/10000 | micro 35800 | avg_loss 5.3411 | lr 4.30e-06 | train_top1 43.75% | elapsed 392.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update 9000/10000 | micro 36000 | avg_loss 5.3357 | lr 3.91e-06 | train_top1 62.50% | elapsed 395.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation @update 9000: macro-F1=0.11838 | top1=19.67% | loss=6.8369 | best=0.11838 | saved=model_upd9000_f10.11838.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mNo CNN submission found to copy as safety.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mResuming training from upd5000 to 10k updates ...\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m train_summary = \u001b[43mtrain_main\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m  \u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconvnextv2_base\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m384\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meff_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m  \u001b[49m\u001b[43mupdates_total\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_updates\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_base\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmixup_alpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutmix_alpha\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmix_prob\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m  \u001b[49m\u001b[43mval_frac\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mckpts_main\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m  \u001b[49m\u001b[43mhead_warmup_updates\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m600\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_head\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m  \u001b[49m\u001b[43mresume_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mckpts_main/model_upd5000_f10.07740.pt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mTrain summary:\u001b[39m\u001b[33m'\u001b[39m, train_summary)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 177\u001b[39m, in \u001b[36mtrain_main\u001b[39m\u001b[34m(backbone, img_size, batch_size, eff_batch, updates_total, warmup_updates, lr_base, weight_decay, seed, mixup_alpha, cutmix_alpha, mix_prob, val_frac, ckpt_dir, head_warmup_updates, lr_head, resume_path)\u001b[39m\n\u001b[32m    175\u001b[39m     need_val = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m need_val \u001b[38;5;129;01mor\u001b[39;00m global_step >= updates_total:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     val_f1, val_top1, val_loss = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     is_best = val_f1 > best_f1\n\u001b[32m    179\u001b[39m     best_f1 = \u001b[38;5;28mmax\u001b[39m(best_f1, val_f1)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 335\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(model, ema, dl_va, device, criterion_val)\u001b[39m\n\u001b[32m    333\u001b[39m     logits = ema_model(x)\n\u001b[32m    334\u001b[39m     loss = criterion_val(logits, y)\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * x.size(\u001b[32m0\u001b[39m)\n\u001b[32m    336\u001b[39m n_items += x.size(\u001b[32m0\u001b[39m)\n\u001b[32m    337\u001b[39m y_preds.append(torch.argmax(logits, dim=\u001b[32m1\u001b[39m).detach().cpu().numpy())\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "e5f979d7-fb1b-4b0d-82c8-146646d14818",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Strong inference (EMA, 2x TTA, per-F0 prior, tau sweep up to 0.8)\n",
        "print('Running strong inference (EMA, 2x TTA, per-F0 prior, tau sweep) ...', flush=True)\n",
        "outs_strong = infer_test(\n",
        "    df_test, idx2cid,\n",
        "    backbone='convnextv2_base', img_size=384,\n",
        "    batch_size=128, num_workers=6, ckpt_dir='ckpts_main',\n",
        "    use_tta=True,\n",
        "    tau_list=(None, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8),\n",
        "    out_prefix='submission_cnn_strong',\n",
        "    use_f0_mask=False,\n",
        "    use_per_f0_prior=True\n",
        ")\n",
        "print('Strong inference outputs:', outs_strong, flush=True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running strong inference (EMA, 2x TTA, per-F0 prior, tau sweep) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected best ckpt by filename f1: model_upd9000_f10.11838.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_94/825408699.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded EMA weights into model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 50/3733 | elapsed 1.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 100/3733 | elapsed 3.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 150/3733 | elapsed 4.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 200/3733 | elapsed 6.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 250/3733 | elapsed 8.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 300/3733 | elapsed 9.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 350/3733 | elapsed 11.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 400/3733 | elapsed 12.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 450/3733 | elapsed 14.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 500/3733 | elapsed 15.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 550/3733 | elapsed 17.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 600/3733 | elapsed 19.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 650/3733 | elapsed 20.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 700/3733 | elapsed 22.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 750/3733 | elapsed 23.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 800/3733 | elapsed 25.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 850/3733 | elapsed 27.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 900/3733 | elapsed 28.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 950/3733 | elapsed 30.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1000/3733 | elapsed 31.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1050/3733 | elapsed 33.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1100/3733 | elapsed 35.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1150/3733 | elapsed 36.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1200/3733 | elapsed 38.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1250/3733 | elapsed 39.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1300/3733 | elapsed 41.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1350/3733 | elapsed 43.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1400/3733 | elapsed 44.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1450/3733 | elapsed 46.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1500/3733 | elapsed 47.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1550/3733 | elapsed 49.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1600/3733 | elapsed 51.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1650/3733 | elapsed 52.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1700/3733 | elapsed 54.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1750/3733 | elapsed 55.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1800/3733 | elapsed 57.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1850/3733 | elapsed 59.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1900/3733 | elapsed 60.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 1950/3733 | elapsed 62.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2000/3733 | elapsed 63.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2050/3733 | elapsed 65.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2100/3733 | elapsed 66.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2150/3733 | elapsed 68.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2200/3733 | elapsed 70.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2250/3733 | elapsed 71.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2300/3733 | elapsed 73.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2350/3733 | elapsed 74.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2400/3733 | elapsed 76.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2450/3733 | elapsed 78.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2500/3733 | elapsed 79.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2550/3733 | elapsed 81.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2600/3733 | elapsed 82.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2650/3733 | elapsed 84.4m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2700/3733 | elapsed 86.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2750/3733 | elapsed 87.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2800/3733 | elapsed 89.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2850/3733 | elapsed 90.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2900/3733 | elapsed 92.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 2950/3733 | elapsed 93.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3000/3733 | elapsed 95.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3050/3733 | elapsed 97.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3100/3733 | elapsed 98.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3150/3733 | elapsed 100.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3200/3733 | elapsed 101.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3250/3733 | elapsed 103.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3300/3733 | elapsed 105.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3350/3733 | elapsed 106.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3400/3733 | elapsed 108.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3450/3733 | elapsed 109.9m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3500/3733 | elapsed 111.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3550/3733 | elapsed 113.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3600/3733 | elapsed 114.6m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3650/3733 | elapsed 116.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer batch 3700/3733 | elapsed 117.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_cnn_strong_tauNone.csv rows: 477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_cnn_strong_tau0_2.csv rows: 477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_cnn_strong_tau0_3.csv rows: 477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_cnn_strong_tau0_4.csv rows: 477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_cnn_strong_tau0_5.csv rows: 477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_cnn_strong_tau0_6.csv rows: 477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_cnn_strong_tau0_7.csv rows: 477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_cnn_strong_tau0_8.csv rows: 477806\nStrong inference outputs: {None: 'submission_cnn_strong_tauNone.csv', 0.2: 'submission_cnn_strong_tau0_2.csv', 0.3: 'submission_cnn_strong_tau0_3.csv', 0.4: 'submission_cnn_strong_tau0_4.csv', 0.5: 'submission_cnn_strong_tau0_5.csv', 0.6: 'submission_cnn_strong_tau0_6.csv', 0.7: 'submission_cnn_strong_tau0_7.csv', 0.8: 'submission_cnn_strong_tau0_8.csv'}\n"
          ]
        }
      ]
    },
    {
      "id": "f55e12cc-da16-484f-8a67-69a9145fcf1c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Select strong inference submission (tau=0.5 primary; tau=0.7 as fallback if desired)\n",
        "import shutil, os, pandas as pd\n",
        "cand_primary = 'submission_cnn_strong_tau0_5.csv'\n",
        "cand_secondary = 'submission_cnn_strong_tau0_7.csv'\n",
        "choose = cand_primary if os.path.exists(cand_primary) else (cand_secondary if os.path.exists(cand_secondary) else None)\n",
        "assert choose is not None, 'No strong inference submission found'\n",
        "shutil.copyfile(choose, 'submission.csv')\n",
        "print(f'Copied {choose} -> submission.csv')\n",
        "print(pd.read_csv('submission.csv').head())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied submission_cnn_strong_tau0_5.csv -> submission.csv\n   Id  Predicted\n0   0      18454\n1   1       5434\n2   2      21267\n3   3      10029\n4   4      63426\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}