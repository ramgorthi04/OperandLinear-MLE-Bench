{
  "cells": [
    {
      "id": "3bd69880-3999-411b-93f0-35184fd289d7",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan to medal - Herbarium 2021 (FGVC8)\n",
        "\n",
        "Objectives:\n",
        "- Establish robust GPU-enabled pipeline quickly.\n",
        "- Validate data loading from provided metadata and image structure.\n",
        "- Build a fast, strong baseline (image classifier with transfer learning, e.g., timm/torchvision).\n",
        "- Lock CV protocol mirroring test (stratified KFold on species).\n",
        "- Iterate: augmentations, resolution, label smoothing, class-balanced loss, mixup/cutmix. Cache checkpoints.\n",
        "- Ensembling if time allows (multi-seed, different backbones).\n",
        "\n",
        "Milestones:\n",
        "1) Environment + data sanity checks.\n",
        "2) EDA: label distribution, image counts, sources, leakage checks.\n",
        "3) Baseline model: pretrained backbone (e.g., convnext_tiny / efficientnet_b3).\n",
        "4) CV + OOF + test inference, submission.csv.\n",
        "5) Error analysis and quick improvements (augmentations, loss, re-balancing).\n",
        "\n",
        "Notes:\n",
        "- Metric: macro F1, long-tail: prioritize class-balanced sampling/loss.\n",
        "- Always log progress and elapsed time per fold.\n",
        "- Save OOF and test logits for future blends.\n",
        "\n",
        "Next: Run environment & data checks."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7ba2d69e-81e8-4a37-8f86-d8094e6518a0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, json, random, time, subprocess, sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "t0 = time.time()\n",
        "print(\"=== GPU check: nvidia-smi ===\", flush=True)\n",
        "try:\n",
        "    print(subprocess.run(['bash','-lc','nvidia-smi || true'], capture_output=True, text=True).stdout)\n",
        "except Exception as e:\n",
        "    print(\"nvidia-smi failed:\", e)\n",
        "\n",
        "ROOT = Path('.')\n",
        "TRAIN_DIR = ROOT / 'train'\n",
        "TEST_DIR = ROOT / 'test'\n",
        "TRAIN_META = TRAIN_DIR / 'metadata.json'\n",
        "TEST_META = TEST_DIR / 'metadata.json'\n",
        "SAMPLE_SUB = ROOT / 'sample_submission.csv'\n",
        "\n",
        "print(\"=== Files existence ===\", flush=True)\n",
        "for p in [TRAIN_DIR, TEST_DIR, TRAIN_DIR/'images', TEST_DIR/'images', TRAIN_META, TEST_META, SAMPLE_SUB]:\n",
        "    print(f\"{p}: {'OK' if p.exists() else 'MISSING'}\")\n",
        "\n",
        "def load_coco_like(pth):\n",
        "    with open(pth, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    # Expected keys: annotations, images, categories\n",
        "    anns = pd.DataFrame(data.get('annotations', []))\n",
        "    imgs = pd.DataFrame(data.get('images', []))\n",
        "    cats = pd.DataFrame(data.get('categories', []))\n",
        "    return anns, imgs, cats\n",
        "\n",
        "print(\"\\n=== Load train/test COCO-like metadata ===\", flush=True)\n",
        "tr_anns, tr_imgs, tr_cats = load_coco_like(TRAIN_META)\n",
        "te_anns, te_imgs, te_cats = load_coco_like(TEST_META)  # test usually has images and no annotations\n",
        "print(\"train anns/imgs/cats shapes:\", tr_anns.shape, tr_imgs.shape, tr_cats.shape)\n",
        "print(\"test anns/imgs/cats shapes:\", te_anns.shape, te_imgs.shape, te_cats.shape)\n",
        "print(\"train anns head:\\n\", tr_anns.head(3))\n",
        "print(\"train imgs head:\\n\", tr_imgs.head(3))\n",
        "print(\"cats head:\\n\", tr_cats.head(3))\n",
        "\n",
        "# Identify columns\n",
        "species_col = None\n",
        "for c in ['category_id','species_id','label','target']:\n",
        "    if c in tr_anns.columns:\n",
        "        species_col = c; break\n",
        "image_id_col = 'image_id' if 'image_id' in tr_anns.columns else None\n",
        "specimen_col = None\n",
        "for c in ['specimen_id','specimen','record_id']:\n",
        "    if c in tr_imgs.columns:\n",
        "        specimen_col = c; break\n",
        "file_col = None\n",
        "for c in ['file_name','file','path']:\n",
        "    if c in tr_imgs.columns:\n",
        "        file_col = c; break\n",
        "\n",
        "print(f\"Detected -> species: {species_col}, specimen: {specimen_col}, file: {file_col}, image_id_col: {image_id_col}\")\n",
        "assert species_col is not None and image_id_col is not None, \"Train annotations must have category_id/species and image_id\"\n",
        "assert file_col is not None and 'id' in tr_imgs.columns, \"Train images must have id and file_name\"\n",
        "\n",
        "# Merge anns with imgs to get file paths and specimen\n",
        "train_df = tr_anns.merge(tr_imgs, left_on=image_id_col, right_on='id', how='inner', suffixes=('_ann','_img'))\n",
        "# Build correct absolute file paths (file_name already includes 'images/...')\n",
        "train_df['file_path'] = train_df[file_col].apply(lambda x: TRAIN_DIR / x)\n",
        "te_imgs['file_path'] = te_imgs[file_col].apply(lambda x: TEST_DIR / x)\n",
        "print(\"train_df merged shape:\", train_df.shape)\n",
        "\n",
        "print(\"\\n=== Basic stats ===\", flush=True)\n",
        "n_species = train_df[species_col].nunique()\n",
        "n_imgs = len(train_df)\n",
        "n_specimens = train_df[specimen_col].nunique() if specimen_col and specimen_col in train_df.columns else None\n",
        "print(\"species unique:\", n_species, \"images:\", n_imgs, \"specimens unique:\", n_specimens)\n",
        "cnts = train_df[species_col].value_counts()\n",
        "print(\"per-class count head:\", cnts.head().to_dict())\n",
        "print(\"per-class count tail:\", cnts.tail().to_dict())\n",
        "\n",
        "print(\"\\n=== Path existence checks (sample) ===\", flush=True)\n",
        "def build_path(split, rel):\n",
        "    base = TRAIN_DIR if split=='train' else TEST_DIR\n",
        "    return base / rel  # file_name already contains 'images/...'\n",
        "sample_train = train_df.sample(min(20, len(train_df)), random_state=42)\n",
        "missing_train = 0\n",
        "for r in sample_train[file_col].tolist():\n",
        "    p = build_path('train', r)\n",
        "    if not p.exists():\n",
        "        missing_train += 1\n",
        "print(f\"Train sample missing paths: {missing_train}/{len(sample_train)}\")\n",
        "\n",
        "print(\"\\n=== Test metadata overview ===\", flush=True)\n",
        "assert 'id' in te_imgs.columns and file_col in te_imgs.columns, \"Test images must have id and file_name\"\n",
        "print(te_imgs[[ 'id', file_col ]].head(3))\n",
        "sample_test = te_imgs.sample(min(20, len(te_imgs)), random_state=42)\n",
        "missing_test = 0\n",
        "for r in sample_test[file_col].tolist():\n",
        "    p = build_path('test', r)\n",
        "    if not p.exists():\n",
        "        missing_test += 1\n",
        "print(f\"Test sample missing paths: {missing_test}/{len(sample_test)}\")\n",
        "\n",
        "print(\"\\n=== Sample submission ===\", flush=True)\n",
        "sdf = pd.read_csv(SAMPLE_SUB)\n",
        "print(\"sample_submission head:\\n\", sdf.head())\n",
        "print(\"Elapsed: %.2fs\" % (time.time()-t0), flush=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GPU check: nvidia-smi ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 29 01:51:45 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |    6722MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n=== Files existence ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: OK\ntest: OK\ntrain/images: OK\ntest/images: OK\ntrain/metadata.json: OK\ntest/metadata.json: OK\nsample_submission.csv: OK\n\n=== Load train/test COCO-like metadata ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train anns/imgs/cats shapes: (1779953, 4) (1779953, 5) (64500, 4)\ntest anns/imgs/cats shapes: (0, 0) (477806, 5) (0, 0)\ntrain anns head:\n    category_id       id  image_id  institution_id\n0        60492  1608432   1608432               0\n1        60492   796948    796948               0\n2        60492   994447    994447               0\ntrain imgs head:\n                    file_name  height       id  license  width\n0  images/604/92/1608432.jpg    1000  1608432        0    671\n1   images/604/92/796948.jpg    1000   796948        0    678\n2   images/604/92/994447.jpg    1000   994447        0    671\ncats head:\n         family  id                             name        order\n0  Orchidaceae   0    Aa calceata (Rchb.f.) Schltr.  Asparagales\n1  Orchidaceae   1  Aa matthewsii (Rchb.f.) Schltr.  Asparagales\n2  Orchidaceae   2      Aa paleacea (Kunth) Rchb.f.  Asparagales\nDetected -> species: category_id, specimen: None, file: file_name, image_id_col: image_id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df merged shape: (1779953, 10)\n\n=== Basic stats ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "species unique: 64500 images: 1779953 specimens unique: None\nper-class count head: {42811: 2647, 25229: 1713, 48372: 1630, 42843: 1324, 22344: 1260}\nper-class count tail: {6742: 1, 57300: 1, 44413: 1, 4970: 1, 37044: 1}\n\n=== Path existence checks (sample) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train sample missing paths: 0/20\n\n=== Test metadata overview ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  id         file_name\n0  0  images/000/0.jpg\n1  1  images/000/1.jpg\n2  2  images/000/2.jpg\nTest sample missing paths: 0/20\n\n=== Sample submission ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_submission head:\n    Id  Predicted\n0   0          0\n1   1          0\n2   2          0\n3   3          0\n4   4          0\nElapsed: 14.35s\n"
          ]
        }
      ]
    },
    {
      "id": "c0adb9d9-81d4-4f2b-8662-98f7b7da7d41",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json, time\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "t0 = time.time()\n",
        "TRAIN_META = Path('train/metadata.json')\n",
        "TEST_META = Path('test/metadata.json')\n",
        "SAMPLE_SUB = Path('sample_submission.csv')\n",
        "\n",
        "print('=== Build majority-class baseline submission ===', flush=True)\n",
        "print('Loading train annotations to compute majority class...', flush=True)\n",
        "with open(TRAIN_META, 'r') as f:\n",
        "    data = json.load(f)\n",
        "anns = data.get('annotations', [])\n",
        "cnt = Counter(a['category_id'] for a in anns)\n",
        "mode_cat, mode_cnt = cnt.most_common(1)[0]\n",
        "n_classes = len(data.get('categories', []))\n",
        "print(f'Mode category_id: {mode_cat} with count {mode_cnt}; total classes: {n_classes}', flush=True)\n",
        "\n",
        "print('Loading sample_submission to get test Id order...', flush=True)\n",
        "sdf = pd.read_csv(SAMPLE_SUB)\n",
        "print('sample_submission shape:', sdf.shape, 'cols:', sdf.columns.tolist())\n",
        "\n",
        "sub = pd.DataFrame({'Id': sdf['Id'].values, 'Predicted': mode_cat})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv')\n",
        "print(sub.head())\n",
        "print('Elapsed: %.2fs' % (time.time()-t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b2d8e99a-ba74-405c-9b65-2f12881e4b03",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, subprocess, shutil, time\n",
        "from pathlib import Path\n",
        "\n",
        "t0 = time.time()\n",
        "print(\"=== Install CUDA 12.1 torch stack + vision deps ===\", flush=True)\n",
        "\n",
        "def pip(*args):\n",
        "    print(\">\", *args, flush=True)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", *args], check=True)\n",
        "\n",
        "# Uninstall any existing torch stack (idempotent)\n",
        "for pkg in (\"torch\",\"torchvision\",\"torchaudio\"):\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg], check=False)\n",
        "\n",
        "# Clean possible stray site dirs (idempotent)\n",
        "for d in (\n",
        "    \"/app/.pip-target/torch\",\n",
        "    \"/app/.pip-target/torchvision\",\n",
        "    \"/app/.pip-target/torchaudio\",\n",
        "    \"/app/.pip-target/torch-2.4.1.dist-info\",\n",
        "    \"/app/.pip-target/torchvision-0.19.1.dist-info\",\n",
        "    \"/app/.pip-target/torchaudio-2.4.1.dist-info\",\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print(\"Removing\", d); shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# Install exact cu121 torch stack\n",
        "pip(\"install\",\n",
        "    \"--index-url\", \"https://download.pytorch.org/whl/cu121\",\n",
        "    \"--extra-index-url\", \"https://pypi.org/simple\",\n",
        "    \"torch==2.4.1\", \"torchvision==0.19.1\", \"torchaudio==2.4.1\")\n",
        "\n",
        "# Freeze torch versions for subsequent installs\n",
        "Path(\"constraints.txt\").write_text(\"\\n\".join([\n",
        "    \"torch==2.4.1\",\n",
        "    \"torchvision==0.19.1\",\n",
        "    \"torchaudio==2.4.1\"\n",
        "]))\n",
        "\n",
        "# Install vision deps respecting constraints (avoid upgrading torch)\n",
        "pip(\"install\", \"-c\", \"constraints.txt\",\n",
        "    \"timm==1.0.9\",\n",
        "    \"albumentations==1.4.14\",\n",
        "    \"opencv-python-headless==4.10.0.84\",\n",
        "    \"numpy\", \"pandas\", \"scikit-learn\",\n",
        "    \"accelerate==0.34.2\",\n",
        "    \"wandb==0.17.9\",\n",
        "    \"einops==0.8.0\",\n",
        "    \"--upgrade-strategy\", \"only-if-needed\")\n",
        "\n",
        "import torch\n",
        "print(\"torch:\", torch.__version__, \"built CUDA:\", getattr(torch.version, \"cuda\", None))\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "assert str(getattr(torch.version, \"cuda\", \"\")).startswith(\"12.1\"), f\"Wrong CUDA build: {torch.version.cuda}\"\n",
        "assert torch.cuda.is_available(), \"CUDA not available\"\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "print(\"Elapsed install: %.1fs\" % (time.time()-t0), flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "6742d90d-3f7f-4d47-a12c-032282b7ee84",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, time, math, random, json, gc, sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import timm\n",
        "from timm.data.mixup import Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy\n",
        "from timm.utils.model_ema import ModelEmaV2\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "ROOT = Path('.')\n",
        "TRAIN_DIR = ROOT / 'train'\n",
        "TEST_DIR = ROOT / 'test'\n",
        "SAMPLE_SUB = ROOT / 'sample_submission.csv'\n",
        "\n",
        "# Use already loaded metadata via fast reload (small cost compared to images I/O)\n",
        "with open(TRAIN_DIR / 'metadata.json','r') as f: tr_data = json.load(f)\n",
        "with open(TEST_DIR / 'metadata.json','r') as f: te_data = json.load(f)\n",
        "tr_anns = pd.DataFrame(tr_data['annotations'])\n",
        "tr_imgs = pd.DataFrame(tr_data['images'])\n",
        "tr_cats = pd.DataFrame(tr_data['categories'])\n",
        "te_imgs = pd.DataFrame(te_data['images'])\n",
        "\n",
        "# Merge to get file paths\n",
        "train_df = tr_anns.merge(tr_imgs, left_on='image_id', right_on='id', how='inner')\n",
        "train_df['file_path'] = train_df['file_name'].apply(lambda x: TRAIN_DIR / x)\n",
        "te_imgs['file_path'] = te_imgs['file_name'].apply(lambda x: TEST_DIR / x)\n",
        "\n",
        "# Label encoding\n",
        "cats = sorted(train_df['category_id'].unique())\n",
        "cat2lbl = {c:i for i,c in enumerate(cats)}\n",
        "lbl2cat = {i:c for c,i in cat2lbl.items()}\n",
        "train_df['label'] = train_df['category_id'].map(cat2lbl)\n",
        "NUM_CLASSES = len(cats)\n",
        "print('NUM_CLASSES:', NUM_CLASSES, 'train images:', len(train_df))\n",
        "\n",
        "# Transforms using torchvision (avoid albumentations dependency issues)\n",
        "IMG_SIZE = 256\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "train_tfms_clean = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.6, 1.0), ratio=(0.75, 1.33)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=mean, std=std),\n",
        "])\n",
        "train_tfms_aug = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.6, 1.0), ratio=(0.75, 1.33)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=mean, std=std),\n",
        "])\n",
        "val_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=mean, std=std),\n",
        "])\n",
        "\n",
        "class HerbDataset(Dataset):\n",
        "    def __init__(self, df, tfms, is_train=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tfms = tfms\n",
        "        self.is_train = is_train\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        fp = row['file_path']\n",
        "        try:\n",
        "            img = Image.open(fp).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.fromarray(np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8))\n",
        "        img = self.tfms(img)\n",
        "        label = int(row['label'])\n",
        "        return img, label\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "seed_everything(42)\n",
        "\n",
        "# Build folds: exclude singleton classes from validation; 2-fold stratified on labels with >=2 samples\n",
        "label_counts = train_df['label'].value_counts()\n",
        "valid_labels = label_counts[label_counts >= 2].index\n",
        "idx_valid = train_df[train_df['label'].isin(valid_labels)].index.values\n",
        "y_valid = train_df.loc[idx_valid, 'label'].values\n",
        "singletons_idx = train_df[~train_df['label'].isin(valid_labels)].index.values\n",
        "print('Singletons (train-only):', len(singletons_idx))\n",
        "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "folds = []\n",
        "for tr_sub, va_sub in skf.split(idx_valid, y_valid):\n",
        "    tr_idx = idx_valid[tr_sub]\n",
        "    va_idx = idx_valid[va_sub]\n",
        "    tr_idx_full = np.concatenate([tr_idx, singletons_idx])\n",
        "    folds.append((tr_idx_full, va_idx))\n",
        "print('Prepared folds:', len(folds), '| fold0 train/val sizes:', len(folds[0][0]), len(folds[0][1]))\n",
        "\n",
        "def build_model():\n",
        "    model = timm.create_model('convnext_tiny.fb_in22k', pretrained=True, num_classes=NUM_CLASSES, drop_path_rate=0.1)\n",
        "    model.to(device)\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    return model\n",
        "\n",
        "def evaluate(model, loader, max_batches=None):\n",
        "    m = model\n",
        "    m.eval()\n",
        "    preds, targs = [], []\n",
        "    with torch.no_grad():\n",
        "        for b, (imgs, labels) in enumerate(loader):\n",
        "            imgs = imgs.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "            logits = m(imgs)\n",
        "            pred = logits.argmax(1)\n",
        "            preds.append(pred.detach().cpu().numpy())\n",
        "            targs.append(labels.detach().cpu().numpy())\n",
        "            if max_batches is not None and (b+1) >= max_batches:\n",
        "                break\n",
        "    preds = np.concatenate(preds); targs = np.concatenate(targs)\n",
        "    f1 = f1_score(targs, preds, average='macro')\n",
        "    return f1\n",
        "\n",
        "def run_fold(fold, train_idx, val_idx, epochs=9, batch_size=64, accum_steps=4):\n",
        "    print(f\"\\n=== Fold {fold} ===\", flush=True)\n",
        "    tr_df = train_df.loc[train_idx]\n",
        "    va_df = train_df.loc[val_idx]\n",
        "    # Datasets (start with clean tfms, will toggle to aug later epochs)\n",
        "    ds_tr = HerbDataset(tr_df, train_tfms_clean, is_train=True)\n",
        "    ds_va = HerbDataset(va_df, val_tfms, is_train=False)\n",
        "    # Mini-val: random 1 image per class (cap at 10k) for stable early F1\n",
        "    mini_va = va_df.groupby('label', group_keys=False).apply(lambda g: g.sample(1, random_state=42))\n",
        "    if len(mini_va) > 10000:\n",
        "        mini_va = mini_va.sample(10000, random_state=42)\n",
        "    ds_mini = HerbDataset(mini_va, val_tfms, is_train=False)\n",
        "    # Balanced sampling per fold (1/sqrt(freq)), epoch length 300k\n",
        "    counts = tr_df['label'].value_counts()\n",
        "    w = tr_df['label'].map(lambda x: 1.0 / (counts[x] ** 0.5)).values\n",
        "    sampler = WeightedRandomSampler(w, num_samples=300000, replacement=True)\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, sampler=sampler, shuffle=False,\n",
        "                       num_workers=12, pin_memory=True, persistent_workers=True,\n",
        "                       prefetch_factor=2, drop_last=True)\n",
        "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=True)\n",
        "    dl_mini = DataLoader(ds_mini, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "    model = build_model()\n",
        "    # Differential LRs: higher LR for head, lower for backbone\n",
        "    head_names = ['head','classifier','fc']\n",
        "    head_params, backbone_params = [], []\n",
        "    for n,p in model.named_parameters():\n",
        "        (head_params if any(h in n for h in head_names) else backbone_params).append(p)\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': backbone_params, 'lr': 5e-4},\n",
        "        {'params': head_params, 'lr': 5e-3}\n",
        "    ], weight_decay=0.05)\n",
        "    # Scheduler with warmup then cosine (step once per epoch)\n",
        "    warmup = LinearLR(optimizer, start_factor=0.1, total_iters=1)\n",
        "    cosine = CosineAnnealingLR(optimizer, T_max=max(1, epochs-1), eta_min=1e-6)\n",
        "    scheduler = SequentialLR(optimizer, [warmup, cosine], milestones=[1])\n",
        "    # EMA\n",
        "    ema = ModelEmaV2(model, decay=0.999, device=device)\n",
        "    # Losses and mixup setup\n",
        "    criterion_ce = nn.CrossEntropyLoss(label_smoothing=0.1).to(device)\n",
        "    criterion_soft = SoftTargetCrossEntropy().to(device)\n",
        "    mixup_fn = Mixup(mixup_alpha=0.3, cutmix_alpha=0.3, prob=0.0, mode='batch', label_smoothing=0.0, num_classes=NUM_CLASSES)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
        "    best_score = -1.0\n",
        "    best_f1 = -1.0\n",
        "    best_mini = -1.0\n",
        "    best_path = f'ckpt_fold{fold}.pt'\n",
        "    global_step = 0\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        t0 = time.time()\n",
        "        model.train()\n",
        "        # Toggle training transforms: enable ColorJitter from epoch 3+\n",
        "        ds_tr.tfms = train_tfms_aug if epoch >= 3 else train_tfms_clean\n",
        "        # Mixup schedule: 1-3 off (CE+LS), 4..E-1 on (SoftTarget), last off (CE+LS)\n",
        "        if epoch <= 3:\n",
        "            mixup_fn.prob = 0.0\n",
        "            criterion = criterion_ce\n",
        "        elif epoch < epochs:\n",
        "            mixup_fn.prob = 0.3\n",
        "            criterion = criterion_soft\n",
        "        else:\n",
        "            mixup_fn.prob = 0.0\n",
        "            criterion = criterion_ce\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        running_loss = 0.0\n",
        "        steps_this_epoch = 0\n",
        "        for step, (imgs, labels) in enumerate(dl_tr):\n",
        "            imgs = imgs.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda', enabled=True):\n",
        "                if mixup_fn.prob > 0.0:\n",
        "                    imgs_m, targets = mixup_fn(imgs, labels)\n",
        "                    logits = model(imgs_m)\n",
        "                    loss = criterion(logits, targets)\n",
        "                else:\n",
        "                    logits = model(imgs)\n",
        "                    loss = criterion(logits, labels)\n",
        "            loss = loss / accum_steps\n",
        "            scaler.scale(loss).backward()\n",
        "            steps_this_epoch += 1\n",
        "            if (step + 1) % accum_steps == 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                ema.update(model)\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "            running_loss += loss.item() * accum_steps\n",
        "            global_step += 1\n",
        "            if step % 50 == 0:\n",
        "                elapsed = time.time()-t0\n",
        "                print(f\"Fold {fold} Epoch {epoch} Step {step} Loss {running_loss/(step+1):.4f} Elapsed {elapsed:.1f}s\", flush=True)\n",
        "        # Flush remaining grads if last micro-batch didn't hit accum boundary\n",
        "        remainder = steps_this_epoch % accum_steps\n",
        "        if remainder != 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            ema.update(model)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Evaluate using EMA weights\n",
        "        print(\"Evaluating on mini-val (1/img per class, cap 10k)\", flush=True)\n",
        "        mini_f1 = evaluate(ema.module, dl_mini, max_batches=None)\n",
        "        # Cap full val; increase cap on final epoch for better selection stability\n",
        "        max_val_batches = 1500 if epoch == epochs else 500\n",
        "        print(f\"Evaluating on capped validation: {max_val_batches} batches\", flush=True)\n",
        "        f1 = evaluate(ema.module, dl_va, max_batches=max_val_batches)\n",
        "        sel_score = 0.7 * mini_f1 + 0.3 * f1\n",
        "        ep_time = time.time()-t0\n",
        "        print(f\"Fold {fold} Epoch {epoch} mini-F1 {mini_f1:.5f} | F1 {f1:.5f} | sel {sel_score:.5f} time {ep_time:.1f}s\", flush=True)\n",
        "        if sel_score > best_score:\n",
        "            best_score = sel_score\n",
        "            best_f1 = f1\n",
        "            best_mini = mini_f1\n",
        "            torch.save({'model': model.state_dict(), 'ema': ema.state_dict(), 'f1': f1, 'mini_f1': mini_f1, 'sel': sel_score}, best_path)\n",
        "            print(f\"Saved best to {best_path}\", flush=True)\n",
        "        # Step scheduler once per epoch\n",
        "        scheduler.step()\n",
        "        gc.collect(); torch.cuda.empty_cache()\n",
        "    print(f\"Fold {fold} best sel {best_score:.5f} (mini {best_mini:.5f} | f1 {best_f1:.5f})\", flush=True)\n",
        "    return best_f1\n",
        "\n",
        "def build_test_df_in_submission_order():\n",
        "    sub = pd.read_csv(SAMPLE_SUB)\n",
        "    # Ensure consistent dtypes for merge\n",
        "    sub['Id'] = sub['Id'].astype(int)\n",
        "    te_tmp = te_imgs.copy()\n",
        "    te_tmp['id'] = te_tmp['id'].astype(int)\n",
        "    df = sub[['Id']].merge(te_tmp[['id','file_path']], left_on='Id', right_on='id', how='left')\n",
        "    return df\n",
        "\n",
        "def infer_fold(fold, batch_size=128):\n",
        "    ckpt_path = f'ckpt_fold{fold}.pt'\n",
        "    state = torch.load(ckpt_path, map_location='cpu')\n",
        "    model = build_model()\n",
        "    model.load_state_dict(state['model'], strict=True)\n",
        "    # Rebuild EMA and load\n",
        "    ema = ModelEmaV2(model, decay=0.999, device=device)\n",
        "    if 'ema' in state:\n",
        "        ema.load_state_dict(state['ema'], strict=False)\n",
        "    m = ema.module if 'ema' in state else model\n",
        "    m.eval()\n",
        "    test_df = build_test_df_in_submission_order()\n",
        "    # Build a test dataset that returns tensors (dummy labels)\n",
        "    tmp = test_df.copy()\n",
        "    tmp['label'] = 0\n",
        "    class TestDataset(Dataset):\n",
        "        def __init__(self, df, tfms):\n",
        "            self.df = df.reset_index(drop=True); self.tfms = tfms\n",
        "        def __len__(self): return len(self.df)\n",
        "        def __getitem__(self, i):\n",
        "            fp = self.df.iloc[i]['file_path']\n",
        "            try:\n",
        "                img = Image.open(fp).convert('RGB')\n",
        "            except Exception:\n",
        "                img = Image.fromarray(np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8))\n",
        "            img = self.tfms(img)\n",
        "            return img, 0\n",
        "    ds_te = TestDataset(tmp, val_tfms)\n",
        "    dl_te = DataLoader(ds_te, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=True)\n",
        "    pred_lbl = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in dl_te:\n",
        "            imgs = imgs.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "            # TTA 2x: center + hflip\n",
        "            logits1 = m(imgs)\n",
        "            imgs_flipped = torch.flip(imgs, dims=[3])\n",
        "            logits2 = m(imgs_flipped)\n",
        "            logits = (logits1 + logits2) / 2.0\n",
        "            pred_lbl.append(logits.argmax(1).detach().cpu().numpy())\n",
        "    pred_lbl = np.concatenate(pred_lbl).astype(np.int32)\n",
        "    np.save(f'test_predlbl_fold{fold}.npy', pred_lbl)\n",
        "    return pred_lbl\n",
        "\n",
        "# Orchestrate: run folds and generate submission\n",
        "def train_and_predict(epochs=9, batch_size=64, run_folds=(0,1)):\n",
        "    fold_scores = []\n",
        "    for fold, (tr, va) in enumerate(folds):\n",
        "        if fold not in run_folds:\n",
        "            continue\n",
        "        print(f\"Starting fold {fold} with {len(tr)} train idx and {len(va)} val idx\", flush=True)\n",
        "        f1 = run_fold(fold, tr, va, epochs=epochs, batch_size=batch_size, accum_steps=4)\n",
        "        fold_scores.append((fold, f1))\n",
        "    print('Fold scores:', fold_scores, flush=True)\n",
        "    # Inference and ensembling (majority vote on per-fold label preds)\n",
        "    fold_preds = []\n",
        "    for fold, _ in fold_scores:\n",
        "        preds = infer_fold(fold, batch_size=128)\n",
        "        fold_preds.append(preds)\n",
        "    if len(fold_preds) == 1:\n",
        "        vote = fold_preds[0]\n",
        "    else:\n",
        "        stack = np.stack(fold_preds, 0)\n",
        "        vote = np.apply_along_axis(lambda x: np.bincount(x).argmax(), 0, stack)\n",
        "    pred_cat = [lbl2cat[int(x)] for x in vote]\n",
        "    sub = pd.DataFrame({ 'Id': pd.read_csv(SAMPLE_SUB)['Id'].values, 'Predicted': pred_cat })\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Wrote submission.csv with shape', sub.shape, flush=True)\n",
        "\n",
        "print('Ready: IMG_SIZE=256; CV=2 folds with singleton-excluded val. CE+LS epochs 1-3; mixup on from epoch 4..E-1; last epoch CE+LS; 300k samples/epoch; EMA=0.999; grad accumulation x4; scheduler step per epoch. Checkpoint by 0.7*mini + 0.3*capped F1; final epoch cap 1500 batches.', flush=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NUM_CLASSES: 64500 train images: 1779953\nSingletons (train-only): 7745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared folds: 2 | fold0 train/val sizes: 893849 886104\nReady: IMG_SIZE=256; CV=2 folds with singleton-excluded val. CE+LS epochs 1-3; mixup on from epoch 4..E-1; last epoch CE+LS; 300k samples/epoch; EMA=0.999; grad accumulation x4; scheduler step per epoch. Checkpoint by 0.7*mini + 0.3*capped F1; final epoch cap 1500 batches.\n"
          ]
        }
      ]
    },
    {
      "id": "1d93f264-9902-4a59-8c97-1a13dc666faa",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick smoke run on a small subset to validate pipeline end-to-end\n",
        "import time, numpy as np, pandas as pd\n",
        "start_time = time.time()\n",
        "print('Preparing subset for smoke run...', flush=True)\n",
        "\n",
        "# Subset size (keep small to finish fast); training still outputs 64.5k classes\n",
        "N = 20000\n",
        "if len(train_df) > N:\n",
        "    sub_df = train_df.sample(N, random_state=42).reset_index(drop=True)\n",
        "    train_df = sub_df\n",
        "    # Recompute stratification bins on subset\n",
        "    cls_counts = train_df['category_id'].value_counts()\n",
        "    freq = train_df['category_id'].map(cls_counts)\n",
        "    try:\n",
        "        y_strat = pd.qcut(freq, q=10, duplicates='drop').astype(str)\n",
        "    except Exception:\n",
        "        y_strat = pd.cut(freq, bins=10, include_lowest=True).astype(str)\n",
        "    # Rebuild folds on subset\n",
        "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    folds = list(skf.split(train_df.index.values, y_strat))\n",
        "    print('Subset prepared:', len(train_df), 'rows; folds rebuilt:', len(folds), flush=True)\n",
        "else:\n",
        "    print('Dataset smaller than subset target; using full set.', flush=True)\n",
        "\n",
        "print('Starting quick smoke run (1 epoch, fold 0)...', flush=True)\n",
        "train_and_predict(epochs=1, batch_size=16, run_folds=(0,))\n",
        "print('Smoke run elapsed: %.1f min' % ((time.time()-start_time)/60.0), flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "bb1fa1e8-c50d-4e72-b0ed-e6c8afcb9e9a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, subprocess, time\n",
        "t0=time.time()\n",
        "print('Fixing albumentations/albucore mismatch...', flush=True)\n",
        "def pip(*args):\n",
        "    print('>', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'albucore'], check=False)\n",
        "pip('install', '-c', 'constraints.txt', 'albumentations==1.3.1', '--upgrade-strategy', 'only-if-needed')\n",
        "import albumentations as A\n",
        "print('albumentations version:', A.__version__)\n",
        "print('Done in %.1fs' % (time.time()-t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c4ca4bd8-d9f0-4171-bf55-f36d9202050f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, subprocess, shutil, os, time\n",
        "t0=time.time()\n",
        "print('Force-reinstall albumentations 1.3.1 and remove albucore remnants...', flush=True)\n",
        "def run(*args, check=True):\n",
        "    print('>', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=check)\n",
        "\n",
        "# Uninstall both to avoid mixed files\n",
        "run('uninstall', '-y', 'albumentations')\n",
        "run('uninstall', '-y', 'albucore')\n",
        "\n",
        "# Clean any stray site dirs that might shadow\n",
        "for d in (\n",
        "    '/app/.pip-target/albumentations',\n",
        "    '/app/.pip-target/albumentations-1.4.14.dist-info',\n",
        "    '/app/.pip-target/albumentations-1.3.1.dist-info',\n",
        "    '/app/.pip-target/albucore',\n",
        "    '/app/.pip-target/albucore-0.0.33.dist-info',\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d); shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# Force reinstall desired version (no albucore dependency)\n",
        "run('install', 'albumentations==1.3.1', '--no-cache-dir', '--upgrade', '--force-reinstall')\n",
        "\n",
        "import albumentations as A\n",
        "print('albumentations version:', A.__version__)\n",
        "print('Done in %.1fs' % (time.time()-t0), flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "18b24f6d-7645-4f58-8ac3-0272cc367128",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train-only extension to 9 epochs (avoid heavy test inference here)\n",
        "import time\n",
        "t0 = time.time()\n",
        "print('Training fold 0 @256, bs=64, epochs=9 (no test inference at end)...', flush=True)\n",
        "tr_idx, va_idx = folds[0]\n",
        "best_f1 = run_fold(0, tr_idx, va_idx, epochs=9, batch_size=64, accum_steps=4)\n",
        "print('Fold0 training complete. Best val F1:', best_f1, flush=True)\n",
        "print('Elapsed: %.1f min' % ((time.time()-t0)/60.0), flush=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 0 @256, bs=64, epochs=9 (no test inference at end)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n=== Fold 0 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_222/4113945092.py:145: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  mini_va = va_df.groupby('label', group_keys=False).apply(lambda g: g.sample(1, random_state=42))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 0 Loss 11.0847 Elapsed 1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 50 Loss 11.0946 Elapsed 9.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 100 Loss 11.0833 Elapsed 17.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 150 Loss 11.0769 Elapsed 26.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 200 Loss 11.0722 Elapsed 34.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 250 Loss 11.0680 Elapsed 42.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 300 Loss 11.0635 Elapsed 50.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 350 Loss 11.0596 Elapsed 58.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 400 Loss 11.0576 Elapsed 67.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 450 Loss 11.0543 Elapsed 75.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 500 Loss 11.0522 Elapsed 83.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 550 Loss 11.0501 Elapsed 91.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 600 Loss 11.0483 Elapsed 99.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 650 Loss 11.0459 Elapsed 108.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 700 Loss 11.0444 Elapsed 116.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 750 Loss 11.0422 Elapsed 124.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 800 Loss 11.0410 Elapsed 132.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 850 Loss 11.0390 Elapsed 141.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 900 Loss 11.0379 Elapsed 149.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 950 Loss 11.0362 Elapsed 157.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1000 Loss 11.0345 Elapsed 166.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1050 Loss 11.0328 Elapsed 174.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1100 Loss 11.0312 Elapsed 182.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1150 Loss 11.0293 Elapsed 191.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1200 Loss 11.0269 Elapsed 199.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1250 Loss 11.0244 Elapsed 207.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1300 Loss 11.0218 Elapsed 216.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1350 Loss 11.0182 Elapsed 224.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1400 Loss 11.0144 Elapsed 232.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1450 Loss 11.0097 Elapsed 241.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1500 Loss 11.0057 Elapsed 249.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1550 Loss 11.0016 Elapsed 257.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1600 Loss 10.9967 Elapsed 266.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1650 Loss 10.9917 Elapsed 274.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1700 Loss 10.9866 Elapsed 283.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1750 Loss 10.9825 Elapsed 291.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1800 Loss 10.9772 Elapsed 299.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1850 Loss 10.9718 Elapsed 308.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1900 Loss 10.9660 Elapsed 316.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 1950 Loss 10.9603 Elapsed 325.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2000 Loss 10.9551 Elapsed 333.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2050 Loss 10.9495 Elapsed 341.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2100 Loss 10.9437 Elapsed 350.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2150 Loss 10.9374 Elapsed 358.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2200 Loss 10.9324 Elapsed 366.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2250 Loss 10.9254 Elapsed 375.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2300 Loss 10.9196 Elapsed 383.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2350 Loss 10.9137 Elapsed 392.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2400 Loss 10.9078 Elapsed 400.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2450 Loss 10.9018 Elapsed 408.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2500 Loss 10.8953 Elapsed 417.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2550 Loss 10.8895 Elapsed 425.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2600 Loss 10.8836 Elapsed 434.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2650 Loss 10.8777 Elapsed 442.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2700 Loss 10.8716 Elapsed 450.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2750 Loss 10.8653 Elapsed 459.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2800 Loss 10.8582 Elapsed 467.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2850 Loss 10.8516 Elapsed 476.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2900 Loss 10.8445 Elapsed 484.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 2950 Loss 10.8378 Elapsed 492.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3000 Loss 10.8311 Elapsed 501.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3050 Loss 10.8245 Elapsed 509.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3100 Loss 10.8177 Elapsed 518.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3150 Loss 10.8105 Elapsed 526.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3200 Loss 10.8028 Elapsed 534.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3250 Loss 10.7960 Elapsed 543.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3300 Loss 10.7886 Elapsed 551.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3350 Loss 10.7812 Elapsed 560.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3400 Loss 10.7740 Elapsed 568.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3450 Loss 10.7665 Elapsed 576.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3500 Loss 10.7580 Elapsed 585.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3550 Loss 10.7501 Elapsed 593.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3600 Loss 10.7419 Elapsed 602.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3650 Loss 10.7334 Elapsed 610.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3700 Loss 10.7251 Elapsed 619.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3750 Loss 10.7170 Elapsed 627.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3800 Loss 10.7084 Elapsed 635.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3850 Loss 10.6999 Elapsed 644.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3900 Loss 10.6914 Elapsed 652.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 3950 Loss 10.6822 Elapsed 661.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4000 Loss 10.6735 Elapsed 669.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4050 Loss 10.6645 Elapsed 678.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4100 Loss 10.6551 Elapsed 686.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4150 Loss 10.6459 Elapsed 694.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4200 Loss 10.6367 Elapsed 703.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4250 Loss 10.6270 Elapsed 711.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4300 Loss 10.6170 Elapsed 720.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4350 Loss 10.6068 Elapsed 728.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4400 Loss 10.5971 Elapsed 737.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4450 Loss 10.5866 Elapsed 745.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4500 Loss 10.5761 Elapsed 754.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4550 Loss 10.5658 Elapsed 762.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4600 Loss 10.5557 Elapsed 770.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 Step 4650 Loss 10.5455 Elapsed 779.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on mini-val (1/img per class, cap 10k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on capped validation: 500 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1 mini-F1 0.00005 | F1 0.00147 | sel 0.00048 time 839.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best to ckpt_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 0 Loss 9.6302 Elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 50 Loss 10.3585 Elapsed 9.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 100 Loss 10.4840 Elapsed 17.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 150 Loss 10.5256 Elapsed 25.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 200 Loss 10.5332 Elapsed 34.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 250 Loss 10.5341 Elapsed 42.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 300 Loss 10.5231 Elapsed 50.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 350 Loss 10.5196 Elapsed 59.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 400 Loss 10.5110 Elapsed 67.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 450 Loss 10.5008 Elapsed 75.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 500 Loss 10.4918 Elapsed 84.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 550 Loss 10.4786 Elapsed 92.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 600 Loss 10.4654 Elapsed 101.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 650 Loss 10.4506 Elapsed 109.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 700 Loss 10.4343 Elapsed 117.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 750 Loss 10.4185 Elapsed 126.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 800 Loss 10.4021 Elapsed 134.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 850 Loss 10.3879 Elapsed 142.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 900 Loss 10.3741 Elapsed 151.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 950 Loss 10.3607 Elapsed 159.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1000 Loss 10.3433 Elapsed 168.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1050 Loss 10.3280 Elapsed 176.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1100 Loss 10.3098 Elapsed 184.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1150 Loss 10.2950 Elapsed 193.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1200 Loss 10.2768 Elapsed 201.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1250 Loss 10.2594 Elapsed 210.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1300 Loss 10.2435 Elapsed 218.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1350 Loss 10.2272 Elapsed 226.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1400 Loss 10.2110 Elapsed 235.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1450 Loss 10.1951 Elapsed 243.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1500 Loss 10.1776 Elapsed 252.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1550 Loss 10.1600 Elapsed 260.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1600 Loss 10.1424 Elapsed 269.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1650 Loss 10.1272 Elapsed 277.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1700 Loss 10.1119 Elapsed 285.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1750 Loss 10.0970 Elapsed 294.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1800 Loss 10.0808 Elapsed 302.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1850 Loss 10.0660 Elapsed 311.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1900 Loss 10.0505 Elapsed 319.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 1950 Loss 10.0336 Elapsed 328.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2000 Loss 10.0162 Elapsed 336.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2050 Loss 9.9988 Elapsed 344.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2100 Loss 9.9830 Elapsed 353.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2150 Loss 9.9661 Elapsed 361.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2200 Loss 9.9486 Elapsed 370.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2250 Loss 9.9312 Elapsed 378.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2300 Loss 9.9135 Elapsed 386.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2350 Loss 9.8980 Elapsed 395.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2400 Loss 9.8817 Elapsed 403.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2450 Loss 9.8639 Elapsed 412.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2500 Loss 9.8466 Elapsed 420.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2550 Loss 9.8301 Elapsed 428.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2600 Loss 9.8132 Elapsed 437.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2650 Loss 9.7972 Elapsed 445.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2700 Loss 9.7800 Elapsed 454.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2750 Loss 9.7626 Elapsed 462.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2800 Loss 9.7456 Elapsed 470.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2850 Loss 9.7288 Elapsed 479.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2900 Loss 9.7123 Elapsed 487.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 2950 Loss 9.6938 Elapsed 495.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3000 Loss 9.6757 Elapsed 504.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3050 Loss 9.6575 Elapsed 512.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3100 Loss 9.6401 Elapsed 521.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3150 Loss 9.6229 Elapsed 529.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3200 Loss 9.6058 Elapsed 537.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3250 Loss 9.5881 Elapsed 546.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3300 Loss 9.5705 Elapsed 554.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3350 Loss 9.5538 Elapsed 563.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3400 Loss 9.5368 Elapsed 571.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3450 Loss 9.5190 Elapsed 580.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3500 Loss 9.5018 Elapsed 588.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3550 Loss 9.4845 Elapsed 596.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3600 Loss 9.4676 Elapsed 605.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3650 Loss 9.4509 Elapsed 613.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3700 Loss 9.4343 Elapsed 622.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3750 Loss 9.4172 Elapsed 630.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3800 Loss 9.3998 Elapsed 638.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3850 Loss 9.3830 Elapsed 647.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3900 Loss 9.3659 Elapsed 655.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 3950 Loss 9.3488 Elapsed 664.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4000 Loss 9.3319 Elapsed 672.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4050 Loss 9.3152 Elapsed 681.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4100 Loss 9.2975 Elapsed 689.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4150 Loss 9.2811 Elapsed 697.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4200 Loss 9.2649 Elapsed 706.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4250 Loss 9.2473 Elapsed 714.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4300 Loss 9.2300 Elapsed 723.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4350 Loss 9.2131 Elapsed 731.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4400 Loss 9.1973 Elapsed 739.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4450 Loss 9.1802 Elapsed 748.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4500 Loss 9.1630 Elapsed 756.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4550 Loss 9.1471 Elapsed 765.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4600 Loss 9.1296 Elapsed 773.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 Step 4650 Loss 9.1134 Elapsed 782.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on mini-val (1/img per class, cap 10k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on capped validation: 500 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2 mini-F1 0.00346 | F1 0.01624 | sel 0.00729 time 840.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best to ckpt_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 0 Loss 7.5914 Elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 50 Loss 7.5384 Elapsed 8.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 100 Loss 7.5344 Elapsed 17.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 150 Loss 7.4998 Elapsed 25.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 200 Loss 7.4715 Elapsed 34.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 250 Loss 7.4642 Elapsed 42.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 300 Loss 7.4620 Elapsed 50.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 350 Loss 7.4469 Elapsed 59.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 400 Loss 7.4382 Elapsed 67.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 450 Loss 7.4291 Elapsed 75.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 500 Loss 7.4257 Elapsed 84.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 550 Loss 7.4088 Elapsed 92.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 600 Loss 7.3917 Elapsed 101.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 650 Loss 7.3815 Elapsed 109.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 700 Loss 7.3679 Elapsed 117.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 750 Loss 7.3553 Elapsed 126.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 800 Loss 7.3406 Elapsed 134.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 850 Loss 7.3248 Elapsed 143.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 900 Loss 7.3198 Elapsed 151.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 950 Loss 7.3062 Elapsed 159.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1000 Loss 7.2974 Elapsed 168.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1050 Loss 7.2827 Elapsed 176.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1100 Loss 7.2696 Elapsed 184.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1150 Loss 7.2591 Elapsed 193.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1200 Loss 7.2512 Elapsed 201.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1250 Loss 7.2455 Elapsed 210.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1300 Loss 7.2369 Elapsed 218.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1350 Loss 7.2259 Elapsed 226.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1400 Loss 7.2194 Elapsed 235.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1450 Loss 7.2091 Elapsed 243.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1500 Loss 7.1993 Elapsed 252.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1550 Loss 7.1926 Elapsed 260.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1600 Loss 7.1778 Elapsed 269.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1650 Loss 7.1653 Elapsed 277.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1700 Loss 7.1571 Elapsed 285.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1750 Loss 7.1441 Elapsed 294.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1800 Loss 7.1313 Elapsed 302.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1850 Loss 7.1197 Elapsed 311.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1900 Loss 7.1102 Elapsed 319.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 1950 Loss 7.1013 Elapsed 328.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2000 Loss 7.0913 Elapsed 336.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2050 Loss 7.0829 Elapsed 344.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2100 Loss 7.0710 Elapsed 353.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2150 Loss 7.0586 Elapsed 361.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2200 Loss 7.0492 Elapsed 370.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2250 Loss 7.0394 Elapsed 378.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2300 Loss 7.0286 Elapsed 386.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2350 Loss 7.0202 Elapsed 395.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2400 Loss 7.0105 Elapsed 403.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2450 Loss 6.9999 Elapsed 412.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2500 Loss 6.9894 Elapsed 420.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2550 Loss 6.9774 Elapsed 428.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2600 Loss 6.9673 Elapsed 437.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2650 Loss 6.9596 Elapsed 445.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2700 Loss 6.9535 Elapsed 454.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2750 Loss 6.9454 Elapsed 462.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2800 Loss 6.9365 Elapsed 470.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2850 Loss 6.9263 Elapsed 479.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2900 Loss 6.9160 Elapsed 487.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 2950 Loss 6.9047 Elapsed 496.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3000 Loss 6.8936 Elapsed 504.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3050 Loss 6.8857 Elapsed 512.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3100 Loss 6.8750 Elapsed 521.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3150 Loss 6.8632 Elapsed 529.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3200 Loss 6.8536 Elapsed 538.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3250 Loss 6.8444 Elapsed 546.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3300 Loss 6.8372 Elapsed 554.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3350 Loss 6.8318 Elapsed 563.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3400 Loss 6.8238 Elapsed 571.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3450 Loss 6.8156 Elapsed 580.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3500 Loss 6.8080 Elapsed 588.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3550 Loss 6.7978 Elapsed 596.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3600 Loss 6.7881 Elapsed 605.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3650 Loss 6.7806 Elapsed 613.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3700 Loss 6.7731 Elapsed 622.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3750 Loss 6.7644 Elapsed 630.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3800 Loss 6.7554 Elapsed 638.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3850 Loss 6.7457 Elapsed 647.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3900 Loss 6.7383 Elapsed 655.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 3950 Loss 6.7316 Elapsed 664.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4000 Loss 6.7241 Elapsed 672.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4050 Loss 6.7172 Elapsed 680.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4100 Loss 6.7098 Elapsed 689.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4150 Loss 6.7028 Elapsed 697.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4200 Loss 6.6961 Elapsed 706.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4250 Loss 6.6900 Elapsed 714.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4300 Loss 6.6820 Elapsed 723.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4350 Loss 6.6742 Elapsed 731.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4400 Loss 6.6665 Elapsed 739.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4450 Loss 6.6612 Elapsed 748.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4500 Loss 6.6551 Elapsed 756.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4550 Loss 6.6488 Elapsed 765.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4600 Loss 6.6430 Elapsed 773.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 Step 4650 Loss 6.6366 Elapsed 781.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on mini-val (1/img per class, cap 10k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on capped validation: 500 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3 mini-F1 0.03784 | F1 0.02877 | sel 0.03512 time 840.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best to ckpt_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 0 Loss 4.5660 Elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 50 Loss 4.7806 Elapsed 9.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 100 Loss 4.7687 Elapsed 17.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 150 Loss 4.7743 Elapsed 25.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 200 Loss 4.7975 Elapsed 34.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 250 Loss 4.8168 Elapsed 42.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 300 Loss 4.7973 Elapsed 51.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 350 Loss 4.7891 Elapsed 59.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 400 Loss 4.7651 Elapsed 67.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 450 Loss 4.7521 Elapsed 76.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 500 Loss 4.7431 Elapsed 84.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 550 Loss 4.7290 Elapsed 93.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 600 Loss 4.7122 Elapsed 101.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 650 Loss 4.6946 Elapsed 109.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 700 Loss 4.6803 Elapsed 118.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 750 Loss 4.6599 Elapsed 126.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 800 Loss 4.6449 Elapsed 135.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 850 Loss 4.6334 Elapsed 143.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 900 Loss 4.6288 Elapsed 152.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 950 Loss 4.6160 Elapsed 160.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1000 Loss 4.6066 Elapsed 168.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1050 Loss 4.5966 Elapsed 177.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1100 Loss 4.5900 Elapsed 185.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1150 Loss 4.5865 Elapsed 194.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1200 Loss 4.5778 Elapsed 202.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1250 Loss 4.5627 Elapsed 210.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1300 Loss 4.5500 Elapsed 219.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1350 Loss 4.5404 Elapsed 227.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1400 Loss 4.5266 Elapsed 236.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1450 Loss 4.5180 Elapsed 244.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1500 Loss 4.5124 Elapsed 253.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1550 Loss 4.5090 Elapsed 261.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1600 Loss 4.5022 Elapsed 269.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1650 Loss 4.4946 Elapsed 278.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1700 Loss 4.4884 Elapsed 286.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1750 Loss 4.4836 Elapsed 295.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1800 Loss 4.4755 Elapsed 303.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1850 Loss 4.4685 Elapsed 311.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1900 Loss 4.4591 Elapsed 320.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 1950 Loss 4.4513 Elapsed 328.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2000 Loss 4.4440 Elapsed 337.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2050 Loss 4.4343 Elapsed 345.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2100 Loss 4.4235 Elapsed 354.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2150 Loss 4.4133 Elapsed 362.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2200 Loss 4.4027 Elapsed 371.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2250 Loss 4.3920 Elapsed 379.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2300 Loss 4.3803 Elapsed 387.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2350 Loss 4.3733 Elapsed 396.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2400 Loss 4.3666 Elapsed 404.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2450 Loss 4.3601 Elapsed 413.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2500 Loss 4.3557 Elapsed 421.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2550 Loss 4.3495 Elapsed 430.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2600 Loss 4.3433 Elapsed 438.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2650 Loss 4.3342 Elapsed 446.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2700 Loss 4.3289 Elapsed 455.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2750 Loss 4.3253 Elapsed 463.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2800 Loss 4.3209 Elapsed 472.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2850 Loss 4.3171 Elapsed 480.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2900 Loss 4.3139 Elapsed 489.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 2950 Loss 4.3076 Elapsed 497.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3000 Loss 4.3041 Elapsed 505.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3050 Loss 4.3015 Elapsed 514.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3100 Loss 4.3001 Elapsed 522.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3150 Loss 4.2976 Elapsed 531.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3200 Loss 4.2939 Elapsed 539.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3250 Loss 4.2885 Elapsed 548.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3300 Loss 4.2837 Elapsed 556.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3350 Loss 4.2811 Elapsed 564.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3400 Loss 4.2782 Elapsed 573.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3450 Loss 4.2722 Elapsed 581.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3500 Loss 4.2676 Elapsed 590.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3550 Loss 4.2617 Elapsed 598.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3600 Loss 4.2577 Elapsed 606.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3650 Loss 4.2547 Elapsed 615.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3700 Loss 4.2518 Elapsed 623.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3750 Loss 4.2500 Elapsed 632.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3800 Loss 4.2463 Elapsed 640.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3850 Loss 4.2419 Elapsed 649.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3900 Loss 4.2378 Elapsed 657.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 3950 Loss 4.2364 Elapsed 665.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4000 Loss 4.2351 Elapsed 674.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4050 Loss 4.2300 Elapsed 682.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4100 Loss 4.2268 Elapsed 691.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4150 Loss 4.2238 Elapsed 699.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4200 Loss 4.2213 Elapsed 708.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4250 Loss 4.2163 Elapsed 716.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4300 Loss 4.2123 Elapsed 725.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4350 Loss 4.2074 Elapsed 733.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4400 Loss 4.2013 Elapsed 741.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4450 Loss 4.1976 Elapsed 750.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4500 Loss 4.1947 Elapsed 758.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4550 Loss 4.1909 Elapsed 767.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4600 Loss 4.1880 Elapsed 775.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 Step 4650 Loss 4.1831 Elapsed 784.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on mini-val (1/img per class, cap 10k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on capped validation: 500 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4 mini-F1 0.09585 | F1 0.03533 | sel 0.07770 time 842.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best to ckpt_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 0 Loss 3.5854 Elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 50 Loss 3.8799 Elapsed 9.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 100 Loss 3.8344 Elapsed 17.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 150 Loss 3.8555 Elapsed 25.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 200 Loss 3.8387 Elapsed 34.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 250 Loss 3.8132 Elapsed 42.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 300 Loss 3.7717 Elapsed 51.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 350 Loss 3.7310 Elapsed 59.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 400 Loss 3.7032 Elapsed 67.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 450 Loss 3.6796 Elapsed 76.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 500 Loss 3.6727 Elapsed 84.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 550 Loss 3.6748 Elapsed 93.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 600 Loss 3.6894 Elapsed 101.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 650 Loss 3.6990 Elapsed 109.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 700 Loss 3.7101 Elapsed 118.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 750 Loss 3.7196 Elapsed 126.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 800 Loss 3.7303 Elapsed 135.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 850 Loss 3.7352 Elapsed 143.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 900 Loss 3.7270 Elapsed 151.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 950 Loss 3.7260 Elapsed 160.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1000 Loss 3.7208 Elapsed 168.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1050 Loss 3.7166 Elapsed 177.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1100 Loss 3.7132 Elapsed 185.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1150 Loss 3.7165 Elapsed 194.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1200 Loss 3.7142 Elapsed 202.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1250 Loss 3.7040 Elapsed 210.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1300 Loss 3.6935 Elapsed 219.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1350 Loss 3.6862 Elapsed 227.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1400 Loss 3.6789 Elapsed 236.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1450 Loss 3.6658 Elapsed 244.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1500 Loss 3.6572 Elapsed 252.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1550 Loss 3.6480 Elapsed 261.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1600 Loss 3.6438 Elapsed 269.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1650 Loss 3.6404 Elapsed 278.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1700 Loss 3.6383 Elapsed 286.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1750 Loss 3.6351 Elapsed 294.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1800 Loss 3.6312 Elapsed 303.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1850 Loss 3.6290 Elapsed 311.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1900 Loss 3.6272 Elapsed 320.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 1950 Loss 3.6256 Elapsed 328.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2000 Loss 3.6218 Elapsed 337.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2050 Loss 3.6200 Elapsed 345.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2100 Loss 3.6147 Elapsed 354.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2150 Loss 3.6054 Elapsed 362.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2200 Loss 3.5965 Elapsed 370.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2250 Loss 3.5883 Elapsed 379.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2300 Loss 3.5786 Elapsed 387.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2350 Loss 3.5687 Elapsed 396.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2400 Loss 3.5604 Elapsed 404.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2450 Loss 3.5541 Elapsed 413.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2500 Loss 3.5483 Elapsed 421.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2550 Loss 3.5458 Elapsed 429.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2600 Loss 3.5399 Elapsed 438.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2650 Loss 3.5354 Elapsed 446.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2700 Loss 3.5330 Elapsed 455.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2750 Loss 3.5322 Elapsed 463.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2800 Loss 3.5292 Elapsed 472.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2850 Loss 3.5269 Elapsed 480.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2900 Loss 3.5246 Elapsed 488.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 2950 Loss 3.5231 Elapsed 497.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3000 Loss 3.5225 Elapsed 505.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3050 Loss 3.5205 Elapsed 514.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3100 Loss 3.5160 Elapsed 522.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3150 Loss 3.5111 Elapsed 530.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3200 Loss 3.5081 Elapsed 539.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3250 Loss 3.5054 Elapsed 547.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3300 Loss 3.5038 Elapsed 556.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3350 Loss 3.5013 Elapsed 564.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3400 Loss 3.4982 Elapsed 573.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3450 Loss 3.4956 Elapsed 581.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3500 Loss 3.4935 Elapsed 589.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3550 Loss 3.4936 Elapsed 598.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3600 Loss 3.4927 Elapsed 606.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3650 Loss 3.4895 Elapsed 615.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3700 Loss 3.4874 Elapsed 623.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3750 Loss 3.4876 Elapsed 632.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3800 Loss 3.4847 Elapsed 640.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3850 Loss 3.4835 Elapsed 648.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3900 Loss 3.4810 Elapsed 657.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 3950 Loss 3.4782 Elapsed 665.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4000 Loss 3.4770 Elapsed 674.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4050 Loss 3.4744 Elapsed 682.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4100 Loss 3.4715 Elapsed 691.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4150 Loss 3.4664 Elapsed 699.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4200 Loss 3.4611 Elapsed 707.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4250 Loss 3.4586 Elapsed 716.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4300 Loss 3.4557 Elapsed 724.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4350 Loss 3.4526 Elapsed 733.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4400 Loss 3.4508 Elapsed 741.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4450 Loss 3.4500 Elapsed 749.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4500 Loss 3.4469 Elapsed 758.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4550 Loss 3.4440 Elapsed 766.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4600 Loss 3.4403 Elapsed 775.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 Step 4650 Loss 3.4366 Elapsed 783.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on mini-val (1/img per class, cap 10k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on capped validation: 500 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5 mini-F1 0.14155 | F1 0.03933 | sel 0.11088 time 842.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best to ckpt_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 0 Loss 3.1498 Elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 50 Loss 3.1014 Elapsed 9.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 100 Loss 3.0566 Elapsed 17.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 150 Loss 2.9867 Elapsed 25.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 200 Loss 2.9502 Elapsed 34.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 250 Loss 2.9226 Elapsed 42.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 300 Loss 2.9076 Elapsed 51.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 350 Loss 2.8779 Elapsed 59.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 400 Loss 2.8698 Elapsed 67.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 450 Loss 2.8769 Elapsed 76.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 500 Loss 2.8609 Elapsed 84.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 550 Loss 2.8523 Elapsed 93.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 600 Loss 2.8582 Elapsed 101.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 650 Loss 2.8677 Elapsed 110.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 700 Loss 2.8713 Elapsed 118.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 750 Loss 2.8684 Elapsed 126.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 800 Loss 2.8634 Elapsed 135.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 850 Loss 2.8616 Elapsed 143.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 900 Loss 2.8570 Elapsed 152.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 950 Loss 2.8580 Elapsed 160.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1000 Loss 2.8558 Elapsed 168.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1050 Loss 2.8515 Elapsed 177.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1100 Loss 2.8487 Elapsed 185.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1150 Loss 2.8428 Elapsed 194.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1200 Loss 2.8376 Elapsed 202.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1250 Loss 2.8374 Elapsed 210.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1300 Loss 2.8335 Elapsed 219.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1350 Loss 2.8288 Elapsed 227.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1400 Loss 2.8241 Elapsed 236.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1450 Loss 2.8192 Elapsed 244.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1500 Loss 2.8124 Elapsed 252.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1550 Loss 2.8038 Elapsed 261.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1600 Loss 2.7956 Elapsed 269.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1650 Loss 2.7872 Elapsed 278.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1700 Loss 2.7811 Elapsed 286.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1750 Loss 2.7820 Elapsed 294.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1800 Loss 2.7780 Elapsed 303.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1850 Loss 2.7745 Elapsed 311.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1900 Loss 2.7714 Elapsed 320.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 1950 Loss 2.7656 Elapsed 328.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2000 Loss 2.7645 Elapsed 337.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2050 Loss 2.7644 Elapsed 345.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2100 Loss 2.7613 Elapsed 353.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2150 Loss 2.7556 Elapsed 362.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2200 Loss 2.7509 Elapsed 370.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2250 Loss 2.7451 Elapsed 379.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2300 Loss 2.7404 Elapsed 387.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2350 Loss 2.7403 Elapsed 395.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2400 Loss 2.7386 Elapsed 404.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2450 Loss 2.7387 Elapsed 412.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2500 Loss 2.7351 Elapsed 421.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2550 Loss 2.7305 Elapsed 429.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2600 Loss 2.7270 Elapsed 438.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2650 Loss 2.7250 Elapsed 446.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2700 Loss 2.7244 Elapsed 455.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2750 Loss 2.7220 Elapsed 463.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2800 Loss 2.7192 Elapsed 471.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2850 Loss 2.7162 Elapsed 480.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2900 Loss 2.7131 Elapsed 488.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 2950 Loss 2.7126 Elapsed 497.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3000 Loss 2.7112 Elapsed 505.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3050 Loss 2.7076 Elapsed 514.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3100 Loss 2.7036 Elapsed 522.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3150 Loss 2.7008 Elapsed 530.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3200 Loss 2.6993 Elapsed 539.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3250 Loss 2.6963 Elapsed 547.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3300 Loss 2.6943 Elapsed 556.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3350 Loss 2.6927 Elapsed 564.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3400 Loss 2.6891 Elapsed 573.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3450 Loss 2.6860 Elapsed 581.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3500 Loss 2.6813 Elapsed 589.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3550 Loss 2.6794 Elapsed 598.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3600 Loss 2.6763 Elapsed 606.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3650 Loss 2.6740 Elapsed 615.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3700 Loss 2.6720 Elapsed 623.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3750 Loss 2.6699 Elapsed 631.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3800 Loss 2.6698 Elapsed 640.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3850 Loss 2.6668 Elapsed 648.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3900 Loss 2.6656 Elapsed 657.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 3950 Loss 2.6629 Elapsed 665.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4000 Loss 2.6605 Elapsed 673.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4050 Loss 2.6571 Elapsed 682.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4100 Loss 2.6529 Elapsed 690.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4150 Loss 2.6479 Elapsed 699.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4200 Loss 2.6433 Elapsed 707.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4250 Loss 2.6398 Elapsed 715.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4300 Loss 2.6372 Elapsed 724.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4350 Loss 2.6346 Elapsed 732.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4400 Loss 2.6304 Elapsed 741.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4450 Loss 2.6274 Elapsed 749.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4500 Loss 2.6259 Elapsed 758.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4550 Loss 2.6241 Elapsed 766.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4600 Loss 2.6213 Elapsed 774.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 Step 4650 Loss 2.6184 Elapsed 783.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on mini-val (1/img per class, cap 10k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on capped validation: 500 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6 mini-F1 0.18055 | F1 0.04283 | sel 0.13923 time 841.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best to ckpt_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 0 Loss 1.9333 Elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 50 Loss 2.2198 Elapsed 9.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 100 Loss 2.2375 Elapsed 17.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 150 Loss 2.2152 Elapsed 25.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 200 Loss 2.2062 Elapsed 34.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 250 Loss 2.1821 Elapsed 42.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 300 Loss 2.1654 Elapsed 51.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 350 Loss 2.1454 Elapsed 59.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 400 Loss 2.1409 Elapsed 67.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 450 Loss 2.1298 Elapsed 76.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 500 Loss 2.1235 Elapsed 84.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 550 Loss 2.1199 Elapsed 93.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 600 Loss 2.1109 Elapsed 101.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 650 Loss 2.1058 Elapsed 110.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 700 Loss 2.0983 Elapsed 118.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 750 Loss 2.0943 Elapsed 126.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 800 Loss 2.0848 Elapsed 135.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 850 Loss 2.0795 Elapsed 143.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 900 Loss 2.0752 Elapsed 152.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 950 Loss 2.0663 Elapsed 160.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1000 Loss 2.0539 Elapsed 168.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1050 Loss 2.0478 Elapsed 177.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1100 Loss 2.0426 Elapsed 185.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1150 Loss 2.0367 Elapsed 194.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1200 Loss 2.0349 Elapsed 202.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1250 Loss 2.0257 Elapsed 210.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1300 Loss 2.0185 Elapsed 219.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1350 Loss 2.0145 Elapsed 227.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1400 Loss 2.0075 Elapsed 236.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1450 Loss 2.0009 Elapsed 244.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1500 Loss 1.9945 Elapsed 253.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1550 Loss 1.9880 Elapsed 261.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1600 Loss 1.9849 Elapsed 269.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1650 Loss 1.9822 Elapsed 278.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1700 Loss 1.9748 Elapsed 286.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1750 Loss 1.9746 Elapsed 295.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1800 Loss 1.9742 Elapsed 303.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1850 Loss 1.9697 Elapsed 311.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1900 Loss 1.9653 Elapsed 320.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 1950 Loss 1.9599 Elapsed 328.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2000 Loss 1.9564 Elapsed 337.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2050 Loss 1.9537 Elapsed 345.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2100 Loss 1.9501 Elapsed 354.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2150 Loss 1.9489 Elapsed 362.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2200 Loss 1.9442 Elapsed 370.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2250 Loss 1.9419 Elapsed 379.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2300 Loss 1.9396 Elapsed 387.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2350 Loss 1.9391 Elapsed 396.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2400 Loss 1.9362 Elapsed 404.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2450 Loss 1.9345 Elapsed 412.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2500 Loss 1.9324 Elapsed 421.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2550 Loss 1.9284 Elapsed 429.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2600 Loss 1.9248 Elapsed 438.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2650 Loss 1.9229 Elapsed 446.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2700 Loss 1.9208 Elapsed 455.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2750 Loss 1.9177 Elapsed 463.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2800 Loss 1.9167 Elapsed 471.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2850 Loss 1.9133 Elapsed 480.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2900 Loss 1.9096 Elapsed 488.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 2950 Loss 1.9082 Elapsed 497.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3000 Loss 1.9046 Elapsed 505.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3050 Loss 1.9016 Elapsed 514.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3100 Loss 1.8996 Elapsed 522.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3150 Loss 1.8979 Elapsed 530.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3200 Loss 1.8947 Elapsed 539.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3250 Loss 1.8931 Elapsed 547.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3300 Loss 1.8923 Elapsed 556.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3350 Loss 1.8883 Elapsed 564.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3400 Loss 1.8849 Elapsed 573.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3450 Loss 1.8819 Elapsed 581.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3500 Loss 1.8789 Elapsed 589.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3550 Loss 1.8782 Elapsed 598.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3600 Loss 1.8761 Elapsed 606.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3650 Loss 1.8746 Elapsed 615.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3700 Loss 1.8709 Elapsed 623.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3750 Loss 1.8681 Elapsed 631.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3800 Loss 1.8648 Elapsed 640.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3850 Loss 1.8627 Elapsed 648.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3900 Loss 1.8611 Elapsed 657.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 3950 Loss 1.8586 Elapsed 665.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4000 Loss 1.8561 Elapsed 673.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4050 Loss 1.8534 Elapsed 682.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4100 Loss 1.8506 Elapsed 690.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4150 Loss 1.8499 Elapsed 699.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4200 Loss 1.8477 Elapsed 707.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4250 Loss 1.8468 Elapsed 715.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4300 Loss 1.8450 Elapsed 724.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4350 Loss 1.8430 Elapsed 732.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4400 Loss 1.8406 Elapsed 741.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4450 Loss 1.8392 Elapsed 749.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4500 Loss 1.8372 Elapsed 758.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4550 Loss 1.8355 Elapsed 766.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4600 Loss 1.8337 Elapsed 774.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 Step 4650 Loss 1.8323 Elapsed 783.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on mini-val (1/img per class, cap 10k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on capped validation: 500 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7 mini-F1 0.21361 | F1 0.04713 | sel 0.16367 time 841.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best to ckpt_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 0 Loss 1.3532 Elapsed 0.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 50 Loss 1.5759 Elapsed 9.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 100 Loss 1.5673 Elapsed 17.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 150 Loss 1.5584 Elapsed 25.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 200 Loss 1.5500 Elapsed 34.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 250 Loss 1.5319 Elapsed 42.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 300 Loss 1.5097 Elapsed 50.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 350 Loss 1.4916 Elapsed 59.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 400 Loss 1.4713 Elapsed 67.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 450 Loss 1.4644 Elapsed 76.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 500 Loss 1.4572 Elapsed 84.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 550 Loss 1.4529 Elapsed 92.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 600 Loss 1.4499 Elapsed 101.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 650 Loss 1.4421 Elapsed 109.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 700 Loss 1.4332 Elapsed 118.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 750 Loss 1.4265 Elapsed 126.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 800 Loss 1.4210 Elapsed 135.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 850 Loss 1.4162 Elapsed 143.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 900 Loss 1.4150 Elapsed 151.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 950 Loss 1.4120 Elapsed 160.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1000 Loss 1.4107 Elapsed 168.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1050 Loss 1.4016 Elapsed 177.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1100 Loss 1.3964 Elapsed 185.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1150 Loss 1.3911 Elapsed 194.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1200 Loss 1.3846 Elapsed 202.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1250 Loss 1.3800 Elapsed 210.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1300 Loss 1.3750 Elapsed 219.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1350 Loss 1.3688 Elapsed 227.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1400 Loss 1.3650 Elapsed 236.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1450 Loss 1.3606 Elapsed 244.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1500 Loss 1.3572 Elapsed 253.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1550 Loss 1.3530 Elapsed 261.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1600 Loss 1.3493 Elapsed 269.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1650 Loss 1.3476 Elapsed 278.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1700 Loss 1.3444 Elapsed 286.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1750 Loss 1.3425 Elapsed 295.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1800 Loss 1.3397 Elapsed 303.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1850 Loss 1.3351 Elapsed 311.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1900 Loss 1.3317 Elapsed 320.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 1950 Loss 1.3282 Elapsed 328.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2000 Loss 1.3253 Elapsed 337.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2050 Loss 1.3224 Elapsed 345.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2100 Loss 1.3169 Elapsed 354.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2150 Loss 1.3131 Elapsed 362.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2200 Loss 1.3094 Elapsed 370.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2250 Loss 1.3070 Elapsed 379.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2300 Loss 1.3056 Elapsed 387.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2350 Loss 1.3027 Elapsed 396.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2400 Loss 1.2999 Elapsed 404.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2450 Loss 1.2971 Elapsed 412.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2500 Loss 1.2944 Elapsed 421.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2550 Loss 1.2923 Elapsed 429.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2600 Loss 1.2897 Elapsed 438.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2650 Loss 1.2860 Elapsed 446.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2700 Loss 1.2836 Elapsed 455.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2750 Loss 1.2816 Elapsed 463.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2800 Loss 1.2805 Elapsed 471.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2850 Loss 1.2777 Elapsed 480.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2900 Loss 1.2759 Elapsed 488.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 2950 Loss 1.2736 Elapsed 497.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3000 Loss 1.2713 Elapsed 505.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3050 Loss 1.2700 Elapsed 514.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3100 Loss 1.2677 Elapsed 522.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3150 Loss 1.2651 Elapsed 530.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3200 Loss 1.2634 Elapsed 539.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3250 Loss 1.2616 Elapsed 547.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3300 Loss 1.2594 Elapsed 556.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3350 Loss 1.2572 Elapsed 564.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3400 Loss 1.2545 Elapsed 572.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3450 Loss 1.2522 Elapsed 581.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3500 Loss 1.2496 Elapsed 589.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3550 Loss 1.2472 Elapsed 598.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3600 Loss 1.2456 Elapsed 606.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3650 Loss 1.2432 Elapsed 615.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3700 Loss 1.2419 Elapsed 623.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3750 Loss 1.2408 Elapsed 631.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3800 Loss 1.2387 Elapsed 640.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3850 Loss 1.2373 Elapsed 648.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3900 Loss 1.2354 Elapsed 657.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 3950 Loss 1.2342 Elapsed 665.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4000 Loss 1.2328 Elapsed 673.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4050 Loss 1.2302 Elapsed 682.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4100 Loss 1.2282 Elapsed 690.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4150 Loss 1.2261 Elapsed 699.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4200 Loss 1.2245 Elapsed 707.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4250 Loss 1.2234 Elapsed 715.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4300 Loss 1.2214 Elapsed 724.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4350 Loss 1.2198 Elapsed 732.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4400 Loss 1.2175 Elapsed 741.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4450 Loss 1.2160 Elapsed 749.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4500 Loss 1.2141 Elapsed 757.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4550 Loss 1.2125 Elapsed 766.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4600 Loss 1.2104 Elapsed 774.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 Step 4650 Loss 1.2091 Elapsed 783.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on mini-val (1/img per class, cap 10k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on capped validation: 500 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8 mini-F1 0.23056 | F1 0.05117 | sel 0.17674 time 841.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best to ckpt_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 0 Loss 3.0708 Elapsed 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 50 Loss 3.1725 Elapsed 9.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 100 Loss 3.1310 Elapsed 17.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 150 Loss 3.0625 Elapsed 25.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 200 Loss 3.0202 Elapsed 34.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 250 Loss 2.9915 Elapsed 42.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 300 Loss 2.9614 Elapsed 50.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 350 Loss 2.9404 Elapsed 59.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 400 Loss 2.9224 Elapsed 67.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 450 Loss 2.9112 Elapsed 76.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 500 Loss 2.8947 Elapsed 84.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 550 Loss 2.8834 Elapsed 92.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 600 Loss 2.8752 Elapsed 101.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 650 Loss 2.8653 Elapsed 109.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 700 Loss 2.8579 Elapsed 118.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 750 Loss 2.8495 Elapsed 126.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 800 Loss 2.8426 Elapsed 134.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 850 Loss 2.8365 Elapsed 143.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 900 Loss 2.8326 Elapsed 151.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 950 Loss 2.8266 Elapsed 160.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1000 Loss 2.8215 Elapsed 168.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1050 Loss 2.8208 Elapsed 177.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1100 Loss 2.8138 Elapsed 185.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1150 Loss 2.8103 Elapsed 193.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1200 Loss 2.8051 Elapsed 202.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1250 Loss 2.8012 Elapsed 210.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1300 Loss 2.7979 Elapsed 219.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1350 Loss 2.7940 Elapsed 227.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1400 Loss 2.7914 Elapsed 236.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1450 Loss 2.7894 Elapsed 244.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1500 Loss 2.7869 Elapsed 252.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1550 Loss 2.7843 Elapsed 261.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1600 Loss 2.7817 Elapsed 269.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1650 Loss 2.7808 Elapsed 278.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1700 Loss 2.7782 Elapsed 286.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1750 Loss 2.7753 Elapsed 294.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1800 Loss 2.7731 Elapsed 303.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1850 Loss 2.7695 Elapsed 311.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1900 Loss 2.7676 Elapsed 320.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 1950 Loss 2.7655 Elapsed 328.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2000 Loss 2.7640 Elapsed 336.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2050 Loss 2.7620 Elapsed 345.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2100 Loss 2.7608 Elapsed 353.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2150 Loss 2.7586 Elapsed 362.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2200 Loss 2.7569 Elapsed 370.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2250 Loss 2.7552 Elapsed 378.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2300 Loss 2.7537 Elapsed 387.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2350 Loss 2.7521 Elapsed 395.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2400 Loss 2.7510 Elapsed 404.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2450 Loss 2.7483 Elapsed 412.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2500 Loss 2.7460 Elapsed 420.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2550 Loss 2.7443 Elapsed 429.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2600 Loss 2.7429 Elapsed 437.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2650 Loss 2.7409 Elapsed 446.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2700 Loss 2.7392 Elapsed 454.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2750 Loss 2.7379 Elapsed 462.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2800 Loss 2.7377 Elapsed 471.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2850 Loss 2.7364 Elapsed 479.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2900 Loss 2.7346 Elapsed 488.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 2950 Loss 2.7330 Elapsed 496.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 3000 Loss 2.7314 Elapsed 504.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 3050 Loss 2.7295 Elapsed 513.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 3100 Loss 2.7272 Elapsed 521.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 3150 Loss 2.7259 Elapsed 530.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 3200 Loss 2.7243 Elapsed 538.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 3250 Loss 2.7235 Elapsed 546.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9 Step 3300 Loss 2.7221 Elapsed 555.2s\n"
          ]
        }
      ]
    },
    {
      "id": "cebc78e6-d028-46fa-904f-8d5875f438a8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity check: try opening a sample of image paths to confirm I/O works\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random, time\n",
        "from pathlib import Path\n",
        "\n",
        "def check_opens(df, n=500, split='train'):\n",
        "    samp = df.sample(min(n, len(df)), random_state=42).reset_index(drop=True)\n",
        "    ok = 0; fail = 0; failed_paths = []\n",
        "    t0 = time.time()\n",
        "    for i in range(len(samp)):\n",
        "        fp = samp.iloc[i]['file_path']\n",
        "        try:\n",
        "            with Image.open(fp) as im:\n",
        "                im.verify()  # lightweight check\n",
        "            ok += 1\n",
        "        except Exception as e:\n",
        "            fail += 1\n",
        "            if len(failed_paths) < 10:\n",
        "                failed_paths.append((str(fp), str(e)))\n",
        "    print(f\"[{split}] Tried {len(samp)} -> OK {ok}, FAIL {fail}, time {time.time()-t0:.1f}s\", flush=True)\n",
        "    if failed_paths:\n",
        "        print('Sample failures:')\n",
        "        for p,e in failed_paths:\n",
        "            print(' -', p, '|', e)\n",
        "\n",
        "print('=== Image open sanity checks ===', flush=True)\n",
        "check_opens(train_df, n=500, split='train')\n",
        "check_opens(te_imgs, n=200, split='test')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Image open sanity checks ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] Tried 500 -> OK 500, FAIL 0, time 0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test] Tried 200 -> OK 200, FAIL 0, time 0.0s\n"
          ]
        }
      ]
    },
    {
      "id": "2c8f8de2-1ff6-4d16-9242-979a11b580ab",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference from saved best checkpoint for fold 0 and write submission\n",
        "import pandas as pd\n",
        "print('Running inference with ckpt_fold0.pt ...', flush=True)\n",
        "preds = infer_fold(0, batch_size=128)\n",
        "sub_ids = pd.read_csv(SAMPLE_SUB)['Id'].values\n",
        "pred_cat = [lbl2cat[int(x)] for x in preds]\n",
        "sub = pd.DataFrame({'Id': sub_ids, 'Predicted': pred_cat})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('submission.csv written with shape', sub.shape, flush=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference with ckpt_fold0.pt ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_222/3574474352.py:268: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mRunning inference with ckpt_fold0.pt ...\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m preds = \u001b[43minfer_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m sub_ids = pd.read_csv(SAMPLE_SUB)[\u001b[33m'\u001b[39m\u001b[33mId\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m      6\u001b[39m pred_cat = [lbl2cat[\u001b[38;5;28mint\u001b[39m(x)] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m preds]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 304\u001b[39m, in \u001b[36minfer_fold\u001b[39m\u001b[34m(fold, batch_size)\u001b[39m\n\u001b[32m    302\u001b[39m         logits2 = m(imgs_flipped)\n\u001b[32m    303\u001b[39m         logits = (logits1 + logits2) / \u001b[32m2.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         pred_lbl.append(\u001b[43mlogits\u001b[49m\u001b[43m.\u001b[49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.numpy())\n\u001b[32m    305\u001b[39m pred_lbl = np.concatenate(pred_lbl).astype(np.int32)\n\u001b[32m    306\u001b[39m np.save(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtest_predlbl_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npy\u001b[39m\u001b[33m'\u001b[39m, pred_lbl)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "33071eb3-8c9a-42b4-a55f-11f666222fdf",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Retrieval baseline (DINO/ViT features + FAISS flat IP). Prep while classifier trains.\n",
        "import sys, subprocess, math, time, faiss, torch, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "RET_IMG_SIZE = 256\n",
        "ret_tfms = T.Compose([\n",
        "    T.Resize(RET_IMG_SIZE),\n",
        "    T.CenterCrop(RET_IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "class ImageTensorDS(Dataset):\n",
        "    def __init__(self, df, tfms):\n",
        "        self.df = df.reset_index(drop=True); self.tfms = tfms\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        fp = self.df.iloc[i]['file_path']\n",
        "        try:\n",
        "            img = Image.open(fp).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.fromarray(np.zeros((RET_IMG_SIZE, RET_IMG_SIZE,3), np.uint8))\n",
        "        return self.tfms(img), i\n",
        "\n",
        "def build_feat_model():\n",
        "    # Prefer fast/compact backbone first to reduce download/compute\n",
        "    names = [\n",
        "        'vit_base_patch16_224.dino',\n",
        "        'convnext_base.fb_in22k',\n",
        "    ]\n",
        "    last_err = None\n",
        "    for name in names:\n",
        "        try:\n",
        "            m = timm.create_model(name, pretrained=True, num_classes=0)  # features only\n",
        "            m.to(device); m.eval(); m = m.to(memory_format=torch.channels_last)\n",
        "            dummy = torch.zeros(1,3,RET_IMG_SIZE,RET_IMG_SIZE, device=device).to(memory_format=torch.channels_last)\n",
        "            with torch.no_grad(), torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                out = m(dummy)\n",
        "            d = out.shape[-1] if out.ndim==2 else out.flatten(1).shape[-1]\n",
        "            return m, d, name\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            continue\n",
        "    raise RuntimeError(f'No backbone available: {last_err}')\n",
        "\n",
        "def extract_embeddings(model, loader, d):\n",
        "    embs = np.zeros((len(loader.dataset), d), dtype=np.float32)\n",
        "    t0=time.time()\n",
        "    with torch.no_grad():\n",
        "        for b, (imgs, idx) in enumerate(loader):\n",
        "            imgs = imgs.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                out = model(imgs)\n",
        "            if out.ndim>2:\n",
        "                out = out.flatten(1)\n",
        "            out = torch.nn.functional.normalize(out.float(), dim=1)\n",
        "            embs[idx.numpy()] = out.detach().cpu().numpy().astype(np.float32)\n",
        "            if b % 50 == 0:\n",
        "                print(f'Emb batch {b} / {len(loader)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "    return embs\n",
        "\n",
        "def build_prototypes(train_df, per_class=4, batch_size=128):\n",
        "    # Use at most 1 image per class (random) for speed on huge label space\n",
        "    per_class_eff = 1\n",
        "    grp = (train_df.groupby('label', group_keys=False)\n",
        "           .apply(lambda g: g.sample(min(len(g), per_class_eff), random_state=42))\n",
        "           .reset_index(drop=True))\n",
        "    print('Prototype sampling rows:', len(grp), flush=True)\n",
        "    ds = ImageTensorDS(grp, ret_tfms)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=False)\n",
        "    model, d, bname = build_feat_model()\n",
        "    print(f'Feature backbone: {bname}, dim={d}', flush=True)\n",
        "    embs = extract_embeddings(model, dl, d)\n",
        "    # One prototype per class (mean of sampled; with 1, it's the vector itself)\n",
        "    proto_vecs, proto_lbls = [], []\n",
        "    for lbl, sub in grp.groupby('label'):\n",
        "        v = embs[sub.index.values]\n",
        "        proto_vecs.append(v.mean(axis=0))\n",
        "        proto_lbls.append(int(lbl))\n",
        "    proto = np.stack(proto_vecs).astype(np.float32)\n",
        "    proto = proto / np.linalg.norm(proto, axis=1, keepdims=True).clip(1e-9, None)\n",
        "    return proto, np.array(proto_lbls, dtype=np.int32), d, bname\n",
        "\n",
        "def build_faiss_index(proto):\n",
        "    d = proto.shape[1]\n",
        "    index = faiss.IndexFlatIP(d)\n",
        "    index.add(proto)\n",
        "    return index\n",
        "\n",
        "def run_retrieval_submission(per_class=4, test_batch=128):\n",
        "    tr = train_df[['file_path','label']].copy()\n",
        "    te = build_test_df_in_submission_order()\n",
        "    # Build prototypes (internally uses 1 per class for speed)\n",
        "    t0 = time.time()\n",
        "    proto, proto_lbls, d, bname = build_prototypes(tr, per_class=per_class, batch_size=128)\n",
        "    print(f'Prototypes: {len(proto)} built in {time.time()-t0:.1f}s', flush=True)\n",
        "    index = build_faiss_index(proto)\n",
        "    # Test embeddings\n",
        "    ds_te = ImageTensorDS(te, ret_tfms)\n",
        "    dl_te = DataLoader(ds_te, batch_size=min(test_batch, 64), shuffle=False, num_workers=4, pin_memory=True, persistent_workers=False)\n",
        "    model, d2, _ = build_feat_model()\n",
        "    assert d2 == d, 'Backbone mismatch'\n",
        "    t1 = time.time()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for b, (imgs, idx) in enumerate(dl_te):\n",
        "            imgs = imgs.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                out = model(imgs)\n",
        "            if out.ndim>2: out = out.flatten(1)\n",
        "            out = torch.nn.functional.normalize(out.float(), dim=1)\n",
        "            q = out.detach().cpu().numpy().astype(np.float32)\n",
        "            D, I = index.search(q, 1)\n",
        "            lbls = proto_lbls[I[:,0]]\n",
        "            preds.append(lbls)\n",
        "            if b % 50 == 0:\n",
        "                print(f'Test batch {b}/{len(dl_te)} elapsed {time.time()-t1:.1f}s', flush=True)\n",
        "    preds = np.concatenate(preds).astype(np.int32)\n",
        "    print(f'Test queried in {time.time()-t1:.1f}s', flush=True)\n",
        "    pred_cat = [lbl2cat[int(x)] for x in preds]\n",
        "    sub = pd.DataFrame({ 'Id': pd.read_csv(SAMPLE_SUB)['Id'].values, 'Predicted': pred_cat })\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Retrieval submission.csv written:', sub.shape, flush=True)\n",
        "\n",
        "print('Retrieval code ready (uses FAISS IndexFlatIP). To run after deps present: \\n- pip install faiss-cpu (in a separate cell) \\n- run_retrieval_submission(per_class=4)', flush=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieval code ready (uses FAISS IndexFlatIP). To run after deps present: \n- pip install faiss-cpu (in a separate cell) \n- run_retrieval_submission(per_class=4)\n"
          ]
        }
      ]
    },
    {
      "id": "019d37f8-0ed7-44c0-a56e-5a4270c1bfaa",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install retrieval dependencies\n",
        "import sys, subprocess, time, importlib\n",
        "t0=time.time()\n",
        "print('Installing faiss-cpu (and huggingface-hub) under torch constraints...', flush=True)\n",
        "def pip(*args):\n",
        "    print('>', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "pip('install', '-c', 'constraints.txt', 'faiss-cpu', 'huggingface-hub', '--upgrade-strategy', 'only-if-needed')\n",
        "print('Installed in %.1fs' % (time.time()-t0), flush=True)\n",
        "import faiss, timm\n",
        "print('faiss version OK; timm version:', timm.__version__, flush=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing faiss-cpu (and huggingface-hub) under torch constraints...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> install -c constraints.txt faiss-cpu huggingface-hub --upgrade-strategy only-if-needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n  Downloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 31.4/31.4 MB 183.4 MB/s eta 0:00:00\nCollecting huggingface-hub\n  Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 563.3/563.3 KB 492.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy<3.0,>=1.25.0\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 264.1 MB/s eta 0:00:00\nCollecting packaging\n  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 66.5/66.5 KB 350.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting tqdm>=4.42.1\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 78.5/78.5 KB 439.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml>=5.1\n  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 806.6/806.6 KB 358.6 MB/s eta 0:00:00\nCollecting requests\n  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.7/64.7 KB 431.1 MB/s eta 0:00:00\nCollecting hf-xet<2.0.0,>=1.1.3\n  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.2/3.2 MB 123.1 MB/s eta 0:00:00\nCollecting fsspec>=2023.5.0\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 469.0 MB/s eta 0:00:00\nCollecting typing-extensions>=3.7.4.3\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 385.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting idna<4,>=2.5\n  Downloading idna-3.10-py3-none-any.whl (70 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 70.4/70.4 KB 348.2 MB/s eta 0:00:00\nCollecting charset_normalizer<4,>=2\n  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 150.3/150.3 KB 479.1 MB/s eta 0:00:00\nCollecting certifi>=2017.4.17\n  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.2/161.2 KB 497.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting urllib3<3,>=1.21.1\n  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129.8/129.8 KB 472.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: urllib3, typing-extensions, tqdm, pyyaml, packaging, numpy, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, requests, faiss-cpu, huggingface-hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed certifi-2025.8.3 charset_normalizer-3.4.3 faiss-cpu-1.12.0 filelock-3.19.1 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.35.1 idna-3.10 numpy-1.26.4 packaging-25.0 pyyaml-6.0.3 requests-2.32.5 tqdm-4.67.1 typing-extensions-4.15.0 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/huggingface_hub-0.35.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/huggingface_hub already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/requests-2.32.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/requests already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/certifi-2025.8.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/certifi already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/charset_normalizer-3.4.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/charset_normalizer already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/hf_xet-1.1.10.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/hf_xet already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/idna-3.10.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/idna already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging-25.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pyyaml-6.0.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/_yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tqdm-4.67.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tqdm already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/urllib3-2.5.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/urllib3 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installed in 6.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "faiss version OK; timm version: 1.0.9\n"
          ]
        }
      ]
    },
    {
      "id": "38f65fa5-d3a3-47d5-afdf-ec5722ef7b39",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run retrieval baseline to generate a fast submission\n",
        "import time\n",
        "t0=time.time()\n",
        "print('Starting retrieval submission (per_class=4, test_batch=128)...', flush=True)\n",
        "run_retrieval_submission(per_class=4, test_batch=128)\n",
        "print('Retrieval done in %.1f min' % ((time.time()-t0)/60.0), flush=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting retrieval submission (per_class=4, test_batch=128)...\n"
          ]
        }
      ]
    },
    {
      "id": "dce728e5-13e0-428b-8039-92aca65688a3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optimized sharded test inference (no TTA) per expert advice\n",
        "import numpy as np, torch, time, pandas as pd, os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "class TestDatasetSharded(Dataset):\n",
        "    def __init__(self, df, tfms, start=0, end=None):\n",
        "        self.df_full = df.reset_index(drop=True)\n",
        "        self.start = int(start)\n",
        "        self.end = int(end) if end is not None else len(self.df_full)\n",
        "        self.df = self.df_full.iloc[self.start:self.end].reset_index(drop=True)\n",
        "        self.tfms = tfms\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        j = i\n",
        "        fp = self.df.iloc[j]['file_path']\n",
        "        try:\n",
        "            img = Image.open(fp).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.fromarray(np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8))\n",
        "        img = self.tfms(img)\n",
        "        return img, self.start + j\n",
        "\n",
        "def _get_log_priors():\n",
        "    # Compute log class priors from training data (align to NUM_CLASSES)\n",
        "    counts = train_df['label'].value_counts().reindex(range(NUM_CLASSES), fill_value=0).values.astype(np.float32)\n",
        "    counts = np.maximum(counts, 1.0)\n",
        "    logp = np.log(counts)\n",
        "    t = torch.from_numpy(logp).to(device)\n",
        "    return t\n",
        "\n",
        "def infer_fold_sharded(fold=0, batch_size=256, chunk_size=50000, out_memmap='test_predlbl.int32', tau=1.0):\n",
        "    # tau: strength of prior correction; 0 disables\n",
        "    ckpt_path = f'ckpt_fold{fold}.pt'\n",
        "    print(f'Loading checkpoint: {ckpt_path}', flush=True)\n",
        "    state = torch.load(ckpt_path, map_location='cpu')\n",
        "    model = build_model()\n",
        "    model.load_state_dict(state['model'], strict=True)\n",
        "    ema = ModelEmaV2(model, decay=0.999, device=device)\n",
        "    if 'ema' in state:\n",
        "        ema.load_state_dict(state['ema'], strict=False)\n",
        "    m = ema.module if 'ema' in state else model\n",
        "    m.eval()\n",
        "    test_df = build_test_df_in_submission_order()\n",
        "    N = len(test_df)\n",
        "    print('Test size:', N, flush=True)\n",
        "\n",
        "    # Prepare/resume memmap\n",
        "    mode = 'r+' if os.path.exists(out_memmap) else 'w+'\n",
        "    mm = np.memmap(out_memmap, dtype='int32', mode=mode, shape=(N,))\n",
        "\n",
        "    # Dataloader params per expert\n",
        "    dl_kwargs = dict(batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True,\n",
        "                     persistent_workers=False, prefetch_factor=4, drop_last=False)\n",
        "    t_all = time.time()\n",
        "    written = 0\n",
        "    prior = _get_log_priors() if tau and tau > 0 else None\n",
        "    with torch.inference_mode():\n",
        "        for s in range(0, N, chunk_size):\n",
        "            e = min(s + chunk_size, N)\n",
        "            print(f'Chunk {s}:{e} ({e-s})', flush=True)\n",
        "            ds = TestDatasetSharded(test_df, val_tfms, start=s, end=e)\n",
        "            dl = DataLoader(ds, **dl_kwargs)\n",
        "            t0 = time.time()\n",
        "            for b, (imgs, idxs) in enumerate(dl):\n",
        "                imgs = imgs.to(device, non_blocking=True, memory_format=torch.channels_last)\n",
        "                with torch.amp.autocast('cuda', dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
        "                    logits = m(imgs)\n",
        "                    if prior is not None:\n",
        "                        logits = logits - float(tau) * prior\n",
        "                pred = logits.argmax(1).detach().cpu().numpy().astype(np.int32)\n",
        "                mm[idxs.numpy()] = pred\n",
        "                written += len(pred)\n",
        "                if b % 50 == 0:\n",
        "                    print(f'  batch {b}/{len(dl)} wrote {written}/{N} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "            mm.flush()\n",
        "            Path('last_done.txt').write_text(str(e))\n",
        "            print(f'Chunk {s}:{e} done in {time.time()-t0:.1f}s (total {time.time()-t_all:.1f}s)', flush=True)\n",
        "    del mm\n",
        "    # Map to category ids and write submission\n",
        "    preds = np.memmap(out_memmap, dtype='int32', mode='r', shape=(N,))\n",
        "    pred_cat = [lbl2cat[int(x)] for x in preds]\n",
        "    sub = pd.DataFrame({'Id': pd.read_csv(SAMPLE_SUB)['Id'].values, 'Predicted': pred_cat})\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('submission.csv written with shape', sub.shape, 'total time %.1fs' % (time.time()-t_all), flush=True)\n",
        "    return 'submission.csv'\n",
        "\n",
        "print('Sharded inference utility ready: call infer_fold_sharded(fold=0, batch_size=256, chunk_size=50000, tau=1.0) after training.', flush=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharded inference utility ready: call infer_fold_sharded(fold=0, batch_size=256, chunk_size=50000, tau=1.0) after training.\n"
          ]
        }
      ]
    },
    {
      "id": "f619a5da-ec92-4b70-ad31-b1537e31ce4f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Launch sharded inference (no TTA) from best fold-0 checkpoint\n",
        "import os, time, pandas as pd\n",
        "t0=time.time()\n",
        "print('Starting sharded inference: fold=0, bs=256, chunk=50k, tau=1.0', flush=True)\n",
        "out = infer_fold_sharded(fold=0, batch_size=256, chunk_size=50000, tau=1.0)\n",
        "assert os.path.exists('submission.csv'), 'submission.csv not found after inference'\n",
        "sub = pd.read_csv('submission.csv')\n",
        "print('submission.csv ready:', sub.shape, 'Elapsed: %.1fs' % (time.time()-t0), flush=True)\n",
        "print(sub.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting sharded inference: fold=0, bs=256, chunk=50k, tau=1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint: ckpt_fold0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_222/793291016.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test size: 477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk 0:50000 (50000)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}