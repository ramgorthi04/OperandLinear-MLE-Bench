{
  "cells": [
    {
      "id": "19b89a55-4d27-4c02-a335-5483f1667cd3",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Herbarium 2021 - FGVC8: Medal Plan v1\n",
        "\n",
        "Objectives:\n",
        "- Establish a fast, correct baseline and produce a valid submission quickly.\n",
        "- Build reliable CV mirroring test and iterate to medal via stronger backbones/augs and ensembling.\n",
        "\n",
        "Environment:\n",
        "- GPU confirmed available (A10, CUDA 12.x). Will install torch cu121 + timm + albumentations.\n",
        "\n",
        "Data understanding:\n",
        "- Train: ~1.78M images, ~64.5k species (long tail). Test: ~478k images.\n",
        "- Metadata: COCO-like lists for images/annotations; categories length ~64.5k.\n",
        "- Images are stored under train/images/<shard>/* and test/images/<shard>/*.\n",
        "\n",
        "Validation:\n",
        "- Stratified KFold by species_id. Start with 1-fold holdout smoke, then 5-fold.\n",
        "- Track macro-F1 OOF; save per-class stats; ensure deterministic splits saved to disk.\n",
        "\n",
        "Baseline model:\n",
        "- timm pretrained classifier; start convnext_tiny/efficientnet_b0 at 224px, AMP, label smoothing.\n",
        "- Augs: RandomResizedCrop(224), HFlip, ColorJitter light. BalancedSampler or class-weighted loss.\n",
        "- Loss: CrossEntropy with label smoothing; consider focal loss if needed.\n",
        "- Optim: AdamW, cosine LR, warmup; early stopping; EMA optional.\n",
        "\n",
        "Scaling:\n",
        "- Increase resolution to 384/448; stronger augs (RandAug, MixUp/CutMix).\n",
        "- Backbones: convnext_base/large; efficientnet_v2_s/m; eva02_tiny if available.\n",
        "- Class reweighting/sampling for long-tail; fine-tune head+last stages first, then full.\n",
        "\n",
        "Efficiency:\n",
        "- Cache train/test filelists and class map; num_workers tuned; pin_memory; prefetch factor.\n",
        "- Log elapsed times per epoch/fold; save OOF logits and test logits to .npy for blending.\n",
        "\n",
        "Submission:\n",
        "- Predict top-1 species_id per test image; ensure mapping aligns with sample_submission Id order.\n",
        "\n",
        "Expert questions:\n",
        "- Best-performing backbones/resolutions for this dataset under time constraints?\n",
        "- Preferred sampling vs loss strategy for long-tail (CB loss vs focal vs LDAM)?\n",
        "- Any known metadata pitfalls (e.g., institution leakage) and recommended CV protocol?\n",
        "- Ensembling approaches that moved LB here?\n",
        "\n",
        "Next steps:\n",
        "1) Install exact cu121 torch stack + deps.\n",
        "2) Build filelist from metadata, label encoder, and a tiny dataloader smoke run.\n",
        "3) Train a 1-fold baseline at 224px; produce a first submission.\n",
        "4) Request expert review before scaling training."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "d55263fa-3d11-4def-ab19-11affcd49338",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, json, time, subprocess, sys, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True).stdout\n",
        "\n",
        "print('Checking GPU with nvidia-smi...\\n', flush=True)\n",
        "print(run(['bash','-lc','nvidia-smi || true']))\n",
        "\n",
        "root = Path.cwd()\n",
        "print('CWD:', root)\n",
        "\n",
        "data_root = root\n",
        "train_dir = data_root / 'train'\n",
        "test_dir = data_root / 'test'\n",
        "print('Train dir exists:', train_dir.exists(), ' Test dir exists:', test_dir.exists())\n",
        "\n",
        "# List top-level files\n",
        "print('Top-level files:', [p.name for p in data_root.iterdir()])\n",
        "\n",
        "# Inspect metadata files\n",
        "def load_json(p):\n",
        "    with open(p, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "train_meta_path = train_dir / 'metadata.json'\n",
        "test_meta_path = test_dir / 'metadata.json'\n",
        "train_meta = load_json(train_meta_path)\n",
        "test_meta = load_json(test_meta_path)\n",
        "\n",
        "def brief_meta(meta, name):\n",
        "    keys = list(meta.keys())[:10]\n",
        "    print(f'{name} keys (first 10):', keys)\n",
        "    # Common fields often include annotations, images, licenses, dataset, etc.\n",
        "    for k in ['annotations','images','licenses','info','categories','species','image_dir','dataset','annotations_path']:\n",
        "        if k in meta:\n",
        "            v = meta[k]\n",
        "            if isinstance(v, list):\n",
        "                print(f'  {k}: list len={len(v)}')\n",
        "            elif isinstance(v, dict):\n",
        "                print(f'  {k}: dict keys={list(v.keys())[:10]}')\n",
        "            else:\n",
        "                print(f'  {k}: type={type(v).__name__}')\n",
        "\n",
        "print('\\nTrain metadata:')\n",
        "brief_meta(train_meta, 'train_meta')\n",
        "print('\\nTest metadata:')\n",
        "brief_meta(test_meta, 'test_meta')\n",
        "\n",
        "# Sample few image subfolders\n",
        "train_img_root = train_dir / 'images'\n",
        "test_img_root = test_dir / 'images'\n",
        "def sample_dirs(p, n=5):\n",
        "    if not p.exists():\n",
        "        return []\n",
        "    return [d.name for d in list(p.iterdir()) if d.is_dir()][:n]\n",
        "\n",
        "print('\\nSample train image subdirs:', sample_dirs(train_img_root))\n",
        "print('Sample test image subdirs:', sample_dirs(test_img_root))\n",
        "\n",
        "# Check sample_submission format\n",
        "ss_path = data_root / 'sample_submission.csv'\n",
        "if ss_path.exists():\n",
        "    import pandas as pd\n",
        "    ss = pd.read_csv(ss_path)\n",
        "    print('\\nsample_submission.csv head:')\n",
        "    print(ss.head())\n",
        "    print('Columns:', ss.columns.tolist(), ' Shape:', ss.shape)\n",
        "else:\n",
        "    print('sample_submission.csv not found!')\n",
        "\n",
        "print('\\nEnvironment check complete. If GPU missing above, we will exit in the next step.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking GPU with nvidia-smi...\n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 29 03:39:57 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\nCWD: /var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751\nTrain dir exists: True  Test dir exists: True\nTop-level files: ['sample_submission.csv', '.00_eda_and_planning_kernel_state.json', 'docker_run.log', 'requirements.txt', 'test', 'submission.csv', 'train', 'agent_metadata', 'task.txt', '00_eda_and_planning.ipynb', 'description.md']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nTrain metadata:\ntrain_meta keys (first 10): ['annotations', 'categories', 'images', 'info', 'institutions', 'licenses']\n  annotations: list len=1779953\n  images: list len=1779953\n  licenses: list len=3\n  info: dict keys=['contributor', 'date_created', 'description', 'url', 'version', 'year']\n  categories: list len=64500\n\nTest metadata:\ntest_meta keys (first 10): ['images', 'info', 'licenses']\n  images: list len=477806\n  licenses: list len=3\n  info: dict keys=['contributor', 'date_created', 'description', 'url', 'version', 'year']\n\nSample train image subdirs: ['544', '036', '392', '519', '110']\nSample test image subdirs: ['036', '392', '110', '037', '375']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nsample_submission.csv head:\n   Id  Predicted\n0   0          0\n1   1          0\n2   2          0\n3   3          0\n4   4          0\nColumns: ['Id', 'Predicted']  Shape: (477806, 2)\n\nEnvironment check complete. If GPU missing above, we will exit in the next step.\n"
          ]
        }
      ]
    },
    {
      "id": "1f514173-1d1c-461d-8b6f-40ca5cbcf951",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "def verify_image_paths(meta, base_dir, n=8, name='train'):\n",
        "    print(f'\\nVerifying {name} image paths...')\n",
        "    idxs = list(range(min(len(meta['images']), 1)))\n",
        "    while len(idxs) < n and len(idxs) < len(meta['images']):\n",
        "        r = random.randrange(len(meta['images']))\n",
        "        if r not in idxs:\n",
        "            idxs.append(r)\n",
        "    ok = 0\n",
        "    for i in idxs:\n",
        "        rel = meta['images'][i]['file_name']\n",
        "        # file_name is relative to split root (e.g., 'images/604/92/xxxx.jpg')\n",
        "        if rel.startswith('images/'):\n",
        "            p = base_dir / rel\n",
        "        else:\n",
        "            # Fallback: assume already under images/ directory provided separately\n",
        "            p = (base_dir / 'images') / rel\n",
        "        exists = p.exists()\n",
        "        print(f'  idx={i} rel={rel} -> path={p} exists={exists}')\n",
        "        if exists and ok == 0:\n",
        "            try:\n",
        "                im = Image.open(p)\n",
        "                print('    opened:', im.size, im.mode)\n",
        "                im.close()\n",
        "                ok += 1\n",
        "            except Exception as e:\n",
        "                print('    open failed:', e)\n",
        "    return\n",
        "\n",
        "verify_image_paths(train_meta, train_dir, n=8, name='train')\n",
        "verify_image_paths(test_meta, test_dir, n=8, name='test')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nVerifying train image paths...\n  idx=0 rel=images/604/92/1608432.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/train/images/604/92/1608432.jpg exists=True\n    opened: (671, 1000) RGB\n  idx=199934 rel=images/577/03/2213991.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/train/images/577/03/2213991.jpg exists=True\n  idx=339915 rel=images/422/13/1522494.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/train/images/422/13/1522494.jpg exists=True\n  idx=541572 rel=images/589/41/386076.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/train/images/589/41/386076.jpg exists=True\n  idx=299819 rel=images/291/50/1564602.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/train/images/291/50/1564602.jpg exists=True\n  idx=384492 rel=images/433/13/2124494.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/train/images/433/13/2124494.jpg exists=True\n  idx=374632 rel=images/632/17/483327.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/train/images/632/17/483327.jpg exists=True\n  idx=1250728 rel=images/347/03/902666.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/train/images/347/03/902666.jpg exists=True\n\nVerifying test image paths...\n  idx=0 rel=images/000/0.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/test/images/000/0.jpg exists=True\n    opened: (666, 1000) RGB\n  idx=406789 rel=images/406/406789.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/test/images/406/406789.jpg exists=True\n  idx=298183 rel=images/298/298183.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/test/images/298/298183.jpg exists=True\n  idx=213888 rel=images/213/213888.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/test/images/213/213888.jpg exists=True\n  idx=172509 rel=images/172/172509.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/test/images/172/172509.jpg exists=True\n  idx=98629 rel=images/098/98629.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/test/images/098/98629.jpg exists=True\n  idx=265706 rel=images/265/265706.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/test/images/265/265706.jpg exists=True\n  idx=477446 rel=images/477/477446.jpg -> path=/var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/test/images/477/477446.jpg exists=True\n"
          ]
        }
      ]
    },
    {
      "id": "2d976abf-7f2a-4e9f-a50f-3541ee64646d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Fallback baseline: predict the most frequent category_id from train annotations for all test rows\n",
        "ann = train_meta['annotations']\n",
        "cnt = Counter(a['category_id'] for a in ann)\n",
        "top_cat, top_freq = cnt.most_common(1)[0]\n",
        "print('Most frequent category_id:', top_cat, 'freq:', top_freq)\n",
        "\n",
        "# Build submission in test image order (Id is row index matching test_meta['images'] order)\n",
        "n_test = len(test_meta['images'])\n",
        "sub = pd.DataFrame({'Id': range(n_test), 'Predicted': [top_cat]*n_test})\n",
        "sub_path = Path('submission.csv')\n",
        "sub.to_csv(sub_path, index=False)\n",
        "print('Wrote', sub_path.resolve(), 'shape:', sub.shape)\n",
        "print(sub.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent category_id: 42811 freq: 2647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote /var/lib/simon/agent_run_states/herbarium-2021-fgvc8-20250929-022751/submission.csv shape: (477806, 2)\n   Id  Predicted\n0   0      42811\n1   1      42811\n2   2      42811\n3   3      42811\n4   4      42811\n"
          ]
        }
      ]
    },
    {
      "id": "f9b21d5e-2619-4ede-9041-ac9389ebddfe",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import itertools\n",
        "import collections\n",
        "import pandas as pd\n",
        "\n",
        "def inspect_image_records(meta, name='train', n=3):\n",
        "    imgs = meta['images']\n",
        "    print(f'\\n{name} images[0] keys:', list(imgs[0].keys()))\n",
        "    for i in range(min(n, len(imgs))):\n",
        "        rec = imgs[i]\n",
        "        sample = {k: rec[k] for k in list(rec.keys())[:10]}\n",
        "        print(f'  {name}[{i}] sample:', sample)\n",
        "    # key presence frequencies (first 50 keys aggregated)\n",
        "    key_counts = collections.Counter(itertools.chain.from_iterable([list(d.keys()) for d in imgs[:5000]]))\n",
        "    print(f'{name} key frequencies (top 20):', key_counts.most_common(20))\n",
        "\n",
        "def inspect_annotation_records(meta, name='train', n=3):\n",
        "    if 'annotations' not in meta:\n",
        "        print(f'\\n{name} has no annotations')\n",
        "        return\n",
        "    anns = meta['annotations']\n",
        "    print(f'\\n{name} annotations[0] keys:', list(anns[0].keys()))\n",
        "    for i in range(min(n, len(anns))):\n",
        "        rec = anns[i]\n",
        "        sample = {k: rec[k] for k in list(rec.keys())[:10]}\n",
        "        print(f'  {name}_ann[{i}] sample:', sample)\n",
        "\n",
        "inspect_image_records(train_meta, 'train', n=2)\n",
        "inspect_annotation_records(train_meta, 'train', n=2)\n",
        "inspect_image_records(test_meta, 'test', n=2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ntrain images[0] keys: ['file_name', 'height', 'id', 'license', 'width']\n  train[0] sample: {'file_name': 'images/604/92/1608432.jpg', 'height': 1000, 'id': 1608432, 'license': 0, 'width': 671}\n  train[1] sample: {'file_name': 'images/604/92/796948.jpg', 'height': 1000, 'id': 796948, 'license': 0, 'width': 678}\ntrain key frequencies (top 20): [('file_name', 5000), ('height', 5000), ('id', 5000), ('license', 5000), ('width', 5000)]\n\ntrain annotations[0] keys: ['category_id', 'id', 'image_id', 'institution_id']\n  train_ann[0] sample: {'category_id': 60492, 'id': 1608432, 'image_id': 1608432, 'institution_id': 0}\n  train_ann[1] sample: {'category_id': 60492, 'id': 796948, 'image_id': 796948, 'institution_id': 0}\n\ntest images[0] keys: ['file_name', 'height', 'id', 'license', 'width']\n  test[0] sample: {'file_name': 'images/000/0.jpg', 'height': 1000, 'id': '0', 'license': 0, 'width': 666}\n  test[1] sample: {'file_name': 'images/000/1.jpg', 'height': 1000, 'id': '1', 'license': 0, 'width': 672}\ntest key frequencies (top 20): [('file_name', 5000), ('height', 5000), ('id', 5000), ('license', 5000), ('width', 5000)]\n"
          ]
        }
      ]
    },
    {
      "id": "fe42d305-6c0c-4046-bf25-0b29e960c14f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Build (width,height) -> top category_id mapping from train\n",
        "img_recs = {img['id']: (img['width'], img['height']) for img in train_meta['images']}\n",
        "wh_to_cats = defaultdict(Counter)\n",
        "for ann in train_meta['annotations']:\n",
        "    img_id = ann['image_id']\n",
        "    wh = img_recs.get(img_id, None)\n",
        "    if wh is None:\n",
        "        continue\n",
        "    wh_to_cats[wh][ann['category_id']] += 1\n",
        "\n",
        "# For each (w,h), pick most common category\n",
        "wh_to_topcat = {wh: cnt.most_common(1)[0][0] for wh, cnt in wh_to_cats.items()}\n",
        "print('Unique (w,h) keys:', len(wh_to_topcat))\n",
        "\n",
        "# Global fallback\n",
        "global_cnt = Counter(a['category_id'] for a in train_meta['annotations'])\n",
        "global_top = global_cnt.most_common(1)[0][0]\n",
        "print('Global top category:', global_top)\n",
        "\n",
        "# Build submission using test (w,h) -> mapped category, else global\n",
        "preds = []\n",
        "for rec in test_meta['images']:\n",
        "    wh = (rec['width'], rec['height'])\n",
        "    cat = wh_to_topcat.get(wh, global_top)\n",
        "    preds.append(cat)\n",
        "\n",
        "sub_wh = pd.DataFrame({'Id': range(len(preds)), 'Predicted': preds})\n",
        "sub_wh.to_csv('submission.csv', index=False)\n",
        "print('submission.csv written with (w,h)-based priors. Shape:', sub_wh.shape)\n",
        "print(sub_wh.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique (w,h) keys: 507\nGlobal top category: 42811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written with (w,h)-based priors. Shape: (477806, 2)\n   Id  Predicted\n0   0      42811\n1   1      25497\n2   2      49885\n3   3      42811\n4   4       5954\n"
          ]
        }
      ]
    },
    {
      "id": "55d7ec44-0a8d-42af-b8cf-b3c3b440fa58",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Improved metadata-only baseline: backoff (w,h) -> w -> global\n",
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "img_recs = {img['id']: (img['width'], img['height']) for img in train_meta['images']}\n",
        "wh_to_cats = defaultdict(Counter)\n",
        "w_to_cats = defaultdict(Counter)\n",
        "for ann in train_meta['annotations']:\n",
        "    img_id = ann['image_id']\n",
        "    wh = img_recs.get(img_id, None)\n",
        "    if wh is None:\n",
        "        continue\n",
        "    w,h = wh\n",
        "    wh_to_cats[wh][ann['category_id']] += 1\n",
        "    w_to_cats[w][ann['category_id']] += 1\n",
        "\n",
        "wh_to_top = {k: v.most_common(1)[0][0] for k,v in wh_to_cats.items()}\n",
        "w_to_top = {k: v.most_common(1)[0][0] for k,v in w_to_cats.items()}\n",
        "global_top = Counter(a['category_id'] for a in train_meta['annotations']).most_common(1)[0][0]\n",
        "print('Sizes: wh_keys', len(wh_to_top), ' w_keys', len(w_to_top), ' global_top', global_top)\n",
        "\n",
        "preds = []\n",
        "for rec in test_meta['images']:\n",
        "    w,h = rec['width'], rec['height']\n",
        "    cat = wh_to_top.get((w,h))\n",
        "    if cat is None:\n",
        "        cat = w_to_top.get(w, global_top)\n",
        "    preds.append(cat)\n",
        "\n",
        "sub = pd.DataFrame({'Id': range(len(preds)), 'Predicted': preds})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv with backoff strategy. Shape:', sub.shape)\n",
        "print(sub.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sizes: wh_keys 507  w_keys 446  global_top 42811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv with backoff strategy. Shape: (477806, 2)\n   Id  Predicted\n0   0      42811\n1   1      25497\n2   2      49885\n3   3      42811\n4   4       5954\n"
          ]
        }
      ]
    },
    {
      "id": "3596d47d-7bd4-475b-b8f2-9d95657b831e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Metadata-only baseline v3: infer institution by (w,h) -> predict institution's top category, with backoffs\n",
        "import pandas as pd\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "# Build image_id -> (w,h)\n",
        "img_wh = {img['id']: (img['width'], img['height']) for img in train_meta['images']}\n",
        "\n",
        "# Build (w,h) -> institution counts and institution -> category counts\n",
        "wh_to_inst = defaultdict(Counter)\n",
        "inst_to_cat = defaultdict(Counter)\n",
        "for ann in train_meta['annotations']:\n",
        "    img_id = ann['image_id']\n",
        "    wh = img_wh.get(img_id)\n",
        "    if wh is None:\n",
        "        continue\n",
        "    inst = ann.get('institution_id', None)\n",
        "    if inst is not None:\n",
        "        wh_to_inst[wh][inst] += 1\n",
        "        inst_to_cat[inst][ann['category_id']] += 1\n",
        "\n",
        "# Top institution per (w,h) and top category per institution\n",
        "wh_to_top_inst = {wh: cnt.most_common(1)[0][0] for wh, cnt in wh_to_inst.items()}\n",
        "inst_to_top_cat = {inst: cnt.most_common(1)[0][0] for inst, cnt in inst_to_cat.items()}\n",
        "\n",
        "# Backoff tables from prior baseline\n",
        "w_to_cats = defaultdict(Counter)\n",
        "for ann in train_meta['annotations']:\n",
        "    wh = img_wh.get(ann['image_id'])\n",
        "    if wh is None:\n",
        "        continue\n",
        "    w_to_cats[wh[0]][ann['category_id']] += 1\n",
        "w_to_top = {k: v.most_common(1)[0][0] for k,v in w_to_cats.items()}\n",
        "global_top = Counter(a['category_id'] for a in train_meta['annotations']).most_common(1)[0][0]\n",
        "\n",
        "# Predict for test\n",
        "preds = []\n",
        "for rec in test_meta['images']:\n",
        "    wh = (rec['width'], rec['height'])\n",
        "    cat = None\n",
        "    inst = wh_to_top_inst.get(wh)\n",
        "    if inst is not None:\n",
        "        cat = inst_to_top_cat.get(inst)\n",
        "    if cat is None:\n",
        "        # backoff to width-only\n",
        "        cat = w_to_top.get(wh[0])\n",
        "    if cat is None:\n",
        "        cat = global_top\n",
        "    preds.append(cat)\n",
        "\n",
        "sub = pd.DataFrame({'Id': range(len(preds)), 'Predicted': preds})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv using inferred institution-by-(w,h) with backoffs. Shape:', sub.shape)\n",
        "print(sub.head())\n",
        "print('Tables: wh_to_top_inst:', len(wh_to_top_inst), ' inst_to_top_cat:', len(inst_to_top_cat), ' w_keys:', len(w_to_top))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv using inferred institution-by-(w,h) with backoffs. Shape: (477806, 2)\n   Id  Predicted\n0   0      42811\n1   1      42811\n2   2      42811\n3   3      42811\n4   4      42811\nTables: wh_to_top_inst: 507  inst_to_top_cat: 5  w_keys: 446\n"
          ]
        }
      ]
    },
    {
      "id": "bad9a93d-19ca-4a51-8761-d235867cb0b7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install CUDA 12.1 torch stack and deps; verify GPU\n",
        "import os, sys, subprocess, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def pip(*args):\n",
        "    print('> pip', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Uninstall any existing torch stack (idempotent)\n",
        "for pkg in ('torch','torchvision','torchaudio'):\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "\n",
        "# Clean stray site dirs that can shadow correct wheels\n",
        "for d in (\n",
        "    '/app/.pip-target/torch',\n",
        "    '/app/.pip-target/torchvision',\n",
        "    '/app/.pip-target/torchaudio',\n",
        "    '/app/.pip-target/torch-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torchvision-0.23.0.dist-info',\n",
        "    '/app/.pip-target/torchaudio-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torch-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchvision-0.19.1.dist-info',\n",
        "    '/app/.pip-target/torchaudio-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchgen',\n",
        "    '/app/.pip-target/functorch',\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d, flush=True)\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# Install exact cu121 torch stack\n",
        "pip('install',\n",
        "    '--index-url', 'https://download.pytorch.org/whl/cu121',\n",
        "    '--extra-index-url', 'https://pypi.org/simple',\n",
        "    'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1')\n",
        "\n",
        "# Freeze torch versions\n",
        "Path('constraints.txt').write_text(\n",
        "    'torch==2.4.1\\n'\n",
        "    'torchvision==0.19.1\\n'\n",
        "    'torchaudio==2.4.1\\n'\n",
        ")\n",
        "\n",
        "# Install non-torch deps without upgrading torch\n",
        "pip('install', '-c', 'constraints.txt',\n",
        "    'timm==1.0.9',\n",
        "    'albumentations==1.4.10',\n",
        "    'opencv-python-headless==4.10.0.84',\n",
        "    'pandas', 'scikit-learn', 'numpy', 'tqdm',\n",
        "    '--upgrade-strategy', 'only-if-needed')\n",
        "\n",
        "import torch\n",
        "print('torch:', torch.__version__, 'built CUDA:', getattr(torch.version, 'cuda', None), flush=True)\n",
        "print('CUDA available:', torch.cuda.is_available(), flush=True)\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0), flush=True)\n",
        "assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f'Wrong CUDA build: {torch.version.cuda}'\n",
        "assert torch.cuda.is_available(), 'CUDA not available'\n",
        "print('Torch stack installed and verified.', flush=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchvision as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install --index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.org/simple torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 561.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 309.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 235.2 MB/s eta 0:00:00\nCollecting networkx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 55.3 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 518.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 517.7 MB/s eta 0:00:00\nCollecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 348.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 325.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 233.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 64.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 184.1 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 242.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 447.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 266.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 142.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 254.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 269.9 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 427.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 427.8 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 131.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 255.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 152.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 118.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 521.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.3 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install -c constraints.txt timm==1.0.9 albumentations==1.4.10 opencv-python-headless==4.10.0.84 pandas scikit-learn numpy tqdm --upgrade-strategy only-if-needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==1.0.9\n  Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.3/2.3 MB 66.1 MB/s eta 0:00:00\nCollecting albumentations==1.4.10\n  Downloading albumentations-1.4.10-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.9/161.9 KB 336.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless==4.10.0.84\n  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 49.9/49.9 MB 211.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas\n  Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12.4/12.4 MB 265.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 9.7/9.7 MB 209.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 167.2 MB/s eta 0:00:00\nCollecting tqdm\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 78.5/78.5 KB 339.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_hub\n  Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 563.3/563.3 KB 513.3 MB/s eta 0:00:00\nCollecting pyyaml\n  Downloading pyyaml-6.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (806 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 806.6/806.6 KB 416.0 MB/s eta 0:00:00\nCollecting torch\n  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 797.1/797.1 MB 286.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting safetensors\n  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 485.8/485.8 KB 323.7 MB/s eta 0:00:00\nCollecting torchvision\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.0/7.0 MB 262.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy>=1.10.0\n  Downloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35.9/35.9 MB 203.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albucore>=0.0.11\n  Downloading albucore-0.0.33-py3-none-any.whl (18 kB)\nCollecting pydantic>=2.7.0\n  Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 444.9/444.9 KB 546.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.9.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 423.8 MB/s eta 0:00:00\nCollecting scikit-image>=0.21.0\n  Downloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.8/14.8 MB 113.5 MB/s eta 0:00:00\nCollecting python-dateutil>=2.8.2\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 229.9/229.9 KB 496.4 MB/s eta 0:00:00\nCollecting tzdata>=2022.7\n  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 347.8/347.8 KB 539.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytz>=2020.1\n  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 509.2/509.2 KB 532.1 MB/s eta 0:00:00\nCollecting threadpoolctl>=3.1.0\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nCollecting joblib>=1.2.0\n  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 308.4/308.4 KB 537.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting simsimd>=5.9.2\n  Downloading simsimd-6.5.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.1/1.1 MB 273.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stringzilla>=3.10.4\n  Downloading stringzilla-4.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (496 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 496.5/496.5 KB 239.6 MB/s eta 0:00:00\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nCollecting typing-inspection>=0.4.0\n  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic-core==2.33.2\n  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 351.9 MB/s eta 0:00:00\nCollecting six>=1.5\n  Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nCollecting imageio!=2.35.0,>=2.33\n  Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 315.8/315.8 KB 509.7 MB/s eta 0:00:00\nCollecting tifffile>=2022.8.12\n  Downloading tifffile-2025.9.20-py3-none-any.whl (230 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 230.1/230.1 KB 478.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lazy-loader>=0.4\n  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\nCollecting networkx>=3.0\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 553.3 MB/s eta 0:00:00\nCollecting packaging>=21\n  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 66.5/66.5 KB 363.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow>=10.1\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 568.1 MB/s eta 0:00:00\nCollecting fsspec>=2023.5.0\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 501.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests\n  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.7/64.7 KB 429.1 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting hf-xet<2.0.0,>=1.1.3\n  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.2/3.2 MB 471.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 179.6 MB/s eta 0:00:00\nCollecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 165.1 MB/s eta 0:00:00\nCollecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 213.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 229.3 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 127.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 201.2 MB/s eta 0:00:00\nCollecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 197.1 MB/s eta 0:00:00\nCollecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 267.9 MB/s eta 0:00:00\nCollecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 469.2 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 165.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 224.1 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 492.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 196.8 MB/s eta 0:00:00\nCollecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 446.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 77.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\nCollecting certifi>=2017.4.17\n  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.2/161.2 KB 524.2 MB/s eta 0:00:00\nCollecting urllib3<3,>=1.21.1\n  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129.8/129.8 KB 466.6 MB/s eta 0:00:00\nCollecting idna<4,>=2.5\n  Downloading idna-3.10-py3-none-any.whl (70 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 70.4/70.4 KB 450.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting charset_normalizer<4,>=2\n  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 150.3/150.3 KB 512.9 MB/s eta 0:00:00\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 539.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: simsimd, pytz, mpmath, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, stringzilla, six, safetensors, pyyaml, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, joblib, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, annotated-types, typing-inspection, triton, tifffile, scipy, requests, python-dateutil, pydantic-core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lazy-loader, jinja2, imageio, scikit-learn, scikit-image, pydantic, pandas, nvidia-cusolver-cu12, huggingface_hub, albucore, torch, albumentations, torchvision, timm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.3 albucore-0.0.33 albumentations-1.4.10 annotated-types-0.7.0 certifi-2025.8.3 charset_normalizer-3.4.3 filelock-3.19.1 fsspec-2025.9.0 hf-xet-1.1.10 huggingface_hub-0.35.1 idna-3.10 imageio-2.37.0 jinja2-3.1.6 joblib-1.5.2 lazy-loader-0.4 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 opencv-python-headless-4.10.0.84 packaging-25.0 pandas-2.3.2 pillow-11.3.0 pydantic-2.11.9 pydantic-core-2.33.2 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 requests-2.32.5 safetensors-0.6.2 scikit-image-0.25.2 scikit-learn-1.7.2 scipy-1.16.2 simsimd-6.5.3 six-1.17.0 stringzilla-4.0.14 sympy-1.14.0 threadpoolctl-3.6.0 tifffile-2025.9.20 timm-1.0.9 torch-2.4.1 torchvision-0.19.1 tqdm-4.67.1 triton-3.0.0 typing-extensions-4.15.0 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe-3.0.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 built CUDA: 12.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: NVIDIA A10-24Q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch stack installed and verified.\n"
          ]
        }
      ]
    },
    {
      "id": "0a425992-ddce-480e-b7d4-4a157ba32c40",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build train/test DataFrames with file paths and label mapping; 80/20 stratified split\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import json, time\n",
        "\n",
        "t0 = time.time()\n",
        "print('Building train dataframe from metadata...')\n",
        "\n",
        "# Image info map: image_id -> (path, width, height)\n",
        "img_map = {}\n",
        "for rec in train_meta['images']:\n",
        "    img_map[rec['id']] = (train_dir / rec['file_name'], rec['width'], rec['height'])\n",
        "\n",
        "paths = []\n",
        "widths = []\n",
        "heights = []\n",
        "cat_ids = []\n",
        "img_ids = []\n",
        "inst_ids = []\n",
        "\n",
        "ann = train_meta['annotations']\n",
        "for a in ann:\n",
        "    iid = a['image_id']\n",
        "    pwh = img_map.get(iid)\n",
        "    if pwh is None:\n",
        "        continue\n",
        "    p, w, h = pwh\n",
        "    paths.append(str(p))\n",
        "    widths.append(w)\n",
        "    heights.append(h)\n",
        "    cat_ids.append(a['category_id'])\n",
        "    img_ids.append(iid)\n",
        "    inst_ids.append(a.get('institution_id', -1))\n",
        "\n",
        "train_df = pd.DataFrame({\n",
        "    'image_id': img_ids,\n",
        "    'file_path': paths,\n",
        "    'width': widths,\n",
        "    'height': heights,\n",
        "    'category_id': cat_ids,\n",
        "    'institution_id': inst_ids,\n",
        "})\n",
        "print('train_df shape:', train_df.shape, 'unique cats:', train_df['category_id'].nunique())\n",
        "print(train_df.head())\n",
        "\n",
        "# Label mapping cat_id -> idx and inverse\n",
        "unique_cats = sorted(train_df['category_id'].unique())\n",
        "cat2idx = {c:i for i,c in enumerate(unique_cats)}\n",
        "idx2cat = {i:c for c,i in cat2idx.items()}\n",
        "train_df['label_idx'] = train_df['category_id'].map(cat2idx)\n",
        "print('Label space size C =', len(unique_cats))\n",
        "\n",
        "# Save mappings\n",
        "with open('cat2idx.json','w') as f:\n",
        "    json.dump({str(k): int(v) for k,v in cat2idx.items()}, f)\n",
        "with open('idx2cat.json','w') as f:\n",
        "    json.dump({str(k): int(v) for k,v in idx2cat.items()}, f)\n",
        "print('Saved cat2idx.json and idx2cat.json')\n",
        "\n",
        "print('Building test dataframe...')\n",
        "t_paths = []\n",
        "t_widths = []\n",
        "t_heights = []\n",
        "t_ids = []\n",
        "for rec in test_meta['images']:\n",
        "    t_paths.append(str(test_dir / rec['file_name']))\n",
        "    t_widths.append(rec['width'])\n",
        "    t_heights.append(rec['height'])\n",
        "    t_ids.append(int(rec['id']))\n",
        "test_df = pd.DataFrame({\n",
        "    'Id': t_ids,\n",
        "    'file_path': t_paths,\n",
        "    'width': t_widths,\n",
        "    'height': t_heights,\n",
        "})\n",
        "test_df = test_df.sort_values('Id').reset_index(drop=True)\n",
        "print('test_df shape:', test_df.shape)\n",
        "print(test_df.head())\n",
        "\n",
        "# 80/20 stratified split\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "train_idx, val_idx = next(sss.split(train_df, train_df['label_idx']))\n",
        "trn_split = train_df.iloc[train_idx].reset_index(drop=True)\n",
        "val_split = train_df.iloc[val_idx].reset_index(drop=True)\n",
        "print('Split sizes:', trn_split.shape, val_split.shape)\n",
        "print('Class counts (train split) top5:\\n', trn_split['label_idx'].value_counts().head())\n",
        "print('Class counts (val split) top5:\\n', val_split['label_idx'].value_counts().head())\n",
        "\n",
        "# Persist splits to speed up future runs\n",
        "trn_split.to_pickle('train_split.pkl')\n",
        "val_split.to_pickle('val_split.pkl')\n",
        "test_df.to_pickle('test_df.pkl')\n",
        "print('Saved splits to train_split.pkl, val_split.pkl, test_df.pkl')\n",
        "print('Done. Elapsed: %.1f s' % (time.time()-t0))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building train dataframe from metadata...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df shape: (1779953, 6) unique cats: 64500\n   image_id                                          file_path  width  height  \\\n0   1608432  /var/lib/simon/agent_run_states/herbarium-2021...    671    1000   \n1    796948  /var/lib/simon/agent_run_states/herbarium-2021...    678    1000   \n2    994447  /var/lib/simon/agent_run_states/herbarium-2021...    671    1000   \n3   1110611  /var/lib/simon/agent_run_states/herbarium-2021...    678    1000   \n4   1769046  /var/lib/simon/agent_run_states/herbarium-2021...    678    1000   \n\n   category_id  institution_id  \n0        60492               0  \n1        60492               0  \n2        60492               0  \n3        60492               0  \n4        60492               0  \nLabel space size C = 64500\nSaved cat2idx.json and idx2cat.json\nBuilding test dataframe...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_df shape: (477806, 4)\n   Id                                          file_path  width  height\n0   0  /var/lib/simon/agent_run_states/herbarium-2021...    666    1000\n1   1  /var/lib/simon/agent_run_states/herbarium-2021...    672    1000\n2   2  /var/lib/simon/agent_run_states/herbarium-2021...    669    1000\n3   3  /var/lib/simon/agent_run_states/herbarium-2021...    666    1000\n4   4  /var/lib/simon/agent_run_states/herbarium-2021...    675    1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# 80/20 stratified split\u001b[39;00m\n\u001b[32m     83\u001b[39m sss = StratifiedShuffleSplit(n_splits=\u001b[32m1\u001b[39m, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m train_idx, val_idx = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msss\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel_idx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m trn_split = train_df.iloc[train_idx].reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     86\u001b[39m val_split = train_df.iloc[val_idx].reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/sklearn/model_selection/_split.py:1927\u001b[39m, in \u001b[36mBaseShuffleSplit.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   1897\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[32m   1898\u001b[39m \n\u001b[32m   1899\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1924\u001b[39m \u001b[33;03mto an integer.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1926\u001b[39m X, y, groups = indexable(X, y, groups)\n\u001b[32m-> \u001b[39m\u001b[32m1927\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1928\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/sklearn/model_selection/_split.py:2342\u001b[39m, in \u001b[36mStratifiedShuffleSplit._iter_indices\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m   2340\u001b[39m class_counts = np.bincount(y_indices)\n\u001b[32m   2341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.min(class_counts) < \u001b[32m2\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2342\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2343\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe least populated class in y has only 1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2344\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m member, which is too few. The minimum\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2345\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m number of groups for any class cannot\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2346\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m be less than 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2347\u001b[39m     )\n\u001b[32m   2349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train < n_classes:\n\u001b[32m   2350\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2351\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m should be greater or \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2352\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % (n_train, n_classes)\n\u001b[32m   2353\u001b[39m     )\n",
            "\u001b[31mValueError\u001b[39m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
          ]
        }
      ]
    },
    {
      "id": "88054005-0784-4bd2-b126-8312482be86f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Safe 80/20 split handling rare classes (freq < 2 go to train only), then persist\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "print('Creating safe stratified split (classes with <2 samples kept in train only)...')\n",
        "\n",
        "# Compute class frequencies\n",
        "freq = train_df['label_idx'].value_counts()\n",
        "mask_strat = train_df['label_idx'].map(freq) >= 2\n",
        "df_strat = train_df[mask_strat].reset_index(drop=True)\n",
        "df_rare = train_df[~mask_strat].reset_index(drop=True)\n",
        "print('Stratifiable samples:', df_strat.shape[0], ' Rare samples:', df_rare.shape[0])\n",
        "\n",
        "# Stratified split on classes with at least 2 samples\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "tr_idx, va_idx = next(sss.split(df_strat, df_strat['label_idx']))\n",
        "tr_strat = df_strat.iloc[tr_idx].reset_index(drop=True)\n",
        "va_strat = df_strat.iloc[va_idx].reset_index(drop=True)\n",
        "\n",
        "# Combine: put all rare classes into train only\n",
        "trn_split = pd.concat([tr_strat, df_rare], axis=0).reset_index(drop=True)\n",
        "val_split = va_strat\n",
        "\n",
        "print('Final split sizes:', trn_split.shape, val_split.shape)\n",
        "print('Train unique classes:', trn_split['label_idx'].nunique(), ' Val unique classes:', val_split['label_idx'].nunique())\n",
        "\n",
        "# Persist splits\n",
        "trn_split.to_pickle('train_split.pkl')\n",
        "val_split.to_pickle('val_split.pkl')\n",
        "test_df.to_pickle('test_df.pkl')\n",
        "print('Saved splits to train_split.pkl, val_split.pkl, test_df.pkl')\n",
        "print('Done. Elapsed: %.1f s' % (time.time()-t0))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating safe stratified split (classes with <2 samples kept in train only)...\nStratifiable samples: 1772208  Rare samples: 7745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final split sizes: (1425511, 7) (354442, 7)\nTrain unique classes: 64500  Val unique classes: 51308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved splits to train_split.pkl, val_split.pkl, test_df.pkl\nDone. Elapsed: 1.6 s\n"
          ]
        }
      ]
    },
    {
      "id": "64cf8eff-6adb-48a7-8e89-9eee3a998079",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dataset, model, and training loop (ConvNeXt-Base @384, CE+LS, AMP, balanced sampler) - torchvision transforms\n",
        "import math, time, json, os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.metrics import f1_score\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load splits\n",
        "trn_split = pd.read_pickle('train_split.pkl')\n",
        "val_split = pd.read_pickle('val_split.pkl')\n",
        "test_df = pd.read_pickle('test_df.pkl')\n",
        "with open('idx2cat.json','r') as f:\n",
        "    idx2cat = {int(k): int(v) for k,v in json.load(f).items()}\n",
        "\n",
        "IMG_SIZE = 384\n",
        "BATCH_SIZE = 16  # safer for A10 with convnext_base@384\n",
        "EPOCHS = 1  # smoke test first\n",
        "MAX_STEPS_PER_EPOCH = 1000  # faster smoke epoch\n",
        "MAX_VAL_STEPS = 200  # limit validation batches for speed\n",
        "LR = 2e-4\n",
        "WD = 1e-4\n",
        "LS_EPS = 0.1\n",
        "SEED = 42\n",
        "MODEL_NAME = 'convnext_base.fb_in22k_ft_in1k'\n",
        "NUM_WORKERS = min(8, os.cpu_count() or 8)\n",
        "\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "train_tfms = T.Compose([\n",
        "    T.RandomResizedCrop(size=IMG_SIZE, scale=(0.7, 1.0), ratio=(0.7, 1.4)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean, std),\n",
        "])\n",
        "val_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "class ImgDS(Dataset):\n",
        "    def __init__(self, df, tfm, label_col='label_idx'):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tfm = tfm\n",
        "        self.has_label = label_col in df.columns\n",
        "        self.label_col = label_col\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        p = r['file_path']\n",
        "        try:\n",
        "            img = Image.open(p).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.fromarray(np.ones((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)*255)\n",
        "        x = self.tfm(img)\n",
        "        if self.has_label:\n",
        "            y = int(r[self.label_col])\n",
        "            return x, y\n",
        "        else:\n",
        "            return x, int(r['Id'])\n",
        "\n",
        "# Balanced sampler weights ~ 1/sqrt(freq)\n",
        "cls_counts = trn_split['label_idx'].value_counts().to_dict()\n",
        "weights = trn_split['label_idx'].map(lambda c: 1.0/ math.sqrt(cls_counts.get(c,1))).astype('float64').values\n",
        "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "\n",
        "train_ds = ImgDS(trn_split, train_tfms)\n",
        "val_ds = ImgDS(val_split, val_tfms)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "num_classes = len(idx2cat)\n",
        "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=num_classes)\n",
        "model.to(device)\n",
        "\n",
        "class LabelSmoothingCE(nn.Module):\n",
        "    def __init__(self, eps=0.1):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "    def forward(self, logits, target):\n",
        "        n = logits.size(-1)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        loss = -(log_probs.gather(dim=-1, index=target.unsqueeze(1)).squeeze(1))\n",
        "        loss = (1 - self.eps) * loss - self.eps * log_probs.mean(dim=-1)\n",
        "        return loss.mean()\n",
        "\n",
        "criterion = LabelSmoothingCE(LS_EPS)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "num_steps = EPOCHS * min(MAX_STEPS_PER_EPOCH, math.ceil(len(train_loader)))\n",
        "warmup_steps = int(0.05 * num_steps)\n",
        "\n",
        "def cosine_warmup(step):\n",
        "    if step < warmup_steps:\n",
        "        return step / max(1, warmup_steps)\n",
        "    p = (step - warmup_steps) / max(1, (num_steps - warmup_steps))\n",
        "    return 0.5 * (1 + math.cos(math.pi * p))\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, cosine_warmup)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
        "\n",
        "def validate(model, loader, max_steps=None):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    targs = []\n",
        "    t0 = time.time()\n",
        "    with torch.no_grad():\n",
        "        for it, (xb, yb) in enumerate(loader):\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(True):\n",
        "                logits = model(xb)\n",
        "            pred = logits.argmax(dim=1)\n",
        "            preds.append(pred.detach().cpu().numpy())\n",
        "            targs.append(yb.detach().cpu().numpy())\n",
        "            if max_steps is not None and (it+1) >= max_steps:\n",
        "                break\n",
        "    preds = np.concatenate(preds)\n",
        "    targs = np.concatenate(targs)\n",
        "    f1 = f1_score(targs, preds, average='macro')\n",
        "    print(f'Validate: macro-F1={f1:.6f}  n={len(targs)}  batches={it+1}  elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    return f1\n",
        "\n",
        "best_f1 = -1.0\n",
        "best_path = 'model_convnext_base_384_best.pth'\n",
        "global_step = 0\n",
        "t_epoch0 = time.time()\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    t0 = time.time()\n",
        "    for it, (xb, yb) in enumerate(train_loader):\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(True):\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "        running += loss.item()\n",
        "        global_step += 1\n",
        "        if (it+1) % 200 == 0:\n",
        "            print(f'E{epoch} It{it+1} loss={running/(it+1):.4f} lr={scheduler.get_last_lr()[0]:.6f} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "        if (it+1) >= MAX_STEPS_PER_EPOCH:\n",
        "            print(f'Reached MAX_STEPS_PER_EPOCH={MAX_STEPS_PER_EPOCH}, breaking epoch early.', flush=True)\n",
        "            break\n",
        "    print(f'Epoch {epoch} train_loss={running/max(1,(it+1)):.4f} epoch_time={time.time()-t0:.1f}s', flush=True)\n",
        "    f1 = validate(model, val_loader, max_steps=MAX_VAL_STEPS)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save({'model': model.state_dict(), 'f1': best_f1}, best_path)\n",
        "        print('Saved best checkpoint:', best_path, 'F1=', best_f1, flush=True)\n",
        "\n",
        "# Safety: save checkpoint even if no improvement recorded\n",
        "if best_f1 < 0:\n",
        "    torch.save({'model': model.state_dict(), 'f1': best_f1}, best_path)\n",
        "    print('Saved checkpoint without val improvement:', best_path, flush=True)\n",
        "print(f'Training done. Best val macro-F1={best_f1:.6f}. Total elapsed={time.time()-t_epoch0:.1f}s', flush=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/convnext_base.fb_in22k_ft_in1k)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._hub:[timm/convnext_base.fb_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:timm.models._builder:Missing keys (head.fc.weight, head.fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_107/2340922128.py:115: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_107/2340922128.py:151: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(True):\n/app/.pip-target/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It200 loss=11.1348 lr=0.000188 elapsed=45.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It400 loss=11.1062 lr=0.000140 elapsed=90.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It600 loss=11.0909 lr=0.000075 elapsed=136.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It800 loss=11.0841 lr=0.000021 elapsed=181.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It1000 loss=11.0754 lr=0.000000 elapsed=227.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reached MAX_STEPS_PER_EPOCH=1000, breaking epoch early.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train_loss=11.0754 epoch_time=227.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_107/2340922128.py:126: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(True):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validate: macro-F1=0.000000  n=3200  batches=200  elapsed=14.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best checkpoint: model_convnext_base_384_best.pth F1= 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done. Best val macro-F1=0.000000. Total elapsed=241.9s\n"
          ]
        }
      ]
    },
    {
      "id": "2cdc3e8c-d049-4499-8b98-7558c2684109",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference: fast single-view + tau tuning on subset -> submission.csv\n",
        "import math, time, json, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score\n",
        "import timm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load artifacts\n",
        "val_split = pd.read_pickle('val_split.pkl')\n",
        "trn_split = pd.read_pickle('train_split.pkl')\n",
        "test_df = pd.read_pickle('test_df.pkl')\n",
        "with open('idx2cat.json','r') as f:\n",
        "    idx2cat = {int(k): int(v) for k,v in json.load(f).items()}\n",
        "num_classes = len(idx2cat)\n",
        "\n",
        "# Faster inference size\n",
        "IMG_SIZE = 320  # faster than 384; convnext can accept variable sizes\n",
        "MODEL_NAME = 'convnext_base.fb_in22k_ft_in1k'\n",
        "ckpt_path = 'model_convnext_base_384_best.pth'\n",
        "\n",
        "# Transforms\n",
        "val_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "def load_model():\n",
        "    model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=num_classes)\n",
        "    ck = torch.load(ckpt_path, map_location='cpu')\n",
        "    model.load_state_dict(ck['model'], strict=True)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def infer_logits_paths(model, paths, batch_size=64, log_every=500):\n",
        "    logits_all = []\n",
        "    n = len(paths)\n",
        "    for i in range(0, n, batch_size):\n",
        "        batch_paths = paths[i:i+batch_size]\n",
        "        imgs = []\n",
        "        for p in batch_paths:\n",
        "            try:\n",
        "                img = Image.open(p).convert('RGB')\n",
        "            except Exception:\n",
        "                img = Image.fromarray(np.ones((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)*255)\n",
        "            imgs.append(val_tfms(img))\n",
        "        xb = torch.stack(imgs).to(device, non_blocking=True)\n",
        "        with torch.no_grad(), torch.cuda.amp.autocast(True):\n",
        "            l = model(xb)  # single-view (no TTA) for speed\n",
        "        logits_all.append(l.float().cpu().numpy())\n",
        "        if ((i//batch_size)+1) % log_every == 0:\n",
        "            print(f'Infer progress: {i+len(batch_paths)}/{n}', flush=True)\n",
        "    return np.concatenate(logits_all, axis=0)\n",
        "\n",
        "# Compute class priors from training split\n",
        "counts = trn_split['label_idx'].value_counts().sort_index()\n",
        "priors = counts.reindex(range(num_classes), fill_value=1).values.astype(np.float64)\n",
        "priors = priors / priors.sum()\n",
        "log_priors = np.log(priors + 1e-12)\n",
        "\n",
        "# Validate tau on a subset of val split for speed\n",
        "model = load_model()\n",
        "VAL_CAP = 5000  # limit val samples\n",
        "val_paths = val_split['file_path'].tolist()[:VAL_CAP]\n",
        "val_y = val_split['label_idx'].values[:VAL_CAP]\n",
        "print(f'Running validation inference to tune tau on {len(val_paths)} samples...', flush=True)\n",
        "val_logits = infer_logits_paths(model, val_paths, batch_size=64, log_every=50)\n",
        "\n",
        "best_tau, best_f1 = 0.0, -1.0\n",
        "for tau in [0.5, 1.0, 1.5]:\n",
        "    adj = val_logits - tau * log_priors[None, :]\n",
        "    pred = adj.argmax(axis=1)\n",
        "    f1 = f1_score(val_y, pred, average='macro')\n",
        "    print(f'tau={tau:.2f} val macro-F1={f1:.6f}', flush=True)\n",
        "    if f1 > best_f1:\n",
        "        best_f1, best_tau = f1, tau\n",
        "print('Best tau:', best_tau, 'Best val F1:', best_f1, flush=True)\n",
        "\n",
        "# Test inference (may take time; single-view, larger batch)\n",
        "print('Running test inference...', flush=True)\n",
        "test_paths = test_df['file_path'].tolist()\n",
        "test_logits = infer_logits_paths(model, test_paths, batch_size=64, log_every=500)\n",
        "test_adj = test_logits - best_tau * log_priors[None, :]\n",
        "test_pred_idx = test_adj.argmax(axis=1)\n",
        "test_pred_cat = [idx2cat[int(i)] for i in test_pred_idx]\n",
        "\n",
        "sub = pd.DataFrame({'Id': test_df['Id'].values, 'Predicted': test_pred_cat})\n",
        "sub = sub.sort_values('Id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('submission.csv written. Shape:', sub.shape, 'Head:\\n', sub.head())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_107/1380778307.py:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ck = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running validation inference to tune tau on 5000 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_107/1380778307.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.no_grad(), torch.cuda.amp.autocast(True):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 3200/5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=0.50 val macro-F1=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=1.00 val macro-F1=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=1.50 val macro-F1=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best tau: 0.5 Best val F1: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running test inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_107/1380778307.py:55: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.no_grad(), torch.cuda.amp.autocast(True):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 32000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 64000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 96000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 128000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 160000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 192000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 224000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 256000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 288000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 320000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 352000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 384000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 416000/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer progress: 448000/477806\n"
          ]
        }
      ]
    },
    {
      "id": "07a40cac-7ccc-46e5-a818-0a60688d29de",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# NCC (Nearest Class Centroid) frozen-feature baseline with tau-prior adjustment (K-per-class sampling)\n",
        "import os, time, json, math, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score\n",
        "import timm\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load splits & label maps\n",
        "trn_split = pd.read_pickle('train_split.pkl')\n",
        "val_split = pd.read_pickle('val_split.pkl')\n",
        "test_df   = pd.read_pickle('test_df.pkl')\n",
        "with open('idx2cat.json','r') as f:\n",
        "    idx2cat = {int(k): int(v) for k,v in json.load(f).items()}\n",
        "with open('cat2idx.json','r') as f:\n",
        "    cat2idx = {int(k): int(v) for k,v in json.load(f).items()}\n",
        "num_classes = len(idx2cat)\n",
        "\n",
        "# Model / transforms\n",
        "MODEL_NAME = 'convnext_base.fb_in22k_ft_in1k'\n",
        "IMG_SIZE = 320  # 320 for throughput; consider 384 later\n",
        "BATCH = 128     # adjust if OOM; A10 should handle ~128 at 320 for features\n",
        "NUM_WORKERS = min(8, os.cpu_count() or 8)\n",
        "TWO_VIEW = False  # start single-view for speed; can enable later\n",
        "K_PER_CLASS = 4   # sample up to K images per class for centroids (fast build)\n",
        "\n",
        "base_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "class ImgDS(Dataset):\n",
        "    def __init__(self, df, has_label, flip=False):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.has_label = has_label\n",
        "        self.flip = flip\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        p = r['file_path']\n",
        "        try:\n",
        "            img = Image.open(p).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.fromarray(np.ones((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)*255)\n",
        "        if self.flip:\n",
        "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        x = base_tfms(img)\n",
        "        if self.has_label:\n",
        "            return x, int(r['label_idx'])\n",
        "        else:\n",
        "            return x, int(r['Id'])\n",
        "\n",
        "def build_feature_model():\n",
        "    # num_classes=0 returns pooled features in timm\n",
        "    model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=0, global_pool='avg')\n",
        "    model.eval().to(device)\n",
        "    return model\n",
        "\n",
        "@torch.inference_mode()\n",
        "def extract_features(model, df, batch=BATCH, two_view=TWO_VIEW, log_every=5000):\n",
        "    ds0 = ImgDS(df, has_label=('label_idx' in df.columns), flip=False)\n",
        "    dl0 = DataLoader(ds0, batch_size=batch, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True)\n",
        "    feats = []\n",
        "    labels = [] if ('label_idx' in df.columns) else None\n",
        "    t0 = time.time()\n",
        "    for it, (xb0, ids0) in enumerate(dl0):\n",
        "        xb0 = xb0.to(device, non_blocking=True)\n",
        "        f0 = model(xb0)\n",
        "        f = f0\n",
        "        f = F.normalize(f, dim=1)\n",
        "        feats.append(f.detach().cpu())\n",
        "        if labels is not None:\n",
        "            labels.append(ids0.detach().cpu())\n",
        "        done = min((it+1)*dl0.batch_size, len(ds0))\n",
        "        if done % log_every < dl0.batch_size:\n",
        "            print(f'Feat progress: {done}/{len(ds0)}  elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    feats = torch.cat(feats, dim=0)\n",
        "    if labels is not None:\n",
        "        labels = torch.cat(labels, dim=0).long()\n",
        "    return feats, labels\n",
        "\n",
        "def compute_centroids(feats, labels):\n",
        "    # Accumulate sums per class in fp32\n",
        "    feat_dim = feats.shape[1]\n",
        "    sums = torch.zeros((num_classes, feat_dim), dtype=torch.float32)\n",
        "    counts = torch.zeros((num_classes,), dtype=torch.long)\n",
        "    for f, y in zip(feats, labels):\n",
        "        sums[y] += f.float()\n",
        "        counts[y] += 1\n",
        "    # Avoid div by zero\n",
        "    mask = counts > 0\n",
        "    sums[mask] = sums[mask] / counts[mask].unsqueeze(1).float()\n",
        "    # L2-normalize\n",
        "    centroids = F.normalize(sums, dim=1).half()  # store fp16\n",
        "    return centroids, counts\n",
        "\n",
        "def tune_tau(val_feats, val_labels, centroids, priors, grid=(0.5, 0.8, 1.0, 1.2, 1.5)):\n",
        "    with torch.no_grad():\n",
        "        cent_t = centroids.to(device).t().float()  # [D,C]\n",
        "        sims = torch.matmul(val_feats.to(device), cent_t).cpu().numpy()  # [N,C]\n",
        "    log_priors = np.log(priors + 1e-12)\n",
        "    best_tau, best_f1 = 0.0, -1.0\n",
        "    y_true = val_labels.numpy()\n",
        "    for tau in grid:\n",
        "        adj = sims - tau * log_priors[None, :]\n",
        "        pred = adj.argmax(axis=1)\n",
        "        f1 = f1_score(y_true, pred, average='macro')\n",
        "        print(f'tau={tau:.2f} val macro-F1={f1:.6f}', flush=True)\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_tau = f1, tau\n",
        "    return best_tau, best_f1\n",
        "\n",
        "# Pipeline\n",
        "t_all = time.time()\n",
        "print('Building NCC centroids with K-per-class sampling...')\n",
        "feat_model = build_feature_model()\n",
        "\n",
        "# Sample up to K images per class for centroid building\n",
        "t0 = time.time()\n",
        "def sample_k_per_class(df, k):\n",
        "    # df must contain 'label_idx'\n",
        "    return (df.groupby('label_idx', group_keys=False)\n",
        "              .apply(lambda g: g.sample(n=min(len(g), k), random_state=42))\n",
        "              .reset_index(drop=True))\n",
        "\n",
        "trn_k = sample_k_per_class(trn_split[['file_path','label_idx']], K_PER_CLASS)\n",
        "print('Sampled for centroids:', trn_k.shape, ' (K_PER_CLASS=', K_PER_CLASS, ')', flush=True)\n",
        "\n",
        "train_feats, train_labels = extract_features(feat_model, trn_k, batch=BATCH, two_view=TWO_VIEW, log_every=32768)\n",
        "centroids, cls_counts = compute_centroids(train_feats, train_labels)\n",
        "np.save('centroids_fp16.npy', centroids.cpu().numpy())\n",
        "np.save('centroids_counts.npy', cls_counts.cpu().numpy())\n",
        "print('Centroids built:', centroids.shape, ' time=%.1fs' % (time.time()-t0), flush=True)\n",
        "del train_feats; del train_labels; gc.collect()\n",
        "\n",
        "# Priors from full training split\n",
        "counts = trn_split['label_idx'].value_counts().sort_index()\n",
        "priors = counts.reindex(range(num_classes), fill_value=1).values.astype(np.float64)\n",
        "priors = priors / priors.sum()\n",
        "\n",
        "# Val features (cap for speed)\n",
        "VAL_CAP = 20000\n",
        "val_sub = val_split.iloc[:VAL_CAP].reset_index(drop=True)\n",
        "v_feats, v_labels = extract_features(feat_model, val_sub[['file_path','label_idx']], batch=BATCH, two_view=TWO_VIEW, log_every=32768)\n",
        "best_tau, best_f1 = tune_tau(v_feats, v_labels, centroids, priors, grid=(0.5, 0.8, 1.0, 1.2, 1.5))\n",
        "print('Best tau:', best_tau, ' Best val F1:', best_f1, flush=True)\n",
        "del v_feats; del v_labels; gc.collect()\n",
        "\n",
        "# Test features\n",
        "print('Extracting test features...')\n",
        "t1 = time.time()\n",
        "t_feats, t_ids = extract_features(feat_model, test_df[['file_path','Id']], batch=BATCH, two_view=TWO_VIEW, log_every=65536)\n",
        "print('Test feats:', t_feats.shape, ' time=%.1fs' % (time.time()-t1), flush=True)\n",
        "\n",
        "# Score in chunks on GPU\n",
        "print('Scoring test...')\n",
        "cent_t = centroids.to(device).t().float()  # [D,C]\n",
        "log_priors = torch.from_numpy(np.log(priors + 1e-12)).to(device).float()\n",
        "N = t_feats.shape[0]\n",
        "CH = 4096\n",
        "pred_idx = np.empty((N,), dtype=np.int32)\n",
        "for s in range(0, N, CH):\n",
        "    e = min(s + CH, N)\n",
        "    feat_chunk = t_feats[s:e].to(device)\n",
        "    sims = torch.matmul(feat_chunk, cent_t)  # [ch, C]\n",
        "    adj = sims - best_tau * log_priors[None, :]\n",
        "    pred = adj.argmax(dim=1).int().cpu().numpy()\n",
        "    pred_idx[s:e] = pred\n",
        "    if ((s // CH) + 1) % 20 == 0:\n",
        "        print(f'Scored {e}/{N}', flush=True)\n",
        "\n",
        "# Map back to original category ids\n",
        "pred_cat = [idx2cat[int(i)] for i in pred_idx]\n",
        "sub = pd.DataFrame({'Id': test_df['Id'].values, 'Predicted': pred_cat})\n",
        "sub = sub.sort_values('Id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('NCC submission.csv written. Shape:', sub.shape, ' head:\\n', sub.head(), flush=True)\n",
        "print('Total NCC pipeline time: %.1fs' % (time.time()-t_all), flush=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building NCC centroids with K-per-class sampling...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled for centroids: (209447, 2)  (K_PER_CLASS= 4 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_4996/4200466363.py:134: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  .apply(lambda g: g.sample(n=min(len(g), k), random_state=42))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 32768/209447  elapsed=267.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 65536/209447  elapsed=534.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 98304/209447  elapsed=803.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 131072/209447  elapsed=1072.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 163840/209447  elapsed=1341.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 196608/209447  elapsed=1610.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Centroids built: torch.Size([64500, 1024])  time=1736.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=0.50 val macro-F1=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=0.80 val macro-F1=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=1.00 val macro-F1=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=1.20 val macro-F1=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=1.50 val macro-F1=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best tau: 0.5  Best val F1: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting test features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 65536/477806  elapsed=537.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 131072/477806  elapsed=1075.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 196608/477806  elapsed=1614.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 262144/477806  elapsed=2152.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 327680/477806  elapsed=2690.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 393216/477806  elapsed=3230.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feat progress: 458752/477806  elapsed=3767.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test feats: torch.Size([477806, 1024])  time=3930.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scored 81920/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scored 163840/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scored 245760/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scored 327680/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scored 409600/477806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NCC submission.csv written. Shape: (477806, 2)  head:\n    Id  Predicted\n0   0      43278\n1   1      25876\n2   2      23067\n3   3       7824\n4   4      20895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total NCC pipeline time: 5851.2s\n"
          ]
        }
      ]
    },
    {
      "id": "222757c5-04a7-44f4-9edb-dd79fb0dd484",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Short fine-tune: ConvNeXt-Base @320, CE+LS, class-balanced sampling, AMP (expert-tuned)\n",
        "import math, time, json, os, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.metrics import f1_score\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load splits and mappings\n",
        "trn_split = pd.read_pickle('train_split.pkl')\n",
        "val_split = pd.read_pickle('val_split.pkl')\n",
        "with open('idx2cat.json','r') as f:\n",
        "    idx2cat = {int(k): int(v) for k,v in json.load(f).items()}\n",
        "num_classes = len(idx2cat)\n",
        "\n",
        "# Config (per expert advice)\n",
        "SEED = 42\n",
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 48  # fallback to 40 if OOM; try 64 if it fits\n",
        "EPOCHS = 2\n",
        "MAX_STEPS_PER_EPOCH = 15000  # ~30k total steps\n",
        "MAX_VAL_STEPS = 1000\n",
        "LR = 2e-4\n",
        "WD = 1e-4\n",
        "LS_EPS = 0.1\n",
        "MODEL_NAME = 'convnext_base.fb_in22k_ft_in1k'\n",
        "NUM_WORKERS = min(8, os.cpu_count() or 8)\n",
        "\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "train_tfms = T.Compose([\n",
        "    T.RandomResizedCrop(size=IMG_SIZE, scale=(0.75, 1.0), ratio=(0.8, 1.25)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.03),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean, std),\n",
        "    T.RandomErasing(p=0.1, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
        "])\n",
        "val_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "class ImgDS(Dataset):\n",
        "    def __init__(self, df, tfm, label_col='label_idx'):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tfm = tfm\n",
        "        self.has_label = label_col in df.columns\n",
        "        self.label_col = label_col\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        p = r['file_path']\n",
        "        try:\n",
        "            img = Image.open(p).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.fromarray(np.ones((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)*255)\n",
        "        x = self.tfm(img)\n",
        "        if self.has_label:\n",
        "            y = int(r[self.label_col])\n",
        "            return x, y\n",
        "        else:\n",
        "            return x, int(r['Id'])\n",
        "\n",
        "# Class-balanced sampler ~ 1/sqrt(freq)\n",
        "cls_counts = trn_split['label_idx'].value_counts().to_dict()\n",
        "weights = trn_split['label_idx'].map(lambda c: 1.0/ math.sqrt(cls_counts.get(c,1))).astype('float64').values\n",
        "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "\n",
        "train_ds = ImgDS(trn_split, train_tfms)\n",
        "val_ds = ImgDS(val_split, val_tfms)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=num_classes)\n",
        "model.to(device)\n",
        "\n",
        "class LabelSmoothingCE(nn.Module):\n",
        "    def __init__(self, eps=0.1):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "    def forward(self, logits, target):\n",
        "        n = logits.size(-1)\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        loss = -(log_probs.gather(dim=-1, index=target.unsqueeze(1)).squeeze(1))\n",
        "        loss = (1 - self.eps) * loss - self.eps * log_probs.mean(dim=-1)\n",
        "        return loss.mean()\n",
        "\n",
        "criterion = LabelSmoothingCE(LS_EPS)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "# Steps & scheduler\n",
        "num_steps = EPOCHS * min(MAX_STEPS_PER_EPOCH, math.ceil(len(train_loader)))\n",
        "warmup_steps = int(0.05 * num_steps)\n",
        "def cosine_warmup(step):\n",
        "    if step < warmup_steps:\n",
        "        return step / max(1, warmup_steps)\n",
        "    p = (step - warmup_steps) / max(1, (num_steps - warmup_steps))\n",
        "    return 0.5 * (1 + math.cos(math.pi * p))\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, cosine_warmup)\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
        "\n",
        "def validate(model, loader, max_steps=None):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    targs = []\n",
        "    t0 = time.time()\n",
        "    with torch.no_grad():\n",
        "        for it, (xb, yb) in enumerate(loader):\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda', enabled=True):\n",
        "                logits = model(xb)\n",
        "            pred = logits.argmax(dim=1)\n",
        "            preds.append(pred.detach().cpu().numpy())\n",
        "            targs.append(yb.detach().cpu().numpy())\n",
        "            if max_steps is not None and (it+1) >= max_steps:\n",
        "                break\n",
        "    preds = np.concatenate(preds)\n",
        "    targs = np.concatenate(targs)\n",
        "    f1 = f1_score(targs, preds, average='macro')\n",
        "    print(f'Validate: macro-F1={f1:.6f}  n={len(targs)}  batches={it+1}  elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    return f1\n",
        "\n",
        "best_f1 = -1.0\n",
        "best_path = 'model_convnext_base_320_ft_best.pth'\n",
        "global_step = 0\n",
        "t_start = time.time()\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    t0 = time.time()\n",
        "    for it, (xb, yb) in enumerate(train_loader):\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast('cuda', enabled=True):\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "        running += loss.item()\n",
        "        global_step += 1\n",
        "        if (it+1) % 200 == 0:\n",
        "            print(f'E{epoch} It{it+1} loss={running/(it+1):.4f} lr={scheduler.get_last_lr()[0]:.6f} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "        if (it+1) >= MAX_STEPS_PER_EPOCH:\n",
        "            print(f'Reached MAX_STEPS_PER_EPOCH={MAX_STEPS_PER_EPOCH}, breaking epoch early.', flush=True)\n",
        "            break\n",
        "    print(f'Epoch {epoch} train_loss={running/max(1,(it+1)):.4f} epoch_time={time.time()-t0:.1f}s', flush=True)\n",
        "    f1 = validate(model, val_loader, max_steps=MAX_VAL_STEPS)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        torch.save({'model': model.state_dict(), 'f1': best_f1}, best_path)\n",
        "        print('Saved best checkpoint:', best_path, 'F1=', best_f1, flush=True)\n",
        "\n",
        "if best_f1 < 0:\n",
        "    torch.save({'model': model.state_dict(), 'f1': best_f1}, best_path)\n",
        "    print('Saved checkpoint without val improvement:', best_path, flush=True)\n",
        "print(f'Training done. Best val macro-F1={best_f1:.6f}. Total elapsed={time.time()-t_start:.1f}s', flush=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It200 loss=11.1912 lr=0.000027 elapsed=96.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It400 loss=11.1239 lr=0.000053 elapsed=181.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It600 loss=11.0947 lr=0.000080 elapsed=266.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It800 loss=11.0737 lr=0.000107 elapsed=353.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It1000 loss=11.0497 lr=0.000133 elapsed=439.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It1200 loss=11.0091 lr=0.000160 elapsed=526.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It1400 loss=10.9575 lr=0.000187 elapsed=613.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It1600 loss=10.8916 lr=0.000200 elapsed=700.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It1800 loss=10.8134 lr=0.000200 elapsed=786.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It2000 loss=10.7237 lr=0.000200 elapsed=873.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It2200 loss=10.6285 lr=0.000200 elapsed=960.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It2400 loss=10.5354 lr=0.000200 elapsed=1046.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It2600 loss=10.4350 lr=0.000199 elapsed=1133.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It2800 loss=10.3315 lr=0.000199 elapsed=1220.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It3000 loss=10.2285 lr=0.000199 elapsed=1307.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It3200 loss=10.1251 lr=0.000198 elapsed=1393.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It3400 loss=10.0250 lr=0.000198 elapsed=1480.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It3600 loss=9.9237 lr=0.000197 elapsed=1567.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It3800 loss=9.8235 lr=0.000197 elapsed=1653.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It4000 loss=9.7245 lr=0.000196 elapsed=1740.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It4200 loss=9.6267 lr=0.000196 elapsed=1827.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It4400 loss=9.5304 lr=0.000195 elapsed=1914.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It4600 loss=9.4374 lr=0.000194 elapsed=2000.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It4800 loss=9.3458 lr=0.000193 elapsed=2087.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It5000 loss=9.2544 lr=0.000193 elapsed=2174.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It5200 loss=9.1642 lr=0.000192 elapsed=2261.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It5400 loss=9.0767 lr=0.000191 elapsed=2347.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It5600 loss=8.9905 lr=0.000190 elapsed=2434.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It5800 loss=8.9067 lr=0.000189 elapsed=2521.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It6000 loss=8.8262 lr=0.000188 elapsed=2608.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It6200 loss=8.7465 lr=0.000187 elapsed=2694.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It6400 loss=8.6686 lr=0.000186 elapsed=2781.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It6600 loss=8.5916 lr=0.000185 elapsed=2868.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It6800 loss=8.5158 lr=0.000183 elapsed=2954.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It7000 loss=8.4414 lr=0.000182 elapsed=3041.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It7200 loss=8.3694 lr=0.000181 elapsed=3128.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It7400 loss=8.2979 lr=0.000180 elapsed=3215.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It7600 loss=8.2279 lr=0.000178 elapsed=3301.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It7800 loss=8.1595 lr=0.000177 elapsed=3388.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It8000 loss=8.0933 lr=0.000175 elapsed=3475.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It8200 loss=8.0277 lr=0.000174 elapsed=3561.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It8400 loss=7.9641 lr=0.000172 elapsed=3648.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It8600 loss=7.9006 lr=0.000171 elapsed=3735.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It8800 loss=7.8383 lr=0.000169 elapsed=3822.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It9000 loss=7.7773 lr=0.000168 elapsed=3908.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It9200 loss=7.7168 lr=0.000166 elapsed=3995.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It9400 loss=7.6585 lr=0.000164 elapsed=4082.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It9600 loss=7.6001 lr=0.000163 elapsed=4168.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It9800 loss=7.5425 lr=0.000161 elapsed=4255.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It10000 loss=7.4871 lr=0.000159 elapsed=4342.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It10200 loss=7.4337 lr=0.000157 elapsed=4428.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It10400 loss=7.3801 lr=0.000156 elapsed=4515.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It10600 loss=7.3281 lr=0.000154 elapsed=4602.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It10800 loss=7.2769 lr=0.000152 elapsed=4689.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It11000 loss=7.2269 lr=0.000150 elapsed=4776.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It11200 loss=7.1772 lr=0.000148 elapsed=4862.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It11400 loss=7.1289 lr=0.000146 elapsed=4949.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It11600 loss=7.0812 lr=0.000144 elapsed=5035.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It11800 loss=7.0348 lr=0.000142 elapsed=5122.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It12000 loss=6.9894 lr=0.000140 elapsed=5209.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It12200 loss=6.9440 lr=0.000138 elapsed=5296.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It12400 loss=6.8992 lr=0.000136 elapsed=5382.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It12600 loss=6.8558 lr=0.000134 elapsed=5469.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It12800 loss=6.8128 lr=0.000132 elapsed=5556.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It13000 loss=6.7701 lr=0.000130 elapsed=5642.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It13200 loss=6.7284 lr=0.000128 elapsed=5729.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It13400 loss=6.6881 lr=0.000126 elapsed=5816.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It13600 loss=6.6480 lr=0.000123 elapsed=5902.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It13800 loss=6.6078 lr=0.000121 elapsed=5989.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It14000 loss=6.5689 lr=0.000119 elapsed=6076.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It14200 loss=6.5299 lr=0.000117 elapsed=6162.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It14400 loss=6.4923 lr=0.000115 elapsed=6249.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It14600 loss=6.4549 lr=0.000113 elapsed=6336.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It14800 loss=6.4174 lr=0.000110 elapsed=6422.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E0 It15000 loss=6.3809 lr=0.000108 elapsed=6509.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reached MAX_STEPS_PER_EPOCH=15000, breaking epoch early.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 train_loss=6.3809 epoch_time=6509.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validate: macro-F1=0.323169  n=48000  batches=1000  elapsed=139.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best checkpoint: model_convnext_base_320_ft_best.pth F1= 0.3231688390264109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It200 loss=3.6406 lr=0.000106 elapsed=87.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It400 loss=3.6331 lr=0.000104 elapsed=174.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It600 loss=3.5975 lr=0.000102 elapsed=261.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It800 loss=3.5827 lr=0.000099 elapsed=347.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It1000 loss=3.5746 lr=0.000097 elapsed=434.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It1200 loss=3.5695 lr=0.000095 elapsed=521.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It1400 loss=3.5615 lr=0.000093 elapsed=608.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It1600 loss=3.5478 lr=0.000091 elapsed=695.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It1800 loss=3.5357 lr=0.000088 elapsed=782.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It2000 loss=3.5222 lr=0.000086 elapsed=868.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It2200 loss=3.5087 lr=0.000084 elapsed=955.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It2400 loss=3.4937 lr=0.000082 elapsed=1042.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It2600 loss=3.4791 lr=0.000080 elapsed=1129.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It2800 loss=3.4667 lr=0.000078 elapsed=1215.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It3000 loss=3.4558 lr=0.000075 elapsed=1302.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It3200 loss=3.4458 lr=0.000073 elapsed=1389.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It3400 loss=3.4355 lr=0.000071 elapsed=1475.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It3600 loss=3.4238 lr=0.000069 elapsed=1562.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It3800 loss=3.4130 lr=0.000067 elapsed=1649.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It4000 loss=3.4009 lr=0.000065 elapsed=1735.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It4200 loss=3.3908 lr=0.000063 elapsed=1822.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It4400 loss=3.3810 lr=0.000061 elapsed=1909.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It4600 loss=3.3703 lr=0.000059 elapsed=1996.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It4800 loss=3.3602 lr=0.000057 elapsed=2082.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It5000 loss=3.3498 lr=0.000055 elapsed=2169.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It5200 loss=3.3393 lr=0.000053 elapsed=2256.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It5400 loss=3.3300 lr=0.000051 elapsed=2342.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It5600 loss=3.3192 lr=0.000049 elapsed=2429.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It5800 loss=3.3097 lr=0.000047 elapsed=2516.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It6000 loss=3.3005 lr=0.000045 elapsed=2603.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It6200 loss=3.2909 lr=0.000043 elapsed=2689.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It6400 loss=3.2825 lr=0.000042 elapsed=2776.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It6600 loss=3.2732 lr=0.000040 elapsed=2863.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It6800 loss=3.2646 lr=0.000038 elapsed=2949.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It7000 loss=3.2557 lr=0.000036 elapsed=3036.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It7200 loss=3.2472 lr=0.000035 elapsed=3123.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It7400 loss=3.2395 lr=0.000033 elapsed=3210.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It7600 loss=3.2315 lr=0.000031 elapsed=3297.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It7800 loss=3.2236 lr=0.000030 elapsed=3383.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It8000 loss=3.2157 lr=0.000028 elapsed=3470.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It8200 loss=3.2090 lr=0.000027 elapsed=3557.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It8400 loss=3.2013 lr=0.000025 elapsed=3643.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It8600 loss=3.1937 lr=0.000024 elapsed=3730.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It8800 loss=3.1871 lr=0.000022 elapsed=3817.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It9000 loss=3.1798 lr=0.000021 elapsed=3904.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It9200 loss=3.1725 lr=0.000020 elapsed=3991.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It9400 loss=3.1662 lr=0.000018 elapsed=4078.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It9600 loss=3.1600 lr=0.000017 elapsed=4165.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It9800 loss=3.1540 lr=0.000016 elapsed=4251.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It10000 loss=3.1479 lr=0.000015 elapsed=4338.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It10200 loss=3.1414 lr=0.000014 elapsed=4425.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It10400 loss=3.1353 lr=0.000013 elapsed=4512.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It10600 loss=3.1295 lr=0.000012 elapsed=4599.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It10800 loss=3.1233 lr=0.000011 elapsed=4685.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It11000 loss=3.1182 lr=0.000010 elapsed=4772.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It11200 loss=3.1126 lr=0.000009 elapsed=4859.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It11400 loss=3.1063 lr=0.000008 elapsed=4946.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It11600 loss=3.1014 lr=0.000007 elapsed=5032.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It11800 loss=3.0963 lr=0.000006 elapsed=5119.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It12000 loss=3.0911 lr=0.000005 elapsed=5206.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It12200 loss=3.0863 lr=0.000005 elapsed=5293.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It12400 loss=3.0816 lr=0.000004 elapsed=5380.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It12600 loss=3.0776 lr=0.000003 elapsed=5466.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It12800 loss=3.0730 lr=0.000003 elapsed=5553.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It13000 loss=3.0686 lr=0.000002 elapsed=5640.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It13200 loss=3.0644 lr=0.000002 elapsed=5727.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It13400 loss=3.0606 lr=0.000002 elapsed=5814.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It13600 loss=3.0561 lr=0.000001 elapsed=5900.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It13800 loss=3.0527 lr=0.000001 elapsed=5987.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It14000 loss=3.0489 lr=0.000001 elapsed=6074.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It14200 loss=3.0455 lr=0.000000 elapsed=6161.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It14400 loss=3.0419 lr=0.000000 elapsed=6248.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It14600 loss=3.0382 lr=0.000000 elapsed=6334.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It14800 loss=3.0345 lr=0.000000 elapsed=6421.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E1 It15000 loss=3.0309 lr=0.000000 elapsed=6508.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reached MAX_STEPS_PER_EPOCH=15000, breaking epoch early.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 train_loss=3.0309 epoch_time=6508.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validate: macro-F1=0.451064  n=48000  batches=1000  elapsed=138.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best checkpoint: model_convnext_base_320_ft_best.pth F1= 0.45106387697791467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done. Best val macro-F1=0.451064. Total elapsed=13297.4s\n"
          ]
        }
      ]
    },
    {
      "id": "940fd2a5-02d3-4c0d-9de5-613786d7afcb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference with 2x TTA (orig + HFlip) at 320 and tau tuning on large val subset\n",
        "import os, time, json, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "from sklearn.metrics import f1_score\n",
        "import timm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "val_split = pd.read_pickle('val_split.pkl')\n",
        "trn_split = pd.read_pickle('train_split.pkl')\n",
        "test_df = pd.read_pickle('test_df.pkl')\n",
        "with open('idx2cat.json','r') as f:\n",
        "    idx2cat = {int(k): int(v) for k,v in json.load(f).items()}\n",
        "num_classes = len(idx2cat)\n",
        "\n",
        "IMG_SIZE = 320\n",
        "MODEL_NAME = 'convnext_base.fb_in22k_ft_in1k'\n",
        "ckpt_path = 'model_convnext_base_320_ft_best.pth'\n",
        "\n",
        "val_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "def load_model_for_infer():\n",
        "    model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=num_classes)\n",
        "    ck = torch.load(ckpt_path, map_location='cpu')\n",
        "    model.load_state_dict(ck['model'], strict=True)\n",
        "    model.to(device).eval()\n",
        "    return model\n",
        "\n",
        "def infer_logits_paths_tta(model, paths, batch_size=96, log_every=100):\n",
        "    # try larger batch, fallback if OOM\n",
        "    bs_try = batch_size\n",
        "    logits_out = []\n",
        "    n = len(paths)\n",
        "    i = 0\n",
        "    t0 = time.time()\n",
        "    while i < n:\n",
        "        cur_bs = min(bs_try, n - i)\n",
        "        batch_paths = paths[i:i+cur_bs]\n",
        "        try:\n",
        "            # orig\n",
        "            imgs0 = []\n",
        "            for p in batch_paths:\n",
        "                try:\n",
        "                    img = Image.open(p).convert('RGB')\n",
        "                except Exception:\n",
        "                    img = Image.fromarray(np.ones((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)*255)\n",
        "                imgs0.append(val_tfms(img))\n",
        "            xb0 = torch.stack(imgs0).to(device, non_blocking=True)\n",
        "            # hflip\n",
        "            imgs1 = []\n",
        "            for p in batch_paths:\n",
        "                try:\n",
        "                    img = Image.open(p).convert('RGB')\n",
        "                except Exception:\n",
        "                    img = Image.fromarray(np.ones((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)*255)\n",
        "                img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "                imgs1.append(val_tfms(img))\n",
        "            xb1 = torch.stack(imgs1).to(device, non_blocking=True)\n",
        "            with torch.no_grad(), torch.amp.autocast('cuda', enabled=True):\n",
        "                l0 = model(xb0)\n",
        "                l1 = model(xb1)\n",
        "                l = (l0 + l1) * 0.5\n",
        "            logits_out.append(l.float().cpu().numpy())\n",
        "            i += cur_bs\n",
        "            if ((i // bs_try) % log_every) == 0:\n",
        "                print(f'Infer TTA progress: {i}/{n} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "        except RuntimeError as e:\n",
        "            if 'CUDA out of memory' in str(e) and bs_try > 32:\n",
        "                torch.cuda.empty_cache()\n",
        "                bs_try = max(32, bs_try // 2)\n",
        "                print('OOM encountered. Reducing batch_size to', bs_try, flush=True)\n",
        "                continue\n",
        "            else:\n",
        "                raise\n",
        "    return np.concatenate(logits_out, axis=0)\n",
        "\n",
        "# Priors from training split\n",
        "counts = trn_split['label_idx'].value_counts().sort_index()\n",
        "priors = counts.reindex(range(num_classes), fill_value=1).values.astype(np.float64)\n",
        "priors = priors / priors.sum()\n",
        "log_priors = np.log(priors + 1e-12)\n",
        "\n",
        "def tune_tau_on_val(model, cap=30000):\n",
        "    n = min(cap, len(val_split))\n",
        "    paths = val_split['file_path'].tolist()[:n]\n",
        "    y_true = val_split['label_idx'].values[:n]\n",
        "    print(f'Running 2x TTA validation on {n} samples for tau tuning...', flush=True)\n",
        "    val_logits = infer_logits_paths_tta(model, paths, batch_size=96, log_every=10)\n",
        "    best_tau, best_f1 = None, -1.0\n",
        "    for tau in [0.6, 0.8, 1.0, 1.2]:\n",
        "        adj = val_logits - tau * log_priors[None, :]\n",
        "        pred = adj.argmax(axis=1)\n",
        "        f1 = f1_score(y_true, pred, average='macro')\n",
        "        print(f'tau={tau:.2f} val macro-F1={f1:.6f}', flush=True)\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_tau = f1, tau\n",
        "    print('Best tau:', best_tau, 'Best val F1:', best_f1, flush=True)\n",
        "    return best_tau, best_f1\n",
        "\n",
        "def run_test_inference(model, tau, batch_size=96):\n",
        "    paths = test_df['file_path'].tolist()\n",
        "    print('Running 2x TTA test inference...', flush=True)\n",
        "    test_logits = infer_logits_paths_tta(model, paths, batch_size=batch_size, log_every=50)\n",
        "    adj = test_logits - tau * log_priors[None, :]\n",
        "    pred_idx = adj.argmax(axis=1)\n",
        "    pred_cat = [idx2cat[int(i)] for i in pred_idx]\n",
        "    sub = pd.DataFrame({'Id': test_df['Id'].values, 'Predicted': pred_cat}).sort_values('Id').reset_index(drop=True)\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('submission.csv written. Shape:', sub.shape, 'Head:\\n', sub.head(), flush=True)\n",
        "\n",
        "print('Loading model checkpoint:', ckpt_path, flush=True)\n",
        "model_for_infer = load_model_for_infer()\n",
        "print('Model loaded. Ready to tune tau and run test after training completes.', flush=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model checkpoint: model_convnext_base_320_ft_best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_4996/638992650.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ck = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded. Ready to tune tau and run test after training completes.\n"
          ]
        }
      ]
    },
    {
      "id": "50cea737-adc5-412e-b79d-4a53ffcbf809",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Execute 2x TTA tau tuning (30k val) and full test inference\n",
        "print('Starting tau tuning on val (cap=30000)...', flush=True)\n",
        "best_tau, best_f1 = tune_tau_on_val(model_for_infer, cap=30000)\n",
        "print(f'Chosen tau={best_tau} with val F1={best_f1:.6f}', flush=True)\n",
        "print('Running full test inference with 2x TTA...', flush=True)\n",
        "run_test_inference(model_for_infer, best_tau, batch_size=96)\n",
        "print('Done: submission.csv written.', flush=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting tau tuning on val (cap=30000)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 2x TTA validation on 30000 samples for tau tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 960/30000 elapsed=25.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 1920/30000 elapsed=47.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 2880/30000 elapsed=68.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 3840/30000 elapsed=90.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 4800/30000 elapsed=111.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 5760/30000 elapsed=133.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 6720/30000 elapsed=154.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 7680/30000 elapsed=176.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 8640/30000 elapsed=197.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 9600/30000 elapsed=219.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 10560/30000 elapsed=240.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 11520/30000 elapsed=261.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 12480/30000 elapsed=283.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 13440/30000 elapsed=304.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 14400/30000 elapsed=326.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 15360/30000 elapsed=347.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 16320/30000 elapsed=369.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 17280/30000 elapsed=390.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 18240/30000 elapsed=412.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 19200/30000 elapsed=433.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 20160/30000 elapsed=454.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 21120/30000 elapsed=476.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 22080/30000 elapsed=497.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 23040/30000 elapsed=519.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 24000/30000 elapsed=540.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 24960/30000 elapsed=562.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 25920/30000 elapsed=583.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 26880/30000 elapsed=606.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 27840/30000 elapsed=627.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 28800/30000 elapsed=649.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 29760/30000 elapsed=670.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=0.60 val macro-F1=0.421119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=0.80 val macro-F1=0.392910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=1.00 val macro-F1=0.358813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tau=1.20 val macro-F1=0.320986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best tau: 0.6 Best val F1: 0.4211189742274307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen tau=0.6 with val F1=0.421119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running full test inference with 2x TTA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running 2x TTA test inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/metrics/_classification.py:98: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_true = type_of_target(y_true, input_name=\"y_true\")\n/app/.pip-target/sklearn/metrics/_classification.py:99: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n/app/.pip-target/sklearn/utils/multiclass.py:79: UserWarning: The number of unique classes is greater than 50% of the number of samples. `y` could represent a regression problem, not a classification problem.\n  ys_types = set(type_of_target(x) for x in ys)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 4800/477806 elapsed=107.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 9600/477806 elapsed=215.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 14400/477806 elapsed=321.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 19200/477806 elapsed=429.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 24000/477806 elapsed=537.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 28800/477806 elapsed=644.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 33600/477806 elapsed=753.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 38400/477806 elapsed=860.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 43200/477806 elapsed=967.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 48000/477806 elapsed=1074.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 52800/477806 elapsed=1183.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 57600/477806 elapsed=1290.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 62400/477806 elapsed=1398.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 67200/477806 elapsed=1506.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 72000/477806 elapsed=1615.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 76800/477806 elapsed=1724.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 81600/477806 elapsed=1832.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 86400/477806 elapsed=1942.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 91200/477806 elapsed=2050.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 96000/477806 elapsed=2158.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 100800/477806 elapsed=2266.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 105600/477806 elapsed=2374.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 110400/477806 elapsed=2482.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 115200/477806 elapsed=2590.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 120000/477806 elapsed=2698.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 124800/477806 elapsed=2806.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 129600/477806 elapsed=2914.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 134400/477806 elapsed=3021.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 139200/477806 elapsed=3129.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 144000/477806 elapsed=3238.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 148800/477806 elapsed=3345.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 153600/477806 elapsed=3453.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 158400/477806 elapsed=3561.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 163200/477806 elapsed=3668.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 168000/477806 elapsed=3776.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 172800/477806 elapsed=3884.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 177600/477806 elapsed=3992.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 182400/477806 elapsed=4100.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 187200/477806 elapsed=4208.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 192000/477806 elapsed=4315.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 196800/477806 elapsed=4425.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 201600/477806 elapsed=4536.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 206400/477806 elapsed=4646.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 211200/477806 elapsed=4754.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 216000/477806 elapsed=4863.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 220800/477806 elapsed=4972.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 225600/477806 elapsed=5082.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 230400/477806 elapsed=5191.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 235200/477806 elapsed=5298.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 240000/477806 elapsed=5408.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 244800/477806 elapsed=5517.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 249600/477806 elapsed=5625.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 254400/477806 elapsed=5734.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 259200/477806 elapsed=5841.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 264000/477806 elapsed=5950.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 268800/477806 elapsed=6059.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 273600/477806 elapsed=6167.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 278400/477806 elapsed=6275.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 283200/477806 elapsed=6384.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 288000/477806 elapsed=6492.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 292800/477806 elapsed=6603.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 297600/477806 elapsed=6710.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 302400/477806 elapsed=6817.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 307200/477806 elapsed=6926.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 312000/477806 elapsed=7034.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 316800/477806 elapsed=7142.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 321600/477806 elapsed=7250.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 326400/477806 elapsed=7357.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 331200/477806 elapsed=7464.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 336000/477806 elapsed=7572.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 340800/477806 elapsed=7681.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 345600/477806 elapsed=7788.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 350400/477806 elapsed=7896.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 355200/477806 elapsed=8004.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 360000/477806 elapsed=8113.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 364800/477806 elapsed=8221.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 369600/477806 elapsed=8329.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 374400/477806 elapsed=8438.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 379200/477806 elapsed=8546.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 384000/477806 elapsed=8653.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 388800/477806 elapsed=8760.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 393600/477806 elapsed=8869.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 398400/477806 elapsed=8978.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 403200/477806 elapsed=9085.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 408000/477806 elapsed=9194.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 412800/477806 elapsed=9302.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 417600/477806 elapsed=9410.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 422400/477806 elapsed=9519.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 427200/477806 elapsed=9627.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 432000/477806 elapsed=9736.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 436800/477806 elapsed=9844.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 441600/477806 elapsed=9952.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 446400/477806 elapsed=10060.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 451200/477806 elapsed=10169.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 456000/477806 elapsed=10279.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 460800/477806 elapsed=10386.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 465600/477806 elapsed=10494.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 470400/477806 elapsed=10603.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infer TTA progress: 475200/477806 elapsed=10712.1s\n"
          ]
        }
      ]
    },
    {
      "id": "25fface9-f646-4966-9b01-3bb7ac09e4c5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fast, reliable single-view inference with fixed tau=0.6 and periodic checkpoints\n",
        "import os, time, json, math, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import timm\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load artifacts\n",
        "val_split = pd.read_pickle('val_split.pkl')  # not strictly needed, but kept for consistency\n",
        "trn_split = pd.read_pickle('train_split.pkl')\n",
        "test_df = pd.read_pickle('test_df.pkl')\n",
        "with open('idx2cat.json','r') as f:\n",
        "    idx2cat = {int(k): int(v) for k,v in json.load(f).items()}\n",
        "num_classes = len(idx2cat)\n",
        "\n",
        "IMG_SIZE = 320\n",
        "MODEL_NAME = 'convnext_base.fb_in22k_ft_in1k'\n",
        "CKPT_PATH = 'model_convnext_base_320_ft_best.pth'\n",
        "TAU = 0.6  # fixed from prior tuning\n",
        "\n",
        "# Priors from training split\n",
        "counts = trn_split['label_idx'].value_counts().sort_index()\n",
        "priors = counts.reindex(range(num_classes), fill_value=1).values.astype(np.float64)\n",
        "priors = priors / priors.sum()\n",
        "log_priors = torch.from_numpy(np.log(priors + 1e-12)).to(device).float()\n",
        "\n",
        "val_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "class TestDS(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        p = r['file_path']\n",
        "        try:\n",
        "            img = Image.open(p).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.fromarray(np.ones((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)*255)\n",
        "        x = val_tfms(img)\n",
        "        return x, int(r['Id'])\n",
        "\n",
        "def load_model():\n",
        "    model = timm.create_model(MODEL_NAME, pretrained=False, num_classes=num_classes)\n",
        "    ck = torch.load(CKPT_PATH, map_location='cpu')\n",
        "    model.load_state_dict(ck['model'], strict=True)\n",
        "    model.to(device).eval()\n",
        "    return model\n",
        "\n",
        "@torch.inference_mode()\n",
        "def run_single_view_infer():\n",
        "    ds = TestDS(test_df)\n",
        "    # Use conservative batch for stability; OOM-safe backoff not needed for single-view\n",
        "    bs = 128\n",
        "    dl = DataLoader(ds, batch_size=bs, shuffle=False, num_workers=min(8, os.cpu_count() or 8), pin_memory=True, persistent_workers=True)\n",
        "    model = load_model()\n",
        "    preds_idx = np.empty((len(ds),), dtype=np.int32)\n",
        "    t0 = time.time()\n",
        "    done = 0\n",
        "    for it, (xb, ids) in enumerate(dl):\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        with torch.amp.autocast('cuda', enabled=True):\n",
        "            logits = model(xb)\n",
        "            adj = logits - TAU * log_priors[None, :]\n",
        "        pred = adj.argmax(dim=1).int().cpu().numpy()\n",
        "        s = done\n",
        "        e = done + len(ids)\n",
        "        preds_idx[s:e] = pred\n",
        "        done = e\n",
        "        if (it+1) % 300 == 0 or e == len(ds):\n",
        "            print(f'Test infer progress: {e}/{len(ds)} elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    # Map to category ids and write submission\n",
        "    pred_cat = [idx2cat[int(i)] for i in preds_idx]\n",
        "    sub = pd.DataFrame({'Id': test_df['Id'].values, 'Predicted': pred_cat}).sort_values('Id').reset_index(drop=True)\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('submission.csv written. Shape:', sub.shape, ' Head:\\n', sub.head(), flush=True)\n",
        "    return sub\n",
        "\n",
        "print('Starting fast single-view inference with tau=0.6 ...', flush=True)\n",
        "sub = run_single_view_infer()\n",
        "print('Done.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fast single-view inference with tau=0.6 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_6142/1872280375.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ck = torch.load(CKPT_PATH, map_location='cpu')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}