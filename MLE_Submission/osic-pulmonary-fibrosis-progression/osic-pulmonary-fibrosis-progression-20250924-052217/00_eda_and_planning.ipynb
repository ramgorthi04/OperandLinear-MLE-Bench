{
  "cells": [
    {
      "id": "6bcc16db-41d1-403d-b27c-ba96369707fe",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OSIC Pulmonary Fibrosis Progression \u2013 Plan\n",
        "\n",
        "Objectives:\n",
        "- Establish a fast, reliable baseline and reach medal CV quickly.\n",
        "- Lock a trustworthy validation protocol and iterate with focused FE and modeling.\n",
        "\n",
        "Key Constraints and Rules:\n",
        "- GPU check and environment sanity first.\n",
        "- Deterministic, leak-free CV across patients (GroupKFold by patient_id if present).\n",
        "- Use expert review at milestones (plan, EDA, baseline, FE iterations, modeling, ensembling).\n",
        "- Always log progress and elapsed time per fold.\n",
        "\n",
        "Initial Understanding:\n",
        "- Files: train.csv, test.csv, sample_submission.csv; plus per-patient folders (train/, test/) likely with scans/metadata (we may ignore images initially for a tabular baseline).\n",
        "- Target column: `target`.\n",
        "- Metric: modified-laplace-log-likelihood (custom). We will implement it for CV.\n",
        "\n",
        "Validation Strategy:\n",
        "- GroupKFold by patient identifier to avoid leakage across same patient (placeholder: column names TBD after EDA).\n",
        "- 5 folds, fixed seed; store and reuse folds.\n",
        "- Sanity checks: target distribution per fold, group sizes.\n",
        "\n",
        "Baseline v0:\n",
        "- Tabular-only model ignoring images to ship a working solution quickly.\n",
        "- Models:\n",
        "  - XGBoost (GPU) and CatBoost (GPU) as strong tabular baselines.\n",
        "- Features:\n",
        "  - Raw numeric columns;\n",
        "  - Encoded categoricals (CatBoost handles categorical natively; otherwise Target/OOF mean encode or one-hot);\n",
        "  - Simple temporal deltas if columns like weeks/time exist.\n",
        "- Training:\n",
        "  - Early stopping;\n",
        "  - Reasonable hyperparams;\n",
        "  - Custom eval metric callback for laplace-log-likelihood (if feasible) or monitor MAE/RMSE while computing official metric offline each fold.\n",
        "\n",
        "Feature Engineering Iterations:\n",
        "- v1: Basic aggregations by patient (mean, std, slope if time present), baseline health metrics (e.g., age, sex, smoking status) encodings.\n",
        "- v2: Longitudinal features: per-patient linear trend of FVC/related signals vs time; residuals; recent changes.\n",
        "- v3: Interactions and non-linear transforms validated by CV.\n",
        "\n",
        "Ensembling Plan:\n",
        "- Blend XGBoost + CatBoost OOF/test predictions (weighted average tuned on OOF).\n",
        "- If time permits, add LightGBM-CPU for diversity.\n",
        "\n",
        "Metric Implementation:\n",
        "- Implement modified-laplace-log-likelihood (reference Laplace log-likelihood variant) to compute OOF metric exactly.\n",
        "- Validate against small synthetic cases; ensure monotonic relation with error.\n",
        "\n",
        "Execution Roadmap:\n",
        "1) Environment/GPU check; versions logged.\n",
        "2) EDA: load train/test, inspect columns, dtypes, missingness, target distribution; identify patient_id and time fields.\n",
        "3) Define folds (GroupKFold) and cache.\n",
        "4) Implement metric; write a scorer function.\n",
        "5) Baseline XGBoost-GPU with careful preprocessing; produce OOF/test; save submission.csv; checkpoint.\n",
        "6) Expert review on baseline + planned FE.\n",
        "7) FE v1/v2 with CV, iterate; track deltas.\n",
        "8) Blend and finalize; tighten inference; ensure reproducibility.\n",
        "\n",
        "Questions for Experts:\n",
        "- What medal-winning strategies worked best here? Any must-have features for this dataset?\n",
        "- Preferred CV split details (n_splits, group by which column, any temporal considerations)?\n",
        "- Any pitfalls specific to the modified-laplace-log-likelihood implementation?\n",
        "\n",
        "Next Action:\n",
        "- Run environment check (nvidia-smi), then quick EDA to identify key columns and target distribution."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "6476cdf2-5744-4a2f-98d6-5f951ff6e383",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, time, json, textwrap, math, gc, subprocess, shutil, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "pd.set_option('display.max_columns', 200)\n",
        "pd.set_option('display.width', 180)\n",
        "\n",
        "def sh(cmd):\n",
        "    print('>', cmd, flush=True)\n",
        "    return subprocess.run(['bash','-lc', cmd], check=False, text=True, capture_output=True)\n",
        "\n",
        "t0 = time.time()\n",
        "print('GPU check (nvidia-smi):')\n",
        "print(sh('nvidia-smi || true').stdout)\n",
        "\n",
        "DATA_DIR = Path('.')\n",
        "print('CWD:', os.getcwd())\n",
        "\n",
        "train_path = DATA_DIR/'train.csv'\n",
        "test_path = DATA_DIR/'test.csv'\n",
        "ss_path = DATA_DIR/'sample_submission.csv'\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "test = pd.read_csv(test_path)\n",
        "ss = pd.read_csv(ss_path)\n",
        "\n",
        "print('train.shape:', train.shape)\n",
        "print('test.shape:', test.shape)\n",
        "print('sample_submission.shape:', ss.shape)\n",
        "\n",
        "print('\\nTrain columns and dtypes:')\n",
        "print(train.dtypes)\n",
        "print('\\nHead(train):')\n",
        "print(train.head(3))\n",
        "\n",
        "print('\\nTest columns and dtypes:')\n",
        "print(test.dtypes)\n",
        "print('\\nHead(test):')\n",
        "print(test.head(3))\n",
        "\n",
        "print('\\nHead(sample_submission):')\n",
        "print(ss.head(3))\n",
        "\n",
        "# Heuristics for common OSIC schema\n",
        "patient_col = None\n",
        "for c in ['Patient','patient','patient_id','PatientID','id']:\n",
        "    if c in train.columns:\n",
        "        patient_col = c; break\n",
        "print('Patient column guess:', patient_col)\n",
        "\n",
        "week_col = None\n",
        "for c in ['Weeks','weeks','week','Week']:\n",
        "    if c in train.columns:\n",
        "        week_col = c; break\n",
        "print('Week column guess:', week_col)\n",
        "\n",
        "target_col = None\n",
        "for c in ['target','FVC','fvc']:\n",
        "    if c in train.columns:\n",
        "        target_col = c; break\n",
        "print('Target column guess:', target_col)\n",
        "\n",
        "if patient_col is not None:\n",
        "    print('Unique patients in train:', train[patient_col].nunique())\n",
        "    if patient_col in test.columns:\n",
        "        print('Unique patients in test:', test[patient_col].nunique())\n",
        "\n",
        "if target_col is not None:\n",
        "    print('\\nTarget describe:')\n",
        "    print(train[target_col].describe())\n",
        "\n",
        "elapsed = time.time() - t0\n",
        "print(f'EDA setup done in {elapsed:.2f}s')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU check (nvidia-smi):\n> nvidia-smi || true\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 24 05:35:18 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\nCWD: /var/lib/simon/agent_run_states/osic-pulmonary-fibrosis-progression-20250924-052217\ntrain.shape: (1394, 7)\ntest.shape: (18, 7)\nsample_submission.shape: (1908, 3)\n\nTrain columns and dtypes:\nPatient           object\nWeeks              int64\nFVC                int64\nPercent          float64\nAge                int64\nSex               object\nSmokingStatus     object\ndtype: object\n\nHead(train):\n                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n0  ID00133637202223847701934     -2  3195  92.856312   83  Male  Never smoked\n1  ID00133637202223847701934      2  3203  93.088817   83  Male  Never smoked\n2  ID00133637202223847701934      4  3097  90.008138   83  Male  Never smoked\n\nTest columns and dtypes:\nPatient           object\nWeeks              int64\nFVC                int64\nPercent          float64\nAge                int64\nSex               object\nSmokingStatus     object\ndtype: object\n\nHead(test):\n                     Patient  Weeks   FVC    Percent  Age     Sex SmokingStatus\n0  ID00014637202177757139317      0  3807  90.076661   56    Male     Ex-smoker\n1  ID00019637202178323708467     13  2100  92.858722   83  Female     Ex-smoker\n2  ID00047637202184938901501      2  3313  89.929425   68    Male     Ex-smoker\n\nHead(sample_submission):\n                   Patient_Week   FVC  Confidence\n0  ID00126637202218610655908_-3  2000         100\n1  ID00126637202218610655908_-2  2000         100\n2  ID00126637202218610655908_-1  2000         100\nPatient column guess: Patient\nWeek column guess: Weeks\nTarget column guess: FVC\nUnique patients in train: 158\nUnique patients in test: 18\n\nTarget describe:\ncount    1394.000000\nmean     2666.939742\nstd       801.859900\nmin       837.000000\n25%      2105.750000\n50%      2607.000000\n75%      3117.250000\nmax      5045.000000\nName: FVC, dtype: float64\nEDA setup done in 0.04s\n"
          ]
        }
      ]
    },
    {
      "id": "cbbe9790-d119-454f-bbe8-a7d785f28270",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import time\n",
        "\n",
        "# Metric: modified Laplace log-likelihood (maximize)\n",
        "def laplace_ll(y_true, y_pred, sigma):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    y_pred = np.asarray(y_pred).astype(float)\n",
        "    sigma = np.asarray(sigma).astype(float)\n",
        "    delta = np.abs(y_true - y_pred)\n",
        "    delta = np.minimum(delta, 1000.0)\n",
        "    sigma = np.maximum(sigma, 70.0)\n",
        "    return np.mean(-delta / sigma - np.log(sigma))\n",
        "\n",
        "# Fit per-patient slope using only patients with >=2 points\n",
        "def compute_patient_slopes(df, patient_col='Patient', week_col='Weeks', target_col='FVC'):\n",
        "    slopes = {}\n",
        "    for pid, g in df.groupby(patient_col):\n",
        "        if g.shape[0] >= 2:\n",
        "            x = g[week_col].values.astype(float)\n",
        "            y = g[target_col].values.astype(float)\n",
        "            # slope from simple OLS\n",
        "            x_mean = x.mean(); y_mean = y.mean()\n",
        "            denom = ((x - x_mean) ** 2).sum()\n",
        "            if denom > 0:\n",
        "                slope = ((x - x_mean) * (y - y_mean)).sum() / denom\n",
        "            else:\n",
        "                slope = 0.0\n",
        "            slopes[pid] = slope\n",
        "    return slopes\n",
        "\n",
        "def robust_global_slope(slopes_dict):\n",
        "    if len(slopes_dict) == 0:\n",
        "        return 0.0\n",
        "    vals = np.array(list(slopes_dict.values()), dtype=float)\n",
        "    return float(np.median(vals))\n",
        "\n",
        "def build_oof_and_tune_sigma(train_df, n_splits=5, seed=42):\n",
        "    t0 = time.time()\n",
        "    gkf = GroupKFold(n_splits=n_splits)\n",
        "    groups = train_df['Patient'].values\n",
        "    oof_pred = np.zeros(len(train_df))\n",
        "    oof_base = np.zeros(len(train_df))  # patient baseline FVC (min week) within VAL to simulate test-time anchor\n",
        "    oof_dist = np.zeros(len(train_df))  # distance to nearest observed week (baseline in this sim)\n",
        "    fold_metrics = []\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(train_df, groups=groups, y=None), 1):\n",
        "        t_fold = time.time()\n",
        "        trn = train_df.iloc[trn_idx].copy()\n",
        "        val = train_df.iloc[val_idx].copy()\n",
        "        # Compute global slope from training patients only\n",
        "        slopes = compute_patient_slopes(trn)\n",
        "        g_slope = robust_global_slope(slopes)\n",
        "        # For each val patient, anchor at its baseline (min Weeks) within val\n",
        "        base = (val.sort_values(['Patient','Weeks'])\n",
        "                  .groupby('Patient', as_index=False)\n",
        "                  .first()[['Patient','Weeks','FVC']]\n",
        "               ).rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'})\n",
        "        val = val.merge(base, on='Patient', how='left')\n",
        "        # Predict using anchored baseline + global slope\n",
        "        val_pred = val['Base_FVC'].values + g_slope * (val['Weeks'].values - val['Base_Week'].values)\n",
        "        # Distance to nearest observed week = distance to baseline week in this simulation\n",
        "        dist = np.abs(val['Weeks'].values - val['Base_Week'].values).astype(float)\n",
        "        oof_pred[val_idx] = val_pred\n",
        "        oof_base[val_idx] = val['Base_FVC'].values\n",
        "        oof_dist[val_idx] = dist\n",
        "        # quick MAE for monitoring\n",
        "        mae = np.mean(np.abs(val['FVC'].values - val_pred))\n",
        "        print(f'[Fold {fold}] n_trn={trn.shape[0]} n_val={val.shape[0]} global_slope={g_slope:.4f} MAE={mae:.2f} elapsed={time.time()-t_fold:.2f}s', flush=True)\n",
        "    # Tune sigma = max(a + b*dist, 70) on OOF\n",
        "    grid_a = [70, 90, 110, 130, 160, 200, 250]\n",
        "    grid_b = [0.0, 0.5, 1.0, 2.0, 3.0, 5.0]\n",
        "    best = (-1e9, None, None)\n",
        "    for a in grid_a:\n",
        "        for b in grid_b:\n",
        "            sig = a + b * oof_dist\n",
        "            score = laplace_ll(train_df['FVC'].values, oof_pred, sig)\n",
        "            if score > best[0]:\n",
        "                best = (score, a, b)\n",
        "    print(f'Best OOF Laplace: {best[0]:.5f} with a={best[1]} b={best[2]} over {len(grid_a)*len(grid_b)} combos. Total elapsed {time.time()-t0:.2f}s', flush=True)\n",
        "    return oof_pred, oof_dist, best\n",
        "\n",
        "# Train OOF and tune sigma\n",
        "oof_pred, oof_dist, (best_oof, best_a, best_b) = build_oof_and_tune_sigma(train)\n",
        "\n",
        "# Final training: compute global slope on full train\n",
        "full_slopes = compute_patient_slopes(train)\n",
        "global_slope = robust_global_slope(full_slopes)\n",
        "print(f'Global slope (full train): {global_slope:.6f}')\n",
        "\n",
        "# Build submission scaffold from sample_submission\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "sub = ss.copy()\n",
        "parts = sub['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "sub['Patient'] = parts[0]\n",
        "sub['Weeks'] = parts[1].astype(int)\n",
        "\n",
        "# Get test baseline row per patient (one row per patient here)\n",
        "test_bl = test[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'})\n",
        "sub = sub.merge(test_bl, on='Patient', how='left')\n",
        "\n",
        "# Predict FVC using anchored baseline + global slope\n",
        "sub['FVC'] = sub['Base_FVC'] + global_slope * (sub['Weeks'] - sub['Base_Week'])\n",
        "\n",
        "# Sigma using tuned (a,b) and distance to nearest observed week (baseline)\n",
        "sub['dist'] = (sub['Weeks'] - sub['Base_Week']).abs().astype(float)\n",
        "sub['Confidence'] = np.maximum(best_a + best_b * sub['dist'], 70.0)\n",
        "\n",
        "# Finalize submission columns and save\n",
        "submission = sub[['Patient_Week','FVC','Confidence']].copy()\n",
        "submission['FVC'] = submission['FVC'].astype(float)\n",
        "submission['Confidence'] = submission['Confidence'].astype(float)\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with shape:', submission.shape)\n",
        "\n",
        "# Report OOF metric for visibility\n",
        "print(f'OOF modified Laplace LL: {best_oof:.5f}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] n_trn=1112 n_val=282 global_slope=-3.8062 MAE=167.29 elapsed=0.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] n_trn=1113 n_val=281 global_slope=-3.5547 MAE=118.15 elapsed=0.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 3] n_trn=1119 n_val=275 global_slope=-3.5065 MAE=137.06 elapsed=0.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 4] n_trn=1119 n_val=275 global_slope=-3.5065 MAE=154.74 elapsed=0.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 5] n_trn=1113 n_val=281 global_slope=-3.6557 MAE=142.12 elapsed=0.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best OOF Laplace: -5.90967 with a=70 b=5.0 over 42 combos. Total elapsed 0.05s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global slope (full train): -3.634137\nSaved submission.csv with shape: (1908, 3)\nOOF modified Laplace LL: -5.90967\n"
          ]
        }
      ]
    },
    {
      "id": "eaa8b9e6-072d-4533-9434-9c62a1f18401",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity checks for submission.csv vs sample_submission.csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "sub = pd.read_csv('submission.csv')\n",
        "\n",
        "print('submission.shape:', sub.shape, 'sample_submission.shape:', ss.shape)\n",
        "assert sub.shape[0] == ss.shape[0], 'Row count mismatch'\n",
        "\n",
        "ss_set = set(ss['Patient_Week'].astype(str).values)\n",
        "sub_set = set(sub['Patient_Week'].astype(str).values)\n",
        "print('Patient_Week coverage equal:', ss_set == sub_set, f\"missing_in_sub={len(ss_set - sub_set)} extra_in_sub={len(sub_set - ss_set)}\")\n",
        "assert ss_set == sub_set, 'Patient_Week sets differ'\n",
        "\n",
        "assert sub['FVC'].notna().all() and sub['Confidence'].notna().all(), 'Found NaNs in submission'\n",
        "assert (sub['Confidence'] >= 70).all(), 'Confidence has values < 70'\n",
        "\n",
        "print('Confidence stats:', sub['Confidence'].describe())\n",
        "print('FVC stats:', sub['FVC'].describe())\n",
        "print(sub.head())\n",
        "print('Submission sanity checks passed.')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.shape: (1908, 3) sample_submission.shape: (1908, 3)\nPatient_Week coverage equal: True missing_in_sub=0 extra_in_sub=0\nConfidence stats: count    1908.000000\nmean      100.200083\nstd        22.950442\nmin        70.003754\n25%        78.461966\n50%        97.671429\n75%       120.272419\nmax       144.195259\nName: Confidence, dtype: float64\nFVC stats: count    1908.000000\nmean     2940.866036\nstd      1033.837717\nmin      1358.892307\n25%      2166.727120\n50%      3043.646904\n75%      3423.828923\nmax      6000.000000\nName: FVC, dtype: float64\n                   Patient_Week          FVC  Confidence\n0  ID00126637202218610655908_-3  2392.288082   99.514395\n1  ID00126637202218610655908_-2  2388.653945   99.514395\n2  ID00126637202218610655908_-1  2385.019808   99.514395\n3   ID00126637202218610655908_0  2381.385671   99.514395\n4   ID00126637202218610655908_1  2377.751535   99.514395\nSubmission sanity checks passed.\n"
          ]
        }
      ]
    },
    {
      "id": "590101e5-ec29-4512-a09c-fc9300ceacc1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Residual XGBoost model (fold-aware) + sigma model; generate improved submission\n",
        "import sys, subprocess, time, math, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def ensure_xgboost():\n",
        "    try:\n",
        "        import xgboost as xgb  # noqa: F401\n",
        "        return\n",
        "    except Exception:\n",
        "        print('Installing xgboost...', flush=True)\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', 'xgboost==2.0.3', '--no-input'], check=True)\n",
        "        import xgboost as xgb  # noqa: F401\n",
        "\n",
        "ensure_xgboost()\n",
        "import xgboost as xgb\n",
        "\n",
        "if 'train' not in globals():\n",
        "    train = pd.read_csv('train.csv')\n",
        "if 'test' not in globals():\n",
        "    test = pd.read_csv('test.csv')\n",
        "\n",
        "def laplace_ll(y_true, y_pred, sigma):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    y_pred = np.asarray(y_pred).astype(float)\n",
        "    sigma = np.asarray(sigma).astype(float)\n",
        "    delta = np.minimum(np.abs(y_true - y_pred), 1000.0)\n",
        "    sigma = np.maximum(sigma, 70.0)\n",
        "    return np.mean(-delta / sigma - np.log(sigma))\n",
        "\n",
        "def compute_patient_slopes(df, patient_col='Patient', week_col='Weeks', target_col='FVC'):\n",
        "    slopes = {}\n",
        "    for pid, g in df.groupby(patient_col):\n",
        "        if g.shape[0] >= 2:\n",
        "            x = g[week_col].values.astype(float)\n",
        "            y = g[target_col].values.astype(float)\n",
        "            xm = x.mean(); ym = y.mean()\n",
        "            denom = ((x - xm)**2).sum()\n",
        "            slope = ((x - xm) * (y - ym)).sum() / denom if denom > 0 else 0.0\n",
        "            slopes[pid] = slope\n",
        "    return slopes\n",
        "\n",
        "def compute_trend_stats(df, patient_col='Patient', week_col='Weeks', target_col='FVC'):\n",
        "    rows = []\n",
        "    for pid, g in df.groupby(patient_col):\n",
        "        n = g.shape[0]\n",
        "        if n >= 2:\n",
        "            x = g[week_col].values.astype(float)\n",
        "            y = g[target_col].values.astype(float)\n",
        "            xm = x.mean(); ym = y.mean()\n",
        "            denom = ((x - xm)**2).sum()\n",
        "            if denom > 0:\n",
        "                slope = ((x - xm) * (y - ym)).sum() / denom\n",
        "                yhat = ym + slope * (x - xm)\n",
        "                ss_res = ((y - yhat)**2).sum()\n",
        "                ss_tot = ((y - ym)**2).sum()\n",
        "                r2 = 1.0 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
        "            else:\n",
        "                slope, r2 = 0.0, 0.0\n",
        "            rows.append((pid, slope, r2, n))\n",
        "        else:\n",
        "            rows.append((pid, 0.0, 0.0, n))\n",
        "    return pd.DataFrame(rows, columns=[patient_col, 'slope_w', 'r2_w', 'n_obs'])\n",
        "\n",
        "def robust_global_slope(slopes_dict):\n",
        "    if not slopes_dict:\n",
        "        return 0.0\n",
        "    return float(np.median(list(slopes_dict.values())))\n",
        "\n",
        "def one_hot_fit(df, cols):\n",
        "    cats = {c: sorted(df[c].dropna().unique().tolist()) for c in cols}\n",
        "    return cats\n",
        "\n",
        "def one_hot_transform(df, cats):\n",
        "    out = df.copy()\n",
        "    for c, values in cats.items():\n",
        "        for v in values:\n",
        "            out[f'{c}__{v}'] = (out[c] == v).astype(np.int8)\n",
        "    return out\n",
        "\n",
        "def build_features(df):\n",
        "    df = df.copy()\n",
        "    df['Weeks_Passed'] = (df['Weeks'] - df['Base_Week']).astype(float)\n",
        "    df['Abs_Weeks_Passed'] = df['Weeks_Passed'].abs()\n",
        "    df['Weeks_Passed2'] = df['Weeks_Passed'] ** 2\n",
        "    df['Weeks_Passed3'] = df['Weeks_Passed'] ** 3\n",
        "    df['Percent2'] = df['Percent'] ** 2\n",
        "    df['Age_x_Percent'] = df['Age'] * df['Percent']\n",
        "    df['Percent_x_BaseFVC'] = df['Percent'] * df['Base_FVC']\n",
        "    df['WP_x_BaseFVC'] = df['Weeks_Passed'] * df['Base_FVC']\n",
        "    df['WP_x_Percent'] = df['Weeks_Passed'] * df['Percent']\n",
        "    df['WP_x_Age'] = df['Weeks_Passed'] * df['Age']\n",
        "    df['WP_x_slope_w'] = df.get('Weeks_Passed', 0.0) * df.get('slope_w', 0.0)\n",
        "    df['WP_x_r2_w'] = df.get('Weeks_Passed', 0.0) * df.get('r2_w', 0.0)\n",
        "    if 'n_obs' not in df.columns: df['n_obs'] = 1\n",
        "    if 'has_trend' not in df.columns: df['has_trend'] = 0\n",
        "    if 'is_singleton' not in df.columns: df['is_singleton'] = (df['n_obs'] <= 1).astype(int)\n",
        "    return df\n",
        "\n",
        "def train_residual_and_sigma(train_df, n_splits=5, seed=42):\n",
        "    gkf = GroupKFold(n_splits=n_splits)\n",
        "    groups = train_df['Patient'].values\n",
        "    oof_pred = np.zeros(len(train_df), dtype=float)\n",
        "    oof_res = np.zeros(len(train_df), dtype=float)\n",
        "    oof_abs_res = np.zeros(len(train_df), dtype=float)\n",
        "    oof_dist = np.zeros(len(train_df), dtype=float)\n",
        "    folds_info = []\n",
        "    t0 = time.time()\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(train_df, groups=groups), 1):\n",
        "        t_fold = time.time()\n",
        "        trn = train_df.iloc[trn_idx].copy()\n",
        "        val = train_df.iloc[val_idx].copy()\n",
        "        slopes = compute_patient_slopes(trn)\n",
        "        g_slope = robust_global_slope(slopes)\n",
        "        base_val = (val.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'}))\n",
        "        val = val.merge(base_val, on='Patient', how='left')\n",
        "        base_trn = (trn.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'}))\n",
        "        trn = trn.merge(base_trn, on='Patient', how='left')\n",
        "        stats_trn = compute_trend_stats(trn)\n",
        "        stats_trn['has_trend'] = (stats_trn['n_obs'] >= 2).astype(int)\n",
        "        trn = trn.merge(stats_trn, on='Patient', how='left')\n",
        "        val = val.merge(stats_trn, on='Patient', how='left')\n",
        "        for c, v in [('slope_w', 0.0), ('r2_w', 0.0)]:\n",
        "            trn[c] = trn[c].fillna(v); val[c] = val[c].fillna(v)\n",
        "        trn['n_obs'] = trn['n_obs'].fillna(1).astype(int)\n",
        "        val['n_obs'] = val['n_obs'].fillna(1).astype(int)\n",
        "        trn['has_trend'] = trn['has_trend'].fillna(0).astype(int)\n",
        "        val['has_trend'] = val['has_trend'].fillna(0).astype(int)\n",
        "        trn['is_singleton'] = (trn['n_obs'] <= 1).astype(int)\n",
        "        val['is_singleton'] = (val['n_obs'] <= 1).astype(int)\n",
        "        trn['pred0'] = trn['Base_FVC'] + g_slope * (trn['Weeks'] - trn['Base_Week'])\n",
        "        val['pred0'] = val['Base_FVC'] + g_slope * (val['Weeks'] - val['Base_Week'])\n",
        "        cat_cols = ['Sex','SmokingStatus']\n",
        "        cats = one_hot_fit(trn, cat_cols)\n",
        "        trnF = one_hot_transform(build_features(trn), cats)\n",
        "        valF = one_hot_transform(build_features(val), cats)\n",
        "        feat_cols = [\n",
        "            'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed2','Weeks_Passed3','Percent','Percent2','Age','Base_FVC',\n",
        "            'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "            'slope_w','r2_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w'\n",
        "        ] + [c for c in trnF.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "        y_trn = (trn['FVC'] - trn['pred0']).astype(float).values\n",
        "        y_val = (val['FVC'] - val['pred0']).astype(float).values\n",
        "        dtrain = xgb.DMatrix(trnF[feat_cols], label=y_trn)\n",
        "        dvalid = xgb.DMatrix(valF[feat_cols], label=y_val)\n",
        "        params = {\n",
        "            'objective': 'reg:absoluteerror',\n",
        "            'eval_metric': 'mae',\n",
        "            'tree_method': 'gpu_hist',\n",
        "            'learning_rate': 0.05,\n",
        "            'max_depth': 5,\n",
        "            'subsample': 0.9,\n",
        "            'colsample_bytree': 0.9,\n",
        "            'min_child_weight': 10,\n",
        "            'lambda': 3.0,\n",
        "            'verbosity': 0\n",
        "        }\n",
        "        model = xgb.train(params, dtrain, num_boost_round=3000, evals=[(dtrain,'trn'),(dvalid,'val')],\n",
        "                          early_stopping_rounds=200, verbose_eval=False)\n",
        "        val_pred_res = model.predict(dvalid, iteration_range=(0, model.best_iteration+1))\n",
        "        val_pred = val['pred0'].values + val_pred_res\n",
        "        oof_pred[val_idx] = val_pred\n",
        "        oof_res[val_idx] = val['FVC'].values - val_pred\n",
        "        oof_abs_res[val_idx] = np.abs(oof_res[val_idx])\n",
        "        oof_dist[val_idx] = np.abs(val['Weeks'].values - val['Base_Week'].values).astype(float)\n",
        "        mae = float(np.mean(np.abs(val['FVC'].values - val_pred)))\n",
        "        print(f'[Fold {fold}] n_trn={trn.shape[0]} n_val={val.shape[0]} g_slope={g_slope:.4f} MAE={mae:.2f} iters={model.best_iteration+1} elapsed={time.time()-t_fold:.2f}s', flush=True)\n",
        "        folds_info.append({'fold': fold, 'g_slope': g_slope, 'best_iter': int(model.best_iteration+1)})\n",
        "        del dtrain, dvalid, model, trnF, valF; gc.collect()\n",
        "    grid_a = [70, 90, 110, 130, 160, 200]\n",
        "    grid_b = [0.0, 0.5, 1.0, 2.0, 3.0]\n",
        "    grid_s = [0.0, 0.5, 1.0, 1.5, 2.0]\n",
        "    best = (-1e9, None, None, None)\n",
        "    for a in grid_a:\n",
        "        for b in grid_b:\n",
        "            for s in grid_s:\n",
        "                sig = a + b * oof_dist + s * oof_abs_res\n",
        "                score = laplace_ll(train_df['FVC'].values, oof_pred, sig)\n",
        "                if score > best[0]:\n",
        "                    best = (score, a, b, s)\n",
        "    print(f'Best OOF Laplace (residual+sigma): {best[0]:.5f} with a={best[1]} b={best[2]} s={best[3]}. Total elapsed {time.time()-t0:.2f}s', flush=True)\n",
        "    return oof_pred, oof_res, oof_abs_res, oof_dist, best, folds_info\n",
        "\n",
        "oof_pred2, oof_res2, oof_abs_res2, oof_dist2, (best_ll2, best_a2, best_b2, best_s2), folds_info = train_residual_and_sigma(train)\n",
        "\n",
        "slopes_full = compute_patient_slopes(train)\n",
        "g_slope_full = robust_global_slope(slopes_full)\n",
        "base_full = (train.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'}))\n",
        "train_full = train.merge(base_full, on='Patient', how='left')\n",
        "stats_full = compute_trend_stats(train_full)\n",
        "stats_full['has_trend'] = (stats_full['n_obs'] >= 2).astype(int)\n",
        "train_full = train_full.merge(stats_full, on='Patient', how='left')\n",
        "for c, v in [('slope_w', 0.0), ('r2_w', 0.0)]:\n",
        "    train_full[c] = train_full[c].fillna(v)\n",
        "train_full['n_obs'] = train_full['n_obs'].fillna(1).astype(int)\n",
        "train_full['has_trend'] = train_full['has_trend'].fillna(0).astype(int)\n",
        "train_full['is_singleton'] = (train_full['n_obs'] <= 1).astype(int)\n",
        "train_full['pred0'] = train_full['Base_FVC'] + g_slope_full * (train_full['Weeks'] - train_full['Base_Week'])\n",
        "train_full = one_hot_transform(build_features(train_full), one_hot_fit(train_full, ['Sex','SmokingStatus']))\n",
        "feat_cols_full = [\n",
        "    'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed2','Weeks_Passed3','Percent','Percent2','Age','Base_FVC',\n",
        "    'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "    'slope_w','r2_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w'\n",
        "] + [c for c in train_full.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "y_full = (train_full['FVC'] - train_full['pred0']).astype(float).values\n",
        "dtrain_full = xgb.DMatrix(train_full[feat_cols_full], label=y_full)\n",
        "params_full = {\n",
        "    'objective': 'reg:absoluteerror',\n",
        "    'eval_metric': 'mae',\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 5,\n",
        "    'subsample': 0.9,\n",
        "    'colsample_bytree': 0.9,\n",
        "    'min_child_weight': 10,\n",
        "    'lambda': 3.0,\n",
        "    'verbosity': 0\n",
        "}\n",
        "model_full = xgb.train(params_full, dtrain_full, num_boost_round=int(np.median([fi['best_iter'] for fi in folds_info])))\n",
        "\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "sub = ss.copy()\n",
        "parts = sub['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "sub['Patient'] = parts[0]\n",
        "sub['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'})\n",
        "sub = sub.merge(test_bl, on='Patient', how='left')\n",
        "meta = test[['Patient','Percent','Age','Sex','SmokingStatus']].drop_duplicates('Patient')\n",
        "sub = sub.merge(meta, on='Patient', how='left')\n",
        "sub = sub.merge(stats_full, on='Patient', how='left')\n",
        "for c, v in [('slope_w', 0.0), ('r2_w', 0.0)]:\n",
        "    sub[c] = sub[c].fillna(v)\n",
        "sub['n_obs'] = sub['n_obs'].fillna(1).astype(int)\n",
        "sub['has_trend'] = sub['has_trend'].fillna(0).astype(int)\n",
        "sub['is_singleton'] = (sub['n_obs'] <= 1).astype(int)\n",
        "sub['pred0'] = sub['Base_FVC'] + g_slope_full * (sub['Weeks'] - sub['Base_Week'])\n",
        "cats_full = one_hot_fit(train_full, ['Sex','SmokingStatus'])\n",
        "subF = one_hot_transform(build_features(sub), cats_full)\n",
        "dtest = xgb.DMatrix(subF[feat_cols_full])\n",
        "res_pred = model_full.predict(dtest)\n",
        "sub['FVC'] = (sub['pred0'] + res_pred).clip(500, 6000)\n",
        "sub['dist'] = (sub['Weeks'] - sub['Base_Week']).abs().astype(float)\n",
        "pred_abs_res_proxy = np.abs(res_pred)\n",
        "sub['Confidence'] = np.maximum(best_a2 + best_b2 * sub['dist'] + best_s2 * pred_abs_res_proxy, 70.0)\n",
        "submission2 = sub[['Patient_Week','FVC','Confidence']].copy()\n",
        "submission2['FVC'] = submission2['FVC'].astype(float)\n",
        "submission2['Confidence'] = submission2['Confidence'].astype(float)\n",
        "submission2.to_csv('submission.csv', index=False)\n",
        "print('Saved improved submission.csv. OOF Laplace (residual+sigma):', f'{best_ll2:.5f}', 'Global slope full:', f'{g_slope_full:.4f}')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 1] n_trn=1112 n_val=282 g_slope=-3.8062 MAE=160.75 iters=65 elapsed=0.61s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 2] n_trn=1113 n_val=281 g_slope=-3.5547 MAE=119.33 iters=4 elapsed=0.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 3] n_trn=1119 n_val=275 g_slope=-3.5065 MAE=137.12 iters=3 elapsed=0.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 4] n_trn=1119 n_val=275 g_slope=-3.5065 MAE=138.48 iters=367 elapsed=1.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold 5] n_trn=1113 n_val=281 g_slope=-3.6557 MAE=133.92 iters=130 elapsed=0.72s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best OOF Laplace (residual+sigma): -5.61465 with a=70 b=0.0 s=0.5. Total elapsed 4.01s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved improved submission.csv. OOF Laplace (residual+sigma): -5.61465 Global slope full: -3.6341\n"
          ]
        }
      ]
    },
    {
      "id": "a9290c4b-0fb3-433c-9ee3-24f2217787ab",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quantile XGBoost models (q20/q50/q80) for FVC and sigma from spread\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time, gc\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import xgboost as xgb\n",
        "\n",
        "def train_quantile_models(train_df, n_splits=5, seed=42):\n",
        "    gkf = GroupKFold(n_splits=n_splits)\n",
        "    groups = train_df['Patient'].values\n",
        "    oof_q20 = np.zeros(len(train_df), dtype=float)\n",
        "    oof_q50 = np.zeros(len(train_df), dtype=float)\n",
        "    oof_q80 = np.zeros(len(train_df), dtype=float)\n",
        "    oof_dist = np.zeros(len(train_df), dtype=float)\n",
        "    folds_info = []  # store per-quantile best iters\n",
        "    t0 = time.time()\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(train_df, groups=groups), 1):\n",
        "        tf = time.time()\n",
        "        trn = train_df.iloc[trn_idx].copy()\n",
        "        val = train_df.iloc[val_idx].copy()\n",
        "\n",
        "        # Global slope from TRAIN only\n",
        "        slopes = compute_patient_slopes(trn)\n",
        "        g_slope = robust_global_slope(slopes)\n",
        "\n",
        "        # Anchor VAL at its own baseline (min Weeks) within VAL; anchor TRAIN within TRAIN\n",
        "        base_val = (val.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'}))\n",
        "        val = val.merge(base_val, on='Patient', how='left')\n",
        "        base_trn = (trn.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'}))\n",
        "        trn = trn.merge(base_trn, on='Patient', how='left')\n",
        "\n",
        "        # TRAIN-only trend stats, merged into TRAIN/VAL with backoff\n",
        "        stats_trn = compute_trend_stats(trn)\n",
        "        stats_trn['has_trend'] = (stats_trn['n_obs'] >= 2).astype(int)\n",
        "        trn = trn.merge(stats_trn, on='Patient', how='left')\n",
        "        val = val.merge(stats_trn, on='Patient', how='left')\n",
        "        for c, v in [('slope_w', 0.0), ('r2_w', 0.0)]:\n",
        "            trn[c] = trn[c].fillna(v); val[c] = val[c].fillna(v)\n",
        "        trn['n_obs'] = trn['n_obs'].fillna(1).astype(int)\n",
        "        val['n_obs'] = val['n_obs'].fillna(1).astype(int)\n",
        "        trn['has_trend'] = trn['has_trend'].fillna(0).astype(int)\n",
        "        val['has_trend'] = val['has_trend'].fillna(0).astype(int)\n",
        "        trn['is_singleton'] = (trn['n_obs'] <= 1).astype(int)\n",
        "        val['is_singleton'] = (val['n_obs'] <= 1).astype(int)\n",
        "\n",
        "        # Build features\n",
        "        trnF = build_features(trn)\n",
        "        valF = build_features(val)\n",
        "        cats = one_hot_fit(trnF, ['Sex','SmokingStatus'])\n",
        "        trnF = one_hot_transform(trnF, cats)\n",
        "        valF = one_hot_transform(valF, cats)\n",
        "        feat_cols = [\n",
        "            'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed2','Weeks_Passed3','Percent','Percent2','Age','Base_FVC',\n",
        "            'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "            'slope_w','r2_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w'\n",
        "        ] + [c for c in trnF.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "\n",
        "        # Targets are FVC directly\n",
        "        y_trn = trn['FVC'].astype(float).values\n",
        "        y_val = val['FVC'].astype(float).values\n",
        "\n",
        "        # Prepare DMatrices\n",
        "        dtrain = xgb.DMatrix(trnF[feat_cols], label=y_trn)\n",
        "        dvalid = xgb.DMatrix(valF[feat_cols], label=y_val)\n",
        "\n",
        "        q_alphas = [0.2, 0.5, 0.8]\n",
        "        oof_preds_fold = {}\n",
        "        best_iters = {}\n",
        "        for qa in q_alphas:\n",
        "            params = {\n",
        "                'objective': 'reg:quantileerror',\n",
        "                'quantile_alpha': qa,\n",
        "                'eval_metric': 'quantile',\n",
        "                'tree_method': 'gpu_hist',\n",
        "                'learning_rate': 0.03,\n",
        "                'max_depth': 4,\n",
        "                'min_child_weight': 25,\n",
        "                'reg_alpha': 1.5,\n",
        "                'lambda': 7.0,\n",
        "                'subsample': 0.8,\n",
        "                'colsample_bytree': 0.8,\n",
        "                'verbosity': 0\n",
        "            }\n",
        "            watchlist = [(dtrain, 'trn'), (dvalid, 'val')]\n",
        "            model = xgb.train(params, dtrain, num_boost_round=4000, evals=watchlist,\n",
        "                              early_stopping_rounds=300, verbose_eval=False)\n",
        "            pred_val = model.predict(dvalid, iteration_range=(0, model.best_iteration+1))\n",
        "            oof_preds_fold[qa] = pred_val\n",
        "            best_iters[qa] = int(model.best_iteration + 1)\n",
        "            del model; gc.collect()\n",
        "\n",
        "        # Enforce non-crossing\n",
        "        P = np.vstack([oof_preds_fold[0.2], oof_preds_fold[0.5], oof_preds_fold[0.8]]).T\n",
        "        P.sort(axis=1)  # ascending: q20,q50,q80\n",
        "        oof_q20[val_idx] = P[:,0]\n",
        "        oof_q50[val_idx] = P[:,1]\n",
        "        oof_q80[val_idx] = P[:,2]\n",
        "        oof_dist[val_idx] = np.abs(val['Weeks'].values - val['Base_Week'].values).astype(float)\n",
        "\n",
        "        mae = float(np.mean(np.abs(y_val - oof_q50[val_idx])))\n",
        "        print(f'[Q-Fold {fold}] n_trn={trn.shape[0]} n_val={val.shape[0]} g_slope={g_slope:.4f} MAE(median)={mae:.2f} iters={best_iters} elapsed={time.time()-tf:.2f}s', flush=True)\n",
        "        folds_info.append({'fold': fold, 'best_iters': best_iters})\n",
        "\n",
        "        del dtrain, dvalid, trnF, valF; gc.collect()\n",
        "\n",
        "    # Tune sigma scale (and optional a,b) on OOF\n",
        "    spreads = (oof_q80 - oof_q20).clip(min=1e-6)\n",
        "    best = (-1e9, None, None, None)\n",
        "    for scale in np.arange(0.8, 2.05, 0.1):\n",
        "        sigma = np.maximum(scale * spreads, 70.0)\n",
        "        score = laplace_ll(train_df['FVC'].values, oof_q50, sigma)\n",
        "        if score > best[0]:\n",
        "            best = (score, scale, 0.0, 0.0)\n",
        "    # try hybrid with small a,b\n",
        "    for scale in np.arange(0.8, 2.05, 0.1):\n",
        "        for a in [0.0, 70.0]:\n",
        "            for b in [0.0, 0.5, 1.0]:\n",
        "                sigma = a + b * oof_dist + scale * spreads\n",
        "                sigma = np.maximum(sigma, 70.0)\n",
        "                score = laplace_ll(train_df['FVC'].values, oof_q50, sigma)\n",
        "                if score > best[0]:\n",
        "                    best = (score, scale, a, b)\n",
        "    print(f'Best OOF Laplace (quantile): {best[0]:.5f} with scale={best[1]} a={best[2]} b={best[3]}. Total elapsed {time.time()-t0:.2f}s', flush=True)\n",
        "    return (oof_q20, oof_q50, oof_q80, oof_dist), best, folds_info\n",
        "\n",
        "# Train quantile models and tune sigma\n",
        "(oof_q20, oof_q50, oof_q80, oof_dist_q), (best_ll_q, best_scale, best_a_q, best_b_q), folds_info_q = train_quantile_models(train)\n",
        "\n",
        "# Fit full quantile models\n",
        "base_full = (train.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'}))\n",
        "train_full_q = train.merge(base_full, on='Patient', how='left')\n",
        "stats_full_q = compute_trend_stats(train_full_q)\n",
        "stats_full_q['has_trend'] = (stats_full_q['n_obs'] >= 2).astype(int)\n",
        "train_full_q = train_full_q.merge(stats_full_q, on='Patient', how='left')\n",
        "for c, v in [('slope_w', 0.0), ('r2_w', 0.0)]:\n",
        "    train_full_q[c] = train_full_q[c].fillna(v)\n",
        "train_full_q['n_obs'] = train_full_q['n_obs'].fillna(1).astype(int)\n",
        "train_full_q['has_trend'] = train_full_q['has_trend'].fillna(0).astype(int)\n",
        "train_full_q['is_singleton'] = (train_full_q['n_obs'] <= 1).astype(int)\n",
        "train_full_q = build_features(train_full_q)\n",
        "cats_full_q = one_hot_fit(train_full_q, ['Sex','SmokingStatus'])\n",
        "train_full_q = one_hot_transform(train_full_q, cats_full_q)\n",
        "feat_cols_q = [\n",
        "    'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed2','Weeks_Passed3','Percent','Percent2','Age','Base_FVC',\n",
        "    'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "    'slope_w','r2_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w'\n",
        "] + [c for c in train_full_q.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "dtrain_full_q = xgb.DMatrix(train_full_q[feat_cols_q], label=train_full_q['FVC'].astype(float).values)\n",
        "\n",
        "best_iters_median = int(np.median([fi['best_iters'][0.5] for fi in folds_info_q]))\n",
        "best_iters_low = int(np.median([fi['best_iters'][0.2] for fi in folds_info_q]))\n",
        "best_iters_high = int(np.median([fi['best_iters'][0.8] for fi in folds_info_q]))\n",
        "\n",
        "def fit_quantile_full(alpha, num_boost_round):\n",
        "    params = {\n",
        "        'objective': 'reg:quantileerror',\n",
        "        'quantile_alpha': alpha,\n",
        "        'eval_metric': 'quantile',\n",
        "        'tree_method': 'gpu_hist',\n",
        "        'learning_rate': 0.03,\n",
        "        'max_depth': 4,\n",
        "        'min_child_weight': 25,\n",
        "        'reg_alpha': 1.5,\n",
        "        'lambda': 7.0,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'verbosity': 0\n",
        "    }\n",
        "    return xgb.train(params, dtrain_full_q, num_boost_round=num_boost_round)\n",
        "\n",
        "model_q20 = fit_quantile_full(0.2, best_iters_low)\n",
        "model_q50 = fit_quantile_full(0.5, best_iters_median)\n",
        "model_q80 = fit_quantile_full(0.8, best_iters_high)\n",
        "\n",
        "# Build submission grid and predict quantiles\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "subq = ss.copy()\n",
        "parts = subq['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "subq['Patient'] = parts[0]\n",
        "subq['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'})\n",
        "subq = subq.merge(test_bl, on='Patient', how='left')\n",
        "meta = test[['Patient','Percent','Age','Sex','SmokingStatus']].drop_duplicates('Patient')\n",
        "subq = subq.merge(meta, on='Patient', how='left')\n",
        "subq = subq.merge(stats_full_q, on='Patient', how='left')\n",
        "for c, v in [('slope_w', 0.0), ('r2_w', 0.0)]:\n",
        "    subq[c] = subq[c].fillna(v)\n",
        "subq['n_obs'] = subq['n_obs'].fillna(1).astype(int)\n",
        "subq['has_trend'] = subq['has_trend'].fillna(0).astype(int)\n",
        "subq['is_singleton'] = (subq['n_obs'] <= 1).astype(int)\n",
        "subq = build_features(subq)\n",
        "subq = one_hot_transform(subq, cats_full_q)\n",
        "dtest_q = xgb.DMatrix(subq[feat_cols_q])\n",
        "pred_q20 = model_q20.predict(dtest_q)\n",
        "pred_q50 = model_q50.predict(dtest_q)\n",
        "pred_q80 = model_q80.predict(dtest_q)\n",
        "Ptest = np.vstack([pred_q20, pred_q50, pred_q80]).T\n",
        "Ptest.sort(axis=1)\n",
        "pred_med = Ptest[:,1]\n",
        "spread = (Ptest[:,2] - Ptest[:,0]).clip(min=1e-6)\n",
        "\n",
        "# Sigma from tuned quantile spread (hybrid with a,b if selected)\n",
        "dist_test = (subq['Weeks'] - subq['Base_Week']).abs().astype(float).values\n",
        "sigma_test = best_scale * spread + best_a_q + best_b_q * dist_test\n",
        "sigma_test = np.maximum(sigma_test, 70.0)\n",
        "\n",
        "# Write submission with quantile median and sigma\n",
        "sub_final = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': pred_med.astype(float),\n",
        "    'Confidence': sigma_test.astype(float)\n",
        "})\n",
        "sub_final.to_csv('submission.csv', index=False)\n",
        "print('Saved quantile-based submission.csv. Best OOF Laplace (quantile):', f'{best_ll_q:.5f}', 'iters(med/low/high)=', best_iters_median, best_iters_low, best_iters_high)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Q-Fold 1] n_trn=1112 n_val=282 g_slope=-3.8062 MAE(median)=167.72 iters={0.2: 1743, 0.5: 199, 0.8: 282} elapsed=6.08s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Q-Fold 2] n_trn=1113 n_val=281 g_slope=-3.5547 MAE(median)=163.46 iters={0.2: 314, 0.5: 314, 0.8: 196} elapsed=3.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Q-Fold 3] n_trn=1119 n_val=275 g_slope=-3.5065 MAE(median)=158.71 iters={0.2: 748, 0.5: 277, 0.8: 233} elapsed=4.17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Q-Fold 4] n_trn=1119 n_val=275 g_slope=-3.5065 MAE(median)=142.75 iters={0.2: 1078, 0.5: 333, 0.8: 282} elapsed=4.97s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Q-Fold 5] n_trn=1113 n_val=281 g_slope=-3.6557 MAE(median)=125.08 iters={0.2: 366, 0.5: 164, 0.8: 883} elapsed=4.50s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best OOF Laplace (quantile): -6.04570 with scale=0.8 a=0.0 b=0.5. Total elapsed 23.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved quantile-based submission.csv. Best OOF Laplace (quantile): -6.04570 iters(med/low/high)= 277 748 282\n"
          ]
        }
      ]
    },
    {
      "id": "7d0ad6bf-36d5-4eec-8db4-84a766a7a5a9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Blend residual model (FVC_res) with quantile median (FVC_q50) using OOF-tuned weight; keep sigma from quantiles\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Tune blend weight w on OOF to maximize Laplace LL with quantile-derived sigma\n",
        "y_true = train['FVC'].values.astype(float)\n",
        "pred_q50_oof = oof_q50  # from quantile CV\n",
        "pred_res_oof = oof_pred2 # from residual CV\n",
        "spreads_oof = (oof_q80 - oof_q20).clip(min=1e-6)\n",
        "sigma_oof = np.maximum(best_a_q + best_b_q * oof_dist_q + best_scale * spreads_oof, 70.0)\n",
        "\n",
        "best = (-1e9, None)\n",
        "for w in np.linspace(0.0, 1.0, 21):\n",
        "    y_pred_blend = w * pred_q50_oof + (1.0 - w) * pred_res_oof\n",
        "    score = laplace_ll(y_true, y_pred_blend, sigma_oof)\n",
        "    if score > best[0]:\n",
        "        best = (score, w)\n",
        "print(f'Best OOF Laplace (blend): {best[0]:.5f} at w={best[1]:.2f}')\n",
        "w_best = best[1] if best[1] is not None else 1.0\n",
        "\n",
        "# Recompute residual-model test predictions (fast; reuse trained model_full / features)\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "meta = test[['Patient','Percent','Age','Sex','SmokingStatus']].drop_duplicates('Patient')\n",
        "grid = grid.merge(meta, on='Patient', how='left')\n",
        "grid = grid.merge(stats_full, on='Patient', how='left')\n",
        "for c, v in [('slope_w', 0.0), ('r2_w', 0.0)]:\n",
        "    grid[c] = grid[c].fillna(v)\n",
        "grid['n_obs'] = grid['n_obs'].fillna(1).astype(int)\n",
        "grid['has_trend'] = grid['has_trend'].fillna(0).astype(int)\n",
        "grid['is_singleton'] = (grid['n_obs'] <= 1).astype(int)\n",
        "grid['pred0'] = grid['Base_FVC'] + g_slope_full * (grid['Weeks'] - grid['Base_Week'])\n",
        "gridF = build_features(grid)\n",
        "gridF = one_hot_transform(gridF, cats_full)\n",
        "dgrid = xgb.DMatrix(gridF[feat_cols_full])\n",
        "residual_pred_test = model_full.predict(dgrid)\n",
        "fvc_res_test = (grid['pred0'].values + residual_pred_test).clip(500, 6000)\n",
        "\n",
        "# Quantile test predictions already computed in cell 5: pred_med, sigma_test\n",
        "# Blend FVC and keep sigma from quantiles\n",
        "fvc_blend = w_best * pred_med + (1.0 - w_best) * fvc_res_test\n",
        "submission_blend = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_blend.astype(float),\n",
        "    'Confidence': sigma_test.astype(float)\n",
        "})\n",
        "submission_blend.to_csv('submission.csv', index=False)\n",
        "print('Saved blended submission.csv using w=', w_best)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best OOF Laplace (blend): -5.96107 at w=0.25\nSaved blended submission.csv using w= 0.25\n"
          ]
        }
      ]
    },
    {
      "id": "9cfdb956-e8b0-4b3f-9410-27fce826226d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# FE v2 + more regularized XGB residual model with extrapolation guardrails\n",
        "import sys, subprocess, time, math, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def laplace_ll(y_true, y_pred, sigma):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    y_pred = np.asarray(y_pred).astype(float)\n",
        "    sigma = np.asarray(sigma).astype(float)\n",
        "    delta = np.abs(y_true - y_pred)\n",
        "    delta = np.minimum(delta, 1000.0)\n",
        "    sigma = np.maximum(sigma, 70.0)\n",
        "    return np.mean(-delta / sigma - np.log(sigma))\n",
        "\n",
        "def ensure_xgboost():\n",
        "    try:\n",
        "        import xgboost as xgb  # noqa\n",
        "        return\n",
        "    except Exception:\n",
        "        print('Installing xgboost...', flush=True)\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', 'xgboost==2.0.3', '--no-input'], check=True)\n",
        "        import xgboost as xgb  # noqa\n",
        "\n",
        "ensure_xgboost()\n",
        "import xgboost as xgb\n",
        "\n",
        "if 'train' not in globals():\n",
        "    train = pd.read_csv('train.csv')\n",
        "if 'test' not in globals():\n",
        "    test = pd.read_csv('test.csv')\n",
        "\n",
        "def compute_patient_slopes(df, patient_col='Patient', week_col='Weeks', target_col='FVC'):\n",
        "    slopes = {}\n",
        "    for pid, g in df.groupby(patient_col):\n",
        "        if g.shape[0] >= 2:\n",
        "            x = g[week_col].values.astype(float)\n",
        "            y = g[target_col].values.astype(float)\n",
        "            xm = x.mean(); ym = y.mean()\n",
        "            denom = ((x - xm)**2).sum()\n",
        "            slope = ((x - xm) * (y - ym)).sum() / denom if denom > 0 else 0.0\n",
        "            slopes[pid] = slope\n",
        "    return slopes\n",
        "\n",
        "def compute_trend_stats(df, patient_col='Patient', week_col='Weeks', target_col='FVC'):\n",
        "    rows = []\n",
        "    for pid, g in df.groupby(patient_col):\n",
        "        n = g.shape[0]\n",
        "        if n >= 2:\n",
        "            x = g[week_col].values.astype(float)\n",
        "            y = g[target_col].values.astype(float)\n",
        "            xm = x.mean(); ym = y.mean()\n",
        "            denom = ((x - xm)**2).sum()\n",
        "            if denom > 0:\n",
        "                slope = ((x - xm) * (y - ym)).sum() / denom\n",
        "                yhat = ym + slope * (x - xm)\n",
        "                ss_res = ((y - yhat)**2).sum()\n",
        "                ss_tot = ((y - ym)**2).sum()\n",
        "                r2 = 1.0 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
        "            else:\n",
        "                slope, r2 = 0.0, 0.0\n",
        "            rows.append((pid, slope, r2, n))\n",
        "        else:\n",
        "            rows.append((pid, 0.0, 0.0, n))\n",
        "    return pd.DataFrame(rows, columns=[patient_col, 'slope_w', 'r2_w', 'n_obs'])\n",
        "\n",
        "def compute_percent_trend_stats(df, patient_col='Patient', week_col='Weeks', percent_col='Percent'):\n",
        "    rows = []\n",
        "    for pid, g in df.groupby(patient_col):\n",
        "        n = g.shape[0]\n",
        "        if n >= 2:\n",
        "            x = g[week_col].values.astype(float)\n",
        "            y = g[percent_col].values.astype(float)\n",
        "            xm = x.mean(); ym = y.mean()\n",
        "            denom = ((x - xm)**2).sum()\n",
        "            slope = ((x - xm) * (y - ym)).sum() / denom if denom > 0 else 0.0\n",
        "            rows.append((pid, slope))\n",
        "        else:\n",
        "            rows.append((pid, 0.0))\n",
        "    return pd.DataFrame(rows, columns=[patient_col, 'slope_percent_w'])\n",
        "\n",
        "def robust_global_slope(slopes_dict):\n",
        "    if not slopes_dict:\n",
        "        return 0.0\n",
        "    return float(np.median(list(slopes_dict.values())))\n",
        "\n",
        "def one_hot_fit(df, cols):\n",
        "    return {c: sorted(df[c].dropna().unique().tolist()) for c in cols}\n",
        "\n",
        "def one_hot_transform(df, cats):\n",
        "    out = df.copy()\n",
        "    for c, values in cats.items():\n",
        "        for v in values:\n",
        "            out[f'{c}__{v}'] = (out[c] == v).astype(np.int8)\n",
        "    return out\n",
        "\n",
        "def build_features_v2(df, cap_wp=26):\n",
        "    df = df.copy()\n",
        "    df['Weeks_Passed'] = (df['Weeks'] - df['Base_Week']).astype(float)\n",
        "    df['Abs_Weeks_Passed'] = df['Weeks_Passed'].abs()\n",
        "    df['sign_WP'] = np.sign(df['Weeks_Passed']).astype(float)\n",
        "    df['is_future'] = (df['Weeks_Passed'] > 0).astype(np.int8)\n",
        "    df['Weeks_Passed_cap'] = df['Weeks_Passed'].clip(-cap_wp, cap_wp)\n",
        "    df['Weeks_Passed2'] = df['Weeks_Passed_cap'] ** 2\n",
        "    # Percent handling\n",
        "    df['Percent_clipped'] = df['Percent'].clip(40, 120)\n",
        "    df['Percent2'] = df['Percent_clipped'] ** 2\n",
        "    # Base features\n",
        "    df['log_BaseFVC'] = np.log1p(df['Base_FVC'].clip(lower=1))\n",
        "    df['Estimated_TLC'] = df['Base_FVC'] / (df['Percent_clipped'] / 100.0)\n",
        "    df['log_TLC'] = np.log1p(df['Estimated_TLC'].clip(lower=1))\n",
        "    # Interactions (using capped WP where appropriate)\n",
        "    df['Age_x_Percent'] = df['Age'] * df['Percent_clipped']\n",
        "    df['Percent_x_BaseFVC'] = df['Percent_clipped'] * df['Base_FVC']\n",
        "    df['WP_x_BaseFVC'] = df['Weeks_Passed_cap'] * df['Base_FVC']\n",
        "    df['WP_x_Percent'] = df['Weeks_Passed_cap'] * df['Percent_clipped']\n",
        "    df['WP_x_Age'] = df['Weeks_Passed_cap'] * df['Age']\n",
        "    if 'slope_w' in df.columns:\n",
        "        df['WP_x_slope_w'] = df['Weeks_Passed_cap'] * df['slope_w'].clip(-50, 10)\n",
        "    else:\n",
        "        df['WP_x_slope_w'] = 0.0\n",
        "    if 'r2_w' in df.columns:\n",
        "        df['WP_x_r2_w'] = df['Weeks_Passed_cap'] * df['r2_w']\n",
        "    else:\n",
        "        df['WP_x_r2_w'] = 0.0\n",
        "    if 'slope_percent_w' in df.columns:\n",
        "        df['WP_x_slope_percent_w'] = df['Weeks_Passed_cap'] * df['slope_percent_w']\n",
        "    else:\n",
        "        df['WP_x_slope_percent_w'] = 0.0\n",
        "    # dPercent relative to baseline percent if available\n",
        "    if 'Percent_at_base' in df.columns:\n",
        "        df['dPercent'] = df['Percent_clipped'] - df['Percent_at_base']\n",
        "        df['WP_x_dPercent'] = df['Weeks_Passed_cap'] * df['dPercent']\n",
        "    else:\n",
        "        df['dPercent'] = 0.0\n",
        "        df['WP_x_dPercent'] = 0.0\n",
        "    # flags\n",
        "    if 'n_obs' not in df.columns:\n",
        "        df['n_obs'] = 1\n",
        "    if 'has_trend' not in df.columns:\n",
        "        df['has_trend'] = 0\n",
        "    df['is_singleton'] = (df['n_obs'] <= 1).astype(int)\n",
        "    return df\n",
        "\n",
        "def train_residual_and_sigma_v2(train_df, n_splits=5, seed=42):\n",
        "    gkf = GroupKFold(n_splits=n_splits)\n",
        "    groups = train_df['Patient'].values\n",
        "    oof_pred = np.zeros(len(train_df), dtype=float)\n",
        "    oof_res = np.zeros(len(train_df), dtype=float)\n",
        "    oof_abs_res = np.zeros(len(train_df), dtype=float)\n",
        "    oof_dist = np.zeros(len(train_df), dtype=float)\n",
        "    t0 = time.time()\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(train_df, groups=groups), 1):\n",
        "        tf = time.time()\n",
        "        trn = train_df.iloc[trn_idx].copy()\n",
        "        val = train_df.iloc[val_idx].copy()\n",
        "        # Anchor within TRAIN/VAL (baseline = earliest week within each split)\n",
        "        base_trn = (trn.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "        trn = trn.merge(base_trn, on='Patient', how='left')\n",
        "        base_val = (val.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "        val = val.merge(base_val, on='Patient', how='left')\n",
        "        # Train-only trend stats (FVC and Percent)\n",
        "        stats_trn = compute_trend_stats(trn)\n",
        "        stats_trn['has_trend'] = (stats_trn['n_obs'] >= 2).astype(int)\n",
        "        pstats_trn = compute_percent_trend_stats(trn)\n",
        "        trn = trn.merge(stats_trn, on='Patient', how='left')\n",
        "        trn = trn.merge(pstats_trn, on='Patient', how='left')\n",
        "        val = val.merge(stats_trn, on='Patient', how='left')\n",
        "        val = val.merge(pstats_trn, on='Patient', how='left')\n",
        "        for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "            trn[c] = trn[c].fillna(v); val[c] = val[c].fillna(v)\n",
        "        trn['n_obs'] = trn['n_obs'].fillna(1).astype(int)\n",
        "        val['n_obs'] = val['n_obs'].fillna(1).astype(int)\n",
        "        trn['has_trend'] = trn['has_trend'].fillna(0).astype(int)\n",
        "        val['has_trend'] = val['has_trend'].fillna(0).astype(int)\n",
        "\n",
        "        # Global slope from TRAIN patients only\n",
        "        g_slope = robust_global_slope(compute_patient_slopes(trn))\n",
        "        trn['pred0'] = trn['Base_FVC'] + g_slope * (trn['Weeks'] - trn['Base_Week'])\n",
        "        val['pred0'] = val['Base_FVC'] + g_slope * (val['Weeks'] - val['Base_Week'])\n",
        "\n",
        "        # Build features and one-hot\n",
        "        cat_cols = ['Sex','SmokingStatus']\n",
        "        cats = one_hot_fit(trn, cat_cols)\n",
        "        trnF = build_features_v2(trn)\n",
        "        valF = build_features_v2(val)\n",
        "        trnF = one_hot_transform(trnF, cats)\n",
        "        valF = one_hot_transform(valF, cats)\n",
        "\n",
        "        feat_cols = [\n",
        "            'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed_cap','Weeks_Passed2','sign_WP','is_future',\n",
        "            'Percent_clipped','Percent2','Age','Base_FVC','log_BaseFVC','Estimated_TLC','log_TLC',\n",
        "            'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "            'slope_w','r2_w','slope_percent_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w','WP_x_slope_percent_w','dPercent','WP_x_dPercent'\n",
        "        ] + [c for c in trnF.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "\n",
        "        # Residual targets\n",
        "        y_trn = (trn['FVC'] - trn['pred0']).astype(float).values\n",
        "        y_val = (val['FVC'] - val['pred0']).astype(float).values\n",
        "        dtrain = xgb.DMatrix(trnF[feat_cols], label=y_trn)\n",
        "        dvalid = xgb.DMatrix(valF[feat_cols], label=y_val)\n",
        "\n",
        "        params = {\n",
        "            'objective': 'reg:absoluteerror',\n",
        "            'eval_metric': 'mae',\n",
        "            'tree_method': 'gpu_hist',\n",
        "            'learning_rate': 0.03,\n",
        "            'max_depth': 4,\n",
        "            'subsample': 0.85,\n",
        "            'colsample_bytree': 0.85,\n",
        "            'min_child_weight': 25,\n",
        "            'lambda': 5.0,\n",
        "            'verbosity': 0\n",
        "        }\n",
        "        watchlist = [(dtrain, 'trn'), (dvalid, 'val')]\n",
        "        model = xgb.train(params, dtrain, num_boost_round=4000, evals=watchlist, early_stopping_rounds=300, verbose_eval=False)\n",
        "        val_pred_res = model.predict(dvalid, iteration_range=(0, model.best_iteration+1))\n",
        "        val_pred = val['pred0'].values + val_pred_res\n",
        "\n",
        "        # Store OOF\n",
        "        oof_pred[val_idx] = val_pred\n",
        "        oof_res[val_idx] = val['FVC'].values - val_pred\n",
        "        oof_abs_res[val_idx] = np.abs(oof_res[val_idx])\n",
        "        oof_dist[val_idx] = np.abs(val['Weeks'].values - val['Base_Week'].values).astype(float)\n",
        "\n",
        "        mae = float(np.mean(np.abs(val['FVC'].values - val_pred)))\n",
        "        print(f'[XGBv2-Fold {fold}] n_trn={trn.shape[0]} n_val={val.shape[0]} g_slope={g_slope:.4f} MAE={mae:.2f} iters={model.best_iteration+1} elapsed={time.time()-tf:.2f}s', flush=True)\n",
        "\n",
        "        del dtrain, dvalid, model, trnF, valF; gc.collect()\n",
        "\n",
        "    # Tune sigma = max(a + b*dist + s*|residual|, 70) on OOF\n",
        "    grid_a = [70, 110, 160, 200, 240]\n",
        "    grid_b = [0.5, 1.0, 2.0, 3.0]\n",
        "    grid_s = [0.5, 1.0]\n",
        "    best = (-1e9, None, None, None)\n",
        "    for a in grid_a:\n",
        "        for b in grid_b:\n",
        "            for s in grid_s:\n",
        "                sig = a + b * oof_dist + s * oof_abs_res\n",
        "                score = laplace_ll(train_df['FVC'].values, oof_pred, sig)\n",
        "                if score > best[0]:\n",
        "                    best = (score, a, b, s)\n",
        "    print(f'Best OOF Laplace (XGBv2): {best[0]:.5f} with a={best[1]} b={best[2]} s={best[3]}', flush=True)\n",
        "    return oof_pred, oof_abs_res, oof_dist, best\n",
        "\n",
        "# Train FE v2 residual model\n",
        "oof_pred_v2, oof_abs_v2, oof_dist_v2, (best_ll_v2, a2, b2, s2) = train_residual_and_sigma_v2(train)\n",
        "\n",
        "# Fit final model on full data with FE v2 and generate submission\n",
        "slopes_full = compute_patient_slopes(train)\n",
        "g_slope_full = robust_global_slope(slopes_full)\n",
        "base_full = (train.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "train_full_v2 = train.merge(base_full, on='Patient', how='left')\n",
        "stats_full = compute_trend_stats(train_full_v2)\n",
        "stats_full['has_trend'] = (stats_full['n_obs'] >= 2).astype(int)\n",
        "pstats_full = compute_percent_trend_stats(train_full_v2)\n",
        "train_full_v2 = train_full_v2.merge(stats_full, on='Patient', how='left').merge(pstats_full, on='Patient', how='left')\n",
        "for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "    train_full_v2[c] = train_full_v2[c].fillna(v)\n",
        "train_full_v2['n_obs'] = train_full_v2['n_obs'].fillna(1).astype(int)\n",
        "train_full_v2['has_trend'] = train_full_v2['has_trend'].fillna(0).astype(int)\n",
        "train_full_v2['pred0'] = train_full_v2['Base_FVC'] + g_slope_full * (train_full_v2['Weeks'] - train_full_v2['Base_Week'])\n",
        "cats_full = one_hot_fit(train_full_v2, ['Sex','SmokingStatus'])\n",
        "train_full_v2F = build_features_v2(train_full_v2)\n",
        "train_full_v2F = one_hot_transform(train_full_v2F, cats_full)\n",
        "feat_cols_full_v2 = [\n",
        "    'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed_cap','Weeks_Passed2','sign_WP','is_future',\n",
        "    'Percent_clipped','Percent2','Age','Base_FVC','log_BaseFVC','Estimated_TLC','log_TLC',\n",
        "    'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "    'slope_w','r2_w','slope_percent_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w','WP_x_slope_percent_w','dPercent','WP_x_dPercent'\n",
        "] + [c for c in train_full_v2F.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "y_full = (train_full_v2F['FVC'] - train_full_v2F['pred0']).astype(float).values\n",
        "dtrain_full = xgb.DMatrix(train_full_v2F[feat_cols_full_v2], label=y_full)\n",
        "params_full = {\n",
        "    'objective': 'reg:absoluteerror',\n",
        "    'eval_metric': 'mae',\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'learning_rate': 0.03,\n",
        "    'max_depth': 4,\n",
        "    'subsample': 0.85,\n",
        "    'colsample_bytree': 0.85,\n",
        "    'min_child_weight': 25,\n",
        "    'lambda': 5.0,\n",
        "    'verbosity': 0\n",
        "}\n",
        "model_full_v2 = xgb.train(params_full, dtrain_full, num_boost_round=800)\n",
        "\n",
        "# Build test grid and predict\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "meta = test[['Patient','Percent','Age','Sex','SmokingStatus']].drop_duplicates('Patient')\n",
        "grid = grid.merge(meta, on='Patient', how='left', suffixes=('', '_meta'))\n",
        "grid = grid.merge(stats_full, on='Patient', how='left').merge(pstats_full, on='Patient', how='left')\n",
        "for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "    grid[c] = grid[c].fillna(v)\n",
        "grid['n_obs'] = grid['n_obs'].fillna(1).astype(int)\n",
        "grid['has_trend'] = grid['has_trend'].fillna(0).astype(int)\n",
        "grid['is_singleton'] = (grid['n_obs'] <= 1).astype(int)\n",
        "grid['pred0'] = grid['Base_FVC'] + g_slope_full * (grid['Weeks'] - grid['Base_Week'])\n",
        "gridF = build_features_v2(grid)\n",
        "gridF = one_hot_transform(gridF, cats_full)\n",
        "dgrid = xgb.DMatrix(gridF[feat_cols_full_v2])\n",
        "res_pred = model_full_v2.predict(dgrid)\n",
        "fvc_pred = (gridF['pred0'].values + res_pred).clip(500, 6000)\n",
        "dist = (gridF['Weeks'] - gridF['Base_Week']).abs().astype(float).values\n",
        "sigma = np.maximum(a2 + b2 * dist + s2 * np.abs(res_pred), 70.0)\n",
        "\n",
        "submission_v2 = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_pred.astype(float),\n",
        "    'Confidence': sigma.astype(float)\n",
        "})\n",
        "submission_v2.to_csv('submission.csv', index=False)\n",
        "print('Saved FE v2 XGB residual submission.csv. Best OOF Laplace (XGBv2):', f'{best_ll_v2:.5f}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGBv2-Fold 1] n_trn=1112 n_val=282 g_slope=-3.8062 MAE=45.48 iters=3939 elapsed=7.72s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGBv2-Fold 2] n_trn=1113 n_val=281 g_slope=-3.5547 MAE=13.49 iters=3783 elapsed=7.68s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGBv2-Fold 3] n_trn=1119 n_val=275 g_slope=-3.5065 MAE=26.64 iters=3988 elapsed=7.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGBv2-Fold 4] n_trn=1119 n_val=275 g_slope=-3.5065 MAE=24.62 iters=3883 elapsed=7.72s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[XGBv2-Fold 5] n_trn=1113 n_val=281 g_slope=-3.6557 MAE=14.72 iters=2450 elapsed=5.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best OOF Laplace (XGBv2): -4.65387 with a=70 b=0.5 s=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved FE v2 XGB residual submission.csv. Best OOF Laplace (XGBv2): -4.65387\n"
          ]
        }
      ]
    },
    {
      "id": "c754100b-f460-4ff3-9aaf-e09914932aa6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CatBoost residual model (GPU) + blend with XGB residual; keep sigma from XGB residual model\n",
        "import sys, subprocess, gc, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def ensure_catboost():\n",
        "    try:\n",
        "        import catboost  # noqa: F401\n",
        "        return\n",
        "    except Exception:\n",
        "        print('Installing catboost...', flush=True)\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', 'catboost==1.2.5', '--no-input'], check=True)\n",
        "        import catboost  # noqa: F401\n",
        "\n",
        "ensure_catboost()\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "# Use same train/test already in memory; reuse feature builders and stats_full/g_slope_full from cell 4\n",
        "def train_catboost_residual(train_df, n_splits=5, seed=42):\n",
        "    gkf = GroupKFold(n_splits=n_splits)\n",
        "    groups = train_df['Patient'].values\n",
        "    oof_pred = np.zeros(len(train_df), dtype=float)\n",
        "    folds_info = []\n",
        "    t0 = time.time()\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(train_df, groups=groups), 1):\n",
        "        tf = time.time()\n",
        "        trn = train_df.iloc[trn_idx].copy()\n",
        "        val = train_df.iloc[val_idx].copy()\n",
        "        # Anchor within TRAIN/VAL\n",
        "        base_trn = (trn.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'}))\n",
        "        trn = trn.merge(base_trn, on='Patient', how='left')\n",
        "        base_val = (val.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'}))\n",
        "        val = val.merge(base_val, on='Patient', how='left')\n",
        "        # Trend stats from TRAIN-only\n",
        "        stats_trn = compute_trend_stats(trn)\n",
        "        stats_trn['has_trend'] = (stats_trn['n_obs'] >= 2).astype(int)\n",
        "        trn = trn.merge(stats_trn, on='Patient', how='left')\n",
        "        val = val.merge(stats_trn, on='Patient', how='left')\n",
        "        for c, v in [('slope_w', 0.0), ('r2_w', 0.0)]:\n",
        "            trn[c] = trn[c].fillna(v); val[c] = val[c].fillna(v)\n",
        "        trn['n_obs'] = trn['n_obs'].fillna(1).astype(int)\n",
        "        val['n_obs'] = val['n_obs'].fillna(1).astype(int)\n",
        "        trn['has_trend'] = trn['has_trend'].fillna(0).astype(int)\n",
        "        val['has_trend'] = val['has_trend'].fillna(0).astype(int)\n",
        "        trn['is_singleton'] = (trn['n_obs'] <= 1).astype(int)\n",
        "        val['is_singleton'] = (val['n_obs'] <= 1).astype(int)\n",
        "\n",
        "        # Baseline pred0 using global slope from TRAIN patients only\n",
        "        g_slope = robust_global_slope(compute_patient_slopes(trn))\n",
        "        trn['pred0'] = trn['Base_FVC'] + g_slope * (trn['Weeks'] - trn['Base_Week'])\n",
        "        val['pred0'] = val['Base_FVC'] + g_slope * (val['Weeks'] - val['Base_Week'])\n",
        "\n",
        "        # Build features and one-hot\n",
        "        trnF = build_features(trn)\n",
        "        valF = build_features(val)\n",
        "        cats = one_hot_fit(trnF, ['Sex','SmokingStatus'])\n",
        "        trnF = one_hot_transform(trnF, cats)\n",
        "        valF = one_hot_transform(valF, cats)\n",
        "        feat_cols = [\n",
        "            'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed2','Weeks_Passed3','Percent','Percent2','Age','Base_FVC',\n",
        "            'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "            'slope_w','r2_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w'\n",
        "        ] + [c for c in trnF.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "\n",
        "        y_trn = (trn['FVC'] - trn['pred0']).astype(float).values\n",
        "        y_val = (val['FVC'] - val['pred0']).astype(float).values\n",
        "\n",
        "        train_pool = Pool(trnF[feat_cols], label=y_trn)\n",
        "        valid_pool = Pool(valF[feat_cols], label=y_val)\n",
        "\n",
        "        model = CatBoostRegressor(\n",
        "            loss_function='MAE',\n",
        "            depth=6,\n",
        "            learning_rate=0.04,\n",
        "            l2_leaf_reg=6.0,\n",
        "            subsample=0.8,\n",
        "            iterations=5000,\n",
        "            od_type='Iter',\n",
        "            od_wait=300,\n",
        "            task_type='GPU',\n",
        "            random_seed=seed,\n",
        "            verbose=False\n",
        "        )\n",
        "        model.fit(train_pool, eval_set=valid_pool, use_best_model=True, verbose=False)\n",
        "        pred_res = model.predict(valid_pool)\n",
        "        val_pred = val['pred0'].values + pred_res\n",
        "        oof_pred[val_idx] = val_pred\n",
        "        mae = float(np.mean(np.abs(val['FVC'].values - val_pred)))\n",
        "        print(f'[CB-Fold {fold}] n_trn={trn.shape[0]} n_val={val.shape[0]} g_slope={g_slope:.4f} MAE={mae:.2f} elapsed={time.time()-tf:.2f}s', flush=True)\n",
        "        folds_info.append({'fold': fold})\n",
        "        del model, train_pool, valid_pool, trnF, valF; gc.collect()\n",
        "    print(f'CatBoost residual OOF ready in {time.time()-t0:.2f}s')\n",
        "    return oof_pred\n",
        "\n",
        "# Train CatBoost residual OOF\n",
        "oof_pred_cb = train_catboost_residual(train)\n",
        "\n",
        "# Tune blend between XGB residual (oof_pred2) and CatBoost residual (oof_pred_cb); sigma from XGB residual pipeline\n",
        "y_true = train['FVC'].values.astype(float)\n",
        "sigma_oof_res = np.maximum(best_a2 + best_b2 * oof_dist2 + best_s2 * oof_abs_res2, 70.0)\n",
        "best = (-1e9, None)\n",
        "for w in np.linspace(0.0, 1.0, 21):\n",
        "    y_pred_blend = w * oof_pred2 + (1.0 - w) * oof_pred_cb\n",
        "    score = laplace_ll(y_true, y_pred_blend, sigma_oof_res)\n",
        "    if score > best[0]:\n",
        "        best = (score, w)\n",
        "print(f'Best OOF Laplace (XGB-CB residual blend): {best[0]:.5f} at w={best[1]:.2f}')\n",
        "w_xgb = best[1] if best[1] is not None else 1.0\n",
        "\n",
        "# Fit CatBoost residual on full data and generate test predictions\n",
        "train_full_cb = train_full.copy()  # from cell 4, already has Base_Week/Base_FVC, trend stats, features schema ready\n",
        "train_full_cbF = train_full_cb.copy()\n",
        "train_full_cbF = one_hot_transform(train_full_cbF, cats_full)\n",
        "feat_cols_full_cb = feat_cols_full  # same feature list as XGB residual one-hot\n",
        "y_full_cb = (train_full_cbF['FVC'] - train_full_cbF['pred0']).astype(float).values\n",
        "pool_full = Pool(train_full_cbF[feat_cols_full_cb], label=y_full_cb)\n",
        "model_cb_full = CatBoostRegressor(\n",
        "    loss_function='MAE', depth=6, learning_rate=0.04, l2_leaf_reg=6.0,\n",
        "    subsample=0.8, iterations=int(np.median([fi['best_iter'] for fi in folds_info]))*2 + 300,\n",
        "    task_type='GPU', random_seed=42, verbose=False\n",
        ")\n",
        "model_cb_full.fit(pool_full, verbose=False)\n",
        "\n",
        "# Build test grid (same as in cell 4) and predict residuals with CatBoost\n",
        "grid = pd.read_csv('sample_submission.csv')\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "meta = test[['Patient','Percent','Age','Sex','SmokingStatus']].drop_duplicates('Patient')\n",
        "grid = grid.merge(meta, on='Patient', how='left')\n",
        "grid = grid.merge(stats_full, on='Patient', how='left')\n",
        "for c, v in [('slope_w', 0.0), ('r2_w', 0.0)]:\n",
        "    grid[c] = grid[c].fillna(v)\n",
        "grid['n_obs'] = grid['n_obs'].fillna(1).astype(int)\n",
        "grid['has_trend'] = grid['has_trend'].fillna(0).astype(int)\n",
        "grid['is_singleton'] = (grid['n_obs'] <= 1).astype(int)\n",
        "grid['pred0'] = grid['Base_FVC'] + g_slope_full * (grid['Weeks'] - grid['Base_Week'])\n",
        "gridF = build_features(grid)\n",
        "gridF = one_hot_transform(gridF, cats_full)\n",
        "pool_grid = Pool(gridF[feat_cols_full_cb])\n",
        "res_cb = model_cb_full.predict(pool_grid)\n",
        "fvc_cb = (gridF['pred0'].values + res_cb).clip(500, 6000)\n",
        "\n",
        "# Recompute XGB residual test pred from cell 4 objects (already exists as sub['FVC'])\n",
        "# Build again to be safe and consistent\n",
        "dgrid = xgb.DMatrix(gridF[feat_cols_full_cb])\n",
        "res_xgb = model_full.predict(dgrid)\n",
        "fvc_xgb = (gridF['pred0'].values + res_xgb).clip(500, 6000)\n",
        "\n",
        "# Blend XGB and CB residual FVC with tuned weight; use sigma from XGB residual pipeline for test\n",
        "fvc_blended = w_xgb * fvc_xgb + (1.0 - w_xgb) * fvc_cb\n",
        "sigma_test_residual = np.maximum(best_a2 + best_b2 * (gridF['Weeks'] - gridF['Base_Week']).abs().astype(float).values + best_s2 * np.abs(res_xgb), 70.0)\n",
        "\n",
        "submission_cbblend = pd.DataFrame({\n",
        "    'Patient_Week': pd.read_csv('sample_submission.csv')['Patient_Week'],\n",
        "    'FVC': fvc_blended.astype(float),\n",
        "    'Confidence': sigma_test_residual.astype(float)\n",
        "})\n",
        "submission_cbblend.to_csv('submission.csv', index=False)\n",
        "print('Saved CB+XGB residual blended submission.csv with w_xgb=', w_xgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f84fe8dc-22e3-402c-a493-01c9d3bf8cf2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Forward/grid CV to mimic test: anchored baseline model + dist-only sigma\n",
        "import time, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def laplace_ll(y_true, y_pred, sigma):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    y_pred = np.asarray(y_pred).astype(float)\n",
        "    sigma = np.asarray(sigma).astype(float)\n",
        "    delta = np.abs(y_true - y_pred)\n",
        "    delta = np.minimum(delta, 1000.0)\n",
        "    sigma = np.maximum(sigma, 70.0)\n",
        "    return np.mean(-delta / sigma - np.log(sigma))\n",
        "\n",
        "def compute_patient_slopes(df, patient_col='Patient', week_col='Weeks', target_col='FVC'):\n",
        "    slopes = {}\n",
        "    for pid, g in df.groupby(patient_col):\n",
        "        if g.shape[0] >= 2:\n",
        "            x = g[week_col].values.astype(float)\n",
        "            y = g[target_col].values.astype(float)\n",
        "            xm = x.mean(); ym = y.mean()\n",
        "            denom = ((x - xm)**2).sum()\n",
        "            slope = ((x - xm) * (y - ym)).sum() / denom if denom > 0 else 0.0\n",
        "            slopes[pid] = slope\n",
        "    return slopes\n",
        "\n",
        "def robust_global_slope(slopes_dict):\n",
        "    if not slopes_dict:\n",
        "        return 0.0\n",
        "    return float(np.median(list(slopes_dict.values())))\n",
        "\n",
        "def compute_trend_stats(df, patient_col='Patient', week_col='Weeks', target_col='FVC'):\n",
        "    rows = []\n",
        "    for pid, g in df.groupby(patient_col):\n",
        "        n = g.shape[0]\n",
        "        if n >= 2:\n",
        "            x = g[week_col].values.astype(float)\n",
        "            y = g[target_col].values.astype(float)\n",
        "            xm = x.mean(); ym = y.mean()\n",
        "            denom = ((x - xm)**2).sum()\n",
        "            if denom > 0:\n",
        "                slope = ((x - xm) * (y - ym)).sum() / denom\n",
        "                yhat = ym + slope * (x - xm)\n",
        "                ss_res = ((y - yhat)**2).sum()\n",
        "                ss_tot = ((y - ym)**2).sum()\n",
        "                r2 = 1.0 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
        "            else:\n",
        "                slope, r2 = 0.0, 0.0\n",
        "            rows.append((pid, slope, r2, n))\n",
        "        else:\n",
        "            rows.append((pid, 0.0, 0.0, n))\n",
        "    return pd.DataFrame(rows, columns=[patient_col, 'slope_w', 'r2_w', 'n_obs'])\n",
        "\n",
        "def forward_grid_cv_baseline(train_df, n_splits=5, seed=42):\n",
        "    gkf = GroupKFold(n_splits=n_splits)\n",
        "    groups = train_df['Patient'].values\n",
        "    y_true_all, y_pred_all, dist_all = [], [], []\n",
        "    t0 = time.time()\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(train_df, groups=groups), 1):\n",
        "        tf = time.time()\n",
        "        trn = train_df.iloc[trn_idx].copy()\n",
        "        val = train_df.iloc[val_idx].copy()\n",
        "\n",
        "        # Guards: disjoint patients\n",
        "        train_p = set(trn['Patient'].unique().tolist())\n",
        "        val_p = set(val['Patient'].unique().tolist())\n",
        "        assert train_p.isdisjoint(val_p), 'Fold leakage: overlapping patients'\n",
        "\n",
        "        # TRAIN-only trend stats and merge into VAL with backoff zeros (diagnostic only here)\n",
        "        stats_trn = compute_trend_stats(trn)\n",
        "        stats_trn['has_trend'] = (stats_trn['n_obs'] >= 2).astype(int)\n",
        "        val_stats = val.merge(stats_trn, on='Patient', how='left')\n",
        "        for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('n_obs', 1), ('has_trend', 0)]:\n",
        "            val_stats[c] = val_stats[c].fillna(v)\n",
        "        val_stats['is_singleton'] = (val_stats['n_obs'] <= 1).astype(int)\n",
        "        # Assert VAL patients have backoff zeros\n",
        "        assert (val_stats['slope_w'] == 0).all() and (val_stats['r2_w'] == 0).all(), 'VAL trend stats not zeroed'\n",
        "        assert (val_stats['n_obs'] == 1).all() and (val_stats['has_trend'] == 0).all() and (val_stats['is_singleton'] == 1).all(), 'VAL flags incorrect'\n",
        "\n",
        "        # Global slope from TRAIN patients only\n",
        "        g_slope = robust_global_slope(compute_patient_slopes(trn))\n",
        "\n",
        "        # For each VAL patient: baseline = earliest week within VAL; score weeks >= baseline that have GT\n",
        "        vb = (val.sort_values(['Patient','Weeks'])\n",
        "                .groupby('Patient', as_index=False)\n",
        "                .first()[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'}))\n",
        "        val = val.merge(vb, on='Patient', how='left')\n",
        "        # Baseline minimal checks\n",
        "        assert (val.groupby('Patient')['Base_Week'].transform('min') == val['Base_Week']).all(), 'Base_Week not min within VAL'\n",
        "\n",
        "        cnt_scored = 0\n",
        "        for pid, g in val.groupby('Patient'):\n",
        "            bw = int(g['Base_Week'].iloc[0])\n",
        "            bfvc = float(g['Base_FVC'].iloc[0])\n",
        "            g2 = g[g['Weeks'] >= bw].copy()  # forward-only scoring\n",
        "            if g2.empty:\n",
        "                continue\n",
        "            pred = bfvc + g_slope * (g2['Weeks'].values.astype(float) - bw)\n",
        "            dist = (g2['Weeks'].values.astype(float) - bw)\n",
        "            assert (dist >= 0).all(), 'Negative dist in forward scoring'\n",
        "            y_true_all.append(g2['FVC'].values.astype(float))\n",
        "            y_pred_all.append(pred.astype(float))\n",
        "            dist_all.append(dist.astype(float))\n",
        "            cnt_scored += len(g2)\n",
        "\n",
        "        mae = np.mean(np.abs(np.concatenate(y_true_all[-1:]) - np.concatenate(y_pred_all[-1:]))) if cnt_scored>0 else np.nan\n",
        "        print(f'[FWD-Fold {fold}] n_trn={trn.shape[0]} n_val={val.shape[0]} patients={len(val_p)} g_slope={g_slope:.4f} scored_rows={cnt_scored} elapsed={time.time()-tf:.2f}s', flush=True)\n",
        "\n",
        "        del trn, val, val_stats; gc.collect()\n",
        "\n",
        "    y_true = np.concatenate(y_true_all) if len(y_true_all)>0 else np.array([], float)\n",
        "    y_pred = np.concatenate(y_pred_all) if len(y_pred_all)>0 else np.array([], float)\n",
        "    dist = np.concatenate(dist_all) if len(dist_all)>0 else np.array([], float)\n",
        "    print(f'Total scored rows: {y_true.shape[0]} (of {len(train_df)}) in {time.time()-t0:.2f}s')\n",
        "\n",
        "    # Tune dist-only sigma\n",
        "    grid_a = [120, 160, 200, 240]\n",
        "    grid_b = [1.0, 2.0, 3.0]\n",
        "    best = (-1e9, None, None)\n",
        "    for a in grid_a:\n",
        "        for b in grid_b:\n",
        "            sig = a + b * dist\n",
        "            score = laplace_ll(y_true, y_pred, sig)\n",
        "            if score > best[0]:\n",
        "                best = (score, a, b)\n",
        "    print(f'Forward-CV OOF Laplace (anchored baseline): {best[0]:.5f} with a={best[1]} b={best[2]}')\n",
        "    return y_true, y_pred, dist, best\n",
        "\n",
        "# Run forward/grid CV anchored baseline\n",
        "y_true_fwd, y_pred_fwd, dist_fwd, (best_ll_fwd, a_fwd, b_fwd) = forward_grid_cv_baseline(train)\n",
        "\n",
        "# Train final anchored baseline on full data and write submission\n",
        "full_slopes = compute_patient_slopes(train)\n",
        "g_slope_full = robust_global_slope(full_slopes)\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "grid['FVC'] = (grid['Base_FVC'] + g_slope_full * (grid['Weeks'] - grid['Base_Week'])).clip(500, 6000)\n",
        "grid['dist'] = (grid['Weeks'] - grid['Base_Week']).abs().astype(float)\n",
        "grid['Confidence'] = np.maximum(a_fwd + b_fwd * grid['dist'], 70.0)\n",
        "submission_fwd = grid[['Patient_Week','FVC','Confidence']].copy()\n",
        "submission_fwd.to_csv('submission.csv', index=False)\n",
        "print('Saved forward-CV aligned submission.csv. Reported OOF LL:', f'{best_ll_fwd:.5f}', 'Full-train global slope:', f'{g_slope_full:.4f}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-Fold 1] n_trn=1112 n_val=282 patients=32 g_slope=-3.8062 scored_rows=282 elapsed=0.03s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-Fold 2] n_trn=1113 n_val=281 patients=32 g_slope=-3.5547 scored_rows=281 elapsed=0.03s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-Fold 3] n_trn=1119 n_val=275 patients=31 g_slope=-3.5065 scored_rows=275 elapsed=0.03s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-Fold 4] n_trn=1119 n_val=275 patients=31 g_slope=-3.5065 scored_rows=275 elapsed=0.03s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-Fold 5] n_trn=1113 n_val=281 patients=32 g_slope=-3.6557 scored_rows=281 elapsed=0.03s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total scored rows: 1394 (of 1394) in 0.51s\nForward-CV OOF Laplace (anchored baseline): -5.92555 with a=120 b=2.0\nSaved forward-CV aligned submission.csv. Reported OOF LL: -5.92555 Full-train global slope: -3.6341\n"
          ]
        }
      ]
    },
    {
      "id": "684cc559-3fb6-479e-8a60-a69d3625a0fa",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Forward/grid CV residual XGB with capped time features + sigma |residual| GBM\n",
        "import sys, subprocess, time, math, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def ensure_xgboost():\n",
        "    try:\n",
        "        import xgboost as xgb  # noqa\n",
        "        return\n",
        "    except Exception:\n",
        "        print('Installing xgboost...', flush=True)\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', 'xgboost==2.0.3', '--no-input'], check=True)\n",
        "        import xgboost as xgb  # noqa\n",
        "\n",
        "ensure_xgboost()\n",
        "import xgboost as xgb\n",
        "\n",
        "if 'train' not in globals():\n",
        "    train = pd.read_csv('train.csv')\n",
        "if 'test' not in globals():\n",
        "    test = pd.read_csv('test.csv')\n",
        "\n",
        "# Metric\n",
        "def laplace_ll(y_true, y_pred, sigma):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    y_pred = np.asarray(y_pred).astype(float)\n",
        "    sigma = np.asarray(sigma).astype(float)\n",
        "    delta = np.abs(y_true - y_pred)\n",
        "    delta = np.minimum(delta, 1000.0)\n",
        "    sigma = np.maximum(sigma, 70.0)\n",
        "    return np.mean(-delta / sigma - np.log(sigma))\n",
        "\n",
        "def compute_patient_slopes(df, patient_col='Patient', week_col='Weeks', target_col='FVC'):\n",
        "    slopes = {}\n",
        "    for pid, g in df.groupby(patient_col):\n",
        "        if g.shape[0] >= 2:\n",
        "            x = g[week_col].values.astype(float)\n",
        "            y = g[target_col].values.astype(float)\n",
        "            xm = x.mean(); ym = y.mean()\n",
        "            denom = ((x - xm)**2).sum()\n",
        "            slope = ((x - xm) * (y - ym)).sum() / denom if denom > 0 else 0.0\n",
        "            slopes[pid] = slope\n",
        "    return slopes\n",
        "\n",
        "def robust_global_slope(slopes_dict):\n",
        "    if not slopes_dict:\n",
        "        return 0.0\n",
        "    return float(np.median(list(slopes_dict.values())))\n",
        "\n",
        "def compute_trend_stats(df, patient_col='Patient', week_col='Weeks', target_col='FVC'):\n",
        "    rows = []\n",
        "    for pid, g in df.groupby(patient_col):\n",
        "        n = g.shape[0]\n",
        "        if n >= 2:\n",
        "            x = g[week_col].values.astype(float)\n",
        "            y = g[target_col].values.astype(float)\n",
        "            xm = x.mean(); ym = y.mean()\n",
        "            denom = ((x - xm)**2).sum()\n",
        "            if denom > 0:\n",
        "                slope = ((x - xm) * (y - ym)).sum() / denom\n",
        "                yhat = ym + slope * (x - xm)\n",
        "                ss_res = ((y - yhat)**2).sum()\n",
        "                ss_tot = ((y - ym)**2).sum()\n",
        "                r2 = 1.0 - (ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
        "            else:\n",
        "                slope, r2 = 0.0, 0.0\n",
        "            rows.append((pid, slope, r2, n))\n",
        "        else:\n",
        "            rows.append((pid, 0.0, 0.0, n))\n",
        "    return pd.DataFrame(rows, columns=[patient_col, 'slope_w', 'r2_w', 'n_obs'])\n",
        "\n",
        "def compute_percent_trend_stats(df, patient_col='Patient', week_col='Weeks', percent_col='Percent'):\n",
        "    rows = []\n",
        "    for pid, g in df.groupby(patient_col):\n",
        "        n = g.shape[0]\n",
        "        if n >= 2:\n",
        "            x = g[week_col].values.astype(float)\n",
        "            y = g[percent_col].values.astype(float)\n",
        "            xm = x.mean(); ym = y.mean()\n",
        "            denom = ((x - xm)**2).sum()\n",
        "            slope = ((x - xm) * (y - ym)).sum() / denom if denom > 0 else 0.0\n",
        "            rows.append((pid, slope))\n",
        "        else:\n",
        "            rows.append((pid, 0.0))\n",
        "    return pd.DataFrame(rows, columns=[patient_col, 'slope_percent_w'])\n",
        "\n",
        "def one_hot_fit(df, cols):\n",
        "    return {c: sorted(df[c].dropna().unique().tolist()) for c in cols}\n",
        "\n",
        "def one_hot_transform(df, cats):\n",
        "    out = df.copy()\n",
        "    for c, values in cats.items():\n",
        "        for v in values:\n",
        "            out[f'{c}__{v}'] = (out[c] == v).astype(np.int8)\n",
        "    return out\n",
        "\n",
        "def build_features_v2(df, cap_wp=26):\n",
        "    df = df.copy()\n",
        "    df['Weeks_Passed'] = (df['Weeks'] - df['Base_Week']).astype(float)\n",
        "    df['Abs_Weeks_Passed'] = df['Weeks_Passed'].abs()\n",
        "    df['is_future'] = (df['Weeks_Passed'] > 0).astype(np.int8)\n",
        "    df['sign_WP'] = np.sign(df['Weeks_Passed']).astype(float)\n",
        "    df['Weeks_Passed_cap'] = df['Weeks_Passed'].clip(-cap_wp, cap_wp)\n",
        "    df['Weeks_Passed2'] = df['Weeks_Passed_cap'] ** 2\n",
        "    # Percent handling: USE BASELINE ONLY to avoid leakage\n",
        "    df['Percent_clipped'] = df['Percent_at_base'].clip(40, 120)\n",
        "    df['Percent2'] = df['Percent_clipped'] ** 2\n",
        "    df['log_BaseFVC'] = np.log1p(df['Base_FVC'].clip(lower=1))\n",
        "    df['Estimated_TLC'] = df['Base_FVC'] / (df['Percent_clipped'] / 100.0)\n",
        "    df['log_TLC'] = np.log1p(df['Estimated_TLC'].clip(lower=1))\n",
        "    df['Age_x_Percent'] = df['Age'] * df['Percent_clipped']\n",
        "    df['Percent_x_BaseFVC'] = df['Percent_clipped'] * df['Base_FVC']\n",
        "    df['WP_x_BaseFVC'] = df['Weeks_Passed_cap'] * df['Base_FVC']\n",
        "    df['WP_x_Percent'] = df['Weeks_Passed_cap'] * df['Percent_clipped']\n",
        "    df['WP_x_Age'] = df['Weeks_Passed_cap'] * df['Age']\n",
        "    df['slope_w'] = df.get('slope_w', 0.0)\n",
        "    df['r2_w'] = df.get('r2_w', 0.0)\n",
        "    df['slope_percent_w'] = df.get('slope_percent_w', 0.0)\n",
        "    df['WP_x_slope_w'] = df['Weeks_Passed_cap'] * pd.Series(df['slope_w']).clip(-50, 10)\n",
        "    df['WP_x_r2_w'] = df['Weeks_Passed_cap'] * df['r2_w']\n",
        "    df['WP_x_slope_percent_w'] = df['Weeks_Passed_cap'] * df['slope_percent_w']\n",
        "    # Do not use time-varying Percent; set dPercent features to zero\n",
        "    df['dPercent'] = 0.0\n",
        "    df['WP_x_dPercent'] = 0.0\n",
        "    if 'n_obs' not in df.columns:\n",
        "        df['n_obs'] = 1\n",
        "    if 'has_trend' not in df.columns:\n",
        "        df['has_trend'] = 0\n",
        "    df['is_singleton'] = (df['n_obs'] <= 1).astype(int)\n",
        "    return df\n",
        "\n",
        "def forward_grid_cv_residual_xgb(train_df, n_splits=5, seed=42):\n",
        "    gkf = GroupKFold(n_splits=n_splits)\n",
        "    groups = train_df['Patient'].values\n",
        "    y_true_all, y_pred_all, dist_all = [], [], []\n",
        "    res_all, rows_sigma = [], []\n",
        "    best_iters = []\n",
        "    t0 = time.time()\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(train_df, groups=groups), 1):\n",
        "        tf = time.time()\n",
        "        trn = train_df.iloc[trn_idx].copy()\n",
        "        val = train_df.iloc[val_idx].copy()\n",
        "        # Disjoint patients\n",
        "        assert set(trn['Patient']).isdisjoint(set(val['Patient'])), 'Overlapping patients'\n",
        "        # Anchors\n",
        "        base_trn = (trn.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False)\n",
        "                    .first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "        trn = trn.merge(base_trn, on='Patient', how='left')\n",
        "        base_val = (val.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False)\n",
        "                    .first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "        val = val.merge(base_val, on='Patient', how='left')\n",
        "        # TRAIN-only stats\n",
        "        stats_trn = compute_trend_stats(trn)\n",
        "        stats_trn['has_trend'] = (stats_trn['n_obs'] >= 2).astype(int)\n",
        "        pstats_trn = compute_percent_trend_stats(trn)\n",
        "        trn = trn.merge(stats_trn, on='Patient', how='left').merge(pstats_trn, on='Patient', how='left')\n",
        "        val = val.merge(stats_trn, on='Patient', how='left').merge(pstats_trn, on='Patient', how='left')\n",
        "        for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "            trn[c] = trn[c].fillna(v); val[c] = val[c].fillna(v)\n",
        "        trn['n_obs'] = trn['n_obs'].fillna(1).astype(int)\n",
        "        val['n_obs'] = val['n_obs'].fillna(1).astype(int)\n",
        "        trn['has_trend'] = trn['has_trend'].fillna(0).astype(int)\n",
        "        val['has_trend'] = val['has_trend'].fillna(0).astype(int)\n",
        "        # Assert VAL trend zeroed\n",
        "        assert (val['slope_w'] == 0).all() and (val['r2_w'] == 0).all(), 'VAL trend not zeroed'\n",
        "        assert (val['n_obs'] == 1).all() and (val['has_trend'] == 0).all(), 'VAL flags incorrect'\n",
        "        val['is_singleton'] = 1; trn['is_singleton'] = (trn['n_obs'] <= 1).astype(int)\n",
        "        # Global slope from TRAIN only\n",
        "        g_slope = robust_global_slope(compute_patient_slopes(trn))\n",
        "        trn['pred0'] = trn['Base_FVC'] + g_slope * (trn['Weeks'] - trn['Base_Week'])\n",
        "        val['pred0'] = val['Base_FVC'] + g_slope * (val['Weeks'] - val['Base_Week'])\n",
        "        # Features and cats\n",
        "        trnF = build_features_v2(trn)\n",
        "        valF = build_features_v2(val)\n",
        "        cats = one_hot_fit(trnF, ['Sex','SmokingStatus'])\n",
        "        trnF = one_hot_transform(trnF, cats)\n",
        "        valF = one_hot_transform(valF, cats)\n",
        "        feat_cols = [\n",
        "            'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed_cap','Weeks_Passed2','sign_WP','is_future',\n",
        "            'Percent_clipped','Percent2','Age','Base_FVC','log_BaseFVC','Estimated_TLC','log_TLC',\n",
        "            'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "            'slope_w','r2_w','slope_percent_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w','WP_x_slope_percent_w','dPercent','WP_x_dPercent'\n",
        "        ] + [c for c in trnF.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "        y_trn = (trn['FVC'] - trn['pred0']).astype(float).values\n",
        "        y_val = (val['FVC'] - val['pred0']).astype(float).values\n",
        "        dtrain = xgb.DMatrix(trnF[feat_cols], label=y_trn)\n",
        "        dvalid = xgb.DMatrix(valF[feat_cols], label=y_val)\n",
        "        params = {\n",
        "            'objective': 'reg:absoluteerror',\n",
        "            'eval_metric': 'mae',\n",
        "            'tree_method': 'gpu_hist',\n",
        "            'learning_rate': 0.03,\n",
        "            'max_depth': 4,\n",
        "            'min_child_weight': 30,\n",
        "            'lambda': 7.0,\n",
        "            'subsample': 0.85,\n",
        "            'colsample_bytree': 0.85,\n",
        "            'verbosity': 0\n",
        "        }\n",
        "        watchlist = [(dtrain, 'trn'), (dvalid, 'val')]\n",
        "        model = xgb.train(params, dtrain, num_boost_round=4000, evals=watchlist, early_stopping_rounds=300, verbose_eval=False)\n",
        "        val_pred_res = model.predict(dvalid, iteration_range=(0, model.best_iteration+1))\n",
        "        val_pred = val['pred0'].values + val_pred_res\n",
        "        # Forward-only scoring mask\n",
        "        mask = (val['Weeks'].values >= val['Base_Week'].values)\n",
        "        v_true = val['FVC'].values[mask].astype(float)\n",
        "        v_pred = val_pred[mask].astype(float)\n",
        "        v_dist = (val['Weeks'].values[mask] - val['Base_Week'].values[mask]).astype(float)\n",
        "        y_true_all.append(v_true); y_pred_all.append(v_pred); dist_all.append(v_dist)\n",
        "        # Residuals for sigma model\n",
        "        v_res = (v_true - v_pred)\n",
        "        res_all.append(v_res)\n",
        "        # Prepare sigma features\n",
        "        vF = valF.loc[mask].copy()\n",
        "        rows_sigma.append(pd.DataFrame({\n",
        "            'Patient': val.loc[mask, 'Patient'].values,\n",
        "            'dist': v_dist,\n",
        "            'Abs_Weeks_Passed_cap': vF['Weeks_Passed_cap'].values,\n",
        "            'sign_WP': vF['sign_WP'].values,\n",
        "            'is_future': vF['is_future'].values,\n",
        "            'n_obs': vF['n_obs'].values,\n",
        "            'is_singleton': vF['is_singleton'].values,\n",
        "            'has_trend': vF['has_trend'].values,\n",
        "            'r2_w': vF['r2_w'].values,\n",
        "            'slope_w': pd.Series(vF['slope_w']).clip(-50,10).values,\n",
        "            'slope_percent_w': pd.Series(vF['slope_percent_w']).clip(-10,10).values,\n",
        "            'dPercent': vF['dPercent'].values,\n",
        "            'Percent_at_base': val.loc[mask, 'Percent_at_base'].values,\n",
        "            'Base_FVC': val.loc[mask, 'Base_FVC'].values,\n",
        "            'log_BaseFVC': vF['log_BaseFVC'].values,\n",
        "            'Estimated_TLC': vF['Estimated_TLC'].values,\n",
        "            'log_TLC': vF['log_TLC'].values,\n",
        "            'Age': val.loc[mask, 'Age'].values,\n",
        "            'Sex': val.loc[mask, 'Sex'].values,\n",
        "            'SmokingStatus': val.loc[mask, 'SmokingStatus'].values\n",
        "        }))\n",
        "        mae = float(np.mean(np.abs(v_true - v_pred))) if v_true.size else np.nan\n",
        "        print(f'[FWD-XGB-Fold {fold}] n_trn={trn.shape[0]} n_val={val.shape[0]} g_slope={g_slope:.4f} scored={v_true.size} MAE={mae:.2f} iters={model.best_iteration+1} elapsed={time.time()-tf:.2f}s', flush=True)\n",
        "        best_iters.append(int(model.best_iteration+1))\n",
        "        if fold == 1:\n",
        "            # Persist schema for full-train fit\n",
        "            globals()['_feat_cols_res'] = feat_cols\n",
        "            globals()['_cats_res'] = cats\n",
        "        del dtrain, dvalid, model, trnF, valF; gc.collect()\n",
        "\n",
        "    y_true = np.concatenate(y_true_all) if y_true_all else np.array([], float)\n",
        "    y_pred = np.concatenate(y_pred_all) if y_pred_all else np.array([], float)\n",
        "    dist = np.concatenate(dist_all) if dist_all else np.array([], float)\n",
        "    res = np.concatenate(res_all) if res_all else np.array([], float)\n",
        "    oof_ll_baseline = laplace_ll(y_true, y_pred, np.maximum(200 + 2.0*dist, 70.0))\n",
        "    print(f'Forward residual OOF baseline LL (simple sigma): {oof_ll_baseline:.5f}')\n",
        "    return (y_true, y_pred, dist, res, rows_sigma, int(np.median(best_iters)))\n",
        "\n",
        "def sigma_model_oof(rows_sigma, res, n_splits=5, seed=42):\n",
        "    df = pd.concat(rows_sigma, ignore_index=True)\n",
        "    df['abs_res'] = np.abs(res)\n",
        "    df['z'] = np.log1p(df['abs_res'])\n",
        "    # One-hot for Sex/Smoking\n",
        "    cats = { 'Sex': sorted(df['Sex'].dropna().unique()), 'SmokingStatus': sorted(df['SmokingStatus'].dropna().unique()) }\n",
        "    for c, vals in cats.items():\n",
        "        for v in vals:\n",
        "            df[f'{c}__{v}'] = (df[c] == v).astype(np.int8)\n",
        "    feat_cols = [\n",
        "        'dist','Abs_Weeks_Passed_cap','sign_WP','is_future','n_obs','is_singleton','has_trend','r2_w','slope_w','slope_percent_w',\n",
        "        'dPercent','Percent_at_base','Base_FVC','log_BaseFVC','Estimated_TLC','log_TLC','Age'\n",
        "    ] + [c for c in df.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "    gkf = GroupKFold(n_splits=n_splits)\n",
        "    groups = df['Patient'].values\n",
        "    z_hat = np.zeros(df.shape[0], dtype=float)\n",
        "    models = []\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(df, groups=groups), 1):\n",
        "        trn = df.iloc[trn_idx]; val = df.iloc[val_idx]\n",
        "        dtrain = xgb.DMatrix(trn[feat_cols], label=trn['z'].values)\n",
        "        dvalid = xgb.DMatrix(val[feat_cols], label=val['z'].values)\n",
        "        params = {\n",
        "            'objective': 'reg:squarederror',\n",
        "            'tree_method': 'gpu_hist',\n",
        "            'learning_rate': 0.05,\n",
        "            'max_depth': 3,\n",
        "            'min_child_weight': 20,\n",
        "            'lambda': 5.0,\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.8,\n",
        "            'verbosity': 0\n",
        "        }\n",
        "        model = xgb.train(params, dtrain, num_boost_round=4000, evals=[(dvalid,'val')], early_stopping_rounds=200, verbose_eval=False)\n",
        "        z_hat[val_idx] = model.predict(dvalid, iteration_range=(0, model.best_iteration+1))\n",
        "        models.append(model)\n",
        "    # Tune a,b,c on OOF\n",
        "    abs_hat = np.expm1(z_hat)\n",
        "    best = (-1e9, None, None, None)\n",
        "    for a in [120, 160, 200, 240]:\n",
        "        for b in [1.0, 2.0, 3.0]:\n",
        "            for c in [0.5, 1.0, 1.5, 2.0]:\n",
        "                sigma = np.maximum(a + b*df['dist'].values + c*abs_hat, 70.0)\n",
        "                score = laplace_ll(df['Base_FVC'].values*0 + df['abs_res'].values*0 + 0,  # dummy\n",
        "                                   df['Base_FVC'].values*0 + df['abs_res'].values*0 + 0,  # y_true not used here\n",
        "                                   sigma)  # we'll compute score with true y outside; keep grid selection simple\n",
        "                if best[0] == -1e9:\n",
        "                    best = (0.0, a, b, c)\n",
        "    return df, z_hat, feat_cols, cats\n",
        "\n",
        "# Run forward/grid residual CV\n",
        "y_true_fw, y_pred_fw, dist_fw, res_fw, rows_sigma, best_iters_res = forward_grid_cv_residual_xgb(train)\n",
        "\n",
        "# Proper tuning of a,b,c on OOF with sigma |res_hat|\n",
        "df_sigma_oof, z_hat_oof, sigma_feat_cols, sigma_cats = sigma_model_oof(rows_sigma, res_fw)\n",
        "abs_hat_oof = np.expm1(z_hat_oof)\n",
        "best = (-1e9, None, None, None)\n",
        "for a in [120, 160, 200, 240]:\n",
        "    for b in [1.0, 2.0, 3.0]:\n",
        "        for c in [0.5, 1.0, 1.5, 2.0]:\n",
        "            sigma = np.maximum(a + b*df_sigma_oof['dist'].values + c*abs_hat_oof, 70.0)\n",
        "            score = laplace_ll(y_true_fw, y_pred_fw, sigma)\n",
        "            if score > best[0]:\n",
        "                best = (score, a, b, c)\n",
        "print(f'Forward OOF LL (residual + sigma-|res_hat|): {best[0]:.5f} with a={best[1]} b={best[2]} c={best[3]}')\n",
        "a_sig, b_sig, c_sig = best[1], best[2], best[3]\n",
        "\n",
        "# Train final residual model on full data\n",
        "slopes_full = compute_patient_slopes(train)\n",
        "g_slope_full = robust_global_slope(slopes_full)\n",
        "base_full = (train.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "train_full = train.merge(base_full, on='Patient', how='left')\n",
        "stats_full = compute_trend_stats(train_full); stats_full['has_trend'] = (stats_full['n_obs'] >= 2).astype(int)\n",
        "pstats_full = compute_percent_trend_stats(train_full)\n",
        "train_full = train_full.merge(stats_full, on='Patient', how='left').merge(pstats_full, on='Patient', how='left')\n",
        "for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "    train_full[c] = train_full[c].fillna(v)\n",
        "train_full['n_obs'] = train_full['n_obs'].fillna(1).astype(int)\n",
        "train_full['has_trend'] = train_full['has_trend'].fillna(0).astype(int)\n",
        "train_full['pred0'] = train_full['Base_FVC'] + g_slope_full * (train_full['Weeks'] - train_full['Base_Week'])\n",
        "train_fullF = build_features_v2(train_full)\n",
        "cats_res_full = one_hot_fit(train_fullF, ['Sex','SmokingStatus'])\n",
        "train_fullF = one_hot_transform(train_fullF, cats_res_full)\n",
        "feat_cols_res = [\n",
        "    'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed_cap','Weeks_Passed2','sign_WP','is_future',\n",
        "    'Percent_clipped','Percent2','Age','Base_FVC','log_BaseFVC','Estimated_TLC','log_TLC',\n",
        "    'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "    'slope_w','r2_w','slope_percent_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w','WP_x_slope_percent_w','dPercent','WP_x_dPercent'\n",
        "] + [c for c in train_fullF.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "y_full = (train_fullF['FVC'] - train_fullF['pred0']).astype(float).values\n",
        "dtrain_full = xgb.DMatrix(train_fullF[feat_cols_res], label=y_full)\n",
        "params_res_full = {\n",
        "    'objective': 'reg:absoluteerror',\n",
        "    'eval_metric': 'mae',\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'learning_rate': 0.03,\n",
        "    'max_depth': 4,\n",
        "    'min_child_weight': 30,\n",
        "    'lambda': 7.0,\n",
        "    'subsample': 0.85,\n",
        "    'colsample_bytree': 0.85,\n",
        "    'verbosity': 0\n",
        "}\n",
        "model_res_full = xgb.train(params_res_full, dtrain_full, num_boost_round=max(200, best_iters_res))\n",
        "\n",
        "# Train final sigma model on all forward-scored rows\n",
        "df_sigma_full = df_sigma_oof.copy()\n",
        "z_full = np.log1p(df_sigma_full['abs_res'].values)  # use true |res| from OOF for fitting\n",
        "for c, vals in sigma_cats.items():\n",
        "    for v in vals:\n",
        "        if f'{c}__{v}' not in df_sigma_full.columns:\n",
        "            df_sigma_full[f'{c}__{v}'] = (df_sigma_full[c] == v).astype(np.int8)\n",
        "dtrain_sigma_full = xgb.DMatrix(df_sigma_full[sigma_feat_cols], label=z_full)\n",
        "params_sigma_full = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 3,\n",
        "    'min_child_weight': 20,\n",
        "    'lambda': 5.0,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'verbosity': 0\n",
        "}\n",
        "model_sigma_full = xgb.train(params_sigma_full, dtrain_sigma_full, num_boost_round=600)\n",
        "\n",
        "# Build test grid and predict\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "meta = test[['Patient','Percent','Age','Sex','SmokingStatus']].drop_duplicates('Patient')\n",
        "grid = grid.merge(meta, on='Patient', how='left', suffixes=('', '_meta'))\n",
        "# Do NOT merge train stats into test; hard-set backoff zeros to mirror VAL/TEST behavior\n",
        "grid['slope_w'] = 0.0\n",
        "grid['r2_w'] = 0.0\n",
        "grid['slope_percent_w'] = 0.0\n",
        "grid['n_obs'] = 1\n",
        "grid['has_trend'] = 0\n",
        "grid['is_singleton'] = 1\n",
        "grid['pred0'] = grid['Base_FVC'] + g_slope_full * (grid['Weeks'] - grid['Base_Week'])\n",
        "gridF = build_features_v2(grid)\n",
        "gridF = one_hot_transform(gridF, cats_res_full)\n",
        "dgrid = xgb.DMatrix(gridF[feat_cols_res])\n",
        "res_pred = model_res_full.predict(dgrid)\n",
        "fvc_pred = (gridF['pred0'].values + res_pred).clip(500, 6000)\n",
        "dist_test = (gridF['Weeks'] - gridF['Base_Week']).abs().astype(float).values\n",
        "\n",
        "# Sigma features for test\n",
        "df_sigma_test = pd.DataFrame({\n",
        "    'dist': dist_test,\n",
        "    'Abs_Weeks_Passed_cap': gridF['Weeks_Passed_cap'].values,\n",
        "    'sign_WP': gridF['sign_WP'].values,\n",
        "    'is_future': gridF['is_future'].values,\n",
        "    'n_obs': gridF['n_obs'].values,\n",
        "    'is_singleton': gridF['is_singleton'].values,\n",
        "    'has_trend': gridF['has_trend'].values,\n",
        "    'r2_w': gridF['r2_w'].values,\n",
        "    'slope_w': pd.Series(gridF['slope_w']).clip(-50,10).values,\n",
        "    'slope_percent_w': pd.Series(gridF['slope_percent_w']).clip(-10,10).values,\n",
        "    'dPercent': gridF['dPercent'].values,\n",
        "    'Percent_at_base': grid['Percent_at_base'].values,\n",
        "    'Base_FVC': grid['Base_FVC'].values,\n",
        "    'log_BaseFVC': gridF['log_BaseFVC'].values,\n",
        "    'Estimated_TLC': gridF['Estimated_TLC'].values,\n",
        "    'log_TLC': gridF['log_TLC'].values,\n",
        "    'Age': grid['Age'].values\n",
        "})\n",
        "for c, vals in sigma_cats.items():\n",
        "    for v in vals:\n",
        "        df_sigma_test[f'{c}__{v}'] = (grid[c] == v).astype(np.int8)\n",
        "for col in sigma_feat_cols:\n",
        "    if col not in df_sigma_test.columns:\n",
        "        df_sigma_test[col] = 0\n",
        "dtest_sigma = xgb.DMatrix(df_sigma_test[sigma_feat_cols])\n",
        "z_hat_test = model_sigma_full.predict(dtest_sigma)\n",
        "abs_hat_test = np.expm1(z_hat_test)\n",
        "sigma_test = np.maximum(a_sig + b_sig*dist_test + c_sig*abs_hat_test, 70.0)\n",
        "\n",
        "submission_fw_res = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_pred.astype(float),\n",
        "    'Confidence': sigma_test.astype(float)\n",
        "})\n",
        "submission_fw_res.to_csv('submission.csv', index=False)\n",
        "print('Saved forward-residual submission.csv. Forward OOF LL (res+sigma):', f'{best[0]:.5f}', 'best_iters_res:', best_iters_res, 'g_slope_full:', f'{g_slope_full:.4f}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-XGB-Fold 1] n_trn=1112 n_val=282 g_slope=-3.8062 scored=282 MAE=167.37 iters=2 elapsed=0.64s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-XGB-Fold 2] n_trn=1113 n_val=281 g_slope=-3.5547 scored=281 MAE=117.11 iters=18 elapsed=0.65s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-XGB-Fold 3] n_trn=1119 n_val=275 g_slope=-3.5065 scored=275 MAE=136.84 iters=6 elapsed=0.62s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-XGB-Fold 4] n_trn=1119 n_val=275 g_slope=-3.5065 scored=275 MAE=154.29 iters=178 elapsed=0.93s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-XGB-Fold 5] n_trn=1113 n_val=281 g_slope=-3.6557 scored=281 MAE=137.79 iters=348 elapsed=1.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward residual OOF baseline LL (simple sigma): -6.03975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward OOF LL (residual + sigma-|res_hat|): -5.93471 with a=120 b=1.0 c=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved forward-residual submission.csv. Forward OOF LL (res+sigma): -5.93471 best_iters_res: 18 g_slope_full: -3.6341\n"
          ]
        }
      ]
    },
    {
      "id": "8559358f-05da-4b20-a6b2-ea8439efd9b7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Forward/grid CatBoost residual (native cats) + blend with XGB forward residual; keep sigma from sigma |res_hat|\n",
        "import sys, subprocess, gc, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def ensure_catboost():\n",
        "    try:\n",
        "        import catboost  # noqa: F401\n",
        "        return\n",
        "    except Exception:\n",
        "        print('Installing catboost...', flush=True)\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', 'catboost==1.2.5', '--no-input'], check=True)\n",
        "        import catboost  # noqa: F401\n",
        "\n",
        "ensure_catboost()\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "if 'train' not in globals():\n",
        "    train = pd.read_csv('train.csv')\n",
        "if 'test' not in globals():\n",
        "    test = pd.read_csv('test.csv')\n",
        "\n",
        "def train_catboost_forward_residual(train_df, n_splits=5, seed=42):\n",
        "    gkf = GroupKFold(n_splits=n_splits)\n",
        "    groups = train_df['Patient'].values\n",
        "    y_true_all, y_pred_all = [], []\n",
        "    t0 = time.time()\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(train_df, groups=groups), 1):\n",
        "        tf = time.time()\n",
        "        trn = train_df.iloc[trn_idx].copy()\n",
        "        val = train_df.iloc[val_idx].copy()\n",
        "        assert set(trn['Patient']).isdisjoint(set(val['Patient'])), 'Overlapping patients'\n",
        "        # Anchors\n",
        "        base_trn = (trn.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False)\n",
        "                    .first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "        trn = trn.merge(base_trn, on='Patient', how='left')\n",
        "        base_val = (val.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False)\n",
        "                    .first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "        val = val.merge(base_val, on='Patient', how='left')\n",
        "        # TRAIN-only stats\n",
        "        stats_trn = compute_trend_stats(trn); stats_trn['has_trend'] = (stats_trn['n_obs'] >= 2).astype(int)\n",
        "        pstats_trn = compute_percent_trend_stats(trn)\n",
        "        trn = trn.merge(stats_trn, on='Patient', how='left').merge(pstats_trn, on='Patient', how='left')\n",
        "        val = val.merge(stats_trn, on='Patient', how='left').merge(pstats_trn, on='Patient', how='left')\n",
        "        for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "            trn[c] = trn[c].fillna(v); val[c] = val[c].fillna(v)\n",
        "        trn['n_obs'] = trn['n_obs'].fillna(1).astype(int)\n",
        "        val['n_obs'] = val['n_obs'].fillna(1).astype(int)\n",
        "        trn['has_trend'] = trn['has_trend'].fillna(0).astype(int)\n",
        "        val['has_trend'] = val['has_trend'].fillna(0).astype(int)\n",
        "        val['is_singleton'] = 1; trn['is_singleton'] = (trn['n_obs'] <= 1).astype(int)\n",
        "        # Global slope\n",
        "        g_slope = robust_global_slope(compute_patient_slopes(trn))\n",
        "        trn['pred0'] = trn['Base_FVC'] + g_slope * (trn['Weeks'] - trn['Base_Week'])\n",
        "        val['pred0'] = val['Base_FVC'] + g_slope * (val['Weeks'] - val['Base_Week'])\n",
        "        # Features for CatBoost: use build_features_v2, keep Sex, SmokingStatus as cats\n",
        "        trnF = build_features_v2(trn)\n",
        "        valF = build_features_v2(val)\n",
        "        feat_cols = [\n",
        "            'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed_cap','Weeks_Passed2','sign_WP','is_future',\n",
        "            'Percent','Percent_clipped','Percent2','Age','Base_FVC','log_BaseFVC','Estimated_TLC','log_TLC',\n",
        "            'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "            'slope_w','r2_w','slope_percent_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w','WP_x_slope_percent_w','dPercent','WP_x_dPercent',\n",
        "            'Sex','SmokingStatus'\n",
        "        ]\n",
        "        cat_cols = ['Sex','SmokingStatus']\n",
        "        cat_idx = [feat_cols.index(c) for c in cat_cols]\n",
        "        y_trn = (trn['FVC'] - trn['pred0']).astype(float).values\n",
        "        y_val = (val['FVC'] - val['pred0']).astype(float).values\n",
        "        train_pool = Pool(trnF[feat_cols], label=y_trn, cat_features=cat_idx)\n",
        "        valid_pool = Pool(valF[feat_cols], label=y_val, cat_features=cat_idx)\n",
        "        model = CatBoostRegressor(\n",
        "            loss_function='MAE',\n",
        "            iterations=6000,\n",
        "            od_type='Iter',\n",
        "            od_wait=300,\n",
        "            learning_rate=0.035,\n",
        "            depth=6,\n",
        "            l2_leaf_reg=8.0,\n",
        "            bootstrap_type='Bernoulli',\n",
        "            subsample=0.8,\n",
        "            task_type='GPU',\n",
        "            random_seed=seed,\n",
        "            verbose=False\n",
        "        )\n",
        "        model.fit(train_pool, eval_set=valid_pool, use_best_model=True, verbose=False)\n",
        "        pred_res = model.predict(valid_pool)\n",
        "        val_pred = val['pred0'].values + pred_res\n",
        "        mask = (val['Weeks'].values >= val['Base_Week'].values)\n",
        "        y_true_all.append(val['FVC'].values[mask].astype(float))\n",
        "        y_pred_all.append(val_pred[mask].astype(float))\n",
        "        mae = float(np.mean(np.abs(val['FVC'].values[mask] - val_pred[mask]))) if mask.any() else np.nan\n",
        "        print(f'[FWD-CB-Fold {fold}] n_trn={trn.shape[0]} n_val={val.shape[0]} g_slope={g_slope:.4f} MAE={mae:.2f} elapsed={time.time()-tf:.2f}s', flush=True)\n",
        "        del model, train_pool, valid_pool, trnF, valF; gc.collect()\n",
        "    y_true = np.concatenate(y_true_all) if y_true_all else np.array([], float)\n",
        "    y_pred = np.concatenate(y_pred_all) if y_pred_all else np.array([], float)\n",
        "    print(f'CatBoost forward OOF ready: {y_true.shape[0]} rows in {time.time()-t0:.2f}s')\n",
        "    return y_true, y_pred\n",
        "\n",
        "# Train CatBoost forward residual OOF\n",
        "y_true_cb, y_pred_cb = train_catboost_forward_residual(train)\n",
        "\n",
        "# If available, blend with XGB forward OOF (from cell 10) using a simple tuned weight; otherwise default w=0.4\n",
        "def safe_blend_weight(y_true_ref, y_pred_xgb, y_pred_cb, dist_ref, a=120, b=1.0, c=0.0):\n",
        "    try:\n",
        "        best = (-1e9, None)\n",
        "        for w in np.linspace(0.0, 1.0, 21):\n",
        "            yb = w * y_pred_xgb + (1.0 - w) * y_pred_cb\n",
        "            sig = np.maximum(a + b * dist_ref, 70.0)\n",
        "            score = laplace_ll(y_true_ref, yb, sig)\n",
        "            if score > best[0]:\n",
        "                best = (score, w)\n",
        "        return best[1] if best[1] is not None else 0.6\n",
        "    except Exception as e:\n",
        "        print('Blend weight tuning failed, fallback w=0.6:', e)\n",
        "        return 0.6\n",
        "\n",
        "try:\n",
        "    w_blend = safe_blend_weight(y_true_fw, y_pred_fw, y_pred_cb, dist_fw, a=120, b=1.0)\n",
        "except Exception as e:\n",
        "    print('Using default blend weight (0.6) due to missing XGB OOF context:', e)\n",
        "    w_blend = 0.6\n",
        "print('Chosen XGB:CB blend weight (XGB share)=', w_blend)\n",
        "\n",
        "# Fit CatBoost residual on full data and generate test predictions\n",
        "slopes_full = compute_patient_slopes(train)\n",
        "g_slope_full = robust_global_slope(slopes_full)\n",
        "base_full = (train.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "train_full_cb = train.merge(base_full, on='Patient', how='left')\n",
        "stats_full = compute_trend_stats(train_full_cb); stats_full['has_trend'] = (stats_full['n_obs'] >= 2).astype(int)\n",
        "pstats_full = compute_percent_trend_stats(train_full_cb)\n",
        "train_full_cb = train_full_cb.merge(stats_full, on='Patient', how='left').merge(pstats_full, on='Patient', how='left')\n",
        "for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "    train_full_cb[c] = train_full_cb[c].fillna(v)\n",
        "train_full_cb['n_obs'] = train_full_cb['n_obs'].fillna(1).astype(int)\n",
        "train_full_cb['has_trend'] = train_full_cb['has_trend'].fillna(0).astype(int)\n",
        "train_full_cb['pred0'] = train_full_cb['Base_FVC'] + g_slope_full * (train_full_cb['Weeks'] - train_full_cb['Base_Week'])\n",
        "train_full_cbF = build_features_v2(train_full_cb)\n",
        "feat_cols_cb_full = [\n",
        "    'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed_cap','Weeks_Passed2','sign_WP','is_future',\n",
        "    'Percent','Percent_clipped','Percent2','Age','Base_FVC','log_BaseFVC','Estimated_TLC','log_TLC',\n",
        "    'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "    'slope_w','r2_w','slope_percent_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w','WP_x_slope_percent_w','dPercent','WP_x_dPercent',\n",
        "    'Sex','SmokingStatus'\n",
        "]\n",
        "cat_cols_full = ['Sex','SmokingStatus']\n",
        "cat_idx_full = [feat_cols_cb_full.index(c) for c in cat_cols_full]\n",
        "pool_full = Pool(train_full_cbF[feat_cols_cb_full], label=(train_full_cbF['FVC'] - train_full_cbF['pred0']).astype(float).values, cat_features=cat_idx_full)\n",
        "model_cb_full = CatBoostRegressor(\n",
        "    loss_function='MAE', depth=6, learning_rate=0.035, l2_leaf_reg=8.0,\n",
        "    bootstrap_type='Bernoulli', subsample=0.8, iterations=3000, od_type='Iter', od_wait=200,\n",
        "    task_type='GPU', random_seed=42, verbose=False\n",
        ")\n",
        "model_cb_full.fit(pool_full, verbose=False)\n",
        "\n",
        "# Build test grid and predict residuals with CatBoost\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "meta = test[['Patient','Percent','Age','Sex','SmokingStatus']].drop_duplicates('Patient')\n",
        "grid = grid.merge(meta, on='Patient', how='left', suffixes=('', '_meta'))\n",
        "grid = grid.merge(stats_full, on='Patient', how='left').merge(pstats_full, on='Patient', how='left')\n",
        "for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "    grid[c] = grid[c].fillna(v)\n",
        "grid['n_obs'] = grid['n_obs'].fillna(1).astype(int)\n",
        "grid['has_trend'] = grid['has_trend'].fillna(0).astype(int)\n",
        "grid['is_singleton'] = (grid['n_obs'] <= 1).astype(int)\n",
        "grid['pred0'] = grid['Base_FVC'] + g_slope_full * (grid['Weeks'] - grid['Base_Week'])\n",
        "gridF = build_features_v2(grid)\n",
        "pool_grid = Pool(gridF[feat_cols_cb_full], cat_features=cat_idx_full)\n",
        "res_cb = model_cb_full.predict(pool_grid)\n",
        "fvc_cb = (gridF['pred0'].values + res_cb).clip(500, 6000)\n",
        "\n",
        "# Recompute/ensure XGB forward predictions available (from cell 10). If missing, fall back to pred0 only.\n",
        "try:\n",
        "    fvc_xgb = fvc_pred.copy()\n",
        "    sigma_out = sigma_test.copy()\n",
        "except Exception as e:\n",
        "    print('XGB forward preds not found in scope, rebuilding baseline preds as fallback:', e)\n",
        "    fvc_xgb = (gridF['pred0'].values).clip(500, 6000)\n",
        "    dist_test_fb = (gridF['Weeks'] - gridF['Base_Week']).abs().astype(float).values\n",
        "    sigma_out = np.maximum(200 + 2.0 * dist_test_fb, 70.0)\n",
        "\n",
        "# Blend and save submission\n",
        "fvc_blend = w_blend * fvc_xgb + (1.0 - w_blend) * fvc_cb\n",
        "submission_cb_fw = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_blend.astype(float),\n",
        "    'Confidence': sigma_out.astype(float)\n",
        "})\n",
        "submission_cb_fw.to_csv('submission.csv', index=False)\n",
        "print('Saved forward CV XGB+CatBoost blended submission.csv with w_blend (XGB share)=', w_blend)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-CB-Fold 1] n_trn=1112 n_val=282 g_slope=-3.8062 MAE=112.78 elapsed=69.58s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-CB-Fold 2] n_trn=1113 n_val=281 g_slope=-3.5547 MAE=67.32 elapsed=69.86s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-CB-Fold 3] n_trn=1119 n_val=275 g_slope=-3.5065 MAE=86.21 elapsed=70.07s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-CB-Fold 4] n_trn=1119 n_val=275 g_slope=-3.5065 MAE=98.66 elapsed=69.93s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FWD-CB-Fold 5] n_trn=1113 n_val=281 g_slope=-3.6557 MAE=89.78 elapsed=69.64s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CatBoost forward OOF ready: 1394 rows in 349.55s\nChosen XGB:CB blend weight (XGB share)= 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved forward CV XGB+CatBoost blended submission.csv with w_blend (XGB share)= 1.0\n"
          ]
        }
      ]
    },
    {
      "id": "9b6c0388-bc29-4daa-b612-ce17b8767916",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write conservative-sigma submission from forward residual XGB predictions (test hygiene fixed)\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# Rebuild test grid and predictions using forward residual model objects from Cell 10\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "meta = test[['Patient','Percent','Age','Sex','SmokingStatus']].drop_duplicates('Patient')\n",
        "grid = grid.merge(meta, on='Patient', how='left', suffixes=('', '_meta'))\n",
        "\n",
        "# STRICT TEST HYGIENE: Do NOT merge any train-derived trend stats. Hard-set zeros like in Cell 10.\n",
        "grid['slope_w'] = 0.0\n",
        "grid['r2_w'] = 0.0\n",
        "grid['slope_percent_w'] = 0.0\n",
        "grid['n_obs'] = 1\n",
        "grid['has_trend'] = 0\n",
        "grid['is_singleton'] = 1\n",
        "\n",
        "# Baseline and features\n",
        "grid['pred0'] = grid['Base_FVC'] + g_slope_full * (grid['Weeks'] - grid['Base_Week'])\n",
        "gridF = build_features_v2(grid)\n",
        "gridF = one_hot_transform(gridF, cats_res_full)\n",
        "dgrid = xgb.DMatrix(gridF[feat_cols_res])\n",
        "res_pred = model_res_full.predict(dgrid)\n",
        "fvc_pred_cons = (gridF['pred0'].values + res_pred).clip(500, 6000)\n",
        "dist_cons = (gridF['Weeks'] - gridF['Base_Week']).abs().astype(float).values\n",
        "\n",
        "# Conservative sigma per expert advice\n",
        "sigma_cons = np.maximum(200.0 + 3.0 * dist_cons, 70.0)\n",
        "\n",
        "submission_cons = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_pred_cons.astype(float),\n",
        "    'Confidence': sigma_cons.astype(float)\n",
        "})\n",
        "submission_cons.to_csv('submission.csv', index=False)\n",
        "print('Saved conservative-sigma submission.csv with dist-only sigma (200 + 3*dist) and strict test hygiene.')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved conservative-sigma submission.csv with dist-only sigma (200 + 3*dist) and strict test hygiene.\n"
          ]
        }
      ]
    },
    {
      "id": "5a9309ad-f71e-4545-b64e-08ebd164e15e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Seed-averaged forward residual XGB (+ sigma re-tune) per expert advice\n",
        "import numpy as np, pandas as pd, time, gc\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import xgboost as xgb\n",
        "\n",
        "def laplace_ll(y_true, y_pred, sigma):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    y_pred = np.asarray(y_pred).astype(float)\n",
        "    sigma = np.asarray(sigma).astype(float)\n",
        "    delta = np.abs(y_true - y_pred)\n",
        "    delta = np.minimum(delta, 1000.0)\n",
        "    sigma = np.maximum(sigma, 70.0)\n",
        "    return np.mean(-delta / sigma - np.log(sigma))\n",
        "\n",
        "def ecdf_percentile(values_sorted, x):\n",
        "    # values_sorted must be sorted ascending; returns percentile in [0,1]\n",
        "    idx = np.searchsorted(values_sorted, np.asarray(x, dtype=float), side='right')\n",
        "    return idx / float(len(values_sorted)) if len(values_sorted) > 0 else np.zeros_like(x, dtype=float)\n",
        "\n",
        "def add_group_slope_prior(trn, val, g_slope_backoff):\n",
        "    # Build static age bins and compute group slope priors from TRAIN-only per-patient slopes\n",
        "    bins = [0, 50, 60, 70, 80, 200]\n",
        "    labels = ['<=50','50-60','60-70','70-80','80+']\n",
        "    trn = trn.copy(); val = val.copy()\n",
        "    trn['AgeBin'] = pd.cut(trn['Age'].astype(float), bins=bins, labels=labels, include_lowest=True)\n",
        "    val['AgeBin'] = pd.cut(val['Age'].astype(float), bins=bins, labels=labels, include_lowest=True)\n",
        "    slopes_trn = compute_patient_slopes(trn)\n",
        "    df_sl = pd.DataFrame({'Patient': list(slopes_trn.keys()), 'slope_p': list(slopes_trn.values())})\n",
        "    trn = trn.merge(df_sl, on='Patient', how='left')\n",
        "    grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n",
        "              .median().reset_index().rename(columns={'slope_p':'group_slope_prior'}))\n",
        "    trn = trn.merge(grp, on=['Sex','SmokingStatus','AgeBin'], how='left')\n",
        "    val = val.merge(grp, on=['Sex','SmokingStatus','AgeBin'], how='left')\n",
        "    trn['group_slope_prior'] = trn['group_slope_prior'].fillna(g_slope_backoff)\n",
        "    val['group_slope_prior'] = val['group_slope_prior'].fillna(g_slope_backoff)\n",
        "    return trn, val\n",
        "\n",
        "def add_basefvc_percentile(trn, val, base_trn_vals_sorted):\n",
        "    trn = trn.copy(); val = val.copy()\n",
        "    trn['BaseFVC_pct'] = ecdf_percentile(base_trn_vals_sorted, trn['Base_FVC'].values)\n",
        "    val['BaseFVC_pct'] = ecdf_percentile(base_trn_vals_sorted, val['Base_FVC'].values)\n",
        "    return trn, val\n",
        "\n",
        "def forward_residual_oof_and_full(seed=42, lr=0.045, max_depth=4, min_child_weight=20, reg_lambda=5.0, subsample=0.9, colsample=0.9, colsample_bylevel=1.0):\n",
        "    gkf = GroupKFold(n_splits=5)\n",
        "    groups = train['Patient'].values\n",
        "    y_true_all, y_pred_all, dist_all, res_all = [], [], [], []\n",
        "    iters = []\n",
        "    t0 = time.time()\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(train, groups=groups), 1):\n",
        "        tf = time.time()\n",
        "        trn = train.iloc[trn_idx].copy()\n",
        "        val = train.iloc[val_idx].copy()\n",
        "        # anchors\n",
        "        base_trn = (trn.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False)\n",
        "                    .first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "        trn = trn.merge(base_trn, on='Patient', how='left')\n",
        "        base_val = (val.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False)\n",
        "                    .first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "        val = val.merge(base_val, on='Patient', how='left')\n",
        "        # train-only stats, VAL zeros\n",
        "        stats_trn = compute_trend_stats(trn); stats_trn['has_trend'] = (stats_trn['n_obs'] >= 2).astype(int)\n",
        "        pstats_trn = compute_percent_trend_stats(trn)\n",
        "        trn = trn.merge(stats_trn, on='Patient', how='left').merge(pstats_trn, on='Patient', how='left')\n",
        "        val = val.merge(stats_trn, on='Patient', how='left').merge(pstats_trn, on='Patient', how='left')\n",
        "        for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "            trn[c] = trn[c].fillna(v); val[c] = val[c].fillna(v)\n",
        "        trn['n_obs'] = trn['n_obs'].fillna(1).astype(int)\n",
        "        val['n_obs'] = val['n_obs'].fillna(1).astype(int)\n",
        "        trn['has_trend'] = trn['has_trend'].fillna(0).astype(int)\n",
        "        val['has_trend'] = val['has_trend'].fillna(0).astype(int)\n",
        "        val['is_singleton'] = 1; trn['is_singleton'] = (trn['n_obs'] <= 1).astype(int)\n",
        "        # global slope\n",
        "        g_slope = robust_global_slope(compute_patient_slopes(trn))\n",
        "        # Add group slope prior (TRAIN-only derived) and BaseFVC percentile rank\n",
        "        trn, val = add_group_slope_prior(trn, val, g_slope_backoff=g_slope)\n",
        "        base_trn_sorted = np.sort(base_trn['Base_FVC'].values.astype(float))\n",
        "        trn, val = add_basefvc_percentile(trn, val, base_trn_sorted)\n",
        "        # Group median Base_FVC and delta from population priors (TRAIN-only)\n",
        "        grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n",
        "                      .median().reset_index().rename(columns={'Base_FVC':'group_basefvc_median'}))\n",
        "        trn = trn.merge(grp_med, on=['Sex','SmokingStatus','AgeBin'], how='left')\n",
        "        val = val.merge(grp_med, on=['Sex','SmokingStatus','AgeBin'], how='left')\n",
        "        trn['group_basefvc_median'] = trn['group_basefvc_median'].fillna(trn['Base_FVC'].median())\n",
        "        val['group_basefvc_median'] = val['group_basefvc_median'].fillna(trn['Base_FVC'].median())\n",
        "        trn['delta_BaseFVC'] = trn['Base_FVC'] - trn['group_basefvc_median']\n",
        "        val['delta_BaseFVC'] = val['Base_FVC'] - val['group_basefvc_median']\n",
        "        # Percent_at_base percentile rank (TRAIN-only ECDF) \u2014 use Percent_at_base to avoid reliance on base_trn['Percent']\n",
        "        base_percent_sorted = np.sort(trn['Percent_at_base'].values.astype(float))\n",
        "        trn['PercentBase_pct'] = ecdf_percentile(base_percent_sorted, trn['Percent_at_base'].values)\n",
        "        val['PercentBase_pct'] = ecdf_percentile(base_percent_sorted, val['Percent_at_base'].values)\n",
        "        # pred0\n",
        "        trn['pred0'] = trn['Base_FVC'] + g_slope * (trn['Weeks'] - trn['Base_Week'])\n",
        "        val['pred0'] = val['Base_FVC'] + g_slope * (val['Weeks'] - val['Base_Week'])\n",
        "        # features\n",
        "        trnF = build_features_v2(trn); valF = build_features_v2(val)\n",
        "        # add interactions for new priors and optional ratios\n",
        "        trnF['WP_x_group_slope'] = trnF['Weeks_Passed_cap'] * trnF['group_slope_prior']\n",
        "        valF['WP_x_group_slope'] = valF['Weeks_Passed_cap'] * valF['group_slope_prior']\n",
        "        trnF['WP_x_BaseFVC_pct'] = trnF['Weeks_Passed_cap'] * trnF['BaseFVC_pct']\n",
        "        valF['WP_x_BaseFVC_pct'] = valF['Weeks_Passed_cap'] * valF['BaseFVC_pct']\n",
        "        # shrunk slope prior\n",
        "        trnF['shrunk_slope'] = 0.7 * trnF['group_slope_prior'] + 0.3 * g_slope\n",
        "        valF['shrunk_slope'] = 0.7 * valF['group_slope_prior'] + 0.3 * g_slope\n",
        "        trnF['WP_x_shrunk_slope'] = trnF['Weeks_Passed_cap'] * trnF['shrunk_slope']\n",
        "        valF['WP_x_shrunk_slope'] = valF['Weeks_Passed_cap'] * valF['shrunk_slope']\n",
        "        # carry delta_BaseFVC and PercentBase_pct\n",
        "        trnF['delta_BaseFVC'] = trn['delta_BaseFVC'].values\n",
        "        valF['delta_BaseFVC'] = val['delta_BaseFVC'].values\n",
        "        trnF['PercentBase_pct'] = trn['PercentBase_pct'].values\n",
        "        valF['PercentBase_pct'] = val['PercentBase_pct'].values\n",
        "        trnF['WP_x_delta_BaseFVC'] = trnF['Weeks_Passed_cap'] * trnF['delta_BaseFVC']\n",
        "        valF['WP_x_delta_BaseFVC'] = valF['Weeks_Passed_cap'] * valF['delta_BaseFVC']\n",
        "        # ratios\n",
        "        trnF['BaseFVC_per_Age'] = trnF['Base_FVC'] / np.clip(trnF['Age'], 1, None)\n",
        "        valF['BaseFVC_per_Age'] = valF['Base_FVC'] / np.clip(valF['Age'], 1, None)\n",
        "        trnF['PercentBase_per_Age'] = trnF['Percent_clipped'] / np.clip(trnF['Age'], 1, None)\n",
        "        valF['PercentBase_per_Age'] = valF['Percent_clipped'] / np.clip(valF['Age'], 1, None)\n",
        "        trnF['WP_x_BaseFVC_per_Age'] = trnF['Weeks_Passed_cap'] * trnF['BaseFVC_per_Age']\n",
        "        valF['WP_x_BaseFVC_per_Age'] = valF['Weeks_Passed_cap'] * valF['BaseFVC_per_Age']\n",
        "        cats = one_hot_fit(trnF, ['Sex','SmokingStatus'])\n",
        "        trnF = one_hot_transform(trnF, cats); valF = one_hot_transform(valF, cats)\n",
        "        feat_cols = [\n",
        "            'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed_cap','Weeks_Passed2','sign_WP','is_future',\n",
        "            'Percent_clipped','Percent2','Age','Base_FVC','log_BaseFVC','Estimated_TLC','log_TLC',\n",
        "            'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "            'n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w','WP_x_slope_percent_w','dPercent','WP_x_dPercent',\n",
        "            'group_slope_prior','WP_x_group_slope','BaseFVC_pct','WP_x_BaseFVC_pct',\n",
        "            'shrunk_slope','WP_x_shrunk_slope','delta_BaseFVC','WP_x_delta_BaseFVC','PercentBase_pct',\n",
        "            'BaseFVC_per_Age','PercentBase_per_Age','WP_x_BaseFVC_per_Age'\n",
        "        ] + [c for c in trnF.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "        y_trn = (trn['FVC'] - trn['pred0']).astype(float).values\n",
        "        y_val = (val['FVC'] - val['pred0']).astype(float).values\n",
        "        dtrain = xgb.DMatrix(trnF[feat_cols], label=y_trn)\n",
        "        dvalid = xgb.DMatrix(valF[feat_cols], label=y_val)\n",
        "        params = {\n",
        "            'objective': 'reg:absoluteerror',\n",
        "            'eval_metric': 'mae',\n",
        "            'tree_method': 'gpu_hist',\n",
        "            'learning_rate': lr,\n",
        "            'max_depth': max_depth,\n",
        "            'min_child_weight': min_child_weight,\n",
        "            'lambda': reg_lambda,\n",
        "            'subsample': subsample,\n",
        "            'colsample_bytree': colsample,\n",
        "            'colsample_bylevel': colsample_bylevel,\n",
        "            'verbosity': 0,\n",
        "            'seed': seed\n",
        "        }\n",
        "        model = xgb.train(params, dtrain, num_boost_round=4000, evals=[(dvalid,'val')], early_stopping_rounds=300, verbose_eval=False)\n",
        "        val_res = model.predict(dvalid, iteration_range=(0, model.best_iteration+1))\n",
        "        val_pred = val['pred0'].values + val_res\n",
        "        mask = (val['Weeks'].values >= val['Base_Week'].values)\n",
        "        v_true = val['FVC'].values[mask].astype(float)\n",
        "        v_pred = val_pred[mask].astype(float)\n",
        "        v_dist = (val['Weeks'].values[mask] - val['Base_Week'].values[mask]).astype(float)\n",
        "        y_true_all.append(v_true); y_pred_all.append(v_pred); dist_all.append(v_dist)\n",
        "        res_all.append((v_true - v_pred))\n",
        "        it = int(model.best_iteration + 1)\n",
        "        iters.append(it)\n",
        "        print(f'[Seed{seed}-Fold {fold}] g_slope={g_slope:.4f} scored={v_true.size} MAE={np.mean(np.abs(v_true - v_pred)):.2f} iters={it} elapsed={time.time()-tf:.2f}s', flush=True)\n",
        "        del dtrain, dvalid, model, trnF, valF; gc.collect()\n",
        "    # OOF arrays (same ordering across seeds since GroupKFold deterministic)\n",
        "    y_true = np.concatenate(y_true_all)\n",
        "    y_pred = np.concatenate(y_pred_all)\n",
        "    dist = np.concatenate(dist_all)\n",
        "    res = np.concatenate(res_all)\n",
        "    # Fit full model with median iters\n",
        "    slopes_full = compute_patient_slopes(train); g_slope_full_loc = robust_global_slope(slopes_full)\n",
        "    base_full = (train.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "    train_full = train.merge(base_full, on='Patient', how='left')\n",
        "    stats_full_loc = compute_trend_stats(train_full); stats_full_loc['has_trend'] = (stats_full_loc['n_obs'] >= 2).astype(int)\n",
        "    pstats_full_loc = compute_percent_trend_stats(train_full)\n",
        "    train_full = train_full.merge(stats_full_loc, on='Patient', how='left').merge(pstats_full_loc, on='Patient', how='left')\n",
        "    for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "        train_full[c] = train_full[c].fillna(v)\n",
        "    train_full['n_obs'] = train_full['n_obs'].fillna(1).astype(int)\n",
        "    train_full['has_trend'] = train_full['has_trend'].fillna(0).astype(int)\n",
        "    # Add TRAIN-only group slope prior and BaseFVC percentile rank for full model\n",
        "    bins = [0, 50, 60, 70, 80, 200]\n",
        "    labels = ['<=50','50-60','60-70','70-80','80+']\n",
        "    train_full['AgeBin'] = pd.cut(train_full['Age'].astype(float), bins=bins, labels=labels, include_lowest=True)\n",
        "    slopes_full_p = compute_patient_slopes(train_full)\n",
        "    df_sl_full = pd.DataFrame({'Patient': list(slopes_full_p.keys()), 'slope_p': list(slopes_full_p.values())})\n",
        "    train_full = train_full.merge(df_sl_full, on='Patient', how='left')\n",
        "    grp_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n",
        "                   .median().reset_index().rename(columns={'slope_p':'group_slope_prior'}))\n",
        "    train_full = train_full.merge(grp_full, on=['Sex','SmokingStatus','AgeBin'], how='left')\n",
        "    train_full['group_slope_prior'] = train_full['group_slope_prior'].fillna(g_slope_full_loc)\n",
        "    base_full_sorted = np.sort(base_full['Base_FVC'].values.astype(float))\n",
        "    train_full['BaseFVC_pct'] = ecdf_percentile(base_full_sorted, train_full['Base_FVC'].values)\n",
        "    # Group median Base_FVC\n",
        "    grp_basefvc_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n",
        "                           .median().reset_index().rename(columns={'Base_FVC':'group_basefvc_median'}))\n",
        "    train_full = train_full.merge(grp_basefvc_full, on=['Sex','SmokingStatus','AgeBin'], how='left')\n",
        "    train_full['group_basefvc_median'] = train_full['group_basefvc_median'].fillna(train_full['Base_FVC'].median())\n",
        "    train_full['delta_BaseFVC'] = train_full['Base_FVC'] - train_full['group_basefvc_median']\n",
        "    # Percent_at_base ECDF (use Percent_at_base)\n",
        "    percent_full_sorted = np.sort(train_full['Percent_at_base'].values.astype(float))\n",
        "    train_full['PercentBase_pct'] = ecdf_percentile(percent_full_sorted, train_full['Percent_at_base'].values)\n",
        "    train_full['pred0'] = train_full['Base_FVC'] + g_slope_full_loc * (train_full['Weeks'] - train_full['Base_Week'])\n",
        "    train_fullF = build_features_v2(train_full)\n",
        "    # Interactions for priors + extras\n",
        "    train_fullF['WP_x_group_slope'] = train_fullF['Weeks_Passed_cap'] * train_fullF['group_slope_prior']\n",
        "    train_fullF['WP_x_BaseFVC_pct'] = train_fullF['Weeks_Passed_cap'] * train_fullF['BaseFVC_pct']\n",
        "    train_fullF['shrunk_slope'] = 0.7 * train_fullF['group_slope_prior'] + 0.3 * g_slope_full_loc\n",
        "    train_fullF['WP_x_shrunk_slope'] = train_fullF['Weeks_Passed_cap'] * train_fullF['shrunk_slope']\n",
        "    train_fullF['delta_BaseFVC'] = train_full['delta_BaseFVC'].values\n",
        "    train_fullF['PercentBase_pct'] = train_full['PercentBase_pct'].values\n",
        "    train_fullF['WP_x_delta_BaseFVC'] = train_fullF['Weeks_Passed_cap'] * train_fullF['delta_BaseFVC']\n",
        "    train_fullF['BaseFVC_per_Age'] = train_fullF['Base_FVC'] / np.clip(train_fullF['Age'], 1, None)\n",
        "    train_fullF['PercentBase_per_Age'] = train_fullF['Percent_clipped'] / np.clip(train_fullF['Age'], 1, None)\n",
        "    train_fullF['WP_x_BaseFVC_per_Age'] = train_fullF['Weeks_Passed_cap'] * train_fullF['BaseFVC_per_Age']\n",
        "    cats_full_loc = one_hot_fit(train_fullF, ['Sex','SmokingStatus'])\n",
        "    train_fullF = one_hot_transform(train_fullF, cats_full_loc)\n",
        "    feat_cols_loc = [\n",
        "        'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed_cap','Weeks_Passed2','sign_WP','is_future',\n",
        "        'Percent_clipped','Percent2','Age','Base_FVC','log_BaseFVC','Estimated_TLC','log_TLC',\n",
        "        'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "        'n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w','WP_x_slope_percent_w','dPercent','WP_x_dPercent',\n",
        "        'group_slope_prior','WP_x_group_slope','BaseFVC_pct','WP_x_BaseFVC_pct',\n",
        "        'shrunk_slope','WP_x_shrunk_slope','delta_BaseFVC','WP_x_delta_BaseFVC','PercentBase_pct',\n",
        "        'BaseFVC_per_Age','PercentBase_per_Age','WP_x_BaseFVC_per_Age'\n",
        "    ] + [c for c in train_fullF.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "    dtrain_full = xgb.DMatrix(train_fullF[feat_cols_loc], label=(train_fullF['FVC'] - train_fullF['pred0']).astype(float).values)\n",
        "    params_full = {\n",
        "        'objective': 'reg:absoluteerror', 'eval_metric': 'mae', 'tree_method': 'gpu_hist',\n",
        "        'learning_rate': lr, 'max_depth': max_depth, 'min_child_weight': min_child_weight, 'lambda': reg_lambda,\n",
        "        'subsample': subsample, 'colsample_bytree': colsample, 'colsample_bylevel': colsample_bylevel, 'verbosity': 0, 'seed': seed\n",
        "    }\n",
        "    model_full = xgb.train(params_full, dtrain_full, num_boost_round=int(np.median(iters)))\n",
        "    # Build strict test grid\n",
        "    ss_loc = pd.read_csv('sample_submission.csv')\n",
        "    grid = ss_loc.copy()\n",
        "    parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "    grid['Patient'] = parts[0]\n",
        "    grid['Weeks'] = parts[1].astype(int)\n",
        "    test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "    grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "    meta = test[['Patient','Percent','Age','Sex','SmokingStatus']].drop_duplicates('Patient')\n",
        "    grid = grid.merge(meta, on='Patient', how='left', suffixes=('', '_meta'))\n",
        "    grid['slope_w'] = 0.0; grid['r2_w'] = 0.0; grid['slope_percent_w'] = 0.0; grid['n_obs'] = 1; grid['has_trend'] = 0; grid['is_singleton'] = 1\n",
        "    # Add group slope prior (from train_full) and BaseFVC percentile + group baseFVC median for TEST\n",
        "    grid['AgeBin'] = pd.cut(grid['Age'].astype(float), bins=[0,50,60,70,80,200], labels=['<=50','50-60','60-70','70-80','80+'], include_lowest=True)\n",
        "    grid = grid.merge(grp_full, on=['Sex','SmokingStatus','AgeBin'], how='left')\n",
        "    grid['group_slope_prior'] = grid['group_slope_prior'].fillna(g_slope_full_loc)\n",
        "    grid = grid.merge(grp_basefvc_full, on=['Sex','SmokingStatus','AgeBin'], how='left')\n",
        "    grid['group_basefvc_median'] = grid['group_basefvc_median'].fillna(train_full['Base_FVC'].median())\n",
        "    grid['delta_BaseFVC'] = grid['Base_FVC'] - grid['group_basefvc_median']\n",
        "    grid['BaseFVC_pct'] = ecdf_percentile(base_full_sorted, grid['Base_FVC'].values)\n",
        "    percent_full_sorted = np.sort(train_full['Percent_at_base'].values.astype(float))\n",
        "    grid['PercentBase_pct'] = ecdf_percentile(percent_full_sorted, grid['Percent_at_base'].values)\n",
        "    grid['pred0'] = grid['Base_FVC'] + g_slope_full_loc * (grid['Weeks'] - grid['Base_Week'])\n",
        "    gridF = build_features_v2(grid)\n",
        "    gridF['WP_x_group_slope'] = gridF['Weeks_Passed_cap'] * gridF['group_slope_prior']\n",
        "    gridF['WP_x_BaseFVC_pct'] = gridF['Weeks_Passed_cap'] * gridF['BaseFVC_pct']\n",
        "    gridF['shrunk_slope'] = 0.7 * gridF['group_slope_prior'] + 0.3 * g_slope_full_loc\n",
        "    gridF['WP_x_shrunk_slope'] = gridF['Weeks_Passed_cap'] * gridF['shrunk_slope']\n",
        "    gridF['delta_BaseFVC'] = grid['delta_BaseFVC'].values\n",
        "    gridF['PercentBase_pct'] = grid['PercentBase_pct'].values\n",
        "    gridF['WP_x_delta_BaseFVC'] = gridF['Weeks_Passed_cap'] * gridF['delta_BaseFVC']\n",
        "    gridF['BaseFVC_per_Age'] = gridF['Base_FVC'] / np.clip(gridF['Age'], 1, None)\n",
        "    gridF['PercentBase_per_Age'] = gridF['Percent_clipped'] / np.clip(gridF['Age'], 1, None)\n",
        "    gridF['WP_x_BaseFVC_per_Age'] = gridF['Weeks_Passed_cap'] * gridF['BaseFVC_per_Age']\n",
        "    gridF = one_hot_transform(gridF, cats_full_loc)\n",
        "    dgrid = xgb.DMatrix(gridF[feat_cols_loc])\n",
        "    res_pred = model_full.predict(dgrid)\n",
        "    fvc_pred = (gridF['pred0'].values + res_pred).clip(500, 6000)\n",
        "    dist_test = (gridF['Weeks'] - gridF['Base_Week']).abs().astype(float).values\n",
        "    return {\n",
        "        'y_true': y_true, 'y_pred': y_pred, 'dist': dist, 'res': res,\n",
        "        'fvc_test': fvc_pred, 'abs_res_hat_test': np.abs(res_pred), 'dist_test': dist_test\n",
        "    }\n",
        "\n",
        "# Expand to 9 seeds with slight jitter per expert advice (more diversity: include depth=3 seeds, subsample/colsample patterns, lr up to 0.055, vary colsample_bylevel)\n",
        "seeds = [42, 1337, 2025, 7, 99, 123, 321, 777, 1001]\n",
        "\n",
        "def jitter_params(seed):\n",
        "    # Deterministic small jitters based on seed for diversity\n",
        "    offs = seed % 4  # 0..3\n",
        "    # learning_rate in 0.040-0.055\n",
        "    lr_choices = [0.040, 0.045, 0.050, 0.055]\n",
        "    lr = lr_choices[offs]\n",
        "    # include a couple of depth=3 seeds; otherwise 4-5\n",
        "    if seed % 6 == 0:\n",
        "        max_depth = 3\n",
        "    else:\n",
        "        max_depth = 4 if (seed % 2 == 0) else 5\n",
        "    # min_child_weight in 12-28\n",
        "    mcw_choices = [12, 18, 22, 28]\n",
        "    min_child_weight = mcw_choices[offs]\n",
        "    # lambda in 3-9\n",
        "    lam_choices = [3.0, 5.0, 7.0, 9.0]\n",
        "    reg_lambda = lam_choices[(seed // 3) % 4]\n",
        "    # subsample patterns {0.75,0.85,0.95}\n",
        "    subs_choices = [0.75, 0.85, 0.95]\n",
        "    subsample = subs_choices[(seed // 5) % 3]\n",
        "    # colsample_bytree {0.80,0.90,1.00}\n",
        "    col_choices = [0.80, 0.90, 1.00]\n",
        "    colsample = col_choices[(seed // 7) % 3]\n",
        "    # colsample_bylevel {1.0, 0.8} on a few seeds\n",
        "    colsample_bylevel = 0.8 if (seed % 7 in (0, 3)) else 1.0\n",
        "    return dict(lr=lr, max_depth=max_depth, min_child_weight=min_child_weight, reg_lambda=reg_lambda, subsample=subsample, colsample=colsample, colsample_bylevel=colsample_bylevel)\n",
        "\n",
        "runs = []\n",
        "for s in seeds:\n",
        "    jp = jitter_params(s)\n",
        "    runs.append(forward_residual_oof_and_full(seed=s, lr=jp['lr'], max_depth=jp['max_depth'], min_child_weight=jp['min_child_weight'], reg_lambda=jp['reg_lambda'], subsample=jp['subsample'], colsample=jp['colsample'], colsample_bylevel=jp['colsample_bylevel']))\n",
        "\n",
        "# Aggregate OOF by averaging predictions; assume identical y_true/dist ordering\n",
        "y_true_ref = runs[0]['y_true']\n",
        "dist_ref = runs[0]['dist']\n",
        "y_pred_avg = np.mean([r['y_pred'] for r in runs], axis=0)\n",
        "abs_res_hat_oof_avg = np.mean([np.abs(r['y_true'] - r['y_pred']) for r in runs], axis=0)  # proxy from OOF errors\n",
        "\n",
        "# Retune sigma on OOF with conservative, transfer-friendly grid\n",
        "best = (-1e9, None, None, None)\n",
        "for a in [160, 200, 240]:\n",
        "    for b in [2.0, 3.0]:\n",
        "        for c in [0.5, 1.0]:\n",
        "            sig = np.maximum(a + b*dist_ref + c*abs_res_hat_oof_avg, 70.0)\n",
        "            score = laplace_ll(y_true_ref, y_pred_avg, sig)\n",
        "            if score > best[0]:\n",
        "                best = (score, a, b, c)\n",
        "print(f'Seed-avg Forward OOF LL: {best[0]:.5f} with a={best[1]} b={best[2]} c={best[3]}')\n",
        "a_best, b_best, c_best = best[1], best[2], best[3]\n",
        "\n",
        "# Average test predictions and abs residual proxy\n",
        "fvc_test_avg = np.mean([r['fvc_test'] for r in runs], axis=0)\n",
        "abs_res_hat_test_avg = np.mean([r['abs_res_hat_test'] for r in runs], axis=0)\n",
        "dist_test_ref = runs[0]['dist_test']\n",
        "sigma_test_primary = np.maximum(a_best + b_best*dist_test_ref + c_best*abs_res_hat_test_avg, 70.0)\n",
        "# Optional long-horizon floor: sigma >= 100 for dist > 20\n",
        "sigma_test_primary = np.where(dist_test_ref > 20.0, np.maximum(sigma_test_primary, 100.0), sigma_test_primary)\n",
        "\n",
        "# Write primary seed-averaged submission\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "submission_primary = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_test_avg.astype(float),\n",
        "    'Confidence': sigma_test_primary.astype(float)\n",
        "})\n",
        "submission_primary.to_csv('submission.csv', index=False)\n",
        "print('Saved seed-averaged forward residual submission.csv with tuned sigma (a,b,c)=', a_best, b_best, c_best)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed42-Fold 1] g_slope=-3.8062 scored=282 MAE=165.22 iters=16 elapsed=0.66s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed42-Fold 2] g_slope=-3.5547 scored=281 MAE=117.13 iters=8 elapsed=0.63s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed42-Fold 3] g_slope=-3.5065 scored=275 MAE=136.70 iters=7 elapsed=0.63s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed42-Fold 4] g_slope=-3.5065 scored=275 MAE=155.62 iters=1 elapsed=0.62s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed42-Fold 5] g_slope=-3.6557 scored=281 MAE=132.67 iters=528 elapsed=1.55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:186: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:193: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_basefvc_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed1337-Fold 1] g_slope=-3.8062 scored=282 MAE=165.59 iters=8 elapsed=0.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed1337-Fold 2] g_slope=-3.5547 scored=281 MAE=118.05 iters=4 elapsed=0.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed1337-Fold 3] g_slope=-3.5065 scored=275 MAE=135.80 iters=43 elapsed=0.86s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed1337-Fold 4] g_slope=-3.5065 scored=275 MAE=154.89 iters=1 elapsed=0.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed1337-Fold 5] g_slope=-3.6557 scored=281 MAE=132.44 iters=665 elapsed=2.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:186: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:193: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_basefvc_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed2025-Fold 1] g_slope=-3.8062 scored=282 MAE=166.53 iters=6 elapsed=0.71s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed2025-Fold 2] g_slope=-3.5547 scored=281 MAE=117.87 iters=3 elapsed=0.70s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed2025-Fold 3] g_slope=-3.5065 scored=275 MAE=135.80 iters=52 elapsed=0.80s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed2025-Fold 4] g_slope=-3.5065 scored=275 MAE=154.78 iters=2 elapsed=0.70s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed2025-Fold 5] g_slope=-3.6557 scored=281 MAE=134.05 iters=198 elapsed=1.11s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:186: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:193: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_basefvc_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed7-Fold 1] g_slope=-3.8062 scored=282 MAE=166.27 iters=10 elapsed=0.81s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed7-Fold 2] g_slope=-3.5547 scored=281 MAE=117.64 iters=2 elapsed=0.79s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed7-Fold 3] g_slope=-3.5065 scored=275 MAE=136.99 iters=1 elapsed=0.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed7-Fold 4] g_slope=-3.5065 scored=275 MAE=154.93 iters=18 elapsed=0.81s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed7-Fold 5] g_slope=-3.6557 scored=281 MAE=135.67 iters=183 elapsed=1.19s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:186: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:193: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_basefvc_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed99-Fold 1] g_slope=-3.8062 scored=282 MAE=167.10 iters=1 elapsed=0.67s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed99-Fold 2] g_slope=-3.5547 scored=281 MAE=117.93 iters=7 elapsed=0.69s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed99-Fold 3] g_slope=-3.5065 scored=275 MAE=136.06 iters=13 elapsed=0.70s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed99-Fold 4] g_slope=-3.5065 scored=275 MAE=155.27 iters=77 elapsed=0.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed99-Fold 5] g_slope=-3.6557 scored=281 MAE=133.82 iters=206 elapsed=1.07s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:186: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:193: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_basefvc_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed123-Fold 1] g_slope=-3.8062 scored=282 MAE=165.45 iters=9 elapsed=0.69s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed123-Fold 2] g_slope=-3.5547 scored=281 MAE=117.75 iters=3 elapsed=0.67s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed123-Fold 3] g_slope=-3.5065 scored=275 MAE=136.82 iters=4 elapsed=0.68s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed123-Fold 4] g_slope=-3.5065 scored=275 MAE=155.21 iters=1 elapsed=0.67s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed123-Fold 5] g_slope=-3.6557 scored=281 MAE=133.84 iters=288 elapsed=1.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:186: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:193: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_basefvc_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed321-Fold 1] g_slope=-3.8062 scored=282 MAE=166.39 iters=34 elapsed=0.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed321-Fold 2] g_slope=-3.5547 scored=281 MAE=117.95 iters=1 elapsed=0.70s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed321-Fold 3] g_slope=-3.5065 scored=275 MAE=136.77 iters=9 elapsed=0.72s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed321-Fold 4] g_slope=-3.5065 scored=275 MAE=154.65 iters=174 elapsed=1.05s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed321-Fold 5] g_slope=-3.6557 scored=281 MAE=135.63 iters=339 elapsed=1.40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:186: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:193: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_basefvc_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed777-Fold 1] g_slope=-3.8062 scored=282 MAE=166.16 iters=29 elapsed=0.85s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed777-Fold 2] g_slope=-3.5547 scored=281 MAE=117.63 iters=1 elapsed=0.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed777-Fold 3] g_slope=-3.5065 scored=275 MAE=136.98 iters=4 elapsed=0.80s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed777-Fold 4] g_slope=-3.5065 scored=275 MAE=154.05 iters=150 elapsed=1.13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed777-Fold 5] g_slope=-3.6557 scored=281 MAE=136.29 iters=232 elapsed=1.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:186: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:193: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_basefvc_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed1001-Fold 1] g_slope=-3.8062 scored=282 MAE=167.30 iters=4 elapsed=0.83s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed1001-Fold 2] g_slope=-3.5547 scored=281 MAE=118.00 iters=2 elapsed=0.79s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed1001-Fold 3] g_slope=-3.5065 scored=275 MAE=136.98 iters=6 elapsed=0.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed1001-Fold 4] g_slope=-3.5065 scored=275 MAE=154.94 iters=1 elapsed=0.77s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed1001-Fold 5] g_slope=-3.6557 scored=281 MAE=133.90 iters=189 elapsed=1.19s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed-avg Forward OOF LL: -5.96224 with a=160 b=2.0 c=0.5\nSaved seed-averaged forward residual submission.csv with tuned sigma (a,b,c)= 160 2.0 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:186: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:193: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_basefvc_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        }
      ]
    },
    {
      "id": "00a450f7-a1d9-488c-a5ee-966a5421cff4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compare OOF LL: primary (seed-avg tuned sigma) vs banker (dist-only 200+3*dist)\n",
        "import numpy as np\n",
        "\n",
        "def laplace_ll(y_true, y_pred, sigma):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    y_pred = np.asarray(y_pred).astype(float)\n",
        "    sigma = np.asarray(sigma).astype(float)\n",
        "    delta = np.abs(y_true - y_pred)\n",
        "    delta = np.minimum(delta, 1000.0)\n",
        "    sigma = np.maximum(sigma, 70.0)\n",
        "    return np.mean(-delta / sigma - np.log(sigma))\n",
        "\n",
        "y_true_cmp = y_true_ref\n",
        "y_pred_cmp = y_pred_avg\n",
        "dist_cmp = dist_ref\n",
        "sig_primary = np.maximum(a_best + b_best*dist_cmp + c_best*abs_res_hat_oof_avg, 70.0)\n",
        "sig_banker = np.maximum(200.0 + 3.0*dist_cmp, 70.0)\n",
        "ll_primary = laplace_ll(y_true_cmp, y_pred_cmp, sig_primary)\n",
        "ll_banker = laplace_ll(y_true_cmp, y_pred_cmp, sig_banker)\n",
        "print(f'OOF LL primary (seed-avg tuned sigma): {ll_primary:.5f}')\n",
        "print(f'OOF LL banker (200 + 3*dist):        {ll_banker:.5f}')\n",
        "print('Delta (primary - banker):', f'{ll_primary - ll_banker:.5f}')\n",
        "print('Note: If delta < 0.02, prefer banker for LB robustness per expert advice.')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF LL primary (seed-avg tuned sigma): -5.81645\nOOF LL banker (200 + 3*dist):        -6.06067\nDelta (primary - banker): 0.24423\nNote: If delta < 0.02, prefer banker for LB robustness per expert advice.\n"
          ]
        }
      ]
    },
    {
      "id": "1649450f-966d-41a3-b759-a927fe12b890",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Blend 0.85*seed-avg forward residual + 0.15*anchored baseline; keep tuned sigma; apply guardrails (FVC non-increasing, sigma monotone in dist)\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# Ensure we have seed-avg outputs from Cell 13\n",
        "assert 'fvc_test_avg' in globals() and 'sigma_test_primary' in globals(), 'Run Cell 13 first to get seed-avg predictions and sigma.'\n",
        "\n",
        "# Build strict test grid and anchored baseline\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "\n",
        "# Use existing g_slope_full if available; otherwise compute\n",
        "try:\n",
        "    gsf = float(g_slope_full)\n",
        "except Exception:\n",
        "    slopes_full_tmp = compute_patient_slopes(train)\n",
        "    gsf = robust_global_slope(slopes_full_tmp)\n",
        "\n",
        "fvc_anchor = (grid['Base_FVC'].values + gsf * (grid['Weeks'].values - grid['Base_Week'].values)).astype(float)\n",
        "\n",
        "# Blend\n",
        "w = 0.85\n",
        "fvc_blend = w * fvc_test_avg.astype(float) + (1.0 - w) * fvc_anchor\n",
        "\n",
        "# Guardrails: per-patient non-increasing w.r.t. future weeks; clip to [500, 6000]\n",
        "df_out = pd.DataFrame({\n",
        "    'Patient': grid['Patient'].values,\n",
        "    'Weeks': grid['Weeks'].values.astype(int),\n",
        "    'FVC': fvc_blend\n",
        "})\n",
        "df_out['FVC'] = df_out['FVC'].clip(500, 6000)\n",
        "def enforce_non_increasing(g):\n",
        "    g = g.sort_values('Weeks').copy()\n",
        "    # cumulative minimum forward in time\n",
        "    g['FVC'] = np.minimum.accumulate(g['FVC'].values[::-1])[::-1]\n",
        "    return g\n",
        "df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n",
        "fvc_blend_guarded = df_out['FVC'].values.astype(float)\n",
        "\n",
        "# Keep sigma from tuned seed-avg, then enforce sigma monotone in dist (non-decreasing with Weeks distance)\n",
        "sigma_out = np.maximum(sigma_test_primary.astype(float), 70.0)\n",
        "df_sig = pd.DataFrame({\n",
        "    'Patient': grid['Patient'].values,\n",
        "    'Weeks': grid['Weeks'].values.astype(int),\n",
        "    'Base_Week': grid['Base_Week'].values.astype(int),\n",
        "    'Sigma': sigma_out\n",
        "})\n",
        "df_sig['dist'] = (df_sig['Weeks'] - df_sig['Base_Week']).abs().astype(float)\n",
        "def enforce_sigma_monotone(g):\n",
        "    g = g.sort_values('dist').copy()\n",
        "    g['Sigma'] = np.maximum.accumulate(g['Sigma'].values)\n",
        "    return g\n",
        "df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n",
        "sigma_out_monotone = df_sig['Sigma'].values.astype(float)\n",
        "\n",
        "# Save submission\n",
        "submission_blended = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_blend_guarded,\n",
        "    'Confidence': sigma_out_monotone\n",
        "})\n",
        "submission_blended.to_csv('submission.csv', index=False)\n",
        "print('Saved blended submission.csv: 0.85*seed-avg + 0.15*anchored baseline with tuned sigma (monotone) and FVC guardrails.')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved blended submission.csv: 0.85*seed-avg + 0.15*anchored baseline with tuned sigma (monotone) and FVC guardrails.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/2445239095.py:41: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n/tmp/ipykernel_170/2445239095.py:57: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n"
          ]
        }
      ]
    },
    {
      "id": "2a02a00a-fd1b-463c-8bae-e99cb3990ede",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Conservative-probe submission: same blended FVC, more conservative sigma (a=160, b=2.0, c=0.5)\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "assert 'fvc_test_avg' in globals() and 'abs_res_hat_test_avg' in globals() and 'dist_test_ref' in globals(), 'Run Cell 13 first.'\n",
        "\n",
        "# Rebuild blend (0.85*seed-avg + 0.15*anchored baseline) to be robust to state\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "try:\n",
        "    gsf = float(g_slope_full)\n",
        "except Exception:\n",
        "    slopes_full_tmp = compute_patient_slopes(train)\n",
        "    gsf = robust_global_slope(slopes_full_tmp)\n",
        "fvc_anchor = (grid['Base_FVC'].values + gsf * (grid['Weeks'].values - grid['Base_Week'].values)).astype(float)\n",
        "w = 0.85\n",
        "fvc_blend = w * fvc_test_avg.astype(float) + (1.0 - w) * fvc_anchor\n",
        "\n",
        "# Guardrails: non-increasing with future weeks and clip\n",
        "df_out = pd.DataFrame({'Patient': grid['Patient'].values, 'Weeks': grid['Weeks'].values.astype(int), 'FVC': fvc_blend})\n",
        "df_out['FVC'] = df_out['FVC'].clip(500, 6000)\n",
        "def enforce_non_increasing(g):\n",
        "    g = g.sort_values('Weeks').copy()\n",
        "    g['FVC'] = np.minimum.accumulate(g['FVC'].values[::-1])[::-1]\n",
        "    return g\n",
        "df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n",
        "fvc_blend_guarded = df_out['FVC'].values.astype(float)\n",
        "\n",
        "# Conservative sigma per expert probe\n",
        "a_cons, b_cons, c_cons = 160.0, 2.0, 0.5\n",
        "sigma_cons_hybrid = np.maximum(a_cons + b_cons*dist_test_ref + c_cons*abs_res_hat_test_avg, 70.0).astype(float)\n",
        "\n",
        "submission_cons2 = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_blend_guarded,\n",
        "    'Confidence': sigma_cons_hybrid\n",
        "})\n",
        "submission_cons2.to_csv('submission.csv', index=False)\n",
        "print('Saved conservative-probe submission.csv with blended FVC and sigma = max(160 + 2*dist + 0.5*|res_hat|, 70).')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved conservative-probe submission.csv with blended FVC and sigma = max(160 + 2*dist + 0.5*|res_hat|, 70).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/3904216958.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n"
          ]
        }
      ]
    },
    {
      "id": "4682f96f-7456-416a-af53-c0ea71121de2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Banker submission: blended FVC with strict hygiene, sigma = max(300 + 6*dist, 70)\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# Require seed-avg predictions computed (Cell 13). Rebuild blend to be state-robust.\n",
        "assert 'fvc_test_avg' in globals(), 'Run Cell 13 first to compute seed-averaged predictions.'\n",
        "\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "\n",
        "# Anchored baseline using global slope from full train\n",
        "try:\n",
        "    gsf = float(g_slope_full)\n",
        "except Exception:\n",
        "    slopes_full_tmp = compute_patient_slopes(train)\n",
        "    gsf = robust_global_slope(slopes_full_tmp)\n",
        "fvc_anchor = (grid['Base_FVC'].values + gsf * (grid['Weeks'].values - grid['Base_Week'].values)).astype(float)\n",
        "\n",
        "# Blend 0.85 seed-avg + 0.15 anchored\n",
        "w = 0.85\n",
        "fvc_blend = w * fvc_test_avg.astype(float) + (1.0 - w) * fvc_anchor\n",
        "\n",
        "# Guardrails: per-patient non-increasing in future weeks; clip\n",
        "df_out = pd.DataFrame({'Patient': grid['Patient'].values, 'Weeks': grid['Weeks'].values.astype(int), 'FVC': fvc_blend})\n",
        "df_out['FVC'] = df_out['FVC'].clip(500, 6000)\n",
        "def enforce_non_increasing(g):\n",
        "    g = g.sort_values('Weeks').copy()\n",
        "    g['FVC'] = np.minimum.accumulate(g['FVC'].values[::-1])[::-1]\n",
        "    return g\n",
        "df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n",
        "fvc_final = df_out['FVC'].values.astype(float)\n",
        "\n",
        "# Banker sigma\n",
        "dist = (grid['Weeks'] - grid['Base_Week']).abs().astype(float).values\n",
        "sigma_banker = np.maximum(300.0 + 6.0 * dist, 70.0)\n",
        "\n",
        "submission_banker = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_final,\n",
        "    'Confidence': sigma_banker.astype(float)\n",
        "})\n",
        "submission_banker.to_csv('submission.csv', index=False)\n",
        "print('Saved banker submission.csv with sigma = max(300 + 6*dist, 70) and blended FVC (0.85 seed-avg + 0.15 anchor).')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved banker submission.csv with sigma = max(300 + 6*dist, 70) and blended FVC (0.85 seed-avg + 0.15 anchor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/234238696.py:34: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n"
          ]
        }
      ]
    },
    {
      "id": "99b7d056-d736-42f0-a1ab-46220a236968",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Banker-240x3 submission: blended FVC with strict hygiene, sigma = max(240 + 3*dist, 70), with guardrails and sigma monotonicity\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "assert 'fvc_test_avg' in globals(), 'Run Cell 13 first to compute seed-averaged predictions.'\n",
        "\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "\n",
        "# Anchored baseline using global slope from full train\n",
        "try:\n",
        "    gsf = float(g_slope_full)\n",
        "except Exception:\n",
        "    slopes_full_tmp = compute_patient_slopes(train)\n",
        "    gsf = robust_global_slope(slopes_full_tmp)\n",
        "fvc_anchor = (grid['Base_FVC'].values + gsf * (grid['Weeks'].values - grid['Base_Week'].values)).astype(float)\n",
        "\n",
        "# Blend 0.85 seed-avg + 0.15 anchored\n",
        "w = 0.85\n",
        "fvc_blend = w * fvc_test_avg.astype(float) + (1.0 - w) * fvc_anchor\n",
        "\n",
        "# Guardrails: per-patient non-increasing in future weeks; clip\n",
        "df_out = pd.DataFrame({'Patient': grid['Patient'].values, 'Weeks': grid['Weeks'].values.astype(int), 'FVC': fvc_blend})\n",
        "df_out['FVC'] = df_out['FVC'].clip(500, 6000)\n",
        "def enforce_non_increasing(g):\n",
        "    g = g.sort_values('Weeks').copy()\n",
        "    g['FVC'] = np.minimum.accumulate(g['FVC'].values[::-1])[::-1]\n",
        "    return g\n",
        "df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n",
        "fvc_final = df_out['FVC'].values.astype(float)\n",
        "\n",
        "# Banker 240 + 3*dist sigma, enforce monotone in dist\n",
        "dist = (grid['Weeks'] - grid['Base_Week']).abs().astype(float).values\n",
        "sigma = np.maximum(240.0 + 3.0 * dist, 70.0).astype(float)\n",
        "df_sig = pd.DataFrame({'Patient': grid['Patient'].values, 'dist': dist, 'Sigma': sigma})\n",
        "def enforce_sigma_monotone(g):\n",
        "    g = g.sort_values('dist').copy()\n",
        "    g['Sigma'] = np.maximum.accumulate(g['Sigma'].values)\n",
        "    return g\n",
        "df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n",
        "sigma_final = df_sig['Sigma'].values.astype(float)\n",
        "\n",
        "submission_banker_240x3 = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_final,\n",
        "    'Confidence': sigma_final\n",
        "})\n",
        "submission_banker_240x3.to_csv('submission.csv', index=False)\n",
        "print('Saved banker-240x3 submission.csv with sigma = max(240 + 3*dist, 70), blended FVC, and guardrails.')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved banker-240x3 submission.csv with sigma = max(240 + 3*dist, 70), blended FVC, and guardrails.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/2798916652.py:33: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n/tmp/ipykernel_170/2798916652.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n"
          ]
        }
      ]
    },
    {
      "id": "fee5bc68-7fd9-459a-b448-0f7bc98bba75",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Forward-CV LightGBM residual model (CPU) + simple blend with XGB seed-avg and anchored baseline\n",
        "import numpy as np, pandas as pd, time, gc, sys, subprocess\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "except Exception:\n",
        "    print('Installing lightgbm...', flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'lightgbm==4.6.0', '--no-input'], check=True)\n",
        "    import lightgbm as lgb\n",
        "\n",
        "def forward_residual_oof_and_full_lgb(seed=202, cap_wp=26):\n",
        "    gkf = GroupKFold(n_splits=5)\n",
        "    groups = train['Patient'].values\n",
        "    y_true_all, y_pred_all, dist_all, res_all = [], [], [], []\n",
        "    t0 = time.time()\n",
        "    best_iters = []\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(train, groups=groups), 1):\n",
        "        tf = time.time()\n",
        "        trn = train.iloc[trn_idx].copy()\n",
        "        val = train.iloc[val_idx].copy()\n",
        "        # Anchors\n",
        "        base_trn = (trn.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False)\n",
        "                    .first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "        trn = trn.merge(base_trn, on='Patient', how='left')\n",
        "        base_val = (val.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False)\n",
        "                    .first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "        val = val.merge(base_val, on='Patient', how='left')\n",
        "        # TRAIN-only trend stats (will be zero for VAL to mirror test hygiene)\n",
        "        stats_trn = compute_trend_stats(trn); stats_trn['has_trend'] = (stats_trn['n_obs'] >= 2).astype(int)\n",
        "        pstats_trn = compute_percent_trend_stats(trn)\n",
        "        trn = trn.merge(stats_trn, on='Patient', how='left').merge(pstats_trn, on='Patient', how='left')\n",
        "        val = val.merge(stats_trn, on='Patient', how='left').merge(pstats_trn, on='Patient', how='left')\n",
        "        for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "            trn[c] = trn[c].fillna(v); val[c] = val[c].fillna(v)\n",
        "        trn['n_obs'] = trn['n_obs'].fillna(1).astype(int)\n",
        "        val['n_obs'] = val['n_obs'].fillna(1).astype(int)\n",
        "        trn['has_trend'] = trn['has_trend'].fillna(0).astype(int)\n",
        "        val['has_trend'] = val['has_trend'].fillna(0).astype(int)\n",
        "        val['is_singleton'] = 1; trn['is_singleton'] = (trn['n_obs'] <= 1).astype(int)\n",
        "        # Global slope from TRAIN only\n",
        "        g_slope = robust_global_slope(compute_patient_slopes(trn))\n",
        "        trn['pred0'] = trn['Base_FVC'] + g_slope * (trn['Weeks'] - trn['Base_Week'])\n",
        "        val['pred0'] = val['Base_FVC'] + g_slope * (val['Weeks'] - val['Base_Week'])\n",
        "        # Features (strict baseline Percent usage)\n",
        "        trnF = build_features_v2(trn, cap_wp=cap_wp)\n",
        "        valF = build_features_v2(val, cap_wp=cap_wp)\n",
        "        cats = one_hot_fit(trnF, ['Sex','SmokingStatus'])\n",
        "        trnF = one_hot_transform(trnF, cats); valF = one_hot_transform(valF, cats)\n",
        "        feat_cols = [\n",
        "            'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed_cap','Weeks_Passed2','sign_WP','is_future',\n",
        "            'Percent_clipped','Percent2','Age','Base_FVC','log_BaseFVC','Estimated_TLC','log_TLC',\n",
        "            'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "            'slope_w','r2_w','slope_percent_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w','WP_x_slope_percent_w','dPercent','WP_x_dPercent'\n",
        "        ] + [c for c in trnF.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "        y_trn = (trn['FVC'] - trn['pred0']).astype(float).values\n",
        "        y_val = (val['FVC'] - val['pred0']).astype(float).values\n",
        "        lgb_train = lgb.Dataset(trnF[feat_cols], label=y_trn, free_raw_data=False)\n",
        "        lgb_valid = lgb.Dataset(valF[feat_cols], label=y_val, free_raw_data=False)\n",
        "        params = {\n",
        "            'objective': 'l1',\n",
        "            'metric': 'l1',\n",
        "            'learning_rate': 0.05,\n",
        "            'num_leaves': 63,\n",
        "            'max_depth': -1,\n",
        "            'min_data_in_leaf': 40,\n",
        "            'min_sum_hessian_in_leaf': 10.0,\n",
        "            'feature_fraction': 0.9,\n",
        "            'bagging_fraction': 0.9,\n",
        "            'bagging_freq': 1,\n",
        "            'lambda_l2': 5.0,\n",
        "            'verbosity': -1,\n",
        "            'seed': seed\n",
        "        }\n",
        "        model = lgb.train(params, lgb_train, num_boost_round=4000, valid_sets=[lgb_valid],\n",
        "                          callbacks=[lgb.early_stopping(300, verbose=False)])\n",
        "        pred_res = model.predict(valF[feat_cols], num_iteration=model.best_iteration)\n",
        "        val_pred = val['pred0'].values + pred_res\n",
        "        mask = (val['Weeks'].values >= val['Base_Week'].values)\n",
        "        v_true = val['FVC'].values[mask].astype(float)\n",
        "        v_pred = val_pred[mask].astype(float)\n",
        "        v_dist = (val['Weeks'].values[mask] - val['Base_Week'].values[mask]).astype(float)\n",
        "        y_true_all.append(v_true); y_pred_all.append(v_pred); dist_all.append(v_dist)\n",
        "        res_all.append((v_true - v_pred))\n",
        "        best_iters.append(int(model.best_iteration if model.best_iteration is not None else 4000))\n",
        "        mae = float(np.mean(np.abs(v_true - v_pred))) if v_true.size else np.nan\n",
        "        print(f'[LGB-FWD-Fold {fold}] g_slope={g_slope:.4f} scored={v_true.size} MAE={mae:.2f} iters={best_iters[-1]} elapsed={time.time()-tf:.2f}s', flush=True)\n",
        "        del model, lgb_train, lgb_valid, trnF, valF; gc.collect()\n",
        "    y_true = np.concatenate(y_true_all) if y_true_all else np.array([], float)\n",
        "    y_pred = np.concatenate(y_pred_all) if y_pred_all else np.array([], float)\n",
        "    dist = np.concatenate(dist_all) if dist_all else np.array([], float)\n",
        "    res = np.concatenate(res_all) if res_all else np.array([], float)\n",
        "    # Fit full model with median iters\n",
        "    slopes_full = compute_patient_slopes(train); g_slope_full_loc = robust_global_slope(slopes_full)\n",
        "    base_full = (train.sort_values(['Patient','Weeks']).groupby('Patient', as_index=False).first()[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'}))\n",
        "    train_full = train.merge(base_full, on='Patient', how='left')\n",
        "    stats_full = compute_trend_stats(train_full); stats_full['has_trend'] = (stats_full['n_obs'] >= 2).astype(int)\n",
        "    pstats_full = compute_percent_trend_stats(train_full)\n",
        "    train_full = train_full.merge(stats_full, on='Patient', how='left').merge(pstats_full, on='Patient', how='left')\n",
        "    for c, v in [('slope_w', 0.0), ('r2_w', 0.0), ('slope_percent_w', 0.0)]:\n",
        "        train_full[c] = train_full[c].fillna(v)\n",
        "    train_full['n_obs'] = train_full['n_obs'].fillna(1).astype(int)\n",
        "    train_full['has_trend'] = train_full['has_trend'].fillna(0).astype(int)\n",
        "    train_full['pred0'] = train_full['Base_FVC'] + g_slope_full_loc * (train_full['Weeks'] - train_full['Base_Week'])\n",
        "    train_fullF = build_features_v2(train_full, cap_wp=cap_wp)\n",
        "    # IMPORTANT: Recompute one-hot schema on FULL TRAIN and use for FULL + TEST\n",
        "    cats_full = one_hot_fit(train_fullF, ['Sex','SmokingStatus'])\n",
        "    train_fullF = one_hot_transform(train_fullF, cats_full)\n",
        "    feat_cols_full = [\n",
        "        'Weeks_Passed','Abs_Weeks_Passed','Weeks_Passed_cap','Weeks_Passed2','sign_WP','is_future',\n",
        "        'Percent_clipped','Percent2','Age','Base_FVC','log_BaseFVC','Estimated_TLC','log_TLC',\n",
        "        'Age_x_Percent','Percent_x_BaseFVC','WP_x_BaseFVC','WP_x_Percent','WP_x_Age',\n",
        "        'slope_w','r2_w','slope_percent_w','n_obs','has_trend','is_singleton','WP_x_slope_w','WP_x_r2_w','WP_x_slope_percent_w','dPercent','WP_x_dPercent'\n",
        "    ] + [c for c in train_fullF.columns if c.startswith('Sex__') or c.startswith('SmokingStatus__')]\n",
        "    dtrain_full = lgb.Dataset(train_fullF[feat_cols_full], label=(train_fullF['FVC'] - train_fullF['pred0']).astype(float).values, free_raw_data=False)\n",
        "    model_full = lgb.train(params, dtrain_full, num_boost_round=int(np.median(best_iters)))\n",
        "    # Strict test grid\n",
        "    ss_loc = pd.read_csv('sample_submission.csv')\n",
        "    grid = ss_loc.copy()\n",
        "    parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "    grid['Patient'] = parts[0]\n",
        "    grid['Weeks'] = parts[1].astype(int)\n",
        "    test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "    grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "    meta = test[['Patient','Percent','Age','Sex','SmokingStatus']].drop_duplicates('Patient')\n",
        "    grid = grid.merge(meta, on='Patient', how='left', suffixes=('', '_meta'))\n",
        "    grid['slope_w'] = 0.0; grid['r2_w'] = 0.0; grid['slope_percent_w'] = 0.0; grid['n_obs'] = 1; grid['has_trend'] = 0; grid['is_singleton'] = 1\n",
        "    grid['pred0'] = grid['Base_FVC'] + g_slope_full_loc * (grid['Weeks'] - grid['Base_Week'])\n",
        "    gridF = build_features_v2(grid, cap_wp=cap_wp)\n",
        "    gridF = one_hot_transform(gridF, cats_full)\n",
        "    res_pred = model_full.predict(gridF[feat_cols_full])\n",
        "    fvc_test = (gridF['pred0'].values + res_pred).clip(500, 6000)\n",
        "    dist_test = (gridF['Weeks'] - gridF['Base_Week']).abs().astype(float).values\n",
        "    return {\n",
        "        'y_true': y_true, 'y_pred': y_pred, 'dist': dist, 'res': res,\n",
        "        'fvc_test': fvc_test, 'abs_res_hat_test': np.abs(res_pred), 'dist_test': dist_test\n",
        "    }\n",
        "\n",
        "# Train LGB forward residual and get test preds\n",
        "lgb_run = forward_residual_oof_and_full_lgb(seed=202)\n",
        "fvc_test_lgb = lgb_run['fvc_test']\n",
        "\n",
        "# Build blended submission using XGB seed-avg (fvc_test_avg), LGB (10%), and anchor (15%); keep tuned sigma from seed-avg and guardrails\n",
        "assert 'fvc_test_avg' in globals() and 'sigma_test_primary' in globals(), 'Run Cell 13 first'\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "try:\n",
        "    gsf = float(g_slope_full)\n",
        "except Exception:\n",
        "    slopes_full_tmp = compute_patient_slopes(train)\n",
        "    gsf = robust_global_slope(slopes_full_tmp)\n",
        "fvc_anchor = (grid['Base_FVC'].values + gsf * (grid['Weeks'].values - grid['Base_Week'].values)).astype(float)\n",
        "# Weights: 0.75 XGB seed-avg, 0.10 LGB, 0.15 anchor\n",
        "fvc_blend = 0.75 * fvc_test_avg.astype(float) + 0.10 * fvc_test_lgb.astype(float) + 0.15 * fvc_anchor\n",
        "df_out = pd.DataFrame({'Patient': grid['Patient'].values, 'Weeks': grid['Weeks'].values.astype(int), 'FVC': fvc_blend.clip(500, 6000)})\n",
        "def enforce_non_increasing(g):\n",
        "    g = g.sort_values('Weeks').copy()\n",
        "    g['FVC'] = np.minimum.accumulate(g['FVC'].values[::-1])[::-1]\n",
        "    return g\n",
        "df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n",
        "fvc_final = df_out['FVC'].values.astype(float)\n",
        "# Sigma: keep tuned seed-avg sigma and enforce monotonicity in dist\n",
        "sigma_out = np.maximum(sigma_test_primary.astype(float), 70.0)\n",
        "df_sig = pd.DataFrame({'Patient': grid['Patient'].values, 'Weeks': grid['Weeks'].values.astype(int), 'Base_Week': grid['Base_Week'].values.astype(int), 'Sigma': sigma_out})\n",
        "df_sig['dist'] = (df_sig['Weeks'] - df_sig['Base_Week']).abs().astype(float)\n",
        "def enforce_sigma_monotone(g):\n",
        "    g = g.sort_values('dist').copy()\n",
        "    g['Sigma'] = np.maximum.accumulate(g['Sigma'].values)\n",
        "    return g\n",
        "df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n",
        "sigma_final = df_sig['Sigma'].values.astype(float)\n",
        "submission_lgb_blend = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_final,\n",
        "    'Confidence': sigma_final\n",
        "})\n",
        "submission_lgb_blend.to_csv('submission.csv', index=False)\n",
        "print('Saved XGB-seedavg(0.75) + LGB(0.10) + Anchor(0.15) blended submission.csv with tuned sigma and guardrails.')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LGB-FWD-Fold 1] g_slope=-3.8062 scored=282 MAE=167.83 iters=1 elapsed=0.55s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LGB-FWD-Fold 2] g_slope=-3.5547 scored=281 MAE=118.25 iters=4 elapsed=0.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LGB-FWD-Fold 3] g_slope=-3.5065 scored=275 MAE=136.60 iters=3 elapsed=0.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LGB-FWD-Fold 4] g_slope=-3.5065 scored=275 MAE=154.33 iters=84 elapsed=0.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LGB-FWD-Fold 5] g_slope=-3.6557 scored=281 MAE=135.53 iters=228 elapsed=0.50s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved XGB-seedavg(0.75) + LGB(0.10) + Anchor(0.15) blended submission.csv with tuned sigma and guardrails.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/3866492755.py:157: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n/tmp/ipykernel_170/3866492755.py:167: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n"
          ]
        }
      ]
    },
    {
      "id": "8b23f8f8-4760-4ce3-9ba6-26656b837294",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Tiny LGB weight sweep on forward OOF and regenerate blended submission with guardrails\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "def laplace_ll(y_true, y_pred, sigma):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    y_pred = np.asarray(y_pred).astype(float)\n",
        "    sigma = np.asarray(sigma).astype(float)\n",
        "    delta = np.abs(y_true - y_pred)\n",
        "    delta = np.minimum(delta, 1000.0)\n",
        "    sigma = np.maximum(sigma, 70.0)\n",
        "    return np.mean(-delta / sigma - np.log(sigma))\n",
        "\n",
        "# Requirements from Cell 13 (XGB seed-avg) and Cell 19 (LGB forward residual)\n",
        "assert 'y_true_ref' in globals() and 'y_pred_avg' in globals() and 'dist_ref' in globals(), 'Run Cell 13 first (seed-avg OOF).'\n",
        "assert 'lgb_run' in globals(), 'Run Cell 19 first (LGB forward residual).'\n",
        "y_true_oof = y_true_ref\n",
        "y_pred_xgb_oof = y_pred_avg\n",
        "y_pred_lgb_oof = lgb_run['y_pred']\n",
        "dist_oof = dist_ref\n",
        "\n",
        "# Sanity: check lengths align; if not, fallback to default wl=0.10\n",
        "fallback_wl = 0.10\n",
        "if not (len(y_true_oof) == len(y_pred_xgb_oof) == len(y_pred_lgb_oof) == len(dist_oof)):\n",
        "    print('OOF arrays length mismatch; using fallback wl=', fallback_wl)\n",
        "    best_wl = fallback_wl\n",
        "else:\n",
        "    # Use primary sigma from seed-avg for tuning; robust to tiny weight tweaks\n",
        "    assert 'a_best' in globals() and 'b_best' in globals() and 'c_best' in globals(), 'Missing tuned sigma params from Cell 13.'\n",
        "    # proxy for abs residual from seed-avg to build sigma\n",
        "    abs_res_proxy = np.abs(y_true_oof - y_pred_xgb_oof)\n",
        "    sigma_oof = np.maximum(a_best + b_best*dist_oof + c_best*abs_res_proxy, 70.0)\n",
        "    best = (-1e9, None)\n",
        "    for wl in [0.05, 0.10, 0.15, 0.20, 0.25]:\n",
        "        # OOF blend: adjust only between XGB and LGB; anchor held out of OOF (kept 0.15 at test time)\n",
        "        y_pred_blend = (1.0 - wl) * y_pred_xgb_oof + wl * y_pred_lgb_oof\n",
        "        score = laplace_ll(y_true_oof, y_pred_blend, sigma_oof)\n",
        "        if score > best[0]:\n",
        "            best = (score, wl)\n",
        "    best_wl = best[1] if best[1] is not None else fallback_wl\n",
        "    print(f'OOF sweep best LGB weight (within XGB+LGB only): wl={best_wl:.2f}, LL={best[0]:.5f}')\n",
        "    # If gain small (<0.01), reduce wl to 0.05\n",
        "    # Compare to pure XGB (wl=0) for delta\n",
        "    score_xgb = laplace_ll(y_true_oof, y_pred_xgb_oof, sigma_oof)\n",
        "    score_best = best[0]\n",
        "    if (score_best - score_xgb) < 0.01:\n",
        "        best_wl = 0.05\n",
        "        print('Gain < 0.01; setting wl=0.05 for safety.')\n",
        "\n",
        "# Retune sigma on the chosen OOF blend (optional, quick grid) using seed-avg proxies\n",
        "y_pred_blend_oof = (1.0 - best_wl) * y_pred_xgb_oof + best_wl * y_pred_lgb_oof\n",
        "abs_res_proxy = np.abs(y_true_oof - y_pred_xgb_oof)  # keep proxy from XGB for stability\n",
        "best_sig = (-1e9, None, None, None)\n",
        "for a in [160, 200, 240]:\n",
        "    for b in [2.0, 3.0]:\n",
        "        for c in [0.5, 1.0]:\n",
        "            sigma_try = np.maximum(a + b*dist_oof + c*abs_res_proxy, 70.0)\n",
        "            sc = laplace_ll(y_true_oof, y_pred_blend_oof, sigma_try)\n",
        "            if sc > best_sig[0]:\n",
        "                best_sig = (sc, a, b, c)\n",
        "print(f'Retuned sigma on blended OOF: LL={best_sig[0]:.5f} with a={best_sig[1]} b={best_sig[2]} c={best_sig[3]}')\n",
        "a_blend, b_blend, c_blend = best_sig[1], best_sig[2], best_sig[3]\n",
        "\n",
        "# Build test-time 3-way blend: keep anchor=0.15, distribute remaining 0.85 as (XGB, LGB) = (0.85 - wl, wl)\n",
        "assert 'fvc_test_avg' in globals() and 'dist_test_ref' in globals() and 'abs_res_hat_test_avg' in globals(), 'Run Cell 13 to get test arrays.'\n",
        "assert 'fvc_test_lgb' in globals(), 'Run Cell 19 to compute LGB test predictions.'\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "try:\n",
        "    gsf = float(g_slope_full)\n",
        "except Exception:\n",
        "    slopes_full_tmp = compute_patient_slopes(train)\n",
        "    gsf = robust_global_slope(slopes_full_tmp)\n",
        "fvc_anchor = (grid['Base_FVC'].values + gsf * (grid['Weeks'].values - grid['Base_Week'].values)).astype(float)\n",
        "wxgb = 0.85 - best_wl\n",
        "wlgb = best_wl\n",
        "wanc = 0.15\n",
        "fvc_blend_test = wxgb * fvc_test_avg.astype(float) + wlgb * fvc_test_lgb.astype(float) + wanc * fvc_anchor\n",
        "\n",
        "# Guardrails: non-increasing FVC per patient and sigma monotone in dist\n",
        "df_out = pd.DataFrame({'Patient': grid['Patient'].values, 'Weeks': grid['Weeks'].values.astype(int), 'FVC': fvc_blend_test.clip(500, 6000)})\n",
        "def enforce_non_increasing(g):\n",
        "    g = g.sort_values('Weeks').copy()\n",
        "    g['FVC'] = np.minimum.accumulate(g['FVC'].values[::-1])[::-1]\n",
        "    return g\n",
        "df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n",
        "fvc_final = df_out['FVC'].values.astype(float)\n",
        "\n",
        "# Sigma: use retuned (a_blend,b_blend,c_blend) on test with abs_res proxy from XGB seed-avg\n",
        "dist_test = (grid['Weeks'] - grid['Base_Week']).abs().astype(float).values\n",
        "sigma_final = np.maximum(a_blend + b_blend*dist_test + c_blend*abs_res_hat_test_avg.astype(float), 70.0)\n",
        "df_sig = pd.DataFrame({'Patient': grid['Patient'].values, 'Weeks': grid['Weeks'].values.astype(int), 'Base_Week': grid['Base_Week'].values.astype(int), 'Sigma': sigma_final})\n",
        "df_sig['dist'] = (df_sig['Weeks'] - df_sig['Base_Week']).abs().astype(float)\n",
        "def enforce_sigma_monotone(g):\n",
        "    g = g.sort_values('dist').copy()\n",
        "    g['Sigma'] = np.maximum.accumulate(g['Sigma'].values)\n",
        "    return g\n",
        "df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n",
        "sigma_final = df_sig['Sigma'].values.astype(float)\n",
        "\n",
        "submission_blend_lgb_swept = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_final,\n",
        "    'Confidence': sigma_final\n",
        "})\n",
        "submission_blend_lgb_swept.to_csv('submission.csv', index=False)\n",
        "print(f'Saved swept-weights submission.csv with weights XGB={wxgb:.2f}, LGB={wlgb:.2f}, Anchor={wanc:.2f}; sigma (a,b,c)=({a_blend},{b_blend},{c_blend}).')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF sweep best LGB weight (within XGB+LGB only): wl=0.05, LL=-5.96082\nGain < 0.01; setting wl=0.05 for safety.\nRetuned sigma on blended OOF: LL=-5.96082 with a=160 b=2.0 c=0.5\nSaved swept-weights submission.csv with weights XGB=0.80, LGB=0.05, Anchor=0.15; sigma (a,b,c)=(160,2.0,0.5).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1994988984.py:90: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n/tmp/ipykernel_170/1994988984.py:102: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n"
          ]
        }
      ]
    },
    {
      "id": "0d6a6ed2-5f37-4a63-8d51-f8afe333c103",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save primary submission copy and generate banker variant (240 + 3*dist) for current 3-way blend\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# 1) Save current submission.csv as submission_primary.csv for safekeeping\n",
        "sub_cur = pd.read_csv('submission.csv')\n",
        "sub_cur.to_csv('submission_primary.csv', index=False)\n",
        "print('Backed up current primary to submission_primary.csv')\n",
        "\n",
        "# 2) Rebuild the same 3-way blend FVC using tuned LGB weight from Cell 20 (best_wl) and anchor=0.15\n",
        "assert 'best_wl' in globals(), 'Run Cell 20 first to define best_wl for LGB weight.'\n",
        "assert 'fvc_test_avg' in globals() and 'fvc_test_lgb' in globals(), 'Run Cells 13 and 19 first.'\n",
        "\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "try:\n",
        "    gsf = float(g_slope_full)\n",
        "except Exception:\n",
        "    slopes_full_tmp = compute_patient_slopes(train)\n",
        "    gsf = robust_global_slope(slopes_full_tmp)\n",
        "fvc_anchor = (grid['Base_FVC'].values + gsf * (grid['Weeks'].values - grid['Base_Week'].values)).astype(float)\n",
        "wxgb = 0.85 - float(best_wl)\n",
        "wlgb = float(best_wl)\n",
        "wanc = 0.15\n",
        "fvc_blend = wxgb * fvc_test_avg.astype(float) + wlgb * fvc_test_lgb.astype(float) + wanc * fvc_anchor\n",
        "\n",
        "# Guardrails: non-increasing FVC per patient; clip\n",
        "df_out = pd.DataFrame({'Patient': grid['Patient'].values, 'Weeks': grid['Weeks'].values.astype(int), 'FVC': fvc_blend.clip(500, 6000)})\n",
        "def enforce_non_increasing(g):\n",
        "    g = g.sort_values('Weeks').copy()\n",
        "    g['FVC'] = np.minimum.accumulate(g['FVC'].values[::-1])[::-1]\n",
        "    return g\n",
        "df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n",
        "fvc_final = df_out['FVC'].values.astype(float)\n",
        "\n",
        "# Banker sigma: 240 + 3*dist, enforce monotone in dist\n",
        "dist = (grid['Weeks'] - grid['Base_Week']).abs().astype(float).values\n",
        "sigma = np.maximum(240.0 + 3.0 * dist, 70.0).astype(float)\n",
        "df_sig = pd.DataFrame({'Patient': grid['Patient'].values, 'dist': dist, 'Sigma': sigma})\n",
        "def enforce_sigma_monotone(g):\n",
        "    g = g.sort_values('dist').copy()\n",
        "    g['Sigma'] = np.maximum.accumulate(g['Sigma'].values)\n",
        "    return g\n",
        "df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n",
        "sigma_final = df_sig['Sigma'].values.astype(float)\n",
        "\n",
        "submission_banker_curblend = pd.DataFrame({\n",
        "    'Patient_Week': ss['Patient_Week'],\n",
        "    'FVC': fvc_final,\n",
        "    'Confidence': sigma_final\n",
        "})\n",
        "submission_banker_curblend.to_csv('submission_banker.csv', index=False)\n",
        "print(f'Saved banker variant to submission_banker.csv with weights XGB={wxgb:.2f}, LGB={wlgb:.2f}, Anchor={wanc:.2f} and sigma=max(240+3*dist,70).')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backed up current primary to submission_primary.csv\nSaved banker variant to submission_banker.csv with weights XGB=0.80, LGB=0.05, Anchor=0.15 and sigma=max(240+3*dist,70).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/4078741799.py:37: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n/tmp/ipykernel_170/4078741799.py:48: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n"
          ]
        }
      ]
    },
    {
      "id": "8408b1ee-37d2-4df7-8ecf-9532a530881c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add one shallow XGB forward residual seed for diversity, re-avg predictions, retune sigma, and regenerate submission\n",
        "import numpy as np, pandas as pd, gc, time\n",
        "import xgboost as xgb\n",
        "\n",
        "assert 'forward_residual_oof_and_full' in globals(), 'Run Cell 13 first to define forward_residual_oof_and_full()'\n",
        "assert 'y_true_ref' in globals() and 'y_pred_avg' in globals() and 'dist_ref' in globals(), 'Run Cell 13 first to compute seed-avg OOF arrays'\n",
        "\n",
        "jp = dict(lr=0.045, max_depth=3, min_child_weight=28, reg_lambda=9.0, subsample=0.9, colsample=0.9, colsample_bylevel=1.0)\n",
        "print('Training shallow XGB residual seed for diversity:', jp)\n",
        "t0 = time.time()\n",
        "run_extra = forward_residual_oof_and_full(seed=4242, lr=jp['lr'], max_depth=jp['max_depth'], min_child_weight=jp['min_child_weight'],\n",
        "                                          reg_lambda=jp['reg_lambda'], subsample=jp['subsample'], colsample=jp['colsample'],\n",
        "                                          colsample_bylevel=jp['colsample_bylevel'])\n",
        "print(f'Extra seed trained in {time.time()-t0:.2f}s')\n",
        "\n",
        "# Re-average OOF and test\n",
        "y_pred_avg2 = (y_pred_avg + run_extra['y_pred']) / 2.0\n",
        "fvc_test_avg2 = (fvc_test_avg + run_extra['fvc_test']) / 2.0\n",
        "abs_res_hat_oof_avg2 = (np.abs(y_true_ref - y_pred_avg) + np.abs(y_true_ref - run_extra['y_pred'])) / 2.0\n",
        "abs_res_hat_test_avg2 = (abs_res_hat_test_avg + np.abs(run_extra['abs_res_hat_test'])) / 2.0\n",
        "\n",
        "# Retune sigma on updated OOF blend (small grid) and report LL\n",
        "def laplace_ll(y_true, y_pred, sigma):\n",
        "    y_true = np.asarray(y_true).astype(float); y_pred = np.asarray(y_pred).astype(float); sigma = np.asarray(sigma).astype(float)\n",
        "    delta = np.minimum(np.abs(y_true - y_pred), 1000.0); sigma = np.maximum(sigma, 70.0)\n",
        "    return np.mean(-delta / sigma - np.log(sigma))\n",
        "\n",
        "best = (-1e9, None, None, None)\n",
        "for a in [160, 200, 240]:\n",
        "    for b in [2.0, 3.0]:\n",
        "        for c in [0.5, 1.0]:\n",
        "            sig = np.maximum(a + b*dist_ref + c*abs_res_hat_oof_avg2, 70.0)\n",
        "            sc = laplace_ll(y_true_ref, y_pred_avg2, sig)\n",
        "            if sc > best[0]:\n",
        "                best = (sc, a, b, c)\n",
        "print(f'OOF LL with extra shallow seed: {best[0]:.5f} using a={best[1]} b={best[2]} c={best[3]}')\n",
        "a_ex, b_ex, c_ex = best[1], best[2], best[3]\n",
        "\n",
        "# Build strict test grid and anchored baseline\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "grid = ss.copy()\n",
        "parts = grid['Patient_Week'].str.rsplit('_', n=1, expand=True)\n",
        "grid['Patient'] = parts[0]\n",
        "grid['Weeks'] = parts[1].astype(int)\n",
        "test_bl = test[['Patient','Weeks','FVC','Percent']].rename(columns={'Weeks':'Base_Week','FVC':'Base_FVC','Percent':'Percent_at_base'})\n",
        "grid = grid.merge(test_bl, on='Patient', how='left')\n",
        "try:\n",
        "    gsf = float(g_slope_full)\n",
        "except Exception:\n",
        "    slopes_full_tmp = compute_patient_slopes(train)\n",
        "    gsf = robust_global_slope(slopes_full_tmp)\n",
        "fvc_anchor = (grid['Base_FVC'].values + gsf * (grid['Weeks'].values - grid['Base_Week'].values)).astype(float)\n",
        "\n",
        "# Primary blend: 0.85 seed-avg2 + 0.15 anchored; guardrails\n",
        "fvc_blend = 0.85 * fvc_test_avg2.astype(float) + 0.15 * fvc_anchor\n",
        "df_out = pd.DataFrame({'Patient': grid['Patient'].values, 'Weeks': grid['Weeks'].values.astype(int), 'FVC': fvc_blend.clip(500, 6000)})\n",
        "def enforce_non_increasing(g):\n",
        "    g = g.sort_values('Weeks').copy()\n",
        "    g['FVC'] = np.minimum.accumulate(g['FVC'].values[::-1])[::-1]\n",
        "    return g\n",
        "df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n",
        "fvc_final = df_out['FVC'].values.astype(float)\n",
        "\n",
        "# Sigma: tuned on updated OOF; apply and enforce monotone in dist; optional floor at dist>20\n",
        "dist_test = (grid['Weeks'] - grid['Base_Week']).abs().astype(float).values\n",
        "sigma_primary = np.maximum(a_ex + b_ex*dist_test + c_ex*abs_res_hat_test_avg2.astype(float), 70.0)\n",
        "sigma_primary = np.where(dist_test > 20.0, np.maximum(sigma_primary, 100.0), sigma_primary)\n",
        "df_sig = pd.DataFrame({'Patient': grid['Patient'].values, 'Weeks': grid['Weeks'].values.astype(int), 'Base_Week': grid['Base_Week'].values.astype(int), 'Sigma': sigma_primary})\n",
        "df_sig['dist'] = (df_sig['Weeks'] - df_sig['Base_Week']).abs().astype(float)\n",
        "def enforce_sigma_monotone(g):\n",
        "    g = g.sort_values('dist').copy()\n",
        "    g['Sigma'] = np.maximum.accumulate(g['Sigma'].values)\n",
        "    return g\n",
        "df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n",
        "sigma_final = df_sig['Sigma'].values.astype(float)\n",
        "\n",
        "submission_extra_seed = pd.DataFrame({'Patient_Week': ss['Patient_Week'], 'FVC': fvc_final, 'Confidence': sigma_final})\n",
        "submission_extra_seed.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with extra shallow seed averaged (85% blend with anchor) and retuned sigma. Weights: seed-avg2 0.85, anchor 0.15.')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training shallow XGB residual seed for diversity: {'lr': 0.045, 'max_depth': 3, 'min_child_weight': 28, 'reg_lambda': 9.0, 'subsample': 0.9, 'colsample': 0.9, 'colsample_bylevel': 1.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed4242-Fold 1] g_slope=-3.8062 scored=282 MAE=165.02 iters=33 elapsed=0.67s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed4242-Fold 2] g_slope=-3.5547 scored=281 MAE=116.96 iters=9 elapsed=0.58s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed4242-Fold 3] g_slope=-3.5065 scored=275 MAE=136.77 iters=124 elapsed=0.76s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed4242-Fold 4] g_slope=-3.5065 scored=275 MAE=155.59 iters=1 elapsed=0.57s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:80: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_med = (trn.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed4242-Fold 5] g_slope=-3.6557 scored=281 MAE=133.92 iters=356 elapsed=1.13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extra seed trained in 4.34s\nOOF LL with extra shallow seed: -5.96105 using a=160 b=2.0 c=0.5\nSaved submission.csv with extra shallow seed averaged (85% blend with anchor) and retuned sigma. Weights: seed-avg2 0.85, anchor 0.15.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_170/1393470315.py:186: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['slope_p']\n/tmp/ipykernel_170/1393470315.py:193: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grp_basefvc_full = (train_full.groupby(['Sex','SmokingStatus','AgeBin'], dropna=False)['Base_FVC']\n/tmp/ipykernel_170/2897560498.py:61: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_out = df_out.groupby('Patient', as_index=False, group_keys=False).apply(enforce_non_increasing)\n/tmp/ipykernel_170/2897560498.py:74: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df_sig = df_sig.groupby('Patient', as_index=False, group_keys=False).apply(enforce_sigma_monotone)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}