{
  "cells": [
    {
      "id": "ad0d8909-1e22-4b8f-bffa-226a7034bedc",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan\n",
        "\n",
        "- Goal: Build a strong, GPU-accelerated image classification pipeline for iWildCam 2019 with reliable CV and fast iterations. Target: \u2265 bronze (macro-F1 \u2265 0.114), aim \u2265 silver.\n",
        "- Validation:\n",
        "  - Stratified KFold on category_id (5 folds). If metadata like site/sequence is available, consider GroupKFold by location/sequence; otherwise stick to StratifiedKFold for speed initially.\n",
        "- Baseline model:\n",
        "  - Pretrained timm backbone (e.g., convnext_tiny or efficientnet_b0) fine-tuned with mixed precision.\n",
        "  - Input size 224, augmentations (RandomResizedCrop, HFlip, ColorJitter, AutoAugment).\n",
        "  - Class-balanced sampler or weighted loss (CrossEntropy with class weights or focal).\n",
        "  - Early stopping, cosine schedule, warmup.\n",
        "- Iteration steps:\n",
        "  1) Environment + GPU check\n",
        "  2) Data load & sanity checks; unzip images (to /mnt for I/O speed), verify paths\n",
        "  3) Fast smoke run on small subset (e.g., 5k images, 1 fold) to validate pipeline\n",
        "  4) Full training with 5-fold CV; save OOF and test logits\n",
        "  5) Error analysis; try alternative backbones (beit_base_224, eva02, nfnet), resolutions 256/320; tune class weights\n",
        "  6) Blend top-2 models by logits\n",
        "\n",
        "- Deliverables:\n",
        "  - Deterministic folds saved\n",
        "  - submission.csv\n",
        "  - Logged training progress per epoch/fold\n",
        "\n",
        "Request expert review after: plan (now), data EDA, baseline smoke OOF, first full CV, and any poor score."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c3ec9ebf-42ab-4b2c-b337-f1ef85725345",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment + Data EDA + Prepare fast storage\n",
        "import os, sys, shutil, time, json, math, subprocess, zipfile, io\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "print('=== GPU CHECK (nvidia-smi) ===', flush=True)\n",
        "try:\n",
        "    out = subprocess.run(['bash','-lc','nvidia-smi || true'], capture_output=True, text=True, check=False)\n",
        "    print(out.stdout)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi failed:', e)\n",
        "\n",
        "print('=== Python & Disk Info ===')\n",
        "print(sys.version)\n",
        "print('CWD:', os.getcwd())\n",
        "print('Free space on / and CWD (GB):', shutil.disk_usage('/').free/1e9, shutil.disk_usage('.').free/1e9)\n",
        "\n",
        "DATA_DIR = Path('.')\n",
        "# Use a writable local fast directory instead of /mnt (permission denied)\n",
        "FAST_DIR = Path('./fast_storage/iwildcam')\n",
        "FAST_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_csv = DATA_DIR/'train.csv'\n",
        "test_csv = DATA_DIR/'test.csv'\n",
        "train_zip = DATA_DIR/'train_images.zip'\n",
        "test_zip = DATA_DIR/'test_images.zip'\n",
        "\n",
        "print('=== Load CSVs ===')\n",
        "train_df = pd.read_csv(train_csv)\n",
        "test_df = pd.read_csv(test_csv)\n",
        "print('train_df shape:', train_df.shape)\n",
        "print('test_df shape:', test_df.shape)\n",
        "print('Columns:', list(train_df.columns))\n",
        "print('Head:\\n', train_df.head(3))\n",
        "\n",
        "# Identify potential grouping columns to avoid leakage\n",
        "candidate_groups = [c for c in ['sequence_id','location','site','seq_id','sequence','location_id'] if c in train_df.columns]\n",
        "print('Candidate group columns:', candidate_groups)\n",
        "for c in candidate_groups:\n",
        "    vc = train_df[c].value_counts().head(5)\n",
        "    print(f'Top groups for {c}:\\n{vc}')\n",
        "\n",
        "# Target distribution\n",
        "target_col = 'category_id'\n",
        "if target_col in train_df.columns:\n",
        "    n_classes = train_df[target_col].nunique()\n",
        "    print('Num classes:', n_classes)\n",
        "    print('Target sample:\\n', train_df[target_col].value_counts().head(10))\n",
        "\n",
        "# Plan image extraction to fast disk if not already extracted\n",
        "fast_train_dir = FAST_DIR/'train_images'\n",
        "fast_test_dir = FAST_DIR/'test_images'\n",
        "\n",
        "def unzip_if_needed(zip_path: Path, out_dir: Path, label: str):\n",
        "    if out_dir.exists() and any(out_dir.iterdir()):\n",
        "        print(f'{label}: already extracted at {out_dir}')\n",
        "        return\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    t0 = time.time()\n",
        "    print(f'Extracting {zip_path} -> {out_dir} ...', flush=True)\n",
        "    # Use system unzip for speed if available\n",
        "    if shutil.which('unzip') is not None:\n",
        "        cmd = f\"unzip -qq -o '{zip_path}' -d '{out_dir}'\"\n",
        "        print('Running:', cmd)\n",
        "        rc = subprocess.call(['bash','-lc', cmd])\n",
        "        if rc != 0:\n",
        "            print('unzip failed with code', rc, '; falling back to python zipfile')\n",
        "        else:\n",
        "            print(f'{label}: unzip completed in {time.time()-t0:.1f}s')\n",
        "            return\n",
        "    # Fallback: python zipfile (slower)\n",
        "    with zipfile.ZipFile(zip_path) as zf:\n",
        "        members = zf.namelist()\n",
        "        n = len(members)\n",
        "        for i, m in enumerate(members, 1):\n",
        "            zf.extract(m, out_dir)\n",
        "            if i % 5000 == 0:\n",
        "                print(f'{label}: extracted {i}/{n}', flush=True)\n",
        "    print(f'{label}: extraction completed in {time.time()-t0:.1f}s')\n",
        "\n",
        "print('=== Ensure images on local fast storage (./fast_storage) ===')\n",
        "if train_zip.exists():\n",
        "    unzip_if_needed(train_zip, fast_train_dir, 'train')\n",
        "else:\n",
        "    print('Missing train_images.zip')\n",
        "if test_zip.exists():\n",
        "    unzip_if_needed(test_zip, fast_test_dir, 'test')\n",
        "else:\n",
        "    print('Missing test_images.zip')\n",
        "\n",
        "# Sanity: sample a few image paths from train_df\n",
        "img_col_candidates = [c for c in ['file_name','filename','image_id','id','image_path'] if c in train_df.columns]\n",
        "print('Image id/path columns candidates:', img_col_candidates)\n",
        "if img_col_candidates:\n",
        "    img_col = img_col_candidates[0]\n",
        "    print('Using image column:', img_col)\n",
        "    # Try to construct absolute paths under fast dir\n",
        "    sample_rows = train_df.head(5)\n",
        "    for _, r in sample_rows.iterrows():\n",
        "        fn = str(r[img_col])\n",
        "        # Many competitions store just filename; adapt if nested\n",
        "        p1 = fast_train_dir/fn\n",
        "        # If not exists, try basename\n",
        "        if not p1.exists():\n",
        "            p1 = fast_train_dir/Path(fn).name\n",
        "        print('Sample image path candidate:', p1, 'exists:', p1.exists())\n",
        "else:\n",
        "    print('Could not identify image filename column; will inspect in later step.')\n",
        "\n",
        "print('=== EDA step complete ===')\n",
        "\n",
        "# Next steps (for operator log):\n",
        "# - Decide grouping key for CV based on candidate_groups (prefer sequence_id, else location).\n",
        "# - Build folds and persist to disk.\n",
        "# - Implement dataloaders and baseline model training script."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== GPU CHECK (nvidia-smi) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 24 19:30:42 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n=== Python & Disk Info ===\n3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]\nCWD: /var/lib/simon/agent_run_states/iwildcam-2019-fgvc6-20250924-184738\nFree space on / and CWD (GB): 1196.94792704 1196.94792704\n=== Load CSVs ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df shape: (179422, 11)\ntest_df shape: (16877, 10)\nColumns: ['category_id', 'date_captured', 'file_name', 'frame_num', 'id', 'location', 'rights_holder', 'seq_id', 'seq_num_frames', 'width', 'height']\nHead:\n    category_id        date_captured                                 file_name  \\\n0           19  2012-03-17 03:48:44  588a679f-23d2-11e8-a6a3-ec086b02610b.jpg   \n1            0  2014-05-11 11:56:46  59279ce3-23d2-11e8-a6a3-ec086b02610b.jpg   \n2            0  2013-10-06 02:00:00  5a2af4ab-23d2-11e8-a6a3-ec086b02610b.jpg   \n\n   frame_num                                    id  location  rights_holder  \\\n0          2  588a679f-23d2-11e8-a6a3-ec086b02610b       115   Justin Brown   \n1          1  59279ce3-23d2-11e8-a6a3-ec086b02610b        96  Erin Boydston   \n2          1  5a2af4ab-23d2-11e8-a6a3-ec086b02610b        57  Erin Boydston   \n\n                                 seq_id  seq_num_frames  width  height  \n0  6f12067d-5567-11e8-b3c0-dca9047ef277               3   1024     747  \n1  6faa92d1-5567-11e8-b1ae-dca9047ef277               1   1024     747  \n2  6f7d4702-5567-11e8-9e03-dca9047ef277               1   1024     747  \nCandidate group columns: ['location', 'seq_id']\nTop groups for location:\nlocation\n96    36080\n26    27380\n23    10246\n38     9745\n76     9345\nName: count, dtype: int64\nTop groups for seq_id:\nseq_id\n6f15e238-5567-11e8-9da0-dca9047ef277    12\n6f15cdc0-5567-11e8-95b2-dca9047ef277    12\n6f16078f-5567-11e8-89b9-dca9047ef277    12\n6f15da66-5567-11e8-a11c-dca9047ef277    12\n6f15e5cf-5567-11e8-b551-dca9047ef277    12\nName: count, dtype: int64\nNum classes: 14\nTarget sample:\n category_id\n0     128468\n19     10861\n1       6035\n8       5783\n11      5762\n13      5303\n16      4773\n17      4125\n3       2902\n18      1846\nName: count, dtype: int64\n=== Ensure images on local fast storage (./fast_storage) ===\nExtracting train_images.zip -> fast_storage/iwildcam/train_images ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 5000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 10000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 15000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 20000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 25000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 30000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 35000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 40000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 45000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 50000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 55000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 60000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 65000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 70000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 75000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 80000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 85000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 90000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 95000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 100000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 105000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 110000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 115000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 120000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 125000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 130000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 135000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 140000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 145000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 150000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 155000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 160000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 165000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 170000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extracted 175000/179224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: extraction completed in 93.2s\nExtracting test_images.zip -> fast_storage/iwildcam/test_images ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: extracted 5000/16862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: extracted 10000/16862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: extracted 15000/16862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: extraction completed in 7.7s\nImage id/path columns candidates: ['file_name', 'id']\nUsing image column: file_name\nSample image path candidate: fast_storage/iwildcam/train_images/588a679f-23d2-11e8-a6a3-ec086b02610b.jpg exists: True\nSample image path candidate: fast_storage/iwildcam/train_images/59279ce3-23d2-11e8-a6a3-ec086b02610b.jpg exists: True\nSample image path candidate: fast_storage/iwildcam/train_images/5a2af4ab-23d2-11e8-a6a3-ec086b02610b.jpg exists: True\nSample image path candidate: fast_storage/iwildcam/train_images/593d68d7-23d2-11e8-a6a3-ec086b02610b.jpg exists: True\nSample image path candidate: fast_storage/iwildcam/train_images/58782b45-23d2-11e8-a6a3-ec086b02610b.jpg exists: True\n=== EDA step complete ===\n"
          ]
        }
      ]
    },
    {
      "id": "2d5b3d72-efec-497b-9205-bb7f5c1a2ac8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build grouped CV folds, label maps, and class weights\n",
        "import pandas as pd, numpy as np, json\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import GroupKFold\n",
        "try:\n",
        "    from sklearn.model_selection import StratifiedGroupKFold\n",
        "    HAS_SGK = True\n",
        "except Exception:\n",
        "    HAS_SGK = False\n",
        "\n",
        "DATA_DIR = Path('.')\n",
        "FAST_DIR = Path('./fast_storage/iwildcam')\n",
        "train_df = pd.read_csv(DATA_DIR/'train.csv')\n",
        "\n",
        "# Determine groups and target\n",
        "target_col = 'category_id'\n",
        "group_col = 'seq_id' if 'seq_id' in train_df.columns else ('location' if 'location' in train_df.columns else None)\n",
        "assert group_col is not None, 'No grouping column found (seq_id/location missing)'\n",
        "y = train_df[target_col].values\n",
        "groups = train_df[group_col].values\n",
        "\n",
        "n_splits = 5\n",
        "rng_seed = 42\n",
        "\n",
        "folds = np.full(len(train_df), -1, dtype=int)\n",
        "if HAS_SGK:\n",
        "    sgk = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=rng_seed)\n",
        "    for fi, (_, val_idx) in enumerate(sgk.split(train_df, y, groups=groups)):\n",
        "        folds[val_idx] = fi\n",
        "else:\n",
        "    print('StratifiedGroupKFold not available; using GroupKFold (CV may be less balanced).')\n",
        "    gk = GroupKFold(n_splits=n_splits)\n",
        "    for fi, (_, val_idx) in enumerate(gk.split(train_df, y, groups=groups)):\n",
        "        folds[val_idx] = fi\n",
        "\n",
        "assert (folds >= 0).all(), 'Fold assignment failed'\n",
        "train_df['fold'] = folds\n",
        "\n",
        "# Create label maps (category_id -> idx 0..K-1)\n",
        "classes = np.sort(train_df[target_col].unique())\n",
        "class_to_idx = {int(c): i for i, c in enumerate(classes)}\n",
        "idx_to_class = {i: int(c) for i, c in enumerate(classes)}\n",
        "train_df['target_idx'] = train_df[target_col].map(class_to_idx).astype(int)\n",
        "\n",
        "# Class weights: (freq + 1e-3)^-0.5 normalized to mean=1\n",
        "counts = train_df[target_col].value_counts().reindex(classes, fill_value=0).astype(float).values\n",
        "weights = (counts + 1e-3) ** -0.5\n",
        "weights = weights / weights.mean()\n",
        "class_weights = {int(c): float(w) for c, w in zip(classes, weights)}\n",
        "\n",
        "# Persist artifacts\n",
        "out_dir = Path('./artifacts')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "(DATA_DIR/'folds.csv').write_text(train_df[['id','file_name',target_col, group_col, 'fold']].to_csv(index=False))\n",
        "json.dump({'class_to_idx': class_to_idx, 'idx_to_class': idx_to_class}, open(out_dir/'label_maps.json','w'))\n",
        "json.dump({'class_weights': class_weights}, open(out_dir/'class_weights.json','w'))\n",
        "\n",
        "# Save a compact meta for training\n",
        "meta_cols = ['id','file_name', target_col, 'target_idx', 'fold', group_col, 'location', 'width', 'height', 'seq_num_frames', 'frame_num']\n",
        "meta_cols = [c for c in meta_cols if c in train_df.columns]\n",
        "train_df[meta_cols].to_csv(out_dir/'train_meta.csv', index=False)\n",
        "\n",
        "# Print summary\n",
        "print('Folds distribution:')\n",
        "print(train_df.groupby('fold')[target_col].agg(['count']).reset_index())\n",
        "print('Num classes:', len(classes))\n",
        "print('Artifacts written to:', out_dir.resolve())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folds distribution:\n   fold  count\n0     0  35901\n1     1  35915\n2     2  35826\n3     3  35870\n4     4  35910\nNum classes: 14\nArtifacts written to: /var/lib/simon/agent_run_states/iwildcam-2019-fgvc6-20250924-184738/artifacts\n"
          ]
        }
      ]
    },
    {
      "id": "236f2362-f27d-4697-baeb-52e98ea50390",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install CUDA 12.1 torch stack and core deps\n",
        "import os, sys, subprocess, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def pip(*args):\n",
        "    print('>', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Uninstall any preexisting torch stacks (best-effort)\n",
        "for pkg in ('torch','torchvision','torchaudio'):\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "\n",
        "# Clean stray site dirs that can shadow correct wheels (idempotent)\n",
        "for d in (\n",
        "    '/app/.pip-target/torch',\n",
        "    '/app/.pip-target/torch-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torch-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchvision',\n",
        "    '/app/.pip-target/torchvision-0.23.0.dist-info',\n",
        "    '/app/.pip-target/torchvision-0.19.1.dist-info',\n",
        "    '/app/.pip-target/torchaudio',\n",
        "    '/app/.pip-target/torchaudio-2.8.0.dist-info',\n",
        "    '/app/.pip-target/torchaudio-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchgen',\n",
        "    '/app/.pip-target/functorch',\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d)\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# 1) Install EXACT cu121 torch stack\n",
        "pip('install',\n",
        "    '--index-url', 'https://download.pytorch.org/whl/cu121',\n",
        "    '--extra-index-url', 'https://pypi.org/simple',\n",
        "    'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1')\n",
        "\n",
        "# 2) Freeze torch versions\n",
        "Path('constraints.txt').write_text(\n",
        "    'torch==2.4.1\\n'\n",
        "    'torchvision==0.19.1\\n'\n",
        "    'torchaudio==2.4.1\\n'\n",
        ")\n",
        "\n",
        "# 3) Install deps honoring constraints\n",
        "pip('install', '-c', 'constraints.txt',\n",
        "    'timm==1.0.9', 'albumentations==1.4.8', 'opencv-python-headless',\n",
        "    'scikit-learn', 'pandas', 'numpy', 'matplotlib', 'seaborn',\n",
        "    'einops', 'ema-pytorch',\n",
        "    '--upgrade-strategy', 'only-if-needed')\n",
        "\n",
        "# 4) Sanity gate\n",
        "import torch\n",
        "print('torch:', torch.__version__, 'built CUDA:', getattr(torch.version, 'cuda', None))\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f'Wrong CUDA build: {torch.version.cuda}'\n",
        "assert torch.cuda.is_available(), 'CUDA not available'\n",
        "print('GPU:', torch.cuda.get_device_name(0))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchvision as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> install --index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.org/simple torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 575.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 437.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 416.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 7.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 345.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 222.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 478.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 390.6 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 333.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 222.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 332.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 195.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 307.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 311.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 498.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 451.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 314.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 467.6 MB/s eta 0:00:00\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 307.4 MB/s eta 0:00:00\nCollecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 492.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 468.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 492.0 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 313.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 487.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> install -c constraints.txt timm==1.0.9 albumentations==1.4.8 opencv-python-headless scikit-learn pandas numpy matplotlib seaborn einops ema-pytorch --upgrade-strategy only-if-needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==1.0.9\n  Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.3/2.3 MB 71.7 MB/s eta 0:00:00\nCollecting albumentations==1.4.8\n  Downloading albumentations-1.4.8-py3-none-any.whl (156 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 156.8/156.8 KB 408.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless\n  Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 54.0/54.0 MB 234.8 MB/s eta 0:00:00\nCollecting scikit-learn\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 9.7/9.7 MB 180.3 MB/s eta 0:00:00\nCollecting pandas\n  Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12.4/12.4 MB 279.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 216.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matplotlib\n  Downloading matplotlib-3.10.6-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 8.7/8.7 MB 193.5 MB/s eta 0:00:00\nCollecting seaborn\n  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 294.9/294.9 KB 160.6 MB/s eta 0:00:00\nCollecting einops\n  Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.4/64.4 KB 403.3 MB/s eta 0:00:00\nCollecting ema-pytorch\n  Downloading ema_pytorch-0.7.7-py3-none-any.whl (9.8 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_hub\n  Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 563.3/563.3 KB 344.8 MB/s eta 0:00:00\nCollecting torchvision\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.0/7.0 MB 210.8 MB/s eta 0:00:00\nCollecting torch\n  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 797.1/797.1 MB 231.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml\n  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 763.0/763.0 KB 515.0 MB/s eta 0:00:00\nCollecting safetensors\n  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 485.8/485.8 KB 479.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albucore>=0.0.4\n  Downloading albucore-0.0.33-py3-none-any.whl (18 kB)\nCollecting scipy>=1.10.0\n  Downloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35.9/35.9 MB 151.0 MB/s eta 0:00:00\nCollecting typing-extensions>=4.9.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 392.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic>=2.7.0\n  Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 444.9/444.9 KB 534.6 MB/s eta 0:00:00\nCollecting scikit-image>=0.21.0\n  Downloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.8/14.8 MB 236.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-python-headless\n  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 50.0/50.0 MB 157.5 MB/s eta 0:00:00\nCollecting joblib>=1.2.0\n  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 308.4/308.4 KB 543.6 MB/s eta 0:00:00\nCollecting threadpoolctl>=3.1.0\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dateutil>=2.8.2\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 229.9/229.9 KB 529.0 MB/s eta 0:00:00\nCollecting pytz>=2020.1\n  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 509.2/509.2 KB 560.5 MB/s eta 0:00:00\nCollecting tzdata>=2022.7\n  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 347.8/347.8 KB 552.2 MB/s eta 0:00:00\nCollecting contourpy>=1.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 355.2/355.2 KB 435.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fonttools>=4.22.0\n  Downloading fonttools-4.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 5.0/5.0 MB 207.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow>=8\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 142.6 MB/s eta 0:00:00\nCollecting pyparsing>=2.3.1\n  Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 113.9/113.9 KB 476.0 MB/s eta 0:00:00\nCollecting cycler>=0.10\n  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\nCollecting packaging>=20.0\n  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 66.5/66.5 KB 431.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kiwisolver>=1.3.1\n  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.4/1.4 MB 116.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting simsimd>=5.9.2\n  Downloading simsimd-6.5.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.1/1.1 MB 287.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stringzilla>=3.10.4\n  Downloading stringzilla-4.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (496 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 496.5/496.5 KB 452.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic-core==2.33.2\n  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 540.9 MB/s eta 0:00:00\nCollecting typing-inspection>=0.4.0\n  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nCollecting six>=1.5\n  Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nCollecting networkx>=3.0\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 528.4 MB/s eta 0:00:00\nCollecting tifffile>=2022.8.12\n  Downloading tifffile-2025.9.20-py3-none-any.whl (230 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 230.1/230.1 KB 488.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lazy-loader>=0.4\n  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\nCollecting imageio!=2.35.0,>=2.33\n  Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 315.8/315.8 KB 513.0 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 216.0 MB/s eta 0:00:00\nCollecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 232.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 358.6 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 189.7 MB/s eta 0:00:00\nCollecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 487.7 MB/s eta 0:00:00\nCollecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 508.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 559.2 MB/s eta 0:00:00\nCollecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 148.7 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 112.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 470.9 MB/s eta 0:00:00\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 289.0 MB/s eta 0:00:00\nCollecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 97.5 MB/s eta 0:00:00\nCollecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 228.7 MB/s eta 0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 296.1 MB/s eta 0:00:00\nCollecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 327.5 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 233.6 MB/s eta 0:00:00\nCollecting requests\n  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.7/64.7 KB 449.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hf-xet<2.0.0,>=1.1.3\n  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.2/3.2 MB 577.8 MB/s eta 0:00:00\nCollecting tqdm>=4.42.1\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 78.5/78.5 KB 479.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.10-py3-none-any.whl (70 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 70.4/70.4 KB 439.1 MB/s eta 0:00:00\nCollecting urllib3<3,>=1.21.1\n  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129.8/129.8 KB 467.5 MB/s eta 0:00:00\nCollecting certifi>=2017.4.17\n  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.2/161.2 KB 480.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting charset_normalizer<4,>=2\n  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 150.3/150.3 KB 518.3 MB/s eta 0:00:00\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 188.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: simsimd, pytz, mpmath, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, stringzilla, six, safetensors, pyyaml, pyparsing, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, joblib, idna, hf-xet, fsspec, fonttools, filelock, einops, cycler, charset_normalizer, certifi, annotated-types, typing-inspection, triton, tifffile, scipy, requests, python-dateutil, pydantic-core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lazy-loader, jinja2, imageio, contourpy, scikit-learn, scikit-image, pydantic, pandas, nvidia-cusolver-cu12, matplotlib, huggingface_hub, albucore, torch, seaborn, albumentations, torchvision, ema-pytorch, timm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 albucore-0.0.33 albumentations-1.4.8 annotated-types-0.7.0 certifi-2025.8.3 charset_normalizer-3.4.3 contourpy-1.3.3 cycler-0.12.1 einops-0.8.1 ema-pytorch-0.7.7 filelock-3.19.1 fonttools-4.60.0 fsspec-2025.9.0 hf-xet-1.1.10 huggingface_hub-0.35.1 idna-3.10 imageio-2.37.0 jinja2-3.1.6 joblib-1.5.2 kiwisolver-1.4.9 lazy-loader-0.4 matplotlib-3.10.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 opencv-python-headless-4.11.0.86 packaging-25.0 pandas-2.3.2 pillow-11.3.0 pydantic-2.11.9 pydantic-core-2.33.2 pyparsing-3.2.5 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 requests-2.32.5 safetensors-0.6.2 scikit-image-0.25.2 scikit-learn-1.7.2 scipy-1.16.2 seaborn-0.13.2 simsimd-6.5.3 six-1.17.0 stringzilla-4.0.14 sympy-1.14.0 threadpoolctl-3.6.0 tifffile-2025.9.20 timm-1.0.9 torch-2.4.1 torchvision-0.19.1 tqdm-4.67.1 triton-3.0.0 typing-extensions-4.15.0 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 built CUDA: 12.1\nCUDA available: True\nGPU: NVIDIA A10-24Q\n"
          ]
        }
      ]
    },
    {
      "id": "2a0e6472-15a2-4152-814d-92c6c6707708",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Smoke training: fold 0, tf_efficientnet_b3_ns @300 for 3 epochs with weighted CE + smoothing\n",
        "import os, time, math, random, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score\n",
        "import timm\n",
        "from PIL import Image, ImageFile\n",
        "import torchvision.transforms as T\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "SEED = 42\n",
        "def seed_everything(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "seed_everything()\n",
        "\n",
        "DATA_DIR = Path('.')\n",
        "FAST_DIR = Path('./fast_storage/iwildcam')\n",
        "IMG_DIR = FAST_DIR/'train_images'\n",
        "assert IMG_DIR.exists(), 'Train images not found; ensure extraction complete.'\n",
        "\n",
        "# Load metadata and build maps\n",
        "df = pd.read_csv(DATA_DIR/'train.csv')\n",
        "assert 'fold' in pd.read_csv(DATA_DIR/'folds.csv').columns, 'folds.csv missing or malformed'\n",
        "folds_df = pd.read_csv(DATA_DIR/'folds.csv')\n",
        "df = df.merge(folds_df[['id','fold']], on='id', how='left')\n",
        "assert df['fold'].notna().all(), 'Some rows missing fold assignment'\n",
        "classes = np.sort(df['category_id'].unique())\n",
        "class_to_idx = {int(c): i for i, c in enumerate(classes)}\n",
        "idx_to_class = {i: int(c) for i, c in enumerate(classes)}\n",
        "df['target_idx'] = df['category_id'].map(class_to_idx).astype(int)\n",
        "K = len(classes)\n",
        "\n",
        "# Class weights (inverse sqrt freq, mean=1)\n",
        "counts = df['category_id'].value_counts().reindex(classes, fill_value=0).astype(float).values\n",
        "weights = (counts + 1e-3) ** -0.5\n",
        "weights = weights / weights.mean()\n",
        "class_weights_tensor = torch.tensor(weights, dtype=torch.float32).cuda()\n",
        "\n",
        "IMG_SIZE = 300\n",
        "VAL_SHORT = 336\n",
        "\n",
        "train_tfm = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.6,1.0), interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "    T.RandomErasing(p=0.25, scale=(0.02,0.15), ratio=(0.3,3.3)),\n",
        "])\n",
        "val_tfm = T.Compose([\n",
        "    T.Resize(VAL_SHORT, interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "class IWildCamDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, tfm, with_target=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.tfm = tfm\n",
        "        self.with_target = with_target\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        fn = str(r['file_name'])\n",
        "        p = self.img_dir/fn\n",
        "        if not p.exists():\n",
        "            p = self.img_dir/Path(fn).name\n",
        "        try:\n",
        "            img = Image.open(p).convert('RGB')\n",
        "        except Exception:\n",
        "            # fallback: create a black image to avoid crash but log index\n",
        "            img = Image.new('RGB', (IMG_SIZE, IMG_SIZE), (0,0,0))\n",
        "        img = self.tfm(img)\n",
        "        if self.with_target:\n",
        "            return img, int(r['target_idx']), r['seq_id'], r['id']\n",
        "        else:\n",
        "            return img, r['seq_id'], r['id']\n",
        "\n",
        "def build_loaders(fold, bs=32, nw=8):\n",
        "    tr = df[df['fold'] != fold].copy()\n",
        "    va = df[df['fold'] == fold].copy()\n",
        "    # Print val class distribution for sanity\n",
        "    print('Fold', fold, 'val class distribution (category_id top-10):')\n",
        "    print(va['category_id'].value_counts().head(10))\n",
        "    ds_tr = IWildCamDataset(tr, IMG_DIR, train_tfm, with_target=True)\n",
        "    ds_va = IWildCamDataset(va, IMG_DIR, val_tfm, with_target=True)\n",
        "    dl_tr = DataLoader(ds_tr, batch_size=bs, shuffle=True, num_workers=nw, pin_memory=True, persistent_workers=True, drop_last=True)\n",
        "    dl_va = DataLoader(ds_va, batch_size=bs*2, shuffle=False, num_workers=nw, pin_memory=True, persistent_workers=True)\n",
        "    return dl_tr, dl_va, va.reset_index(drop=True)\n",
        "\n",
        "def macro_f1_from_logits_np(logits_np, targets_np, K):\n",
        "    preds = logits_np.argmax(1)\n",
        "    return f1_score(targets_np, preds, average='macro', labels=list(range(K)), zero_division=0)\n",
        "\n",
        "def evaluate(model, dl, df_va, device, tta=False):\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "    all_targets = []\n",
        "    all_seq = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb, seqs, _ids in dl:\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            logits = model(xb)\n",
        "            if tta:\n",
        "                xb_flip = torch.flip(xb, dims=[3])\n",
        "                logits_flip = model(xb_flip)\n",
        "                logits = 0.5*(logits + logits_flip)\n",
        "            all_logits.append(logits.float().cpu())\n",
        "            all_targets.append(yb.cpu())\n",
        "            all_seq.extend(list(seqs))\n",
        "    logits = torch.cat(all_logits, 0).numpy()\n",
        "    targets = torch.cat(all_targets, 0).numpy()\n",
        "    # Plain macro-F1 over all K classes\n",
        "    f1_plain = macro_f1_from_logits_np(logits, targets, K)\n",
        "    # Sequence-level averaging\n",
        "    df_tmp = pd.DataFrame({'seq_id': all_seq})\n",
        "    seq_indices = {}\n",
        "    for i, s in enumerate(df_tmp['seq_id']):\n",
        "        seq_indices.setdefault(s, []).append(i)\n",
        "    logits_seq = logits.copy()\n",
        "    for s, idxs in seq_indices.items():\n",
        "        m = logits[idxs].mean(axis=0, keepdims=True)\n",
        "        for i in idxs:\n",
        "            logits_seq[i] = m\n",
        "    f1_seq = macro_f1_from_logits_np(logits_seq, targets, K)\n",
        "    return float(f1_plain), float(f1_seq)\n",
        "\n",
        "def train_fold(fold=0, epochs=3, img_size=IMG_SIZE, bs=32, lr=3e-4, wd=1e-5):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f'Training fold {fold} for {epochs} epochs on {device}', flush=True)\n",
        "    dl_tr, dl_va, df_va = build_loaders(fold, bs=bs, nw=8)\n",
        "    model = timm.create_model('tf_efficientnet_b3_ns', pretrained=True, num_classes=K)\n",
        "    model = model.to(device).to(memory_format=torch.channels_last)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    num_steps = epochs * len(dl_tr)\n",
        "    warmup_steps = max(1, len(dl_tr))\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup_steps:\n",
        "            return float(step+1)/float(warmup_steps)\n",
        "        progress = (step - warmup_steps) / max(1, num_steps - warmup_steps)\n",
        "        return 0.5*(1.0 + math.cos(math.pi * progress))\n",
        "    sch = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda=lr_lambda)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor, label_smoothing=0.05)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
        "    best_f1 = -1.0\n",
        "    ckpt_dir = Path('checkpoints'); ckpt_dir.mkdir(exist_ok=True, parents=True)\n",
        "    t_start = time.time()\n",
        "    global_step = 0\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        t0 = time.time()\n",
        "        for it, (xb, yb, _seqs, _ids) in enumerate(dl_tr):\n",
        "            xb = xb.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=True):\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            sch.step()\n",
        "            epoch_loss += loss.item()\n",
        "            global_step += 1\n",
        "            if (it+1) % 100 == 0:\n",
        "                elapsed = time.time()-t0\n",
        "                print(f'Epoch {epoch} iter {it+1}/{len(dl_tr)} loss {epoch_loss/(it+1):.4f} elapsed {elapsed:.1f}s', flush=True)\n",
        "        # Eval\n",
        "        f1_plain, f1_seq = evaluate(model, dl_va, df_va, device, tta=True)\n",
        "        print(f'Epoch {epoch} done. TrainLoss {epoch_loss/len(dl_tr):.4f} | Val F1 {f1_plain:.4f} | Val F1 seq-avg {f1_seq:.4f} | elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "        if f1_seq > best_f1:\n",
        "            best_f1 = f1_seq\n",
        "            ckpt_path = ckpt_dir/f'b3_fold{fold}_best.pth'\n",
        "            torch.save({'model': model.state_dict(), 'f1_seq': best_f1, 'epoch': epoch}, ckpt_path)\n",
        "            print('Saved best checkpoint:', ckpt_path, flush=True)\n",
        "    print(f'Fold {fold} training complete. Best Val F1 seq-avg: {best_f1:.4f}. Total time {time.time()-t_start:.1f}s', flush=True)\n",
        "\n",
        "# Run smoke training on fold 0\n",
        "train_fold(fold=0, epochs=3, bs=32, lr=3e-4, wd=1e-5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fold 0 for 3 epochs on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 val class distribution (category_id top-10):\ncategory_id\n0     25727\n19     2137\n1      1226\n8      1208\n11     1175\n13     1047\n16      986\n17      810\n3       609\n18      357\nName: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b3_ns to current tf_efficientnet_b3.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_235/3706356251.py:158: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_235/3706356251.py:171: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=True):\n/app/.pip-target/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 100/4506 loss 3.9344 elapsed 11.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 200/4506 loss 3.6609 elapsed 23.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 300/4506 loss 3.3738 elapsed 34.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 400/4506 loss 3.1659 elapsed 45.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 500/4506 loss 3.0023 elapsed 56.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 600/4506 loss 2.8753 elapsed 67.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 700/4506 loss 2.7643 elapsed 79.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 800/4506 loss 2.6739 elapsed 90.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 900/4506 loss 2.5908 elapsed 101.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 1000/4506 loss 2.5219 elapsed 112.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 1100/4506 loss 2.4629 elapsed 123.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 1200/4506 loss 2.4095 elapsed 135.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 1300/4506 loss 2.3644 elapsed 146.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 1400/4506 loss 2.3208 elapsed 157.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 1500/4506 loss 2.2813 elapsed 168.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 1600/4506 loss 2.2460 elapsed 179.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 1700/4506 loss 2.2152 elapsed 191.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 1800/4506 loss 2.1841 elapsed 202.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 1900/4506 loss 2.1577 elapsed 213.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 2000/4506 loss 2.1326 elapsed 224.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 2100/4506 loss 2.1089 elapsed 236.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 2200/4506 loss 2.0865 elapsed 247.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 2300/4506 loss 2.0650 elapsed 258.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 2400/4506 loss 2.0442 elapsed 269.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 2500/4506 loss 2.0261 elapsed 280.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 2600/4506 loss 2.0089 elapsed 292.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 2700/4506 loss 1.9907 elapsed 303.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 2800/4506 loss 1.9745 elapsed 314.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 2900/4506 loss 1.9601 elapsed 325.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 3000/4506 loss 1.9467 elapsed 337.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 3100/4506 loss 1.9355 elapsed 348.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 3200/4506 loss 1.9228 elapsed 359.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 3300/4506 loss 1.9118 elapsed 371.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 3400/4506 loss 1.9012 elapsed 382.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 3500/4506 loss 1.8910 elapsed 393.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 3600/4506 loss 1.8822 elapsed 405.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 3700/4506 loss 1.8725 elapsed 416.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 3800/4506 loss 1.8627 elapsed 427.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 3900/4506 loss 1.8552 elapsed 438.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 4000/4506 loss 1.8484 elapsed 450.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 4100/4506 loss 1.8411 elapsed 461.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 4200/4506 loss 1.8341 elapsed 472.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 4300/4506 loss 1.8271 elapsed 483.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 4400/4506 loss 1.8199 elapsed 495.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 iter 4500/4506 loss 1.8131 elapsed 506.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 done. TrainLoss 1.8128 | Val F1 0.7811 | Val F1 seq-avg 0.7979 | elapsed 631.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved best checkpoint: checkpoints/b3_fold0_best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_235/3706356251.py:171: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=True):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 100/4506 loss 1.4339 elapsed 11.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 200/4506 loss 1.4325 elapsed 22.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 300/4506 loss 1.4274 elapsed 34.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 400/4506 loss 1.4386 elapsed 45.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 500/4506 loss 1.4383 elapsed 56.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 600/4506 loss 1.4406 elapsed 67.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 700/4506 loss 1.4388 elapsed 79.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 800/4506 loss 1.4409 elapsed 90.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 900/4506 loss 1.4459 elapsed 101.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 1000/4506 loss 1.4490 elapsed 112.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 1100/4506 loss 1.4476 elapsed 124.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 1200/4506 loss 1.4487 elapsed 135.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 1300/4506 loss 1.4446 elapsed 146.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 1400/4506 loss 1.4417 elapsed 158.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 1500/4506 loss 1.4428 elapsed 169.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 1600/4506 loss 1.4434 elapsed 180.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 1700/4506 loss 1.4418 elapsed 192.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 1800/4506 loss 1.4406 elapsed 203.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 1900/4506 loss 1.4388 elapsed 214.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 2000/4506 loss 1.4373 elapsed 225.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 2100/4506 loss 1.4376 elapsed 237.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 2200/4506 loss 1.4387 elapsed 248.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 2300/4506 loss 1.4376 elapsed 259.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 2400/4506 loss 1.4394 elapsed 270.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 2500/4506 loss 1.4389 elapsed 282.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 2600/4506 loss 1.4393 elapsed 293.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 2700/4506 loss 1.4396 elapsed 304.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 2800/4506 loss 1.4394 elapsed 316.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 2900/4506 loss 1.4392 elapsed 327.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 3000/4506 loss 1.4408 elapsed 338.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 3100/4506 loss 1.4412 elapsed 349.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 3200/4506 loss 1.4423 elapsed 361.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 3300/4506 loss 1.4427 elapsed 372.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 3400/4506 loss 1.4439 elapsed 383.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 3500/4506 loss 1.4440 elapsed 395.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 3600/4506 loss 1.4429 elapsed 406.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 iter 3700/4506 loss 1.4430 elapsed 417.6s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 195\u001b[39m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m training complete. Best Val F1 seq-avg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Total time \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()-t_start\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# Run smoke training on fold 0\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m \u001b[43mtrain_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 176\u001b[39m, in \u001b[36mtrain_fold\u001b[39m\u001b[34m(fold, epochs, img_size, bs, lr, wd)\u001b[39m\n\u001b[32m    174\u001b[39m scaler.scale(loss).backward()\n\u001b[32m    175\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[32m1.0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m scaler.update()\n\u001b[32m    178\u001b[39m sch.step()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/amp/grad_scaler.py:454\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    448\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    450\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    451\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    452\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/amp/grad_scaler.py:351\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/amp/grad_scaler.py:351\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    345\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    348\u001b[39m     **kwargs: Any,\n\u001b[32m    349\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    350\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    352\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    353\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "33d3acd5-d3b6-4a89-b106-7294f8202a80",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference: TTA + optional sequence averaging, generate submission.csv aligned to sample_submission Ids\n",
        "import os, json, math, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "\n",
        "DATA_DIR = Path('.')\n",
        "FAST_DIR = Path('./fast_storage/iwildcam')\n",
        "TEST_IMG_DIR = FAST_DIR/'test_images'\n",
        "assert TEST_IMG_DIR.exists(), 'Test images dir missing'\n",
        "\n",
        "# Load label maps from train\n",
        "train_df_map = pd.read_csv(DATA_DIR/'train.csv')\n",
        "classes = np.sort(train_df_map['category_id'].unique())\n",
        "class_to_idx = {int(c): i for i, c in enumerate(classes)}\n",
        "idx_to_class = {i: int(c) for i, c in enumerate(classes)}\n",
        "K = len(classes)\n",
        "\n",
        "# Load test and sample_submission to define required Id order\n",
        "test_df = pd.read_csv(DATA_DIR/'test.csv')\n",
        "has_seq = 'seq_id' in test_df.columns\n",
        "n_test = len(test_df)\n",
        "print('test.csv rows:', n_test, 'unique ids:', test_df['id'].nunique())\n",
        "sample_df = pd.read_csv(DATA_DIR/'sample_submission.csv')\n",
        "if sample_df.columns[0].startswith('Unnamed'):\n",
        "    sample_df = sample_df.drop(columns=[sample_df.columns[0]])\n",
        "assert set(['Id','Category']).issubset(sample_df.columns), 'sample_submission missing required columns'\n",
        "sample_ids = sample_df['Id'].astype(str).values\n",
        "print('sample_submission rows:', len(sample_ids))\n",
        "\n",
        "IMG_SIZE = 300\n",
        "VAL_SHORT = 336\n",
        "val_tfm = T.Compose([\n",
        "    T.Resize(VAL_SHORT, interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, tfm):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.tfm = tfm\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        fn = str(r['file_name']) if 'file_name' in r else str(r['id'])\n",
        "        p = self.img_dir/fn\n",
        "        if not p.exists():\n",
        "            p = self.img_dir/Path(fn).name\n",
        "        try:\n",
        "            img = Image.open(p).convert('RGB')\n",
        "        except Exception:\n",
        "            img = Image.new('RGB', (IMG_SIZE, IMG_SIZE), (0,0,0))\n",
        "        img = self.tfm(img)\n",
        "        sid = r['seq_id'] if 'seq_id' in r else None\n",
        "        iid = str(r['id']) if 'id' in r else Path(fn).stem\n",
        "        return img, sid, iid\n",
        "\n",
        "def infer_checkpoint(ckpt_path, bs=64, tta=True):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    ds = TestDataset(test_df, TEST_IMG_DIR, val_tfm)\n",
        "    dl = DataLoader(ds, batch_size=bs, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=True)\n",
        "    model = timm.create_model('tf_efficientnet_b3_ns', pretrained=False, num_classes=K)\n",
        "    state = torch.load(ckpt_path, map_location='cpu')\n",
        "    model.load_state_dict(state['model'] if isinstance(state, dict) and 'model' in state else state, strict=False)\n",
        "    model = model.to(device).to(memory_format=torch.channels_last)\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "    all_seqs = []\n",
        "    all_ids = []\n",
        "    with torch.no_grad():\n",
        "        for xb, seqs, ids in dl:\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            logits = model(xb)\n",
        "            if tta:\n",
        "                xb_flip = torch.flip(xb, dims=[3])\n",
        "                logits_flip = model(xb_flip)\n",
        "                logits = 0.5*(logits + logits_flip)\n",
        "            all_logits.append(logits.float().cpu())\n",
        "            all_seqs.extend(list(seqs))\n",
        "            all_ids.extend(list(ids))\n",
        "    logits = torch.cat(all_logits, 0).numpy()\n",
        "    return logits, np.array(all_seqs, dtype=object), np.array(all_ids, dtype=object)\n",
        "\n",
        "# Choose checkpoint\n",
        "ckpt1 = Path('checkpoints/b3_fold0_best.pth')\n",
        "if not ckpt1.exists():\n",
        "    alt = FAST_DIR/'b3_fold0_best.pth'\n",
        "    ckpt1 = alt if alt.exists() else ckpt1\n",
        "print('Using checkpoint:', ckpt1)\n",
        "\n",
        "logits, seqs, ids = infer_checkpoint(ckpt1, bs=64, tta=True)\n",
        "assert logits.shape[0] == len(test_df), f'logits rows {logits.shape[0]} != test rows {len(test_df)}'\n",
        "\n",
        "# Sequence-level averaging on test if seq_id present\n",
        "if has_seq:\n",
        "    df_tmp = pd.DataFrame({'seq_id': seqs})\n",
        "    seq_indices = {}\n",
        "    for i, s in enumerate(df_tmp['seq_id']):\n",
        "        seq_indices.setdefault(s, []).append(i)\n",
        "    logits_seq = logits.copy()\n",
        "    for s, idxs in seq_indices.items():\n",
        "        m = logits[idxs].mean(axis=0, keepdims=True)\n",
        "        for i in idxs:\n",
        "            logits_seq[i] = m\n",
        "    logits = logits_seq\n",
        "else:\n",
        "    print('seq_id not in test.csv; skipping sequence averaging')\n",
        "\n",
        "# Aggregate duplicate ids by mean logits\n",
        "df_pred = pd.DataFrame({'id': ids})\n",
        "for k in range(K):\n",
        "    df_pred[f'l{k}'] = logits[:, k]\n",
        "agg = df_pred.groupby('id', as_index=False).mean()\n",
        "print('Unique ids predicted:', len(agg))\n",
        "\n",
        "# Map predictions to sample_submission Id order; fallback to class 0 for missing ids\n",
        "logit_cols = [c for c in agg.columns if c.startswith('l')]\n",
        "id_to_vec = {iid: agg.loc[i, logit_cols].values for i, iid in enumerate(agg['id'].astype(str).values)}\n",
        "vec0 = np.zeros(K, dtype=np.float32); vec0[class_to_idx.get(0, 0)] = 1.0\n",
        "pred_idx_list = []\n",
        "miss = 0\n",
        "for iid in sample_ids:\n",
        "    v = id_to_vec.get(str(iid))\n",
        "    if v is None:\n",
        "        miss += 1\n",
        "        v = vec0\n",
        "    pred_idx_list.append(int(np.argmax(v)))\n",
        "print('Missing ids in predictions (filled with 0):', miss)\n",
        "pred_cat = [idx_to_class[i] for i in pred_idx_list]\n",
        "\n",
        "sub = pd.DataFrame({'Id': sample_ids, 'Category': pred_cat})\n",
        "assert list(sub.columns) == ['Id','Category'] and len(sub) == len(sample_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with shape', sub.shape, 'and columns', list(sub.columns))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test.csv rows: 16877 unique ids: 16862\nsample_submission rows: 16877\nUsing checkpoint: checkpoints/b3_fold0_best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name tf_efficientnet_b3_ns to current tf_efficientnet_b3.ns_jft_in1k.\n  model = create_fn(\n/tmp/ipykernel_235/978938898.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}