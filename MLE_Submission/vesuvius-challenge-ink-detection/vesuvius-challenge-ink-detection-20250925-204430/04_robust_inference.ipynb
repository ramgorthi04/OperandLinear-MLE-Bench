{
  "cells": [
    {
      "id": "5de48c15-148d-44aa-b865-d3c18ed142e8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 1. Setup and Imports ---\n",
        "\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "print(\"Assuming packages are pre-installed from previous notebooks. Skipping installation step.\")\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "from albumentations import ToTensorV2\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assuming packages are pre-installed from previous notebooks. Skipping installation step.\n"
          ]
        }
      ]
    },
    {
      "id": "3d310dcd-3dae-481e-bef2-3f6c26766d88",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 2. Configuration ---\n",
        "import os\n",
        "\n",
        "class CFG:\n",
        "    # General\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    # Data Paths\n",
        "    TEST_PATH = 'test'\n",
        "    VALID_PATH = 'train'\n",
        "    TEST_FRAGMENTS = sorted([d for d in os.listdir('test') if os.path.isdir(os.path.join('test', d))])\n",
        "    CALIBRATION_FRAGMENT_ID = '2' # Use fragment 2 from train set for calibration\n",
        "\n",
        "    # Data Reading (must match training)\n",
        "    Z_START = 20\n",
        "    Z_END = 44\n",
        "    IN_CHANS = (Z_END - Z_START) + 1\n",
        "\n",
        "    # Tiling (must match training)\n",
        "    TILE_SIZE = 256\n",
        "    STRIDE = TILE_SIZE // 2\n",
        "\n",
        "    # Model\n",
        "    BACKBONE = 'timm-efficientnet-b4'\n",
        "    MODEL_PATH = 'best_robust_model.pth' # Using the new robust model\n",
        "\n",
        "    # Inference Strategy\n",
        "    USE_TTA = True\n",
        "    USE_CALIBRATION = True\n",
        "    BATCH_SIZE = 16 # Can be adjusted based on memory\n",
        "    \n",
        "    # These will be dynamically set by the calibration step\n",
        "    BEST_THRESHOLD = 0.45\n",
        "    MIN_AREA_SIZE = 100\n",
        "\n",
        "print(f\"Device: {CFG.DEVICE}\")\n",
        "print(f\"Model Path: {CFG.MODEL_PATH}\")\n",
        "print(f\"Input Channels: {CFG.IN_CHANS}\")\n",
        "print(f\"Tile Size: {CFG.TILE_SIZE}\")\n",
        "print(f\"Stride for tiling: {CFG.STRIDE}\")\n",
        "print(f\"Discovered test fragments: {CFG.TEST_FRAGMENTS}\")\n",
        "print(f\"Calibration enabled: {CFG.USE_CALIBRATION} on fragment {CFG.CALIBRATION_FRAGMENT_ID}\")\n",
        "print(f\"TTA enabled: {CFG.USE_TTA}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\nModel Path: best_robust_model.pth\nInput Channels: 25\nTile Size: 256\nStride for tiling: 128\nDiscovered test fragments: ['a']\nCalibration enabled: True on fragment 2\nTTA enabled: True\n"
          ]
        }
      ]
    },
    {
      "id": "31731e19-33b6-4bf4-95b5-de2e6011f186",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 3. Advanced Helper Functions & Dataset ---\n",
        "\n",
        "def get_hann_window(size):\n",
        "    \"\"\"Creates a 2D Hanning window.\"\"\"\n",
        "    hann_1d = np.hanning(size)\n",
        "    hann_2d = np.outer(hann_1d, hann_1d)\n",
        "    return hann_2d\n",
        "\n",
        "def remove_small_components(mask, min_size):\n",
        "    \"\"\"Removes small connected components from a binary mask.\"\"\"\n",
        "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
        "    # Start from 1 to ignore the background label 0\n",
        "    for i in range(1, num_labels):\n",
        "        if stats[i, cv2.CC_STAT_AREA] < min_size:\n",
        "            mask[labels == i] = 0\n",
        "    return mask\n",
        "\n",
        "def rle_encode(mask):\n",
        "    \"\"\"Encodes a binary mask into Run-Length Encoding format (column-major).\"\"\"\n",
        "    # The competition requires column-major order, so we transpose the mask\n",
        "    pixels = mask.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def get_img_stack(fragment_id, z_start, z_end, data_path, simulate_ir_absence=False):\n",
        "    \"\"\"\n",
        "    Loads a stack of TIF images and the IR image for a given fragment.\n",
        "    Applies per-channel percentile normalization.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    \n",
        "    # Load TIF slices\n",
        "    for i in range(z_start, z_end):\n",
        "        image_path = os.path.join(data_path, fragment_id, 'surface_volume', f'{i:02}.tif')\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"TIF file not found or failed to read: {image_path}\")\n",
        "        images.append(image.astype(np.float32))\n",
        "\n",
        "    # Load IR image\n",
        "    ir_path = os.path.join(data_path, fragment_id, 'ir.png')\n",
        "    ir_image = cv2.imread(ir_path, cv2.IMREAD_UNCHANGED)\n",
        "    \n",
        "    # Handle missing or simulated-missing IR\n",
        "    if ir_image is None or simulate_ir_absence:\n",
        "        if ir_image is None:\n",
        "            print(f\"Warning: IR file not found at '{ir_path}'.\")\n",
        "        print(\"IR Fallback: Using mean of TIF slices as IR channel.\")\n",
        "        # EXPERT FIX: Keep dtype as float32 to avoid precision loss.\n",
        "        ir_image = np.mean(np.stack(images, axis=0), axis=0).astype(np.float32)\n",
        "    else:\n",
        "        ir_image = ir_image.astype(np.float32)\n",
        "\n",
        "    # Ensure IR image has the same dimensions as the TIF slices\n",
        "    if ir_image.shape != images[0].shape:\n",
        "        print(f\"Warning: IR image shape {ir_image.shape} differs from TIF shape {images[0].shape}. Resizing IR to match.\")\n",
        "        ir_image = cv2.resize(ir_image, (images[0].shape[1], images[0].shape[0]), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    images.append(ir_image)\n",
        "    \n",
        "    # Per-channel percentile normalization\n",
        "    normalized_images = []\n",
        "    for i, img in enumerate(images):\n",
        "        p1, p99 = np.percentile(img, [1, 99])\n",
        "        img_normalized = (img - p1) / (p99 - p1 + 1e-6)\n",
        "        img_normalized = np.clip(img_normalized, 0, 1)\n",
        "        normalized_images.append(img_normalized)\n",
        "        \n",
        "    return np.stack(normalized_images, axis=-1)\n",
        "\n",
        "class VesuviusTestDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for inference. Assumes images are already pre-processed and normalized.\n",
        "    \"\"\"\n",
        "    def __init__(self, tiles, fragment_images, tile_size):\n",
        "        self.tiles = tiles\n",
        "        self.fragment_images = fragment_images\n",
        "        self.tile_size = tile_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tiles)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        y, x = self.tiles[idx]\n",
        "        \n",
        "        # Get tile from the pre-loaded, pre-normalized fragment images\n",
        "        image_tile = self.fragment_images[y:y + self.tile_size, x:x + self.tile_size, :]\n",
        "        \n",
        "        # Transpose from HWC to CHW\n",
        "        image = np.transpose(image_tile, (2, 0, 1))\n",
        "        \n",
        "        return torch.from_numpy(image).float()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "id": "5fb8cfc1-5203-4b70-982c-bf7221518ad9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 4. Model Loading ---\n",
        "\n",
        "# Define the model architecture (must match training)\n",
        "model = smp.FPN(\n",
        "    encoder_name=CFG.BACKBONE,\n",
        "    encoder_weights=None,  # Weights will be loaded from file\n",
        "    in_channels=CFG.IN_CHANS,\n",
        "    classes=1,\n",
        "    activation=None,\n",
        ")\n",
        "\n",
        "# Load the trained weights\n",
        "model.load_state_dict(torch.load(CFG.MODEL_PATH))\n",
        "model.to(CFG.DEVICE)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded from {CFG.MODEL_PATH} and moved to {CFG.DEVICE}.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from best_robust_model.pth and moved to cuda.\n"
          ]
        }
      ]
    },
    {
      "id": "4c358afd-fde8-4233-a546-125a1cd66cb5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 5. TTA and Prediction Functions ---\n",
        "\n",
        "def tta_predict(model, image_batch):\n",
        "    \"\"\"Performs 8-way Test-Time Augmentation and returns averaged logits.\"\"\"\n",
        "    # EXPERT FIX: Avoid wasted forward pass by initializing tensor with known shape.\n",
        "    B, C, H, W = image_batch.shape\n",
        "    logits_tta = torch.zeros((B, 1, H, W), device=image_batch.device, dtype=image_batch.dtype)\n",
        "\n",
        "    # Original\n",
        "    logits_tta += model(image_batch)\n",
        "\n",
        "    # Horizontal Flip\n",
        "    logits_tta += torch.flip(model(torch.flip(image_batch, dims=[3])), dims=[3])\n",
        "\n",
        "    # Rotations (90, 180, 270) and their flips\n",
        "    for k in [1, 2, 3]:\n",
        "        img_rot = torch.rot90(image_batch, k, [2, 3])\n",
        "        # Rotated\n",
        "        logits_tta += torch.rot90(model(img_rot), -k, [2, 3])\n",
        "        # Rotated + Flipped\n",
        "        logits_tta += torch.flip(torch.rot90(model(torch.flip(img_rot, dims=[3])), -k, [2, 3]), dims=[3])\n",
        "\n",
        "    return logits_tta / 8.0\n",
        "\n",
        "def predict_fragment(model, fragment_images, roi_mask):\n",
        "    \"\"\"\n",
        "    Runs full-image inference on a fragment using overlapping tiles,\n",
        "    Hanning window blending, and optional TTA. Returns the final logit map.\n",
        "    \"\"\"\n",
        "    img_height, img_width, _ = fragment_images.shape\n",
        "    \n",
        "    # Canvases for blending\n",
        "    logit_canvas = np.zeros((img_height, img_width), dtype=np.float32)\n",
        "    weight_canvas = np.zeros((img_height, img_width), dtype=np.float32)\n",
        "    \n",
        "    # Hanning window for smooth blending\n",
        "    hann_window = get_hann_window(CFG.TILE_SIZE)\n",
        "    \n",
        "    # Generate tile coordinates with full coverage\n",
        "    tiles = []\n",
        "    for y in range(0, img_height, CFG.STRIDE):\n",
        "        for x in range(0, img_width, CFG.STRIDE):\n",
        "            y_start = min(y, img_height - CFG.TILE_SIZE)\n",
        "            x_start = min(x, img_width - CFG.TILE_SIZE)\n",
        "            # Only predict on tiles that have some overlap with the ROI\n",
        "            if (roi_mask[y_start:y_start+CFG.TILE_SIZE, x_start:x_start+CFG.TILE_SIZE] > 0).mean() > 0.1:\n",
        "                if (y_start, x_start) not in tiles:\n",
        "                    tiles.append((y_start, x_start))\n",
        "    \n",
        "    print(f\"Generated {len(tiles)} tiles for prediction.\")\n",
        "    \n",
        "    # Create dataset and dataloader\n",
        "    dataset = VesuviusTestDataset(tiles, fragment_images, CFG.TILE_SIZE)\n",
        "    dataloader = DataLoader(dataset, batch_size=CFG.BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    \n",
        "    # Inference loop\n",
        "    with torch.no_grad():\n",
        "        for i, images_batch in enumerate(tqdm(dataloader, desc=\"Predicting tiles\")):\n",
        "            images_batch = images_batch.to(CFG.DEVICE)\n",
        "            \n",
        "            if CFG.USE_TTA:\n",
        "                logits_batch = tta_predict(model, images_batch)\n",
        "            else:\n",
        "                logits_batch = model(images_batch)\n",
        "            \n",
        "            logits_batch = logits_batch.cpu().numpy()\n",
        "            \n",
        "            # Stitch logits back with Hanning blending\n",
        "            for j, (y, x) in enumerate(tiles[i*CFG.BATCH_SIZE : (i+1)*CFG.BATCH_SIZE]):\n",
        "                logit_canvas[y:y+CFG.TILE_SIZE, x:x+CFG.TILE_SIZE] += logits_batch[j, 0, :, :] * hann_window\n",
        "                weight_canvas[y:y+CFG.TILE_SIZE, x:x+CFG.TILE_SIZE] += hann_window\n",
        "    \n",
        "    # Normalize logits by weights\n",
        "    logit_canvas /= (weight_canvas + 1e-6)\n",
        "    \n",
        "    return logit_canvas"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "id": "c732bff1-2517-42e6-89f1-87778df31465",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 6. Calibration Step ---\n",
        "from scipy.ndimage import mean as ndimage_mean\n",
        "def fbeta_score(y_true, y_pred, beta=0.5):\n",
        "    \"\"\"Calculates the F-beta score.\"\"\"\n",
        "    tp = np.sum(y_true * y_pred)\n",
        "    fp = np.sum((1 - y_true) * y_pred)\n",
        "    fn = np.sum(y_true * (1 - y_pred))\n",
        "    \n",
        "    precision = tp / (tp + fp + 1e-6)\n",
        "    recall = tp / (tp + fn + 1e-6)\n",
        "    \n",
        "    fbeta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall + 1e-6)\n",
        "    return fbeta, precision, recall\n",
        "\n",
        "def calibrate_parameters(model):\n",
        "    \"\"\"\n",
        "    Calibrates the threshold and min_area_size on a validation fragment\n",
        "    by simulating test conditions (missing IR). Uses a highly optimized grid search.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Starting Parameter Calibration ---\")\n",
        "    fragment_id = CFG.CALIBRATION_FRAGMENT_ID\n",
        "    \n",
        "    # Load validation data\n",
        "    print(f\"Loading validation fragment {fragment_id} for calibration...\")\n",
        "    roi_mask = cv2.imread(os.path.join(CFG.VALID_PATH, fragment_id, 'mask.png'), cv2.IMREAD_GRAYSCALE)\n",
        "    gt_mask = cv2.imread(os.path.join(CFG.VALID_PATH, fragment_id, 'inklabels.png'), cv2.IMREAD_GRAYSCALE)\n",
        "    gt_mask = (gt_mask > 0).astype(np.uint8)\n",
        "    \n",
        "    # Load images and get full-fragment logit predictions\n",
        "    fragment_images = get_img_stack(fragment_id, CFG.Z_START, CFG.Z_END, data_path=CFG.VALID_PATH, simulate_ir_absence=True)\n",
        "    logit_map = predict_fragment(model, fragment_images, roi_mask)\n",
        "    prob_map = 1 / (1 + np.exp(-logit_map))\n",
        "    \n",
        "    # --- Highly Optimized Grid Search (Updated with Expert Advice) ---\n",
        "    print(\"Performing highly optimized grid search...\")\n",
        "    thresholds = np.arange(0.20, 0.80, 0.025)\n",
        "    min_areas = [64, 96, 128, 160, 196, 256, 300]\n",
        "    best_score = -1\n",
        "    best_params = (CFG.BEST_THRESHOLD, CFG.MIN_AREA_SIZE)\n",
        "\n",
        "    # 1. Find components ONCE at the lowest threshold\n",
        "    print(\"Step 1/3: Finding connected components...\")\n",
        "    pred_mask_base = (prob_map > thresholds.min()).astype(np.uint8)\n",
        "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(pred_mask_base, connectivity=8)\n",
        "    component_areas = stats[1:, cv2.CC_STAT_AREA]\n",
        "\n",
        "    # 2. Calculate average probability for each component ONCE (Vectorized)\n",
        "    print(\"Step 2/3: Calculating component probabilities...\")\n",
        "    component_probs = ndimage_mean(prob_map, labels=labels, index=np.arange(1, num_labels))\n",
        "\n",
        "    # 3. Fast grid search over pre-calculated properties\n",
        "    print(\"Step 3/3: Searching for best parameters...\")\n",
        "    gt_pixels_roi = gt_mask[roi_mask > 0]\n",
        "    for threshold in tqdm(thresholds, desc=\"Thresholds\"):\n",
        "        for min_area in min_areas:\n",
        "            passing_indices = np.where((component_probs > threshold) & (component_areas >= min_area))[0] + 1\n",
        "            pred_mask = np.isin(labels, passing_indices).astype(np.uint8)\n",
        "            pred_pixels_roi = pred_mask[roi_mask > 0]\n",
        "            score, _, _ = fbeta_score(gt_pixels_roi, pred_pixels_roi)\n",
        "            \n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_params = (threshold, min_area)\n",
        "\n",
        "    print(f\"Calibration complete. Best F0.5 score: {best_score:.4f}\")\n",
        "    print(f\"Best parameters found: Threshold={best_params[0]:.2f}, Min Area={best_params[1]}\")\n",
        "    \n",
        "    return best_params\n",
        "\n",
        "# Run calibration if enabled\n",
        "if CFG.USE_CALIBRATION:\n",
        "    best_threshold, best_min_area = calibrate_parameters(model)\n",
        "    CFG.BEST_THRESHOLD = best_threshold\n",
        "    CFG.MIN_AREA_SIZE = best_min_area\n",
        "else:\n",
        "    print(\"Skipping calibration. Using default parameters.\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "id": "ac92e7f7-5f48-4abe-b914-88a112bb9532",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 7. Final Inference and Submission ---\n",
        "\n",
        "print(\"\\n--- Starting Final Inference on Test Set ---\")\n",
        "print(f\"Using calibrated parameters: Threshold={CFG.BEST_THRESHOLD:.2f}, Min Area={CFG.MIN_AREA_SIZE}\")\n",
        "\n",
        "submission_data = []\n",
        "\n",
        "for fragment_id in CFG.TEST_FRAGMENTS:\n",
        "    print(f\"\\nProcessing fragment: {fragment_id}\")\n",
        "    \n",
        "    # Load data for the test fragment\n",
        "    print(\"Step 1/5: Loading images...\")\n",
        "    fragment_images = get_img_stack(fragment_id, CFG.Z_START, CFG.Z_END, data_path=CFG.TEST_PATH)\n",
        "    roi_mask = cv2.imread(os.path.join(CFG.TEST_PATH, fragment_id, 'mask.png'), cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "    # Get full fragment predictions\n",
        "    print(\"Step 2/5: Predicting logits...\")\n",
        "    logit_map = predict_fragment(model, fragment_images, roi_mask)\n",
        "    \n",
        "    # Convert to probabilities and apply threshold\n",
        "    print(\"Step 3/5: Applying threshold...\")\n",
        "    prob_map = 1 / (1 + np.exp(-logit_map))\n",
        "    pred_mask = (prob_map > CFG.BEST_THRESHOLD).astype(np.uint8)\n",
        "    \n",
        "    # Apply ROI mask\n",
        "    pred_mask *= (roi_mask > 0).astype(np.uint8)\n",
        "    \n",
        "    # Post-processing: remove small components\n",
        "    print(\"Step 4/5: Removing small components...\")\n",
        "    final_mask = remove_small_components(pred_mask, CFG.MIN_AREA_SIZE)\n",
        "    \n",
        "    # RLE encode for submission\n",
        "    print(\"Step 5/5: RLE encoding...\")\n",
        "    rle = rle_encode(final_mask)\n",
        "    submission_data.append({'Id': fragment_id, 'Predicted': rle})\n",
        "    \n",
        "    # Clean up memory\n",
        "    del fragment_images, roi_mask, logit_map, prob_map, pred_mask, final_mask\n",
        "    gc.collect()\n",
        "\n",
        "# Create and save submission file\n",
        "print(\"\\nCreating submission file...\")\n",
        "submission_df = pd.DataFrame(submission_data)\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"\\u2705 submission.csv created successfully!\")"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}