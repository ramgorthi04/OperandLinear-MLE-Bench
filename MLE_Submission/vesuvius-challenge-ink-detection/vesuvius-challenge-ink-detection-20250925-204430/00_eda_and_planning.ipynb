{
  "cells": [
    {
      "id": "acbf54a2-e6c4-4369-a939-709478fc1e7f",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vesuvius Challenge - Ink Detection: Medal-Winning Plan\n",
        "\n",
        "This notebook outlines a refined plan to tackle the Vesuvius Challenge, incorporating expert advice to target a medal-winning F0.5 score.\n",
        "\n",
        "## 1. Initial Setup & Focused EDA\n",
        "*   **Goal:** Quickly understand the data and set up the project structure.\n",
        "*   **Actions:**\n",
        "    1.  List file structure of `train/` and `test/` to confirm fragments.\n",
        "    2.  Load a sample fragment: `mask.png`, `ir.png`, and the `surface_volume/` TIFs.\n",
        "    3.  **Key EDA Task:** Plot ink presence (`mask.png`) against the z-slice index to identify the most informative slice range for our 2.5D model. This will determine which slices to stack.\n",
        "    4.  **ROI Definition:** The `mask.png` defines the Region of Interest (ROI). All training, validation, and inference will be strictly confined to this mask. We will crop images to the bounding box of the mask to save compute.\n",
        "    5.  Verify `sample_submission.csv` format.\n",
        "\n",
        "## 2. Data Pipeline (2.5D Approach)\n",
        "*   **Input Representation:** Treat the 3D volume as a multi-channel 2D image.\n",
        "    *   **Slices:** Stack `N=24` adjacent slices from the surface volume (e.g., from z-index `i-12` to `i+11`). The exact range will be informed by EDA.\n",
        "    *   **IR Channel:** Add the `ir.png` as an additional channel.\n",
        "    *   **Total Channels:** `24 (slices) + 1 (IR) = 25` input channels.\n",
        "*   **Tiling Strategy:**\n",
        "    *   **Tile Size:** `320x320` with 50% overlap for both training and inference.\n",
        "    *   **Sampling:** Create a custom PyTorch `Dataset` that generates tiles.\n",
        "        *   **ROI-Only:** Only sample tiles that are within the `mask.png` ROI.\n",
        "        *   **Balanced Sampling:** To combat class imbalance, sample ~50% of tiles that contain ink pixels and ~50% that do not (but are still within the ROI).\n",
        "*   **Normalization:**\n",
        "    *   **Per-Fragment:** Normalize each fragment independently. Do not use global statistics.\n",
        "    *   **Method:** Use robust percentile scaling. Clip values to the [1%, 99.5%] range, then scale to `[0, 1]`. Convert 16-bit TIFs to `float32`.\n",
        "*   **Augmentations:**\n",
        "    *   **Geometric:** Horizontal/Vertical flips, 90-degree rotations.\n",
        "    *   **Photometric (light):** Random brightness/contrast.\n",
        "\n",
        "## 3. Model & Training\n",
        "*   **Framework:** PyTorch with `segmentation-models-pytorch` (SMP).\n",
        "*   **Architecture:** `FPN` (Feature Pyramid Network) or `U-Net`.\n",
        "*   **Backbone:** `timm-tf_efficientnetv2_s` (recommended) or `timm-efficientnet-b4`.\n",
        "*   **Loss Function:** Start with a 50/50 combination of `BCEWithLogitsLoss` and `DiceLoss`. Consider upgrading to Focal Tversky loss for better F0.5 optimization.\n",
        "*   **Optimizer:** AdamW (e.g., `lr=3e-4`, `weight_decay=1e-4`).\n",
        "*   **Scheduler:** `CosineAnnealingLR` with a warmup phase.\n",
        "*   **Hardware Optimization:** Use Automatic Mixed Precision (AMP) to accelerate training and reduce memory usage.\n",
        "\n",
        "## 4. Validation Strategy\n",
        "*   **Method:** Leave-One-Fragment-Out Cross-Validation (3 folds). Train on two fragments, validate on the third.\n",
        "*   **Metric:** Calculate the F0.5 score on the validation set. **Crucially, the metric should only be computed on pixels within the validation fragment's ROI mask.**\n",
        "*   **Model Selection:** Use early stopping based on the validation F0.5 score, saving the checkpoint with the best performance.\n",
        "\n",
        "## 5. Inference & Post-processing\n",
        "*   **Tiling & Blending:** Perform inference on overlapping tiles (`320x320` or `512x512`) and stitch the predictions using a smooth blending function (e.g., Gaussian or cosine weights) to eliminate seam artifacts.\n",
        "*   **Test-Time Augmentation (TTA):** Apply flips (horizontal, vertical) for a 4x TTA. Average the resulting *logits* before applying the sigmoid function.\n",
        "*   **Z-Ensembling:** (Optional, if time permits) Predict on slightly shifted z-stacks (e.g., centered at `z-2`, `z`, `z+2`) and average the logits.\n",
        "*   **ROI Masking:** **Multiply the final probability map by the test fragment's `mask.png`** to zero out any predictions outside the valid area.\n",
        "*   **Thresholding:** **Tune the probability threshold per fragment.** Search for the optimal threshold (e.g., in the 0.35-0.75 range) on the validation set to maximize the F0.5 score.\n",
        "*   **Cleaning:** Apply post-processing to the binary mask. **Remove small connected components** (e.g., fewer than 20-100 pixels). Tune this size threshold on the validation set.\n",
        "\n",
        "## 6. Submission\n",
        "*   **Encoding:** Convert the final, cleaned binary masks into Run-Length Encoding (RLE) format.\n",
        "*   **Verification:** Double-check the RLE output against the `sample_submission.csv` format to ensure correctness (row-major order, `Id` format).\n",
        "*   **Ensembling:** For a final push, average the logits from the models trained on each of the 3 folds before post-processing."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a56882cd-4de2-427e-8ad8-1b56ab8c69cf",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "# The environment's !pip magic is broken. Using subprocess directly.\n",
        "command = [\n",
        "    sys.executable,\n",
        "    '-m', 'pip', 'install', '-q',\n",
        "    'opencv-python-headless',\n",
        "    'segmentation-models-pytorch',\n",
        "    'timm',\n",
        "    'albumentations'\n",
        "]\n",
        "\n",
        "result = subprocess.run(command, capture_output=True, text=True)\n",
        "\n",
        "if result.returncode == 0:\n",
        "    print(\"\u2705 Packages installed successfully.\")\n",
        "    # Manually invalidate import caches to ensure new packages are discoverable\n",
        "    importlib.invalidate_caches()\n",
        "else:\n",
        "    print(\"\u274c Package installation failed.\")\n",
        "    print(\"--- stdout ---\")\n",
        "    print(result.stdout)\n",
        "    print(\"--- stderr ---\")\n",
        "    print(result.stderr)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Packages installed successfully.\nError in callback <function _enable_matplotlib_integration.<locals>.configure_once at 0x7cc28c63b560> (for post_run_cell), with arguments args (<ExecutionResult object at 7cc282385710, execution_count=14 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7cc282420b10, raw_cell=\"import sys\nimport subprocess\nimport importlib\n\n# T..\" transformed_cell=\"import sys\nimport subprocess\nimport importlib\n\n# T..\" store_history=True silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'matplotlib' has no attribute 'backend_bases'",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/matplotlib_inline/backend_inline.py:222\u001b[39m, in \u001b[36m_enable_matplotlib_integration.<locals>.configure_once\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconfigure_once\u001b[39m(*args):\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[43mactivate_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m     configure_inline_support(ip, backend)\n\u001b[32m    224\u001b[39m     ip.events.unregister(\u001b[33m'\u001b[39m\u001b[33mpost_run_cell\u001b[39m\u001b[33m'\u001b[39m, configure_once)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:410\u001b[39m, in \u001b[36mactivate_matplotlib\u001b[39m\u001b[34m(backend)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# Due to circular imports, pyplot may be only partially initialised\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;66;03m# when this function runs.\u001b[39;00m\n\u001b[32m    407\u001b[39m \u001b[38;5;66;03m# So avoid needing matplotlib attribute-lookup to access pyplot.\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m plt.show._needmain = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# We need to detect at runtime whether show() is called by the user.\u001b[39;00m\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# For this, we wrap it into a decorator which adds a 'called' flag.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py:449\u001b[39m, in \u001b[36mswitch_backend\u001b[39m\u001b[34m(newbackend)\u001b[39m\n\u001b[32m    443\u001b[39m show = \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mshow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# In that classical approach, backends are implemented as modules, but\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;66;03m# \"inherit\" default method implementations from backend_bases._Backend.\u001b[39;00m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# This is achieved by creating a \"class\" that inherits from\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m# backend_bases._Backend and whose body is filled with the module globals.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbackend_mod\u001b[39;00m(\u001b[43mmatplotlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackend_bases\u001b[49m._Backend):\n\u001b[32m    450\u001b[39m     \u001b[38;5;28mlocals\u001b[39m().update(\u001b[38;5;28mvars\u001b[39m(module))\n\u001b[32m    452\u001b[39m \u001b[38;5;66;03m# However, the newer approach for defining new_figure_manager and\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# show is to derive them from canvas methods.  In that case, also\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# update backend_mod accordingly; also, per-backend customization of\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# draw_if_interactive is disabled.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/matplotlib/_api/__init__.py:218\u001b[39m, in \u001b[36mcaching_module_getattr.<locals>.__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name].\u001b[34m__get__\u001b[39m(instance)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    219\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mAttributeError\u001b[39m: module 'matplotlib' has no attribute 'backend_bases'"
          ]
        }
      ]
    },
    {
      "id": "adf6da0c-9921-4e45-91e9-1619cf1247b4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "# import matplotlib\n",
        "# matplotlib.use('Agg') # Commenting out to see if default backend works\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # Use standard tqdm\n",
        "\n",
        "# --- 1. Initial Setup & File Exploration ---\n",
        "\n",
        "TRAIN_PATH = 'train/'\n",
        "TEST_PATH = 'test/'\n",
        "\n",
        "train_fragments = sorted(os.listdir(TRAIN_PATH))\n",
        "test_fragments = sorted(os.listdir(TEST_PATH))\n",
        "\n",
        "print(f\"Training fragments: {train_fragments}\")\n",
        "print(f\"Test fragments: {test_fragments}\")\n",
        "\n",
        "# Let's inspect the first training fragment\n",
        "fragment_id = train_fragments[0]\n",
        "fragment_path = os.path.join(TRAIN_PATH, fragment_id)\n",
        "\n",
        "# Load mask (ink labels)\n",
        "mask_path = os.path.join(fragment_path, 'inklabels.png')\n",
        "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Load IR image\n",
        "ir_path = os.path.join(fragment_path, 'ir.png')\n",
        "ir_image = cv2.imread(ir_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Load surface volume slices (TIF files)\n",
        "surface_volume_path = os.path.join(fragment_path, 'surface_volume')\n",
        "slice_paths = sorted(glob.glob(os.path.join(surface_volume_path, '*.tif')))\n",
        "num_slices = len(slice_paths)\n",
        "\n",
        "print(f\"\\n--- Inspecting Fragment '{fragment_id}' --- \")\n",
        "print(f\"Mask shape: {mask.shape}, dtype: {mask.dtype}\")\n",
        "print(f\"IR image shape: {ir_image.shape}, dtype: {ir_image.dtype}\")\n",
        "print(f\"Number of slices in surface volume: {num_slices}\")\n",
        "\n",
        "# Load one slice to check its properties\n",
        "if num_slices > 0:\n",
        "    sample_slice = cv2.imread(slice_paths[0], cv2.IMREAD_UNCHANGED)\n",
        "    print(f\"Sample slice shape: {sample_slice.shape}, dtype: {sample_slice.dtype}\")\n",
        "    print(f\"Sample slice value range: [{np.min(sample_slice)}, {np.max(sample_slice)}]\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training fragments: ['1', '2']\nTest fragments: ['a']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n--- Inspecting Fragment '1' --- \nMask shape: (8181, 6330), dtype: uint8\nIR image shape: (8181, 6330), dtype: uint8\nNumber of slices in surface volume: 65\nSample slice shape: (8181, 6330), dtype: uint16\nSample slice value range: [0, 65535]\nError in callback <function _enable_matplotlib_integration.<locals>.configure_once at 0x7cc28c63b560> (for post_run_cell), with arguments args (<ExecutionResult object at 7cc277507e90, execution_count=15 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7cc28c571410, raw_cell=\"import os\nimport glob\nimport numpy as np\nimport pa..\" transformed_cell=\"import os\nimport glob\nimport numpy as np\nimport pa..\" store_history=True silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'matplotlib' has no attribute 'backend_bases'",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/matplotlib_inline/backend_inline.py:222\u001b[39m, in \u001b[36m_enable_matplotlib_integration.<locals>.configure_once\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconfigure_once\u001b[39m(*args):\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[43mactivate_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m     configure_inline_support(ip, backend)\n\u001b[32m    224\u001b[39m     ip.events.unregister(\u001b[33m'\u001b[39m\u001b[33mpost_run_cell\u001b[39m\u001b[33m'\u001b[39m, configure_once)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:410\u001b[39m, in \u001b[36mactivate_matplotlib\u001b[39m\u001b[34m(backend)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# Due to circular imports, pyplot may be only partially initialised\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;66;03m# when this function runs.\u001b[39;00m\n\u001b[32m    407\u001b[39m \u001b[38;5;66;03m# So avoid needing matplotlib attribute-lookup to access pyplot.\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m plt.show._needmain = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# We need to detect at runtime whether show() is called by the user.\u001b[39;00m\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# For this, we wrap it into a decorator which adds a 'called' flag.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py:449\u001b[39m, in \u001b[36mswitch_backend\u001b[39m\u001b[34m(newbackend)\u001b[39m\n\u001b[32m    443\u001b[39m show = \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mshow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# In that classical approach, backends are implemented as modules, but\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;66;03m# \"inherit\" default method implementations from backend_bases._Backend.\u001b[39;00m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# This is achieved by creating a \"class\" that inherits from\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m# backend_bases._Backend and whose body is filled with the module globals.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbackend_mod\u001b[39;00m(\u001b[43mmatplotlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackend_bases\u001b[49m._Backend):\n\u001b[32m    450\u001b[39m     \u001b[38;5;28mlocals\u001b[39m().update(\u001b[38;5;28mvars\u001b[39m(module))\n\u001b[32m    452\u001b[39m \u001b[38;5;66;03m# However, the newer approach for defining new_figure_manager and\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# show is to derive them from canvas methods.  In that case, also\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# update backend_mod accordingly; also, per-backend customization of\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# draw_if_interactive is disabled.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/matplotlib/_api/__init__.py:218\u001b[39m, in \u001b[36mcaching_module_getattr.<locals>.__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name].\u001b[34m__get__\u001b[39m(instance)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    219\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mAttributeError\u001b[39m: module 'matplotlib' has no attribute 'backend_bases'"
          ]
        }
      ]
    },
    {
      "id": "0935f448-3663-4ba2-a7c9-4c1d5e4c8887",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 2. EDA: Find Informative Z-Slice Range (Calculation Only) ---\n",
        "\n",
        "print(\"Starting EDA to find informative z-slice range...\")\n",
        "\n",
        "# The matplotlib installation is corrupted, but the data loading in the previous cell worked.\n",
        "# We will proceed with the calculations and print the results, but comment out the plotting.\n",
        "\n",
        "# Convert mask to boolean and find where the ink is\n",
        "ink_mask = mask > 0\n",
        "ink_pixels_count = np.sum(ink_mask)\n",
        "\n",
        "if ink_pixels_count == 0:\n",
        "    print(f\"Warning: No ink pixels found in the mask for fragment {fragment_id}.\")\n",
        "else:\n",
        "    print(f\"Found {ink_pixels_count} ink pixels in fragment {fragment_id}.\")\n",
        "    mean_ink_intensities = []\n",
        "    \n",
        "    for slice_path in tqdm(slice_paths, desc=f\"Analyzing slices for fragment {fragment_id}\"):\n",
        "        slice_img = cv2.imread(slice_path, cv2.IMREAD_UNCHANGED)\n",
        "        ink_intensity = slice_img[ink_mask].mean()\n",
        "        mean_ink_intensities.append(ink_intensity)\n",
        "\n",
        "    # --- Plotting is disabled due to environment errors ---\n",
        "    # plt.figure(figsize=(15, 7))\n",
        "    # plt.plot(range(num_slices), mean_ink_intensities, marker='o', linestyle='-')\n",
        "    # plt.title(f'Mean Intensity under Ink Mask vs. Z-Slice Index (Fragment {fragment_id})')\n",
        "    # plt.xlabel('Slice Index (Z-depth)')\n",
        "    # plt.ylabel('Mean Pixel Intensity')\n",
        "    # plt.grid(True)\n",
        "\n",
        "    best_slice_idx = np.argmax(mean_ink_intensities)\n",
        "    z_center = num_slices // 2\n",
        "    z_start = z_center - 12\n",
        "    z_end = z_center + 12\n",
        "    \n",
        "    print(\"\\n--- EDA Results ---\")\n",
        "    print(f\"Total slices available: {num_slices}\")\n",
        "    print(f\"Slice with highest intensity under mask: {best_slice_idx}\")\n",
        "    print(f\"Default centered slice range for 24 slices: {z_start} to {z_end-1}\")\n",
        "    print(\"Based on this, the middle slices seem to be a good starting point as per the plan.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting EDA to find informative z-slice range...\nFound 5339362 ink pixels in fragment 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:   0%|          | 0/65 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:   3%|\u258e         | 2/65 [00:00<00:03, 16.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:   6%|\u258c         | 4/65 [00:00<00:03, 16.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:   9%|\u2589         | 6/65 [00:00<00:03, 16.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  12%|\u2588\u258f        | 8/65 [00:00<00:03, 16.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  15%|\u2588\u258c        | 10/65 [00:00<00:03, 16.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  18%|\u2588\u258a        | 12/65 [00:00<00:03, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  22%|\u2588\u2588\u258f       | 14/65 [00:00<00:03, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  25%|\u2588\u2588\u258d       | 16/65 [00:00<00:02, 16.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  28%|\u2588\u2588\u258a       | 18/65 [00:01<00:02, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  31%|\u2588\u2588\u2588       | 20/65 [00:01<00:02, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  34%|\u2588\u2588\u2588\u258d      | 22/65 [00:01<00:02, 16.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  37%|\u2588\u2588\u2588\u258b      | 24/65 [00:01<00:02, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  40%|\u2588\u2588\u2588\u2588      | 26/65 [00:01<00:02, 16.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  43%|\u2588\u2588\u2588\u2588\u258e     | 28/65 [00:01<00:02, 16.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  46%|\u2588\u2588\u2588\u2588\u258c     | 30/65 [00:01<00:02, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  49%|\u2588\u2588\u2588\u2588\u2589     | 32/65 [00:01<00:02, 16.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 34/65 [00:02<00:01, 16.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 36/65 [00:02<00:01, 16.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 38/65 [00:02<00:01, 16.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 40/65 [00:02<00:01, 16.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 42/65 [00:02<00:01, 16.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 44/65 [00:02<00:01, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 46/65 [00:02<00:01, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 48/65 [00:02<00:01, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 50/65 [00:03<00:00, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 52/65 [00:03<00:00, 16.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 54/65 [00:03<00:00, 16.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 56/65 [00:03<00:00, 16.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 58/65 [00:03<00:00, 16.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 60/65 [00:03<00:00, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 62/65 [00:03<00:00, 16.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 64/65 [00:03<00:00, 16.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rAnalyzing slices for fragment 1: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 65/65 [00:03<00:00, 16.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n--- EDA Results ---\nTotal slices available: 65\nSlice with highest intensity under mask: 28\nDefault centered slice range for 24 slices: 20 to 43\nBased on this, the middle slices seem to be a good starting point as per the plan.\nError in callback <function _enable_matplotlib_integration.<locals>.configure_once at 0x7cc28c63b560> (for post_run_cell), with arguments args (<ExecutionResult object at 7cc28c265d90, execution_count=16 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7cc28c266f90, raw_cell=\"# --- 2. EDA: Find Informative Z-Slice Range (Calc..\" transformed_cell=\"# --- 2. EDA: Find Informative Z-Slice Range (Calc..\" store_history=True silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'matplotlib' has no attribute 'backend_bases'",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/matplotlib_inline/backend_inline.py:222\u001b[39m, in \u001b[36m_enable_matplotlib_integration.<locals>.configure_once\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconfigure_once\u001b[39m(*args):\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[43mactivate_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m     configure_inline_support(ip, backend)\n\u001b[32m    224\u001b[39m     ip.events.unregister(\u001b[33m'\u001b[39m\u001b[33mpost_run_cell\u001b[39m\u001b[33m'\u001b[39m, configure_once)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:410\u001b[39m, in \u001b[36mactivate_matplotlib\u001b[39m\u001b[34m(backend)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;66;03m# Due to circular imports, pyplot may be only partially initialised\u001b[39;00m\n\u001b[32m    406\u001b[39m \u001b[38;5;66;03m# when this function runs.\u001b[39;00m\n\u001b[32m    407\u001b[39m \u001b[38;5;66;03m# So avoid needing matplotlib attribute-lookup to access pyplot.\u001b[39;00m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m plt.show._needmain = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# We need to detect at runtime whether show() is called by the user.\u001b[39;00m\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# For this, we wrap it into a decorator which adds a 'called' flag.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py:449\u001b[39m, in \u001b[36mswitch_backend\u001b[39m\u001b[34m(newbackend)\u001b[39m\n\u001b[32m    443\u001b[39m show = \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mshow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# In that classical approach, backends are implemented as modules, but\u001b[39;00m\n\u001b[32m    446\u001b[39m \u001b[38;5;66;03m# \"inherit\" default method implementations from backend_bases._Backend.\u001b[39;00m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# This is achieved by creating a \"class\" that inherits from\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[38;5;66;03m# backend_bases._Backend and whose body is filled with the module globals.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbackend_mod\u001b[39;00m(\u001b[43mmatplotlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackend_bases\u001b[49m._Backend):\n\u001b[32m    450\u001b[39m     \u001b[38;5;28mlocals\u001b[39m().update(\u001b[38;5;28mvars\u001b[39m(module))\n\u001b[32m    452\u001b[39m \u001b[38;5;66;03m# However, the newer approach for defining new_figure_manager and\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# show is to derive them from canvas methods.  In that case, also\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# update backend_mod accordingly; also, per-backend customization of\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# draw_if_interactive is disabled.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/matplotlib/_api/__init__.py:218\u001b[39m, in \u001b[36mcaching_module_getattr.<locals>.__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m props:\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m props[name].\u001b[34m__get__\u001b[39m(instance)\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    219\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mAttributeError\u001b[39m: module 'matplotlib' has no attribute 'backend_bases'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}