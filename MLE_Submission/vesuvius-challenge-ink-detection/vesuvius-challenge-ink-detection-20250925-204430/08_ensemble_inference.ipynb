{
  "cells": [
    {
      "id": "046d9911-e6ae-411d-9633-5d6f1f915509",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 1. Setup and Configuration ---\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class CFG:\n",
        "    # General\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    \n",
        "    # Data\n",
        "    TEST_FRAGMENTS = ['a', 'b', 'c']\n",
        "    VAL_FRAGMENT_ID = 2 # For calibration\n",
        "    \n",
        "    # Slices - Load a wide range to accommodate both models\n",
        "    Z_START = 16 \n",
        "    Z_END = 48\n",
        "    \n",
        "    # Tiling\n",
        "    TILE_SIZE = 256\n",
        "    STRIDE = TILE_SIZE // 2\n",
        "\n",
        "    # Models\n",
        "    # The robust model uses b4, the new model uses b0. We need to handle this.\n",
        "    ENCODER_NAME_ROBUST = 'efficientnet-b4'\n",
        "    ENCODER_NAME_TIF_V2 = 'efficientnet-b0'\n",
        "    MODEL_ROBUST_PATH = 'best_robust_model.pth'\n",
        "    MODEL_TIF_V2_PATH = 'best_tif_only_model_v4_b0.pth' # From 07_training\n",
        "    \n",
        "    # Model-specific input channels\n",
        "    IN_CHANNELS_ROBUST = 32 # Trained on Z-range 16-48\n",
        "    IN_CHANNELS_TIF_V2 = 25 # Trained on Z-range 20-45\n",
        "    \n",
        "    # Ensemble\n",
        "    ENSEMBLE_WEIGHTS = [0.4, 0.6] # [robust, tif_v2]\n",
        "    USE_TTA = True\n",
        "    \n",
        "    # Post-processing (to be calibrated)\n",
        "    THRESHOLD = 0.4\n",
        "    MIN_AREA = 100\n",
        "\n",
        "print(f\"Device: {CFG.DEVICE}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "id": "ed06edae-851f-4838-8580-0c3534aaabc9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 2. Model and Data Loading ---\n",
        "\n",
        "def load_model(model_path, in_channels, encoder_name):\n",
        "    \"\"\"Loads a segmentation model from a state dict.\"\"\"\n",
        "    model = smp.Unet(\n",
        "        encoder_name=encoder_name,\n",
        "        encoder_weights=None,  # Weights are loaded from file\n",
        "        in_channels=in_channels,\n",
        "        classes=1,\n",
        "        activation=None,\n",
        "    )\n",
        "    model.load_state_dict(torch.load(model_path, map_location=CFG.DEVICE))\n",
        "    model.to(CFG.DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def get_img_stack(fragment_id, is_test=True):\n",
        "    \"\"\"Reads a stack of TIF images for a given fragment.\"\"\"\n",
        "    images = []\n",
        "    \n",
        "    data_folder = 'test' if is_test else 'train'\n",
        "    fragment_path = f\"{data_folder}/{fragment_id}/surface_volume\"\n",
        "    \n",
        "    for i in range(CFG.Z_START, CFG.Z_END):\n",
        "        image_path = os.path.join(fragment_path, f'{i:02}.tif')\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "            \n",
        "        # Normalize slice\n",
        "        p_low, p_high = np.percentile(image, [1, 99])\n",
        "        image = np.clip((image.astype(np.float32) - p_low) / (p_high - p_low + 1e-6), 0, 1)\n",
        "        images.append(image)\n",
        "        \n",
        "    return np.stack(images, axis=-1)\n",
        "\n",
        "def rle_encode(mask):\n",
        "    \"\"\"Encodes a binary mask into Run-Length Encoding format.\"\"\"\n",
        "    pixels = mask.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "# Define TTA transforms\n",
        "def get_tta_transforms():\n",
        "    \"\"\"Returns a list of augmentation functions for TTA.\"\"\"\n",
        "    return [\n",
        "        A.Compose([ToTensorV2(transpose_mask=True)]),\n",
        "        A.Compose([A.HorizontalFlip(p=1.0), ToTensorV2(transpose_mask=True)]),\n",
        "        A.Compose([A.VerticalFlip(p=1.0), ToTensorV2(transpose_mask=True)]),\n",
        "        A.Compose([A.RandomRotate90(p=1.0), ToTensorV2(transpose_mask=True)]),\n",
        "    ]\n",
        "\n",
        "# Inverse TTA transforms\n",
        "def get_inverse_tta_transforms():\n",
        "    \"\"\"Returns a list of inverse functions for TTA predictions.\"\"\"\n",
        "    return [\n",
        "        lambda x: x, # Original\n",
        "        lambda x: torch.flip(x, dims=[-1]), # HorizontalFlip\n",
        "        lambda x: torch.flip(x, dims=[-2]), # VerticalFlip\n",
        "        lambda x: torch.rot90(x, k=-1, dims=[-2, -1]), # RandomRotate90\n",
        "    ]\n",
        "\n",
        "print(\"Helper functions and TTA defined.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions and TTA defined.\n"
          ]
        }
      ]
    },
    {
      "id": "1f809a0c-9587-45bf-9421-4dd7badf8e12",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 3. Main Inference Loop ---\n",
        "\n",
        "def predict_fragment(fragment_id, model_robust, model_tif_v2, is_test=True):\n",
        "    \"\"\"Runs tiled inference on a single fragment and returns the predicted mask.\"\"\"\n",
        "    print(f\"\\nProcessing fragment {fragment_id}...\")\n",
        "    \n",
        "    # Load data\n",
        "    images = get_img_stack(fragment_id, is_test=is_test)\n",
        "    height, width, _ = images.shape\n",
        "    \n",
        "    # Create prediction and normalization arrays\n",
        "    pred_mask = np.zeros((height, width), dtype=np.float32)\n",
        "    norm_mask = np.zeros((height, width), dtype=np.float32)\n",
        "    \n",
        "    # Get TTA transforms\n",
        "    tta_transforms = get_tta_transforms() if CFG.USE_TTA else [get_tta_transforms()[0]]\n",
        "    inverse_tta_transforms = get_inverse_tta_transforms() if CFG.USE_TTA else [get_inverse_tta_transforms()[0]]\n",
        "\n",
        "    # Tiled inference\n",
        "    for y in tqdm(range(0, height - CFG.TILE_SIZE + 1, CFG.STRIDE), desc=f\"Inferring on {fragment_id}\"):\n",
        "        for x in range(0, width - CFG.TILE_SIZE + 1, CFG.STRIDE):\n",
        "            tile = images[y:y+CFG.TILE_SIZE, x:x+CFG.TILE_SIZE, :]\n",
        "            \n",
        "            ensembled_preds = torch.zeros((1, 1, CFG.TILE_SIZE, CFG.TILE_SIZE), device=CFG.DEVICE)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                # TTA loop\n",
        "                for transform, inv_transform in zip(tta_transforms, inverse_tta_transforms):\n",
        "                    # --- Prepare inputs for each model ---\n",
        "                    # Robust model input (Z: 16-48 -> 32 channels)\n",
        "                    tile_robust = transform(image=tile)['image'].unsqueeze(0).to(CFG.DEVICE)\n",
        "                    \n",
        "                    # TIF v2 model input (Z: 20-45 -> 25 channels)\n",
        "                    # The full stack is 16-48. We need 20-45. This corresponds to indices 4 to 4+25=29.\n",
        "                    tile_tif_v2_np = tile[:, :, 4:29]\n",
        "                    tile_tif_v2 = transform(image=tile_tif_v2_np)['image'].unsqueeze(0).to(CFG.DEVICE)\n",
        "\n",
        "                    # --- Get predictions ---\n",
        "                    pred_robust = model_robust(tile_robust)\n",
        "                    pred_tif_v2 = model_tif_v2(tile_tif_v2)\n",
        "                    \n",
        "                    # Inverse TTA\n",
        "                    pred_robust = inv_transform(pred_robust)\n",
        "                    pred_tif_v2 = inv_transform(pred_tif_v2)\n",
        "                    \n",
        "                    # --- Ensemble (averaging sigmoid outputs) ---\n",
        "                    ensembled_pred = (CFG.ENSEMBLE_WEIGHTS[0] * torch.sigmoid(pred_robust) + \n",
        "                                      CFG.ENSEMBLE_WEIGHTS[1] * torch.sigmoid(pred_tif_v2))\n",
        "                    \n",
        "                    ensembled_preds += ensembled_pred\n",
        "\n",
        "            # Average TTA predictions\n",
        "            avg_preds = ensembled_preds / len(tta_transforms)\n",
        "            \n",
        "            # Add to full mask\n",
        "            pred_mask[y:y+CFG.TILE_SIZE, x:x+CFG.TILE_SIZE] += avg_preds.squeeze().cpu().numpy()\n",
        "            norm_mask[y:y+CFG.TILE_SIZE, x:x+CFG.TILE_SIZE] += 1\n",
        "\n",
        "    # Normalize overlapping predictions\n",
        "    pred_mask /= (norm_mask + 1e-6)\n",
        "    \n",
        "    return pred_mask\n",
        "\n",
        "def main():\n",
        "    # Load models\n",
        "    print(\"Loading models...\")\n",
        "    model_robust = load_model(CFG.MODEL_ROBUST_PATH, CFG.IN_CHANNELS_ROBUST, CFG.ENCODER_NAME_ROBUST)\n",
        "    model_tif_v2 = load_model(CFG.MODEL_TIF_V2_PATH, CFG.IN_CHANNELS_TIF_V2, CFG.ENCODER_NAME_TIF_V2)\n",
        "    print(\"Models loaded.\")\n",
        "\n",
        "    results = []\n",
        "    for fragment_id in CFG.TEST_FRAGMENTS:\n",
        "        # Predict\n",
        "        pred_mask = predict_fragment(fragment_id, model_robust, model_tif_v2, is_test=True)\n",
        "        \n",
        "        # Post-process\n",
        "        binary_mask = (pred_mask > CFG.THRESHOLD).astype(np.uint8)\n",
        "        \n",
        "        # Remove small components\n",
        "        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary_mask, connectivity=8)\n",
        "        for i in range(1, num_labels):\n",
        "            if stats[i, cv2.CC_STAT_AREA] < CFG.MIN_AREA:\n",
        "                binary_mask[labels == i] = 0\n",
        "        \n",
        "        # Apply original ROI mask from test set\n",
        "        roi_mask = cv2.imread(f\"test/{fragment_id}/mask.png\", cv2.IMREAD_GRAYSCALE) > 0\n",
        "        final_mask = binary_mask * roi_mask\n",
        "        \n",
        "        # RLE encode\n",
        "        rle = rle_encode(final_mask)\n",
        "        results.append({'Id': fragment_id, 'Predicted': rle})\n",
        "\n",
        "    # Create submission file\n",
        "    submission_df = pd.DataFrame(results)\n",
        "    submission_df.to_csv('submission.csv', index=False)\n",
        "    print(\"\\nSubmission file created: submission.csv\")\n",
        "\n",
        "# Note: This notebook will be run once the training in 07 is complete and the model is saved.\n",
        "# To run, uncomment the line below.\n",
        "# main()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "id": "47f91ffa-ff85-4d13-a30d-f48d7de31d7a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 4. Calibration on Validation Set ---\n",
        "\n",
        "def fbeta_score(y_true, y_pred, beta=0.5):\n",
        "    \"\"\"Calculates the F-beta score.\"\"\"\n",
        "    tp = (y_true * y_pred).sum()\n",
        "    fp = ((1 - y_true) * y_pred).sum()\n",
        "    fn = (y_true * (1 - y_pred)).sum()\n",
        "\n",
        "    precision = tp / (tp + fp + 1e-6)\n",
        "    recall = tp / (tp + fn + 1e-6)\n",
        "    \n",
        "    fbeta = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall + 1e-6)\n",
        "    return fbeta\n",
        "\n",
        "def calibrate_params(model_robust, model_tif_v2):\n",
        "    \"\"\"Finds the best threshold and min_area on the validation fragment.\"\"\"\n",
        "    print(\"\\n--- Starting Calibration on Fragment 2 ---\")\n",
        "    \n",
        "    # Predict on validation fragment (is_test=False)\n",
        "    pred_mask_val = predict_fragment(CFG.VAL_FRAGMENT_ID, model_robust, model_tif_v2, is_test=False)\n",
        "    \n",
        "    # Load ground truth mask\n",
        "    gt_mask = cv2.imread(f\"train/{CFG.VAL_FRAGMENT_ID}/inklabels.png\", cv2.IMREAD_GRAYSCALE) / 255\n",
        "    gt_mask = gt_mask.astype(np.uint8)\n",
        "    \n",
        "    # Define search space\n",
        "    thresholds = np.arange(0.2, 0.7, 0.05)\n",
        "    min_areas = [25, 50, 75, 100, 125, 150]\n",
        "    \n",
        "    best_score = 0\n",
        "    best_threshold = 0\n",
        "    best_min_area = 0\n",
        "\n",
        "    for threshold in tqdm(thresholds, desc=\"Calibrating Thresholds\"):\n",
        "        for min_area in min_areas:\n",
        "            binary_mask = (pred_mask_val > threshold).astype(np.uint8)\n",
        "            \n",
        "            # Remove small components\n",
        "            num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary_mask, connectivity=8)\n",
        "            processed_mask = binary_mask.copy()\n",
        "            for i in range(1, num_labels):\n",
        "                if stats[i, cv2.CC_STAT_AREA] < min_area:\n",
        "                    processed_mask[labels == i] = 0\n",
        "            \n",
        "            score = fbeta_score(gt_mask, processed_mask)\n",
        "            \n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_threshold = threshold\n",
        "                best_min_area = min_area\n",
        "                print(f\"New best score: {best_score:.4f} at T={best_threshold:.2f}, A={best_min_area}\")\n",
        "\n",
        "    print(f\"\\n--- Calibration Complete ---\")\n",
        "    print(f\"Best F0.5 Score: {best_score:.4f}\")\n",
        "    print(f\"Optimal Threshold: {best_threshold:.2f}\")\n",
        "    print(f\"Optimal Min Area: {best_min_area}\")\n",
        "    \n",
        "    # Update CFG with optimal values\n",
        "    CFG.THRESHOLD = best_threshold\n",
        "    CFG.MIN_AREA = best_min_area\n",
        "\n",
        "# To run calibration, load models and then call this function.\n",
        "# Note: This requires 'best_tif_only_model_v3_b0.pth' to exist.\n",
        "# model_r = load_model(CFG.MODEL_ROBUST_PATH, CFG.IN_CHANNELS_ROBUST, CFG.ENCODER_NAME_ROBUST)\n",
        "# model_t = load_model(CFG.MODEL_TIF_V2_PATH, CFG.IN_CHANNELS_TIF_V2, CFG.ENCODER_NAME_TIF_V2)\n",
        "# calibrate_params(model_r, model_t)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "id": "5f443505-4558-4c4d-9cd9-9aa629bd1dcc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 5. Run Calibration ---\n",
        "print(\"Loading models for calibration...\")\n",
        "model_r = load_model(CFG.MODEL_ROBUST_PATH, CFG.IN_CHANNELS_ROBUST, CFG.ENCODER_NAME_ROBUST)\n",
        "model_t = load_model(CFG.MODEL_TIF_V2_PATH, CFG.IN_CHANNELS_TIF_V2, CFG.ENCODER_NAME_TIF_V2)\n",
        "print(\"Models loaded.\")\n",
        "\n",
        "calibrate_params(model_r, model_t)\n",
        "\n",
        "# Clean up memory\n",
        "del model_r, model_t\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\nCFG updated with calibrated parameters:\")\n",
        "print(f\"CFG.THRESHOLD = {CFG.THRESHOLD}\")\n",
        "print(f\"CFG.MIN_AREA = {CFG.MIN_AREA}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "86e55517-8b5c-4684-a39f-9c8a468275a0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 6. Run Final Inference & Generate Submission ---\n",
        "print(\"\\nStarting final inference on test fragments...\")\n",
        "main()\n",
        "print(\"\\nInference complete. submission.csv is ready.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}