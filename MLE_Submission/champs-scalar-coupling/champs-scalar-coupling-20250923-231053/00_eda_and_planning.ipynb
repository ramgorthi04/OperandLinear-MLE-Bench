{
  "cells": [
    {
      "id": "11278ee2-1083-4c8a-829e-199df7ba0986",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CHAMPS Scalar Coupling \u2013 Plan\n",
        "\n",
        "Objectives:\n",
        "- Establish reliable CV and baseline fast\n",
        "- Build strong feature pipeline from provided data (structures, tensors, charges, potential_energy, dipoles)\n",
        "- Train fast GPU models (CatBoost/XGBoost) per coupling type and blend\n",
        "- Target: medal-tier LogMAE (competition metric: mean over coupling types of log(MAE_type)) and track per-type OOF\n",
        "\n",
        "Initial Steps:\n",
        "1) Environment sanity: GPU availability (nvidia-smi), versions\n",
        "2) Data audit: load train/test; row counts; columns; NA; target profile; coupling_type distribution; per-type stats\n",
        "3) CV: GroupKFold by molecule_name; stratify by type; lock seed; cache folds\n",
        "4) Baseline features v0:\n",
        "   - From train/test: distance between the two atoms (from structures), atom types (one-hot/emb), mulliken charges (sum/diff), shielding isotropic (sum/diff), potential_energy, dipole norms\n",
        "   - Simple geometric: interatomic distance, d^2, 1/d, 1/d^2, 1/d^3; optional log(d)\n",
        "   - Graph basics from structures: is_bonded via covalent radii threshold, shortest_path_len, degrees, ring flag\n",
        "   - Per molecule context (counts, element counts) computed fold-safely\n",
        "5) Models:\n",
        "   - Fast screen: XGBoost GPU per type; 5 folds; early stopping\n",
        "   - Compare CatBoost GPU; per-type models typically win here\n",
        "6) Iteration:\n",
        "   - Add angles (cos) via nearest neighbors; then dihedrals/Karplus for 3J types\n",
        "   - Error buckets by type and distance/path bins\n",
        "7) Ensembling:\n",
        "   - Weighted blend XGB + CatBoost by per-type OOF\n",
        "\n",
        "Risks & Checks:\n",
        "- Leakage: fit transforms within folds; compute molecule-level aggs inside folds\n",
        "- Do NOT use scalar_coupling_contributions (FC/SD/PSO/DSO) as features (train-only). Safe: mulliken, shielding, potential_energy, dipoles.\n",
        "- CV must group by molecule_name; ensure all types present per fold\n",
        "- Cache heavy joins (parquet); subsample dev runs\n",
        "\n",
        "Milestones (request expert review at each):\n",
        "A) Plan + env check\n",
        "B) Data audit + CV finalized\n",
        "C) Baseline FE v0 + XGB OOF\n",
        "D) FE v1 (angles/dihedrals) + CatBoost\n",
        "E) Blend + submission\n",
        "\n",
        "Next: run environment check and quick data peek."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "aaab9843-5b6a-42d7-a462-284091c88022",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment check + quick data peek\n",
        "import os, sys, subprocess, time, json, gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "t0 = time.time()\n",
        "print('Running nvidia-smi...')\n",
        "try:\n",
        "    out = subprocess.run(['bash','-lc','nvidia-smi || true'], capture_output=True, text=True, check=False)\n",
        "    print(out.stdout)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi failed:', e)\n",
        "\n",
        "print('Python', sys.version)\n",
        "print('Pandas', pd.__version__)\n",
        "print('NumPy', np.__version__)\n",
        "\n",
        "DATA_FILES = ['train.csv','test.csv']\n",
        "for f in DATA_FILES:\n",
        "    print(f, 'exists:', os.path.exists(f), 'size(MB):', round(os.path.getsize(f)/1e6,2) if os.path.exists(f) else None)\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "def mem(df):\n",
        "    return round(df.memory_usage(deep=True).sum()/1e6, 2)\n",
        "\n",
        "# Load train/test (quick peek)\n",
        "print('\\nLoading train/test...')\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "print('train shape:', train.shape, 'mem(MB):', mem(train))\n",
        "print('test  shape:', test.shape,  'mem(MB):', mem(test))\n",
        "\n",
        "print('\\nTrain head:')\n",
        "print(train.head(3))\n",
        "print('\\nCoupling types (train):')\n",
        "print(train['type'].value_counts())\n",
        "\n",
        "print('\\nTarget summary:')\n",
        "print(train['scalar_coupling_constant'].describe())\n",
        "\n",
        "elapsed = time.time() - t0\n",
        "print(f'Env + data peek done in {elapsed:.2f}s', flush=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running nvidia-smi...\nTue Sep 23 23:19:52 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\nPython 3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]\nPandas 2.2.2\nNumPy 1.26.4\ntrain.csv exists: True size(MB): 189.64\ntest.csv exists: True size(MB): 16.3\n\nLoading train/test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape: (4191263, 6) mem(MB): 695.75\ntest  shape: (467813, 5) mem(MB): 73.91\n\nTrain head:\n        id     molecule_name  atom_index_0  atom_index_1  type  \\\n0  3872080  dsgdb9nsd_109986             9             0  1JHC   \n1  3872081  dsgdb9nsd_109986             9             2  3JHC   \n2  3872082  dsgdb9nsd_109986             9            10  2JHH   \n\n   scalar_coupling_constant  \n0                  95.47000  \n1                   1.47412  \n2                  -9.90448  \n\nCoupling types (train):\ntype\n3JHC    1359077\n2JHC    1026379\n1JHC     637912\n3JHH     531224\n2JHH     340097\n3JHN     150067\n2JHN     107091\n1JHN      39416\nName: count, dtype: int64\n\nTarget summary:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    4.191263e+06\nmean     1.591607e+01\nstd      3.493526e+01\nmin     -4.476050e+01\n25%     -2.563940e-01\n50%      2.280420e+00\n75%      7.391740e+00\nmax      2.077090e+02\nName: scalar_coupling_constant, dtype: float64\nEnv + data peek done in 2.64s\n"
          ]
        }
      ]
    },
    {
      "id": "f0fb301b-785c-4cba-99f6-94112759be21",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build and cache GroupKFold (stratified by predominant type if available)\n",
        "import pandas as pd, numpy as np, time, os, sys\n",
        "from collections import Counter\n",
        "t0 = time.time()\n",
        "print('Loading minimal columns for CV...')\n",
        "use_cols = ['molecule_name','type']\n",
        "df = pd.read_csv('train.csv', usecols=use_cols)\n",
        "print('Rows:', len(df), 'Molecules:', df['molecule_name'].nunique())\n",
        "\n",
        "# Derive a single stratification label per molecule: predominant type\n",
        "print('Computing predominant type per molecule...')\n",
        "type_idx = df.groupby('molecule_name')['type'].agg(lambda s: s.value_counts().idxmax()).rename('strat_label')\n",
        "mol_df = type_idx.reset_index()\n",
        "\n",
        "FOLDS = 5\n",
        "seed = 42\n",
        "mol_names = mol_df['molecule_name'].values\n",
        "strat_labels = mol_df['strat_label'].values\n",
        "\n",
        "folds = np.full(len(mol_df), -1, dtype=int)\n",
        "assigned = 0\n",
        "try:\n",
        "    from sklearn.model_selection import StratifiedGroupKFold\n",
        "    print('Using StratifiedGroupKFold...')\n",
        "    sgkf = StratifiedGroupKFold(n_splits=FOLDS, shuffle=True, random_state=seed)\n",
        "    for k, (_, val_idx) in enumerate(sgkf.split(np.zeros(len(mol_df)), strat_labels, groups=mol_names)):\n",
        "        folds[val_idx] = k\n",
        "        print(f'Fold {k}: molecules {len(val_idx)}')\n",
        "        assigned += len(val_idx)\n",
        "except Exception as e:\n",
        "    print('StratifiedGroupKFold unavailable, falling back to GroupKFold. Reason:', e)\n",
        "    from sklearn.model_selection import GroupKFold\n",
        "    gkf = GroupKFold(n_splits=FOLDS)\n",
        "    for k, (_, val_idx) in enumerate(gkf.split(np.zeros(len(mol_df)), groups=mol_names)):\n",
        "        folds[val_idx] = k\n",
        "        print(f'Fold {k}: molecules {len(val_idx)}')\n",
        "        assigned += len(val_idx)\n",
        "\n",
        "assert (folds >= 0).all(), 'Unassigned folds present'\n",
        "mol_df['fold'] = folds\n",
        "\n",
        "# Save molecule-level folds mapping\n",
        "fold_path = 'folds_molecules.csv'\n",
        "mol_df[['molecule_name','fold']].to_csv(fold_path, index=False)\n",
        "print('Saved', fold_path, 'with shape', mol_df.shape)\n",
        "\n",
        "# Diagnostics: per-fold type distribution\n",
        "df = df.merge(mol_df[['molecule_name','fold']], on='molecule_name', how='left')\n",
        "print('Per-fold type counts:')\n",
        "cnt = df.groupby(['fold','type']).size().unstack(fill_value=0)\n",
        "print(cnt)\n",
        "\n",
        "# Quick logMAE metric helper (OOF later) placeholder\n",
        "def log_mae_by_type(y_true, y_pred, types):\n",
        "    out = []\n",
        "    for t in np.unique(types):\n",
        "        mask = (types == t)\n",
        "        mae = np.mean(np.abs(y_true[mask] - y_pred[mask]))\n",
        "        out.append(np.log(mae + 1e-9))\n",
        "    return float(np.mean(out))\n",
        "\n",
        "print(f'Fold build done in {time.time()-t0:.2f}s', flush=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading minimal columns for CV...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 4191263 Molecules: 76510\nComputing predominant type per molecule...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using StratifiedGroupKFold...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: molecules 15302\nFold 1: molecules 15301\nFold 2: molecules 15302\nFold 3: molecules 15302\nFold 4: molecules 15303\nSaved folds_molecules.csv with shape (76510, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per-fold type counts:\ntype    1JHC  1JHN    2JHC   2JHH   2JHN    3JHC    3JHH   3JHN\nfold                                                           \n0     127506  7909  205166  68000  21339  271802  106072  29674\n1     127794  7857  205413  68236  21313  272225  106385  29972\n2     127603  7843  205146  68029  21505  271866  106131  29880\n3     127552  7914  205316  67979  21483  271724  106219  30304\n4     127457  7893  205338  67853  21451  271460  106417  30237\nFold build done in 26.16s\n"
          ]
        }
      ]
    },
    {
      "id": "b4b0c88b-40f9-47f3-9307-d5792911aee8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build and cache atoms table (structures + periodic props)\n",
        "import pandas as pd, numpy as np, time, os, gc\n",
        "\n",
        "t0 = time.time()\n",
        "atoms_parquet = 'atoms.parquet'\n",
        "if os.path.exists(atoms_parquet):\n",
        "    atoms = pd.read_parquet(atoms_parquet)\n",
        "    print('Loaded cached', atoms_parquet, 'shape:', atoms.shape)\n",
        "else:\n",
        "    print('Reading structures.csv ...')\n",
        "    atoms = pd.read_csv('structures.csv')  # columns: molecule_name, atom_index, atom, x, y, z\n",
        "    print('structures shape:', atoms.shape)\n",
        "\n",
        "    # Periodic table props for CHAMPS atoms (H, C, N, O, F)\n",
        "    periodic = {\n",
        "        'H': {'Z':1,  'EN':2.20, 'covrad':0.31, 'period':1, 'group':1,  'valence_e':1},\n",
        "        'C': {'Z':6,  'EN':2.55, 'covrad':0.76, 'period':2, 'group':14, 'valence_e':4},\n",
        "        'N': {'Z':7,  'EN':3.04, 'covrad':0.71, 'period':2, 'group':15, 'valence_e':5},\n",
        "        'O': {'Z':8,  'EN':3.44, 'covrad':0.66, 'period':2, 'group':16, 'valence_e':6},\n",
        "        'F': {'Z':9,  'EN':3.98, 'covrad':0.57, 'period':2, 'group':17, 'valence_e':7},\n",
        "    }\n",
        "    pmap = pd.DataFrame.from_dict(periodic, orient='index')\n",
        "    pmap.index.name = 'atom'\n",
        "    pmap = pmap.reset_index()\n",
        "    atoms = atoms.merge(pmap, on='atom', how='left')\n",
        "\n",
        "    # Dtypes/downcast\n",
        "    atoms['atom_index'] = atoms['atom_index'].astype(np.int32)\n",
        "    for c in ['x','y','z','EN','covrad']:\n",
        "        atoms[c] = atoms[c].astype(np.float32)\n",
        "    for c in ['Z','period','group','valence_e']:\n",
        "        atoms[c] = atoms[c].astype(np.int16)\n",
        "\n",
        "    # Save cache\n",
        "    atoms.to_parquet(atoms_parquet, index=False)\n",
        "    print('Saved', atoms_parquet, 'shape:', atoms.shape)\n",
        "\n",
        "print('Unique molecules in atoms:', atoms['molecule_name'].nunique())\n",
        "print('Atom symbols:', atoms['atom'].value_counts().to_dict())\n",
        "print(f'Atoms table ready in {time.time()-t0:.2f}s', flush=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading structures.csv ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "structures shape: (1379964, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved atoms.parquet shape: (1379964, 12)\nUnique molecules in atoms: 76510\nAtom symbols: {'H': 707001, 'C': 486817, 'O': 107091, 'N': 77209, 'F': 1846}\nAtoms table ready in 1.09s\n"
          ]
        }
      ]
    },
    {
      "id": "ea76422e-7518-4400-a1b9-dd94d4c3a159",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Baseline submission: per-type median prediction\n",
        "import pandas as pd, numpy as np, time, os\n",
        "t0 = time.time()\n",
        "train = pd.read_csv('train.csv', usecols=['type','scalar_coupling_constant'])\n",
        "test = pd.read_csv('test.csv', usecols=['id','type'])\n",
        "med = train.groupby('type')['scalar_coupling_constant'].median().to_dict()\n",
        "print('Per-type medians:', med)\n",
        "pred = test['type'].map(med).astype(np.float32)\n",
        "sub = pd.DataFrame({'id': test['id'].values, 'scalar_coupling_constant': pred.values})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv shape:', sub.shape, 'size(MB):', round(os.path.getsize('submission.csv')/1e6, 2))\n",
        "print(sub.head())\n",
        "print(f'Baseline submission ready in {time.time()-t0:.2f}s')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Per-type medians: {'1JHC': 88.20235, '1JHN': 47.869299999999996, '2JHC': -0.953401, '2JHH': -11.3289, '2JHN': 2.0169900000000003, '3JHC': 2.87845, '3JHH': 3.687980000000001, '3JHN': 0.6542279999999999}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv shape: (467813, 2) size(MB): 7.73\n        id  scalar_coupling_constant\n0  2324604                 88.202347\n1  2324605                 -0.953401\n2  2324606                  2.878450\n3  2324607                  2.878450\n4  2324608                -11.328900\nBaseline submission ready in 1.31s\n"
          ]
        }
      ]
    },
    {
      "id": "a0661280-c933-4119-a178-268274afce50",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# FE v0: geometry + periodic + molecule context; cache train/test feature tables\n",
        "import pandas as pd, numpy as np, time, os, gc\n",
        "\n",
        "t0 = time.time()\n",
        "print('Loading base tables...')\n",
        "atoms = pd.read_parquet('atoms.parquet')\n",
        "folds = pd.read_csv('folds_molecules.csv')\n",
        "train_cols = ['id','molecule_name','atom_index_0','atom_index_1','type','scalar_coupling_constant']\n",
        "test_cols  = ['id','molecule_name','atom_index_0','atom_index_1','type']\n",
        "train_df = pd.read_csv('train.csv', usecols=train_cols)\n",
        "test_df  = pd.read_csv('test.csv',  usecols=test_cols)\n",
        "print('train_df:', train_df.shape, 'test_df:', test_df.shape)\n",
        "\n",
        "# Molecule-level safe tables\n",
        "pot = pd.read_csv('potential_energy.csv')  # molecule_name, potential_energy\n",
        "dip = pd.read_csv('dipole_moments.csv')    # molecule_name, components\n",
        "# Normalize dipole column names to dx,dy,dz\n",
        "dip_cols = set(dip.columns.str.lower())\n",
        "if {'dx','dy','dz'}.issubset(dip_cols):\n",
        "    # already correct or mixed case\n",
        "    rename_map = {c: c.lower() for c in dip.columns if c.lower() in {'dx','dy','dz'}}\n",
        "    dip = dip.rename(columns=rename_map)\n",
        "elif {'x','y','z'}.issubset(dip_cols):\n",
        "    # common Kaggle file has X,Y,Z\n",
        "    rename_map = {}\n",
        "    for c in dip.columns:\n",
        "        cl = c.lower()\n",
        "        if cl == 'x': rename_map[c] = 'dx'\n",
        "        if cl == 'y': rename_map[c] = 'dy'\n",
        "        if cl == 'z': rename_map[c] = 'dz'\n",
        "    dip = dip.rename(columns=rename_map)\n",
        "else:\n",
        "    print('Warning: unexpected dipole_moments columns:', dip.columns.tolist())\n",
        "dip['dip_norm'] = np.sqrt(dip['dx']**2 + dip['dy']**2 + dip['dz']**2).astype(np.float32)\n",
        "mol_ctx = pot.merge(dip, on='molecule_name', how='left')\n",
        "\n",
        "def build_features(df, is_train: bool):\n",
        "    t1 = time.time()\n",
        "    # Merge atom0 and atom1 records\n",
        "    a0 = atoms.rename(columns={\n",
        "        'atom_index':'atom_index_0','atom':'atom_0','x':'x0','y':'y0','z':'z0','Z':'Z0','EN':'EN0','covrad':'covrad0','period':'period0','group':'group0','valence_e':'valence_e0'\n",
        "    })\n",
        "    a1 = atoms.rename(columns={\n",
        "        'atom_index':'atom_index_1','atom':'atom_1','x':'x1','y':'y1','z':'z1','Z':'Z1','EN':'EN1','covrad':'covrad1','period':'period1','group':'group1','valence_e':'valence_e1'\n",
        "    })\n",
        "    df = df.merge(a0, on=['molecule_name','atom_index_0'], how='left')\n",
        "    df = df.merge(a1, on=['molecule_name','atom_index_1'], how='left')\n",
        "    # Molecule context\n",
        "    df = df.merge(mol_ctx, on='molecule_name', how='left')\n",
        "    # Geometry\n",
        "    dx = (df['x0'].values - df['x1'].values).astype(np.float32)\n",
        "    dy = (df['y0'].values - df['y1'].values).astype(np.float32)\n",
        "    dz = (df['z0'].values - df['z1'].values).astype(np.float32)\n",
        "    d2 = dx*dx + dy*dy + dz*dz\n",
        "    dist = np.sqrt(d2) + 1e-6\n",
        "    df['dist'] = dist.astype(np.float32)\n",
        "    df['dist2'] = d2.astype(np.float32)\n",
        "    df['inv_dist']  = (1.0/dist).astype(np.float32)\n",
        "    df['inv_d2']    = (1.0/d2.clip(min=1e-6)).astype(np.float32)\n",
        "    df['inv_d3']    = (1.0/(dist*dist*dist)).astype(np.float32)\n",
        "    # Atom identity & periodic props\n",
        "    df['same_element'] = (df['atom_0'].values == df['atom_1'].values).astype(np.int8)\n",
        "    for a in ['Z','EN','covrad','valence_e','period','group']:\n",
        "        a0c, a1c = f'{a}0', f'{a}1'\n",
        "        df[f'{a}_sum']  = (df[a0c].values + df[a1c].values).astype(np.float32)\n",
        "        df[f'{a}_diff'] = (df[a0c].values - df[a1c].values).astype(np.float32)\n",
        "        if a in ('EN','covrad','Z'):\n",
        "            df[f'{a}_ratio'] = (df[a0c].values / (df[a1c].replace(0, np.nan))).astype(np.float32)\n",
        "            df[f'{a}_ratio'] = df[f'{a}_ratio'].replace([np.inf, -np.inf], np.nan).fillna(0).astype(np.float32)\n",
        "    # Dipole and potential energy\n",
        "    for c in ['potential_energy','dx','dy','dz','dip_norm']:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(np.float32)\n",
        "    # Minimal categorical encodings for atom symbols (handle unknowns safely)\n",
        "    sym_map = {'H':0,'C':1,'N':2,'O':3,'F':4}\n",
        "    df['sym0'] = df['atom_0'].map(sym_map).fillna(-1).astype(np.int8)\n",
        "    df['sym1'] = df['atom_1'].map(sym_map).fillna(-1).astype(np.int8)\n",
        "    # Keep only needed columns\n",
        "    base_cols = [\n",
        "        'id','type','molecule_name','dist','dist2','inv_dist','inv_d2','inv_d3','same_element','sym0','sym1',\n",
        "        'Z0','Z1','EN0','EN1','covrad0','covrad1','valence_e0','valence_e1','period0','period1','group0','group1',\n",
        "        'Z_sum','Z_diff','EN_sum','EN_diff','EN_ratio','covrad_sum','covrad_diff','covrad_ratio','valence_e_sum','valence_e_diff','period_sum','period_diff','group_sum','group_diff',\n",
        "        'potential_energy','dx','dy','dz','dip_norm'\n",
        "    ]\n",
        "    cols_exist = [c for c in base_cols if c in df.columns]\n",
        "    out = df[cols_exist].copy()\n",
        "    if is_train:\n",
        "        out = out.merge(folds, on='molecule_name', how='left')\n",
        "    del df; gc.collect()\n",
        "    print('Built features in', f'{time.time()-t1:.2f}s', 'shape:', out.shape)\n",
        "    return out\n",
        "\n",
        "Xtr = build_features(train_df, is_train=True)\n",
        "ytr = pd.DataFrame({'id': train_df['id'].values, 'scalar_coupling_constant': train_df['scalar_coupling_constant'].values, 'type': train_df['type'].values})\n",
        "Xte = build_features(test_df, is_train=False)\n",
        "\n",
        "# Downcast numerics\n",
        "def downcast_numeric(df):\n",
        "    for c in df.select_dtypes(include=['float64']).columns:\n",
        "        df[c] = df[c].astype(np.float32)\n",
        "    for c in df.select_dtypes(include=['int64']).columns:\n",
        "        if c == 'id':\n",
        "            df[c] = df[c].astype(np.int32)\n",
        "        else:\n",
        "            df[c] = df[c].astype(np.int32)\n",
        "    return df\n",
        "\n",
        "Xtr = downcast_numeric(Xtr)\n",
        "Xte = downcast_numeric(Xte)\n",
        "\n",
        "# Save caches\n",
        "Xtr_path = 'X_train_v0.parquet'; Xte_path = 'X_test_v0.parquet'; y_path = 'y_train.csv'\n",
        "Xtr.to_parquet(Xtr_path, index=False)\n",
        "Xte.to_parquet(Xte_path, index=False)\n",
        "ytr.to_csv(y_path, index=False)\n",
        "print('Saved:', Xtr_path, Xtr.shape, '|', Xte_path, Xte.shape, '|', y_path, ytr.shape)\n",
        "print(f'FE v0 total time: {time.time()-t0:.2f}s', flush=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base tables...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df: (4191263, 6) test_df: (467813, 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built features in 3.23s shape: (4191263, 43)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built features in 0.60s shape: (467813, 42)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: X_train_v0.parquet (4191263, 43) | X_test_v0.parquet (467813, 42) | y_train.csv (4191263, 3)\nFE v0 total time: 10.78s\n"
          ]
        }
      ]
    },
    {
      "id": "a7d34503-4a9f-4274-ac4c-62401e425ec0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# FE v1: add mulliken + shielding iso + quick extras + covalent graph features; cache v1\n",
        "import pandas as pd, numpy as np, time, os, gc\n",
        "from collections import deque, defaultdict\n",
        "\n",
        "t0 = time.time()\n",
        "print('Loading base inputs...')\n",
        "atoms = pd.read_parquet('atoms.parquet')  # has periodic props, coords\n",
        "folds = pd.read_csv('folds_molecules.csv')\n",
        "train = pd.read_csv('train.csv', usecols=['id','molecule_name','atom_index_0','atom_index_1','type','scalar_coupling_constant'])\n",
        "test  = pd.read_csv('test.csv',  usecols=['id','molecule_name','atom_index_0','atom_index_1','type'])\n",
        "\n",
        "# Molecule-level safe tables\n",
        "pot = pd.read_csv('potential_energy.csv')\n",
        "dip = pd.read_csv('dipole_moments.csv')\n",
        "dip_cols = set(dip.columns.str.lower())\n",
        "if {'dx','dy','dz'}.issubset(dip_cols):\n",
        "    dip = dip.rename(columns={c: c.lower() for c in dip.columns if c.lower() in {'dx','dy','dz'}})\n",
        "elif {'x','y','z'}.issubset(dip_cols):\n",
        "    r = {};\n",
        "    [r.setdefault(c, {'x':'dx','y':'dy','z':'dz'}[c.lower()]) for c in dip.columns if c.lower() in {'x','y','z'}]\n",
        "    dip = dip.rename(columns=r)\n",
        "dip['dip_norm'] = np.sqrt(dip['dx']**2 + dip['dy']**2 + dip['dz']**2).astype(np.float32)\n",
        "mol_ctx = pot.merge(dip, on='molecule_name', how='left')\n",
        "\n",
        "# Quantum per-atom tables (safe for test)\n",
        "print('Loading mulliken and shielding...')\n",
        "mull = pd.read_csv('mulliken_charges.csv')        # molecule_name, atom_index, mulliken_charge\n",
        "shield = pd.read_csv('magnetic_shielding_tensors.csv')  # molecule_name, atom_index, diag terms\n",
        "# Normalize shield column names to robustly find diagonal terms\n",
        "shield.columns = [str(c).lower() for c in shield.columns]\n",
        "def find_col(sdf, suffix):\n",
        "    for c in sdf.columns:\n",
        "        cl = str(c).lower()\n",
        "        if cl == suffix or cl.endswith('_'+suffix):\n",
        "            return c\n",
        "    return None\n",
        "c_xx = find_col(shield, 'xx')\n",
        "c_yy = find_col(shield, 'yy')\n",
        "c_zz = find_col(shield, 'zz')\n",
        "if c_xx is None or c_yy is None or c_zz is None:\n",
        "    raise KeyError(f'Diagonal shielding columns not found. Available: {shield.columns.tolist()}')\n",
        "shield['shield_iso'] = ((shield[c_xx] + shield[c_yy] + shield[c_zz]) / 3.0).astype(np.float32)\n",
        "mull['mulliken_charge'] = mull['mulliken_charge'].astype(np.float32)\n",
        "shield = shield[['molecule_name','atom_index','shield_iso']]\n",
        "atom_q = mull.merge(shield, on=['molecule_name','atom_index'], how='left')\n",
        "\n",
        "# Molecule atom counts (n_atoms, n_H, n_heavy)\n",
        "mol_counts = atoms.groupby('molecule_name').agg(\n",
        "    n_atoms=('atom_index','count'),\n",
        "    n_H=('atom', lambda s: (s=='H').sum()),\n",
        "    n_heavy=('atom', lambda s: (s!='H').sum()),\n",
        ").reset_index()\n",
        "\n",
        "sym_map = {'H':0,'C':1,'N':2,'O':3,'F':4}\n",
        "\n",
        "def build_pair_frame(df, is_train: bool):\n",
        "    t1 = time.time()\n",
        "    # Prepare atom tables for merge with per-atom quantum props\n",
        "    a = atoms.merge(atom_q, on=['molecule_name','atom_index'], how='left')\n",
        "    a0 = a.rename(columns={'atom_index':'atom_index_0','atom':'atom_0','x':'x0','y':'y0','z':'z0','Z':'Z0','EN':'EN0','covrad':'covrad0','period':'period0','group':'group0','valence_e':'valence_e0','mulliken_charge':'q0','shield_iso':'shield0'})\n",
        "    a1 = a.rename(columns={'atom_index':'atom_index_1','atom':'atom_1','x':'x1','y':'y1','z':'z1','Z':'Z1','EN':'EN1','covrad':'covrad1','period':'period1','group':'group1','valence_e':'valence_e1','mulliken_charge':'q1','shield_iso':'shield1'})\n",
        "    out = df.merge(a0, on=['molecule_name','atom_index_0'], how='left')\n",
        "    out = out.merge(a1, on=['molecule_name','atom_index_1'], how='left')\n",
        "    out = out.merge(mol_ctx, on='molecule_name', how='left')\n",
        "    out = out.merge(mol_counts, on='molecule_name', how='left')\n",
        "    # Geometry\n",
        "    dx = (out['x0'].values - out['x1'].values).astype(np.float32)\n",
        "    dy = (out['y0'].values - out['y1'].values).astype(np.float32)\n",
        "    dz = (out['z0'].values - out['z1'].values).astype(np.float32)\n",
        "    d2 = dx*dx + dy*dy + dz*dz\n",
        "    dist = np.sqrt(d2) + 1e-6\n",
        "    out['dist'] = dist.astype(np.float32)\n",
        "    out['log_dist'] = np.log(dist).astype(np.float32)\n",
        "    out['dist2'] = d2.astype(np.float32)\n",
        "    out['inv_dist'] = (1.0/dist).astype(np.float32)\n",
        "    out['inv_d2'] = (1.0/d2.clip(min=1e-6)).astype(np.float32)\n",
        "    out['inv_d3'] = (1.0/(dist*dist*dist)).astype(np.float32)\n",
        "    # Dipole projection onto bond\n",
        "    bond_ux = dx/dist; bond_uy = dy/dist; bond_uz = dz/dist\n",
        "    out['dip_proj'] = (out['dx'].values*bond_ux + out['dy'].values*bond_uy + out['dz'].values*bond_uz).astype(np.float32)\n",
        "    out['dip_cos'] = (out['dip_proj'] / (out['dip_norm'] + 1e-6)).astype(np.float32)\n",
        "    out['dip_abs_proj'] = out['dip_proj'].abs().astype(np.float32)\n",
        "    # Atom identity/features\n",
        "    out['same_element'] = (out['atom_0'].values == out['atom_1'].values).astype(np.int8)\n",
        "    for a in ['Z','EN','covrad','valence_e','period','group']:\n",
        "        a0c, a1c = f'{a}0', f'{a}1'\n",
        "        out[f'{a}_sum']  = (out[a0c].values + out[a1c].values).astype(np.float32)\n",
        "        out[f'{a}_diff'] = (out[a0c].values - out[a1c].values).astype(np.float32)\n",
        "    out['EN_absdiff'] = out['EN_diff'].abs().astype(np.float32)\n",
        "    out['covrad_ratio'] = (out['covrad0'].values / np.where(out['covrad1'].values==0, np.nan, out['covrad1'].values)).astype(np.float32)\n",
        "    out['covrad_ratio'] = pd.Series(out['covrad_ratio']).replace([np.inf,-np.inf], np.nan).fillna(0).astype(np.float32)\n",
        "    # Cheap extras\n",
        "    covsum = (out['covrad0'].values + out['covrad1'].values + 1e-6).astype(np.float32)\n",
        "    out['dist_over_covsum'] = (out['dist'].values / covsum).astype(np.float32)\n",
        "    out['covrad_min'] = np.minimum(out['covrad0'].values, out['covrad1'].values).astype(np.float32)\n",
        "    out['covrad_max'] = np.maximum(out['covrad0'].values, out['covrad1'].values).astype(np.float32)\n",
        "    # Mulliken & shielding\n",
        "    for c in ['q0','q1','shield0','shield1']:\n",
        "        out[c] = out[c].astype(np.float32)\n",
        "    out['q_sum'] = (out['q0'].values + out['q1'].values).astype(np.float32)\n",
        "    out['q_diff'] = (out['q0'].values - out['q1'].values).astype(np.float32)\n",
        "    out['shield_sum'] = (out['shield0'].values + out['shield1'].values).astype(np.float32)\n",
        "    out['shield_diff'] = (out['shield0'].values - out['shield1'].values).astype(np.float32)\n",
        "    # Sym codes and unordered pair code\n",
        "    out['sym0'] = out['atom_0'].map(sym_map).fillna(-1).astype(np.int8)\n",
        "    out['sym1'] = out['atom_1'].map(sym_map).fillna(-1).astype(np.int8)\n",
        "    smin = np.minimum(out['sym0'].values, out['sym1'].values).astype(np.int16)\n",
        "    smax = np.maximum(out['sym0'].values, out['sym1'].values).astype(np.int16)\n",
        "    out['pair_code'] = (smin*8 + smax).astype(np.int16)\n",
        "    # Merge fold for train\n",
        "    if is_train:\n",
        "        out = out.merge(folds, on='molecule_name', how='left')\n",
        "        assert 'fold' in out.columns and out['fold'].isna().sum()==0, \"Missing 'fold' after merge for train\"\n",
        "    # Build keep list without duplicating molecule_name\n",
        "    base_head = ['id','type','molecule_name'] + (['fold'] if is_train else [])\n",
        "    keep_rest = [\n",
        "        'dist','log_dist','dist2','inv_dist','inv_d2','inv_d3','same_element','sym0','sym1','pair_code',\n",
        "        'Z0','Z1','EN0','EN1','covrad0','covrad1','valence_e0','valence_e1','period0','period1','group0','group1',\n",
        "        'Z_sum','Z_diff','EN_sum','EN_diff','EN_absdiff','covrad_sum','covrad_diff','covrad_ratio','valence_e_sum','valence_e_diff','period_sum','period_diff','group_sum','group_diff',\n",
        "        'q0','q1','q_sum','q_diff','shield0','shield1','shield_sum','shield_diff',\n",
        "        'potential_energy','dx','dy','dz','dip_norm','dip_proj','dip_cos','dip_abs_proj','dist_over_covsum','covrad_min','covrad_max',\n",
        "        'n_atoms','n_H','n_heavy',\n",
        "        'atom_index_0','atom_index_1'\n",
        "    ]\n",
        "    keep = base_head + [c for c in keep_rest if c in out.columns]\n",
        "    out = out.loc[:, ~pd.Index(out.columns).duplicated()].copy()\n",
        "    out = out[keep].copy()\n",
        "    # Dtypes\n",
        "    for c in out.select_dtypes(include=['float64']).columns: out[c] = out[c].astype(np.float32)\n",
        "    for c in out.select_dtypes(include=['int64']).columns: out[c] = out[c].astype(np.int32)\n",
        "    print('Built pair frame in', f'{time.time()-t1:.2f}s', 'shape:', out.shape)\n",
        "    return out\n",
        "\n",
        "Xtr_base = build_pair_frame(train, is_train=True)\n",
        "ytr = pd.DataFrame({'id': train['id'].values, 'scalar_coupling_constant': train['scalar_coupling_constant'].values, 'type': train['type'].values})\n",
        "Xte_base = build_pair_frame(test, is_train=False)\n",
        "\n",
        "# Sanity checks on base frames\n",
        "assert Xtr_base['id'].is_unique and Xte_base['id'].is_unique, 'IDs not unique'\n",
        "assert 'fold' in Xtr_base.columns and Xtr_base['fold'].isna().sum()==0, \"Train base missing fold\"\n",
        "assert Xtr_base['molecule_name'].isna().sum()==0 and Xte_base['molecule_name'].isna().sum()==0, 'Missing molecule_name after merges'\n",
        "\n",
        "# Graph features: per-molecule covalent graph with k=1.15*(covrad_i+covrad_j)\n",
        "def graph_features_for_molecule(mol_atoms, pairs_rows, k=1.15, clip_len=6):\n",
        "    # mol_atoms has columns: atom_index (global within mol), x,y,z,covrad\n",
        "    idx = mol_atoms['atom_index'].values.astype(np.int32)\n",
        "    idx2local = {g:i for i,g in enumerate(idx)}\n",
        "    coords = mol_atoms[['x','y','z']].values.astype(np.float32)\n",
        "    covr = mol_atoms['covrad'].values.astype(np.float32)\n",
        "    n = len(idx)\n",
        "    adj = [[] for _ in range(n)]\n",
        "    # Build adjacency\n",
        "    for i in range(n):\n",
        "        ci = coords[i]\n",
        "        for j in range(i+1, n):\n",
        "            dij = float(np.linalg.norm(ci - coords[j]))\n",
        "            thr = float(k * (covr[i] + covr[j]))\n",
        "            if dij < thr:\n",
        "                adj[i].append(j); adj[j].append(i)\n",
        "    deg = np.array([len(nei) for nei in adj], dtype=np.int16)\n",
        "    adj_sets = [set(nei) for nei in adj]\n",
        "    # Prepare pairs in local indices\n",
        "    a0g = pairs_rows['atom_index_0'].values.astype(np.int32)\n",
        "    a1g = pairs_rows['atom_index_1'].values.astype(np.int32)\n",
        "    a0 = np.array([idx2local.get(g, -1) for g in a0g], dtype=np.int32)\n",
        "    a1 = np.array([idx2local.get(g, -1) for g in a1g], dtype=np.int32)\n",
        "    # BFS from unique sources\n",
        "    uniq_src = sorted(set([int(s) for s in a0 if s >= 0]))\n",
        "    dist_map = {}\n",
        "    for s in uniq_src:\n",
        "        dist = np.full(n, -1, dtype=np.int16); dist[s] = 0\n",
        "        dq = deque([s])\n",
        "        while dq:\n",
        "            u = dq.popleft()\n",
        "            if dist[u] >= clip_len:\n",
        "                continue\n",
        "            for v in adj[u]:\n",
        "                if dist[v] == -1:\n",
        "                    dist[v] = dist[u] + 1\n",
        "                    dq.append(v)\n",
        "        dist_map[s] = dist\n",
        "    # Collect features\n",
        "    m = len(a0)\n",
        "    path_len = np.full(m, clip_len, dtype=np.int16)\n",
        "    is_bonded = np.zeros(m, dtype=np.int8)\n",
        "    deg0 = np.zeros(m, dtype=np.int16)\n",
        "    deg1 = np.zeros(m, dtype=np.int16)\n",
        "    common_nei = np.zeros(m, dtype=np.int16)\n",
        "    for i in range(m):\n",
        "        u,v = a0[i], a1[i]\n",
        "        if u >= 0 and v >= 0:\n",
        "            d = dist_map.get(int(u), None)\n",
        "            if d is not None and d[v] != -1:\n",
        "                path_len[i] = min(int(d[v]), clip_len)\n",
        "                is_bonded[i] = 1 if path_len[i] == 1 else 0\n",
        "            deg0[i] = deg[u]\n",
        "            deg1[i] = deg[v]\n",
        "            common_nei[i] = len(adj_sets[u].intersection(adj_sets[v]))\n",
        "    return path_len, is_bonded, deg0, deg1, common_nei\n",
        "\n",
        "def add_graph_features(Xbase):\n",
        "    t2 = time.time()\n",
        "    # Ensure no duplicate column names (e.g., molecule_name)\n",
        "    Xbase = Xbase.loc[:, ~pd.Index(Xbase.columns).duplicated()]\n",
        "    # Prepare atoms per molecule minimal subset\n",
        "    atoms_min = atoms[['molecule_name','atom_index','x','y','z','covrad']].copy()\n",
        "    # Group by molecule to process\n",
        "    Xbase = Xbase.sort_values(['molecule_name']).reset_index(drop=True)\n",
        "    grp_idx = Xbase.groupby('molecule_name').indices\n",
        "    # Arrays to fill\n",
        "    n = len(Xbase)\n",
        "    path_len = np.full(n, 6, dtype=np.int16)\n",
        "    is_bonded = np.zeros(n, dtype=np.int8)\n",
        "    deg0 = np.zeros(n, dtype=np.int16)\n",
        "    deg1 = np.zeros(n, dtype=np.int16)\n",
        "    comn = np.zeros(n, dtype=np.int16)\n",
        "    processed = 0\n",
        "    for gi, (mol, idxs) in enumerate(grp_idx.items()):\n",
        "        pairs_rows = Xbase.loc[idxs, ['atom_index_0','atom_index_1']]\n",
        "        mol_atoms = atoms_min[atoms_min['molecule_name'] == mol]\n",
        "        pl, ib, d0, d1, cn = graph_features_for_molecule(mol_atoms, pairs_rows, k=1.15, clip_len=6)\n",
        "        path_len[idxs] = pl\n",
        "        is_bonded[idxs] = ib\n",
        "        deg0[idxs] = d0\n",
        "        deg1[idxs] = d1\n",
        "        comn[idxs] = cn\n",
        "        processed += 1\n",
        "        if processed % 2000 == 0:\n",
        "            print(f'  processed {processed}/{len(grp_idx)} molecules; elapsed {time.time()-t2:.1f}s', flush=True)\n",
        "    Xbase['path_len'] = path_len\n",
        "    Xbase['is_bonded'] = is_bonded\n",
        "    Xbase['degree_0'] = deg0\n",
        "    Xbase['degree_1'] = deg1\n",
        "    Xbase['deg_sum'] = (Xbase['degree_0'].values + Xbase['degree_1'].values).astype(np.int16)\n",
        "    Xbase['deg_diff'] = (Xbase['degree_0'].values - Xbase['degree_1'].values).astype(np.int16)\n",
        "    Xbase['common_neighbors'] = comn\n",
        "    print('Graph features added in', f'{time.time()-t2:.2f}s')\n",
        "    return Xbase\n",
        "\n",
        "Xtr_v1_path = 'X_train_v1.parquet'; Xte_v1_path = 'X_test_v1.parquet'\n",
        "\n",
        "# Compute/load train graph\n",
        "if os.path.exists(Xtr_v1_path):\n",
        "    print('Loading cached train v1 features...')\n",
        "    Xtr_v1 = pd.read_parquet(Xtr_v1_path)\n",
        "else:\n",
        "    print('Adding graph features to train...')\n",
        "    Xtr_v1 = add_graph_features(Xtr_base)\n",
        "    # Save immediately to avoid losing work if test step fails later\n",
        "    Xtr_v1.to_parquet(Xtr_v1_path, index=False)\n",
        "    print('Saved train v1 to', Xtr_v1_path)\n",
        "\n",
        "# Compute/load test graph\n",
        "if os.path.exists(Xte_v1_path):\n",
        "    print('Loading cached test v1 features...')\n",
        "    Xte_v1 = pd.read_parquet(Xte_v1_path)\n",
        "else:\n",
        "    print('Adding graph features to test...')\n",
        "    Xte_v1 = add_graph_features(Xte_base)\n",
        "    Xte_v1.to_parquet(Xte_v1_path, index=False)\n",
        "    print('Saved test v1 to', Xte_v1_path)\n",
        "\n",
        "# Post-run sanity checks\n",
        "assert Xtr_v1.shape[0] == train.shape[0], f'Train rows mismatch: {Xtr_v1.shape[0]} vs {train.shape[0]}'\n",
        "assert Xte_v1.shape[0] == test.shape[0], f'Test rows mismatch: {Xte_v1.shape[0]} vs {test.shape[0]}'\n",
        "for df_chk, name in [(Xtr_v1,'train_v1'), (Xte_v1,'test_v1')]:\n",
        "    key_cols = [c for c in ['dist','inv_dist','covrad_ratio','dip_proj','dip_cos','dist_over_covsum'] if c in df_chk.columns]\n",
        "    if key_cols:\n",
        "        assert np.isfinite(df_chk[key_cols].to_numpy()).all(), f'Non-finite values found in {name}'\n",
        "\n",
        "# Save y\n",
        "ytr.to_csv('y_train.csv', index=False)\n",
        "print('Saved v1:', Xtr_v1_path, Xtr_v1.shape, '|', Xte_v1_path, Xte_v1.shape, '| y:', ytr.shape)\n",
        "print(f'FE v1 total time: {time.time()-t0:.2f}s', flush=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base inputs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading mulliken and shielding...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built pair frame in 4.39s shape: (4191263, 64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built pair frame in 0.79s shape: (467813, 63)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding graph features to train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 2000/76510 molecules; elapsed 128.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 4000/76510 molecules; elapsed 253.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 6000/76510 molecules; elapsed 379.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 8000/76510 molecules; elapsed 505.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 10000/76510 molecules; elapsed 631.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 12000/76510 molecules; elapsed 756.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 14000/76510 molecules; elapsed 881.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 16000/76510 molecules; elapsed 1006.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 18000/76510 molecules; elapsed 1132.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 20000/76510 molecules; elapsed 1257.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 22000/76510 molecules; elapsed 1383.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 24000/76510 molecules; elapsed 1510.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 26000/76510 molecules; elapsed 1635.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 28000/76510 molecules; elapsed 1760.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 30000/76510 molecules; elapsed 1886.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 32000/76510 molecules; elapsed 2011.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 34000/76510 molecules; elapsed 2138.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 36000/76510 molecules; elapsed 2265.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 38000/76510 molecules; elapsed 2391.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 40000/76510 molecules; elapsed 2517.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 42000/76510 molecules; elapsed 2644.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 44000/76510 molecules; elapsed 2770.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 46000/76510 molecules; elapsed 2897.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 48000/76510 molecules; elapsed 3023.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 50000/76510 molecules; elapsed 3150.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 52000/76510 molecules; elapsed 3276.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 54000/76510 molecules; elapsed 3403.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 56000/76510 molecules; elapsed 3530.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 58000/76510 molecules; elapsed 3656.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 60000/76510 molecules; elapsed 3783.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 62000/76510 molecules; elapsed 3910.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 64000/76510 molecules; elapsed 4036.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 66000/76510 molecules; elapsed 4163.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 68000/76510 molecules; elapsed 4290.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 70000/76510 molecules; elapsed 4417.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 72000/76510 molecules; elapsed 4543.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 74000/76510 molecules; elapsed 4668.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 76000/76510 molecules; elapsed 4792.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph features added in 4824.49s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved train v1 to X_train_v1.parquet\nAdding graph features to test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 2000/8502 molecules; elapsed 118.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 4000/8502 molecules; elapsed 237.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 6000/8502 molecules; elapsed 356.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  processed 8000/8502 molecules; elapsed 475.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph features added in 504.74s\nSaved test v1 to X_test_v1.parquet\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Non-finite values found in test_v1",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 269\u001b[39m\n\u001b[32m    267\u001b[39m     key_cols = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mdist\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33minv_dist\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mcovrad_ratio\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mdip_proj\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mdip_cos\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mdist_over_covsum\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df_chk.columns]\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key_cols:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m np.isfinite(df_chk[key_cols].to_numpy()).all(), \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mNon-finite values found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;66;03m# Save y\u001b[39;00m\n\u001b[32m    272\u001b[39m ytr.to_csv(\u001b[33m'\u001b[39m\u001b[33my_train.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[31mAssertionError\u001b[39m: Non-finite values found in test_v1"
          ]
        }
      ]
    },
    {
      "id": "360bfce0-aff2-424f-bb6b-f20a4a847e86",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Modeling v1: per-type XGBoost GPU with GroupCV (prebuilt folds). Run after X_train_v1.parquet exists.\n",
        "import os, time, gc, json\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import xgboost as xgb\n",
        "\n",
        "def log_mae_by_type(y_true, y_pred, types):\n",
        "    vals = []\n",
        "    for t in np.unique(types):\n",
        "        m = (types == t)\n",
        "        mae = float(np.mean(np.abs(y_true[m] - y_pred[m])))\n",
        "        vals.append(np.log(mae + 1e-9))\n",
        "    return float(np.mean(vals))\n",
        "\n",
        "feat_train_path = 'X_train_v1.parquet'\n",
        "y_path = 'y_train.csv'\n",
        "assert os.path.exists(feat_train_path), f'Missing {feat_train_path}; run FE v1 first.'\n",
        "X = pd.read_parquet(feat_train_path)\n",
        "y = pd.read_csv(y_path)\n",
        "assert X.shape[0] == y.shape[0], 'Row mismatch X vs y'\n",
        "\n",
        "# Align by id to be safe\n",
        "X = X.sort_values('id').reset_index(drop=True)\n",
        "y = y.sort_values('id').reset_index(drop=True)\n",
        "for c in ['id','type']:\n",
        "    assert (X[c].values == y[c].values).all(), f'Mismatch in column {c}'\n",
        "\n",
        "# Feature columns\n",
        "drop_cols = [c for c in ['id','molecule_name','type','fold','atom_index_0','atom_index_1'] if c in X.columns]\n",
        "feat_cols = [c for c in X.columns if c not in drop_cols]\n",
        "print('Num features:', len(feat_cols))\n",
        "\n",
        "types = X['type'].values\n",
        "folds = X['fold'].values\n",
        "target = y['scalar_coupling_constant'].values.astype(np.float32)\n",
        "\n",
        "type_list = sorted(np.unique(types))\n",
        "oof = np.zeros_like(target, dtype=np.float32)\n",
        "models_info = {}\n",
        "\n",
        "xgb_params = {\n",
        "    'tree_method': 'gpu_hist',\n",
        "    'predictor': 'gpu_predictor',\n",
        "    'objective': 'reg:absoluteerror',\n",
        "    'eval_metric': 'mae',\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 8,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'reg_alpha': 0.0,\n",
        "    'reg_lambda': 1.0,\n",
        "    'n_estimators': 20000,\n",
        "}\n",
        "ESR = 100\n",
        "\n",
        "t0 = time.time()\n",
        "for t in type_list:\n",
        "    m_type = (types == t)\n",
        "    Xt = X.loc[m_type, feat_cols].astype(np.float32)\n",
        "    yt = target[m_type]\n",
        "    ft = folds[m_type]\n",
        "    print(f'\\nType {t}: rows={Xt.shape[0]} features={Xt.shape[1]}')\n",
        "    oof_t = np.zeros_like(yt, dtype=np.float32)\n",
        "    fold_models = []\n",
        "    for k in sorted(np.unique(folds)):\n",
        "        tr_idx = (ft != k)\n",
        "        va_idx = (ft == k)\n",
        "        if va_idx.sum() == 0 or tr_idx.sum() == 0:\n",
        "            continue\n",
        "        dtrain = xgb.DMatrix(Xt.loc[tr_idx], label=yt[tr_idx])\n",
        "        dvalid = xgb.DMatrix(Xt.loc[va_idx], label=yt[va_idx])\n",
        "        w = xgb.train(xgb_params, dtrain, num_boost_round=xgb_params['n_estimators'], evals=[(dvalid, 'valid')],\n",
        "                      early_stopping_rounds=ESR, verbose_eval=False)\n",
        "        preds = w.predict(dvalid, iteration_range=(0, w.best_iteration+1))\n",
        "        oof_t[va_idx] = preds.astype(np.float32)\n",
        "        fold_models.append({'fold': int(k), 'best_iteration': int(w.best_iteration)})\n",
        "        print(f'  fold {k}: best_iter={int(w.best_iteration)} MAE={mean_absolute_error(yt[va_idx], preds):.5f}', flush=True)\n",
        "    oof[m_type] = oof_t\n",
        "    mae_t = mean_absolute_error(yt, oof_t)\n",
        "    print(f'Type {t}: OOF MAE={mae_t:.5f}', flush=True)\n",
        "    models_info[t] = fold_models\n",
        "    del Xt; gc.collect()\n",
        "\n",
        "overall_logmae = log_mae_by_type(target, oof, types)\n",
        "print('\\nOOF log-MAE (competition metric proxy):', overall_logmae)\n",
        "\n",
        "# Save OOF for diagnostics\n",
        "oof_df = pd.DataFrame({'id': X['id'].values, 'type': types, 'oof': oof, 'y': target})\n",
        "oof_df.to_csv('oof_xgb_v1.csv', index=False)\n",
        "json.dump(models_info, open('models_info_xgb_v1.json','w'))\n",
        "print('Saved oof and models info. Total time:', f'{time.time()-t0:.1f}s', flush=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num features: 65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nType 1JHC: rows=637912 features=65\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:02:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n\n    E.g. tree_method = \"hist\", device = \"cuda\"\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:02:36] WARNING: /workspace/src/context.cc:43: No visible GPU is found, setting device to CPU.\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:02:36] WARNING: /workspace/src/context.cc:196: XGBoost is not compiled with CUDA support.\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [03:02:36] WARNING: /workspace/src/learner.cc:740: \nParameters: { \"n_estimators\", \"predictor\" } are not used.\n\n  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "XGBoostError",
          "evalue": "[03:02:36] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [03:02:36] /workspace/src/tree/updater_gpu_hist.cu:867: Check failed: ctx_->Ordinal() >= 0 (-1 vs. 0) : Must have at least one device\nStack trace:\n  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x25c1ac) [0x7d679405c1ac]\n  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0xe2d2dd) [0x7d6794c2d2dd]\n  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0xe3b814) [0x7d6794c3b814]\n  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5ad006) [0x7d67943ad006]\n  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5ae3d4) [0x7d67943ae3d4]\n  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5f8cd8) [0x7d67943f8cd8]\n  [bt] (6) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x7d6793f65a1f]\n  [bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d6a645f5e2e]\n  [bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d6a645f2493]\n\n\n\nStack trace:\n  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x25c1ac) [0x7d679405c1ac]\n  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0xe3ba0b) [0x7d6794c3ba0b]\n  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5ad006) [0x7d67943ad006]\n  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5ae3d4) [0x7d67943ae3d4]\n  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5f8cd8) [0x7d67943f8cd8]\n  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x7d6793f65a1f]\n  [bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d6a645f5e2e]\n  [bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d6a645f2493]\n  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa99d) [0x7d6a65e8899d]\n\n",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mXGBoostError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     70\u001b[39m dtrain = xgb.DMatrix(Xt.loc[tr_idx], label=yt[tr_idx])\n\u001b[32m     71\u001b[39m dvalid = xgb.DMatrix(Xt.loc[va_idx], label=yt[va_idx])\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m w = \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxgb_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_estimators\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdvalid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m              \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mESR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m preds = w.predict(dvalid, iteration_range=(\u001b[32m0\u001b[39m, w.best_iteration+\u001b[32m1\u001b[39m))\n\u001b[32m     75\u001b[39m oof_t[va_idx] = preds.astype(np.float32)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py:726\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    725\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/xgboost/training.py:181\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py:2100\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2100\u001b[39m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2101\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2102\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2103\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2106\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py:284\u001b[39m, in \u001b[36m_check_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[32m    274\u001b[39m \n\u001b[32m    275\u001b[39m \u001b[33;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    281\u001b[39m \u001b[33;03m    return value from API calls\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "\u001b[31mXGBoostError\u001b[39m: [03:02:36] /workspace/src/tree/updater_gpu_hist.cu:861: Exception in gpu_hist: [03:02:36] /workspace/src/tree/updater_gpu_hist.cu:867: Check failed: ctx_->Ordinal() >= 0 (-1 vs. 0) : Must have at least one device\nStack trace:\n  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x25c1ac) [0x7d679405c1ac]\n  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0xe2d2dd) [0x7d6794c2d2dd]\n  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0xe3b814) [0x7d6794c3b814]\n  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5ad006) [0x7d67943ad006]\n  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5ae3d4) [0x7d67943ae3d4]\n  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5f8cd8) [0x7d67943f8cd8]\n  [bt] (6) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x7d6793f65a1f]\n  [bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d6a645f5e2e]\n  [bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d6a645f2493]\n\n\n\nStack trace:\n  [bt] (0) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x25c1ac) [0x7d679405c1ac]\n  [bt] (1) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0xe3ba0b) [0x7d6794c3ba0b]\n  [bt] (2) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5ad006) [0x7d67943ad006]\n  [bt] (3) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5ae3d4) [0x7d67943ae3d4]\n  [bt] (4) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(+0x5f8cd8) [0x7d67943f8cd8]\n  [bt] (5) /usr/local/lib/python3.11/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x6f) [0x7d6793f65a1f]\n  [bt] (6) /usr/lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7d6a645f5e2e]\n  [bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7d6a645f2493]\n  [bt] (8) /usr/lib/python3.11/lib-dynload/_ctypes.cpython-311-x86_64-linux-gnu.so(+0xa99d) [0x7d6a65e8899d]\n\n"
          ]
        }
      ]
    },
    {
      "id": "bd6861b5-81cf-487e-a2f6-67ef44a020c2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Monitor CatBoost training artifacts and GPU status\n",
        "import os, time, json, pandas as pd, numpy as np, subprocess, datetime as dt\n",
        "\n",
        "def fstat(path):\n",
        "    if not os.path.exists(path):\n",
        "        return {'exists': False}\n",
        "    st = os.stat(path)\n",
        "    return {'exists': True, 'size_MB': round(st.st_size/1e6, 3), 'mtime': dt.datetime.fromtimestamp(st.st_mtime).isoformat(timespec='seconds')}\n",
        "\n",
        "paths = [\n",
        "    'oof_cat_v1.csv',\n",
        "    'models_info_cat_v1.json',\n",
        "    'best_iters_by_type_cat_v1.json',\n",
        "    'submission_cat_v1.csv',\n",
        "    'submission.csv',\n",
        "    'docker_run.log',\n",
        "]\n",
        "print('Artifact status:')\n",
        "for p in paths:\n",
        "    print(p, fstat(p))\n",
        "\n",
        "print('\\nGPU status (nvidia-smi):')\n",
        "try:\n",
        "    out = subprocess.run(['bash','-lc','nvidia-smi || true'], capture_output=True, text=True, check=False)\n",
        "    print(out.stdout)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi failed:', e)\n",
        "\n",
        "# If OOF exists, show quick summary\n",
        "if os.path.exists('oof_cat_v1.csv'):\n",
        "    oof = pd.read_csv('oof_cat_v1.csv')\n",
        "    def log_mae_by_type(y_true, y_pred, types):\n",
        "        vals = []\n",
        "        for t in np.unique(types):\n",
        "            m = (types == t)\n",
        "            mae = float(np.mean(np.abs(y_true[m] - y_pred[m])))\n",
        "            vals.append(np.log(mae + 1e-9))\n",
        "        return float(np.mean(vals))\n",
        "    score = log_mae_by_type(oof['y'].values, oof['oof'].values, oof['type'].values)\n",
        "    print(f'OOF log-MAE proxy: {score:.6f}')\n",
        "    print(oof.groupby('type').apply(lambda d: np.log(np.mean(np.abs(d['y']-d['oof']))+1e-9)).to_string())\n",
        "\n",
        "print('Monitoring done at', time.strftime('%Y-%m-%d %H:%M:%S'), flush=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artifact status:\noof_cat_v1.csv {'exists': False}\nmodels_info_cat_v1.json {'exists': False}\nbest_iters_by_type_cat_v1.json {'exists': False}\nsubmission_cat_v1.csv {'exists': False}\nsubmission.csv {'exists': True, 'size_MB': 7.731, 'mtime': '2025-09-23T23:22:09'}\ndocker_run.log {'exists': True, 'size_MB': 0.523, 'mtime': '2025-09-24T09:22:15'}\n\nGPU status (nvidia-smi):\nFailed to initialize NVML: Unknown Error\n\nMonitoring done at 2025-09-24 09:22:15\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}