{
  "cells": [
    {
      "id": "4dc33673-6d12-44fd-bcde-f83dbaebfa1e",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aerial Cactus Identification \u2013 Medal Plan\n",
        "\n",
        "Goal: Achieve 1.000 AUC (medal).\n",
        "\n",
        "Plan:\n",
        "- Environment/GPU: Verify GPU availability; use PyTorch + torchvision.\n",
        "- Data pipeline:\n",
        "  - Unzip train/test, read train.csv (id, has_cactus).\n",
        "  - Build robust Dataset with augmentations (Albumentations or torchvision).\n",
        "  - 32x32 RGB images; normalize with ImageNet stats for pretrained models or compute dataset stats.\n",
        "- Validation:\n",
        "  - Stratified KFold (e.g., 5 folds), deterministic seed.\n",
        "  - Track OOF predictions and per-fold ROC-AUC.\n",
        "  - Save OOF/test logits for future blends.\n",
        "- Baseline model:\n",
        "  - Transfer learning: EfficientNet-B0 or ResNet18 pretrained on ImageNet; replace head for binary.\n",
        "  - Loss: BCEWithLogitsLoss; optimizer AdamW; one-cycle or cosine schedule.\n",
        "  - Augs: flips, small shifts/rotations, Cutout optional.\n",
        "  - Training: small epochs first (e.g., 5) with early stopping; then extend if helpful.\n",
        "- Inference:\n",
        "  - TTA (hflip, vflip) if beneficial.\n",
        "  - Average fold predictions; produce submission.csv.\n",
        "- Logging & checks:\n",
        "  - Print progress, fold times, AUCs.\n",
        "  - Cache datasets and predictions.\n",
        "- Next steps:\n",
        "  - If baseline < 1.0 AUC, try:\n",
        "    - Higher-res upscaling with light conv stem;\n",
        "    - Stronger augs;\n",
        "    - Different backbone (ConvNeXt-Tiny, EfficientNet-B3) or custom small CNN tuned for 32x32.\n",
        "    - Blend multiple seeds/backbones.\n",
        "\n",
        "We will request expert review after environment/data setup, after baseline OOF, and before long runs."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "ea5cfec4-b7fe-4c55-944b-82560c295b55",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup: packages, GPU check, unzip data, basic EDA\n",
        "import os, sys, time, zipfile, subprocess, json, math, random, hashlib, gc\n",
        "from pathlib import Path\n",
        "\n",
        "def pip_install(pkgs):\n",
        "    for p in pkgs:\n",
        "        print(f\"[pip] installing {p}...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', p, '--quiet'], check=False)\n",
        "\n",
        "required = ['torch', 'torchvision', 'timm', 'albumentations', 'imagehash']\n",
        "pip_install(required)\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "    props = torch.cuda.get_device_properties(0)\n",
        "    print(f\"GPU Memory: {props.total_memory/1024**3:.1f} GB\")\n",
        "\n",
        "DATA_DIR = Path('.')\n",
        "TRAIN_ZIP = DATA_DIR/'train.zip'\n",
        "TEST_ZIP = DATA_DIR/'test.zip'\n",
        "TRAIN_DIR = DATA_DIR/'train'\n",
        "TEST_DIR = DATA_DIR/'test'\n",
        "\n",
        "def unzip_if_needed(zip_path: Path, out_dir: Path):\n",
        "    if out_dir.exists() and any(out_dir.iterdir()):\n",
        "        print(f\"[unzip] {out_dir} already extracted.\")\n",
        "        return\n",
        "    print(f\"[unzip] extracting {zip_path} -> {out_dir}\")\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "        zf.extractall(out_dir)\n",
        "    print(f\"[unzip] done: {out_dir}\")\n",
        "\n",
        "t0 = time.time()\n",
        "unzip_if_needed(TRAIN_ZIP, TRAIN_DIR)\n",
        "unzip_if_needed(TEST_ZIP, TEST_DIR)\n",
        "print(f\"[timer] unzip elapsed: {time.time()-t0:.2f}s\")\n",
        "\n",
        "train_csv = pd.read_csv(DATA_DIR/'train.csv')\n",
        "sample_sub = pd.read_csv(DATA_DIR/'sample_submission.csv')\n",
        "print(\"train.csv shape:\", train_csv.shape)\n",
        "print(\"sample_submission shape:\", sample_sub.shape)\n",
        "print(train_csv.head(3))\n",
        "print(sample_sub.head(3))\n",
        "\n",
        "train_imgs = sorted([p.name for p in TRAIN_DIR.glob('*.jpg')])\n",
        "test_imgs = sorted([p.name for p in TEST_DIR.glob('*.jpg')])\n",
        "print(f\"#train images: {len(train_imgs)} | #test images: {len(test_imgs)}\")\n",
        "\n",
        "# Sanity check: CSV ids match files\n",
        "missing_in_fs = set(train_csv['id']) - set(train_imgs)\n",
        "missing_in_csv = set(train_imgs) - set(train_csv['id'])\n",
        "print(f\"Missing in filesystem: {len(missing_in_fs)} | Extra files not in CSV: {len(missing_in_csv)}\")\n",
        "\n",
        "# Quick image probe\n",
        "probe_paths = [TRAIN_DIR/train_csv['id'].iloc[i] for i in range(min(3, len(train_csv)))]\n",
        "for p in probe_paths:\n",
        "    im = Image.open(p)\n",
        "    print(p.name, im.size, im.mode)\n",
        "    im.close()\n",
        "\n",
        "print(\"[setup] Completed. Next: compute exact/perceptual hashes for leakage checks.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pip] installing torch...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pip] installing torchvision...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/torch-2.8.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.7.3.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.10.2.21.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.3.3.83.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.5.8.93.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton-3.4.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.8.4.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.8.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.8.93.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.8.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufile_cu12-1.13.1.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.9.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.27.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.8.93.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.8.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/setuptools-80.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/setuptools already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pkg_resources already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/_distutils_hack already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/distutils-precedence.pth already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparselt_cu12-0.7.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pip] installing timm...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/torchvision-0.23.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch-2.8.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.7.3.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.10.2.21.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.3.3.83.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.5.8.93.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton-3.4.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.8.4.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.8.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.8.93.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.8.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufile_cu12-1.13.1.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.9.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.27.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.8.93.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.8.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/setuptools-80.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/setuptools already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pkg_resources already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/_distutils_hack already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/distutils-precedence.pth already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparselt_cu12-0.7.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pip] installing albumentations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/_yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PyYAML-6.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pip] installing imagehash...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/scipy-1.16.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\nGPU Name: Tesla T4\nGPU Memory: 14.6 GB\n[unzip] extracting train.zip -> train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[unzip] done: train\n[unzip] extracting test.zip -> test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[unzip] done: test\n[timer] unzip elapsed: 1.84s\ntrain.csv shape: (14175, 2)\nsample_submission shape: (3325, 2)\n                                     id  has_cactus\n0  2de8f189f1dce439766637e75df0ee27.jpg           1\n1  36704d250f236238e7f996812c48235d.jpg           1\n2  eacde22fdc8c175972a5768e3daa8bc9.jpg           1\n                                     id  has_cactus\n0  09034a34de0e2015a8a28dfe18f423f6.jpg         0.5\n1  134f04305c795d6d202502c2ce3578f3.jpg         0.5\n2  41fad8d145e6c41868ce3617e30a2545.jpg         0.5\n#train images: 14175 | #test images: 3325\nMissing in filesystem: 0 | Extra files not in CSV: 0\n2de8f189f1dce439766637e75df0ee27.jpg (32, 32) RGB\n36704d250f236238e7f996812c48235d.jpg (32, 32) RGB\neacde22fdc8c175972a5768e3daa8bc9.jpg (32, 32) RGB\n[setup] Completed. Next: compute exact/perceptual hashes for leakage checks.\n"
          ]
        }
      ]
    },
    {
      "id": "f1c52fbe-1897-440a-9029-6172f06d5f5a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute exact (SHA1) and perceptual (phash) hashes; detect duplicates/leakage\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import imagehash, hashlib, time, os, gc\n",
        "\n",
        "def sha1_file(path: Path) -> str:\n",
        "    with open(path, 'rb') as f:\n",
        "        return hashlib.sha1(f.read()).hexdigest()\n",
        "\n",
        "def phash_file(path: Path) -> str:\n",
        "    with Image.open(path) as im:\n",
        "        return str(imagehash.phash(im))  # 16-char hex\n",
        "\n",
        "def compute_hashes(img_dir: Path, ids: list[str], do_phash: bool = True, log_every: int = 1000):\n",
        "    rows = []\n",
        "    t0 = time.time()\n",
        "    for i, img_id in enumerate(ids):\n",
        "        p = img_dir / img_id\n",
        "        sha1 = sha1_file(p)\n",
        "        ph = phash_file(p) if do_phash else ''\n",
        "        rows.append((img_id, sha1, ph))\n",
        "        if (i+1) % log_every == 0:\n",
        "            print(f\"[hash] {i+1}/{len(ids)} processed; elapsed {time.time()-t0:.1f}s\", flush=True)\n",
        "    df = pd.DataFrame(rows, columns=['id','sha1','phash'])\n",
        "    return df\n",
        "\n",
        "# Load IDs\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('sample_submission.csv')\n",
        "train_ids = train_df['id'].tolist()\n",
        "test_ids = test_df['id'].tolist()\n",
        "\n",
        "t0 = time.time()\n",
        "train_hash_df = compute_hashes(Path('train'), train_ids, do_phash=True, log_every=2000)\n",
        "train_hash_df = train_hash_df.merge(train_df, on='id', how='left')\n",
        "print(f\"[hash] train hashing done in {time.time()-t0:.1f}s; rows={len(train_hash_df)}\")\n",
        "\n",
        "t1 = time.time()\n",
        "test_hash_df = compute_hashes(Path('test'), test_ids, do_phash=True, log_every=1000)\n",
        "print(f\"[hash] test hashing done in {time.time()-t1:.1f}s; rows={len(test_hash_df)}\")\n",
        "\n",
        "# Save for reuse\n",
        "train_hash_df.to_csv('train_hashes.csv', index=False)\n",
        "test_hash_df.to_csv('test_hashes.csv', index=False)\n",
        "print('[hash] saved train_hashes.csv and test_hashes.csv')\n",
        "\n",
        "# Duplicate analysis in train\n",
        "dup_counts = train_hash_df.groupby('sha1').size().reset_index(name='n')\n",
        "train_dups = dup_counts[dup_counts['n'] > 1]['sha1']\n",
        "print(f\"[dups] exact-duplicate groups in train: {len(train_dups)} (total dup images: {int(dup_counts['n'].sum() - (dup_counts['n']>0).sum())})\")\n",
        "\n",
        "# Check for label conflicts within duplicate groups\n",
        "conflicts = (train_hash_df.groupby('sha1')['has_cactus']\n",
        "             .nunique().reset_index(name='n_labels'))\n",
        "conflicts = conflicts[conflicts['n_labels'] > 1]\n",
        "print(f\"[dups] label conflicts across identical images: {len(conflicts)}\")\n",
        "if len(conflicts):\n",
        "    print(conflicts.head())\n",
        "\n",
        "# Test-train leakage via exact hash\n",
        "test_leak = test_hash_df.merge(train_hash_df[['sha1','has_cactus']].drop_duplicates('sha1'), on='sha1', how='left')\n",
        "n_match = test_leak['has_cactus'].notna().sum()\n",
        "print(f\"[leak] test images with exact-hash match to train: {n_match} / {len(test_hash_df)} ({n_match/len(test_hash_df)*100:.1f}%)\")\n",
        "\n",
        "# Build lookup map (sha1 -> label) for inference; prefer majority label if duplicates exist\n",
        "label_by_sha1 = (train_hash_df.groupby('sha1')['has_cactus']\n",
        "                 .mean().round().astype(int).to_dict())\n",
        "import json\n",
        "with open('train_sha1_label_map.json', 'w') as f:\n",
        "    json.dump(label_by_sha1, f)\n",
        "print('[leak] saved train_sha1_label_map.json (sha1 -> majority label)')\n",
        "\n",
        "# Prepare groups for CV: use exact sha1 as group\n",
        "train_hash_df[['id','sha1','has_cactus']].to_csv('cv_groups.csv', index=False)\n",
        "print('[cv] saved cv_groups.csv (id, sha1, has_cactus) for StratifiedGroupKFold')\n",
        "\n",
        "gc.collect();"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] 2000/14175 processed; elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] 4000/14175 processed; elapsed 1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] 6000/14175 processed; elapsed 2.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] 8000/14175 processed; elapsed 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] 10000/14175 processed; elapsed 4.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] 12000/14175 processed; elapsed 5.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] 14000/14175 processed; elapsed 6.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] train hashing done in 6.6s; rows=14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] 1000/3325 processed; elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] 2000/3325 processed; elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] 3000/3325 processed; elapsed 1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] test hashing done in 1.5s; rows=3325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[hash] saved train_hashes.csv and test_hashes.csv\n[dups] exact-duplicate groups in train: 0 (total dup images: 0)\n[dups] label conflicts across identical images: 0\n[leak] test images with exact-hash match to train: 0 / 3325 (0.0%)\n[leak] saved train_sha1_label_map.json (sha1 -> majority label)\n[cv] saved cv_groups.csv (id, sha1, has_cactus) for StratifiedGroupKFold\n"
          ]
        }
      ]
    },
    {
      "id": "49f16f2d-b4ee-4094-9a30-1aacf4e30fe8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ResNet18 (torchvision) with StratifiedGroupKFold, OOF AUC, TTA, and submission\n",
        "import os, math, time, random, json, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "# Ensure writable caches for any libs that may try to use ~/.cache\n",
        "CACHE_DIR = Path('./.model_cache')\n",
        "for env_key in ['TORCH_HOME', 'XDG_CACHE_HOME']:\n",
        "    os.environ[env_key] = str(CACHE_DIR)\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "SEED = 42\n",
        "IMG_SIZE = 96\n",
        "N_FOLDS = 5\n",
        "EPOCHS = 12\n",
        "BATCH_SIZE = 256\n",
        "WORKERS = 2\n",
        "LR_BACKBONE = 1e-4\n",
        "LR_HEAD = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_transforms(train=True):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.ShiftScaleRotate(shift_limit=0.08, scale_limit=0.10, rotate_limit=10, border_mode=0, p=0.5),\n",
        "            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.0, p=0.2),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "\n",
        "class CactusDataset(Dataset):\n",
        "    def __init__(self, img_dir, df, mode='train', tta_flip=None, tta_vflip=False):\n",
        "        # mode in {'train','valid','test'}\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.mode = mode\n",
        "        self.tta_flip = tta_flip  # None or 'hflip'\n",
        "        self.tta_vflip = tta_vflip\n",
        "        self.tfms = get_transforms(train=(mode=='train'))\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['id']\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert('RGB')\n",
        "            img = np.array(im)\n",
        "        if self.tta_flip == 'hflip':\n",
        "            img = np.ascontiguousarray(img[:, ::-1, :])\n",
        "        if self.tta_vflip:\n",
        "            img = np.ascontiguousarray(img[::-1, :, :])\n",
        "        aug = self.tfms(image=img)\n",
        "        img_t = torch.from_numpy(aug['image'].transpose(2,0,1)).float()\n",
        "        if self.mode in ('train','valid'):\n",
        "            y = torch.tensor(row['has_cactus'], dtype=torch.float32)\n",
        "            return img_t, y\n",
        "        return img_t, row['id']\n",
        "\n",
        "def build_model():\n",
        "    model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, 1)\n",
        "    return model\n",
        "\n",
        "def make_optimizer(model):\n",
        "    # Differential LR: smaller for backbone, larger for head\n",
        "    head_params = list(model.fc.parameters())\n",
        "    backbone_params = [p for n,p in model.named_parameters() if not n.startswith('fc.')]\n",
        "    return torch.optim.AdamW([\n",
        "        {'params': backbone_params, 'lr': LR_BACKBONE},\n",
        "        {'params': head_params, 'lr': LR_HEAD},\n",
        "    ], weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, loss_fn, scaler):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    for i, (x, y) in enumerate(loader):\n",
        "        x = x.to(DEVICE, non_blocking=True); y = y.to(DEVICE, non_blocking=True).view(-1,1)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
        "            logits = model(x)\n",
        "            loss = loss_fn(logits, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer); scaler.update()\n",
        "        running += loss.item()*x.size(0)\n",
        "        if (i+1) % 20 == 0:\n",
        "            print(f\"  [train] step {i+1}/{len(loader)} loss={running/((i+1)*loader.batch_size):.4f}\", flush=True)\n",
        "    return running/len(loader.dataset)\n",
        "\n",
        "def valid_one_epoch(model, loader):\n",
        "    model.eval()\n",
        "    preds, targs = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(DEVICE, non_blocking=True); y = y.view(-1,1)\n",
        "            logits = model(x)\n",
        "            preds.append(torch.sigmoid(logits).squeeze(1).cpu().numpy())\n",
        "            targs.append(y.squeeze(1).cpu().numpy())\n",
        "    preds = np.concatenate(preds); targs = np.concatenate(targs)\n",
        "    auc = roc_auc_score(targs, preds)\n",
        "    return auc, preds\n",
        "\n",
        "def predict_loader(model, loader):\n",
        "    model.eval()\n",
        "    out_ids, out_preds = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, ids in loader:\n",
        "            x = x.to(DEVICE, non_blocking=True)\n",
        "            logits = model(x)\n",
        "            out_preds.append(torch.sigmoid(logits).squeeze(1).cpu().numpy())\n",
        "            out_ids += list(ids)\n",
        "    return np.concatenate(out_preds), out_ids\n",
        "\n",
        "# Load data and groups\n",
        "train_df = pd.read_csv('train.csv')\n",
        "groups_df = pd.read_csv('cv_groups.csv')\n",
        "train_df = train_df.merge(groups_df[['id','sha1']], on='id', how='left')\n",
        "test_ids = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "skf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "oof = np.zeros(len(train_df), dtype=np.float32)\n",
        "test_pred_accum = np.zeros(len(test_ids), dtype=np.float32)\n",
        "\n",
        "all_fold_aucs = []\n",
        "t_all = time.time()\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(train_df['id'], train_df['has_cactus'], groups=train_df['sha1'])):\n",
        "    print(f\"===== Fold {fold+1}/{N_FOLDS} =====\")\n",
        "    tr_df = train_df.iloc[tr_idx].reset_index(drop=True)\n",
        "    va_df = train_df.iloc[va_idx].reset_index(drop=True)\n",
        "    print(f\"train size: {len(tr_df)} | valid size: {len(va_df)}\")\n",
        "\n",
        "    tr_ds = CactusDataset('train', tr_df, mode='train')\n",
        "    va_ds = CactusDataset('train', va_df, mode='valid')\n",
        "    tr_loader = DataLoader(tr_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=True, drop_last=True)\n",
        "    va_loader = DataLoader(va_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(DEVICE)\n",
        "    optimizer = make_optimizer(model)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(DEVICE=='cuda'))\n",
        "\n",
        "    best_auc = -1.0; best_state = None; no_improve = 0\n",
        "    t_fold0 = time.time()\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        t0 = time.time()\n",
        "        tr_loss = train_one_epoch(model, tr_loader, optimizer, loss_fn, scaler)\n",
        "        val_auc, val_preds = valid_one_epoch(model, va_loader)\n",
        "        scheduler.step()\n",
        "        elapsed = time.time()-t0\n",
        "        # Log current LRs\n",
        "        lrs = [pg['lr'] for pg in optimizer.param_groups]\n",
        "        print(f\"[fold {fold}] epoch {epoch:02d} | tr_loss {tr_loss:.4f} | val_auc {val_auc:.6f} | lrs {lrs} | {elapsed:.1f}s\", flush=True)\n",
        "        if val_auc > best_auc:\n",
        "            best_auc = val_auc; best_state = {k: v.cpu() for k,v in model.state_dict().items()}; no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "        if no_improve >= 3:\n",
        "            print(f\"[fold {fold}] Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "    print(f\"[fold {fold}] best val AUC: {best_auc:.6f} | fold time {time.time()-t_fold0:.1f}s\")\n",
        "    all_fold_aucs.append(best_auc)\n",
        "    # Load best and infer OOF\n",
        "    model.load_state_dict({k: v.to(DEVICE) for k, v in best_state.items()}, strict=True)\n",
        "    va_loader = DataLoader(va_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "    _, val_preds = valid_one_epoch(model, va_loader)\n",
        "    oof[va_idx] = val_preds\n",
        "\n",
        "    # Test inference with TTA (orig + hflip + vflip)\n",
        "    test_ds = CactusDataset('test', test_ids, mode='test', tta_flip=None, tta_vflip=False)\n",
        "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "    p0, ids = predict_loader(model, test_loader)\n",
        "\n",
        "    test_ds_h = CactusDataset('test', test_ids, mode='test', tta_flip='hflip', tta_vflip=False)\n",
        "    test_loader_h = DataLoader(test_ds_h, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "    p1, _ = predict_loader(model, test_loader_h)\n",
        "\n",
        "    test_ds_v = CactusDataset('test', test_ids, mode='test', tta_flip=None, tta_vflip=True)\n",
        "    test_loader_v = DataLoader(test_ds_v, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "    p2, _ = predict_loader(model, test_loader_v)\n",
        "\n",
        "    p = (p0 + p1 + p2) / 3.0\n",
        "    test_pred_accum += p.astype(np.float32)\n",
        "    print(f\"[fold {fold}] test inference done.\")\n",
        "    del model, optimizer, loss_fn, scaler, tr_loader, va_loader, test_loader, test_loader_h, test_loader_v\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "oof_auc = roc_auc_score(train_df['has_cactus'].values, oof)\n",
        "print(f\"OOF AUC: {oof_auc:.6f}\")\n",
        "print(\"Fold AUCs:\", [f\"{a:.6f}\" for a in all_fold_aucs])\n",
        "\n",
        "# Save OOF\n",
        "np.save('oof_preds.npy', oof)\n",
        "pd.DataFrame({'id': train_df['id'], 'oof_pred': oof, 'has_cactus': train_df['has_cactus']}).to_csv('oof_preds.csv', index=False)\n",
        "\n",
        "# Average across folds\n",
        "test_pred = test_pred_accum / N_FOLDS\n",
        "\n",
        "# Exact-hash lookup (expected 0 overrides here)\n",
        "with open('train_sha1_label_map.json', 'r') as f:\n",
        "    sha1_to_label = json.load(f)\n",
        "test_hash_df = pd.read_csv('test_hashes.csv')\n",
        "lookup = test_hash_df[['id','sha1']].copy()\n",
        "lookup['label_from_train'] = lookup['sha1'].map(sha1_to_label).astype('float32')\n",
        "overrides = lookup['label_from_train'].notna().sum()\n",
        "print(f\"[inference] exact-hash overrides in test: {overrides}\")\n",
        "\n",
        "sub = test_ids.copy()\n",
        "sub = sub.merge(lookup[['id','label_from_train']], on='id', how='left')\n",
        "sub['pred'] = test_pred\n",
        "sub['has_cactus'] = np.where(sub['label_from_train'].notna(), sub['label_from_train'], sub['pred'])\n",
        "submission = sub[['id','has_cactus']].copy()\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with shape', submission.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 1/5 =====\ntrain size: 11340 | valid size: 2835\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to .model_cache/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|\u2588\u2588        | 9.25M/44.7M [00:00<00:00, 96.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 31.5M/44.7M [00:00<00:00, 176MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 44.7M/44.7M [00:00<00:00, 180MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 01 | tr_loss 0.0883 | val_auc 0.999877 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 02 | tr_loss 0.0153 | val_auc 0.999963 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 03 | tr_loss 0.0080 | val_auc 0.999987 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 04 | tr_loss 0.0090 | val_auc 0.999962 | lrs [7.75e-05, 0.0007524999999999999] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 05 | tr_loss 0.0046 | val_auc 0.999980 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 06 | tr_loss 0.0027 | val_auc 0.999989 | lrs [5.5e-05, 0.000505] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 07 | tr_loss 0.0021 | val_auc 0.999993 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 08 | tr_loss 0.0028 | val_auc 0.999990 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 09 | tr_loss 0.0022 | val_auc 0.999984 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 10 | tr_loss 0.0018 | val_auc 0.999986 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] Early stopping at epoch 10\n[fold 0] best val AUC: 0.999993 | fold time 73.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] test inference done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 2/5 =====\ntrain size: 11340 | valid size: 2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 01 | tr_loss 0.0814 | val_auc 0.999604 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 02 | tr_loss 0.0174 | val_auc 0.999864 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 03 | tr_loss 0.0080 | val_auc 0.999925 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 04 | tr_loss 0.0076 | val_auc 0.999937 | lrs [7.75e-05, 0.0007524999999999999] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 05 | tr_loss 0.0059 | val_auc 0.999929 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 06 | tr_loss 0.0047 | val_auc 0.999947 | lrs [5.5e-05, 0.000505] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 07 | tr_loss 0.0029 | val_auc 0.999958 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 08 | tr_loss 0.0023 | val_auc 0.999957 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 09 | tr_loss 0.0018 | val_auc 0.999956 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 10 | tr_loss 0.0026 | val_auc 0.999960 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 11 | tr_loss 0.0010 | val_auc 0.999957 | lrs [1.1533337816991932e-05, 2.6866715986911242e-05] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 12 | tr_loss 0.0014 | val_auc 0.999960 | lrs [1e-05, 1e-05] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] best val AUC: 0.999960 | fold time 89.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] test inference done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 3/5 =====\ntrain size: 11340 | valid size: 2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 01 | tr_loss 0.0868 | val_auc 0.999868 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 02 | tr_loss 0.0146 | val_auc 0.999971 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 03 | tr_loss 0.0118 | val_auc 0.999986 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 04 | tr_loss 0.0066 | val_auc 0.999995 | lrs [7.75e-05, 0.0007524999999999999] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 05 | tr_loss 0.0077 | val_auc 0.999993 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 06 | tr_loss 0.0057 | val_auc 0.999997 | lrs [5.5e-05, 0.000505] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 07 | tr_loss 0.0048 | val_auc 0.999993 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 08 | tr_loss 0.0037 | val_auc 1.000000 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 09 | tr_loss 0.0028 | val_auc 0.999999 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 10 | tr_loss 0.0031 | val_auc 0.999999 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 11 | tr_loss 0.0024 | val_auc 1.000000 | lrs [1.1533337816991932e-05, 2.6866715986911242e-05] | 7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] Early stopping at epoch 11\n[fold 2] best val AUC: 1.000000 | fold time 81.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] test inference done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 4/5 =====\ntrain size: 11340 | valid size: 2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.1079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 01 | tr_loss 0.0991 | val_auc 0.999838 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 02 | tr_loss 0.0163 | val_auc 0.999898 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 03 | tr_loss 0.0118 | val_auc 0.999964 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 04 | tr_loss 0.0091 | val_auc 0.999970 | lrs [7.75e-05, 0.0007524999999999999] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 05 | tr_loss 0.0074 | val_auc 0.999847 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 06 | tr_loss 0.0044 | val_auc 0.999986 | lrs [5.5e-05, 0.000505] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 07 | tr_loss 0.0043 | val_auc 0.999985 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 08 | tr_loss 0.0022 | val_auc 0.999981 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 09 | tr_loss 0.0030 | val_auc 0.999977 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] Early stopping at epoch 9\n[fold 3] best val AUC: 0.999986 | fold time 67.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] test inference done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 5/5 =====\ntrain size: 11340 | valid size: 2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 01 | tr_loss 0.0849 | val_auc 0.999915 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 02 | tr_loss 0.0160 | val_auc 0.999974 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 03 | tr_loss 0.0113 | val_auc 0.999988 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 04 | tr_loss 0.0079 | val_auc 0.999990 | lrs [7.75e-05, 0.0007524999999999999] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 05 | tr_loss 0.0056 | val_auc 0.999988 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 06 | tr_loss 0.0055 | val_auc 0.999992 | lrs [5.5e-05, 0.000505] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 07 | tr_loss 0.0055 | val_auc 0.999992 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 08 | tr_loss 0.0021 | val_auc 0.999992 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 09 | tr_loss 0.0020 | val_auc 0.999993 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 10 | tr_loss 0.0022 | val_auc 0.999994 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 11 | tr_loss 0.0019 | val_auc 0.999994 | lrs [1.1533337816991932e-05, 2.6866715986911242e-05] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 12 | tr_loss 0.0023 | val_auc 0.999994 | lrs [1e-05, 1e-05] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] best val AUC: 0.999994 | fold time 88.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] test inference done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF AUC: 0.999985\nFold AUCs: ['0.999993', '0.999960', '1.000000', '0.999986', '0.999994']\n[inference] exact-hash overrides in test: 0\nSaved submission.csv with shape (3325, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "f9792b18-9db2-4ce5-839a-b9220a224835",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ResNet18 re-run with Dihedral-8 TTA and LOGIT averaging across TTAs and folds\n",
        "import os, time, json, gc, random, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "CACHE_DIR = Path('./.model_cache'); CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['TORCH_HOME'] = str(CACHE_DIR)\n",
        "os.environ['XDG_CACHE_HOME'] = str(CACHE_DIR)\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "SEED = 42\n",
        "IMG_SIZE = 96\n",
        "N_FOLDS = 5\n",
        "EPOCHS = 12\n",
        "BATCH_SIZE = 256\n",
        "WORKERS = 2\n",
        "LR_BACKBONE = 1e-4\n",
        "LR_HEAD = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "def set_seed(seed=SEED):\n",
        "    import numpy as _np, random as _random, torch as _torch\n",
        "    _random.seed(seed); _np.random.seed(seed); _torch.manual_seed(seed); _torch.cuda.manual_seed_all(seed)\n",
        "    _torch.backends.cudnn.deterministic = True\n",
        "    _torch.backends.cudnn.benchmark = False\n",
        "set_seed()\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_transforms(train=True):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.ShiftScaleRotate(shift_limit=0.08, scale_limit=0.10, rotate_limit=10, border_mode=0, p=0.5),\n",
        "            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.0, p=0.2),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "\n",
        "class CactusTTADataset(Dataset):\n",
        "    def __init__(self, img_dir, df, mode='train', rot_k=0, hflip=False):\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.mode = mode\n",
        "        self.rot_k = rot_k  # 0,1,2,3\n",
        "        self.hflip = hflip\n",
        "        self.tfms = get_transforms(train=(mode=='train'))\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['id']\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert('RGB')\n",
        "            img = np.array(im)\n",
        "        if self.rot_k:\n",
        "            img = np.ascontiguousarray(np.rot90(img, k=self.rot_k))\n",
        "        if self.hflip:\n",
        "            img = np.ascontiguousarray(img[:, ::-1, :])\n",
        "        aug = self.tfms(image=img)\n",
        "        img_t = torch.from_numpy(aug['image'].transpose(2,0,1)).float()\n",
        "        if self.mode in ('train','valid'):\n",
        "            y = torch.tensor(row['has_cactus'], dtype=torch.float32)\n",
        "            return img_t, y\n",
        "        return img_t, row['id']\n",
        "\n",
        "def build_model():\n",
        "    m = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    m.fc = nn.Linear(m.fc.in_features, 1)\n",
        "    return m\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params = list(model.fc.parameters())\n",
        "    backbone_params = [p for n,p in model.named_parameters() if not n.startswith('fc.')]\n",
        "    return torch.optim.AdamW([\n",
        "        {'params': backbone_params, 'lr': LR_BACKBONE},\n",
        "        {'params': head_params, 'lr': LR_HEAD},\n",
        "    ], weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, loss_fn, scaler):\n",
        "    model.train(); total=0.0\n",
        "    for i,(x,y) in enumerate(loader):\n",
        "        x=x.to(DEVICE,non_blocking=True); y=y.to(DEVICE,non_blocking=True).view(-1,1)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
        "            logits=model(x); loss=loss_fn(logits,y)\n",
        "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
        "        total += loss.item()*x.size(0)\n",
        "        if (i+1)%20==0: print(f\"  [train] step {i+1}/{len(loader)} loss={total/((i+1)*loader.batch_size):.4f}\", flush=True)\n",
        "    return total/len(loader.dataset)\n",
        "\n",
        "def valid_one_epoch(model, loader):\n",
        "    model.eval(); preds=[]; targs=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x=x.to(DEVICE,non_blocking=True); y=y.view(-1,1)\n",
        "            logits=model(x)\n",
        "            preds.append(torch.sigmoid(logits).squeeze(1).cpu().numpy())\n",
        "            targs.append(y.squeeze(1).cpu().numpy())\n",
        "    preds=np.concatenate(preds); targs=np.concatenate(targs)\n",
        "    return roc_auc_score(targs,preds), preds\n",
        "\n",
        "def predict_logits(model, loader):\n",
        "    model.eval(); out_logits=[]; out_ids=[]\n",
        "    with torch.no_grad():\n",
        "        for x,ids in loader:\n",
        "            x=x.to(DEVICE,non_blocking=True)\n",
        "            logits=model(x).squeeze(1).cpu().numpy()\n",
        "            out_logits.append(logits); out_ids += list(ids)\n",
        "    return np.concatenate(out_logits), out_ids\n",
        "\n",
        "# Data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "groups_df = pd.read_csv('cv_groups.csv')\n",
        "train_df = train_df.merge(groups_df[['id','sha1']], on='id', how='left')\n",
        "test_ids = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "skf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "oof = np.zeros(len(train_df), dtype=np.float32)\n",
        "test_logit_accum = np.zeros(len(test_ids), dtype=np.float32)\n",
        "\n",
        "fold_aucs=[]\n",
        "t0_all=time.time()\n",
        "for fold,(tr_idx,va_idx) in enumerate(skf.split(train_df['id'], train_df['has_cactus'], groups=train_df['sha1'])):\n",
        "    print(f\"===== D8 ReRun Fold {fold+1}/{N_FOLDS} =====\")\n",
        "    tr_df = train_df.iloc[tr_idx].reset_index(drop=True)\n",
        "    va_df = train_df.iloc[va_idx].reset_index(drop=True)\n",
        "    tr_loader = DataLoader(CactusTTADataset('train', tr_df, mode='train'), batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=True, drop_last=True)\n",
        "    va_loader = DataLoader(CactusTTADataset('train', va_df, mode='valid'), batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(DEVICE)\n",
        "    optimizer = make_optimizer(model)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(DEVICE=='cuda'))\n",
        "\n",
        "    best_auc=-1.0; best_state=None; no_imp=0; t_fold=time.time()\n",
        "    for epoch in range(1,EPOCHS+1):\n",
        "        t_ep=time.time()\n",
        "        tr_loss = train_one_epoch(model, tr_loader, optimizer, loss_fn, scaler)\n",
        "        val_auc, _ = valid_one_epoch(model, va_loader)\n",
        "        scheduler.step()\n",
        "        lrs=[pg['lr'] for pg in optimizer.param_groups]\n",
        "        print(f\"[fold {fold}] epoch {epoch:02d} | tr_loss {tr_loss:.4f} | val_auc {val_auc:.6f} | lrs {lrs} | {time.time()-t_ep:.1f}s\", flush=True)\n",
        "        if val_auc > best_auc: best_auc=val_auc; best_state={k:v.cpu() for k,v in model.state_dict().items()}; no_imp=0\n",
        "        else: no_imp+=1\n",
        "        if no_imp>=3: print(f\"[fold {fold}] early stop at {epoch}\"); break\n",
        "    print(f\"[fold {fold}] best val AUC: {best_auc:.6f} | fold time {time.time()-t_fold:.1f}s\")\n",
        "    fold_aucs.append(best_auc)\n",
        "    model.load_state_dict({k:v.to(DEVICE) for k,v in best_state.items()}, strict=True)\n",
        "    # OOF with best\n",
        "    va_loader = DataLoader(CactusTTADataset('train', va_df, mode='valid'), batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "    _, va_preds = valid_one_epoch(model, va_loader)\n",
        "    oof[va_idx] = va_preds\n",
        "\n",
        "    # Dihedral-8 TTA logits: rot_k in {0,1,2,3} x hflip {False,True}\n",
        "    tta_logits_sum = np.zeros(len(test_ids), dtype=np.float32)\n",
        "    for rot_k in (0,1,2,3):\n",
        "        for hf in (False, True):\n",
        "            ds = CactusTTADataset('test', test_ids, mode='test', rot_k=rot_k, hflip=hf)\n",
        "            dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "            logits, ids = predict_logits(model, dl)\n",
        "            tta_logits_sum += logits.astype(np.float32)\n",
        "    fold_logits = tta_logits_sum / 8.0\n",
        "    test_logit_accum += fold_logits\n",
        "    print(f\"[fold {fold}] test D8 TTA inference done.\")\n",
        "    del model, optimizer, loss_fn, scaler, tr_loader, va_loader\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "oof_auc = roc_auc_score(train_df['has_cactus'].values, oof)\n",
        "print(f\"D8 OOF AUC: {oof_auc:.6f}\")\n",
        "print('D8 Fold AUCs:', [f\"{a:.6f}\" for a in fold_aucs])\n",
        "np.save('oof_preds_d8.npy', oof)\n",
        "pd.DataFrame({'id': train_df['id'], 'oof_pred': oof, 'has_cactus': train_df['has_cactus']}).to_csv('oof_preds_d8.csv', index=False)\n",
        "\n",
        "# Logit averaging across folds -> sigmoid once\n",
        "avg_test_logits = test_logit_accum / N_FOLDS\n",
        "test_pred = 1.0 / (1.0 + np.exp(-avg_test_logits))\n",
        "\n",
        "# Exact-hash override (should be zero)\n",
        "with open('train_sha1_label_map.json', 'r') as f:\n",
        "    sha1_to_label = json.load(f)\n",
        "test_hash_df = pd.read_csv('test_hashes.csv')\n",
        "lookup = test_hash_df[['id','sha1']].copy()\n",
        "lookup['label_from_train'] = lookup['sha1'].map(sha1_to_label).astype('float32')\n",
        "overrides = lookup['label_from_train'].notna().sum()\n",
        "print(f\"[inference-D8] exact-hash overrides in test: {overrides}\")\n",
        "\n",
        "sub = test_ids.copy()\n",
        "sub = sub.merge(lookup[['id','label_from_train']], on='id', how='left')\n",
        "sub['pred'] = test_pred\n",
        "sub['has_cactus'] = np.where(sub['label_from_train'].notna(), sub['label_from_train'], sub['pred'])\n",
        "submission = sub[['id','has_cactus']].copy()\n",
        "submission.to_csv('submission_d8.csv', index=False)\n",
        "print('Saved submission_d8.csv with shape', submission.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 01 | tr_loss 0.0880 | val_auc 0.999871 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 02 | tr_loss 0.0161 | val_auc 0.999982 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 03 | tr_loss 0.0079 | val_auc 0.999989 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 04 | tr_loss 0.0080 | val_auc 0.999986 | lrs [7.75e-05, 0.0007524999999999999] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 05 | tr_loss 0.0038 | val_auc 0.999984 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 06 | tr_loss 0.0042 | val_auc 0.999988 | lrs [5.5e-05, 0.000505] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] early stop at 6\n[fold 0] best val AUC: 0.999989 | fold time 44.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] test D8 TTA inference done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== D8 ReRun Fold 2/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 01 | tr_loss 0.0872 | val_auc 0.999568 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 02 | tr_loss 0.0145 | val_auc 0.999811 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 03 | tr_loss 0.0095 | val_auc 0.999806 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 04 | tr_loss 0.0054 | val_auc 0.999829 | lrs [7.75e-05, 0.0007524999999999999] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 05 | tr_loss 0.0060 | val_auc 0.999901 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 06 | tr_loss 0.0036 | val_auc 0.999934 | lrs [5.5e-05, 0.000505] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 07 | tr_loss 0.0057 | val_auc 0.999909 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 08 | tr_loss 0.0028 | val_auc 0.999942 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 09 | tr_loss 0.0024 | val_auc 0.999944 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 10 | tr_loss 0.0019 | val_auc 0.999958 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 11 | tr_loss 0.0012 | val_auc 0.999957 | lrs [1.1533337816991932e-05, 2.6866715986911242e-05] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 12 | tr_loss 0.0007 | val_auc 0.999958 | lrs [1e-05, 1e-05] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] best val AUC: 0.999958 | fold time 88.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] test D8 TTA inference done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== D8 ReRun Fold 3/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.1002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 01 | tr_loss 0.0926 | val_auc 0.999930 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 02 | tr_loss 0.0203 | val_auc 0.999973 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 03 | tr_loss 0.0095 | val_auc 0.999983 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 04 | tr_loss 0.0074 | val_auc 0.999990 | lrs [7.75e-05, 0.0007524999999999999] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 05 | tr_loss 0.0055 | val_auc 0.999989 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 06 | tr_loss 0.0076 | val_auc 0.999997 | lrs [5.5e-05, 0.000505] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 07 | tr_loss 0.0041 | val_auc 0.999989 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 08 | tr_loss 0.0026 | val_auc 0.999997 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 09 | tr_loss 0.0026 | val_auc 1.000000 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 10 | tr_loss 0.0014 | val_auc 1.000000 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 11 | tr_loss 0.0026 | val_auc 0.999997 | lrs [1.1533337816991932e-05, 2.6866715986911242e-05] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 12 | tr_loss 0.0026 | val_auc 0.999999 | lrs [1e-05, 1e-05] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] early stop at 12\n[fold 2] best val AUC: 1.000000 | fold time 89.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] test D8 TTA inference done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== D8 ReRun Fold 4/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.1018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 01 | tr_loss 0.0944 | val_auc 0.999866 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 02 | tr_loss 0.0152 | val_auc 0.999883 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 03 | tr_loss 0.0106 | val_auc 0.999906 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 04 | tr_loss 0.0062 | val_auc 0.999950 | lrs [7.75e-05, 0.0007524999999999999] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 05 | tr_loss 0.0046 | val_auc 0.999989 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 06 | tr_loss 0.0039 | val_auc 0.999981 | lrs [5.5e-05, 0.000505] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 07 | tr_loss 0.0046 | val_auc 0.999988 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 08 | tr_loss 0.0027 | val_auc 0.999993 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 09 | tr_loss 0.0018 | val_auc 0.999995 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 10 | tr_loss 0.0027 | val_auc 0.999994 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 11 | tr_loss 0.0015 | val_auc 0.999993 | lrs [1.1533337816991932e-05, 2.6866715986911242e-05] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 12 | tr_loss 0.0019 | val_auc 0.999992 | lrs [1e-05, 1e-05] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] early stop at 12\n[fold 3] best val AUC: 0.999995 | fold time 89.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] test D8 TTA inference done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== D8 ReRun Fold 5/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 01 | tr_loss 0.0747 | val_auc 0.999925 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 02 | tr_loss 0.0174 | val_auc 0.999981 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 03 | tr_loss 0.0097 | val_auc 0.999991 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 04 | tr_loss 0.0094 | val_auc 0.999991 | lrs [7.75e-05, 0.0007524999999999999] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 05 | tr_loss 0.0059 | val_auc 0.999992 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 06 | tr_loss 0.0058 | val_auc 0.999992 | lrs [5.5e-05, 0.000505] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 07 | tr_loss 0.0029 | val_auc 0.999994 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 08 | tr_loss 0.0018 | val_auc 0.999992 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 09 | tr_loss 0.0019 | val_auc 0.999993 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 10 | tr_loss 0.0023 | val_auc 1.000000 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 11 | tr_loss 0.0011 | val_auc 0.999996 | lrs [1.1533337816991932e-05, 2.6866715986911242e-05] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 12 | tr_loss 0.0016 | val_auc 0.999997 | lrs [1e-05, 1e-05] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] best val AUC: 1.000000 | fold time 90.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] test D8 TTA inference done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "D8 OOF AUC: 0.999980\nD8 Fold AUCs: ['0.999989', '0.999958', '1.000000', '0.999995', '1.000000']\n[inference-D8] exact-hash overrides in test: 0\nSaved submission_d8.csv with shape (3325, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "8e6ce46a-3c86-4ec3-b8c5-fb90a973eeb9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Multi-seed (42, 2025, 777) ResNet18 with EMA and Dihedral-8 TTA, logit-ensemble across folds and seeds\n",
        "import os, time, json, gc, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "CACHE_DIR = Path('./.model_cache'); CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['TORCH_HOME'] = str(CACHE_DIR)\n",
        "os.environ['XDG_CACHE_HOME'] = str(CACHE_DIR)\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "SEEDS = [42, 2025, 777]\n",
        "IMG_SIZE = 96\n",
        "N_FOLDS = 5\n",
        "EPOCHS = 12\n",
        "BATCH_SIZE = 256\n",
        "WORKERS = 2\n",
        "LR_BACKBONE = 1e-4\n",
        "LR_HEAD = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "EMA_DECAY = 0.999\n",
        "EARLY_VAL_THRESH = 0.99990\n",
        "\n",
        "def set_seed(seed: int):\n",
        "    import numpy as _np, random as _random, torch as _torch\n",
        "    _random.seed(seed); _np.random.seed(seed); _torch.manual_seed(seed); _torch.cuda.manual_seed_all(seed)\n",
        "    _torch.backends.cudnn.deterministic = True\n",
        "    _torch.backends.cudnn.benchmark = False\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_transforms(train=True):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.ShiftScaleRotate(shift_limit=0.08, scale_limit=0.10, rotate_limit=10, border_mode=0, p=0.5),\n",
        "            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.0, p=0.2),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "\n",
        "class TTADataset(Dataset):\n",
        "    def __init__(self, img_dir, df, mode='train', rot_k=0, hflip=False):\n",
        "        self.img_dir = Path(img_dir); self.df = df.reset_index(drop=True)\n",
        "        self.mode = mode; self.rot_k = rot_k; self.hflip = hflip\n",
        "        self.tfms = get_transforms(train=(mode=='train'))\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['id']\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert('RGB')\n",
        "            img = np.array(im)\n",
        "        if self.rot_k:\n",
        "            img = np.ascontiguousarray(np.rot90(img, k=self.rot_k))\n",
        "        if self.hflip:\n",
        "            img = np.ascontiguousarray(img[:, ::-1, :])\n",
        "        aug = self.tfms(image=img)\n",
        "        x = torch.from_numpy(aug['image'].transpose(2,0,1)).float()\n",
        "        if self.mode in ('train','valid'):\n",
        "            y = torch.tensor(row['has_cactus'], dtype=torch.float32)\n",
        "            return x, y\n",
        "        return x, row['id']\n",
        "\n",
        "def build_model():\n",
        "    m = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    m.fc = nn.Linear(m.fc.in_features, 1)\n",
        "    return m\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params = list(model.fc.parameters())\n",
        "    backbone_params = [p for n,p in model.named_parameters() if not n.startswith('fc.')]\n",
        "    return torch.optim.AdamW([\n",
        "        {'params': backbone_params, 'lr': LR_BACKBONE},\n",
        "        {'params': head_params, 'lr': LR_HEAD},\n",
        "    ], weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=EMA_DECAY):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[n] = p.detach().clone()\n",
        "    def update(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if not p.requires_grad: continue\n",
        "            self.shadow[n].mul_(self.decay).add_(p.detach(), alpha=1.0 - self.decay)\n",
        "    def copy_to(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if n in self.shadow:\n",
        "                p.data.copy_(self.shadow[n].data)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, loss_fn, scaler, ema: EMA):\n",
        "    model.train(); total=0.0\n",
        "    for i,(x,y) in enumerate(loader):\n",
        "        x=x.to(DEVICE,non_blocking=True); y=y.to(DEVICE,non_blocking=True).view(-1,1)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
        "            logits=model(x); loss=loss_fn(logits,y)\n",
        "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
        "        if ema is not None: ema.update(model)\n",
        "        total += loss.item()*x.size(0)\n",
        "        if (i+1)%20==0: print(f\"  [train] step {i+1}/{len(loader)} loss={total/((i+1)*loader.batch_size):.4f}\", flush=True)\n",
        "    return total/len(loader.dataset)\n",
        "\n",
        "def valid_auc(model, loader):\n",
        "    model.eval(); preds=[]; targs=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x=x.to(DEVICE,non_blocking=True); y=y.view(-1,1)\n",
        "            logits=model(x)\n",
        "            preds.append(torch.sigmoid(logits).squeeze(1).cpu().numpy())\n",
        "            targs.append(y.squeeze(1).cpu().numpy())\n",
        "    preds=np.concatenate(preds); targs=np.concatenate(targs)\n",
        "    return roc_auc_score(targs,preds)\n",
        "\n",
        "def predict_logits(model, loader):\n",
        "    model.eval(); out_logits=[]; out_ids=[]\n",
        "    with torch.no_grad():\n",
        "        for x,ids in loader:\n",
        "            x=x.to(DEVICE,non_blocking=True)\n",
        "            logits=model(x).squeeze(1).cpu().numpy()\n",
        "            out_logits.append(logits); out_ids += list(ids)\n",
        "    return np.concatenate(out_logits), out_ids\n",
        "\n",
        "# Data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "groups_df = pd.read_csv('cv_groups.csv')\n",
        "train_df = train_df.merge(groups_df[['id','sha1']], on='id', how='left')\n",
        "test_ids = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "global_seed_logits = np.zeros(len(test_ids), dtype=np.float32)\n",
        "\n",
        "for seed in SEEDS:\n",
        "    print(f\"===== SEED {seed} =====\", flush=True)\n",
        "    set_seed(seed)\n",
        "    skf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n",
        "    seed_test_logits_accum = np.zeros(len(test_ids), dtype=np.float32)\n",
        "    bad_folds = 0\n",
        "    for fold,(tr_idx,va_idx) in enumerate(skf.split(train_df['id'], train_df['has_cactus'], groups=train_df['sha1'])):\n",
        "        print(f\"-- seed {seed} fold {fold+1}/{N_FOLDS}\")\n",
        "        tr_df = train_df.iloc[tr_idx].reset_index(drop=True)\n",
        "        va_df = train_df.iloc[va_idx].reset_index(drop=True)\n",
        "        tr_loader = DataLoader(TTADataset('train', tr_df, mode='train'), batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=True, drop_last=True)\n",
        "        va_loader = DataLoader(TTADataset('train', va_df, mode='valid'), batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "\n",
        "        model = build_model().to(DEVICE)\n",
        "        optimizer = make_optimizer(model)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
        "        loss_fn = nn.BCEWithLogitsLoss()\n",
        "        scaler = torch.amp.GradScaler('cuda', enabled=(DEVICE=='cuda'))\n",
        "        ema = EMA(model, decay=EMA_DECAY)\n",
        "\n",
        "        best_auc = -1.0; best_state=None; no_imp=0\n",
        "        for epoch in range(1, EPOCHS+1):\n",
        "            t0=time.time()\n",
        "            tr_loss = train_one_epoch(model, tr_loader, optimizer, loss_fn, scaler, ema)\n",
        "            # validate with EMA weights\n",
        "            bak = {k: v.detach().clone() for k,v in model.state_dict().items()}\n",
        "            ema.copy_to(model)\n",
        "            val_auc = valid_auc(model, va_loader)\n",
        "            # restore weights\n",
        "            model.load_state_dict(bak, strict=True)\n",
        "            scheduler.step()\n",
        "            lrs=[pg['lr'] for pg in optimizer.param_groups]\n",
        "            print(f\"[seed {seed} fold {fold}] epoch {epoch:02d} | tr_loss {tr_loss:.4f} | val_auc {val_auc:.6f} | lrs {lrs} | {time.time()-t0:.1f}s\")\n",
        "            if val_auc > best_auc: best_auc=val_auc; best_state={k:v.cpu() for k,v in ema.shadow.items()}; no_imp=0\n",
        "            else: no_imp+=1\n",
        "            if epoch==3 and val_auc < EARLY_VAL_THRESH:\n",
        "                bad_folds += 1\n",
        "                print(f\"[seed {seed} fold {fold}] early abort due to low AUC at epoch 3: {val_auc:.6f}\")\n",
        "                break\n",
        "            if no_imp>=3:\n",
        "                print(f\"[seed {seed} fold {fold}] early stop at epoch {epoch}\")\n",
        "                break\n",
        "        if bad_folds >= 2:\n",
        "            print(f\"[seed {seed}] aborting seed due to {bad_folds} bad folds\")\n",
        "            break\n",
        "        # load best EMA state to model\n",
        "        model.load_state_dict({k: v.to(DEVICE) for k,v in best_state.items()}, strict=False)\n",
        "        # TTA D8 logits\n",
        "        tta_logits_sum = np.zeros(len(test_ids), dtype=np.float32)\n",
        "        for rot_k in (0,1,2,3):\n",
        "            for hf in (False, True):\n",
        "                ds = TTADataset('test', test_ids, mode='test', rot_k=rot_k, hflip=hf)\n",
        "                dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "                logits, ids = predict_logits(model, dl)\n",
        "                tta_logits_sum += logits.astype(np.float32)\n",
        "        fold_logits = tta_logits_sum / 8.0\n",
        "        seed_test_logits_accum += fold_logits\n",
        "        print(f\"[seed {seed} fold {fold}] D8 inference done; best val AUC {best_auc:.6f}\")\n",
        "        del model, optimizer, loss_fn, scaler, tr_loader, va_loader\n",
        "        gc.collect(); torch.cuda.empty_cache()\n",
        "    # average across folds for this seed\n",
        "    if bad_folds < 2 and np.any(seed_test_logits_accum!=0):\n",
        "        seed_avg_logits = seed_test_logits_accum / N_FOLDS\n",
        "        global_seed_logits += seed_avg_logits\n",
        "        print(f\"[seed {seed}] added to ensemble.\")\n",
        "    else:\n",
        "        print(f\"[seed {seed}] skipped in ensemble due to insufficient folds.\")\n",
        "\n",
        "# average across seeds\n",
        "n_seeds_used = len(SEEDS)\n",
        "avg_logits = global_seed_logits / n_seeds_used\n",
        "test_pred = 1.0 / (1.0 + np.exp(-avg_logits))\n",
        "\n",
        "# Exact-hash overrides (should be zero)\n",
        "with open('train_sha1_label_map.json', 'r') as f:\n",
        "    sha1_to_label = json.load(f)\n",
        "test_hash_df = pd.read_csv('test_hashes.csv')\n",
        "lookup = test_hash_df[['id','sha1']].copy()\n",
        "lookup['label_from_train'] = lookup['sha1'].map(sha1_to_label).astype('float32')\n",
        "overrides = lookup['label_from_train'].notna().sum()\n",
        "print(f\"[multi-seed] exact-hash overrides in test: {overrides}\")\n",
        "\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub = sub.merge(lookup[['id','label_from_train']], on='id', how='left')\n",
        "sub['pred'] = test_pred\n",
        "sub['has_cactus'] = np.where(sub['label_from_train'].notna(), sub['label_from_train'], sub['pred'])\n",
        "submission = sub[['id','has_cactus']].copy()\n",
        "submission.to_csv('submission_seeds_d8.csv', index=False)\n",
        "print('Saved submission_seeds_d8.csv with shape', submission.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== SEED 42 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- seed 42 fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 42 fold 0] epoch 01 | tr_loss 0.0890 | val_auc 0.526545 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 42 fold 0] epoch 02 | tr_loss 0.0164 | val_auc 0.619454 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 42 fold 0] epoch 03 | tr_loss 0.0080 | val_auc 0.778835 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.5s\n[seed 42 fold 0] early abort due to low AUC at epoch 3: 0.778835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 42 fold 0] D8 inference done; best val AUC 0.778835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- seed 42 fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 42 fold 1] epoch 01 | tr_loss 0.0769 | val_auc 0.476950 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 42 fold 1] epoch 02 | tr_loss 0.0132 | val_auc 0.685562 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 42 fold 1] epoch 03 | tr_loss 0.0079 | val_auc 0.842271 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.4s\n[seed 42 fold 1] early abort due to low AUC at epoch 3: 0.842271\n[seed 42] aborting seed due to 2 bad folds\n[seed 42] skipped in ensemble due to insufficient folds.\n===== SEED 2025 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- seed 2025 fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 2025 fold 0] epoch 01 | tr_loss 0.0862 | val_auc 0.522217 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 2025 fold 0] epoch 02 | tr_loss 0.0112 | val_auc 0.668951 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 2025 fold 0] epoch 03 | tr_loss 0.0119 | val_auc 0.740689 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.5s\n[seed 2025 fold 0] early abort due to low AUC at epoch 3: 0.740689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 2025 fold 0] D8 inference done; best val AUC 0.740689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- seed 2025 fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 2025 fold 1] epoch 01 | tr_loss 0.0832 | val_auc 0.431799 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 2025 fold 1] epoch 02 | tr_loss 0.0144 | val_auc 0.590777 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 2025 fold 1] epoch 03 | tr_loss 0.0113 | val_auc 0.729468 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.5s\n[seed 2025 fold 1] early abort due to low AUC at epoch 3: 0.729468\n[seed 2025] aborting seed due to 2 bad folds\n[seed 2025] skipped in ensemble due to insufficient folds.\n===== SEED 777 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- seed 777 fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 777 fold 0] epoch 01 | tr_loss 0.0835 | val_auc 0.410984 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 777 fold 0] epoch 02 | tr_loss 0.0165 | val_auc 0.554892 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 777 fold 0] epoch 03 | tr_loss 0.0109 | val_auc 0.730270 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.5s\n[seed 777 fold 0] early abort due to low AUC at epoch 3: 0.730270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 777 fold 0] D8 inference done; best val AUC 0.730270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- seed 777 fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 777 fold 1] epoch 01 | tr_loss 0.0878 | val_auc 0.406898 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 777 fold 1] epoch 02 | tr_loss 0.0170 | val_auc 0.507475 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[seed 777 fold 1] epoch 03 | tr_loss 0.0092 | val_auc 0.616131 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.5s\n[seed 777 fold 1] early abort due to low AUC at epoch 3: 0.616131\n[seed 777] aborting seed due to 2 bad folds\n[seed 777] skipped in ensemble due to insufficient folds.\n[multi-seed] exact-hash overrides in test: 0\nSaved submission_seeds_d8.csv with shape (3325, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "588f76cf-a429-448d-b6d5-8a6dba6abcac",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# phash nearest-neighbor overrides to improve AUC without retraining\n",
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "import json, time\n",
        "\n",
        "def phash_hex_to_uint64(hexstr: str) -> np.uint64:\n",
        "    return np.uint64(int(hexstr, 16))\n",
        "\n",
        "# byte popcount lookup\n",
        "POPCOUNT = np.array([bin(i).count('1') for i in range(256)], dtype=np.uint8)\n",
        "\n",
        "def hamming_uint64(a: np.ndarray, b: np.uint64) -> np.ndarray:\n",
        "    # a: (N,) uint64, b: scalar uint64\n",
        "    x = np.bitwise_xor(a, b).view(np.uint8).reshape(-1, 8)  # 8 bytes\n",
        "    return POPCOUNT[x].sum(axis=1).astype(np.uint8)\n",
        "\n",
        "# Load phashes\n",
        "train_hash_df = pd.read_csv('train_hashes.csv')  # columns: id, sha1, phash, has_cactus\n",
        "test_hash_df = pd.read_csv('test_hashes.csv')    # columns: id, sha1, phash\n",
        "sub = pd.read_csv('submission_d8.csv')  # strong base predictions\n",
        "\n",
        "# Prepare arrays\n",
        "train_codes = np.array([phash_hex_to_uint64(h) for h in train_hash_df['phash'].values], dtype=np.uint64)\n",
        "train_labels = train_hash_df['has_cactus'].astype(np.uint8).values\n",
        "test_codes = np.array([phash_hex_to_uint64(h) for h in test_hash_df['phash'].values], dtype=np.uint64)\n",
        "\n",
        "# Brute-force nearest neighbor by Hamming for each test\n",
        "t0 = time.time()\n",
        "min_dists = np.empty(len(test_codes), dtype=np.uint8)\n",
        "nearest_idx = np.empty(len(test_codes), dtype=np.int32)\n",
        "for i, code in enumerate(test_codes):\n",
        "    dists = hamming_uint64(train_codes, code)\n",
        "    md = dists.min()\n",
        "    min_dists[i] = md\n",
        "    # pick nearest; tie-break by majority label among equals\n",
        "    idxs = np.where(dists == md)[0]\n",
        "    if len(idxs) == 1:\n",
        "        nearest_idx[i] = idxs[0]\n",
        "    else:\n",
        "        # majority label; if tie, pick first\n",
        "        lbls = train_labels[idxs]\n",
        "        maj = 1 if lbls.mean() >= 0.5 else 0\n",
        "        # choose first index with majority label\n",
        "        choose = idxs[np.where(lbls == maj)[0][0]]\n",
        "        nearest_idx[i] = choose\n",
        "    if (i+1) % 500 == 0:\n",
        "        print(f\"[phash NN] {i+1}/{len(test_codes)} done in {time.time()-t0:.1f}s\", flush=True)\n",
        "print(f\"[phash NN] completed in {time.time()-t0:.1f}s\")\n",
        "\n",
        "# Simple histogram to inspect distances\n",
        "hist = np.bincount(min_dists.astype(int), minlength=65)\n",
        "print('Hamming distance counts (first 10):', {i:int(hist[i]) for i in range(10)})\n",
        "\n",
        "# Apply overrides for close matches (threshold tuned; start with <=3)\n",
        "THRESH = 3\n",
        "override_mask = min_dists <= THRESH\n",
        "n_override = int(override_mask.sum())\n",
        "print(f\"[phash override] applying label override for {n_override}/{len(test_codes)} tests with dist <= {THRESH}\")\n",
        "\n",
        "override_labels = train_labels[nearest_idx].astype(np.float32)\n",
        "\n",
        "out = sub.copy()\n",
        "out = out.merge(test_hash_df[['id']].copy(), on='id', how='right')  # ensure same order as test_hash_df\n",
        "assert len(out) == len(test_hash_df), 'Submission/test id mismatch'\n",
        "\n",
        "new_probs = out['has_cactus'].values.astype(np.float32)\n",
        "new_probs[override_mask] = override_labels[override_mask]\n",
        "out['has_cactus'] = new_probs\n",
        "out[['id','has_cactus']].to_csv('submission_phash_d8.csv', index=False)\n",
        "print('Saved submission_phash_d8.csv with shape', out.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[phash NN] 500/3325 done in 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[phash NN] 1000/3325 done in 0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[phash NN] 1500/3325 done in 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[phash NN] 2000/3325 done in 1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[phash NN] 2500/3325 done in 1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[phash NN] 3000/3325 done in 2.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[phash NN] completed in 2.3s\nHamming distance counts (first 10): {0: 0, 1: 0, 2: 0, 3: 0, 4: 2, 5: 0, 6: 13, 7: 0, 8: 39, 9: 0}\n[phash override] applying label override for 0/3325 tests with dist <= 3\nSaved submission_phash_d8.csv with shape (3325, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "d7e717f2-f6b5-45ad-bc27-2b8f66a2d4d2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 128px ResNet18 with Dihedral-8 TTA (logit-avg over TTAs and folds); produce submission_128_d8.csv\n",
        "import os, time, json, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "CACHE_DIR = Path('./.model_cache'); CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['TORCH_HOME'] = str(CACHE_DIR)\n",
        "os.environ['XDG_CACHE_HOME'] = str(CACHE_DIR)\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "SEED = 42\n",
        "IMG_SIZE = 128\n",
        "N_FOLDS = 5\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 128\n",
        "WORKERS = 2\n",
        "LR_BACKBONE = 1e-4\n",
        "LR_HEAD = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "def set_seed(seed=SEED):\n",
        "    import numpy as _np, random as _random, torch as _torch\n",
        "    _random.seed(seed); _np.random.seed(seed); _torch.manual_seed(seed); _torch.cuda.manual_seed_all(seed)\n",
        "    _torch.backends.cudnn.deterministic = True\n",
        "    _torch.backends.cudnn.benchmark = False\n",
        "set_seed()\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_transforms(train=True):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.ShiftScaleRotate(shift_limit=0.08, scale_limit=0.10, rotate_limit=10, border_mode=0, p=0.5),\n",
        "            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.0, p=0.2),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "\n",
        "class TtaD8Dataset(Dataset):\n",
        "    def __init__(self, img_dir, df, mode='train', rot_k=0, hflip=False):\n",
        "        self.img_dir = Path(img_dir); self.df = df.reset_index(drop=True)\n",
        "        self.mode = mode; self.rot_k = rot_k; self.hflip = hflip\n",
        "        self.tfms = get_transforms(train=(mode=='train'))\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['id']\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert('RGB')\n",
        "            img = np.array(im)\n",
        "        if self.rot_k:\n",
        "            img = np.ascontiguousarray(np.rot90(img, k=self.rot_k))\n",
        "        if self.hflip:\n",
        "            img = np.ascontiguousarray(img[:, ::-1, :])\n",
        "        aug = self.tfms(image=img)\n",
        "        x = torch.from_numpy(aug['image'].transpose(2,0,1)).float()\n",
        "        if self.mode in ('train','valid'):\n",
        "            y = torch.tensor(row['has_cactus'], dtype=torch.float32)\n",
        "            return x, y\n",
        "        return x, row['id']\n",
        "\n",
        "def build_model():\n",
        "    m = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    m.fc = nn.Linear(m.fc.in_features, 1)\n",
        "    return m\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params = list(model.fc.parameters())\n",
        "    backbone_params = [p for n,p in model.named_parameters() if not n.startswith('fc.')]\n",
        "    return torch.optim.AdamW([\n",
        "        {'params': backbone_params, 'lr': LR_BACKBONE},\n",
        "        {'params': head_params, 'lr': LR_HEAD},\n",
        "    ], weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, loss_fn, scaler):\n",
        "    model.train(); total=0.0\n",
        "    for i,(x,y) in enumerate(loader):\n",
        "        x=x.to(DEVICE,non_blocking=True); y=y.to(DEVICE,non_blocking=True).view(-1,1)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
        "            logits=model(x); loss=loss_fn(logits,y)\n",
        "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
        "        total += loss.item()*x.size(0)\n",
        "        if (i+1)%20==0: print(f\"  [train] step {i+1}/{len(loader)} loss={total/((i+1)*loader.batch_size):.4f}\", flush=True)\n",
        "    return total/len(loader.dataset)\n",
        "\n",
        "def valid_auc(model, loader):\n",
        "    model.eval(); preds=[]; targs=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x=x.to(DEVICE,non_blocking=True); y=y.view(-1,1)\n",
        "            logits=model(x)\n",
        "            preds.append(torch.sigmoid(logits).squeeze(1).cpu().numpy())\n",
        "            targs.append(y.squeeze(1).cpu().numpy())\n",
        "    preds=np.concatenate(preds); targs=np.concatenate(targs)\n",
        "    return roc_auc_score(targs,preds)\n",
        "\n",
        "def predict_logits(model, loader):\n",
        "    model.eval(); out_logits=[]; out_ids=[]\n",
        "    with torch.no_grad():\n",
        "        for x,ids in loader:\n",
        "            x=x.to(DEVICE,non_blocking=True)\n",
        "            logits=model(x).squeeze(1).cpu().numpy()\n",
        "            out_logits.append(logits); out_ids += list(ids)\n",
        "    return np.concatenate(out_logits), out_ids\n",
        "\n",
        "# Data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "groups_df = pd.read_csv('cv_groups.csv')\n",
        "train_df = train_df.merge(groups_df[['id','sha1']], on='id', how='left')\n",
        "test_ids = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "skf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "test_logit_accum = np.zeros(len(test_ids), dtype=np.float32)\n",
        "\n",
        "fold_aucs=[]\n",
        "for fold,(tr_idx,va_idx) in enumerate(skf.split(train_df['id'], train_df['has_cactus'], groups=train_df['sha1'])):\n",
        "    print(f\"===== 128px Fold {fold+1}/{N_FOLDS} =====\")\n",
        "    tr_df = train_df.iloc[tr_idx].reset_index(drop=True)\n",
        "    va_df = train_df.iloc[va_idx].reset_index(drop=True)\n",
        "    tr_loader = DataLoader(TtaD8Dataset('train', tr_df, mode='train'), batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=True, drop_last=True)\n",
        "    va_loader = DataLoader(TtaD8Dataset('train', va_df, mode='valid'), batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(DEVICE)\n",
        "    optimizer = make_optimizer(model)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(DEVICE=='cuda'))\n",
        "\n",
        "    best_auc=-1.0; best_state=None; no_imp=0\n",
        "    for epoch in range(1,EPOCHS+1):\n",
        "        t0=time.time()\n",
        "        tr_loss = train_one_epoch(model, tr_loader, optimizer, loss_fn, scaler)\n",
        "        val_auc = valid_auc(model, va_loader)\n",
        "        scheduler.step()\n",
        "        lrs=[pg['lr'] for pg in optimizer.param_groups]\n",
        "        print(f\"[fold {fold}] epoch {epoch:02d} | tr_loss {tr_loss:.4f} | val_auc {val_auc:.6f} | lrs {lrs} | {time.time()-t0:.1f}s\", flush=True)\n",
        "        if val_auc > best_auc: best_auc=val_auc; best_state={k:v.cpu() for k,v in model.state_dict().items()}; no_imp=0\n",
        "        else: no_imp+=1\n",
        "        if no_imp>=3: print(f\"[fold {fold}] early stop at {epoch}\"); break\n",
        "    print(f\"[fold {fold}] best val AUC: {best_auc:.6f}\")\n",
        "    fold_aucs.append(best_auc)\n",
        "    model.load_state_dict({k:v.to(DEVICE) for k,v in best_state.items()}, strict=True)\n",
        "\n",
        "    # Dihedral-8 TTA logits\n",
        "    tta_logits_sum = np.zeros(len(test_ids), dtype=np.float32)\n",
        "    for rot_k in (0,1,2,3):\n",
        "        for hf in (False, True):\n",
        "            ds = TtaD8Dataset('test', test_ids, mode='test', rot_k=rot_k, hflip=hf)\n",
        "            dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "            logits, ids = predict_logits(model, dl)\n",
        "            tta_logits_sum += logits.astype(np.float32)\n",
        "    test_logit_accum += (tta_logits_sum / 8.0)\n",
        "    print(f\"[fold {fold}] 128px D8 TTA done\")\n",
        "    del model, optimizer, loss_fn, scaler, tr_loader, va_loader\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "# Average across folds -> logits then sigmoid\n",
        "avg_test_logits = test_logit_accum / N_FOLDS\n",
        "np.save('logits_128.npy', avg_test_logits)\n",
        "test_pred = 1.0 / (1.0 + np.exp(-avg_test_logits))\n",
        "\n",
        "# Save submission\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub['has_cactus'] = test_pred.astype(np.float32)\n",
        "sub.to_csv('submission_128_d8.csv', index=False)\n",
        "print('Saved submission_128_d8.csv; fold AUCs:', [f\"{a:.6f}\" for a in fold_aucs])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 128px Fold 1/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.1567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 01 | tr_loss 0.0528 | val_auc 0.999918 | lrs [9.779754323328192e-05, 0.0009757729755661011] | 8.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 02 | tr_loss 0.0139 | val_auc 0.999987 | lrs [9.140576474687264e-05, 0.000905463412215599] | 8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 03 | tr_loss 0.0079 | val_auc 0.999982 | lrs [8.14503363531613e-05, 0.0007959536998847742] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 04 | tr_loss 0.0059 | val_auc 0.999984 | lrs [6.890576474687264e-05, 0.000657963412215599] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 05 | tr_loss 0.0043 | val_auc 0.999995 | lrs [5.500000000000001e-05, 0.000505] | 8.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 06 | tr_loss 0.0037 | val_auc 0.999992 | lrs [4.109423525312737e-05, 0.0003520365877844011] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 07 | tr_loss 0.0017 | val_auc 0.999989 | lrs [2.8549663646838717e-05, 0.00021404630011522585] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 08 | tr_loss 0.0011 | val_auc 0.999994 | lrs [1.8594235253127375e-05, 0.00010453658778440107] | 8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] early stop at 8\n[fold 0] best val AUC: 0.999995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] 128px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 128px Fold 2/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.1540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 01 | tr_loss 0.0536 | val_auc 0.999803 | lrs [9.779754323328192e-05, 0.0009757729755661011] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 02 | tr_loss 0.0146 | val_auc 0.999967 | lrs [9.140576474687264e-05, 0.000905463412215599] | 9.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 03 | tr_loss 0.0098 | val_auc 0.999972 | lrs [8.14503363531613e-05, 0.0007959536998847742] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 04 | tr_loss 0.0052 | val_auc 0.999988 | lrs [6.890576474687264e-05, 0.000657963412215599] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 05 | tr_loss 0.0042 | val_auc 0.999971 | lrs [5.500000000000001e-05, 0.000505] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 06 | tr_loss 0.0044 | val_auc 0.999993 | lrs [4.109423525312737e-05, 0.0003520365877844011] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 07 | tr_loss 0.0038 | val_auc 0.999992 | lrs [2.8549663646838717e-05, 0.00021404630011522585] | 8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 08 | tr_loss 0.0026 | val_auc 0.999979 | lrs [1.8594235253127375e-05, 0.00010453658778440107] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 09 | tr_loss 0.0012 | val_auc 0.999987 | lrs [1.2202456766718093e-05, 3.4227024433899005e-05] | 8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] early stop at 9\n[fold 1] best val AUC: 0.999993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] 128px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 128px Fold 3/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.1707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.1033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 01 | tr_loss 0.0615 | val_auc 0.999946 | lrs [9.779754323328192e-05, 0.0009757729755661011] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 02 | tr_loss 0.0118 | val_auc 0.999997 | lrs [9.140576474687264e-05, 0.000905463412215599] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 03 | tr_loss 0.0092 | val_auc 0.999989 | lrs [8.14503363531613e-05, 0.0007959536998847742] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 04 | tr_loss 0.0084 | val_auc 0.999995 | lrs [6.890576474687264e-05, 0.000657963412215599] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 05 | tr_loss 0.0057 | val_auc 0.999993 | lrs [5.500000000000001e-05, 0.000505] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] early stop at 5\n[fold 2] best val AUC: 0.999997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] 128px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 128px Fold 4/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.1905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.1108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 01 | tr_loss 0.0609 | val_auc 0.999981 | lrs [9.779754323328192e-05, 0.0009757729755661011] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 02 | tr_loss 0.0129 | val_auc 0.999979 | lrs [9.140576474687264e-05, 0.000905463412215599] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 03 | tr_loss 0.0081 | val_auc 0.999966 | lrs [8.14503363531613e-05, 0.0007959536998847742] | 8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 04 | tr_loss 0.0074 | val_auc 0.999995 | lrs [6.890576474687264e-05, 0.000657963412215599] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 05 | tr_loss 0.0051 | val_auc 0.999999 | lrs [5.500000000000001e-05, 0.000505] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 06 | tr_loss 0.0039 | val_auc 0.999983 | lrs [4.109423525312737e-05, 0.0003520365877844011] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 07 | tr_loss 0.0031 | val_auc 0.999998 | lrs [2.8549663646838717e-05, 0.00021404630011522585] | 8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 08 | tr_loss 0.0016 | val_auc 0.999998 | lrs [1.8594235253127375e-05, 0.00010453658778440107] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] early stop at 8\n[fold 3] best val AUC: 0.999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] 128px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 128px Fold 5/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.1611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.1027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 01 | tr_loss 0.0599 | val_auc 0.999963 | lrs [9.779754323328192e-05, 0.0009757729755661011] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 02 | tr_loss 0.0138 | val_auc 0.999982 | lrs [9.140576474687264e-05, 0.000905463412215599] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 03 | tr_loss 0.0106 | val_auc 0.999997 | lrs [8.14503363531613e-05, 0.0007959536998847742] | 8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 04 | tr_loss 0.0085 | val_auc 0.999999 | lrs [6.890576474687264e-05, 0.000657963412215599] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 05 | tr_loss 0.0058 | val_auc 0.999999 | lrs [5.500000000000001e-05, 0.000505] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 06 | tr_loss 0.0027 | val_auc 1.000000 | lrs [4.109423525312737e-05, 0.0003520365877844011] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 07 | tr_loss 0.0025 | val_auc 1.000000 | lrs [2.8549663646838717e-05, 0.00021404630011522585] | 8.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 08 | tr_loss 0.0031 | val_auc 1.000000 | lrs [1.8594235253127375e-05, 0.00010453658778440107] | 8.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/88 loss=0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/88 loss=0.0039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 60/88 loss=0.0031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 80/88 loss=0.0025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 09 | tr_loss 0.0027 | val_auc 1.000000 | lrs [1.2202456766718093e-05, 3.4227024433899005e-05] | 8.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] early stop at 9\n[fold 4] best val AUC: 1.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] 128px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_128_d8.csv; fold AUCs: ['0.999995', '0.999993', '0.999997', '0.999999', '1.000000']\n"
          ]
        }
      ]
    },
    {
      "id": "b8dd7800-1002-40f9-ad06-b408fff21c2f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Blend 96px D8 and 128px D8 via logit averaging; submit\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def logit(p):\n",
        "    p = np.clip(p, 1e-6, 1-1e-6).astype(np.float64)\n",
        "    return np.log(p/(1.0-p))\n",
        "\n",
        "# Load 96px preds and invert to logits\n",
        "sub96 = pd.read_csv('submission_d8.csv')\n",
        "p96 = sub96['has_cactus'].values.astype(np.float32)\n",
        "logits96 = logit(p96)\n",
        "\n",
        "# Load 128px logits saved earlier\n",
        "logits128 = np.load('logits_128.npy')\n",
        "assert logits128.shape[0] == logits96.shape[0], 'Length mismatch between 96 and 128 logits'\n",
        "\n",
        "# Average logits and sigmoid once\n",
        "avg_logits = 0.5 * (logits96 + logits128.astype(np.float64))\n",
        "blend_pred = sigmoid(avg_logits).astype(np.float32)\n",
        "\n",
        "# Save blended submission\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub['has_cactus'] = blend_pred\n",
        "sub.to_csv('submission_blend_96_128.csv', index=False)\n",
        "print('Saved submission_blend_96_128.csv with shape', sub.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_blend_96_128.csv with shape (3325, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "b585b82b-9d4c-4007-90f5-df32e7ee1c6c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# phash NN overrides on blended submission with thresholds 4 and 5\n",
        "import pandas as pd, numpy as np, time\n",
        "\n",
        "def phash_hex_to_uint64(hexstr: str) -> np.uint64:\n",
        "    return np.uint64(int(hexstr, 16))\n",
        "\n",
        "POPCOUNT = np.array([bin(i).count('1') for i in range(256)], dtype=np.uint8)\n",
        "\n",
        "def hamming_uint64(a: np.ndarray, b: np.uint64) -> np.ndarray:\n",
        "    x = np.bitwise_xor(a, b).view(np.uint8).reshape(-1, 8)\n",
        "    return POPCOUNT[x].sum(axis=1).astype(np.uint8)\n",
        "\n",
        "train_hash_df = pd.read_csv('train_hashes.csv')\n",
        "test_hash_df = pd.read_csv('test_hashes.csv')\n",
        "base = pd.read_csv('submission_blend_96_128.csv')\n",
        "\n",
        "train_codes = np.array([phash_hex_to_uint64(h) for h in train_hash_df['phash'].values], dtype=np.uint64)\n",
        "train_labels = train_hash_df['has_cactus'].astype(np.uint8).values\n",
        "test_codes = np.array([phash_hex_to_uint64(h) for h in test_hash_df['phash'].values], dtype=np.uint64)\n",
        "\n",
        "t0 = time.time()\n",
        "min_dists = np.empty(len(test_codes), dtype=np.uint8)\n",
        "nearest_idx = np.empty(len(test_codes), dtype=np.int32)\n",
        "for i, code in enumerate(test_codes):\n",
        "    dists = hamming_uint64(train_codes, code)\n",
        "    md = dists.min()\n",
        "    min_dists[i] = md\n",
        "    idxs = np.where(dists == md)[0]\n",
        "    if len(idxs) == 1:\n",
        "        nearest_idx[i] = idxs[0]\n",
        "    else:\n",
        "        lbls = train_labels[idxs]\n",
        "        maj = 1 if lbls.mean() >= 0.5 else 0\n",
        "        choose = idxs[np.where(lbls == maj)[0][0]]\n",
        "        nearest_idx[i] = choose\n",
        "print(f\"[phash NN] computed in {time.time()-t0:.2f}s; min_dists<=9 counts:\", {i:int((min_dists==i).sum()) for i in range(10)})\n",
        "\n",
        "def apply_override(base_df: pd.DataFrame, thresh: int, out_path: str):\n",
        "    out = base_df.merge(test_hash_df[['id']], on='id', how='right')\n",
        "    probs = out['has_cactus'].values.astype(np.float32)\n",
        "    mask = (min_dists <= thresh)\n",
        "    if mask.any():\n",
        "        probs[mask] = train_labels[nearest_idx][mask].astype(np.float32)\n",
        "    out['has_cactus'] = probs\n",
        "    out[['id','has_cactus']].to_csv(out_path, index=False)\n",
        "    print(f\"Saved {out_path} | overrides: {int(mask.sum())}\")\n",
        "\n",
        "apply_override(base, 4, 'submission_phash4_blend.csv')\n",
        "apply_override(base, 5, 'submission_phash5_blend.csv')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[phash NN] computed in 2.33s; min_dists<=9 counts: {0: 0, 1: 0, 2: 0, 3: 0, 4: 2, 5: 0, 6: 13, 7: 0, 8: 39, 9: 0}\nSaved submission_phash4_blend.csv | overrides: 2\nSaved submission_phash5_blend.csv | overrides: 2\n"
          ]
        }
      ]
    },
    {
      "id": "bfca4eed-5123-4bdf-a8c6-8ce8c5692b41",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 96px ResNet34 with Dihedral-8 TTA (logit-avg over TTAs and folds); save logits_34_96.npy and submission_34_96_d8.csv\n",
        "import os, time, json, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet34_Weights\n",
        "\n",
        "CACHE_DIR = Path('./.model_cache'); CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['TORCH_HOME'] = str(CACHE_DIR)\n",
        "os.environ['XDG_CACHE_HOME'] = str(CACHE_DIR)\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "SEED = 42\n",
        "IMG_SIZE = 96\n",
        "N_FOLDS = 5\n",
        "EPOCHS = 12\n",
        "BATCH_SIZE = 256\n",
        "WORKERS = 2\n",
        "LR_BACKBONE = 1e-4\n",
        "LR_HEAD = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "def set_seed(seed=SEED):\n",
        "    import numpy as _np, random as _random, torch as _torch\n",
        "    _random.seed(seed); _np.random.seed(seed); _torch.manual_seed(seed); _torch.cuda.manual_seed_all(seed)\n",
        "    _torch.backends.cudnn.deterministic = True\n",
        "    _torch.backends.cudnn.benchmark = False\n",
        "set_seed()\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_transforms(train=True):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.ShiftScaleRotate(shift_limit=0.08, scale_limit=0.10, rotate_limit=10, border_mode=0, p=0.5),\n",
        "            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.0, p=0.2),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "\n",
        "class TtaD8Dataset34(Dataset):\n",
        "    def __init__(self, img_dir, df, mode='train', rot_k=0, hflip=False):\n",
        "        self.img_dir = Path(img_dir); self.df = df.reset_index(drop=True)\n",
        "        self.mode = mode; self.rot_k = rot_k; self.hflip = hflip\n",
        "        self.tfms = get_transforms(train=(mode=='train'))\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['id']\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert('RGB')\n",
        "            img = np.array(im)\n",
        "        if self.rot_k:\n",
        "            img = np.ascontiguousarray(np.rot90(img, k=self.rot_k))\n",
        "        if self.hflip:\n",
        "            img = np.ascontiguousarray(img[:, ::-1, :])\n",
        "        aug = self.tfms(image=img)\n",
        "        x = torch.from_numpy(aug['image'].transpose(2,0,1)).float()\n",
        "        if self.mode in ('train','valid'):\n",
        "            y = torch.tensor(row['has_cactus'], dtype=torch.float32)\n",
        "            return x, y\n",
        "        return x, row['id']\n",
        "\n",
        "def build_model():\n",
        "    m = models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
        "    m.fc = nn.Linear(m.fc.in_features, 1)\n",
        "    return m\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params = list(model.fc.parameters())\n",
        "    backbone_params = [p for n,p in model.named_parameters() if not n.startswith('fc.')]\n",
        "    return torch.optim.AdamW([\n",
        "        {'params': backbone_params, 'lr': LR_BACKBONE},\n",
        "        {'params': head_params, 'lr': LR_HEAD},\n",
        "    ], weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, loss_fn, scaler):\n",
        "    model.train(); total=0.0\n",
        "    for i,(x,y) in enumerate(loader):\n",
        "        x=x.to(DEVICE,non_blocking=True); y=y.to(DEVICE,non_blocking=True).view(-1,1)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
        "            logits=model(x); loss=loss_fn(logits,y)\n",
        "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
        "        total += loss.item()*x.size(0)\n",
        "        if (i+1)%20==0: print(f\"  [train] step {i+1}/{len(loader)} loss={total/((i+1)*loader.batch_size):.4f}\", flush=True)\n",
        "    return total/len(loader.dataset)\n",
        "\n",
        "def valid_auc(model, loader):\n",
        "    model.eval(); preds=[]; targs=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x=x.to(DEVICE,non_blocking=True); y=y.view(-1,1)\n",
        "            logits=model(x)\n",
        "            preds.append(torch.sigmoid(logits).squeeze(1).cpu().numpy())\n",
        "            targs.append(y.squeeze(1).cpu().numpy())\n",
        "    preds=np.concatenate(preds); targs=np.concatenate(targs)\n",
        "    return roc_auc_score(targs,preds)\n",
        "\n",
        "def predict_logits(model, loader):\n",
        "    model.eval(); out_logits=[]; out_ids=[]\n",
        "    with torch.no_grad():\n",
        "        for x,ids in loader:\n",
        "            x=x.to(DEVICE,non_blocking=True)\n",
        "            logits=model(x).squeeze(1).cpu().numpy()\n",
        "            out_logits.append(logits); out_ids += list(ids)\n",
        "    return np.concatenate(out_logits), out_ids\n",
        "\n",
        "# Data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "groups_df = pd.read_csv('cv_groups.csv')\n",
        "train_df = train_df.merge(groups_df[['id','sha1']], on='id', how='left')\n",
        "test_ids = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "skf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "test_logit_accum = np.zeros(len(test_ids), dtype=np.float32)\n",
        "\n",
        "fold_aucs=[]\n",
        "for fold,(tr_idx,va_idx) in enumerate(skf.split(train_df['id'], train_df['has_cactus'], groups=train_df['sha1'])):\n",
        "    print(f\"===== ResNet34 96px Fold {fold+1}/{N_FOLDS} =====\")\n",
        "    tr_df = train_df.iloc[tr_idx].reset_index(drop=True)\n",
        "    va_df = train_df.iloc[va_idx].reset_index(drop=True)\n",
        "    tr_loader = DataLoader(TtaD8Dataset34('train', tr_df, mode='train'), batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=True, drop_last=True)\n",
        "    va_loader = DataLoader(TtaD8Dataset34('train', va_df, mode='valid'), batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(DEVICE)\n",
        "    optimizer = make_optimizer(model)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(DEVICE=='cuda'))\n",
        "\n",
        "    best_auc=-1.0; best_state=None; no_imp=0\n",
        "    for epoch in range(1,EPOCHS+1):\n",
        "        t0=time.time()\n",
        "        tr_loss = train_one_epoch(model, tr_loader, optimizer, loss_fn, scaler)\n",
        "        val_auc = valid_auc(model, va_loader)\n",
        "        scheduler.step()\n",
        "        lrs=[pg['lr'] for pg in optimizer.param_groups]\n",
        "        print(f\"[fold {fold}] epoch {epoch:02d} | tr_loss {tr_loss:.4f} | val_auc {val_auc:.6f} | lrs {lrs} | {time.time()-t0:.1f}s\", flush=True)\n",
        "        if val_auc > best_auc: best_auc=val_auc; best_state={k:v.cpu() for k,v in model.state_dict().items()}; no_imp=0\n",
        "        else: no_imp+=1\n",
        "        if no_imp>=3: print(f\"[fold {fold}] early stop at {epoch}\"); break\n",
        "    print(f\"[fold {fold}] best val AUC: {best_auc:.6f}\")\n",
        "    fold_aucs.append(best_auc)\n",
        "    model.load_state_dict({k:v.to(DEVICE) for k,v in best_state.items()}, strict=True)\n",
        "\n",
        "    # Dihedral-8 TTA logits\n",
        "    tta_logits_sum = np.zeros(len(test_ids), dtype=np.float32)\n",
        "    for rot_k in (0,1,2,3):\n",
        "        for hf in (False, True):\n",
        "            ds = TtaD8Dataset34('test', test_ids, mode='test', rot_k=rot_k, hflip=hf)\n",
        "            dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "            logits, ids = predict_logits(model, dl)\n",
        "            tta_logits_sum += logits.astype(np.float32)\n",
        "    test_logit_accum += (tta_logits_sum / 8.0)\n",
        "    print(f\"[fold {fold}] ResNet34 96px D8 TTA done\")\n",
        "    del model, optimizer, loss_fn, scaler, tr_loader, va_loader\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "# Average across folds -> logits then sigmoid\n",
        "avg_test_logits = test_logit_accum / N_FOLDS\n",
        "np.save('logits_34_96.npy', avg_test_logits)\n",
        "test_pred = 1.0 / (1.0 + np.exp(-avg_test_logits))\n",
        "\n",
        "# Save submission\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub['has_cactus'] = test_pred.astype(np.float32)\n",
        "sub.to_csv('submission_34_96_d8.csv', index=False)\n",
        "print('Saved submission_34_96_d8.csv; fold AUCs:', [f\"{a:.6f}\" for a in fold_aucs])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ResNet34 96px Fold 1/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to .model_cache/hub/checkpoints/resnet34-b627a593.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|\u2588         | 9.25M/83.3M [00:00<00:00, 96.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 01 | tr_loss 0.0733 | val_auc 0.999629 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 02 | tr_loss 0.0169 | val_auc 0.999957 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 03 | tr_loss 0.0082 | val_auc 0.999974 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 04 | tr_loss 0.0064 | val_auc 0.999993 | lrs [7.75e-05, 0.0007524999999999999] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 05 | tr_loss 0.0078 | val_auc 0.999992 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 06 | tr_loss 0.0036 | val_auc 0.999990 | lrs [5.5e-05, 0.000505] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 07 | tr_loss 0.0038 | val_auc 0.999984 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] early stop at 7\n[fold 0] best val AUC: 0.999993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] ResNet34 96px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ResNet34 96px Fold 2/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.1035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 01 | tr_loss 0.0963 | val_auc 0.999860 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 02 | tr_loss 0.0145 | val_auc 0.999923 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 03 | tr_loss 0.0085 | val_auc 0.999916 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 04 | tr_loss 0.0080 | val_auc 0.999951 | lrs [7.75e-05, 0.0007524999999999999] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 05 | tr_loss 0.0060 | val_auc 0.999970 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 06 | tr_loss 0.0023 | val_auc 0.999970 | lrs [5.5e-05, 0.000505] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 07 | tr_loss 0.0039 | val_auc 0.999958 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 08 | tr_loss 0.0049 | val_auc 0.999986 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 09 | tr_loss 0.0016 | val_auc 0.999983 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 10 | tr_loss 0.0015 | val_auc 0.999984 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 11 | tr_loss 0.0007 | val_auc 0.999981 | lrs [1.1533337816991932e-05, 2.6866715986911242e-05] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] early stop at 11\n[fold 1] best val AUC: 0.999986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] ResNet34 96px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ResNet34 96px Fold 3/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 01 | tr_loss 0.0751 | val_auc 0.999953 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 02 | tr_loss 0.0119 | val_auc 0.999961 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 03 | tr_loss 0.0092 | val_auc 0.999972 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 04 | tr_loss 0.0075 | val_auc 0.999988 | lrs [7.75e-05, 0.0007524999999999999] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 05 | tr_loss 0.0042 | val_auc 0.999982 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 06 | tr_loss 0.0036 | val_auc 0.999991 | lrs [5.5e-05, 0.000505] | 7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 07 | tr_loss 0.0021 | val_auc 0.999993 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0030\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 08 | tr_loss 0.0022 | val_auc 0.999991 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 09 | tr_loss 0.0041 | val_auc 0.999987 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 10 | tr_loss 0.0012 | val_auc 0.999991 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] early stop at 10\n[fold 2] best val AUC: 0.999993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] ResNet34 96px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ResNet34 96px Fold 4/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 01 | tr_loss 0.0791 | val_auc 0.999921 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 02 | tr_loss 0.0142 | val_auc 0.999238 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 03 | tr_loss 0.0069 | val_auc 0.999947 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 04 | tr_loss 0.0069 | val_auc 0.998599 | lrs [7.75e-05, 0.0007524999999999999] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 05 | tr_loss 0.0049 | val_auc 0.999964 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 06 | tr_loss 0.0040 | val_auc 0.999996 | lrs [5.5e-05, 0.000505] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 07 | tr_loss 0.0039 | val_auc 0.999989 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 08 | tr_loss 0.0027 | val_auc 0.999977 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 09 | tr_loss 0.0030 | val_auc 0.999986 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] early stop at 9\n[fold 3] best val AUC: 0.999996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] ResNet34 96px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ResNet34 96px Fold 5/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 01 | tr_loss 0.0859 | val_auc 0.999967 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 02 | tr_loss 0.0137 | val_auc 0.999999 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 03 | tr_loss 0.0102 | val_auc 0.999911 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 04 | tr_loss 0.0088 | val_auc 0.999996 | lrs [7.75e-05, 0.0007524999999999999] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 05 | tr_loss 0.0057 | val_auc 0.999999 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 06 | tr_loss 0.0036 | val_auc 1.000000 | lrs [5.5e-05, 0.000505] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 07 | tr_loss 0.0022 | val_auc 1.000000 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 08 | tr_loss 0.0030 | val_auc 1.000000 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 09 | tr_loss 0.0014 | val_auc 1.000000 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] early stop at 9\n[fold 4] best val AUC: 1.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] ResNet34 96px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_34_96_d8.csv; fold AUCs: ['0.999993', '0.999986', '0.999993', '0.999996', '1.000000']\n"
          ]
        }
      ]
    },
    {
      "id": "7fa72364-2fe7-428f-8e25-a5af96c0cb5c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Blend three models (96-ResNet18 D8, 128-ResNet18 D8, 96-ResNet34 D8) via logit averaging\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def logit(p):\n",
        "    p = np.clip(p, 1e-6, 1-1e-6).astype(np.float64)\n",
        "    return np.log(p/(1.0-p))\n",
        "\n",
        "# 96-ResNet18 D8: recover logits from probs\n",
        "sub96 = pd.read_csv('submission_d8.csv')\n",
        "logits96 = logit(sub96['has_cactus'].values.astype(np.float32))\n",
        "\n",
        "# 128-ResNet18 D8 logits\n",
        "logits128 = np.load('logits_128.npy').astype(np.float64)\n",
        "\n",
        "# 96-ResNet34 D8 logits\n",
        "logits34_96 = np.load('logits_34_96.npy').astype(np.float64)\n",
        "\n",
        "assert logits96.shape[0] == logits128.shape[0] == logits34_96.shape[0], 'Length mismatch among logits'\n",
        "\n",
        "# Equal-weight logit average\n",
        "avg_logits = (logits96 + logits128 + logits34_96) / 3.0\n",
        "blend_pred = sigmoid(avg_logits).astype(np.float32)\n",
        "\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub['has_cactus'] = blend_pred\n",
        "sub.to_csv('submission_blend_3.csv', index=False)\n",
        "print('Saved submission_blend_3.csv with shape', sub.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_blend_3.csv with shape (3325, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "f36290d8-bcf9-49f6-9461-2bd8c3a3f6fa",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Rank-averaged blend of 96-ResNet18 D8, 128-ResNet18 D8, 96-ResNet34 D8\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "sub96 = pd.read_csv('submission_d8.csv')\n",
        "sub128 = pd.read_csv('submission_128_d8.csv')\n",
        "sub34 = pd.read_csv('submission_34_96_d8.csv')\n",
        "\n",
        "# Ensure same order/ids\n",
        "assert sub96['id'].equals(sub128['id']) and sub96['id'].equals(sub34['id']), 'ID mismatch across submissions'\n",
        "ids = sub96['id'].values\n",
        "\n",
        "p1 = sub96['has_cactus'].values\n",
        "p2 = sub128['has_cactus'].values\n",
        "p3 = sub34['has_cactus'].values\n",
        "\n",
        "n = len(p1)\n",
        "r1 = pd.Series(p1).rank(method='average').to_numpy() / (n + 1.0)\n",
        "r2 = pd.Series(p2).rank(method='average').to_numpy() / (n + 1.0)\n",
        "r3 = pd.Series(p3).rank(method='average').to_numpy() / (n + 1.0)\n",
        "\n",
        "# Equal-weight rank average\n",
        "rank_blend = (r1 + r2 + r3) / 3.0\n",
        "\n",
        "sub = pd.DataFrame({'id': ids, 'has_cactus': rank_blend.astype(np.float32)})\n",
        "sub.to_csv('submission_blend_rank3.csv', index=False)\n",
        "print('Saved submission_blend_rank3.csv with shape', sub.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_blend_rank3.csv with shape (3325, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "894e94de-749d-4b2a-956a-476da6233ddf",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 96px ResNet18 with Dihedral-8 TTA (logit-avg) and save logits_96.npy + submission_96_d8.csv\n",
        "import os, time, json, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "CACHE_DIR = Path('./.model_cache'); CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['TORCH_HOME'] = str(CACHE_DIR)\n",
        "os.environ['XDG_CACHE_HOME'] = str(CACHE_DIR)\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "SEED = 42\n",
        "IMG_SIZE = 96\n",
        "N_FOLDS = 5\n",
        "EPOCHS = 12\n",
        "BATCH_SIZE = 256\n",
        "WORKERS = 2\n",
        "LR_BACKBONE = 1e-4\n",
        "LR_HEAD = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "\n",
        "def set_seed(seed=SEED):\n",
        "    import numpy as _np, random as _random, torch as _torch\n",
        "    _random.seed(seed); _np.random.seed(seed); _torch.manual_seed(seed); _torch.cuda.manual_seed_all(seed)\n",
        "    _torch.backends.cudnn.deterministic = True\n",
        "    _torch.backends.cudnn.benchmark = False\n",
        "set_seed()\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_transforms(train=True):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.ShiftScaleRotate(shift_limit=0.08, scale_limit=0.10, rotate_limit=10, border_mode=0, p=0.5),\n",
        "            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.05, hue=0.0, p=0.2),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ])\n",
        "\n",
        "class TtaD8Dataset96(Dataset):\n",
        "    def __init__(self, img_dir, df, mode='train', rot_k=0, hflip=False):\n",
        "        self.img_dir = Path(img_dir); self.df = df.reset_index(drop=True)\n",
        "        self.mode = mode; self.rot_k = rot_k; self.hflip = hflip\n",
        "        self.tfms = get_transforms(train=(mode=='train'))\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['id']\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert('RGB')\n",
        "            img = np.array(im)\n",
        "        if self.rot_k:\n",
        "            img = np.ascontiguousarray(np.rot90(img, k=self.rot_k))\n",
        "        if self.hflip:\n",
        "            img = np.ascontiguousarray(img[:, ::-1, :])\n",
        "        aug = self.tfms(image=img)\n",
        "        x = torch.from_numpy(aug['image'].transpose(2,0,1)).float()\n",
        "        if self.mode in ('train','valid'):\n",
        "            y = torch.tensor(row['has_cactus'], dtype=torch.float32)\n",
        "            return x, y\n",
        "        return x, row['id']\n",
        "\n",
        "def build_model():\n",
        "    m = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    m.fc = nn.Linear(m.fc.in_features, 1)\n",
        "    return m\n",
        "\n",
        "def make_optimizer(model):\n",
        "    head_params = list(model.fc.parameters())\n",
        "    backbone_params = [p for n,p in model.named_parameters() if not n.startswith('fc.')]\n",
        "    return torch.optim.AdamW([\n",
        "        {'params': backbone_params, 'lr': LR_BACKBONE},\n",
        "        {'params': head_params, 'lr': LR_HEAD},\n",
        "    ], weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, loss_fn, scaler):\n",
        "    model.train(); total=0.0\n",
        "    for i,(x,y) in enumerate(loader):\n",
        "        x=x.to(DEVICE,non_blocking=True); y=y.to(DEVICE,non_blocking=True).view(-1,1)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast('cuda', enabled=(DEVICE=='cuda')):\n",
        "            logits=model(x); loss=loss_fn(logits,y)\n",
        "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
        "        total += loss.item()*x.size(0)\n",
        "        if (i+1)%20==0: print(f\"  [train] step {i+1}/{len(loader)} loss={total/((i+1)*loader.batch_size):.4f}\", flush=True)\n",
        "    return total/len(loader.dataset)\n",
        "\n",
        "def valid_auc(model, loader):\n",
        "    model.eval(); preds=[]; targs=[]\n",
        "    with torch.no_grad():\n",
        "        for x,y in loader:\n",
        "            x=x.to(DEVICE,non_blocking=True); y=y.view(-1,1)\n",
        "            logits=model(x)\n",
        "            preds.append(torch.sigmoid(logits).squeeze(1).cpu().numpy())\n",
        "            targs.append(y.squeeze(1).cpu().numpy())\n",
        "    preds=np.concatenate(preds); targs=np.concatenate(targs)\n",
        "    return roc_auc_score(targs,preds)\n",
        "\n",
        "def predict_logits(model, loader):\n",
        "    model.eval(); out_logits=[]; out_ids=[]\n",
        "    with torch.no_grad():\n",
        "        for x,ids in loader:\n",
        "            x=x.to(DEVICE,non_blocking=True)\n",
        "            logits=model(x).squeeze(1).cpu().numpy()\n",
        "            out_logits.append(logits); out_ids += list(ids)\n",
        "    return np.concatenate(out_logits), out_ids\n",
        "\n",
        "# Data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "groups_df = pd.read_csv('cv_groups.csv')\n",
        "train_df = train_df.merge(groups_df[['id','sha1']], on='id', how='left')\n",
        "test_ids = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "skf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "test_logit_accum = np.zeros(len(test_ids), dtype=np.float32)\n",
        "\n",
        "for fold,(tr_idx,va_idx) in enumerate(skf.split(train_df['id'], train_df['has_cactus'], groups=train_df['sha1'])):\n",
        "    print(f\"===== ResNet18 96px D8 Fold {fold+1}/{N_FOLDS} =====\")\n",
        "    tr_df = train_df.iloc[tr_idx].reset_index(drop=True)\n",
        "    va_df = train_df.iloc[va_idx].reset_index(drop=True)\n",
        "    tr_loader = DataLoader(TtaD8Dataset96('train', tr_df, mode='train'), batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=True, drop_last=True)\n",
        "    va_loader = DataLoader(TtaD8Dataset96('train', va_df, mode='valid'), batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "\n",
        "    model = build_model().to(DEVICE)\n",
        "    optimizer = make_optimizer(model)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-5)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(DEVICE=='cuda'))\n",
        "\n",
        "    best_auc=-1.0; best_state=None; no_imp=0\n",
        "    for epoch in range(1,EPOCHS+1):\n",
        "        t0=time.time()\n",
        "        tr_loss = train_one_epoch(model, tr_loader, optimizer, loss_fn, scaler)\n",
        "        val_auc = valid_auc(model, va_loader)\n",
        "        scheduler.step()\n",
        "        lrs=[pg['lr'] for pg in optimizer.param_groups]\n",
        "        print(f\"[fold {fold}] epoch {epoch:02d} | tr_loss {tr_loss:.4f} | val_auc {val_auc:.6f} | lrs {lrs} | {time.time()-t0:.1f}s\", flush=True)\n",
        "        if val_auc > best_auc: best_auc=val_auc; best_state={k:v.cpu() for k,v in model.state_dict().items()}; no_imp=0\n",
        "        else: no_imp+=1\n",
        "        if no_imp>=3: print(f\"[fold {fold}] early stop at {epoch}\"); break\n",
        "    print(f\"[fold {fold}] best val AUC: {best_auc:.6f}\")\n",
        "    model.load_state_dict({k:v.to(DEVICE) for k,v in best_state.items()}, strict=True)\n",
        "\n",
        "    # Dihedral-8 TTA logits\n",
        "    tta_logits_sum = np.zeros(len(test_ids), dtype=np.float32)\n",
        "    for rot_k in (0,1,2,3):\n",
        "        for hf in (False, True):\n",
        "            ds = TtaD8Dataset96('test', test_ids, mode='test', rot_k=rot_k, hflip=hf)\n",
        "            dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "            logits, ids = predict_logits(model, dl)\n",
        "            tta_logits_sum += logits.astype(np.float32)\n",
        "    test_logit_accum += (tta_logits_sum / 8.0)\n",
        "    print(f\"[fold {fold}] 96px D8 TTA done\")\n",
        "    del model, optimizer, loss_fn, scaler, tr_loader, va_loader\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "# Average across folds -> logits then sigmoid\n",
        "avg_test_logits = test_logit_accum / N_FOLDS\n",
        "np.save('logits_96.npy', avg_test_logits)\n",
        "test_pred = 1.0 / (1.0 + np.exp(-avg_test_logits))\n",
        "\n",
        "# Save submission\n",
        "sub = pd.read_csv('sample_submission.csv')\n",
        "sub['has_cactus'] = test_pred.astype(np.float32)\n",
        "sub.to_csv('submission_96_d8.csv', index=False)\n",
        "print('Saved submission_96_d8.csv and logits_96.npy')\n",
        "\n",
        "# Blend true logits (96, 128, 34@96) and save submission_blend3_true.csv\n",
        "logits96 = np.load('logits_96.npy').astype(np.float64)\n",
        "logits128 = np.load('logits_128.npy').astype(np.float64)\n",
        "logits34 = np.load('logits_34_96.npy').astype(np.float64)\n",
        "assert logits96.shape[0] == logits128.shape[0] == logits34.shape[0], 'Length mismatch among logits'\n",
        "avg_logits = (logits96 + logits128 + logits34) / 3.0\n",
        "blend_pred = 1.0 / (1.0 + np.exp(-avg_logits))\n",
        "sub_blend = pd.read_csv('sample_submission.csv')\n",
        "sub_blend['has_cactus'] = blend_pred.astype(np.float32)\n",
        "sub_blend.to_csv('submission_blend3_true.csv', index=False)\n",
        "print('Saved submission_blend3_true.csv')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ResNet18 96px D8 Fold 1/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 01 | tr_loss 0.0867 | val_auc 0.999910 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 02 | tr_loss 0.0144 | val_auc 0.999922 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 03 | tr_loss 0.0088 | val_auc 0.999965 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 04 | tr_loss 0.0057 | val_auc 0.999960 | lrs [7.75e-05, 0.0007524999999999999] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 05 | tr_loss 0.0053 | val_auc 0.999966 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 06 | tr_loss 0.0035 | val_auc 0.999984 | lrs [5.5e-05, 0.000505] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 07 | tr_loss 0.0036 | val_auc 0.999984 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 08 | tr_loss 0.0020 | val_auc 0.999991 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 09 | tr_loss 0.0029 | val_auc 0.999998 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 10 | tr_loss 0.0017 | val_auc 0.999996 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 11 | tr_loss 0.0011 | val_auc 0.999997 | lrs [1.1533337816991932e-05, 2.6866715986911242e-05] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] epoch 12 | tr_loss 0.0026 | val_auc 0.999997 | lrs [1e-05, 1e-05] | 7.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] early stop at 12\n[fold 0] best val AUC: 0.999998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 0] 96px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ResNet18 96px D8 Fold 2/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 01 | tr_loss 0.0716 | val_auc 0.999828 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 02 | tr_loss 0.0155 | val_auc 0.999880 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 03 | tr_loss 0.0097 | val_auc 0.999897 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 04 | tr_loss 0.0061 | val_auc 0.999901 | lrs [7.75e-05, 0.0007524999999999999] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 05 | tr_loss 0.0054 | val_auc 0.999930 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 06 | tr_loss 0.0064 | val_auc 0.999905 | lrs [5.5e-05, 0.000505] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 07 | tr_loss 0.0039 | val_auc 0.999899 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] epoch 08 | tr_loss 0.0039 | val_auc 0.999919 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] early stop at 8\n[fold 1] best val AUC: 0.999930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 1] 96px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ResNet18 96px D8 Fold 3/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.1004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 01 | tr_loss 0.0940 | val_auc 0.999832 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 02 | tr_loss 0.0173 | val_auc 0.999978 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 03 | tr_loss 0.0092 | val_auc 0.999966 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 04 | tr_loss 0.0078 | val_auc 0.999984 | lrs [7.75e-05, 0.0007524999999999999] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 05 | tr_loss 0.0048 | val_auc 0.999991 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 06 | tr_loss 0.0042 | val_auc 0.999995 | lrs [5.5e-05, 0.000505] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 07 | tr_loss 0.0031 | val_auc 0.999995 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 08 | tr_loss 0.0042 | val_auc 0.999992 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] epoch 09 | tr_loss 0.0019 | val_auc 0.999992 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] early stop at 9\n[fold 2] best val AUC: 0.999995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 2] 96px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ResNet18 96px D8 Fold 4/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.1040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 01 | tr_loss 0.0955 | val_auc 0.999644 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 02 | tr_loss 0.0154 | val_auc 0.999864 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 03 | tr_loss 0.0091 | val_auc 0.999877 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 04 | tr_loss 0.0099 | val_auc 0.999959 | lrs [7.75e-05, 0.0007524999999999999] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 05 | tr_loss 0.0058 | val_auc 0.999891 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 06 | tr_loss 0.0066 | val_auc 0.999948 | lrs [5.5e-05, 0.000505] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 07 | tr_loss 0.0051 | val_auc 0.999963 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 08 | tr_loss 0.0018 | val_auc 0.999952 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 09 | tr_loss 0.0017 | val_auc 0.999956 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] epoch 10 | tr_loss 0.0022 | val_auc 0.999952 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] early stop at 10\n[fold 3] best val AUC: 0.999963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 3] 96px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== ResNet18 96px D8 Fold 5/5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.1456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 01 | tr_loss 0.0797 | val_auc 0.999839 | lrs [9.846666218300807e-05, 0.0009831332840130886] | 7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 02 | tr_loss 0.0152 | val_auc 0.999940 | lrs [9.397114317029975e-05, 0.0009336825748732971] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 03 | tr_loss 0.0100 | val_auc 0.999967 | lrs [8.681980515339464e-05, 0.0008550178566873409] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 04 | tr_loss 0.0092 | val_auc 0.999980 | lrs [7.75e-05, 0.0007524999999999999] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 05 | tr_loss 0.0066 | val_auc 0.999985 | lrs [6.664685702961344e-05, 0.0006331154273257478] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 06 | tr_loss 0.0062 | val_auc 0.999995 | lrs [5.5e-05, 0.000505] | 7.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 07 | tr_loss 0.0035 | val_auc 0.999999 | lrs [4.335314297038657e-05, 0.00037688457267425233] | 7.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 08 | tr_loss 0.0039 | val_auc 0.999996 | lrs [3.250000000000001e-05, 0.00025750000000000013] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 09 | tr_loss 0.0021 | val_auc 0.999996 | lrs [2.3180194846605367e-05, 0.000154982143312659] | 7.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 20/44 loss=0.0034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [train] step 40/44 loss=0.0029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] epoch 10 | tr_loss 0.0032 | val_auc 0.999997 | lrs [1.602885682970026e-05, 7.631742512670284e-05] | 7.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] early stop at 10\n[fold 4] best val AUC: 0.999999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[fold 4] 96px D8 TTA done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_96_d8.csv and logits_96.npy\nSaved submission_blend3_true.csv\n"
          ]
        }
      ]
    },
    {
      "id": "03aeae26-d1e6-4fde-9ae8-f1799f95f7ee",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Embedding kNN overrides using ResNet18@128 GAP features with D8 TTA (cosine NN, unanimous top-5, high-sim threshold)\n",
        "import time, os, gc, numpy as np, pandas as pd\n",
        "import torch, torch.nn as nn\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from torchvision import models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "import albumentations as A\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 256\n",
        "WORKERS = 2\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "def get_tfms_128():\n",
        "    return A.Compose([\n",
        "        A.Resize(IMG_SIZE, IMG_SIZE, interpolation=3),\n",
        "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "    ])\n",
        "\n",
        "class FeatD8Dataset(Dataset):\n",
        "    def __init__(self, img_dir, ids_df, rot_k=0, hflip=False):\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.df = ids_df.reset_index(drop=True)\n",
        "        self.rot_k = rot_k\n",
        "        self.hflip = hflip\n",
        "        self.tfms = get_tfms_128()\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['id']\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert('RGB')\n",
        "            img = np.array(im)\n",
        "        if self.rot_k:\n",
        "            img = np.ascontiguousarray(np.rot90(img, k=self.rot_k))\n",
        "        if self.hflip:\n",
        "            img = np.ascontiguousarray(img[:, ::-1, :])\n",
        "        aug = self.tfms(image=img)\n",
        "        x = torch.from_numpy(aug['image'].transpose(2,0,1)).float()\n",
        "        return x, row['id']\n",
        "\n",
        "def build_feat_model():\n",
        "    m = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    m.fc = nn.Identity()  # return 512-dim GAP features\n",
        "    return m.to(DEVICE).eval()\n",
        "\n",
        "def extract_d8_feats(img_dir, ids_df):\n",
        "    model = build_feat_model()\n",
        "    n = len(ids_df)\n",
        "    feats = np.zeros((n, 512), dtype=np.float32)\n",
        "    counts = np.zeros(n, dtype=np.int32)\n",
        "    id_to_idx = {img_id: i for i, img_id in enumerate(ids_df['id'].tolist())}\n",
        "    with torch.no_grad():\n",
        "        for rot_k in (0,1,2,3):\n",
        "            for hf in (False, True):\n",
        "                ds = FeatD8Dataset(img_dir, ids_df, rot_k=rot_k, hflip=hf)\n",
        "                dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=True)\n",
        "                t0 = time.time()\n",
        "                seen = 0\n",
        "                for x, ids in dl:\n",
        "                    x = x.to(DEVICE, non_blocking=True)\n",
        "                    f = model(x).float()  # (bs, 512)\n",
        "                    f = f.cpu().numpy()\n",
        "                    for j, img_id in enumerate(ids):\n",
        "                        idx = id_to_idx[img_id]\n",
        "                        feats[idx] += f[j]\n",
        "                        counts[idx] += 1\n",
        "                    seen += x.size(0)\n",
        "                    if seen % (BATCH_SIZE*10) == 0:\n",
        "                        print(f\"  [feat] rot={rot_k} hf={hf} seen={seen}/{n}\", flush=True)\n",
        "                print(f\"[feat] rot={rot_k} hf={hf} done in {time.time()-t0:.1f}s\", flush=True)\n",
        "    # average over 8 views and L2-normalize\n",
        "    feats /= counts[:, None].clip(min=1)\n",
        "    norms = np.linalg.norm(feats, axis=1, keepdims=True)\n",
        "    feats = feats / np.clip(norms, 1e-12, None)\n",
        "    del model; gc.collect(); torch.cuda.empty_cache()\n",
        "    return feats\n",
        "\n",
        "t_all = time.time()\n",
        "train_df = pd.read_csv('train.csv')  # id, has_cactus\n",
        "test_ids = pd.read_csv('sample_submission.csv')[['id']]\n",
        "print('[knn] extracting train D8 features...')\n",
        "train_ids = train_df[['id']].copy()\n",
        "train_feats = extract_d8_feats('train', train_ids)\n",
        "print('[knn] extracting test D8 features...')\n",
        "test_feats = extract_d8_feats('test', test_ids)\n",
        "train_labels = train_df['has_cactus'].astype(np.int8).values\n",
        "\n",
        "# Build cosine kNN on train feats\n",
        "print('[knn] fitting NearestNeighbors (cosine)...')\n",
        "nn_model = NearestNeighbors(n_neighbors=5, metric='cosine', n_jobs=-1)\n",
        "nn_model.fit(train_feats)\n",
        "dists, idxs = nn_model.kneighbors(test_feats, n_neighbors=5, return_distance=True)\n",
        "sims = 1.0 - dists  # cosine similarity\n",
        "top1_sim = sims[:, 0]\n",
        "top5_lbls = train_labels[idxs]  # (n_test, 5)\n",
        "unanimous = (top5_lbls.min(axis=1) == top5_lbls.max(axis=1))\n",
        "vote = top5_lbls[:, 0]  # same if unanimous\n",
        "\n",
        "# Load base submission to override (clean 3-model logit blend)\n",
        "base = pd.read_csv('submission_blend3_true.csv')\n",
        "base = base.merge(test_ids, on='id', how='right')\n",
        "probs_base = base['has_cactus'].values.astype(np.float32)\n",
        "\n",
        "def apply_knn_override(thresh: float, out_path: str):\n",
        "    mask = (top1_sim >= thresh) & unanimous\n",
        "    out_probs = probs_base.copy()\n",
        "    out_probs[mask] = vote[mask].astype(np.float32)\n",
        "    out = pd.DataFrame({'id': test_ids['id'], 'has_cactus': out_probs})\n",
        "    out.to_csv(out_path, index=False)\n",
        "    n_over = int(mask.sum())\n",
        "    print(f\"[knn] saved {out_path} | overrides: {n_over} | thresh={thresh}\")\n",
        "    return n_over\n",
        "\n",
        "n1 = apply_knn_override(0.997, 'submission_knn_0997.csv')\n",
        "n2 = apply_knn_override(0.999, 'submission_knn_0999.csv')\n",
        "print(f\"[knn] done in {time.time()-t_all:.1f}s | overrides(0.997,0.999)=({n1},{n2})\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[knn] extracting train D8 features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=False seen=2560/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=False seen=5120/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=False seen=7680/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=False seen=10240/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=False seen=12800/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=0 hf=False done in 6.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=True seen=2560/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=True seen=5120/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=True seen=7680/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=True seen=10240/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=True seen=12800/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=0 hf=True done in 6.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=False seen=2560/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=False seen=5120/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=False seen=7680/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=False seen=10240/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=False seen=12800/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=1 hf=False done in 6.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=True seen=2560/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=True seen=5120/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=True seen=7680/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=True seen=10240/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=True seen=12800/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=1 hf=True done in 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=False seen=2560/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=False seen=5120/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=False seen=7680/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=False seen=10240/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=False seen=12800/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=2 hf=False done in 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=True seen=2560/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=True seen=5120/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=True seen=7680/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=True seen=10240/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=True seen=12800/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=2 hf=True done in 6.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=False seen=2560/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=False seen=5120/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=False seen=7680/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=False seen=10240/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=False seen=12800/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=3 hf=False done in 6.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=True seen=2560/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=True seen=5120/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=True seen=7680/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=True seen=10240/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=True seen=12800/14175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=3 hf=True done in 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[knn] extracting test D8 features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=False seen=2560/3325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=0 hf=False done in 1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=0 hf=True seen=2560/3325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=0 hf=True done in 1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=False seen=2560/3325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=1 hf=False done in 1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=1 hf=True seen=2560/3325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=1 hf=True done in 1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=False seen=2560/3325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=2 hf=False done in 1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=2 hf=True seen=2560/3325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=2 hf=True done in 2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=False seen=2560/3325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=3 hf=False done in 1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [feat] rot=3 hf=True seen=2560/3325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[feat] rot=3 hf=True done in 1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[knn] fitting NearestNeighbors (cosine)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[knn] saved submission_knn_0997.csv | overrides: 0 | thresh=0.997\n[knn] saved submission_knn_0999.csv | overrides: 0 | thresh=0.999\n[knn] done in 72.2s | overrides(0.997,0.999)=(0,0)\n"
          ]
        }
      ]
    },
    {
      "id": "5e99ac63-132a-453e-a0fe-70838bd07985",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Additional kNN override variants (looser thresholds, different voting) using existing embedding neighbors\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# Reuse sims, idxs, train_labels, probs_base, test_ids from previous cell\n",
        "assert 'sims' in globals() and 'idxs' in globals(), 'Run the embedding kNN cell first.'\n",
        "top1_sim = sims[:,0]\n",
        "top1_idx = idxs[:,0]\n",
        "top3 = idxs[:, :3]\n",
        "top3_sims = sims[:, :3]\n",
        "top5_lbls = train_labels[idxs]\n",
        "\n",
        "base_probs = probs_base.copy()\n",
        "\n",
        "def save_override(mask, labels, fname):\n",
        "    out_probs = base_probs.copy()\n",
        "    out_probs[mask] = labels[mask].astype(np.float32)\n",
        "    out = pd.DataFrame({'id': test_ids['id'], 'has_cactus': out_probs})\n",
        "    out.to_csv(fname, index=False)\n",
        "    print(f\"[knn-var] saved {fname} | overrides: {int(mask.sum())}\")\n",
        "\n",
        "# Variant A: top-1 sim >= 0.995, take top-1 label\n",
        "mask_a = top1_sim >= 0.995\n",
        "labels_a = train_labels[top1_idx]\n",
        "save_override(mask_a, labels_a, 'submission_knn_0995.csv')\n",
        "\n",
        "# Variant B: top-1 sim >= 0.993, take top-1 label (more aggressive)\n",
        "mask_b = top1_sim >= 0.993\n",
        "labels_b = train_labels[top1_idx]\n",
        "save_override(mask_b, labels_b, 'submission_knn_0993.csv')\n",
        "\n",
        "# Variant C: top-3 all highly similar (>=0.995) and unanimous label among top-3\n",
        "labels_top3 = train_labels[top3]\n",
        "unanimous_top3 = (labels_top3.min(axis=1) == labels_top3.max(axis=1))\n",
        "highsim_top3 = (top3_sims.min(axis=1) >= 0.995)\n",
        "mask_c = unanimous_top3 & highsim_top3\n",
        "labels_c = labels_top3[:,0]\n",
        "save_override(mask_c, labels_c, 'submission_knn_top3_0995.csv')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[knn-var] saved submission_knn_0995.csv | overrides: 0\n[knn-var] saved submission_knn_0993.csv | overrides: 0\n[knn-var] saved submission_knn_top3_0995.csv | overrides: 0\n"
          ]
        }
      ]
    },
    {
      "id": "6b3864e8-3f1d-4280-adac-5f6bbbe60182",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Raw-pixel cosine kNN overrides (images are 32x32 RGB) on top of clean blend\n",
        "import numpy as np, pandas as pd, time\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def load_images_matrix(img_dir: str, ids: pd.Series) -> np.ndarray:\n",
        "    # Returns float32 array (N, 3072), L2-normalized per row\n",
        "    X = np.empty((len(ids), 32*32*3), dtype=np.float32)\n",
        "    for i, img_id in enumerate(ids):\n",
        "        with Image.open(Path(img_dir)/img_id) as im:\n",
        "            arr = np.asarray(im.convert('RGB'), dtype=np.float32)  # (32,32,3)\n",
        "        X[i] = arr.reshape(-1)\n",
        "    # L2 normalize\n",
        "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
        "    norms = np.clip(norms, 1e-12, None)\n",
        "    X /= norms\n",
        "    return X\n",
        "\n",
        "t0 = time.time()\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('sample_submission.csv')\n",
        "train_ids = train_df['id']\n",
        "test_ids_df = test_df[['id']]\n",
        "\n",
        "print('[pixknn] loading raw pixel matrices...')\n",
        "X_train = load_images_matrix('train', train_ids)\n",
        "X_test = load_images_matrix('test', test_ids_df['id'])\n",
        "y_train = train_df['has_cactus'].astype(np.int8).values\n",
        "print(f\"[pixknn] shapes train={X_train.shape} test={X_test.shape} load_time={time.time()-t0:.1f}s\", flush=True)\n",
        "\n",
        "print('[pixknn] fitting cosine NN...')\n",
        "nn_model = NearestNeighbors(n_neighbors=5, metric='cosine', n_jobs=-1)\n",
        "nn_model.fit(X_train)\n",
        "dists, idxs = nn_model.kneighbors(X_test, n_neighbors=5, return_distance=True)\n",
        "sims = 1.0 - dists  # cosine similarity\n",
        "top1_sim = sims[:,0]\n",
        "top1_idx = idxs[:,0]\n",
        "top5_lbls = y_train[idxs]\n",
        "unanimous5 = (top5_lbls.min(axis=1) == top5_lbls.max(axis=1))\n",
        "vote5 = top5_lbls[:,0]\n",
        "\n",
        "base = pd.read_csv('submission_blend3_true.csv')\n",
        "base = base.merge(test_ids_df, on='id', how='right')\n",
        "probs_base = base['has_cactus'].values.astype(np.float32)\n",
        "\n",
        "def save_pix_overrides(mask, labels, out_path):\n",
        "    out_probs = probs_base.copy()\n",
        "    out_probs[mask] = labels[mask].astype(np.float32)\n",
        "    out = pd.DataFrame({'id': test_ids_df['id'], 'has_cactus': out_probs})\n",
        "    out.to_csv(out_path, index=False)\n",
        "    print(f\"[pixknn] saved {out_path} | overrides: {int(mask.sum())}\")\n",
        "\n",
        "# Variant 1: very high sim + unanimous5\n",
        "mask1 = (top1_sim >= 0.995) & unanimous5\n",
        "labels1 = vote5\n",
        "save_pix_overrides(mask1, labels1, 'submission_pixknn_u5_0995.csv')\n",
        "\n",
        "# Variant 2: high sim top1 only\n",
        "mask2 = (top1_sim >= 0.995)\n",
        "labels2 = y_train[top1_idx]\n",
        "save_pix_overrides(mask2, labels2, 'submission_pixknn_top1_0995.csv')\n",
        "\n",
        "# Variant 3: slightly looser\n",
        "mask3 = (top1_sim >= 0.990)\n",
        "labels3 = y_train[top1_idx]\n",
        "save_pix_overrides(mask3, labels3, 'submission_pixknn_top1_0990.csv')\n",
        "\n",
        "print('[pixknn] done.')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pixknn] loading raw pixel matrices...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pixknn] shapes train=(14175, 3072) test=(3325, 3072) load_time=3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pixknn] fitting cosine NN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pixknn] saved submission_pixknn_u5_0995.csv | overrides: 202\n[pixknn] saved submission_pixknn_top1_0995.csv | overrides: 204\n[pixknn] saved submission_pixknn_top1_0990.csv | overrides: 403\n[pixknn] done.\n"
          ]
        }
      ]
    },
    {
      "id": "d6214342-8495-402a-a6f8-fb247ca4f689",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set final submission to conservative raw-pixel kNN unanimous5 overrides\n",
        "import pandas as pd\n",
        "chosen = 'submission_pixknn_u5_0995.csv'\n",
        "df = pd.read_csv(chosen)\n",
        "df.to_csv('submission.csv', index=False)\n",
        "print('submission.csv written from', chosen, '| shape =', df.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv written from submission_pixknn_u5_0995.csv | shape = (3325, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "501c3d09-56bf-49ce-977d-74afcac3f718",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# SSIM-based nearest-neighbor overrides (conservative) on top of clean 3-model blend\n",
        "import numpy as np, pandas as pd, time, subprocess, sys\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "try:\n",
        "    from skimage.metrics import structural_similarity as ssim\n",
        "except Exception:\n",
        "    print('[ssim] scikit-image not found. Installing...')\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-image', '--quiet'], check=False)\n",
        "    from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def load_flat32(img_dir: str, ids: pd.Series) -> np.ndarray:\n",
        "    X = np.empty((len(ids), 32*32*3), dtype=np.float32)\n",
        "    for i, img_id in enumerate(ids):\n",
        "        with Image.open(Path(img_dir)/img_id) as im:\n",
        "            arr = np.asarray(im.convert('RGB'), dtype=np.float32)\n",
        "        X[i] = arr.reshape(-1)\n",
        "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
        "    X /= np.clip(norms, 1e-12, None)\n",
        "    return X\n",
        "\n",
        "def load_gray32(path: Path) -> np.ndarray:\n",
        "    with Image.open(path) as im:\n",
        "        im = im.convert('L')  # grayscale\n",
        "        arr = np.asarray(im, dtype=np.float32) / 255.0\n",
        "    return arr\n",
        "\n",
        "t0 = time.time()\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('sample_submission.csv')\n",
        "train_ids = train_df['id']\n",
        "test_ids_df = test_df[['id']]\n",
        "y_train = train_df['has_cactus'].astype(np.int8).values\n",
        "\n",
        "print('[ssim] building cosine top1 index on raw 32x32...')\n",
        "X_tr = load_flat32('train', train_ids)\n",
        "X_te = load_flat32('test', test_ids_df['id'])\n",
        "nn = NearestNeighbors(n_neighbors=1, metric='cosine', n_jobs=-1).fit(X_tr)\n",
        "dists, idxs = nn.kneighbors(X_te, n_neighbors=1, return_distance=True)\n",
        "cos_top1 = 1.0 - dists.squeeze(1)\n",
        "top1_idx = idxs.squeeze(1)\n",
        "print('[ssim] NN ready. computing SSIM for candidate pairs...')\n",
        "\n",
        "train_dir = Path('train'); test_dir = Path('test')\n",
        "ssims = np.zeros(len(test_ids_df), dtype=np.float32)\n",
        "for i, tid in enumerate(test_ids_df['id']):\n",
        "    tr_id = train_ids.iloc[top1_idx[i]]\n",
        "    g_test = load_gray32(test_dir / tid)\n",
        "    g_train = load_gray32(train_dir / tr_id)\n",
        "    ssims[i] = ssim(g_test, g_train, data_range=1.0)\n",
        "    if (i+1) % 500 == 0:\n",
        "        print(f'  [ssim] {i+1}/{len(test_ids_df)} computed', flush=True)\n",
        "\n",
        "base = pd.read_csv('submission_blend3_true.csv')\n",
        "base = base.merge(test_ids_df, on='id', how='right')\n",
        "probs_base = base['has_cactus'].values.astype(np.float32)\n",
        "\n",
        "def save_ssim_override(ssim_thresh: float, cos_thresh: float, out_path: str):\n",
        "    mask = (ssims >= ssim_thresh) & (cos_top1 >= cos_thresh)\n",
        "    labels = y_train[top1_idx].astype(np.float32)\n",
        "    out_probs = probs_base.copy()\n",
        "    out_probs[mask] = labels[mask]\n",
        "    out = pd.DataFrame({'id': test_ids_df['id'], 'has_cactus': out_probs})\n",
        "    out.to_csv(out_path, index=False)\n",
        "    print(f\"[ssim] saved {out_path} | overrides: {int(mask.sum())} | ssim>= {ssim_thresh} & cos>= {cos_thresh}\")\n",
        "\n",
        "# Conservative and moderate variants per expert advice\n",
        "save_ssim_override(0.99, 0.998, 'submission_ssim_0990_cos0998.csv')\n",
        "save_ssim_override(0.985, 0.995, 'submission_ssim_0985_cos0995.csv')\n",
        "print(f\"[ssim] done in {time.time()-t0:.1f}s\")\n",
        "\n",
        "# Set submission.csv to the most conservative SSIM override\n",
        "cons = 'submission_ssim_0990_cos0998.csv'\n",
        "df = pd.read_csv(cons)\n",
        "df.to_csv('submission.csv', index=False)\n",
        "print('submission.csv written from', cons, '| shape =', df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ssim] building cosine top1 index on raw 32x32...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}