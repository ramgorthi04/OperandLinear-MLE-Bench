{
  "cells": [
    {
      "id": "06ab3666-5389-4612-8184-967bdd88208a",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan: Aerial Cactus Identification (Kernels-Only Emulation)\n",
        "\n",
        "Objectives:\n",
        "- Produce submission.csv with test predictions.\n",
        "- Target AUC-ROC ~1.0 (medal-level).\n",
        "\n",
        "Data:\n",
        "- train.csv: id,label\n",
        "- train.zip: training images\n",
        "- test.zip: test images\n",
        "- sample_submission.csv: required format\n",
        "\n",
        "High-Level Approach:\n",
        "1) Setup & Unzip: Extract train.zip and test.zip. Verify counts.\n",
        "2) EDA/Checks: Class balance, image size, basic sanity-check.\n",
        "3) Cross-Validation: Stratified KFold (e.g., 5 folds).\n",
        "4) Model: Simple but strong image classifier.\n",
        "   - Preferred: PyTorch + timm (efficientnet_b0 or resnet18) with pretrained weights.\n",
        "   - If timm unavailable: torchvision resnet18 pretrained.\n",
        "   - Augmentations via Albumentations.\n",
        "5) Training:\n",
        "   - Input size: 128 or 224.\n",
        "   - Loss: BCEWithLogitsLoss.\n",
        "   - Optimizer: AdamW, OneCycle or cosine schedule.\n",
        "   - Early stopping on AUC; 5\u201310 epochs per fold (dataset is small).\n",
        "6) Inference:\n",
        "   - TTA (horizontal/vertical flips) if time allows.\n",
        "   - Average fold predictions.\n",
        "7) Submission: Create submission.csv with id, has_cactus.\n",
        "\n",
        "Efficiency/Logging:\n",
        "- Print fold indices, times, and epoch logs with AUC.\n",
        "- Keep training light; interrupt if diminishing returns.\n",
        "\n",
        "Checkpoints for Expert Review:\n",
        "- After this plan.\n",
        "- After data load/unzip & EDA.\n",
        "- After baseline CV model and initial AUC.\n",
        "- Before long trainings or grid searches.\n",
        "- After validation AUC and before final inference.\n",
        "\n",
        "Risk Mitigation:\n",
        "- If installs heavy, fall back to torchvision-only resnet18.\n",
        "- If torch unavailable, quick Keras/TF CNN.\n",
        "- If time-critical, train single model no-CV and submit.\n",
        "\n",
        "Next:\n",
        "- Get expert feedback on plan; then implement unzip + data loaders."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a6c02dae-ba2f-4d2c-b30e-a3c83f4cedcb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup: imports, seed, unzip, quick EDA\n",
        "import os, sys, time, random, zipfile, math, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "SEED = 42\n",
        "def set_seed(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()\n",
        "\n",
        "DATA_DIR = Path('.')\n",
        "TRAIN_ZIP = DATA_DIR / 'train.zip'\n",
        "TEST_ZIP = DATA_DIR / 'test.zip'\n",
        "TRAIN_DIR = DATA_DIR / 'train'\n",
        "TEST_DIR = DATA_DIR / 'test'\n",
        "\n",
        "def safe_unzip(zip_path, out_dir):\n",
        "    if out_dir.exists() and any(out_dir.iterdir()):\n",
        "        print(f\"Exists: {out_dir}, skipping unzip.\")\n",
        "        return\n",
        "    print(f\"Unzipping {zip_path} -> {out_dir}\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        z.extractall(out_dir)\n",
        "    print(f\"Done unzip: {out_dir}\")\n",
        "\n",
        "safe_unzip(TRAIN_ZIP, TRAIN_DIR)\n",
        "safe_unzip(TEST_ZIP, TEST_DIR)\n",
        "\n",
        "# Load CSVs\n",
        "train_df = pd.read_csv(DATA_DIR / 'train.csv')\n",
        "sub_df = pd.read_csv(DATA_DIR / 'sample_submission.csv')\n",
        "print('train_df shape:', train_df.shape)\n",
        "print('sub_df shape:', sub_df.shape)\n",
        "print('train head:\\n', train_df.head())\n",
        "\n",
        "# Basic checks\n",
        "print('Unique labels:', train_df['has_cactus'].value_counts().to_dict())\n",
        "pos_rate = train_df['has_cactus'].mean()\n",
        "print(f'Pos rate: {pos_rate:.4f}')\n",
        "\n",
        "# Verify a few images and size\n",
        "sample_ids = train_df['id'].head(3).tolist()\n",
        "sizes = []\n",
        "for sid in sample_ids:\n",
        "    p = TRAIN_DIR / sid\n",
        "    with Image.open(p) as im:\n",
        "        sizes.append(im.size)\n",
        "print('Sample image sizes:', sizes)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping train.zip -> train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done unzip: train\nUnzipping test.zip -> test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done unzip: test\ntrain_df shape: (14175, 2)\nsub_df shape: (3325, 2)\ntrain head:\n                                      id  has_cactus\n0  2de8f189f1dce439766637e75df0ee27.jpg           1\n1  36704d250f236238e7f996812c48235d.jpg           1\n2  eacde22fdc8c175972a5768e3daa8bc9.jpg           1\n3  5d442f834da5e57d22b24802c32a8ca8.jpg           1\n4  152491e0daf75c0e669400300ff7e645.jpg           1\nUnique labels: {1: 10628, 0: 3547}\nPos rate: 0.7498\nSample image sizes: [(32, 32), (32, 32), (32, 32)]\nDevice: cuda\n"
          ]
        }
      ]
    },
    {
      "id": "09d2a0f6-f479-4c09-984b-ac4f64646e81",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install PyTorch (CUDA 12.1 wheels) and torchvision\n",
        "import sys, subprocess, time\n",
        "start = time.time()\n",
        "print('Installing torch/torchvision...')\n",
        "cmd = [sys.executable, '-m', 'pip', 'install', '--quiet', '--upgrade', 'pip']\n",
        "subprocess.run(cmd, check=True)\n",
        "cmd = [sys.executable, '-m', 'pip', 'install', '--quiet', '--index-url', 'https://download.pytorch.org/whl/cu121', 'torch', 'torchvision']\n",
        "subprocess.run(cmd, check=True)\n",
        "print(f'Install done in {time.time()-start:.1f}s')\n",
        "\n",
        "# Quick import test\n",
        "import torch, torchvision\n",
        "print('torch version:', torch.__version__)\n",
        "print('torchvision version:', torchvision.__version__)\n",
        "print('CUDA available:', torch.cuda.is_available())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing torch/torchvision...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33mWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Install done in 106.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.5.1+cu121\ntorchvision version: 0.20.1+cu121\nCUDA available: True\n"
          ]
        }
      ]
    },
    {
      "id": "42e10962-a52a-4d03-86cf-0a78a7c5dce7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dataset, Model, 5-fold Training, Inference, Submission\n",
        "import time, copy\n",
        "from collections import defaultdict\n",
        "\n",
        "class CactusDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transforms=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transforms = transforms\n",
        "        self.has_label = 'has_cactus' in self.df.columns\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['id']\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert('RGB')\n",
        "            img = im\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "        if self.has_label:\n",
        "            label = torch.tensor(row['has_cactus'], dtype=torch.float32)\n",
        "            return img, label\n",
        "        else:\n",
        "            return img, row['id']\n",
        "\n",
        "# Transforms\n",
        "train_tfms = T.Compose([\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomVerticalFlip(p=0.5),\n",
        "    T.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "])\n",
        "valid_tfms = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def block(in_c, out_c):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_c),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_c, out_c, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_c),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(2)\n",
        "            )\n",
        "        self.features = nn.Sequential(\n",
        "            block(3, 32),   # 32->16\n",
        "            block(32, 64),  # 16->8\n",
        "            block(64, 128)  # 8->4\n",
        "        )\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.head = nn.Linear(128, 1)\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.gap(x).flatten(1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "def compute_auc(y_true, y_pred):\n",
        "    try:\n",
        "        return roc_auc_score(y_true, y_pred)\n",
        "    except ValueError:\n",
        "        return float('nan')\n",
        "\n",
        "def train_one_fold(fold, trn_df, val_df, epochs=12, batch_size=256, lr=1e-3, wd=1e-4, min_epochs=5, patience=3):\n",
        "    model = SmallCNN().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    train_ds = CactusDataset(trn_df, TRAIN_DIR, transforms=train_tfms)\n",
        "    val_ds = CactusDataset(val_df, TRAIN_DIR, transforms=valid_tfms)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=False)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, drop_last=False)\n",
        "\n",
        "    best_auc = -1.0\n",
        "    best_state = None\n",
        "    no_improve = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        ep_start = time.time()\n",
        "        # Warmup (simple): linearly scale lr for first 2 epochs\n",
        "        if epoch <= 2:\n",
        "            for pg in optimizer.param_groups:\n",
        "                pg['lr'] = lr * epoch / 2.0\n",
        "        model.train()\n",
        "        trn_loss = 0.0\n",
        "        n_batches = 0\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True).view(-1,1)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n",
        "                logits = model(xb)\n",
        "                loss = loss_fn(logits, yb)\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            trn_loss += loss.item()\n",
        "            n_batches += 1\n",
        "        scheduler.step()\n",
        "        trn_loss /= max(1, n_batches)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_probs = []\n",
        "        val_targets = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb = xb.to(device, non_blocking=True)\n",
        "                logits = model(xb)\n",
        "                probs = torch.sigmoid(logits).squeeze(1).detach().cpu().numpy()\n",
        "                val_probs.append(probs)\n",
        "                val_targets.append(yb.numpy())\n",
        "        val_probs = np.concatenate(val_probs)\n",
        "        val_targets = np.concatenate(val_targets)\n",
        "        val_auc = compute_auc(val_targets, val_probs)\n",
        "        elapsed_ep = time.time() - ep_start\n",
        "        print(f\"Fold {fold} Epoch {epoch}/{epochs} - trn_loss {trn_loss:.4f} val_auc {val_auc:.6f} time {elapsed_ep:.1f}s\")\n",
        "        # Early stopping\n",
        "        improved = val_auc > best_auc + 1e-6\n",
        "        if improved:\n",
        "            best_auc = val_auc\n",
        "            best_state = copy.deepcopy(model.state_dict())\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "        if epoch >= min_epochs and no_improve >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}. Best val_auc {best_auc:.6f}\")\n",
        "            break\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"Fold {fold} training done in {total_time/60:.2f} min. Best AUC {best_auc:.6f}\")\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    # OOF for this fold\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "    model.eval()\n",
        "    oof_probs = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            logits = model(xb)\n",
        "            probs = torch.sigmoid(logits).squeeze(1).cpu().numpy()\n",
        "            oof_probs.append(probs)\n",
        "    oof_probs = np.concatenate(oof_probs)\n",
        "    return model, oof_probs, best_auc\n",
        "\n",
        "# Prepare folds\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "train_df = train_df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)  # shuffle once\n",
        "oof = np.zeros(len(train_df), dtype=np.float32)\n",
        "fold_models = []\n",
        "fold_aucs = []\n",
        "\n",
        "for fold, (trn_idx, val_idx) in enumerate(skf.split(train_df['id'], train_df['has_cactus']), start=1):\n",
        "    trn_df = train_df.iloc[trn_idx].reset_index(drop=True)\n",
        "    val_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
        "    print(f\"========== Fold {fold} (n_trn={len(trn_df)} n_val={len(val_df)}) ==========\")\n",
        "    model, val_probs, best_auc = train_one_fold(\n",
        "        fold=fold, trn_df=trn_df, val_df=val_df,\n",
        "        epochs=12, batch_size=256, lr=1e-3, wd=1e-4, min_epochs=5, patience=3\n",
        "    )\n",
        "    oof[val_idx] = val_probs\n",
        "    fold_models.append(model)\n",
        "    fold_aucs.append(best_auc)\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "oof_auc = compute_auc(train_df['has_cactus'].values, oof)\n",
        "print(f\"OOF AUC: {oof_auc:.6f}\")\n",
        "print(\"Fold AUCs:\", [float(f\"{a:.6f}\") for a in fold_aucs])\n",
        "\n",
        "# Inference with TTA (original, hflip, vflip, rot90) averaged across folds\n",
        "def tta_preds(models, img_tensor):\n",
        "    # img_tensor: [B,3,32,32] normalized\n",
        "    with torch.no_grad():\n",
        "        logits_agg = 0.0\n",
        "        for m in models:\n",
        "            m.eval()\n",
        "            # original\n",
        "            logits = m(img_tensor)\n",
        "            logits_agg += logits\n",
        "            # hflip\n",
        "            logits_agg += m(torch.flip(img_tensor, dims=[3]))\n",
        "            # vflip\n",
        "            logits_agg += m(torch.flip(img_tensor, dims=[2]))\n",
        "            # rot90 (k=1)\n",
        "            logits_agg += m(torch.rot90(img_tensor, k=1, dims=[2,3]))\n",
        "        logits_agg = logits_agg / (len(models) * 4.0)\n",
        "        probs = torch.sigmoid(logits_agg).squeeze(1)\n",
        "    return probs\n",
        "\n",
        "test_ds = CactusDataset(sub_df, TEST_DIR, transforms=valid_tfms)\n",
        "test_loader = DataLoader(test_ds, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
        "all_probs = []\n",
        "start_inf = time.time()\n",
        "with torch.no_grad():\n",
        "    for xb, ids in test_loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        probs = tta_preds(fold_models, xb).cpu().numpy()\n",
        "        all_probs.append(probs)\n",
        "all_probs = np.concatenate(all_probs)\n",
        "print(f\"Test inference done in {time.time()-start_inf:.1f}s\")\n",
        "\n",
        "# Create submission in sample order\n",
        "submission = sub_df.copy()\n",
        "submission['has_cactus'] = all_probs.astype(float)\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with shape:', submission.shape)\n",
        "submission.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Fold 1 (n_trn=11340 n_val=2835) ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:78: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 1/12 - trn_loss 0.1824 val_auc 0.996398 time 4.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 2/12 - trn_loss 0.0816 val_auc 0.997705 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 3/12 - trn_loss 0.0592 val_auc 0.999294 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 4/12 - trn_loss 0.0516 val_auc 0.998784 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 5/12 - trn_loss 0.0339 val_auc 0.999463 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 6/12 - trn_loss 0.0275 val_auc 0.999093 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 7/12 - trn_loss 0.0246 val_auc 0.998875 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 8/12 - trn_loss 0.0198 val_auc 0.999626 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 9/12 - trn_loss 0.0170 val_auc 0.999701 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 10/12 - trn_loss 0.0113 val_auc 0.999647 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 11/12 - trn_loss 0.0095 val_auc 0.999619 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 12/12 - trn_loss 0.0076 val_auc 0.999792 time 3.6s\nFold 1 training done in 0.74 min. Best AUC 0.999792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Fold 2 (n_trn=11340 n_val=2835) ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:78: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 1/12 - trn_loss 0.1983 val_auc 0.994566 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 2/12 - trn_loss 0.0906 val_auc 0.998635 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 3/12 - trn_loss 0.0554 val_auc 0.997253 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 4/12 - trn_loss 0.0467 val_auc 0.998887 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 5/12 - trn_loss 0.0357 val_auc 0.999668 time 3.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 6/12 - trn_loss 0.0298 val_auc 0.999813 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 7/12 - trn_loss 0.0250 val_auc 0.999550 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 8/12 - trn_loss 0.0233 val_auc 0.999854 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 9/12 - trn_loss 0.0176 val_auc 0.999877 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 10/12 - trn_loss 0.0143 val_auc 0.999862 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 11/12 - trn_loss 0.0125 val_auc 0.999876 time 3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 12/12 - trn_loss 0.0117 val_auc 0.999932 time 3.5s\nFold 2 training done in 0.72 min. Best AUC 0.999932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Fold 3 (n_trn=11340 n_val=2835) ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:78: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 1/12 - trn_loss 0.1665 val_auc 0.993516 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 2/12 - trn_loss 0.0800 val_auc 0.997751 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 3/12 - trn_loss 0.0518 val_auc 0.993817 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 4/12 - trn_loss 0.0518 val_auc 0.998712 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 5/12 - trn_loss 0.0418 val_auc 0.998805 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 6/12 - trn_loss 0.0282 val_auc 0.999496 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 7/12 - trn_loss 0.0247 val_auc 0.999402 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 8/12 - trn_loss 0.0177 val_auc 0.999464 time 3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 9/12 - trn_loss 0.0163 val_auc 0.999720 time 3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 10/12 - trn_loss 0.0130 val_auc 0.999574 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 11/12 - trn_loss 0.0107 val_auc 0.999759 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 12/12 - trn_loss 0.0111 val_auc 0.999794 time 3.6s\nFold 3 training done in 0.72 min. Best AUC 0.999794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Fold 4 (n_trn=11340 n_val=2835) ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:78: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 1/12 - trn_loss 0.1859 val_auc 0.991696 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 2/12 - trn_loss 0.0853 val_auc 0.996551 time 3.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 3/12 - trn_loss 0.0664 val_auc 0.998479 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 4/12 - trn_loss 0.0487 val_auc 0.999221 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 5/12 - trn_loss 0.0333 val_auc 0.995456 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 6/12 - trn_loss 0.0290 val_auc 0.998598 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 7/12 - trn_loss 0.0229 val_auc 0.999611 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 8/12 - trn_loss 0.0181 val_auc 0.999665 time 3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 9/12 - trn_loss 0.0144 val_auc 0.999791 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 10/12 - trn_loss 0.0119 val_auc 0.999818 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 11/12 - trn_loss 0.0108 val_auc 0.999779 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 12/12 - trn_loss 0.0096 val_auc 0.999810 time 3.5s\nFold 4 training done in 0.72 min. Best AUC 0.999818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== Fold 5 (n_trn=11340 n_val=2835) ==========\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:78: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device.type=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 1/12 - trn_loss 0.1689 val_auc 0.995291 time 3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 2/12 - trn_loss 0.0859 val_auc 0.992425 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 3/12 - trn_loss 0.0573 val_auc 0.998798 time 3.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 4/12 - trn_loss 0.0420 val_auc 0.999245 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 5/12 - trn_loss 0.0357 val_auc 0.999356 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 6/12 - trn_loss 0.0340 val_auc 0.999779 time 3.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 7/12 - trn_loss 0.0215 val_auc 0.999344 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 8/12 - trn_loss 0.0202 val_auc 0.999807 time 3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 9/12 - trn_loss 0.0135 val_auc 0.999895 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 10/12 - trn_loss 0.0129 val_auc 0.999922 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 11/12 - trn_loss 0.0095 val_auc 0.999955 time 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_61/2851671739.py:104: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 12/12 - trn_loss 0.0083 val_auc 0.999961 time 3.5s\nFold 5 training done in 0.72 min. Best AUC 0.999961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF AUC: 0.999864\nFold AUCs: [0.999792, 0.999932, 0.999794, 0.999818, 0.999961]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test inference done in 2.4s\nSaved submission.csv with shape: (3325, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                     id  has_cactus\n0  09034a34de0e2015a8a28dfe18f423f6.jpg    0.999596\n1  134f04305c795d6d202502c2ce3578f3.jpg    0.999914\n2  41fad8d145e6c41868ce3617e30a2545.jpg    0.999906\n3  35f8a11352c8d41b6231bb33d8d09f7e.jpg    0.999976\n4  b77dc902b035887cbbc01920ce0e3151.jpg    0.999909",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>has_cactus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>09034a34de0e2015a8a28dfe18f423f6.jpg</td>\n      <td>0.999596</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>134f04305c795d6d202502c2ce3578f3.jpg</td>\n      <td>0.999914</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41fad8d145e6c41868ce3617e30a2545.jpg</td>\n      <td>0.999906</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35f8a11352c8d41b6231bb33d8d09f7e.jpg</td>\n      <td>0.999976</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b77dc902b035887cbbc01920ce0e3151.jpg</td>\n      <td>0.999909</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "id": "1e9311fa-5164-4d96-ac44-dde4852f5dce",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Backup Track B: ResNet18 pretrained 5-fold + Ensemble with SmallCNN\n",
        "import os\n",
        "import torchvision.models as models\n",
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "# Ensure a writable cache directory for pretrained weights (avoid read-only /app/.cache)\n",
        "TORCH_CACHE = Path('./torch_cache')\n",
        "TORCH_CACHE.mkdir(exist_ok=True, parents=True)\n",
        "os.environ['TORCH_HOME'] = str(TORCH_CACHE.resolve())\n",
        "os.environ['XDG_CACHE_HOME'] = str(TORCH_CACHE.resolve())  # force torch.hub to use ./torch_cache/torch\n",
        "import torch.hub as hub\n",
        "hub.set_dir(str(TORCH_CACHE.resolve()))\n",
        "print('TORCH_HOME:', os.environ.get('TORCH_HOME'))\n",
        "print('XDG_CACHE_HOME:', os.environ.get('XDG_CACHE_HOME'))\n",
        "\n",
        "IMG_SIZE = 128\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_tfms_res = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE), interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomVerticalFlip(p=0.5),\n",
        "    T.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
        "])\n",
        "valid_tfms_res = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE), interpolation=T.InterpolationMode.BICUBIC),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
        "])\n",
        "\n",
        "class ResNet18Binary(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "        in_feats = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Linear(in_feats, 1)\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "def train_one_fold_resnet(fold, trn_df, val_df, epochs=8, batch_size=128, lr=1e-3, wd=1e-4, min_epochs=4, patience=2):\n",
        "    model = ResNet18Binary().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type=='cuda'))\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    train_ds = CactusDataset(trn_df, TRAIN_DIR, transforms=train_tfms_res)\n",
        "    val_ds = CactusDataset(val_df, TRAIN_DIR, transforms=valid_tfms_res)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=False)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True, drop_last=False)\n",
        "\n",
        "    best_auc = -1.0\n",
        "    best_state = None\n",
        "    no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        if epoch <= 2:\n",
        "            for pg in optimizer.param_groups:\n",
        "                pg['lr'] = lr * epoch / 2.0\n",
        "        model.train()\n",
        "        trn_loss = 0.0\n",
        "        nb = 0\n",
        "        ep_start = time.time()\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True).view(-1,1)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "                logits = model(xb)\n",
        "                loss = loss_fn(logits, yb)\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            trn_loss += loss.item()\n",
        "            nb += 1\n",
        "        scheduler.step()\n",
        "        trn_loss /= max(1, nb)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_probs, val_tgts = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb = xb.to(device, non_blocking=True)\n",
        "                logits = model(xb)\n",
        "                probs = torch.sigmoid(logits).squeeze(1).cpu().numpy()\n",
        "                val_probs.append(probs)\n",
        "                val_tgts.append(yb.numpy())\n",
        "        val_probs = np.concatenate(val_probs)\n",
        "        val_tgts = np.concatenate(val_tgts)\n",
        "        val_auc = compute_auc(val_tgts, val_probs)\n",
        "        print(f\"[ResNet] Fold {fold} Epoch {epoch}/{epochs} - trn_loss {trn_loss:.4f} val_auc {val_auc:.6f} time {time.time()-ep_start:.1f}s\")\n",
        "        if val_auc > best_auc + 1e-6:\n",
        "            best_auc = val_auc\n",
        "            best_state = copy.deepcopy(model.state_dict())\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "        if epoch >= min_epochs and no_improve >= patience:\n",
        "            print(f\"[ResNet] Early stopping at epoch {epoch}. Best AUC {best_auc:.6f}\")\n",
        "            break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    # Return OOF predictions for this fold\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "    model.eval()\n",
        "    oof_probs = []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader:\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            logits = model(xb)\n",
        "            probs = torch.sigmoid(logits).squeeze(1).cpu().numpy()\n",
        "            oof_probs.append(probs)\n",
        "    return model, np.concatenate(oof_probs), best_auc\n",
        "\n",
        "def tta_preds_resnet(models, img_tensor):\n",
        "    with torch.no_grad():\n",
        "        logits_agg = 0.0\n",
        "        for m in models:\n",
        "            m.eval()\n",
        "            logits_agg += m(img_tensor)\n",
        "            logits_agg += m(torch.flip(img_tensor, dims=[3]))\n",
        "            logits_agg += m(torch.flip(img_tensor, dims=[2]))\n",
        "            logits_agg += m(torch.rot90(img_tensor, k=1, dims=[2,3]))\n",
        "        logits_agg = logits_agg / (len(models) * 4.0)\n",
        "        probs = torch.sigmoid(logits_agg).squeeze(1)\n",
        "    return probs\n",
        "\n",
        "# Train 5-fold ResNet18\n",
        "skf2 = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "oof_res = np.zeros(len(train_df), dtype=np.float32)\n",
        "res_models = []\n",
        "res_fold_aucs = []\n",
        "for fold, (trn_idx, val_idx) in enumerate(skf2.split(train_df['id'], train_df['has_cactus']), start=1):\n",
        "    trn_df = train_df.iloc[trn_idx].reset_index(drop=True)\n",
        "    val_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
        "    print(f\"[ResNet] ===== Fold {fold} (n_trn={len(trn_df)} n_val={len(val_df)}) =====\")\n",
        "    model, val_probs, best_auc = train_one_fold_resnet(\n",
        "        fold=fold, trn_df=trn_df, val_df=val_df,\n",
        "        epochs=8, batch_size=128, lr=1e-3, wd=1e-4, min_epochs=4, patience=2\n",
        "    )\n",
        "    oof_res[val_idx] = val_probs\n",
        "    res_models.append(model)\n",
        "    res_fold_aucs.append(best_auc)\n",
        "    gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "oof_auc_res = compute_auc(train_df['has_cactus'].values, oof_res)\n",
        "print(f\"[ResNet] OOF AUC: {oof_auc_res:.6f}\")\n",
        "print(\"[ResNet] Fold AUCs:\", [float(f\"{a:.6f}\") for a in res_fold_aucs])\n",
        "\n",
        "# Test inference for ResNet\n",
        "test_ds_res = CactusDataset(sub_df, TEST_DIR, transforms=valid_tfms_res)\n",
        "test_loader_res = DataLoader(test_ds_res, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
        "all_probs_res = []\n",
        "with torch.no_grad():\n",
        "    for xb, ids in test_loader_res:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        probs = tta_preds_resnet(res_models, xb).cpu().numpy()\n",
        "        all_probs_res.append(probs)\n",
        "all_probs_res = np.concatenate(all_probs_res)\n",
        "\n",
        "# Recompute SmallCNN test preds (ensure fresh loader) and ensemble\n",
        "test_ds_small = CactusDataset(sub_df, TEST_DIR, transforms=valid_tfms)\n",
        "test_loader_small = DataLoader(test_ds_small, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
        "all_probs_small = []\n",
        "with torch.no_grad():\n",
        "    for xb, ids in test_loader_small:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        probs = tta_preds(fold_models, xb).cpu().numpy()\n",
        "        all_probs_small.append(probs)\n",
        "all_probs_small = np.concatenate(all_probs_small)\n",
        "\n",
        "final_probs = (all_probs_small + all_probs_res) / 2.0\n",
        "submission2 = sub_df.copy()\n",
        "submission2['has_cactus'] = final_probs.astype(float)\n",
        "submission2.to_csv('submission.csv', index=False)\n",
        "print('Ensembled submission saved. Shape:', submission2.shape)\n",
        "submission2.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TORCH_HOME: /app/agent_run_states/aerial-cactus-identification-spray-20250910-034735/torch_cache\nXDG_CACHE_HOME: /app/agent_run_states/aerial-cactus-identification-spray-20250910-034735/torch_cache\n[ResNet] ===== Fold 1 (n_trn=11340 n_val=2835) =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /app/agent_run_states/aerial-cactus-identification-spray-20250910-034735/torch_cache/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|\u2588\u2588\u2588\u258c      | 16.1M/44.7M [00:00<00:00, 168MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 39.2M/44.7M [00:00<00:00, 212MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 44.7M/44.7M [00:00<00:00, 209MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 1 Epoch 1/8 - trn_loss 0.0536 val_auc 0.999820 time 7.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 1 Epoch 2/8 - trn_loss 0.0319 val_auc 0.999303 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 1 Epoch 3/8 - trn_loss 0.0401 val_auc 0.999626 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 1 Epoch 4/8 - trn_loss 0.0220 val_auc 0.999976 time 7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 1 Epoch 5/8 - trn_loss 0.0145 val_auc 0.999969 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 1 Epoch 6/8 - trn_loss 0.0032 val_auc 0.999997 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 1 Epoch 7/8 - trn_loss 0.0015 val_auc 1.000000 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 1 Epoch 8/8 - trn_loss 0.0004 val_auc 1.000000 time 6.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] ===== Fold 2 (n_trn=11340 n_val=2835) =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 2 Epoch 1/8 - trn_loss 0.0557 val_auc 0.999903 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 2 Epoch 2/8 - trn_loss 0.0336 val_auc 0.999625 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 2 Epoch 3/8 - trn_loss 0.0189 val_auc 0.999662 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 2 Epoch 4/8 - trn_loss 0.0235 val_auc 0.999122 time 6.9s\n[ResNet] Early stopping at epoch 4. Best AUC 0.999903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] ===== Fold 3 (n_trn=11340 n_val=2835) =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 3 Epoch 1/8 - trn_loss 0.0533 val_auc 0.999916 time 7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 3 Epoch 2/8 - trn_loss 0.0287 val_auc 0.999064 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 3 Epoch 3/8 - trn_loss 0.0273 val_auc 0.999699 time 7.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 3 Epoch 4/8 - trn_loss 0.0196 val_auc 0.999203 time 6.9s\n[ResNet] Early stopping at epoch 4. Best AUC 0.999916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] ===== Fold 4 (n_trn=11340 n_val=2835) =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 4 Epoch 1/8 - trn_loss 0.0520 val_auc 0.999900 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 4 Epoch 2/8 - trn_loss 0.0422 val_auc 0.999239 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 4 Epoch 3/8 - trn_loss 0.0289 val_auc 0.999856 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 4 Epoch 4/8 - trn_loss 0.0286 val_auc 0.999834 time 6.9s\n[ResNet] Early stopping at epoch 4. Best AUC 0.999900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] ===== Fold 5 (n_trn=11340 n_val=2835) =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 5 Epoch 1/8 - trn_loss 0.0885 val_auc 0.999910 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 5 Epoch 2/8 - trn_loss 0.0441 val_auc 0.999200 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 5 Epoch 3/8 - trn_loss 0.0258 val_auc 0.999645 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 5 Epoch 4/8 - trn_loss 0.0210 val_auc 0.999992 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 5 Epoch 5/8 - trn_loss 0.0164 val_auc 1.000000 time 6.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 5 Epoch 6/8 - trn_loss 0.0042 val_auc 1.000000 time 6.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] Fold 5 Epoch 7/8 - trn_loss 0.0029 val_auc 1.000000 time 7.1s\n[ResNet] Early stopping at epoch 7. Best AUC 1.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ResNet] OOF AUC: 0.999919\n[ResNet] Fold AUCs: [1.0, 0.999903, 0.999916, 0.9999, 1.0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensembled submission saved. Shape: (3325, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                     id  has_cactus\n0  09034a34de0e2015a8a28dfe18f423f6.jpg    0.999798\n1  134f04305c795d6d202502c2ce3578f3.jpg    0.999956\n2  41fad8d145e6c41868ce3617e30a2545.jpg    0.999952\n3  35f8a11352c8d41b6231bb33d8d09f7e.jpg    0.999987\n4  b77dc902b035887cbbc01920ce0e3151.jpg    0.999953",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>has_cactus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>09034a34de0e2015a8a28dfe18f423f6.jpg</td>\n      <td>0.999798</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>134f04305c795d6d202502c2ce3578f3.jpg</td>\n      <td>0.999956</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41fad8d145e6c41868ce3617e30a2545.jpg</td>\n      <td>0.999952</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35f8a11352c8d41b6231bb33d8d09f7e.jpg</td>\n      <td>0.999987</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b77dc902b035887cbbc01920ce0e3151.jpg</td>\n      <td>0.999953</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "id": "537ed35c-6d60-4363-a8d8-a1faafa0d090",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Recompute test predictions with stronger 8-way TTA and re-save submission\n",
        "import torch\n",
        "def tta8_preds(models, x):\n",
        "    # x: [B,3,H,W]\n",
        "    outs = 0.0\n",
        "    trans = []\n",
        "    trans.append(x)  # 0 deg\n",
        "    trans.append(torch.flip(x, dims=[3]))  # hflip\n",
        "    trans.append(torch.flip(x, dims=[2]))  # vflip\n",
        "    trans.append(torch.rot90(x, k=1, dims=[2,3]))  # 90\n",
        "    trans.append(torch.rot90(x, k=2, dims=[2,3]))  # 180\n",
        "    trans.append(torch.rot90(x, k=3, dims=[2,3]))  # 270\n",
        "    trans.append(torch.flip(torch.rot90(x, k=1, dims=[2,3]), dims=[3]))  # 90 + hflip\n",
        "    trans.append(torch.flip(torch.rot90(x, k=1, dims=[2,3]), dims=[2]))  # 90 + vflip\n",
        "    with torch.no_grad():\n",
        "        for m in models:\n",
        "            m.eval()\n",
        "            logits_sum = 0.0\n",
        "            for t in trans:\n",
        "                logits_sum = logits_sum + m(t)\n",
        "            outs = outs + logits_sum / len(trans)\n",
        "    outs = outs / len(models)\n",
        "    probs = torch.sigmoid(outs).squeeze(1)\n",
        "    return probs\n",
        "\n",
        "# SmallCNN test preds with 8-way TTA\n",
        "test_ds_small8 = CactusDataset(sub_df, TEST_DIR, transforms=valid_tfms)\n",
        "test_loader_small8 = DataLoader(test_ds_small8, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
        "probs_small8 = []\n",
        "with torch.no_grad():\n",
        "    for xb, ids in test_loader_small8:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        probs_small8.append(tta8_preds(fold_models, xb).cpu().numpy())\n",
        "probs_small8 = np.concatenate(probs_small8)\n",
        "\n",
        "# ResNet18 test preds with 8-way TTA\n",
        "test_ds_res8 = CactusDataset(sub_df, TEST_DIR, transforms=valid_tfms_res)\n",
        "test_loader_res8 = DataLoader(test_ds_res8, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
        "probs_res8 = []\n",
        "with torch.no_grad():\n",
        "    for xb, ids in test_loader_res8:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        probs_res8.append(tta8_preds(res_models, xb).cpu().numpy())\n",
        "probs_res8 = np.concatenate(probs_res8)\n",
        "\n",
        "# Weighted ensemble (lean slightly on ResNet)\n",
        "final_probs8 = (0.6 * probs_res8 + 0.4 * probs_small8).astype(float)\n",
        "submission8 = sub_df.copy()\n",
        "submission8['has_cactus'] = final_probs8\n",
        "submission8.to_csv('submission.csv', index=False)\n",
        "print('Saved enhanced TTA submission.csv. Shape:', submission8.shape)\n",
        "submission8.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved enhanced TTA submission.csv. Shape: (3325, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                     id  has_cactus\n0  09034a34de0e2015a8a28dfe18f423f6.jpg    0.999739\n1  134f04305c795d6d202502c2ce3578f3.jpg    0.999962\n2  41fad8d145e6c41868ce3617e30a2545.jpg    0.999972\n3  35f8a11352c8d41b6231bb33d8d09f7e.jpg    0.999991\n4  b77dc902b035887cbbc01920ce0e3151.jpg    0.999964",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>has_cactus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>09034a34de0e2015a8a28dfe18f423f6.jpg</td>\n      <td>0.999739</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>134f04305c795d6d202502c2ce3578f3.jpg</td>\n      <td>0.999962</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41fad8d145e6c41868ce3617e30a2545.jpg</td>\n      <td>0.999972</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35f8a11352c8d41b6231bb33d8d09f7e.jpg</td>\n      <td>0.999991</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b77dc902b035887cbbc01920ce0e3151.jpg</td>\n      <td>0.999964</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "id": "08abf64b-9e60-4778-94c4-b93499c30fba",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add pixel-level Logistic Regression CV model and ensemble with current submission\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def load_flat_pixels(df, img_dir):\n",
        "    X = np.zeros((len(df), 32*32*3), dtype=np.float32)\n",
        "    for i, img_id in enumerate(df['id'].values):\n",
        "        with Image.open(Path(img_dir)/img_id) as im:\n",
        "            im = im.convert('RGB')\n",
        "            arr = np.asarray(im, dtype=np.float32) / 255.0\n",
        "        X[i] = arr.reshape(-1)\n",
        "        if (i+1) % 5000 == 0:\n",
        "            print(f\"Loaded {i+1}/{len(df)} images...\", flush=True)\n",
        "    return X\n",
        "\n",
        "print('Loading flat pixel features for train/test...')\n",
        "X = load_flat_pixels(train_df, TRAIN_DIR)\n",
        "X_test = load_flat_pixels(sub_df, TEST_DIR)\n",
        "y = train_df['has_cactus'].values.astype(np.int32)\n",
        "print('Shapes:', X.shape, X_test.shape)\n",
        "\n",
        "skf_lr = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "oof_lr = np.zeros(len(train_df), dtype=np.float32)\n",
        "test_preds_lr = np.zeros(len(sub_df), dtype=np.float32)\n",
        "\n",
        "fold = 1\n",
        "for trn_idx, val_idx in skf_lr.split(X, y):\n",
        "    print(f\"[LR] Fold {fold}: train {len(trn_idx)} val {len(val_idx)}\")\n",
        "    X_tr, X_va = X[trn_idx], X[val_idx]\n",
        "    y_tr, y_va = y[trn_idx], y[val_idx]\n",
        "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
        "    X_trs = scaler.fit_transform(X_tr)\n",
        "    X_vas = scaler.transform(X_va)\n",
        "    X_tes = scaler.transform(X_test)\n",
        "    clf = LogisticRegression(max_iter=500, C=1.0, solver='lbfgs')\n",
        "    clf.fit(X_trs, y_tr)\n",
        "    oof_lr[val_idx] = clf.predict_proba(X_vas)[:,1]\n",
        "    test_preds_lr += clf.predict_proba(X_tes)[:,1] / skf_lr.n_splits\n",
        "    fold += 1\n",
        "\n",
        "auc_lr = roc_auc_score(y, oof_lr)\n",
        "print(f\"[LR] OOF AUC: {auc_lr:.6f}\")\n",
        "\n",
        "# Ensemble with current submission.csv predictions\n",
        "prev_sub = pd.read_csv('submission.csv')\n",
        "assert 'has_cactus' in prev_sub.columns and len(prev_sub)==len(sub_df)\n",
        "ens_probs = 0.5 * prev_sub['has_cactus'].values.astype(float) + 0.5 * test_preds_lr.astype(float)\n",
        "final_sub = sub_df.copy()\n",
        "final_sub['has_cactus'] = ens_probs\n",
        "final_sub.to_csv('submission.csv', index=False)\n",
        "print('Saved LR-ensembled submission.csv. Shape:', final_sub.shape)\n",
        "final_sub.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading flat pixel features for train/test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 5000/14175 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 10000/14175 images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (14175, 3072) (3325, 3072)\n[LR] Fold 1: train 11340 val 2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR] Fold 2: train 11340 val 2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR] Fold 3: train 11340 val 2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR] Fold 4: train 11340 val 2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR] Fold 5: train 11340 val 2835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR] OOF AUC: 0.950838\nSaved LR-ensembled submission.csv. Shape: (3325, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                     id  has_cactus\n0  09034a34de0e2015a8a28dfe18f423f6.jpg    0.692693\n1  134f04305c795d6d202502c2ce3578f3.jpg    0.999976\n2  41fad8d145e6c41868ce3617e30a2545.jpg    0.999677\n3  35f8a11352c8d41b6231bb33d8d09f7e.jpg    0.972646\n4  b77dc902b035887cbbc01920ce0e3151.jpg    0.922241",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>has_cactus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>09034a34de0e2015a8a28dfe18f423f6.jpg</td>\n      <td>0.692693</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>134f04305c795d6d202502c2ce3578f3.jpg</td>\n      <td>0.999976</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41fad8d145e6c41868ce3617e30a2545.jpg</td>\n      <td>0.999677</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35f8a11352c8d41b6231bb33d8d09f7e.jpg</td>\n      <td>0.972646</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b77dc902b035887cbbc01920ce0e3151.jpg</td>\n      <td>0.922241</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "id": "9c33926b-eb5a-4f66-b6b3-d0768efca055",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Overwrite submission with ResNet18-only 8-way TTA (no LR, no SmallCNN)\n",
        "import torch\n",
        "\n",
        "def tta8_preds_res_only(models, x):\n",
        "    outs = 0.0\n",
        "    trans = []\n",
        "    trans.append(x)\n",
        "    trans.append(torch.flip(x, dims=[3]))\n",
        "    trans.append(torch.flip(x, dims=[2]))\n",
        "    trans.append(torch.rot90(x, k=1, dims=[2,3]))\n",
        "    trans.append(torch.rot90(x, k=2, dims=[2,3]))\n",
        "    trans.append(torch.rot90(x, k=3, dims=[2,3]))\n",
        "    trans.append(torch.flip(torch.rot90(x, k=1, dims=[2,3]), dims=[3]))\n",
        "    trans.append(torch.flip(torch.rot90(x, k=1, dims=[2,3]), dims=[2]))\n",
        "    with torch.no_grad():\n",
        "        for m in models:\n",
        "            m.eval()\n",
        "            logits_sum = 0.0\n",
        "            for t in trans:\n",
        "                logits_sum = logits_sum + m(t)\n",
        "            outs = outs + logits_sum / len(trans)\n",
        "    outs = outs / len(models)\n",
        "    probs = torch.sigmoid(outs).squeeze(1)\n",
        "    return probs\n",
        "\n",
        "# DataLoader for ResNet transforms already defined as valid_tfms_res\n",
        "test_ds_res8_only = CactusDataset(sub_df, TEST_DIR, transforms=valid_tfms_res)\n",
        "test_loader_res8_only = DataLoader(test_ds_res8_only, batch_size=256, shuffle=False, num_workers=4, pin_memory=True)\n",
        "probs_res8_only = []\n",
        "with torch.no_grad():\n",
        "    for xb, ids in test_loader_res8_only:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        probs_res8_only.append(tta8_preds_res_only(res_models, xb).cpu().numpy())\n",
        "probs_res8_only = np.concatenate(probs_res8_only).astype(float)\n",
        "\n",
        "sub_res_only = sub_df.copy()\n",
        "sub_res_only['has_cactus'] = probs_res8_only\n",
        "sub_res_only.to_csv('submission.csv', index=False)\n",
        "print('Saved ResNet-only 8-way TTA submission.csv. Shape:', sub_res_only.shape)\n",
        "sub_res_only.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved ResNet-only 8-way TTA submission.csv. Shape: (3325, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                     id  has_cactus\n0  09034a34de0e2015a8a28dfe18f423f6.jpg    0.999999\n1  134f04305c795d6d202502c2ce3578f3.jpg    0.999998\n2  41fad8d145e6c41868ce3617e30a2545.jpg    0.999998\n3  35f8a11352c8d41b6231bb33d8d09f7e.jpg    0.999999\n4  b77dc902b035887cbbc01920ce0e3151.jpg    0.999998",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>has_cactus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>09034a34de0e2015a8a28dfe18f423f6.jpg</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>134f04305c795d6d202502c2ce3578f3.jpg</td>\n      <td>0.999998</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41fad8d145e6c41868ce3617e30a2545.jpg</td>\n      <td>0.999998</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35f8a11352c8d41b6231bb33d8d09f7e.jpg</td>\n      <td>0.999999</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b77dc902b035887cbbc01920ce0e3151.jpg</td>\n      <td>0.999998</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}