{
  "cells": [
    {
      "id": "4850eae0-a4c9-4996-8fd8-7e917064da52",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan to Medal: Google Brain Ventilator Pressure Prediction\n",
        "\n",
        "Objectives:\n",
        "- Establish GPU-verified environment and robust CV.\n",
        "- Build fast, strong baseline (XGBoost GPU) with proven ventilator FE.\n",
        "- Pivot to a BiGRU baseline; blend with trees; apply fold-safe snapping.\n",
        "\n",
        "Data facts (from prior comp):\n",
        "- Each breath_id is a sequence of 80 timesteps.\n",
        "- Inputs: time_step, u_in, u_out, R, C, plus engineered sequence features.\n",
        "- Target: pressure; evaluation uses only timesteps where u_out == 0 (we predict all steps, but mask metric/loss to u_out==0).\n",
        "\n",
        "Validation:\n",
        "- 5-fold GroupKFold by breath_id to avoid leakage; stratify folds by (R, C) distribution if possible.\n",
        "- Fix seeds; log OOF per fold; save OOF for error analysis.\n",
        "- Metric: MAE computed only on u_out==0 (masked).\n",
        "\n",
        "Baseline v1:\n",
        "- FE: lags/leads of u_in, rolling stats per breath, cumulative integrals (volume via u_in*dt), time diffs, R/C and interaction, step index (t_idx 0..79), RC-aware EWM.\n",
        "- Model: XGBoost regressor with GPU, objective=reg:squarederror, eval_metric=mae, sample_weight=(u_out==0). Early stopping.\n",
        "- Post-proc: fold-safe snap to train pressure grid; test snap per-(R,C) grid, optional median filter (window=3) per breath.\n",
        "\n",
        "Next iterations:\n",
        "- BiGRU baseline with masked MAE; inputs: physics + dynamics features above.\n",
        "- Blend BiGRU + XGB (and CatBoost if time); tune weights on OOF; snap after blend.\n",
        "\n",
        "Discipline:\n",
        "- Cache features to feather/parquet.\n",
        "- Heavy jobs: print elapsed per fold; stop if divergence.\n",
        "- After baseline built, request expert review for FE/model/validation.\n",
        "\n",
        "Milestones:\n",
        "1) Env + EDA + CV spec.\n",
        "2) FE v1 + XGB baseline OOF (masked MAE + fold-safe snap).\n",
        "3) BiGRU baseline + OOF + snap; blend with XGB.\n",
        "4) Finalize blend + per-(R,C) snap + median(3) + submission."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a511b9c9-9ae0-406f-b172-8ac2def9c7e9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, time, subprocess, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "t0 = time.time()\n",
        "print('=== Environment check ===', flush=True)\n",
        "try:\n",
        "    out = subprocess.run(['bash','-lc','nvidia-smi || true'], capture_output=True, text=True, check=False)\n",
        "    print(out.stdout.strip()[:2000], flush=True)\n",
        "except Exception as e:\n",
        "    print('nvidia-smi error:', e, flush=True)\n",
        "print('Python', sys.version)\n",
        "print('Pandas', pd.__version__)\n",
        "\n",
        "print('\\n=== Load data ===', flush=True)\n",
        "train_path = Path('train.csv')\n",
        "test_path = Path('test.csv')\n",
        "assert train_path.exists() and test_path.exists(), 'Missing train/test CSVs'\n",
        "usecols = None  # load all\n",
        "train = pd.read_csv(train_path, low_memory=False, usecols=usecols)\n",
        "test = pd.read_csv(test_path, low_memory=False, usecols=usecols)\n",
        "print('train shape:', train.shape, 'test shape:', test.shape, flush=True)\n",
        "print('train columns:', list(train.columns), flush=True)\n",
        "print('\\nDtypes:\\n', train.dtypes, flush=True)\n",
        "print('\\nMemory usage (MB):', round(train.memory_usage(deep=True).sum()/1e6, 2), flush=True)\n",
        "\n",
        "if 'pressure' in train.columns:\n",
        "    desc = train['pressure'].describe()\n",
        "    print('\\npressure describe:\\n', desc, flush=True)\n",
        "    print('pressure unique approx:', train['pressure'].nunique(), flush=True)\n",
        "\n",
        "key_cols = [c for c in ['breath_id','R','C','time_step','u_in','u_out'] if c in train.columns]\n",
        "print('\\nKey cols present:', key_cols, flush=True)\n",
        "if 'breath_id' in train.columns:\n",
        "    n_breaths = train['breath_id'].nunique()\n",
        "    lens = train.groupby('breath_id').size().value_counts().head()\n",
        "    print('breaths:', n_breaths, 'sequence length distribution (top):\\n', lens, flush=True)\n",
        "    # quick check: typical 80 timesteps\n",
        "    if 80 in train.groupby('breath_id').size().values:\n",
        "        print('80-timestep sequences detected', flush=True)\n",
        "\n",
        "print('\\nHead:\\n', train.head(8), flush=True)\n",
        "print('\\nElapsed:', round(time.time()-t0,2), 's', flush=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Environment check ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 24 17:01:11 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     128MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0]\nPandas 2.2.2\n\n=== Load data ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape: (5432400, 8) test shape: (603600, 7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train columns: ['id', 'breath_id', 'R', 'C', 'time_step', 'u_in', 'u_out', 'pressure']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nDtypes:\n id             int64\nbreath_id      int64\nR              int64\nC              int64\ntime_step    float64\nu_in         float64\nu_out          int64\npressure     float64\ndtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nMemory usage (MB): 347.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\npressure describe:\n count    5.432400e+06\nmean     1.121807e+01\nstd      8.106474e+00\nmin     -1.895744e+00\n25%      6.329607e+00\n50%      7.032628e+00\n75%      1.364103e+01\nmax      6.482099e+01\nName: pressure, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pressure unique approx: 950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nKey cols present: ['breath_id', 'R', 'C', 'time_step', 'u_in', 'u_out']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "breaths: 67905 sequence length distribution (top):\n 80    67905\nName: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80-timestep sequences detected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nHead:\n    id  breath_id  R   C  time_step      u_in  u_out   pressure\n0   1      85053  5  10   0.000000  4.174419      0   6.118700\n1   2      85053  5  10   0.033812  7.050149      0   5.907794\n2   3      85053  5  10   0.067497  7.564931      0   7.313837\n3   4      85053  5  10   0.101394  8.103306      0   8.227765\n4   5      85053  5  10   0.135344  8.502619      0   9.422901\n5   6      85053  5  10   0.169323  8.758625      0  10.899246\n6   7      85053  5  10   0.203229  9.110845      0  11.602268\n7   8      85053  5  10   0.236715  9.209150      0  13.148915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nElapsed: 2.19 s\n"
          ]
        }
      ]
    },
    {
      "id": "ebb43ef7-d825-400f-a96c-3594ced34c43",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, numpy as np, pandas as pd, os, gc\n",
        "from pathlib import Path\n",
        "t0 = time.time()\n",
        "print('=== FE v3: expanded physics + dynamics + integrals + breath stats (stabilized) + peak & vol_insp lags ===', flush=True)\n",
        "\n",
        "# Load (reuse if present)\n",
        "if 'train' not in globals():\n",
        "    train = pd.read_csv('train.csv')\n",
        "if 'test' not in globals():\n",
        "    test = pd.read_csv('test.csv')\n",
        "\n",
        "# Concatenate for consistent FE\n",
        "train['is_train'] = 1\n",
        "test['is_train'] = 0\n",
        "test['pressure'] = np.nan  # placeholder to keep cols aligned\n",
        "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
        "df = df.sort_values(['breath_id','time_step']).reset_index(drop=True)\n",
        "\n",
        "# Helpers\n",
        "grp = df.groupby('breath_id', sort=False)\n",
        "\n",
        "# Base\n",
        "df['t_idx'] = grp.cumcount().astype(np.int16)\n",
        "df['dt'] = grp['time_step'].diff().fillna(0.0).astype(np.float32)\n",
        "df['t_idx_norm'] = (df['t_idx'] / 79.0).astype(np.float32)\n",
        "df['RC'] = (df['R'] * df['C']).astype(np.int32)\n",
        "df['rc_key'] = (df['R'] * 100 + df['C']).astype(np.int32)\n",
        "\n",
        "# Lags/Leads\n",
        "for k in [1,2,3,4,5]:\n",
        "    df[f'u_in_lag{k}'] = grp['u_in'].shift(k).fillna(0.0)\n",
        "for k in [1,2]:\n",
        "    df[f'u_in_lead{k}'] = grp['u_in'].shift(-k).fillna(0.0)\n",
        "\n",
        "# First/second/third diffs\n",
        "df['du1'] = (df['u_in'] - df['u_in_lag1']).astype(np.float32)\n",
        "df['du2'] = (df['u_in'] - df['u_in_lag2']).astype(np.float32)\n",
        "df['du3'] = (df['u_in'] - df['u_in_lag3']).astype(np.float32)\n",
        "\n",
        "# Rolling stats (window=3) per breath\n",
        "roll = grp['u_in'].rolling(window=3, min_periods=1)\n",
        "df['roll_mean3_uin'] = roll.mean().reset_index(level=0, drop=True)\n",
        "df['roll_std3_uin']  = roll.std().reset_index(level=0, drop=True).fillna(0.0)\n",
        "df['roll_max3_uin']  = roll.max().reset_index(level=0, drop=True)\n",
        "\n",
        "# Integrals/areas\n",
        "df['vol_dt'] = (df['u_in'] * df['dt']).groupby(df['breath_id']).cumsum()\n",
        "df['u_in_cumsum'] = grp['u_in'].cumsum()\n",
        "insp_mask = (df['u_out'] == 0).astype(np.float32)\n",
        "df['vol_insp'] = (df['u_in'] * df['dt'] * insp_mask).groupby(df['breath_id']).cumsum()\n",
        "df['u_in_cumsum_insp'] = (df['u_in'] * insp_mask).groupby(df['breath_id']).cumsum()\n",
        "\n",
        "# vol_insp lags and rolling mean\n",
        "for k in [1,2,3]:\n",
        "    df[f'vol_insp_lag{k}'] = grp['vol_insp'].shift(k).fillna(0.0)\n",
        "df['roll_mean3_vol_insp'] = grp['vol_insp'].rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "# Breath stats (broadcast within breath)\n",
        "b_max = grp['u_in'].transform('max')\n",
        "b_mean = grp['u_in'].transform('mean')\n",
        "b_std = grp['u_in'].transform('std').fillna(0.0)\n",
        "df['u_in_max_breath'] = b_max\n",
        "df['u_in_mean_breath'] = b_mean\n",
        "df['u_in_std_breath'] = b_std\n",
        "end_vol = grp['vol_dt'].transform('last')\n",
        "df['vol_dt_end_breath'] = end_vol\n",
        "df['u_in_over_max'] = (df['u_in'] / (b_max + 1e-6)).astype(np.float32)\n",
        "df['vol_dt_over_end'] = (df['vol_dt'] / (end_vol + 1e-6)).fillna(0.0).astype(np.float32)\n",
        "\n",
        "# Peak features: idx_peak_uin, u_in_at_peak, dist_to_peak, vol_at_peak\n",
        "peak_idx_rows = df.loc[grp['u_in'].idxmax(), ['breath_id','t_idx','u_in','vol_insp']]\n",
        "peak_idx_rows = peak_idx_rows.rename(columns={'t_idx':'idx_peak_uin','u_in':'u_in_at_peak','vol_insp':'vol_at_peak'})\n",
        "df = df.merge(peak_idx_rows, on='breath_id', how='left')\n",
        "df['idx_peak_uin'] = df['idx_peak_uin'].astype(np.int16)\n",
        "df['u_in_at_peak'] = df['u_in_at_peak'].astype(np.float32)\n",
        "df['vol_at_peak'] = df['vol_at_peak'].astype(np.float32)\n",
        "df['dist_to_peak'] = (df['t_idx'].astype(np.int16) - df['idx_peak_uin'].astype(np.int16)).astype(np.int16)\n",
        "\n",
        "# RC/physics + interactions\n",
        "df['R_term'] = (df['R'].astype(np.float32) * df['u_in'].astype(np.float32))\n",
        "df['V_term'] = (df['vol_dt'] / df['C'].replace(0, np.nan)).fillna(0.0)\n",
        "\n",
        "def ewm_rc_group(g):\n",
        "    u = g['u_in'].to_numpy(dtype=np.float32, copy=False)\n",
        "    dt = g['dt'].to_numpy(dtype=np.float32, copy=False)\n",
        "    RC_val = float(g['R'].iloc[0]) * float(g['C'].iloc[0])\n",
        "    if RC_val == 0:\n",
        "        RC_val = 1.0\n",
        "    RC = np.float32(RC_val)\n",
        "    alpha = 1.0 - np.exp(-dt / RC)\n",
        "    y = np.empty_like(u, dtype=np.float32)\n",
        "    prev = np.float32(0.0)\n",
        "    for i in range(u.shape[0]):\n",
        "        a = alpha[i]\n",
        "        prev = a * u[i] + (1.0 - a) * prev\n",
        "        y[i] = prev\n",
        "    return pd.Series(y, index=g.index, dtype='float32')\n",
        "df['ewm_rc'] = grp.apply(ewm_rc_group).reset_index(level=0, drop=True)\n",
        "\n",
        "# Simple per-breath EWM of u_in (alpha ~0.1)\n",
        "def ewm_simple_group(g, alpha=0.1):\n",
        "    u = g['u_in'].to_numpy(dtype=np.float32, copy=False)\n",
        "    y = np.empty_like(u, dtype=np.float32)\n",
        "    prev = np.float32(0.0)\n",
        "    a = np.float32(alpha)\n",
        "    for i in range(u.shape[0]):\n",
        "        prev = a * u[i] + (1.0 - a) * prev\n",
        "        y[i] = prev\n",
        "    return pd.Series(y, index=g.index, dtype='float32')\n",
        "df['ewm_simple_uin'] = grp.apply(ewm_simple_group).reset_index(level=0, drop=True)\n",
        "\n",
        "df['u_in_time'] = (df['u_in'] * df['time_step']).astype(np.float32)\n",
        "# Patch B: stabilize u_in_dt and du1_dt; clamp to sane range and add diagnostics\n",
        "dt_eps = 1e-3\n",
        "dt_arr = df['dt'].to_numpy(dtype=np.float32, copy=False)\n",
        "dt_safe = np.where(dt_arr > dt_eps, dt_arr, dt_eps).astype(np.float32)\n",
        "uin = df['u_in'].to_numpy(dtype=np.float32, copy=False)\n",
        "uin_dt = (uin / dt_safe).astype(np.float32)\n",
        "uin_dt = np.clip(uin_dt, -2e3, 2e3)\n",
        "df['u_in_dt'] = uin_dt\n",
        "du1 = df['du1'].to_numpy(dtype=np.float32, copy=False)\n",
        "du1_dt = (du1 / dt_safe).astype(np.float32)\n",
        "du1_dt = np.clip(du1_dt, -2e3, 2e3)\n",
        "df['du1_dt'] = du1_dt\n",
        "\n",
        "# Phase/progress\n",
        "df['breath_progress'] = df['t_idx_norm']\n",
        "df['u_out_lag1'] = grp['u_out'].shift(1).fillna(0).astype(np.int16)\n",
        "df['u_out_lead1'] = grp['u_out'].shift(-1).fillna(0).astype(np.int16)\n",
        "df['insp_step'] = grp['u_out'].apply(lambda s: (~(s.astype(bool))).cumsum()).reset_index(level=0, drop=True).astype(np.int16)\n",
        "df['insp_max'] = grp['insp_step'].transform('max').replace(0, 1).astype(np.int16)\n",
        "df['insp_frac'] = (df['insp_step'] / df['insp_max'].replace(0, 1)).astype(np.float32)\n",
        "\n",
        "# Cast types for memory (safe casts only)\n",
        "for col in ['t_idx','R','C','RC','rc_key','u_out','u_out_lag1','u_out_lead1','insp_step','insp_max','idx_peak_uin','dist_to_peak']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(np.int16)\n",
        "\n",
        "num_cols = [\n",
        "    'time_step','u_in','pressure','dt','t_idx_norm','breath_progress',\n",
        "    'u_in_lag1','u_in_lag2','u_in_lag3','u_in_lag4','u_in_lag5','u_in_lead1','u_in_lead2',\n",
        "    'du1','du2','du3','du1_dt','roll_mean3_uin','roll_std3_uin','roll_max3_uin',\n",
        "    'vol_dt','vol_insp','vol_insp_lag1','vol_insp_lag2','vol_insp_lag3','roll_mean3_vol_insp',\n",
        "    'u_in_cumsum','u_in_cumsum_insp','vol_dt_end_breath',\n",
        "    'u_in_over_max','vol_dt_over_end','R_term','V_term','ewm_rc','ewm_simple_uin','u_in_time','u_in_dt',\n",
        "    'u_in_at_peak','vol_at_peak'\n",
        "]\n",
        "for col in num_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').astype(np.float32)\n",
        "\n",
        "# Diagnostics for NaN/Inf after FE\n",
        "num_check_cols = [c for c in df.columns if c not in ['id'] and (np.issubdtype(df[c].dtype, np.number))]\n",
        "n_nans = 0; n_infs = 0\n",
        "for c in num_check_cols:\n",
        "    vals = df[c].to_numpy()\n",
        "    n_nans += np.isnan(vals).sum()\n",
        "    n_infs += np.isinf(vals).sum()\n",
        "print(f'FE diagnostics: total NaNs={int(n_nans)} | Infs={int(n_infs)} across numeric features', flush=True)\n",
        "if n_infs > 0:\n",
        "    for c in num_check_cols:\n",
        "        vals = df[c].to_numpy()\n",
        "        if np.isinf(vals).any():\n",
        "            df[c] = np.where(np.isinf(vals), 0.0, vals).astype(np.float32)\n",
        "if n_nans > 0:\n",
        "    for c in num_check_cols:\n",
        "        if df[c].isna().any():\n",
        "            df[c] = df[c].fillna(0.0).astype(np.float32)\n",
        "\n",
        "print('FE columns count:', len(df.columns), 'Sample:', [c for c in df.columns if c not in ['id']][:25], flush=True)\n",
        "\n",
        "# Split back\n",
        "train_fe = df[df['is_train']==1].copy()\n",
        "test_fe = df[df['is_train']==0].copy()\n",
        "train_fe = train_fe.sort_values('id').reset_index(drop=True)\n",
        "test_fe = test_fe.sort_values('id').reset_index(drop=True)\n",
        "\n",
        "# Save features to parquet\n",
        "train_fe_path = Path('train_fe_v3.parquet')\n",
        "test_fe_path = Path('test_fe_v3.parquet')\n",
        "train_fe.to_parquet(train_fe_path, index=False)\n",
        "test_fe.to_parquet(test_fe_path, index=False)\n",
        "print('Saved:', str(train_fe_path), str(test_fe_path), flush=True)\n",
        "\n",
        "# Build 5-fold GroupKFold with (R,C) strat if available\n",
        "from sklearn.model_selection import GroupKFold\n",
        "try:\n",
        "    from sklearn.model_selection import StratifiedGroupKFold\n",
        "    use_sgk = True\n",
        "except Exception:\n",
        "    use_sgk = False\n",
        "\n",
        "breath_df = (train_fe[['breath_id','R','C']].drop_duplicates().reset_index(drop=True))\n",
        "breath_df['rc_key'] = (breath_df['R']*100 + breath_df['C']).astype(np.int32)\n",
        "breath_df = breath_df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "\n",
        "n_splits = 5\n",
        "fold_col = np.full(len(breath_df), -1, dtype=np.int8)\n",
        "if use_sgk:\n",
        "    sgk = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    for k, (_, val_idx) in enumerate(sgk.split(breath_df, y=breath_df['rc_key'], groups=breath_df['breath_id'])):\n",
        "        fold_col[val_idx] = k\n",
        "    print('Using StratifiedGroupKFold', flush=True)\n",
        "else:\n",
        "    gk = GroupKFold(n_splits=n_splits)\n",
        "    for k, (_, val_idx) in enumerate(gk.split(breath_df, groups=breath_df['breath_id'])):\n",
        "        fold_col[val_idx] = k\n",
        "    print('Using GroupKFold (no strat fallback)', flush=True)\n",
        "\n",
        "breath_df['fold'] = fold_col\n",
        "assert (breath_df['fold']>=0).all()\n",
        "breath_df.to_csv('folds_breath_v3.csv', index=False)\n",
        "print('Saved folds_breath_v3.csv', flush=True)\n",
        "\n",
        "# Attach fold to train rows\n",
        "train_fe = train_fe.merge(breath_df[['breath_id','fold']], on='breath_id', how='left')\n",
        "train_fe.to_parquet(train_fe_path, index=False)  # overwrite with fold column included\n",
        "print('Train parquet updated with fold column.', flush=True)\n",
        "\n",
        "# Cleanup\n",
        "del df; gc.collect()\n",
        "print('Done FE v3+. Elapsed:', round(time.time()-t0,2), 's', flush=True)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FE v3: expanded physics + dynamics + integrals + breath stats (stabilized) + peak & vol_insp lags ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_107/1032188650.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  df = pd.concat([train, test], axis=0, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_107/1032188650.py:98: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df['ewm_rc'] = grp.apply(ewm_rc_group).reset_index(level=0, drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_107/1032188650.py:110: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  df['ewm_simple_uin'] = grp.apply(ewm_simple_group).reset_index(level=0, drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE diagnostics: total NaNs=1207200 | Infs=0 across numeric features\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE columns count: 63 Sample: ['breath_id', 'R', 'C', 'time_step', 'u_in', 'u_out', 'pressure', 'is_train', 't_idx', 'dt', 't_idx_norm', 'RC', 'rc_key', 'u_in_lag1', 'u_in_lag2', 'u_in_lag3', 'u_in_lag4', 'u_in_lag5', 'u_in_lead1', 'u_in_lead2', 'du1', 'du2', 'du3', 'roll_mean3_uin', 'roll_std3_uin']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: train_fe_v3.parquet test_fe_v3.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using StratifiedGroupKFold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved folds_breath_v3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train parquet updated with fold column.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done FE v3+. Elapsed: 99.94 s\n"
          ]
        }
      ]
    },
    {
      "id": "5a6a4ae7-2247-4d55-9be3-d7a5392a693b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd, time\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "print('=== Fold-safe physics baselines: fix unit mix; vectorized; fit on u_out==0 only ===', flush=True)\n",
        "\n",
        "tr_path, te_path = Path('train_fe_v3.parquet'), Path('test_fe_v3.parquet')\n",
        "train_fe = pd.read_parquet(tr_path).sort_values('id').reset_index(drop=True)\n",
        "test_fe  = pd.read_parquet(te_path).sort_values('id').reset_index(drop=True)\n",
        "\n",
        "y = train_fe['pressure'].to_numpy(np.float32)\n",
        "u = train_fe['u_in'].to_numpy(np.float32)\n",
        "R = train_fe['R'].to_numpy(np.float32)\n",
        "C = train_fe['C'].to_numpy(np.float32)\n",
        "w = (train_fe['u_out'].to_numpy()==0).astype(np.float32)\n",
        "voli = train_fe['vol_insp'].to_numpy(np.float32)  # already cumsum(u_in*dt*mask)\n",
        "\n",
        "u_te = test_fe['u_in'].to_numpy(np.float32)\n",
        "R_te = test_fe['R'].to_numpy(np.float32)\n",
        "C_te = test_fe['C'].to_numpy(np.float32)\n",
        "voli_te = test_fe['vol_insp'].to_numpy(np.float32)\n",
        "\n",
        "rc_tr = (train_fe['R'].astype(np.int32)*100 + train_fe['C'].astype(np.int32)).to_numpy()\n",
        "rc_te = (test_fe['R'].astype(np.int32)*100 + test_fe['C'].astype(np.int32)).to_numpy()\n",
        "rcs = np.unique(rc_tr)\n",
        "folds = train_fe['fold'].to_numpy(np.int32)\n",
        "n_folds = int(folds.max()) + 1\n",
        "\n",
        "def fit_on_insp(X, y, w):\n",
        "    m = w > 0\n",
        "    if m.sum() < 3:\n",
        "        return np.array([0.,0.,float(y[m].mean()) if m.any() else float(y.mean())], dtype=np.float64)\n",
        "    beta, *_ = np.linalg.lstsq(X[m].astype(np.float64), y[m].astype(np.float64), rcond=None)\n",
        "    return beta.astype(np.float64)\n",
        "\n",
        "def run_wls(x1_tr, x2_tr, x1_te, x2_te, label=''):\n",
        "    oof = np.zeros_like(y, dtype=np.float32)\n",
        "    test_fold = np.zeros((len(test_fe), n_folds), dtype=np.float32)\n",
        "    for k in range(n_folds):\n",
        "        tr_mask = (folds != k); va_mask = (folds == k)\n",
        "        betas = {}\n",
        "        for rc in rcs:\n",
        "            m = (rc_tr == rc) & tr_mask\n",
        "            if not np.any(m):\n",
        "                continue\n",
        "            X = np.stack([x1_tr[m], x2_tr[m], np.ones(m.sum(), np.float32)], 1)\n",
        "            beta = fit_on_insp(X, y[m], w[m])\n",
        "            betas[int(rc)] = beta\n",
        "        for rc, beta in betas.items():\n",
        "            a,b,c = [float(t) for t in beta]\n",
        "            mv = (rc_tr == rc) & va_mask\n",
        "            if np.any(mv):\n",
        "                oof[mv] = a*x1_tr[mv] + b*x2_tr[mv] + c\n",
        "            mt = (rc_te == rc)\n",
        "            if np.any(mt):\n",
        "                test_fold[mt, k] = a*x1_te[mt] + b*x2_te[mt] + c\n",
        "        mae_k = mean_absolute_error(y[va_mask & (w>0)], oof[va_mask & (w>0)])\n",
        "        print(f'Fold {k} masked MAE{\" \"+label if label else \"\"}: {mae_k:.4f}', flush=True)\n",
        "    mae = mean_absolute_error(y[w>0], oof[w>0])\n",
        "    return mae, oof, test_fold.mean(1).astype(np.float32)\n",
        "\n",
        "# Main physics-consistent variant\n",
        "flow_tr = u * 0.01\n",
        "flow_te = u_te * 0.01\n",
        "x1_tr = R * flow_tr\n",
        "x2_tr = voli / C                  # NOTE: no extra 0.01 here\n",
        "x1_te = R_te * flow_te\n",
        "x2_te = voli_te / C_te\n",
        "print('=== Physics WLS: X=[R*(u_in/100), vol_insp/C, 1] ===')\n",
        "mae_phys, oof_phys, test_phys = run_wls(x1_tr, x2_tr, x1_te, x2_te, label='(phys)')\n",
        "print(f'OOF masked MAE (physics): {mae_phys:.4f}', flush=True)\n",
        "\n",
        "# Alt Kaggle prior (vectorized cumsum, no loops)\n",
        "for df in (train_fe, test_fe):\n",
        "    df.sort_values(['breath_id','t_idx'], inplace=True)\n",
        "    df['flow'] = (df['u_in'].astype(np.float32) * 0.01).astype(np.float32)\n",
        "    df['vol_cumsum'] = df.groupby('breath_id')['flow'].cumsum().astype(np.float32)\n",
        "train_fe.sort_values('id', inplace=True); test_fe.sort_values('id', inplace=True)\n",
        "\n",
        "flow_tr2 = train_fe['flow'].to_numpy(np.float32)\n",
        "volc_tr  = train_fe['vol_cumsum'].to_numpy(np.float32)\n",
        "flow_te2 = test_fe['flow'].to_numpy(np.float32)\n",
        "volc_te  = test_fe['vol_cumsum'].to_numpy(np.float32)\n",
        "\n",
        "print('=== Alt WLS: X=[flow, vol_cumsum, 1] (no dt) ===')\n",
        "mae_alt, oof_alt, test_alt = run_wls(flow_tr2, volc_tr, flow_te2, volc_te, label='(alt)')\n",
        "print(f'OOF masked MAE (alt): {mae_alt:.4f}', flush=True)\n",
        "\n",
        "# Choose best and save\n",
        "use_alt = mae_alt < mae_phys\n",
        "p_train = oof_alt if use_alt else oof_phys\n",
        "p_test  = test_alt if use_alt else test_phys\n",
        "train_fe['p_phys'] = p_train.astype(np.float32)\n",
        "test_fe['p_phys']  = p_test.astype(np.float32)\n",
        "train_fe.to_parquet(tr_path, index=False)\n",
        "test_fe.to_parquet(te_path, index=False)\n",
        "print(f'Saved p_phys (alt_used={use_alt})')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Fold-safe physics baselines: fix unit mix; vectorized; fit on u_out==0 only ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Physics WLS: X=[R*(u_in/100), vol_insp/C, 1] ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 masked MAE (phys): 3.2763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 masked MAE (phys): 3.2769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 masked MAE (phys): 3.2406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 masked MAE (phys): 3.2641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 masked MAE (phys): 3.2831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF masked MAE (physics): 3.2682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Alt WLS: X=[flow, vol_cumsum, 1] (no dt) ===\nFold 0 masked MAE (alt): 3.4351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 masked MAE (alt): 3.4387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 masked MAE (alt): 3.3935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 masked MAE (alt): 3.4218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 masked MAE (alt): 3.4345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF masked MAE (alt): 3.4247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved p_phys (alt_used=False)\n"
          ]
        }
      ]
    },
    {
      "id": "85e418c3-215c-41d0-907d-ef6fbf36b20b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, time, math, gc, shutil, subprocess\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print('=== BiGRU Prep v4 rollback: minimal FEATS, exclude integrals from std, target z-score, cosine (no warmup), ReLU head ===', flush=True)\n",
        "\n",
        "# Install exact cu121 torch stack if not present\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision, torchaudio\n",
        "    ok = (getattr(torch.version, 'cuda', '') or '').startswith('12.1') and torch.cuda.is_available()\n",
        "    if not ok:\n",
        "        raise RuntimeError('Torch CUDA stack mismatch or CUDA not available')\n",
        "except Exception as e:\n",
        "    print('Installing PyTorch cu121 ...', e, flush=True)\n",
        "    for pkg in ('torch','torchvision','torchaudio'):\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "    for d in ('/app/.pip-target/torch', '/app/.pip-target/torchvision', '/app/.pip-target/torchaudio',\n",
        "              '/app/.pip-target/torch-2.4.1.dist-info','/app/.pip-target/torchvision-0.19.1.dist-info','/app/.pip-target/torchaudio-2.4.1.dist-info','/app/.pip-target/torchgen','/app/.pip-target/functorch'):\n",
        "        if os.path.exists(d):\n",
        "            shutil.rmtree(d, ignore_errors=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install',\n",
        "                    '--index-url','https://download.pytorch.org/whl/cu121',\n",
        "                    '--extra-index-url','https://pypi.org/simple',\n",
        "                    'torch==2.4.1','torchvision==0.19.1','torchaudio==2.4.1'], check=True)\n",
        "    import torch\n",
        "    import torchvision, torchaudio\n",
        "    print('torch:', torch.__version__, 'cuda build:', getattr(torch.version,'cuda',None), 'CUDA avail:', torch.cuda.is_available(), flush=True)\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# ---------------- Data load ----------------\n",
        "FE_PATH_TRAIN = Path('train_fe_v3.parquet')\n",
        "FE_PATH_TEST = Path('test_fe_v3.parquet')\n",
        "assert FE_PATH_TRAIN.exists() and FE_PATH_TEST.exists(), 'Run FE v3 cell first'\n",
        "train_fe = pd.read_parquet(FE_PATH_TRAIN)\n",
        "test_fe = pd.read_parquet(FE_PATH_TEST)\n",
        "\n",
        "# Add p_phys for NN too (R_term + V_term)\n",
        "train_fe['p_phys'] = (train_fe['R_term'].astype(np.float32) + train_fe['V_term'].astype(np.float32)).astype(np.float32)\n",
        "test_fe['p_phys']  = (test_fe['R_term'].astype(np.float32) + test_fe['V_term'].astype(np.float32)).astype(np.float32)\n",
        "\n",
        "train_fe = train_fe.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "test_fe = test_fe.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "\n",
        "# Minimal stable FEATS (no u_out, no leads)\n",
        "FEATS = [\n",
        "    'u_in','dt','t_idx_norm','R','C','RC',\n",
        "    'u_in_lag1','u_in_lag2','u_in_lag3',\n",
        "    'du1',\n",
        "    'vol_dt','vol_insp','u_in_cumsum',\n",
        "    'R_term','V_term','p_phys',\n",
        "    'breath_progress','insp_frac'\n",
        "]\n",
        "missing = [c for c in FEATS if c not in train_fe.columns]\n",
        "if missing:\n",
        "    raise ValueError(f'Missing features: {missing}')\n",
        "\n",
        "SEQ_LEN = int(train_fe.groupby('breath_id').size().mode().iloc[0])\n",
        "print('SEQ_LEN:', SEQ_LEN, flush=True)\n",
        "\n",
        "def make_sequences(df: pd.DataFrame, feats):\n",
        "    g = df.groupby('breath_id', sort=False)\n",
        "    breath_ids = g.size().index.to_numpy()\n",
        "    B = breath_ids.shape[0]\n",
        "    F = len(feats)\n",
        "    X = np.zeros((B, SEQ_LEN, F), dtype=np.float32)\n",
        "    mask = np.zeros((B, SEQ_LEN), dtype=np.float32)\n",
        "    rc_key = np.zeros(B, dtype=np.int32)\n",
        "    y = None\n",
        "    has_y = 'pressure' in df.columns and not df['pressure'].isna().all()\n",
        "    if has_y:\n",
        "        y = np.zeros((B, SEQ_LEN), dtype=np.float32)\n",
        "    for i, (bid, sub) in enumerate(g):\n",
        "        sub = sub.sort_values('t_idx')\n",
        "        tlen = len(sub)\n",
        "        if tlen != SEQ_LEN:\n",
        "            sub = sub.iloc[:SEQ_LEN]\n",
        "            tlen = len(sub)\n",
        "        X[i, :tlen, :] = sub[feats].to_numpy(dtype=np.float32, copy=False)\n",
        "        mask[i, :tlen] = (sub['u_out'].to_numpy() == 0).astype(np.float32)\n",
        "        rc_key[i] = (int(sub['R'].iloc[0])*100 + int(sub['C'].iloc[0]))\n",
        "        if has_y:\n",
        "            y[i, :tlen] = sub['pressure'].to_numpy(dtype=np.float32, copy=False)\n",
        "    return X, y, mask, rc_key, breath_ids\n",
        "\n",
        "X_all, y_all, mask_all, rc_all, bids_all = make_sequences(train_fe, FEATS)\n",
        "X_test_all, _, mask_test_dummy, rc_test_all, bids_test_all = make_sequences(test_fe, FEATS)\n",
        "print('Train seq:', X_all.shape, 'Test seq:', X_test_all.shape, flush=True)\n",
        "print(f'Target stats: min={y_all.min():.2f}, max={y_all.max():.2f}, mean={y_all.mean():.2f}')\n",
        "print('FEATS used:', len(FEATS))\n",
        "\n",
        "# Quick sanity checks\n",
        "m0 = mask_all[0].mean()\n",
        "print('Sanity: first breath shapes:', X_all[0].shape, y_all[0].shape, mask_all[0].shape, '| mask_mean:', round(float(m0),3), flush=True)\n",
        "assert X_all.shape[1] == SEQ_LEN and X_test_all.shape[1] == SEQ_LEN\n",
        "assert np.isfinite(X_all).all() and np.isfinite(y_all).all() and np.isfinite(mask_all).all(), 'NaN/Inf in sequences'\n",
        "\n",
        "class BreathDataset(Dataset):\n",
        "    def __init__(self, X, y, mask, idx=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.m = mask\n",
        "        self.idx = np.arange(X.shape[0], dtype=np.int64) if idx is None else np.asarray(idx, dtype=np.int64)\n",
        "    def __len__(self): return self.X.shape[0]\n",
        "    def __getitem__(self, i):\n",
        "        x = torch.from_numpy(self.X[i])\n",
        "        m_arr = self.m[i]\n",
        "        if not isinstance(m_arr, np.ndarray):\n",
        "            m_arr = np.asarray(m_arr, dtype=np.float32)\n",
        "        if m_arr.ndim == 0:\n",
        "            m_arr = np.full((x.shape[0],), float(m_arr), dtype=np.float32)\n",
        "        elif m_arr.dtype != np.float32:\n",
        "            m_arr = m_arr.astype(np.float32)\n",
        "        m = torch.from_numpy(m_arr)\n",
        "        idx_val = int(self.idx[i])\n",
        "        if self.y is None:\n",
        "            return x, m, idx_val\n",
        "        return x, torch.from_numpy(self.y[i]), m, idx_val\n",
        "\n",
        "class BiGRUReg(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=256, layers=3, dropout=0.2, layer_norm=True):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(in_dim, hidden, num_layers=layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
        "        self.ln = nn.LayerNorm(hidden*2) if layer_norm else nn.Identity()\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(hidden*2, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        y, _ = self.gru(x)\n",
        "        y = self.ln(y)\n",
        "        out = self.head(y)\n",
        "        return out.squeeze(-1)\n",
        "\n",
        "def masked_smooth_l1(pred, target, mask, beta=0.5):\n",
        "    diff = (pred - target).abs()\n",
        "    loss = torch.where(diff < beta, 0.5 * (diff ** 2) / beta, diff - 0.5 * beta)\n",
        "    loss = loss * mask\n",
        "    denom = mask.sum().clamp_min(1.0)\n",
        "    return loss.sum() / denom\n",
        "\n",
        "def train_bigru_cv(seed=42, n_folds=5, batch_size=1536, epochs=25, lr=2e-4, hidden=256, layers=3, dropout=0.2):\n",
        "    torch.manual_seed(seed); np.random.seed(seed)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print('Device:', device, flush=True)\n",
        "    folds_df = pd.read_csv('folds_breath_v3.csv')\n",
        "    fold_map = dict(zip(folds_df['breath_id'].astype(int).values, folds_df['fold'].astype(int).values))\n",
        "    folds = np.array([fold_map[int(b)] for b in bids_all], dtype=np.int16)\n",
        "\n",
        "    # Build per-(R,C) grid for snapping\n",
        "    grid_all = np.unique(train_fe['pressure'].values.astype(np.float32)); grid_all.sort()\n",
        "    rc_train = (train_fe['R']*100 + train_fe['C']).astype(np.int32)\n",
        "    rc_press = {}\n",
        "    for rc, grp in train_fe.groupby(rc_train):\n",
        "        g = np.unique(grp['pressure'].values.astype(np.float32)); g.sort(); rc_press[int(rc)] = g\n",
        "    for rc in np.unique(rc_test_all):\n",
        "        if int(rc) not in rc_press:\n",
        "            rc_press[int(rc)] = grid_all\n",
        "\n",
        "    def snap_to_grid(arr, grid):\n",
        "        idx = np.searchsorted(grid, arr)\n",
        "        idx0 = np.clip(idx-1, 0, grid.size-1); idx1 = np.clip(idx, 0, grid.size-1)\n",
        "        left = grid[idx0]; right = grid[idx1]\n",
        "        return np.where(np.abs(arr-left) <= np.abs(arr-right), left, right).astype(np.float32)\n",
        "\n",
        "    from scipy.signal import medfilt\n",
        "\n",
        "    # Exclude discrete/progress/integrals/physics from standardization\n",
        "    EXCLUDE_STD = set(['R','C','RC','t_idx_norm','breath_progress','insp_frac','vol_dt','vol_insp','u_in_cumsum','V_term','p_phys'])\n",
        "    cont_idx = [i for i, f in enumerate(FEATS) if f not in EXCLUDE_STD]\n",
        "\n",
        "    oof = np.zeros_like(y_all, dtype=np.float32)\n",
        "    test_preds_folds = []\n",
        "\n",
        "    for k in range(n_folds):\n",
        "        t_fold = time.time()\n",
        "        trn_idx = np.where(folds != k)[0]\n",
        "        val_idx = np.where(folds == k)[0]\n",
        "        print(f'Fold {k+1}/{n_folds}: train breaths {trn_idx.size} | val breaths {val_idx.size}', flush=True)\n",
        "\n",
        "        # Fold-safe global standardization on continuous features\n",
        "        X_tr = X_all[trn_idx].copy(); X_va = X_all[val_idx].copy(); X_te = X_test_all.copy()\n",
        "        flat_tr = X_tr[:, :, cont_idx].reshape(-1, len(cont_idx))\n",
        "        mu = flat_tr.mean(axis=0, keepdims=True)\n",
        "        sd = flat_tr.std(axis=0, keepdims=True) + 1e-6\n",
        "        print('Std stats (min/max):', float(sd.min()), float(sd.max()), flush=True)\n",
        "        X_tr[:, :, cont_idx] = (X_tr[:, :, cont_idx] - mu) / sd\n",
        "        X_va[:, :, cont_idx] = (X_va[:, :, cont_idx] - mu) / sd\n",
        "        X_te[:, :, cont_idx] = (X_te[:, :, cont_idx] - mu) / sd\n",
        "        assert np.isfinite(X_tr).all() and np.isfinite(X_va).all() and np.isfinite(X_te).all()\n",
        "\n",
        "        y_tr = y_all[trn_idx]\n",
        "        y_va = y_all[val_idx]\n",
        "        m_tr = mask_all[trn_idx]\n",
        "        m_va = mask_all[val_idx]\n",
        "\n",
        "        # Target z-score on masked (u_out==0) timesteps in training fold\n",
        "        ytr_flat = y_tr.reshape(-1)\n",
        "        mtr_flat = (m_tr.reshape(-1) > 0)\n",
        "        tgt_mu = float(ytr_flat[mtr_flat].mean())\n",
        "        tgt_sd = float(ytr_flat[mtr_flat].std() + 1e-6)\n",
        "        y_tr_n = (y_tr - tgt_mu) / tgt_sd\n",
        "        print(f'target sd (masked): {tgt_sd:.3f}', flush=True)\n",
        "\n",
        "        print('Sanity fold', k, ': X_tr', X_tr.shape, 'y_tr', y_tr.shape, 'mask mean tr', round(float(m_tr.mean()),3), flush=True)\n",
        "        assert np.isfinite(y_tr).all() and np.isfinite(m_tr).all()\n",
        "\n",
        "        ds_tr = BreathDataset(X_tr, y_tr_n, m_tr, idx=trn_idx)   # normalized target\n",
        "        ds_va = BreathDataset(X_va, y_va,   m_va, idx=val_idx)    # raw target for val loss\n",
        "        dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "        dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "        model = BiGRUReg(in_dim=len(FEATS), hidden=hidden, layers=layers, dropout=dropout).to(device)\n",
        "        opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "        sched = CosineAnnealingLR(opt, T_max=epochs, eta_min=2e-5)\n",
        "        scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
        "        best = 1e9; best_state = None; patience = 6; bad=0\n",
        "\n",
        "        for ep in range(1, epochs+1):\n",
        "            model.train(); tr_loss=0.0; nsteps=0\n",
        "            for xb, yb, mb, _idx in dl_tr:\n",
        "                xb = xb.to(device); yb = yb.to(device); mb = mb.to(device)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                with torch.amp.autocast('cuda', enabled=(device=='cuda')):\n",
        "                    pred_n = model(xb)\n",
        "                    loss = masked_smooth_l1(pred_n, yb, mb, beta=0.5)\n",
        "                scaler.scale(loss).backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "                scaler.step(opt); scaler.update()\n",
        "                tr_loss += loss.item(); nsteps += 1\n",
        "            model.eval(); va_loss=0.0; vsteps=0\n",
        "            with torch.no_grad():\n",
        "                for xb, yb, mb, _idx in dl_va:\n",
        "                    xb = xb.to(device); yb = yb.to(device); mb = mb.to(device)\n",
        "                    with torch.amp.autocast('cuda', enabled=(device=='cuda')):\n",
        "                        pred_n = model(xb)\n",
        "                        pred = pred_n * tgt_sd + tgt_mu\n",
        "                        loss = masked_smooth_l1(pred, yb, mb, beta=0.5)\n",
        "                    va_loss += loss.item(); vsteps += 1\n",
        "            va = va_loss/max(vsteps,1); tr = tr_loss/max(nsteps,1)\n",
        "            print(f'Epoch {ep}: tr {tr:.5f} va {va:.5f}', flush=True)\n",
        "            sched.step()\n",
        "            if va < best - 1e-5:\n",
        "                best = va; best_state = {k_:v_.detach().cpu().clone() for k_,v_ in model.state_dict().items()}; bad=0\n",
        "            else:\n",
        "                bad += 1\n",
        "                if bad >= patience:\n",
        "                    print('Early stop at epoch', ep, flush=True); break\n",
        "\n",
        "        for k_, v_ in best_state.items():\n",
        "            model.state_dict()[k_].copy_(v_.to(device))\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for xb, yb, mb, idx_batch in dl_va:\n",
        "                xb = xb.to(device)\n",
        "                with torch.amp.autocast('cuda', enabled=(device=='cuda')):\n",
        "                    pred_n = model(xb).float().cpu().numpy()\n",
        "                pred = pred_n * tgt_sd + tgt_mu\n",
        "                oof[idx_batch,:] = pred\n",
        "\n",
        "        ds_te = BreathDataset(X_te, None, mask_test_dummy, idx=np.arange(X_te.shape[0]))\n",
        "        dl_te = DataLoader(ds_te, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "        te_preds = []\n",
        "        with torch.no_grad():\n",
        "            for xb, mb, _idx in dl_te:\n",
        "                xb = xb.to(device)\n",
        "                with torch.amp.autocast('cuda', enabled=(device=='cuda')):\n",
        "                    pred_n = model(xb).float().cpu().numpy()\n",
        "                pred = pred_n * tgt_sd + tgt_mu\n",
        "                te_preds.append(pred)\n",
        "        te_pred = np.concatenate(te_preds, axis=0)\n",
        "        test_preds_folds.append(te_pred.astype(np.float32))\n",
        "\n",
        "        m_flat = mask_all[val_idx].reshape(-1)\n",
        "        pred_flat = oof[val_idx].reshape(-1)\n",
        "        y_flat = y_all[val_idx].reshape(-1)\n",
        "        mae_raw = np.mean(np.abs(pred_flat[m_flat > 0] - y_flat[m_flat > 0]))\n",
        "        print(f'Fold {k} raw masked MAE: {mae_raw:.6f} | elapsed {time.time()-t_fold:.1f}s', flush=True)\n",
        "\n",
        "    test_pred_mean = np.mean(np.stack(test_preds_folds, axis=0), axis=0)\n",
        "\n",
        "    from scipy.signal import medfilt\n",
        "    oof_snap = np.zeros_like(oof)\n",
        "    for k in range(n_folds):\n",
        "        trn_idx = np.where(folds != k)[0]\n",
        "        fold_grid = np.unique(y_all[trn_idx].reshape(-1)); fold_grid.sort()\n",
        "        val_idx = np.where(folds == k)[0]\n",
        "        for i, bi in enumerate(val_idx):\n",
        "            pred_b = oof[bi]\n",
        "            snapped = snap_to_grid(pred_b, fold_grid)\n",
        "            snapped = np.where(mask_all[bi]>0, medfilt(snapped, 3), snapped)\n",
        "            oof_snap[bi] = snapped\n",
        "    m_all = mask_all.reshape(-1) > 0\n",
        "    mae_oof_raw = np.mean(np.abs(oof.reshape(-1)[m_all] - y_all.reshape(-1)[m_all]))\n",
        "    mae_oof_snap = np.mean(np.abs(oof_snap.reshape(-1)[m_all] - y_all.reshape(-1)[m_all]))\n",
        "    print(f'OOF MAE raw: {mae_oof_raw:.6f} | snapped+median3: {mae_oof_snap:.6f}', flush=True)\n",
        "    np.save('oof_bigru_raw.npy', oof.astype(np.float32))\n",
        "\n",
        "    test_rows = test_fe.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "    pred_rows = np.zeros(test_rows.shape[0], dtype=np.float32)\n",
        "    start = 0\n",
        "    for i, bid in enumerate(bids_test_all):\n",
        "        T = SEQ_LEN\n",
        "        pred_b = test_pred_mean[i]\n",
        "        rc = int(test_rows.loc[start, 'R'])*100 + int(test_rows.loc[start, 'C'])\n",
        "        grid = rc_press.get(rc, grid_all)\n",
        "        pred_b = snap_to_grid(pred_b, grid)\n",
        "        m = (test_rows.iloc[start:start+T]['u_out'].to_numpy()==0).astype(np.float32)\n",
        "        sm = medfilt(pred_b, kernel_size=3)\n",
        "        pred_b = np.where(m>0, sm, pred_b).astype(np.float32)\n",
        "        pred_rows[start:start+T] = pred_b\n",
        "        start += T\n",
        "\n",
        "    sub = pd.DataFrame({'id': test_rows['id'].to_numpy(), 'pressure': pred_rows})\n",
        "    sub = sub.sort_values('id').reset_index(drop=True)\n",
        "    sub.to_csv('submission_nn.csv', index=False)\n",
        "    np.save('oof_bigru.npy', oof_snap.astype(np.float32))\n",
        "    print('Saved submission_nn.csv and oof_bigru.npy', flush=True)\n",
        "\n",
        "    return mae_oof_snap\n",
        "\n",
        "print('BiGRU prep v4 rollback ready. Run train_bigru_cv(epochs=25, lr=2e-4).', flush=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== BiGRU Prep v4 rollback: minimal FEATS, exclude integrals from std, target z-score, cosine (no warmup), ReLU head ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEQ_LEN: 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train seq: (67905, 80, 18) Test seq: (7545, 80, 18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target stats: min=-1.90, max=64.82, mean=11.22\nFEATS used: 18\nSanity: first breath shapes: (80, 18) (80,) (80,) | mask_mean: 0.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BiGRU prep v4 rollback ready. Run train_bigru_cv(epochs=25, lr=2e-4).\n"
          ]
        }
      ]
    },
    {
      "id": "b6e59aa6-c022-4c2e-829a-3de4779dbb8d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, subprocess, time\n",
        "print('=== Launch BiGRU CV v4 (fold-safe std, SmoothL1, Cosine, target z-score) ===', flush=True)\n",
        "try:\n",
        "    import scipy\n",
        "except Exception:\n",
        "    print('Installing scipy for median filter...', flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scipy'], check=True)\n",
        "\n",
        "t0 = time.time()\n",
        "mae = train_bigru_cv(\n",
        "    seed=42,\n",
        "    n_folds=5,\n",
        "    batch_size=1536,\n",
        "    epochs=25,\n",
        "    lr=2e-4,\n",
        "    hidden=256,\n",
        "    layers=3,\n",
        "    dropout=0.2\n",
        ")\n",
        "print(f'BiGRU OOF MAE (snapped+median3): {mae:.6f} | Elapsed: {time.time()-t0:.1f}s', flush=True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Launch BiGRU CV v4 (fold-safe std, SmoothL1, Cosine, target z-score) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5: train breaths 54324 | val breaths 13581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Std stats (min/max): 0.0038702357560396194 329.40277099609375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target sd (masked): 9.244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity fold 0 : X_tr (54324, 80, 18) y_tr (54324, 80) mask mean tr 0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_107/3519590824.py:223: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: tr 0.25111 va 2.35440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: tr 0.11760 va 1.71015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: tr 0.08876 va 1.54783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: tr 0.07374 va 1.28922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: tr 0.07054 va 1.35449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: tr 0.06240 va 1.31222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: tr 0.06121 va 1.23026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: tr 0.05601 va 1.15984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: tr 0.05338 va 1.16836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: tr 0.05038 va 1.07716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: tr 0.04849 va 1.16266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: tr 0.04708 va 1.03108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: tr 0.04575 va 1.03394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: tr 0.04491 va 1.02620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: tr 0.04311 va 0.98272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: tr 0.04229 va 0.99538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: tr 0.04132 va 0.95885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: tr 0.04070 va 0.95036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: tr 0.03979 va 0.95623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: tr 0.03933 va 0.93660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: tr 0.03888 va 0.92711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: tr 0.03838 va 0.93270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: tr 0.03784 va 0.91739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: tr 0.03770 va 0.92008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: tr 0.03735 va 0.91086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 raw masked MAE: 1.131406 | elapsed 97.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2/5: train breaths 54324 | val breaths 13581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Std stats (min/max): 0.0038637558463960886 330.52703857421875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target sd (masked): 9.251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity fold 1 : X_tr (54324, 80, 18) y_tr (54324, 80) mask mean tr 0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: tr 0.23392 va 2.29220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: tr 0.11163 va 1.63146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: tr 0.08389 va 1.49932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: tr 0.07699 va 1.96965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: tr 0.07729 va 1.51499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: tr 0.06247 va 1.34346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: tr 0.06141 va 1.38116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: tr 0.06145 va 1.38495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: tr 0.05292 va 1.16495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: tr 0.04959 va 1.04130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: tr 0.04664 va 1.02150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: tr 0.04657 va 1.00516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: tr 0.04591 va 1.11673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: tr 0.04260 va 1.05561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: tr 0.04146 va 0.95469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: tr 0.03949 va 0.92210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: tr 0.03863 va 0.91607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: tr 0.03766 va 0.89999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: tr 0.03678 va 0.90474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: tr 0.03630 va 0.87902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: tr 0.03581 va 0.91834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: tr 0.03517 va 0.89966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: tr 0.03469 va 0.87335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: tr 0.03440 va 0.86371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: tr 0.03428 va 0.86271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 raw masked MAE: 1.082569 | elapsed 97.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3/5: train breaths 54324 | val breaths 13581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Std stats (min/max): 0.003875849535688758 329.597900390625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target sd (masked): 9.251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity fold 2 : X_tr (54324, 80, 18) y_tr (54324, 80) mask mean tr 0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: tr 0.23222 va 2.23736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: tr 0.12628 va 1.80180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: tr 0.09223 va 1.55313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: tr 0.07826 va 1.32470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: tr 0.08966 va 2.02992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: tr 0.07517 va 1.23903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: tr 0.06085 va 1.40576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: tr 0.06209 va 1.24813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: tr 0.05214 va 1.10024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: tr 0.04739 va 1.05085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: tr 0.04576 va 1.13903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: tr 0.04455 va 1.02279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: tr 0.04223 va 0.97764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: tr 0.04100 va 0.99451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: tr 0.03941 va 0.93780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: tr 0.03782 va 0.94641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: tr 0.03916 va 0.90830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: tr 0.03643 va 0.88828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: tr 0.03579 va 0.90165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: tr 0.03540 va 0.90010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: tr 0.03494 va 0.86384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: tr 0.03455 va 0.85456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: tr 0.03396 va 0.86095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: tr 0.03371 va 0.85697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: tr 0.03340 va 0.86044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 raw masked MAE: 1.072442 | elapsed 98.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4/5: train breaths 54324 | val breaths 13581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Std stats (min/max): 0.0038729801308363676 329.4145812988281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target sd (masked): 9.236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity fold 3 : X_tr (54324, 80, 18) y_tr (54324, 80) mask mean tr 0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: tr 0.25335 va 2.27817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: tr 0.11098 va 1.69992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: tr 0.08498 va 1.48975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: tr 0.07779 va 1.42073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: tr 0.07646 va 1.41307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: tr 0.06456 va 1.25663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: tr 0.06521 va 1.25529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: tr 0.05634 va 1.15209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: tr 0.05427 va 1.31013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: tr 0.05163 va 1.37395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: tr 0.04837 va 1.04527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: tr 0.04639 va 1.05161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: tr 0.04540 va 1.17564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: tr 0.04389 va 1.00157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: tr 0.04303 va 0.99547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: tr 0.04154 va 1.01512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: tr 0.04079 va 0.97526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: tr 0.04025 va 1.03295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: tr 0.03945 va 0.93208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: tr 0.03850 va 0.93272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: tr 0.03794 va 0.94885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: tr 0.03745 va 0.94881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: tr 0.03716 va 0.91811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: tr 0.03678 va 0.89953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: tr 0.03639 va 0.91050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 raw masked MAE: 1.120140 | elapsed 99.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5/5: train breaths 54324 | val breaths 13581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Std stats (min/max): 0.0038754011038690805 330.1415100097656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target sd (masked): 9.241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity fold 4 : X_tr (54324, 80, 18) y_tr (54324, 80) mask mean tr 0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: tr 0.25844 va 2.49062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: tr 0.12085 va 2.02166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: tr 0.09547 va 1.72610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: tr 0.07751 va 1.46919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: tr 0.07380 va 1.25820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: tr 0.06175 va 1.26759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: tr 0.05857 va 1.23203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: tr 0.05364 va 1.21241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: tr 0.05226 va 1.04517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: tr 0.04859 va 1.09289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: tr 0.04915 va 1.21394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: tr 0.04736 va 1.01510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: tr 0.04298 va 0.98517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: tr 0.04235 va 0.98192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: tr 0.03949 va 0.92632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: tr 0.03950 va 1.01942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: tr 0.03805 va 0.94003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: tr 0.03715 va 0.92626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: tr 0.03694 va 0.92181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: tr 0.03652 va 0.87615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: tr 0.03574 va 0.88280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: tr 0.03496 va 0.87973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: tr 0.03476 va 0.88710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: tr 0.03456 va 0.86591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: tr 0.03410 va 0.87326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 raw masked MAE: 1.085498 | elapsed 99.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF MAE raw: 1.098407 | snapped+median3: 1.182177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_nn.csv and oof_bigru.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BiGRU OOF MAE (snapped+median3): 1.182177 | Elapsed: 499.0s\n"
          ]
        }
      ]
    },
    {
      "id": "dc7be985-d8f0-4a1e-979c-d5ef8d5b9772",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, sys, subprocess, numpy as np, pandas as pd, os\n",
        "from pathlib import Path\n",
        "print('=== Blend XGB + BiGRU (OOF-tuned), then per-(R,C) snap + median(3) ===', flush=True)\n",
        "\n",
        "# Ensure scipy for median filter\n",
        "try:\n",
        "    from scipy.signal import medfilt\n",
        "except Exception:\n",
        "    print('Installing scipy...', flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scipy'], check=True)\n",
        "    from scipy.signal import medfilt\n",
        "\n",
        "sub_xgb_path = Path('submission.csv')            # from XGB\n",
        "sub_nn_path = Path('submission_nn.csv')          # from BiGRU\n",
        "oof_xgb_path = Path('oof_xgb.npy')\n",
        "# Prefer raw NN OOF if available\n",
        "oof_nn_raw = Path('oof_bigru_raw.npy')\n",
        "oof_nn_snap = Path('oof_bigru.npy')\n",
        "oof_nn_path = oof_nn_raw if oof_nn_raw.exists() else oof_nn_snap\n",
        "\n",
        "# Tune weight on OOF if both present\n",
        "best_w = 0.7\n",
        "if oof_xgb_path.exists() and oof_nn_path.exists():\n",
        "    print(f'Tuning blend weight on OOF using {oof_nn_path.name} ...', flush=True)\n",
        "    oof_x_id = np.load(oof_xgb_path).astype(np.float32)  # id-order\n",
        "    oof_n = np.load(oof_nn_path).astype(np.float32)      # breath-major [B,80]\n",
        "    # Load train in both orders to align OOFs\n",
        "    tr_breath = pd.read_parquet('train_fe_v3.parquet').sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "    tr_id = pd.read_parquet('train_fe_v3.parquet').sort_values('id').reset_index(drop=True)\n",
        "    assert len(tr_breath) == len(tr_id) == oof_x_id.shape[0], 'OOF length mismatch'\n",
        "    # Reorder XGB OOF from id-order to breath-order\n",
        "    id_to_pos = dict(zip(tr_id['id'].to_numpy(), np.arange(len(tr_id), dtype=np.int64)))\n",
        "    idx_breath_order = np.array([id_to_pos[i] for i in tr_breath['id'].to_numpy()], dtype=np.int64)\n",
        "    oof_x = oof_x_id[idx_breath_order]\n",
        "    mask = (tr_breath['u_out'].to_numpy()==0)\n",
        "    y_true = tr_breath['pressure'].to_numpy(dtype=np.float32, copy=False)\n",
        "    # Flatten breath-major NN OOF to row order (breath-order)\n",
        "    oof_n_flat = np.zeros_like(y_true, dtype=np.float32)\n",
        "    start = 0\n",
        "    for i, (bid, g) in enumerate(tr_breath.groupby('breath_id', sort=False)):\n",
        "        L = len(g)\n",
        "        oof_n_flat[start:start+L] = oof_n[i, :L]\n",
        "        start += L\n",
        "    ws = np.linspace(0.0, 1.0, 21)\n",
        "    best_mae = 1e9\n",
        "    for w in ws:\n",
        "        pred = w*oof_n_flat + (1.0-w)*oof_x\n",
        "        mae = np.mean(np.abs(pred[mask]-y_true[mask]))\n",
        "        if mae < best_mae:\n",
        "            best_mae, best_w = mae, float(w)\n",
        "    print(f'Best OOF weight: w_nn={best_w:.2f} -> MAE={best_mae:.6f}', flush=True)\n",
        "else:\n",
        "    print('OOF not available for both models; using default w_nn=0.7', flush=True)\n",
        "\n",
        "assert sub_xgb_path.exists(), 'submission.csv (XGB) not found'\n",
        "while not sub_nn_path.exists():\n",
        "    print('Waiting for submission_nn.csv ...', flush=True); time.sleep(10)\n",
        "\n",
        "sub_xgb = pd.read_csv(sub_xgb_path)\n",
        "sub_nn = pd.read_csv(sub_nn_path)\n",
        "assert sub_xgb.shape == sub_nn.shape, 'Submissions shape mismatch'\n",
        "sub = sub_xgb.merge(sub_nn, on='id', suffixes=('_xgb','_nn'))\n",
        "\n",
        "# Blend with tuned weight\n",
        "w_nn = best_w; w_xgb = 1.0 - best_w\n",
        "sub['pressure_blend'] = (w_xgb*sub['pressure_xgb'] + w_nn*sub['pressure_nn']).astype(np.float32)\n",
        "\n",
        "# Load FE/test info for per-breath smoothing and (R,C) snapping (v3 files)\n",
        "test_fe = pd.read_parquet('test_fe_v3.parquet').sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "train_fe = pd.read_parquet('train_fe_v3.parquet')\n",
        "\n",
        "# Build per-(R,C) pressure grids from full train\n",
        "grid_all = np.unique(train_fe['pressure'].values.astype(np.float32)); grid_all.sort()\n",
        "rc_train = (train_fe['R']*100 + train_fe['C']).astype(np.int32)\n",
        "rc_press = {}\n",
        "for rc, grp in train_fe.groupby(rc_train):\n",
        "    g = np.unique(grp['pressure'].values.astype(np.float32)); g.sort(); rc_press[int(rc)] = g\n",
        "\n",
        "def snap_to_grid(arr, grid):\n",
        "    idx = np.searchsorted(grid, arr)\n",
        "    idx0 = np.clip(idx-1, 0, grid.size-1); idx1 = np.clip(idx, 0, grid.size-1)\n",
        "    left = grid[idx0]; right = grid[idx1]\n",
        "    return np.where(np.abs(arr-left) <= np.abs(arr-right), left, right).astype(np.float32)\n",
        "\n",
        "# Attach blend to test rows, then per-breath median(3) on u_out==0 and per-(R,C) snap\n",
        "df = test_fe[['id','breath_id','t_idx','u_out','R','C']].copy()\n",
        "df = df.merge(sub[['id','pressure_blend']], on='id', how='left')\n",
        "assert df['pressure_blend'].notna().all(), 'Missing blended pressures after merge'\n",
        "\n",
        "out_vals = np.zeros(len(df), dtype=np.float32)\n",
        "start = 0\n",
        "for bid, g in df.groupby('breath_id', sort=False):\n",
        "    g = g.sort_values('t_idx')\n",
        "    vals = g['pressure_blend'].to_numpy(dtype=np.float32, copy=False)\n",
        "    mask_b = (g['u_out'].to_numpy()==0).astype(np.float32)\n",
        "    rc = int(g['R'].iloc[0])*100 + int(g['C'].iloc[0])\n",
        "    grid = rc_press.get(rc, grid_all)\n",
        "    vals = snap_to_grid(vals, grid)\n",
        "    sm = medfilt(vals, kernel_size=3)\n",
        "    vals = np.where(mask_b>0, sm, vals).astype(np.float32)\n",
        "    out_vals[start:start+len(g)] = vals\n",
        "    start += len(g)\n",
        "\n",
        "blend_sub = pd.DataFrame({'id': df['id'].to_numpy(), 'pressure': out_vals})\n",
        "blend_sub = blend_sub.sort_values('id').reset_index(drop=True)\n",
        "blend_sub.to_csv('submission_blend.csv', index=False)\n",
        "blend_sub.to_csv('submission.csv', index=False)\n",
        "print(f'Saved submission_blend.csv and updated submission.csv (w_nn={w_nn:.2f}, w_xgb={1.0-w_nn:.2f})', flush=True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Blend XGB + BiGRU (OOF-tuned), then per-(R,C) snap + median(3) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning blend weight on OOF using oof_bigru_raw.npy ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best OOF weight: w_nn=0.00 -> MAE=0.301180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_blend.csv and updated submission.csv (w_nn=0.00, w_xgb=1.00)\n"
          ]
        }
      ]
    },
    {
      "id": "9f689707-faf5-44ce-8497-457cf6424ac5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "print('=== DEBUG: Verify u_in integrity between raw train.csv and FE v3 ===', flush=True)\n",
        "raw = pd.read_csv('train.csv', usecols=['id','u_in'])\n",
        "fe = pd.read_parquet('train_fe_v3.parquet', columns=['id','u_in'])\n",
        "print('Shapes:', raw.shape, fe.shape, flush=True)\n",
        "raw = raw.sort_values('id').reset_index(drop=True)\n",
        "fe = fe.sort_values('id').reset_index(drop=True)\n",
        "assert (raw['id'].values == fe['id'].values).all(), 'ID misalignment between raw and FE'\n",
        "diff = (raw['u_in'].astype(np.float32).values - fe['u_in'].astype(np.float32).values)\n",
        "abs_diff = np.abs(diff)\n",
        "print('Raw u_in stats: min/max', float(raw['u_in'].min()), float(raw['u_in'].max()))\n",
        "print('FE  u_in stats: min/max', float(fe['u_in'].min()), float(fe['u_in'].max()))\n",
        "print('Diff stats: max', float(abs_diff.max()), 'mean', float(abs_diff.mean()), '95th', float(np.quantile(abs_diff, 0.95)))\n",
        "idx_bad = np.where(abs_diff > 1e-5)[0]\n",
        "print('Mismatched rows:', idx_bad.size)\n",
        "if idx_bad.size > 0:\n",
        "    sample = idx_bad[:10]\n",
        "    print('Sample mismatches:\\n', pd.DataFrame({\n",
        "        'id': raw['id'].iloc[sample].values,\n",
        "        'u_in_raw': raw['u_in'].iloc[sample].values,\n",
        "        'u_in_fe': fe['u_in'].iloc[sample].values,\n",
        "        'abs_diff': abs_diff[sample]\n",
        "    }))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DEBUG: Verify u_in integrity between raw train.csv and FE v3 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (5432400, 2) (5432400, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw u_in stats: min/max 0.0 100.0\nFE  u_in stats: min/max 0.0 100.0\nDiff stats: max 0.0 mean 0.0 95th 0.0\nMismatched rows: 0\n"
          ]
        }
      ]
    },
    {
      "id": "a461b9e1-6c8a-4a1c-9eda-ece4f9ef968a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "print('=== DEBUG: Recompute vol_insp from raw and compare to FE v3 ===', flush=True)\n",
        "# Load raw and FE, align by id\n",
        "raw = pd.read_csv('train.csv', usecols=['id','breath_id','time_step','u_in','u_out'])\n",
        "fe = pd.read_parquet('train_fe_v3.parquet', columns=['id','breath_id','t_idx','vol_insp'])\n",
        "raw = raw.sort_values(['breath_id','time_step']).reset_index(drop=True)\n",
        "\n",
        "# Compute dt per breath and inspiration-only integral\n",
        "grp = raw.groupby('breath_id', sort=False)\n",
        "dt = grp['time_step'].diff().fillna(0.0).astype(np.float32)\n",
        "vol_insp_re = (raw['u_in'].astype(np.float32) * dt * (raw['u_out'].values==0).astype(np.float32))\n",
        "vol_insp_re = vol_insp_re.groupby(raw['breath_id']).cumsum().astype(np.float32)\n",
        "\n",
        "# Attach recomputed to raw ids order\n",
        "raw_comp = raw[['id']].copy(); raw_comp['vol_insp_re'] = vol_insp_re.values.astype(np.float32)\n",
        "raw_comp = raw_comp.sort_values('id').reset_index(drop=True)\n",
        "fe_sorted = fe.sort_values('id').reset_index(drop=True)\n",
        "assert (raw_comp['id'].values == fe_sorted['id'].values).all(), 'ID misalignment'\n",
        "\n",
        "diff = (fe_sorted['vol_insp'].astype(np.float32).values - raw_comp['vol_insp_re'].values)\n",
        "abs_diff = np.abs(diff)\n",
        "print('vol_insp FE vs recomputed | max abs diff:', float(abs_diff.max()), 'mean abs diff:', float(abs_diff.mean()),\n",
        "      'p95:', float(np.quantile(abs_diff, 0.95)), flush=True)\n",
        "print('vol_insp ranges | FE min/max:', float(fe_sorted['vol_insp'].min()), float(fe_sorted['vol_insp'].max()),\n",
        "      '| recomputed min/max:', float(raw_comp['vol_insp_re'].min()), float(raw_comp['vol_insp_re'].max()))\n",
        "\n",
        "# Spot-check a breath with largest discrepancy\n",
        "idx_bad = np.argmax(abs_diff)\n",
        "bid_bad = int(fe_sorted.loc[idx_bad, 'breath_id'])\n",
        "print('Worst breath_id:', bid_bad, 'sample compare (first 10 rows by t_idx):', flush=True)\n",
        "fe_b = fe[fe['breath_id']==bid_bad].sort_values('t_idx')\n",
        "raw_b = raw[raw['breath_id']==bid_bad].sort_values('time_step')\n",
        "print(pd.DataFrame({\n",
        "    'id': fe_b['id'].head(10).values,\n",
        "    't_idx': fe_b['t_idx'].head(10).values,\n",
        "    'vol_insp_FE': fe_b['vol_insp'].head(10).values,\n",
        "    'vol_insp_re': raw_b['u_in'].astype(np.float32).head(10).values * 0 + raw_b['u_in'].head(10).values  # placeholder to show alignment\n",
        "}))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DEBUG: Recompute vol_insp from raw and compare to FE v3 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vol_insp FE vs recomputed | max abs diff: 7.62939453125e-06 mean abs diff: 8.23157577656275e-08 p95: 4.76837158203125e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vol_insp ranges | FE min/max: 0.0 86.46919250488281 | recomputed min/max: 0.0 86.46919250488281\nWorst breath_id: 3230 sample compare (first 10 rows by t_idx):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     id  t_idx  vol_insp_FE  vol_insp_re\n0  4321      0     0.000000        100.0\n1  4322      1     3.192830        100.0\n2  4323      2     6.383181        100.0\n3  4324      3     9.572363        100.0\n4  4325      4    12.868190        100.0\n5  4326      5    16.054226        100.0\n6  4327      6    19.248676        100.0\n7  4328      7    22.425915        100.0\n8  4329      8    25.711609        100.0\n9  4330      9    28.886341        100.0\n"
          ]
        }
      ]
    },
    {
      "id": "26d663a6-fc87-4437-a0f3-eec398f2b446",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== Diagnostics: inspect shapes, mask counts, correlations, and betas per (R,C) ===', flush=True)\n",
        "tr_path = Path('train_fe_v3.parquet'); te_path = Path('test_fe_v3.parquet')\n",
        "train_fe = pd.read_parquet(tr_path).sort_values('id').reset_index(drop=True)\n",
        "\n",
        "y = train_fe['pressure'].to_numpy(np.float32)\n",
        "u = train_fe['u_in'].to_numpy(np.float32)\n",
        "R = train_fe['R'].to_numpy(np.float32)\n",
        "C = train_fe['C'].to_numpy(np.float32)\n",
        "w = (train_fe['u_out'].to_numpy()==0).astype(np.float32)\n",
        "voli = train_fe['vol_insp'].to_numpy(np.float32)\n",
        "folds = train_fe['fold'].to_numpy(np.int32)\n",
        "\n",
        "flow = u * 0.01\n",
        "x1 = R * flow\n",
        "x2 = voli / C\n",
        "print('Shapes:', x1.shape, x2.shape, y.shape, w.shape, flush=True)\n",
        "print('Mask fraction (u_out==0):', float(w.mean()), flush=True)\n",
        "m_insp = w > 0\n",
        "def safe_corr(a,b):\n",
        "    a = a[m_insp].astype(np.float64); b = b[m_insp].astype(np.float64)\n",
        "    if a.size < 3: return np.nan\n",
        "    a = (a - a.mean())/(a.std()+1e-9); b = (b - b.mean())/(b.std()+1e-9)\n",
        "    return float(np.mean(a*b))\n",
        "print('Corr(y,x1) insp:', safe_corr(y, x1), 'Corr(y,x2) insp:', safe_corr(y, x2), flush=True)\n",
        "print('Ranges: flow[min,max]=', float(flow.min()), float(flow.max()), ' x1[min,max]=', float(x1.min()), float(x1.max()),\n",
        "      ' voli[min,max]=', float(voli.min()), float(voli.max()), ' x2[min,max]=', float(x2.min()), float(x2.max()), flush=True)\n",
        "\n",
        "rc_tr = (train_fe['R'].astype(np.int32)*100 + train_fe['C'].astype(np.int32)).to_numpy()\n",
        "rcs = np.unique(rc_tr)\n",
        "print('Unique RCs:', rcs.tolist(), flush=True)\n",
        "\n",
        "def fit_beta(X, y, w):\n",
        "    m = w > 0\n",
        "    if m.sum() < 3:\n",
        "        return np.array([0.,0.,float(y[m].mean()) if m.any() else float(y.mean())], dtype=np.float64)\n",
        "    return np.linalg.lstsq(X[m].astype(np.float64), y[m].astype(np.float64), rcond=None)[0].astype(np.float64)\n",
        "\n",
        "print('--- Global fit (no folds), per RC, physics X=[x1,x2,1] ---', flush=True)\n",
        "betas = {}\n",
        "for rc in rcs[:9]:\n",
        "    m = (rc_tr == rc)\n",
        "    X = np.stack([x1[m], x2[m], np.ones(m.sum(), np.float32)], 1)\n",
        "    b = fit_beta(X, y[m], w[m])\n",
        "    betas[int(rc)] = b\n",
        "    mae_rc = mean_absolute_error(y[m & (w>0)], (X @ b).astype(np.float64)[w[m]>0]) if (w[m]>0).any() else np.nan\n",
        "    print(f'RC {int(rc)}: n={int(m.sum())} | insp={int((w[m]>0).sum())} | betas={b.round(4).tolist()} | MAE_insp={mae_rc:.4f}', flush=True)\n",
        "\n",
        "print('--- Fold 0 quick check per RC ---', flush=True)\n",
        "k = 0\n",
        "tr_mask = (folds != k); va_mask = (folds == k)\n",
        "for rc in rcs[:9]:\n",
        "    m = (rc_tr == rc) & tr_mask\n",
        "    if not np.any(m):\n",
        "        continue\n",
        "    Xtr = np.stack([x1[m], x2[m], np.ones(m.sum(), np.float32)], 1)\n",
        "    b = fit_beta(Xtr, y[m], w[m])\n",
        "    mv = (rc_tr == rc) & va_mask\n",
        "    if np.any(mv):\n",
        "        pred = (np.stack([x1[mv], x2[mv], np.ones(mv.sum(), np.float32)], 1) @ b).astype(np.float64)\n",
        "        mae_rc = mean_absolute_error(y[mv & (w>0)], pred[w[mv]>0]) if (w[mv]>0).any() else np.nan\n",
        "        print(f'[Fold0] RC {int(rc)}: tr_insp={int((w[m]>0).sum())} va_insp={int((w[mv]>0).sum())} betas={b.round(4).tolist()} MAE_insp={mae_rc:.4f}', flush=True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Diagnostics: inspect shapes, mask counts, correlations, and betas per (R,C) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (5432400,) (5432400,) (5432400,) (5432400,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mask fraction (u_out==0): 0.37956005334854126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corr(y,x1) insp: 0.1323156083300688 Corr(y,x2) insp: 0.739106385554138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranges: flow[min,max]= 0.0 1.0  x1[min,max]= 0.0 50.0  voli[min,max]= 0.0 86.46919250488281  x2[min,max]= 0.0 8.646919250488281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique RCs: [510, 520, 550, 2010, 2020, 2050, 5010, 5020, 5050]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Global fit (no folds), per RC, physics X=[x1,x2,1] ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RC 510: n=598880 | insp=224610 | betas=[-1.5169, 18.0364, 8.556] | MAE_insp=2.0161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RC 520: n=596720 | insp=230359 | betas=[-0.2575, 11.1536, 9.5992] | MAE_insp=2.3522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RC 550: n=595600 | insp=221169 | betas=[0.4466, 18.0487, 7.2372] | MAE_insp=0.9777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RC 2010: n=437520 | insp=165879 | betas=[-0.1151, 18.3685, 8.9759] | MAE_insp=2.4242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RC 2020: n=446960 | insp=167233 | betas=[0.0991, 17.5953, 9.9233] | MAE_insp=3.3876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RC 2050: n=589600 | insp=218932 | betas=[0.3136, 28.603, 8.9024] | MAE_insp=2.9114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RC 5010: n=981120 | insp=374926 | betas=[-0.0712, 21.5121, 8.8611] | MAE_insp=3.7730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RC 5020: n=596480 | insp=231001 | betas=[0.0655, 28.8646, 11.1694] | MAE_insp=5.7068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RC 5050: n=589520 | insp=227813 | betas=[-0.1198, 63.7526, 11.5931] | MAE_insp=5.2155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Fold 0 quick check per RC ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold0] RC 510: tr_insp=180503 va_insp=44107 betas=[-1.4977, 18.1179, 8.5094] MAE_insp=2.0637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold0] RC 520: tr_insp=185571 va_insp=44788 betas=[-0.2496, 11.1212, 9.5933] MAE_insp=2.3468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold0] RC 550: tr_insp=176761 va_insp=44408 betas=[0.4446, 18.0314, 7.2327] MAE_insp=0.9715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold0] RC 2010: tr_insp=133091 va_insp=32788 betas=[-0.1174, 18.3808, 8.9925] MAE_insp=2.3731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold0] RC 2020: tr_insp=134371 va_insp=32862 betas=[0.1015, 17.6541, 9.8717] MAE_insp=3.4271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold0] RC 2050: tr_insp=172756 va_insp=46176 betas=[0.3024, 28.6513, 8.9291] MAE_insp=2.8928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold0] RC 5010: tr_insp=298900 va_insp=76026 betas=[-0.0712, 21.5147, 8.8647] MAE_insp=3.8031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold0] RC 5020: tr_insp=185062 va_insp=45939 betas=[0.0722, 28.8874, 11.1516] MAE_insp=5.6991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Fold0] RC 5050: tr_insp=182596 va_insp=45217 betas=[-0.1211, 63.7526, 11.5743] MAE_insp=5.2332\n"
          ]
        }
      ]
    },
    {
      "id": "b1cfb1f5-8750-4bd1-a7ad-0c284124e2bc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== Deployable physics prior: [R*flow, vol_true/C, u_in_first, 1] per-(R,C), fit on u_out==0 ===', flush=True)\n",
        "tr_path, te_path = Path('train_fe_v3.parquet'), Path('test_fe_v3.parquet')\n",
        "train = pd.read_parquet(tr_path).sort_values('id').reset_index(drop=True)\n",
        "test  = pd.read_parquet(te_path).sort_values('id').reset_index(drop=True)\n",
        "\n",
        "# Per-breath proxy for intercept (available at test)\n",
        "for df in (train, test):\n",
        "    df['u_in_first'] = df.groupby('breath_id')['u_in'].transform('first').astype(np.float32)\n",
        "\n",
        "y = train['pressure'].to_numpy(np.float32)\n",
        "w = (train['u_out'].to_numpy()==0)\n",
        "\n",
        "# Consistent physics units\n",
        "flow_tr = (train['u_in'].to_numpy(np.float32) * 0.01)\n",
        "flow_te = (test['u_in'].to_numpy(np.float32)  * 0.01)\n",
        "vol_tr  = (train['vol_insp'].to_numpy(np.float32) * 0.01)  # vol_true = cumsum(flow*dt)\n",
        "vol_te  = (test['vol_insp'].to_numpy(np.float32)  * 0.01)\n",
        "R_tr = train['R'].to_numpy(np.float32); C_tr = train['C'].to_numpy(np.float32)\n",
        "R_te = test['R'].to_numpy(np.float32);  C_te = test['C'].to_numpy(np.float32)\n",
        "x1_tr = R_tr * flow_tr\n",
        "x2_tr = vol_tr / C_tr\n",
        "x3_tr = train['u_in_first'].to_numpy(np.float32)\n",
        "x1_te = R_te * flow_te\n",
        "x2_te = vol_te / C_te\n",
        "x3_te = test['u_in_first'].to_numpy(np.float32)\n",
        "\n",
        "rc_tr = (train['R'].astype(np.int32)*100 + train['C'].astype(np.int32)).to_numpy()\n",
        "rc_te = (test['R'].astype(np.int32)*100 + test['C'].astype(np.int32)).to_numpy()\n",
        "rcs = np.unique(rc_tr)\n",
        "folds = train['fold'].to_numpy(np.int32)\n",
        "n_folds = int(folds.max()) + 1\n",
        "\n",
        "def fit_on_insp(X, y):\n",
        "    if X.shape[0] < X.shape[1] + 1:\n",
        "        return np.zeros(X.shape[1], dtype=np.float64)\n",
        "    beta, *_ = np.linalg.lstsq(X.astype(np.float64), y.astype(np.float64), rcond=None)\n",
        "    return beta.astype(np.float64)\n",
        "\n",
        "oof = np.zeros_like(y, dtype=np.float32)\n",
        "test_fold = np.zeros((len(test), n_folds), dtype=np.float32)\n",
        "\n",
        "for k in range(n_folds):\n",
        "    tr_mask = (folds != k) & w\n",
        "    va_mask = (folds == k) & w\n",
        "    betas = {}\n",
        "    for rc in rcs:\n",
        "        m = tr_mask & (rc_tr == rc)\n",
        "        if not m.any():\n",
        "            continue\n",
        "        X = np.stack([x1_tr[m], x2_tr[m], x3_tr[m], np.ones(m.sum(), np.float32)], 1)\n",
        "        b = fit_on_insp(X, y[m])\n",
        "        betas[int(rc)] = b\n",
        "    for rc, b in betas.items():\n",
        "        a1,a2,a3,c0 = [float(t) for t in b]\n",
        "        mv = (rc_tr == rc) & (folds == k)\n",
        "        if mv.any():\n",
        "            oof[mv] = (a1*x1_tr[mv] + a2*x2_tr[mv] + a3*x3_tr[mv] + c0).astype(np.float32)\n",
        "        mt = (rc_te == rc)\n",
        "        if mt.any():\n",
        "            test_fold[mt, k] = (a1*x1_te[mt] + a2*x2_te[mt] + a3*x3_te[mt] + c0).astype(np.float32)\n",
        "    mae_k = mean_absolute_error(y[va_mask], oof[va_mask])\n",
        "    print(f'Fold {k} masked MAE (deployable 3-term): {mae_k:.4f}', flush=True)\n",
        "\n",
        "mae = mean_absolute_error(y[w], oof[w])\n",
        "print('OOF masked MAE (deployable 3-term):', round(mae,4))\n",
        "\n",
        "train['p_phys'] = oof.astype(np.float32)\n",
        "test['p_phys']  = test_fold.mean(1).astype(np.float32)\n",
        "train.to_parquet(tr_path, index=False)\n",
        "test.to_parquet(te_path, index=False)\n",
        "print('Saved p_phys (deployable).')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Deployable physics prior: [R*flow, vol_true/C, u_in_first, 1] per-(R,C), fit on u_out==0 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 masked MAE (deployable 3-term): 3.2530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 masked MAE (deployable 3-term): 3.2532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 masked MAE (deployable 3-term): 3.2209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 masked MAE (deployable 3-term): 3.2406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 masked MAE (deployable 3-term): 3.2591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF masked MAE (deployable 3-term): 3.2454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved p_phys (deployable).\n"
          ]
        }
      ]
    },
    {
      "id": "d6e0bb35-87b1-4b58-98d9-2665aee956c5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== Sanity: Fixed-effects OOF (per-breath intercept from val y) ===', flush=True)\n",
        "tr_path, te_path = Path('train_fe_v3.parquet'), Path('test_fe_v3.parquet')\n",
        "train = pd.read_parquet(tr_path).sort_values(['id']).reset_index(drop=True)\n",
        "test  = pd.read_parquet(te_path).sort_values(['id']).reset_index(drop=True)\n",
        "\n",
        "y = train['pressure'].to_numpy(np.float32)\n",
        "w = (train['u_out'].to_numpy()==0)\n",
        "\n",
        "# Consistent physics features\n",
        "flow_tr = (train['u_in'].to_numpy(np.float32) * 0.01)\n",
        "flow_te = (test['u_in'].to_numpy(np.float32)  * 0.01)\n",
        "vol_tr  = (train['vol_insp'].to_numpy(np.float32) * 0.01)  # vol_true = cumsum(flow*dt)\n",
        "vol_te  = (test['vol_insp'].to_numpy(np.float32)  * 0.01)\n",
        "R_tr = train['R'].to_numpy(np.float32); C_tr = train['C'].to_numpy(np.float32)\n",
        "R_te = test['R'].to_numpy(np.float32);  C_te = test['C'].to_numpy(np.float32)\n",
        "\n",
        "x1_tr = R_tr * flow_tr\n",
        "x2_tr = vol_tr / C_tr\n",
        "x1_te = R_te * flow_te\n",
        "x2_te = vol_te / C_te\n",
        "\n",
        "rc_tr = (train['R'].astype(np.int32)*100 + train['C'].astype(np.int32)).to_numpy()\n",
        "rc_te = (test['R'].astype(np.int32)*100 + test['C'].astype(np.int32)).to_numpy()\n",
        "rcs = np.unique(rc_tr)\n",
        "\n",
        "folds = train['fold'].to_numpy(np.int32)\n",
        "n_folds = folds.max() + 1\n",
        "\n",
        "def fit_slopes_no_intercept(X, y):\n",
        "    b, *_ = np.linalg.lstsq(X.astype(np.float64), y.astype(np.float64), rcond=None)\n",
        "    return b.astype(np.float64)\n",
        "\n",
        "oof = np.zeros_like(y, dtype=np.float32)\n",
        "test_fold = np.zeros((len(test), n_folds), dtype=np.float32)\n",
        "\n",
        "for k in range(n_folds):\n",
        "    tr_mask = (folds != k) & w\n",
        "    va_mask = (folds == k) & w\n",
        "\n",
        "    betas = {}; c_rc = {}\n",
        "    for rc in rcs:\n",
        "        m = tr_mask & (rc_tr == rc)\n",
        "        if not m.any():\n",
        "            continue\n",
        "        Xtr = np.stack([x1_tr[m], x2_tr[m]], 1)\n",
        "        ytr = y[m]\n",
        "        b = fit_slopes_no_intercept(Xtr, ytr)\n",
        "        betas[int(rc)] = b\n",
        "        c_rc[int(rc)] = float(np.median(ytr - (Xtr @ b)))\n",
        "\n",
        "    # Validation: per-breath intercept from that fold's y\n",
        "    for bid, g in train[va_mask].groupby('breath_id', sort=False):\n",
        "        idx = g.index.to_numpy()\n",
        "        rc = int((g['R'].iat[0])*100 + g['C'].iat[0])\n",
        "        if rc not in betas:\n",
        "            continue\n",
        "        a,b = betas[rc]\n",
        "        pred_shape = a*x1_tr[idx] + b*x2_tr[idx]\n",
        "        c_b = float(np.median(y[idx] - pred_shape))\n",
        "        oof[idx] = (pred_shape + c_b).astype(np.float32)\n",
        "\n",
        "    # Test: per-(R,C) fallback intercept\n",
        "    for rc, beta in betas.items():\n",
        "        a,b = beta\n",
        "        mt = (rc_te == rc)\n",
        "        if mt.any():\n",
        "            test_fold[mt, k] = (a*x1_te[mt] + b*x2_te[mt] + c_rc[rc]).astype(np.float32)\n",
        "\n",
        "    mae_k = mean_absolute_error(y[va_mask], oof[va_mask])\n",
        "    print(f'Fold {k} masked MAE (fixed-effects OOF): {mae_k:.4f}', flush=True)\n",
        "\n",
        "mae_oof = mean_absolute_error(y[w], oof[w])\n",
        "print(f'OOF masked MAE (fixed-effects): {mae_oof:.4f}')\n",
        "\n",
        "train['p_phys'] = oof.astype(np.float32)\n",
        "test['p_phys']  = test_fold.mean(1).astype(np.float32)\n",
        "train = train.sort_values('id').reset_index(drop=True)\n",
        "test  = test.sort_values('id').reset_index(drop=True)\n",
        "train.to_parquet(tr_path, index=False)\n",
        "test.to_parquet(te_path, index=False)\n",
        "print('Saved p_phys (fixed-effects OOF sanity).')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Sanity: Fixed-effects OOF (per-breath intercept from val y) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 masked MAE (fixed-effects OOF): 2.3842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 masked MAE (fixed-effects OOF): 2.3825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 masked MAE (fixed-effects OOF): 2.3738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 masked MAE (fixed-effects OOF): 2.3684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 masked MAE (fixed-effects OOF): 2.3974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF masked MAE (fixed-effects): 2.3813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved p_phys (fixed-effects OOF sanity).\n"
          ]
        }
      ]
    },
    {
      "id": "ace89539-d169-4193-bb21-a76735f83f73",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd, time, gc, os\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== Per-timestep XGBoost GPU baseline: masked training on u_out==0, fold-safe OOF/Test ===', flush=True)\n",
        "\n",
        "import xgboost as xgb\n",
        "tr_path, te_path = Path('train_fe_v3.parquet'), Path('test_fe_v3.parquet')\n",
        "train = pd.read_parquet(tr_path)\n",
        "test  = pd.read_parquet(te_path)\n",
        "\n",
        "# Ensure id/breath order availability\n",
        "train_id = train.sort_values('id').reset_index(drop=True)\n",
        "train_b = train.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "test_b  = test.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "\n",
        "# Feature set (safe, target-free). Exclude pressure, is_train, fold, ids.\n",
        "drop_cols = {'pressure','is_train','fold','id'}\n",
        "feat_blacklist = set()\n",
        "FEATS = [c for c in train.columns if c not in drop_cols and c in test.columns and c not in feat_blacklist]\n",
        "FEATS = [c for c in FEATS if c not in ['u_out']]  # exclude mask as feature\n",
        "print('Num features:', len(FEATS))\n",
        "\n",
        "# Build fold mapping (breath-wise)\n",
        "folds_df = pd.read_csv('folds_breath_v3.csv')\n",
        "b2f = dict(zip(folds_df['breath_id'].astype(int), folds_df['fold'].astype(int)))\n",
        "folds_b = train_b['breath_id'].astype(int).map(b2f).astype(np.int8).to_numpy()\n",
        "assert not np.isnan(folds_b).any(), 'Missing folds for some breaths'\n",
        "\n",
        "# Targets and mask\n",
        "y_b = train_b['pressure'].to_numpy(np.float32)\n",
        "mask_b = (train_b['u_out'].to_numpy()==0)\n",
        "t_idx_b = train_b['t_idx'].astype(np.int16).to_numpy()\n",
        "\n",
        "n_folds = int(folds_df['fold'].max()) + 1\n",
        "T = int(train_b['t_idx'].max()) + 1\n",
        "print('Folds:', n_folds, 'Timesteps:', T, flush=True)\n",
        "\n",
        "# Prepare OOF and test preds (breath-order grids) then convert to id-order at end\n",
        "B = train_b['breath_id'].nunique()\n",
        "oof = np.zeros(train_b.shape[0], dtype=np.float32)\n",
        "test_pred_all = np.zeros(test_b.shape[0], dtype=np.float32)\n",
        "\n",
        "params = {\n",
        "    'tree_method': 'hist',\n",
        "    'device': 'cuda',\n",
        "    'max_depth': 8,\n",
        "    'min_child_weight': 16,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'lambda': 4.0,\n",
        "    'alpha': 4.0,\n",
        "    'eta': 0.05,\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'mae',\n",
        "    'nthread': max(1, os.cpu_count()-2)\n",
        "}\n",
        "n_rounds = 1500\n",
        "early = 100\n",
        "\n",
        "t0 = time.time()\n",
        "for t in range(T):\n",
        "    idx_t_tr = (t_idx_b == t)\n",
        "    # Only inspiration rows participate (masked metric)\n",
        "    idx_fit = idx_t_tr & mask_b\n",
        "    if idx_fit.sum() == 0:\n",
        "        continue\n",
        "    X_t = train_b.loc[idx_fit, FEATS].to_numpy(np.float32, copy=False)\n",
        "    y_t = y_b[idx_fit]\n",
        "    f_t = folds_b[idx_fit]\n",
        "    # Build arrays for mapping back to full t-slice positions\n",
        "    pos_all_t = np.where(idx_t_tr)[0]\n",
        "    pos_fit_t = np.where(idx_fit)[0]\n",
        "    fold_pred_val = np.zeros(idx_t_tr.sum(), dtype=np.float32)\n",
        "    fold_pred_test = np.zeros(test_b.shape[0]//T, dtype=np.float32)  # per-breath rows per t\n",
        "    # Test slice for this t\n",
        "    mt = (test_b['t_idx'].to_numpy()==t)\n",
        "    X_te_t = test_b.loc[mt, FEATS].to_numpy(np.float32, copy=False)\n",
        "    dte = xgb.DMatrix(X_te_t)\n",
        "    for k in range(n_folds):\n",
        "        m_tr = (f_t != k)\n",
        "        m_va = (f_t == k)\n",
        "        if m_tr.sum() == 0 or m_va.sum() == 0:\n",
        "            continue\n",
        "        dtr = xgb.DMatrix(X_t[m_tr], label=y_t[m_tr])\n",
        "        dva = xgb.DMatrix(X_t[m_va], label=y_t[m_va])\n",
        "        watch = [(dtr, 'tr'), (dva, 'va')]\n",
        "        bst = xgb.train(params, dtr, num_boost_round=n_rounds, evals=watch, early_stopping_rounds=early, verbose_eval=False)\n",
        "        # best iteration handling for xgboost >=2.0\n",
        "        attrs = bst.attributes()\n",
        "        best_it = int(attrs.get('best_iteration', '0'))\n",
        "        iter_range = (0, best_it + 1) if best_it > 0 else None\n",
        "        # Val predictions\n",
        "        fold_pred_val_subset = bst.predict(dva, iteration_range=iter_range)\n",
        "        pos_va_fit = pos_fit_t[m_va]\n",
        "        fold_pred_val_indices = np.searchsorted(pos_all_t, pos_va_fit)\n",
        "        fold_pred_val[fold_pred_val_indices] = fold_pred_val_subset.astype(np.float32)\n",
        "        # Test predictions\n",
        "        fold_pred_test += bst.predict(dte, iteration_range=iter_range).astype(np.float32) / n_folds\n",
        "    # Write back this timestep's OOF and test predictions\n",
        "    oof[idx_t_tr] = fold_pred_val\n",
        "    test_pred_all[mt] = fold_pred_test\n",
        "    if (t+1) % 10 == 0 or t in (0,1,2):\n",
        "        m_slice = mask_b & (t_idx_b == t)\n",
        "        mae_t = mean_absolute_error(y_b[m_slice], oof[m_slice]) if m_slice.any() else np.nan\n",
        "        print(f't={t:02d} | rows_fit={int(idx_fit.sum())} | val_rows={int((idx_t_tr & mask_b).sum())} | MAE_masked={mae_t:.4f} | elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    gc.collect()\n",
        "\n",
        "# Compute overall OOF masked MAE\n",
        "mae_all = mean_absolute_error(y_b[mask_b], oof[mask_b])\n",
        "print(f'OOF masked MAE (per-t XGB): {mae_all:.6f}', flush=True)\n",
        "\n",
        "# Convert breath-order predictions back to id-order for saving and blending\n",
        "train_b_pred = train_b[['id']].copy(); train_b_pred['pressure'] = oof.astype(np.float32)\n",
        "train_id_pred = train_b_pred.sort_values('id').reset_index(drop=True)\n",
        "np.save('oof_xgb.npy', train_id_pred['pressure'].to_numpy(np.float32))\n",
        "print('Saved oof_xgb.npy (id-order)', flush=True)\n",
        "\n",
        "test_b_pred = test_b[['id']].copy(); test_b_pred['pressure'] = test_pred_all.astype(np.float32)\n",
        "sub = test_b_pred.sort_values('id').reset_index(drop=True)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv from per-t XGB.', flush=True)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Per-timestep XGBoost GPU baseline: masked training on u_out==0, fold-safe OOF/Test ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num features: 58\nFolds: 5 Timesteps: 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t=00 | rows_fit=67905 | val_rows=67905 | MAE_masked=0.1990 | elapsed=47.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t=01 | rows_fit=67905 | val_rows=67905 | MAE_masked=0.1823 | elapsed=97.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t=02 | rows_fit=67905 | val_rows=67905 | MAE_masked=0.1884 | elapsed=148.3s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     85\u001b[39m dva = xgb.DMatrix(X_t[m_va], label=y_t[m_va])\n\u001b[32m     86\u001b[39m watch = [(dtr, \u001b[33m'\u001b[39m\u001b[33mtr\u001b[39m\u001b[33m'\u001b[39m), (dva, \u001b[33m'\u001b[39m\u001b[33mva\u001b[39m\u001b[33m'\u001b[39m)]\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m bst = \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# best iteration handling for xgboost >=2.0\u001b[39;00m\n\u001b[32m     89\u001b[39m attrs = bst.attributes()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py:726\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    725\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/xgboost/training.py:181\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/xgboost/core.py:2101\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2100\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2101\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2102\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2103\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2104\u001b[39m     )\n\u001b[32m   2105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2106\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "99e16b40-3432-41b9-ba91-32f0b48ce27b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd, time, gc, os, sys, subprocess\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== Per-timestep CatBoost GPU baseline: masked training on u_out==0, fold-safe OOF/Test ===', flush=True)\n",
        "\n",
        "try:\n",
        "    import catboost as cb\n",
        "except Exception:\n",
        "    print('Installing catboost...', flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'catboost==1.2.5'], check=True)\n",
        "    import catboost as cb\n",
        "\n",
        "tr_path, te_path = Path('train_fe_v3.parquet'), Path('test_fe_v3.parquet')\n",
        "train = pd.read_parquet(tr_path)\n",
        "test  = pd.read_parquet(te_path)\n",
        "\n",
        "# Sort to breath-order for per-t training\n",
        "train_b = train.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "test_b  = test.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "\n",
        "# Feature set: same as XGB (exclude target, ids, fold, u_out)\n",
        "drop_cols = {'pressure','is_train','fold','id'}\n",
        "FEATS = [c for c in train.columns if c not in drop_cols and c in test.columns and c != 'u_out']\n",
        "print('Num features:', len(FEATS))\n",
        "\n",
        "# Folds (breath-wise)\n",
        "folds_df = pd.read_csv('folds_breath_v3.csv')\n",
        "b2f = dict(zip(folds_df['breath_id'].astype(int), folds_df['fold'].astype(int)))\n",
        "folds_b = train_b['breath_id'].astype(int).map(b2f).astype(np.int8).to_numpy()\n",
        "assert not np.isnan(folds_b).any(), 'Missing folds for some breaths'\n",
        "\n",
        "# Targets and mask\n",
        "y_b = train_b['pressure'].to_numpy(np.float32)\n",
        "mask_b = (train_b['u_out'].to_numpy()==0)\n",
        "t_idx_b = train_b['t_idx'].astype(np.int16).to_numpy()\n",
        "\n",
        "n_folds = int(folds_df['fold'].max()) + 1\n",
        "T = int(train_b['t_idx'].max()) + 1\n",
        "print('Folds:', n_folds, 'Timesteps:', T, flush=True)\n",
        "\n",
        "oof = np.zeros(train_b.shape[0], dtype=np.float32)\n",
        "test_pred_all = np.zeros(test_b.shape[0], dtype=np.float32)\n",
        "\n",
        "params = dict(\n",
        "    loss_function='MAE',\n",
        "    depth=8,\n",
        "    learning_rate=0.05,\n",
        "    l2_leaf_reg=6.0,\n",
        "    subsample=0.8,\n",
        "    bootstrap_type='Bernoulli',\n",
        "    random_strength=0.5,\n",
        "    task_type='GPU',\n",
        "    devices='0',\n",
        "    border_count=128,\n",
        "    random_seed=42,\n",
        "    verbose=False\n",
        ")\n",
        "n_rounds = 2000\n",
        "early = 150\n",
        "\n",
        "t0 = time.time()\n",
        "for t in range(T):\n",
        "    idx_t_tr = (t_idx_b == t)\n",
        "    idx_fit = idx_t_tr & mask_b\n",
        "    if idx_fit.sum() == 0:\n",
        "        continue\n",
        "    X_t = train_b.loc[idx_fit, FEATS]\n",
        "    y_t = y_b[idx_fit]\n",
        "    f_t = folds_b[idx_fit]\n",
        "    # mapping indices back\n",
        "    pos_all_t = np.where(idx_t_tr)[0]\n",
        "    pos_fit_t = np.where(idx_fit)[0]\n",
        "    fold_pred_val = np.zeros(idx_t_tr.sum(), dtype=np.float32)\n",
        "    fold_pred_test = np.zeros(test_b.shape[0]//T, dtype=np.float32)\n",
        "    # Test slice\n",
        "    mt = (test_b['t_idx'].to_numpy()==t)\n",
        "    X_te_t = test_b.loc[mt, FEATS]\n",
        "    for k in range(n_folds):\n",
        "        m_tr = (f_t != k)\n",
        "        m_va = (f_t == k)\n",
        "        if m_tr.sum() == 0 or m_va.sum() == 0:\n",
        "            continue\n",
        "        dtr = cb.Pool(X_t.iloc[m_tr], y_t[m_tr])\n",
        "        dva = cb.Pool(X_t.iloc[m_va], y_t[m_va])\n",
        "        model = cb.CatBoostRegressor(**params, iterations=n_rounds, early_stopping_rounds=early)\n",
        "        model.fit(dtr, eval_set=dva, use_best_model=True, verbose=False)\n",
        "        pred_va = model.predict(dva).astype(np.float32)\n",
        "        pos_va_fit = pos_fit_t[m_va]\n",
        "        fold_pred_val_indices = np.searchsorted(pos_all_t, pos_va_fit)\n",
        "        fold_pred_val[fold_pred_val_indices] = pred_va\n",
        "        fold_pred_test += model.predict(X_te_t).astype(np.float32) / n_folds\n",
        "    oof[idx_t_tr] = fold_pred_val\n",
        "    test_pred_all[mt] = fold_pred_test\n",
        "    if (t+1) % 10 == 0 or t in (0,1,2):\n",
        "        m_slice = mask_b & (t_idx_b == t)\n",
        "        mae_t = mean_absolute_error(y_b[m_slice], oof[m_slice]) if m_slice.any() else np.nan\n",
        "        print(f't={t:02d} | rows_fit={int(idx_fit.sum())} | MAE_masked={mae_t:.4f} | elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    gc.collect()\n",
        "\n",
        "mae_all = mean_absolute_error(y_b[mask_b], oof[mask_b])\n",
        "print(f'OOF masked MAE (per-t CatBoost): {mae_all:.6f}', flush=True)\n",
        "\n",
        "# Save OOF (id-order) and submission\n",
        "train_b_pred = train_b[['id']].copy(); train_b_pred['pressure'] = oof.astype(np.float32)\n",
        "train_id_pred = train_b_pred.sort_values('id').reset_index(drop=True)\n",
        "np.save('oof_cat.npy', train_id_pred['pressure'].to_numpy(np.float32))\n",
        "print('Saved oof_cat.npy (id-order)', flush=True)\n",
        "\n",
        "test_b_pred = test_b[['id']].copy(); test_b_pred['pressure'] = test_pred_all.astype(np.float32)\n",
        "sub_cat = test_b_pred.sort_values('id').reset_index(drop=True)\n",
        "sub_cat.to_csv('submission_cat.csv', index=False)\n",
        "print('Saved submission_cat.csv', flush=True)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Per-timestep CatBoost GPU baseline: masked training on u_out==0, fold-safe OOF/Test ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num features: 50\nFolds: 5 Timesteps: 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14764.125 Total: 24291.375\nDefault metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14762.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14762.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14762.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     84\u001b[39m dva = cb.Pool(X_t.iloc[m_va], y_t[m_va])\n\u001b[32m     85\u001b[39m model = cb.CatBoostRegressor(**params, iterations=n_rounds, early_stopping_rounds=early)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdva\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m pred_va = model.predict(dva).astype(np.float32)\n\u001b[32m     88\u001b[39m pos_va_fit = pos_fit_t[m_va]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/catboost/core.py:5873\u001b[39m, in \u001b[36mCatBoostRegressor.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5872\u001b[39m     CatBoostRegressor._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5874\u001b[39m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5875\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5876\u001b[39m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/catboost/core.py:2410\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2407\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2409\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m.get_params())]):\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2418\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2419\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/catboost/core.py:1790\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5023\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5072\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ]
    },
    {
      "id": "61678075-0f87-4f5d-87d1-dbd19c714684",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd, time\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== XGB OOF post-processing v3: fix breath start map + per-(R,C) fold-safe grid + insp-segment median(3) + RC\u00d7t de-bias ===', flush=True)\n",
        "\n",
        "tr_path = Path('train_fe_v3.parquet')\n",
        "oof_path = Path('oof_xgb.npy')\n",
        "assert tr_path.exists() and oof_path.exists(), 'Missing train_fe_v3.parquet or oof_xgb.npy'\n",
        "\n",
        "train_id = pd.read_parquet(tr_path).sort_values('id').reset_index(drop=True)\n",
        "train_b = pd.read_parquet(tr_path).sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "oof_id = np.load(oof_path).astype(np.float32)\n",
        "assert len(oof_id) == len(train_id), 'OOF length mismatch vs train rows'\n",
        "\n",
        "# Map id-order OOF to breath-order\n",
        "id_to_pos = dict(zip(train_id['id'].to_numpy(), np.arange(len(train_id), dtype=np.int64)))\n",
        "idx_breath_order = np.array([id_to_pos[i] for i in train_b['id'].to_numpy()], dtype=np.int64)\n",
        "pred_breath = oof_id[idx_breath_order].astype(np.float32)\n",
        "\n",
        "y = train_b['pressure'].to_numpy(np.float32)\n",
        "mask = (train_b['u_out'].to_numpy()==0)\n",
        "t_idx = train_b['t_idx'].to_numpy(np.int16)\n",
        "rc_key = (train_b['R'].astype(np.int32)*100 + train_b['C'].astype(np.int32)).to_numpy()\n",
        "\n",
        "folds_df = pd.read_csv('folds_breath_v3.csv')\n",
        "b2f = dict(zip(folds_df['breath_id'].astype(int), folds_df['fold'].astype(int)))\n",
        "folds_row = train_b['breath_id'].astype(int).map(b2f).to_numpy()\n",
        "n_folds = int(folds_df['fold'].max()) + 1\n",
        "\n",
        "raw_mae = mean_absolute_error(y[mask], pred_breath[mask])\n",
        "print(f'OOF masked MAE (raw XGB): {raw_mae:.6f}', flush=True)\n",
        "\n",
        "B = train_b['breath_id'].nunique()\n",
        "T = int(train_b['t_idx'].max()) + 1\n",
        "assert B*T == len(train_b), 'Breath-order rows not contiguous; cannot reshape'\n",
        "\n",
        "def snap_to_grid(arr, grid):\n",
        "    idx = np.searchsorted(grid, arr)\n",
        "    idx0 = np.clip(idx-1, 0, grid.size-1); idx1 = np.clip(idx, 0, grid.size-1)\n",
        "    left = grid[idx0]; right = grid[idx1]\n",
        "    return np.where(np.abs(arr-left) <= np.abs(arr-right), left, right).astype(np.float32)\n",
        "\n",
        "def median_insp_segments(vals: np.ndarray, m: np.ndarray, k: int = 3) -> np.ndarray:\n",
        "    out = vals.copy()\n",
        "    n = len(vals)\n",
        "    i = 0\n",
        "    while i < n:\n",
        "        if not m[i]:\n",
        "            i += 1\n",
        "            continue\n",
        "        j = i\n",
        "        while j < n and m[j]:\n",
        "            j += 1\n",
        "        seg = vals[i:j]\n",
        "        if seg.size >= 3 and k == 3:\n",
        "            seg_ext = np.pad(seg, (1,1), mode='edge')\n",
        "            med = np.median(np.stack([seg_ext[:-2], seg_ext[1:-1], seg_ext[2:]], axis=0), axis=0)\n",
        "            out[i:j] = med.astype(np.float32)\n",
        "        else:\n",
        "            out[i:j] = seg.astype(np.float32)\n",
        "        i = j\n",
        "    return out\n",
        "\n",
        "# Build correct breath_id -> start index map (use first index from breath-order, preserve order) once\n",
        "first_rows = train_b.groupby('breath_id', sort=False).head(1)\n",
        "bid_to_start = dict(zip(first_rows['breath_id'].to_numpy(), first_rows.index.to_numpy()))\n",
        "\n",
        "# Prepare containers for PP result\n",
        "pp_pred = pred_breath.copy()\n",
        "\n",
        "t_start = time.time()\n",
        "for k in range(n_folds):\n",
        "    tr_rows = (folds_row != k)\n",
        "    va_rows = (folds_row == k)\n",
        "    if not va_rows.any():\n",
        "        continue\n",
        "    # RC\u00d7t de-bias computed from training folds only on masked rows\n",
        "    resid = (y - pred_breath).astype(np.float32)\n",
        "    m_tr = tr_rows & mask\n",
        "    df_res = pd.DataFrame({\n",
        "        'rc': rc_key[m_tr],\n",
        "        't': t_idx[m_tr],\n",
        "        'resid': resid[m_tr]\n",
        "    })\n",
        "    delta_tbl = df_res.groupby(['rc','t'])['resid'].median().astype(np.float32)\n",
        "    # Build per-(R,C) grid from training folds only, RC-specific\n",
        "    df_tr = pd.DataFrame({'y': y[tr_rows], 'rc': rc_key[tr_rows]})\n",
        "    rc_grids = {}\n",
        "    for rc, grp in df_tr.groupby('rc'):\n",
        "        g = np.unique(grp['y'].values.astype(np.float32))\n",
        "        rc_grids[int(rc)] = g\n",
        "\n",
        "    # Process breath-wise for this fold's validation breaths\n",
        "    va_breaths = np.unique(train_b.loc[va_rows, 'breath_id'].to_numpy())\n",
        "    for bid in va_breaths:\n",
        "        s = bid_to_start[int(bid)]\n",
        "        e = s + T\n",
        "        vals = pp_pred[s:e].copy()\n",
        "        rc = int(rc_key[s])\n",
        "        # de-bias with per-(rc,t) median residuals from train folds\n",
        "        dt = delta_tbl.reindex(pd.MultiIndex.from_product([[rc], np.arange(T)], names=['rc','t']))\n",
        "        if dt is not None:\n",
        "            delta_arr = dt.values.astype(np.float32)\n",
        "            if np.isnan(delta_arr).any():\n",
        "                delta_arr = np.where(np.isnan(delta_arr), 0.0, delta_arr).astype(np.float32)\n",
        "            vals = vals + delta_arr\n",
        "        # median(3) only within inspiration segments\n",
        "        m_b = mask[s:e]\n",
        "        vals = median_insp_segments(vals, m_b, k=3)\n",
        "        # snap to per-(R,C) fold-safe grid\n",
        "        grid = rc_grids.get(rc, None)\n",
        "        if grid is None or grid.size == 0:\n",
        "            grid = np.unique(y[tr_rows].astype(np.float32))\n",
        "        vals = snap_to_grid(vals, grid)\n",
        "        pp_pred[s:e] = vals.astype(np.float32)\n",
        "    print(f'Fold {k}: processed {va_rows.sum()} rows | elapsed {time.time()-t_start:.1f}s', flush=True)\n",
        "\n",
        "pp_mae = mean_absolute_error(y[mask], pp_pred[mask])\n",
        "print(f'OOF masked MAE (PP v3: RC\u00d7t de-bias + RC-grids + median3-insp + fixed breath map): {pp_mae:.6f}', flush=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== XGB OOF post-processing v3: fix breath start map + per-(R,C) fold-safe grid + insp-segment median(3) + RC\u00d7t de-bias ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF masked MAE (raw XGB): 0.301180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0: processed 1086480 rows | elapsed 9.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: processed 1086480 rows | elapsed 19.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2: processed 1086480 rows | elapsed 28.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3: processed 1086480 rows | elapsed 37.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4: processed 1086480 rows | elapsed 47.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF masked MAE (PP v3: RC\u00d7t de-bias + RC-grids + median3-insp + fixed breath map): 0.489980\n"
          ]
        }
      ]
    },
    {
      "id": "f36fc7ac-8522-43a2-8acf-421eff99f6a3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd, time\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== Test-time: apply RC\u00d7t de-bias (from XGB OOF), then per-(R,C) snap + insp-only median(3) ===', flush=True)\n",
        "\n",
        "tr_path = Path('train_fe_v3.parquet')\n",
        "te_path = Path('test_fe_v3.parquet')\n",
        "oof_path = Path('oof_xgb.npy')\n",
        "sub_path = Path('submission.csv')  # current XGB test preds\n",
        "assert tr_path.exists() and te_path.exists() and oof_path.exists() and sub_path.exists(), 'Missing required artifacts'\n",
        "\n",
        "# Load train/test FE and align orders\n",
        "train_id = pd.read_parquet(tr_path).sort_values('id').reset_index(drop=True)\n",
        "train_b = pd.read_parquet(tr_path).sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "test_id  = pd.read_parquet(te_path).sort_values('id').reset_index(drop=True)\n",
        "test_b   = pd.read_parquet(te_path).sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "sub = pd.read_csv(sub_path).sort_values('id').reset_index(drop=True)\n",
        "assert (sub['id'].values == test_id['id'].values).all(), 'submission.csv not aligned to test id order'\n",
        "\n",
        "# Map id-order OOF to breath-order to compute residual table\n",
        "oof_id = np.load(oof_path).astype(np.float32)\n",
        "assert len(oof_id) == len(train_id), 'OOF length mismatch vs train rows'\n",
        "id_to_pos_tr = dict(zip(train_id['id'].to_numpy(), np.arange(len(train_id), dtype=np.int64)))\n",
        "idx_breath_order = np.array([id_to_pos_tr[i] for i in train_b['id'].to_numpy()], dtype=np.int64)\n",
        "oof_breath = oof_id[idx_breath_order].astype(np.float32)\n",
        "\n",
        "# Residual de-bias per (R,C,t_idx) on masked rows, using full train (no fold needed for test)\n",
        "y = train_b['pressure'].to_numpy(np.float32)\n",
        "mask = (train_b['u_out'].to_numpy()==0)\n",
        "t_idx = train_b['t_idx'].to_numpy(np.int16)\n",
        "rc_key_tr = (train_b['R'].astype(np.int32)*100 + train_b['C'].astype(np.int32)).to_numpy()\n",
        "resid = (y - oof_breath).astype(np.float32)\n",
        "df_res = pd.DataFrame({'rc': rc_key_tr[mask], 't': t_idx[mask], 'resid': resid[mask]})\n",
        "delta_tbl = df_res.groupby(['rc','t'])['resid'].median().astype(np.float32)\n",
        "print('Built delta table size:', delta_tbl.size, flush=True)\n",
        "\n",
        "# Build per-(R,C) pressure grids from full train\n",
        "grid_all = np.unique(train_b['pressure'].values.astype(np.float32)); grid_all.sort()\n",
        "rc_train = (train_b['R'].astype(np.int32)*100 + train_b['C'].astype(np.int32)).to_numpy()\n",
        "rc_press = {}\n",
        "for rc, grp in pd.DataFrame({'rc': rc_train, 'p': train_b['pressure'].values.astype(np.float32)}).groupby('rc'):\n",
        "    g = np.unique(grp['p'].values); g.sort(); rc_press[int(rc)] = g\n",
        "\n",
        "def snap_to_grid(arr, grid):\n",
        "    idx = np.searchsorted(grid, arr)\n",
        "    idx0 = np.clip(idx-1, 0, grid.size-1); idx1 = np.clip(idx, 0, grid.size-1)\n",
        "    left = grid[idx0]; right = grid[idx1]\n",
        "    return np.where(np.abs(arr-left) <= np.abs(arr-right), left, right).astype(np.float32)\n",
        "\n",
        "def median_insp_segments(vals: np.ndarray, m: np.ndarray, k: int = 3) -> np.ndarray:\n",
        "    out = vals.copy()\n",
        "    n = len(vals); i = 0\n",
        "    while i < n:\n",
        "        if not m[i]:\n",
        "            i += 1; continue\n",
        "        j = i\n",
        "        while j < n and m[j]:\n",
        "            j += 1\n",
        "        seg = vals[i:j]\n",
        "        if seg.size >= 3 and k == 3:\n",
        "            seg_ext = np.pad(seg, (1,1), mode='edge')\n",
        "            med = np.median(np.stack([seg_ext[:-2], seg_ext[1:-1], seg_ext[2:]], axis=0), axis=0)\n",
        "            out[i:j] = med.astype(np.float32)\n",
        "        else:\n",
        "            out[i:j] = seg.astype(np.float32)\n",
        "        i = j\n",
        "    return out\n",
        "\n",
        "# Prepare test predictions in breath-order\n",
        "press_id_order = sub['pressure'].to_numpy(np.float32)\n",
        "id_to_pos_te = dict(zip(test_id['id'].to_numpy(), np.arange(len(test_id), dtype=np.int64)))\n",
        "idx_test_breath_order = np.array([id_to_pos_te[i] for i in test_b['id'].to_numpy()], dtype=np.int64)\n",
        "test_vals_breath = press_id_order[idx_test_breath_order].astype(np.float32)\n",
        "\n",
        "t0 = time.time()\n",
        "out_vals = np.zeros_like(test_vals_breath, dtype=np.float32)\n",
        "start = 0\n",
        "T = int(test_b['t_idx'].max()) + 1\n",
        "for bid, g in test_b.groupby('breath_id', sort=False):\n",
        "    g = g.sort_values('t_idx')\n",
        "    L = len(g)\n",
        "    vals = test_vals_breath[start:start+L].copy()\n",
        "    rc = int(g['R'].iloc[0])*100 + int(g['C'].iloc[0])\n",
        "    tt = g['t_idx'].to_numpy(np.int16)\n",
        "    # apply RC\u00d7t de-bias (missing -> 0)\n",
        "    keys = pd.MultiIndex.from_arrays([np.full(L, rc, dtype=np.int32), tt], names=['rc','t'])\n",
        "    delta = delta_tbl.reindex(keys).to_numpy()\n",
        "    delta = np.where(np.isnan(delta), 0.0, delta).astype(np.float32)\n",
        "    vals = vals + delta\n",
        "    # median filter only on inspiration steps\n",
        "    m = (g['u_out'].to_numpy()==0)\n",
        "    vals = median_insp_segments(vals, m, k=3)\n",
        "    # snap to per-(R,C) train grid\n",
        "    grid = rc_press.get(rc, grid_all)\n",
        "    vals = snap_to_grid(vals, grid)\n",
        "    out_vals[start:start+L] = vals.astype(np.float32)\n",
        "    start += L\n",
        "\n",
        "# Map back to id-order for saving\n",
        "out_df_breath = pd.DataFrame({'id': test_b['id'].to_numpy(), 'pressure': out_vals})\n",
        "sub_out = out_df_breath.sort_values('id').reset_index(drop=True)\n",
        "sub_out.to_csv('submission.csv', index=False)\n",
        "print('Saved updated submission.csv with RC\u00d7t de-bias + per-(R,C) snap + insp-only median(3). Elapsed:', round(time.time()-t0,1), 's', flush=True)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Test-time: apply RC\u00d7t de-bias (from XGB OOF), then per-(R,C) snap + insp-only median(3) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built delta table size: 288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved updated submission.csv with RC\u00d7t de-bias + per-(R,C) snap + insp-only median(3). Elapsed: 5.2 s\n"
          ]
        }
      ]
    },
    {
      "id": "1204d9ef-c090-49c4-b0de-dd897fade015",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd, time, gc, os, sys\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== Per-timestep XGBoost MAE | 3 seeds (S42/S17/S91) | GPU | masked rows | fold-safe OOF/Test ===', flush=True)\n",
        "\n",
        "import xgboost as xgb\n",
        "tr_path, te_path = Path('train_fe_v3.parquet'), Path('test_fe_v3.parquet')\n",
        "assert tr_path.exists() and te_path.exists(), 'Run FE cell first'\n",
        "train = pd.read_parquet(tr_path)\n",
        "test  = pd.read_parquet(te_path)\n",
        "\n",
        "# Sort to breath-major for per-t training\n",
        "train_b = train.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "test_b  = test.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "\n",
        "# Features: exclude target/meta and u_out (keep lags/leads etc.)\n",
        "drop_cols = {'pressure','is_train','fold','id'}\n",
        "FEATS = [c for c in train.columns if c not in drop_cols and c in test.columns and c != 'u_out']\n",
        "print('Num features:', len(FEATS))\n",
        "\n",
        "# Folds mapping (breath-wise)\n",
        "folds_df = pd.read_csv('folds_breath_v3.csv')\n",
        "b2f = dict(zip(folds_df['breath_id'].astype(int), folds_df['fold'].astype(int)))\n",
        "folds_b = train_b['breath_id'].astype(int).map(b2f).astype(np.int8).to_numpy()\n",
        "assert not np.isnan(folds_b).any(), 'Missing folds for some breaths'\n",
        "\n",
        "# Targets and mask\n",
        "y_b = train_b['pressure'].to_numpy(np.float32)\n",
        "mask_b = (train_b['u_out'].to_numpy()==0)\n",
        "t_idx_b = train_b['t_idx'].astype(np.int16).to_numpy()\n",
        "\n",
        "n_folds = int(folds_df['fold'].max()) + 1\n",
        "T = int(train_b['t_idx'].max()) + 1\n",
        "B = train_b['breath_id'].nunique()\n",
        "print('Folds:', n_folds, 'Timesteps:', T, 'Breaths:', B, flush=True)\n",
        "\n",
        "# Seed configurations (expert presets) with rounds/early stop\n",
        "seed_cfgs = [\n",
        "    dict(name='S42', seed=42, rounds=900, params=dict(eta=0.03, max_depth=8, min_child_weight=48, subsample=0.80, colsample_bytree=0.60, reg_lambda=24, reg_alpha=2, gamma=0.0)),\n",
        "    dict(name='S17', seed=17, rounds=850, params=dict(eta=0.035, max_depth=7, min_child_weight=40, subsample=0.75, colsample_bytree=0.55, reg_lambda=16, reg_alpha=0, gamma=0.1)),\n",
        "    dict(name='S91', seed=91, rounds=800, params=dict(eta=0.03, max_depth=8, min_child_weight=64, subsample=0.85, colsample_bytree=0.70, reg_lambda=32, reg_alpha=4, gamma=0.0)),\n",
        "]\n",
        "early = 100\n",
        "\n",
        "def train_one_seed(cfg):\n",
        "    name = cfg['name']; seed = int(cfg['seed']); rounds = int(cfg['rounds']); hp = cfg['params']\n",
        "    print(f'-- Seed {name} start | rounds={rounds} --', flush=True)\n",
        "    params = {\n",
        "        'tree_method': 'hist',\n",
        "        'device': 'cuda',\n",
        "        'objective': 'reg:absoluteerror',\n",
        "        'eval_metric': 'mae',\n",
        "        'nthread': max(1, os.cpu_count()-2),\n",
        "        'seed': seed,\n",
        "        'eta': hp['eta'],\n",
        "        'max_depth': hp['max_depth'],\n",
        "        'min_child_weight': hp['min_child_weight'],\n",
        "        'subsample': hp['subsample'],\n",
        "        'colsample_bytree': hp['colsample_bytree'],\n",
        "        'lambda': hp['reg_lambda'],\n",
        "        'alpha': hp['reg_alpha'],\n",
        "        'gamma': hp['gamma'],\n",
        "    }\n",
        "    oof = np.zeros(train_b.shape[0], dtype=np.float32)\n",
        "    test_pred_all = np.zeros(test_b.shape[0], dtype=np.float32)\n",
        "    t0 = time.time()\n",
        "    # Precompute per-t test slice index and data to avoid repeated to_numpy conversions\n",
        "    t_vec_test = test_b['t_idx'].to_numpy()\n",
        "    for t in range(T):\n",
        "        idx_t_tr = (t_idx_b == t)\n",
        "        idx_fit = idx_t_tr & mask_b\n",
        "        if idx_fit.sum() == 0:\n",
        "            continue\n",
        "        X_t = train_b.loc[idx_fit, FEATS].to_numpy(np.float32, copy=False)\n",
        "        y_t = y_b[idx_fit]\n",
        "        f_t = folds_b[idx_fit]\n",
        "        # positions to place back fold preds into the full t-slice\n",
        "        pos_all_t = np.where(idx_t_tr)[0]\n",
        "        pos_fit_t = np.where(idx_fit)[0]\n",
        "        fold_pred_val = np.zeros(idx_t_tr.sum(), dtype=np.float32)\n",
        "        # Test slice for this t\n",
        "        mt = (t_vec_test == t)\n",
        "        X_te_t = test_b.loc[mt, FEATS].to_numpy(np.float32, copy=False)\n",
        "        dte = xgb.DMatrix(X_te_t)\n",
        "        fold_pred_test = np.zeros(mt.sum(), dtype=np.float32)\n",
        "        for k in range(n_folds):\n",
        "            m_tr = (f_t != k); m_va = (f_t == k)\n",
        "            if m_tr.sum() == 0 or m_va.sum() == 0:\n",
        "                continue\n",
        "            dtr = xgb.DMatrix(X_t[m_tr], label=y_t[m_tr])\n",
        "            dva = xgb.DMatrix(X_t[m_va], label=y_t[m_va])\n",
        "            bst = xgb.train(params=params, dtrain=dtr, num_boost_round=rounds, evals=[(dtr,'tr'),(dva,'va')], early_stopping_rounds=early, verbose_eval=False)\n",
        "            attrs = bst.attributes()\n",
        "            best_it = int(attrs.get('best_iteration', '0'))\n",
        "            iter_range = (0, best_it + 1) if best_it > 0 else None\n",
        "            # Validation predictions mapped back to t-slice\n",
        "            pred_va = bst.predict(dva, iteration_range=iter_range).astype(np.float32)\n",
        "            pos_va_fit = pos_fit_t[m_va]\n",
        "            fold_pred_val_indices = np.searchsorted(pos_all_t, pos_va_fit)\n",
        "            fold_pred_val[fold_pred_val_indices] = pred_va\n",
        "            # Test predictions averaged across folds\n",
        "            fold_pred_test += bst.predict(dte, iteration_range=iter_range).astype(np.float32) / n_folds\n",
        "        # Write back\n",
        "        oof[idx_t_tr] = fold_pred_val\n",
        "        test_pred_all[mt] = fold_pred_test\n",
        "        if (t+1) % 10 == 0 or t < 3:\n",
        "            m_slice = mask_b & (t_idx_b == t)\n",
        "            mae_t = mean_absolute_error(y_b[m_slice], oof[m_slice]) if m_slice.any() else np.nan\n",
        "            print(f'{name} | t={t:02d} | rows_fit={int(idx_fit.sum())} | MAE_masked={mae_t:.4f} | elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "        gc.collect()\n",
        "    # Overall OOF masked MAE\n",
        "    mae_all = mean_absolute_error(y_b[mask_b], oof[mask_b])\n",
        "    print(f'{name} | OOF masked MAE: {mae_all:.6f} | total elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "    # Save OOF (id-order) and test preds (id-order)\n",
        "    train_b_pred = train_b[['id']].copy(); train_b_pred['pressure'] = oof.astype(np.float32)\n",
        "    train_id_pred = train_b_pred.sort_values('id').reset_index(drop=True)\n",
        "    np.save(f'oof_xgb_{name.lower()}.npy', train_id_pred['pressure'].to_numpy(np.float32))\n",
        "    test_b_pred = test_b[['id']].copy(); test_b_pred['pressure'] = test_pred_all.astype(np.float32)\n",
        "    sub_seed = test_b_pred.sort_values('id').reset_index(drop=True)\n",
        "    sub_seed.to_csv(f'submission_xgb_{name.lower()}.csv', index=False)\n",
        "    np.save(f'test_xgb_{name.lower()}.npy', sub_seed['pressure'].to_numpy(np.float32))\n",
        "    print(f'{name} | Saved oof_xgb_{name.lower()}.npy and test_xgb_{name.lower()}.npy', flush=True)\n",
        "    return oof, test_pred_all\n",
        "\n",
        "# Run seeds and average\n",
        "all_oof = []; all_test = []\n",
        "for cfg in seed_cfgs:\n",
        "    oof_s, test_s = train_one_seed(cfg)\n",
        "    all_oof.append(oof_s.astype(np.float32))\n",
        "    all_test.append(test_s.astype(np.float32))\n",
        "\n",
        "oof_mean = np.mean(np.stack(all_oof, axis=0), axis=0)\n",
        "test_mean = np.mean(np.stack(all_test, axis=0), axis=0)\n",
        "mae_mean = mean_absolute_error(y_b[mask_b], oof_mean[mask_b])\n",
        "print(f'AVG(3 seeds) OOF masked MAE: {mae_mean:.6f}', flush=True)\n",
        "\n",
        "# Save averaged OOF (id-order) and submission\n",
        "train_b_pred = train_b[['id']].copy(); train_b_pred['pressure'] = oof_mean.astype(np.float32)\n",
        "train_id_pred = train_b_pred.sort_values('id').reset_index(drop=True)\n",
        "np.save('oof_xgb_mae_avg.npy', train_id_pred['pressure'].to_numpy(np.float32))\n",
        "test_b_pred = test_b[['id']].copy(); test_b_pred['pressure'] = test_mean.astype(np.float32)\n",
        "sub_avg = test_b_pred.sort_values('id').reset_index(drop=True)\n",
        "sub_avg.to_csv('submission_xgb_mae_avg.csv', index=False)\n",
        "sub_avg.to_csv('submission.csv', index=False)  # set as current submission (raw, no PP)\n",
        "print('Saved oof_xgb_mae_avg.npy and submission_xgb_mae_avg.csv; updated submission.csv to seed-avg raw.', flush=True)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Per-timestep XGBoost MAE | 3 seeds (S42/S17/S91) | GPU | masked rows | fold-safe OOF/Test ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num features: 58\nFolds: 5 Timesteps: 80 Breaths: 67905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Seed S42 start | rounds=900 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S42 | t=00 | rows_fit=67905 | MAE_masked=0.2153 | elapsed=26.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S42 | t=01 | rows_fit=67905 | MAE_masked=0.2038 | elapsed=52.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S42 | t=02 | rows_fit=67905 | MAE_masked=0.2149 | elapsed=79.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S42 | t=09 | rows_fit=67905 | MAE_masked=0.3827 | elapsed=264.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S42 | t=19 | rows_fit=67905 | MAE_masked=0.3946 | elapsed=534.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S42 | t=29 | rows_fit=47285 | MAE_masked=0.4253 | elapsed=809.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S42 | OOF masked MAE: 0.369073 | total elapsed 852.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S42 | Saved oof_xgb_s42.npy and test_xgb_s42.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Seed S17 start | rounds=850 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S17 | t=00 | rows_fit=67905 | MAE_masked=0.2231 | elapsed=19.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S17 | t=01 | rows_fit=67905 | MAE_masked=0.2110 | elapsed=39.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S17 | t=02 | rows_fit=67905 | MAE_masked=0.2252 | elapsed=59.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S17 | t=09 | rows_fit=67905 | MAE_masked=0.4012 | elapsed=199.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S17 | t=19 | rows_fit=67905 | MAE_masked=0.4128 | elapsed=402.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S17 | t=29 | rows_fit=47285 | MAE_masked=0.4435 | elapsed=607.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S17 | OOF masked MAE: 0.385862 | total elapsed 640.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S17 | Saved oof_xgb_s17.npy and test_xgb_s17.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Seed S91 start | rounds=800 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S91 | t=00 | rows_fit=67905 | MAE_masked=0.2178 | elapsed=23.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S91 | t=01 | rows_fit=67905 | MAE_masked=0.2058 | elapsed=47.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S91 | t=02 | rows_fit=67905 | MAE_masked=0.2206 | elapsed=71.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S91 | t=09 | rows_fit=67905 | MAE_masked=0.3987 | elapsed=236.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S91 | t=19 | rows_fit=67905 | MAE_masked=0.3976 | elapsed=473.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S91 | t=29 | rows_fit=47285 | MAE_masked=0.4251 | elapsed=714.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S91 | OOF masked MAE: 0.375033 | total elapsed 753.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S91 | Saved oof_xgb_s91.npy and test_xgb_s91.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AVG(3 seeds) OOF masked MAE: 0.363891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved oof_xgb_mae_avg.npy and submission_xgb_mae_avg.csv; updated submission.csv to seed-avg raw.\n"
          ]
        }
      ]
    },
    {
      "id": "e2d49f30-ba31-4a09-8753-1781324484da",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd, time, gc, os, sys, subprocess\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== CatBoost t-bucket (t_bin=t_idx//8 -> 10 bins) | GPU | MAE | masked rows | fold-safe OOF/Test ===', flush=True)\n",
        "\n",
        "try:\n",
        "    import catboost as cb\n",
        "except Exception:\n",
        "    print('Installing catboost...', flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'catboost==1.2.5'], check=True)\n",
        "    import catboost as cb\n",
        "\n",
        "tr_path, te_path = Path('train_fe_v3.parquet'), Path('test_fe_v3.parquet')\n",
        "assert tr_path.exists() and te_path.exists(), 'Run FE cell first'\n",
        "train = pd.read_parquet(tr_path)\n",
        "test  = pd.read_parquet(te_path)\n",
        "\n",
        "# Sort breath-major\n",
        "train_b = train.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "test_b  = test.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "\n",
        "# Features: exclude target/meta and u_out (keep lags/leads etc.)\n",
        "drop_cols = {'pressure','is_train','fold','id'}\n",
        "FEATS = [c for c in train.columns if c not in drop_cols and c in test.columns and c != 'u_out']\n",
        "print('Num features:', len(FEATS))\n",
        "\n",
        "# Folds by breath\n",
        "folds_df = pd.read_csv('folds_breath_v3.csv')\n",
        "b2f = dict(zip(folds_df['breath_id'].astype(int), folds_df['fold'].astype(int)))\n",
        "folds_b = train_b['breath_id'].astype(int).map(b2f).astype(np.int8).to_numpy()\n",
        "assert not np.isnan(folds_b).any(), 'Missing folds for some breaths'\n",
        "\n",
        "# Targets and mask\n",
        "y_b = train_b['pressure'].to_numpy(np.float32)\n",
        "mask_b = (train_b['u_out'].to_numpy()==0)\n",
        "t_idx_b = train_b['t_idx'].astype(np.int16).to_numpy()\n",
        "t_bin_b = (t_idx_b // 8).astype(np.int16)  # 0..9\n",
        "t_bin_te = (test_b['t_idx'].astype(np.int16).to_numpy() // 8).astype(np.int16)\n",
        "\n",
        "n_folds = int(folds_df['fold'].max()) + 1\n",
        "NBINS = int(train_b['t_idx'].max() // 8) + 1\n",
        "print('Folds:', n_folds, 't_bins:', NBINS, flush=True)\n",
        "\n",
        "oof = np.zeros(train_b.shape[0], dtype=np.float32)\n",
        "test_pred_all = np.zeros(test_b.shape[0], dtype=np.float32)\n",
        "\n",
        "params = dict(\n",
        "    loss_function='MAE',\n",
        "    task_type='GPU',\n",
        "    devices='0',\n",
        "    depth=8,\n",
        "    learning_rate=0.033,\n",
        "    l2_leaf_reg=10.0,\n",
        "    subsample=0.8,\n",
        "    bootstrap_type='Bernoulli',\n",
        "    random_strength=0.3,\n",
        "    border_count=128,\n",
        "    random_seed=42,\n",
        "    verbose=False\n",
        ")\n",
        "n_rounds = 1300\n",
        "early = 130\n",
        "\n",
        "t0 = time.time()\n",
        "for b in range(NBINS):\n",
        "    idx_bin_tr_all = (t_bin_b == b)\n",
        "    idx_fit = idx_bin_tr_all & mask_b\n",
        "    if idx_fit.sum() == 0:\n",
        "        print(f'Bin {b}: no fit rows (masked). Skipping.', flush=True)\n",
        "        continue\n",
        "    X_t = train_b.loc[idx_fit, FEATS]\n",
        "    y_t = y_b[idx_fit]\n",
        "    f_t = folds_b[idx_fit]\n",
        "    pos_all_bin = np.where(idx_bin_tr_all)[0]\n",
        "    pos_fit_bin = np.where(idx_fit)[0]\n",
        "    fold_pred_val = np.zeros(idx_bin_tr_all.sum(), dtype=np.float32)\n",
        "    # Test slice for this bin\n",
        "    mt = (t_bin_te == b)\n",
        "    X_te_t = test_b.loc[mt, FEATS]\n",
        "    fold_pred_test = np.zeros(mt.sum(), dtype=np.float32)\n",
        "    for k in range(n_folds):\n",
        "        m_tr = (f_t != k); m_va = (f_t == k)\n",
        "        if m_tr.sum() == 0 or m_va.sum() == 0:\n",
        "            continue\n",
        "        dtr = cb.Pool(X_t.iloc[m_tr], y_t[m_tr])\n",
        "        dva = cb.Pool(X_t.iloc[m_va], y_t[m_va])\n",
        "        model = cb.CatBoostRegressor(**params, iterations=n_rounds, early_stopping_rounds=early)\n",
        "        model.fit(dtr, eval_set=dva, use_best_model=True, verbose=False)\n",
        "        pred_va = model.predict(dva).astype(np.float32)\n",
        "        pos_va_fit = pos_fit_bin[m_va]\n",
        "        fold_pred_val_indices = np.searchsorted(pos_all_bin, pos_va_fit)\n",
        "        fold_pred_val[fold_pred_val_indices] = pred_va\n",
        "        fold_pred_test += model.predict(X_te_t).astype(np.float32) / n_folds\n",
        "    oof[idx_bin_tr_all] = fold_pred_val\n",
        "    test_pred_all[mt] = fold_pred_test\n",
        "    m_slice = mask_b & idx_bin_tr_all\n",
        "    mae_b = mean_absolute_error(y_b[m_slice], oof[m_slice]) if m_slice.any() else np.nan\n",
        "    print(f'bin={b:02d} | rows_fit={int(idx_fit.sum())} | MAE_masked={mae_b:.4f} | elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    gc.collect()\n",
        "\n",
        "mae_all = mean_absolute_error(y_b[mask_b], oof[mask_b])\n",
        "print(f'OOF masked MAE (CatBoost t-bucket): {mae_all:.6f}', flush=True)\n",
        "\n",
        "# Save OOF (id-order) and submission\n",
        "train_b_pred = train_b[['id']].copy(); train_b_pred['pressure'] = oof.astype(np.float32)\n",
        "train_id_pred = train_b_pred.sort_values('id').reset_index(drop=True)\n",
        "np.save('oof_cat_bucket.npy', train_id_pred['pressure'].to_numpy(np.float32))\n",
        "test_b_pred = test_b[['id']].copy(); test_b_pred['pressure'] = test_pred_all.astype(np.float32)\n",
        "sub_catb = test_b_pred.sort_values('id').reset_index(drop=True)\n",
        "sub_catb.to_csv('submission_cat_bucket.csv', index=False)\n",
        "print('Saved oof_cat_bucket.npy and submission_cat_bucket.csv', flush=True)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CatBoost t-bucket (t_bin=t_idx//8 -> 10 bins) | GPU | MAE | masked rows | fold-safe OOF/Test ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num features: 58\nFolds: 5 t_bins: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14684.125 Total: 24291.375\nDefault metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14684.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14684.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14684.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14684.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin=00 | rows_fit=543240 | MAE_masked=0.9301 | elapsed=36.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\nDefault metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin=01 | rows_fit=543240 | MAE_masked=0.9541 | elapsed=72.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\nDefault metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin=02 | rows_fit=543240 | MAE_masked=0.7475 | elapsed=108.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\nDefault metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: less than 75% GPU memory available for training. Free: 14748.125 Total: 24291.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin=03 | rows_fit=432202 | MAE_masked=0.7120 | elapsed=142.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin 4: no fit rows (masked). Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin 5: no fit rows (masked). Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin 6: no fit rows (masked). Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin 7: no fit rows (masked). Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin 8: no fit rows (masked). Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bin 9: no fit rows (masked). Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF masked MAE (CatBoost t-bucket): 0.842597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved oof_cat_bucket.npy and submission_cat_bucket.csv\n"
          ]
        }
      ]
    },
    {
      "id": "277eea90-7084-48b0-baa0-d3326d055022",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd, time\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== Stepwise OOF PP diagnostics: RC fold-safe snap -> +median(3) -> +RC\u00d7t de-bias ===', flush=True)\n",
        "\n",
        "tr_path = Path('train_fe_v3.parquet')\n",
        "assert tr_path.exists(), 'Missing train_fe_v3.parquet'\n",
        "train_id = pd.read_parquet(tr_path).sort_values('id').reset_index(drop=True)\n",
        "train_b = pd.read_parquet(tr_path).sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "\n",
        "# Pick OOF file (prefer the stronger per-t XGB squarederror run if available)\n",
        "candidates = ['oof_xgb.npy','oof_xgb_s91.npy','oof_xgb_s42.npy','oof_xgb_s17.npy','oof_xgb_mae_avg.npy']\n",
        "oof_file = None\n",
        "for c in candidates:\n",
        "    if Path(c).exists():\n",
        "        oof_file = c; break\n",
        "assert oof_file is not None, 'No OOF file found among: ' + ', '.join(candidates)\n",
        "print('Using OOF file:', oof_file, flush=True)\n",
        "oof_id = np.load(oof_file).astype(np.float32)\n",
        "assert len(oof_id) == len(train_id), 'OOF length mismatch vs train rows'\n",
        "\n",
        "# Map id-order OOF to breath-order\n",
        "id_to_pos = dict(zip(train_id['id'].to_numpy(), np.arange(len(train_id), dtype=np.int64)))\n",
        "idx_breath_order = np.array([id_to_pos[i] for i in train_b['id'].to_numpy()], dtype=np.int64)\n",
        "pred_breath = oof_id[idx_breath_order].astype(np.float32)\n",
        "\n",
        "y = train_b['pressure'].to_numpy(np.float32)\n",
        "mask = (train_b['u_out'].to_numpy()==0)\n",
        "t_idx = train_b['t_idx'].to_numpy(np.int16)\n",
        "rc_key = (train_b['R'].astype(np.int32)*100 + train_b['C'].astype(np.int32)).to_numpy()\n",
        "\n",
        "folds_df = pd.read_csv('folds_breath_v3.csv')\n",
        "b2f = dict(zip(folds_df['breath_id'].astype(int), folds_df['fold'].astype(int)))\n",
        "folds_row = train_b['breath_id'].astype(int).map(b2f).to_numpy()\n",
        "n_folds = int(folds_df['fold'].max()) + 1\n",
        "\n",
        "raw_mae = mean_absolute_error(y[mask], pred_breath[mask])\n",
        "print(f'Step 0 | OOF masked MAE (raw): {raw_mae:.6f}', flush=True)\n",
        "\n",
        "B = train_b['breath_id'].nunique()\n",
        "T = int(train_b['t_idx'].max()) + 1\n",
        "assert B*T == len(train_b), 'Breath-order rows not contiguous; cannot reshape'\n",
        "\n",
        "def snap_to_grid(arr, grid):\n",
        "    idx = np.searchsorted(grid, arr)\n",
        "    idx0 = np.clip(idx-1, 0, grid.size-1); idx1 = np.clip(idx, 0, grid.size-1)\n",
        "    left = grid[idx0]; right = grid[idx1]\n",
        "    return np.where(np.abs(arr-left) <= np.abs(arr-right), left, right).astype(np.float32)\n",
        "\n",
        "def median_insp_segments(vals: np.ndarray, m: np.ndarray, k: int = 3) -> np.ndarray:\n",
        "    out = vals.copy()\n",
        "    n = len(vals); i = 0\n",
        "    while i < n:\n",
        "        if not m[i]:\n",
        "            i += 1; continue\n",
        "        j = i\n",
        "        while j < n and m[j]:\n",
        "            j += 1\n",
        "        seg = vals[i:j]\n",
        "        if seg.size >= 3 and k == 3:\n",
        "            seg_ext = np.pad(seg, (1,1), mode='edge')\n",
        "            med = np.median(np.stack([seg_ext[:-2], seg_ext[1:-1], seg_ext[2:]], axis=0), axis=0)\n",
        "            out[i:j] = med.astype(np.float32)\n",
        "        else:\n",
        "            out[i:j] = seg.astype(np.float32)\n",
        "        i = j\n",
        "    return out\n",
        "\n",
        "# Step 1: per-fold RC snap only\n",
        "pp1 = pred_breath.copy()\n",
        "t_start = time.time()\n",
        "for k in range(n_folds):\n",
        "    tr_rows = (folds_row != k); va_rows = (folds_row == k)\n",
        "    if not va_rows.any():\n",
        "        continue\n",
        "    df_tr = pd.DataFrame({'y': y[tr_rows], 'rc': rc_key[tr_rows]})\n",
        "    rc_grids = {int(rc): np.unique(grp['y'].values.astype(np.float32)) for rc, grp in df_tr.groupby('rc')}\n",
        "    va_breaths = np.unique(train_b.loc[va_rows, 'breath_id'].to_numpy())\n",
        "    # build breath start map\n",
        "    first_rows = train_b.groupby('breath_id', sort=False).head(1)\n",
        "    bid_to_start = dict(zip(first_rows['breath_id'].to_numpy(), first_rows.index.to_numpy()))\n",
        "    for bid in va_breaths:\n",
        "        s = bid_to_start[int(bid)]; e = s + T\n",
        "        rc = int(rc_key[s])\n",
        "        grid = rc_grids.get(rc, None)\n",
        "        if grid is None or grid.size == 0:\n",
        "            grid = np.unique(y[tr_rows].astype(np.float32))\n",
        "        pp1[s:e] = snap_to_grid(pp1[s:e], grid)\n",
        "print(f'Step 1 done in {time.time()-t_start:.1f}s', flush=True)\n",
        "mae1 = mean_absolute_error(y[mask], pp1[mask])\n",
        "print(f'Step 1 | OOF masked MAE (RC snap only): {mae1:.6f}', flush=True)\n",
        "\n",
        "# Step 2: RC snap + median(3) within inspiration segments\n",
        "pp2 = pp1.copy()\n",
        "t_start = time.time()\n",
        "first_rows = train_b.groupby('breath_id', sort=False).head(1)\n",
        "bid_to_start = dict(zip(first_rows['breath_id'].to_numpy(), first_rows.index.to_numpy()))\n",
        "for bid in np.unique(train_b['breath_id'].to_numpy()):\n",
        "    s = bid_to_start[int(bid)]; e = s + T\n",
        "    mb = mask[s:e]\n",
        "    pp2[s:e] = median_insp_segments(pp2[s:e], mb, k=3)\n",
        "print(f'Step 2 done in {time.time()-t_start:.1f}s', flush=True)\n",
        "mae2 = mean_absolute_error(y[mask], pp2[mask])\n",
        "print(f'Step 2 | OOF masked MAE (RC snap + median3-insp): {mae2:.6f}', flush=True)\n",
        "\n",
        "# Step 3: add RC\u00d7t de-bias (train-fold med residual) + RC snap + median3-insp\n",
        "pp3 = pred_breath.copy()\n",
        "t_start = time.time()\n",
        "first_rows = train_b.groupby('breath_id', sort=False).head(1)\n",
        "bid_to_start = dict(zip(first_rows['breath_id'].to_numpy(), first_rows.index.to_numpy()))\n",
        "for k in range(n_folds):\n",
        "    tr_rows = (folds_row != k); va_rows = (folds_row == k)\n",
        "    if not va_rows.any():\n",
        "        continue\n",
        "    resid = (y - pred_breath).astype(np.float32)\n",
        "    m_tr = tr_rows & mask\n",
        "    df_res = pd.DataFrame({'rc': rc_key[m_tr], 't': t_idx[m_tr], 'resid': resid[m_tr]})\n",
        "    delta_tbl = df_res.groupby(['rc','t'])['resid'].median().astype(np.float32)\n",
        "    df_tr = pd.DataFrame({'y': y[tr_rows], 'rc': rc_key[tr_rows]})\n",
        "    rc_grids = {int(rc): np.unique(grp['y'].values.astype(np.float32)) for rc, grp in df_tr.groupby('rc')}\n",
        "    for bid in np.unique(train_b.loc[va_rows, 'breath_id'].to_numpy()):\n",
        "        s = bid_to_start[int(bid)]; e = s + T\n",
        "        rc = int(rc_key[s])\n",
        "        # de-bias\n",
        "        keys = pd.MultiIndex.from_product([[rc], np.arange(T)], names=['rc','t'])\n",
        "        dt = delta_tbl.reindex(keys).to_numpy() if not delta_tbl.empty else None\n",
        "        vals = pp3[s:e].copy()\n",
        "        if dt is not None:\n",
        "            dt = np.where(np.isnan(dt), 0.0, dt).astype(np.float32)\n",
        "            vals = vals + dt\n",
        "        # snap\n",
        "        grid = rc_grids.get(rc, None)\n",
        "        if grid is None or grid.size == 0:\n",
        "            grid = np.unique(y[tr_rows].astype(np.float32))\n",
        "        vals = snap_to_grid(vals, grid)\n",
        "        # median within insp\n",
        "        vals = median_insp_segments(vals, mask[s:e], k=3)\n",
        "        pp3[s:e] = vals.astype(np.float32)\n",
        "print(f'Step 3 done in {time.time()-t_start:.1f}s', flush=True)\n",
        "mae3 = mean_absolute_error(y[mask], pp3[mask])\n",
        "print(f'Step 3 | OOF masked MAE (de-bias + RC snap + median3-insp): {mae3:.6f}', flush=True)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Stepwise OOF PP diagnostics: RC fold-safe snap -> +median(3) -> +RC\u00d7t de-bias ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using OOF file: oof_xgb.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0 | OOF masked MAE (raw): 0.301180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 done in 2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1 | OOF masked MAE (RC snap only): 0.300484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 2 done in 3.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 2 | OOF masked MAE (RC snap + median3-insp): 0.489931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 3 done in 47.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 3 | OOF masked MAE (de-bias + RC snap + median3-insp): 0.489980\n"
          ]
        }
      ]
    },
    {
      "id": "9212a251-09ca-49f8-b943-98c6d0b0d099",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd, time\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== Blend XGB(3-seed MAE-avg) + CatBoost t-bucket on raw OOF; then test-time PP: de-bias -> RC snap -> median(3) ===', flush=True)\n",
        "\n",
        "tr_path = Path('train_fe_v3.parquet')\n",
        "te_path = Path('test_fe_v3.parquet')\n",
        "oof_xgb_path = Path('oof_xgb_mae_avg.npy')\n",
        "oof_cat_path = Path('oof_cat_bucket.npy')\n",
        "sub_xgb_path = Path('submission_xgb_mae_avg.csv')\n",
        "sub_cat_path = Path('submission_cat_bucket.csv')\n",
        "assert tr_path.exists() and te_path.exists() and oof_xgb_path.exists() and oof_cat_path.exists() and sub_xgb_path.exists() and sub_cat_path.exists(), 'Missing artifacts for blend'\n",
        "\n",
        "# Load FE and align\n",
        "train_id = pd.read_parquet(tr_path).sort_values('id').reset_index(drop=True)\n",
        "train_b  = pd.read_parquet(tr_path).sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "test_id  = pd.read_parquet(te_path).sort_values('id').reset_index(drop=True)\n",
        "test_b   = pd.read_parquet(te_path).sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "\n",
        "# Load OOF preds (id-order) and map to breath-order\n",
        "oof_xgb_id = np.load(oof_xgb_path).astype(np.float32)\n",
        "oof_cat_id = np.load(oof_cat_path).astype(np.float32)\n",
        "assert len(oof_xgb_id) == len(train_id) == len(oof_cat_id), 'OOF length mismatch vs train rows'\n",
        "id_to_pos = dict(zip(train_id['id'].to_numpy(), np.arange(len(train_id), dtype=np.int64)))\n",
        "idx_breath_order = np.array([id_to_pos[i] for i in train_b['id'].to_numpy()], dtype=np.int64)\n",
        "oof_xgb = oof_xgb_id[idx_breath_order].astype(np.float32)\n",
        "oof_cat = oof_cat_id[idx_breath_order].astype(np.float32)\n",
        "\n",
        "y = train_b['pressure'].to_numpy(np.float32)\n",
        "mask = (train_b['u_out'].to_numpy()==0)\n",
        "\n",
        "# Grid-search blend weight on raw OOF\n",
        "ws = np.linspace(0.0, 1.0, 21)\n",
        "best_w = 0.0; best_mae = 1e9\n",
        "for w in ws:\n",
        "    pred = (1.0-w)*oof_xgb + w*oof_cat\n",
        "    mae = mean_absolute_error(y[mask], pred[mask])\n",
        "    if mae < best_mae:\n",
        "        best_mae, best_w = float(mae), float(w)\n",
        "print(f'Best raw OOF blend weight w_cat={best_w:.2f} (w_xgb={1.0-best_w:.2f}) -> MAE={best_mae:.6f}', flush=True)\n",
        "\n",
        "# Build blended OOF (breath-order) and residual table for de-bias\n",
        "oof_blend = (1.0-best_w)*oof_xgb + best_w*oof_cat\n",
        "t_idx = train_b['t_idx'].to_numpy(np.int16)\n",
        "rc_key_tr = (train_b['R'].astype(np.int32)*100 + train_b['C'].astype(np.int32)).to_numpy()\n",
        "resid = (y - oof_blend).astype(np.float32)\n",
        "df_res = pd.DataFrame({'rc': rc_key_tr[mask], 't': t_idx[mask], 'resid': resid[mask]})\n",
        "delta_tbl = df_res.groupby(['rc','t'])['resid'].median().astype(np.float32)\n",
        "print('Delta table size:', delta_tbl.size, flush=True)\n",
        "\n",
        "# Load test submissions and blend in id-order, then map to breath-order for PP\n",
        "sub_xgb = pd.read_csv(sub_xgb_path).sort_values('id').reset_index(drop=True)\n",
        "sub_cat = pd.read_csv(sub_cat_path).sort_values('id').reset_index(drop=True)\n",
        "assert (sub_xgb['id'].values == test_id['id'].values).all() and (sub_cat['id'].values == test_id['id'].values).all(), 'Submission id mismatch'\n",
        "pred_xgb_id = sub_xgb['pressure'].to_numpy(np.float32)\n",
        "pred_cat_id = sub_cat['pressure'].to_numpy(np.float32)\n",
        "pred_blend_id = (1.0-best_w)*pred_xgb_id + best_w*pred_cat_id\n",
        "\n",
        "# Map blended test preds to breath-order\n",
        "id_to_pos_te = dict(zip(test_id['id'].to_numpy(), np.arange(len(test_id), dtype=np.int64)))\n",
        "idx_test_breath_order = np.array([id_to_pos_te[i] for i in test_b['id'].to_numpy()], dtype=np.int64)\n",
        "test_vals_breath = pred_blend_id[idx_test_breath_order].astype(np.float32)\n",
        "\n",
        "# Build per-(R,C) train pressure grids\n",
        "grid_all = np.unique(train_b['pressure'].values.astype(np.float32)); grid_all.sort()\n",
        "rc_train = (train_b['R'].astype(np.int32)*100 + train_b['C'].astype(np.int32)).to_numpy()\n",
        "rc_press = {}\n",
        "tmp_df = pd.DataFrame({'rc': rc_train, 'p': train_b['pressure'].values.astype(np.float32)})\n",
        "for rc, grp in tmp_df.groupby('rc'):\n",
        "    g = np.unique(grp['p'].values); g.sort(); rc_press[int(rc)] = g\n",
        "\n",
        "def snap_to_grid(arr, grid):\n",
        "    idx = np.searchsorted(grid, arr)\n",
        "    idx0 = np.clip(idx-1, 0, grid.size-1); idx1 = np.clip(idx, 0, grid.size-1)\n",
        "    left = grid[idx0]; right = grid[idx1]\n",
        "    return np.where(np.abs(arr-left) <= np.abs(arr-right), left, right).astype(np.float32)\n",
        "\n",
        "def median_insp_segments(vals: np.ndarray, m: np.ndarray, k: int = 3) -> np.ndarray:\n",
        "    out = vals.copy()\n",
        "    n = len(vals); i = 0\n",
        "    while i < n:\n",
        "        if not m[i]:\n",
        "            i += 1; continue\n",
        "        j = i\n",
        "        while j < n and m[j]:\n",
        "            j += 1\n",
        "        seg = vals[i:j]\n",
        "        if seg.size >= 3 and k == 3:\n",
        "            seg_ext = np.pad(seg, (1,1), mode='edge')\n",
        "            med = np.median(np.stack([seg_ext[:-2], seg_ext[1:-1], seg_ext[2:]], axis=0), axis=0)\n",
        "            out[i:j] = med.astype(np.float32)\n",
        "        else:\n",
        "            out[i:j] = seg.astype(np.float32)\n",
        "        i = j\n",
        "    return out\n",
        "\n",
        "# Apply test-time PP: de-bias -> RC snap -> median(3) within inspiration segments\n",
        "t0 = time.time()\n",
        "out_vals = np.zeros_like(test_vals_breath, dtype=np.float32)\n",
        "start = 0\n",
        "T = int(test_b['t_idx'].max()) + 1\n",
        "for bid, g in test_b.groupby('breath_id', sort=False):\n",
        "    g = g.sort_values('t_idx')\n",
        "    L = len(g)\n",
        "    vals = test_vals_breath[start:start+L].copy()\n",
        "    rc = int(g['R'].iloc[0])*100 + int(g['C'].iloc[0])\n",
        "    tt = g['t_idx'].to_numpy(np.int16)\n",
        "    # de-bias\n",
        "    keys = pd.MultiIndex.from_arrays([np.full(L, rc, dtype=np.int32), tt], names=['rc','t'])\n",
        "    delta = delta_tbl.reindex(keys).to_numpy()\n",
        "    delta = np.where(np.isnan(delta), 0.0, delta).astype(np.float32)\n",
        "    vals = vals + delta\n",
        "    # snap\n",
        "    grid = rc_press.get(rc, grid_all)\n",
        "    vals = snap_to_grid(vals, grid)\n",
        "    # median only on inspiration\n",
        "    m = (g['u_out'].to_numpy()==0)\n",
        "    vals = median_insp_segments(vals, m, k=3)\n",
        "    out_vals[start:start+L] = vals.astype(np.float32)\n",
        "    start += L\n",
        "\n",
        "# Map back to id-order and save\n",
        "out_df_breath = pd.DataFrame({'id': test_b['id'].to_numpy(), 'pressure': out_vals})\n",
        "sub_out = out_df_breath.sort_values('id').reset_index(drop=True)\n",
        "sub_out.to_csv('submission.csv', index=False)\n",
        "print(f'Saved submission.csv (blend w_cat={best_w:.2f}) with test-time PP. Elapsed {round(time.time()-t0,1)}s', flush=True)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Blend XGB(3-seed MAE-avg) + CatBoost t-bucket on raw OOF; then test-time PP: de-bias -> RC snap -> median(3) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best raw OOF blend weight w_cat=0.00 (w_xgb=1.00) -> MAE=0.363891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Delta table size: 288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (blend w_cat=0.00) with test-time PP. Elapsed 5.1s\n"
          ]
        }
      ]
    },
    {
      "id": "6659b994-11d4-4644-ac7c-d04121ee17be",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd, os\n",
        "from pathlib import Path\n",
        "print('=== Reset submission.csv from best available prior artifact ===', flush=True)\n",
        "candidates = ['submission_blend.csv', 'submission_xgb_mae_avg.csv', 'submission_xgb_s42.csv']\n",
        "src = None\n",
        "for c in candidates:\n",
        "    if Path(c).exists():\n",
        "        src = c; break\n",
        "assert src is not None, 'No candidate submission file found'\n",
        "sub = pd.read_csv(src).sort_values('id').reset_index(drop=True)\n",
        "assert {'id','pressure'}.issubset(sub.columns), f'Bad columns in {src}'\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print(f'Wrote submission.csv from {src} (rows={len(sub)})', flush=True)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Reset submission.csv from best available prior artifact ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv from submission_blend.csv (rows=603600)\n"
          ]
        }
      ]
    },
    {
      "id": "eb8bef18-84c3-422a-9613-cb30cb759301",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd, time, gc, os\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== Fast recovery: per-timestep XGB (squarederror) with single holdout fold and RC snap-only ===', flush=True)\n",
        "\n",
        "import xgboost as xgb\n",
        "tr_path, te_path = Path('train_fe_v3.parquet'), Path('test_fe_v3.parquet')\n",
        "assert tr_path.exists() and te_path.exists(), 'Run FE v3 cell first'\n",
        "train = pd.read_parquet(tr_path)\n",
        "test  = pd.read_parquet(te_path)\n",
        "\n",
        "# Sort to breath-major for per-t training\n",
        "train_b = train.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "test_b  = test.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "\n",
        "# Features: exclude target/meta and u_out\n",
        "drop_cols = {'pressure','is_train','fold','id'}\n",
        "FEATS = [c for c in train.columns if c not in drop_cols and c in test.columns and c != 'u_out']\n",
        "print('Num features:', len(FEATS), flush=True)\n",
        "\n",
        "# Folds mapping (breath-wise); pick one holdout fold for early stopping (k_holdout)\n",
        "folds_df = pd.read_csv('folds_breath_v3.csv')\n",
        "b2f = dict(zip(folds_df['breath_id'].astype(int), folds_df['fold'].astype(int)))\n",
        "folds_b = train_b['breath_id'].astype(int).map(b2f).astype(np.int8).to_numpy()\n",
        "assert not np.isnan(folds_b).any(), 'Missing folds for some breaths'\n",
        "n_folds = int(folds_df['fold'].max()) + 1\n",
        "k_holdout = 0\n",
        "print('Using holdout fold:', k_holdout, flush=True)\n",
        "\n",
        "# Targets and mask\n",
        "y_b = train_b['pressure'].to_numpy(np.float32)\n",
        "mask_b = (train_b['u_out'].to_numpy()==0)\n",
        "t_idx_b = train_b['t_idx'].astype(np.int16).to_numpy()\n",
        "\n",
        "T = int(train_b['t_idx'].max()) + 1\n",
        "B = train_b['breath_id'].nunique()\n",
        "print('Timesteps:', T, 'Breaths:', B, flush=True)\n",
        "\n",
        "# Prepare OOF (holdout only, for monitoring) and test preds\n",
        "oof = np.zeros(train_b.shape[0], dtype=np.float32)\n",
        "test_pred_all = np.zeros(test_b.shape[0], dtype=np.float32)\n",
        "\n",
        "# Fast-recovery params (expert-guided)\n",
        "params = {\n",
        "    'tree_method': 'hist',\n",
        "    'device': 'cuda',\n",
        "    'max_depth': 7,\n",
        "    'min_child_weight': 32,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'lambda': 12.0,\n",
        "    'alpha': 1.0,\n",
        "    'eta': 0.10,\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'mae',\n",
        "    'nthread': max(1, os.cpu_count()-2)\n",
        "}\n",
        "num_round = 400\n",
        "early = 50\n",
        "\n",
        "t0 = time.time()\n",
        "t_vec_test = test_b['t_idx'].to_numpy()\n",
        "for t in range(T):\n",
        "    idx_t_all = (t_idx_b == t)\n",
        "    idx_fit = idx_t_all & mask_b\n",
        "    if idx_fit.sum() == 0:\n",
        "        continue\n",
        "    X_t = train_b.loc[idx_fit, FEATS].to_numpy(np.float32, copy=False)\n",
        "    y_t = y_b[idx_fit]\n",
        "    f_t = folds_b[idx_fit]\n",
        "    # Train/Val split by breath fold\n",
        "    m_tr = (f_t != k_holdout)\n",
        "    m_va = (f_t == k_holdout)\n",
        "    if m_tr.sum() == 0 or m_va.sum() == 0:\n",
        "        # fallback: simple split 90/10\n",
        "        n = X_t.shape[0]\n",
        "        cut = int(n*0.9)\n",
        "        m_tr = np.zeros(n, dtype=bool); m_tr[:cut] = True\n",
        "        m_va = ~m_tr\n",
        "    dtr = xgb.DMatrix(X_t[m_tr], label=y_t[m_tr])\n",
        "    dva = xgb.DMatrix(X_t[m_va], label=y_t[m_va])\n",
        "    watch = [(dtr,'tr'),(dva,'va')]\n",
        "    bst = xgb.train(params, dtr, num_boost_round=num_round, evals=watch, early_stopping_rounds=early, verbose_eval=False)\n",
        "    attrs = bst.attributes()\n",
        "    best_it = int(attrs.get('best_iteration', '0'))\n",
        "    iter_range = (0, best_it + 1) if best_it > 0 else None\n",
        "    # Map holdout preds back to full positions of timestep t\n",
        "    pos_all_t = np.where(idx_t_all)[0]\n",
        "    pos_fit_t = np.where(idx_fit)[0]\n",
        "    pos_va_fit = pos_fit_t[m_va]\n",
        "    fold_pred_val = np.zeros(idx_t_all.sum(), dtype=np.float32)\n",
        "    pred_va = bst.predict(dva, iteration_range=iter_range).astype(np.float32)\n",
        "    fold_pred_val_indices = np.searchsorted(pos_all_t, pos_va_fit)\n",
        "    fold_pred_val[fold_pred_val_indices] = pred_va\n",
        "    oof[idx_t_all] = fold_pred_val\n",
        "    # Test slice for this t\n",
        "    mt = (t_vec_test == t)\n",
        "    if mt.any():\n",
        "        X_te_t = test_b.loc[mt, FEATS].to_numpy(np.float32, copy=False)\n",
        "        dte = xgb.DMatrix(X_te_t)\n",
        "        test_pred_all[mt] = bst.predict(dte, iteration_range=iter_range).astype(np.float32)\n",
        "    if (t+1) % 10 == 0 or t < 3:\n",
        "        m_slice = mask_b & (t_idx_b == t)\n",
        "        mae_t = mean_absolute_error(y_b[m_slice], oof[m_slice]) if m_slice.any() else np.nan\n",
        "        print(f't={t:02d} | fit_rows={int(idx_fit.sum())} | holdout MAE_masked={mae_t:.4f} | elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    gc.collect()\n",
        "\n",
        "# Holdout OOF masked MAE (for monitoring only)\n",
        "mae_holdout = mean_absolute_error(y_b[mask_b & (folds_b==k_holdout)], oof[mask_b & (folds_b==k_holdout)])\n",
        "print(f'Holdout fold {k_holdout} masked MAE: {mae_holdout:.6f}', flush=True)\n",
        "\n",
        "# Save raw test preds (id-order)\n",
        "test_b_pred = test_b[['id']].copy(); test_b_pred['pressure'] = test_pred_all.astype(np.float32)\n",
        "sub_raw = test_b_pred.sort_values('id').reset_index(drop=True)\n",
        "sub_raw.to_csv('submission_raw_xgb_fast.csv', index=False)\n",
        "print('Saved submission_raw_xgb_fast.csv (raw, no PP)', flush=True)\n",
        "\n",
        "# Build per-(R,C) pressure grids from full train for snap-only\n",
        "grid_all = np.unique(train_b['pressure'].values.astype(np.float32)); grid_all.sort()\n",
        "rc_train = (train_b['R'].astype(np.int32)*100 + train_b['C'].astype(np.int32)).to_numpy()\n",
        "rc_press = {}\n",
        "tmp_df = pd.DataFrame({'rc': rc_train, 'p': train_b['pressure'].values.astype(np.float32)})\n",
        "for rc, grp in tmp_df.groupby('rc'):\n",
        "    g = np.unique(grp['p'].values); g.sort(); rc_press[int(rc)] = g\n",
        "\n",
        "def snap_to_grid(arr, grid):\n",
        "    idx = np.searchsorted(grid, arr)\n",
        "    idx0 = np.clip(idx-1, 0, grid.size-1); idx1 = np.clip(idx, 0, grid.size-1)\n",
        "    left = grid[idx0]; right = grid[idx1]\n",
        "    return np.where(np.abs(arr-left) <= np.abs(arr-right), left, right).astype(np.float32)\n",
        "\n",
        "# Apply RC snap-only to test preds in breath-order\n",
        "test_id  = test.sort_values('id').reset_index(drop=True)\n",
        "press_id_order = sub_raw['pressure'].to_numpy(np.float32)\n",
        "id_to_pos_te = dict(zip(test_id['id'].to_numpy(), np.arange(len(test_id), dtype=np.int64)))\n",
        "idx_test_breath_order = np.array([id_to_pos_te[i] for i in test_b['id'].to_numpy()], dtype=np.int64)\n",
        "test_vals_breath = press_id_order[idx_test_breath_order].astype(np.float32)\n",
        "\n",
        "out_vals = np.zeros_like(test_vals_breath, dtype=np.float32)\n",
        "start = 0\n",
        "T = int(test_b['t_idx'].max()) + 1\n",
        "t1 = time.time()\n",
        "for bid, g in test_b.groupby('breath_id', sort=False):\n",
        "    g = g.sort_values('t_idx')\n",
        "    L = len(g)\n",
        "    vals = test_vals_breath[start:start+L].copy()\n",
        "    rc = int(g['R'].iloc[0])*100 + int(g['C'].iloc[0])\n",
        "    grid = rc_press.get(rc, grid_all)\n",
        "    vals = snap_to_grid(vals, grid)\n",
        "    out_vals[start:start+L] = vals.astype(np.float32)\n",
        "    start += L\n",
        "print('Snap-only done in', round(time.time()-t1,1), 's', flush=True)\n",
        "\n",
        "# Map back to id-order and save final submission (snap-only)\n",
        "out_df_breath = pd.DataFrame({'id': test_b['id'].to_numpy(), 'pressure': out_vals})\n",
        "sub_out = out_df_breath.sort_values('id').reset_index(drop=True)\n",
        "sub_out.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (RC snap-only applied to raw fast XGB preds).', flush=True)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Fast recovery: per-timestep XGB (squarederror) with single holdout fold and RC snap-only ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num features: 58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using holdout fold: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timesteps: 80 Breaths: 67905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t=00 | fit_rows=67905 | holdout MAE_masked=4.6953 | elapsed=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t=01 | fit_rows=67905 | holdout MAE_masked=5.3090 | elapsed=4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t=02 | fit_rows=67905 | holdout MAE_masked=7.3975 | elapsed=6.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t=09 | fit_rows=67905 | holdout MAE_masked=13.6506 | elapsed=20.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t=19 | fit_rows=67905 | holdout MAE_masked=16.2944 | elapsed=40.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t=29 | fit_rows=47285 | holdout MAE_masked=17.8744 | elapsed=59.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Holdout fold 0 masked MAE: 0.353893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_raw_xgb_fast.csv (raw, no PP)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Snap-only done in 1.1 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (RC snap-only applied to raw fast XGB preds).\n"
          ]
        }
      ]
    },
    {
      "id": "d5b22b4e-3850-4d5e-8f29-0e3bddf82a49",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np, pandas as pd, time, gc, os, sys, subprocess\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "print('=== Per-t LightGBM (CPU, MAE) fast run with holdout; blend with fast XGB; RC snap-only ===', flush=True)\n",
        "\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "except Exception:\n",
        "    print('Installing lightgbm...', flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'lightgbm==4.6.0'], check=True)\n",
        "    import lightgbm as lgb\n",
        "\n",
        "tr_path, te_path = Path('train_fe_v3.parquet'), Path('test_fe_v3.parquet')\n",
        "assert tr_path.exists() and te_path.exists(), 'Run FE v3 cell first'\n",
        "train = pd.read_parquet(tr_path)\n",
        "test  = pd.read_parquet(te_path)\n",
        "\n",
        "# Sort breath-major\n",
        "train_b = train.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "test_b  = test.sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "\n",
        "# Features: exclude target/meta and u_out\n",
        "drop_cols = {'pressure','is_train','fold','id'}\n",
        "FEATS = [c for c in train.columns if c not in drop_cols and c in test.columns and c != 'u_out']\n",
        "print('Num features:', len(FEATS), flush=True)\n",
        "\n",
        "# Folds mapping (breath-wise) and holdout fold\n",
        "folds_df = pd.read_csv('folds_breath_v3.csv')\n",
        "b2f = dict(zip(folds_df['breath_id'].astype(int), folds_df['fold'].astype(int)))\n",
        "folds_b = train_b['breath_id'].astype(int).map(b2f).astype(np.int8).to_numpy()\n",
        "assert not np.isnan(folds_b).any(), 'Missing folds for some breaths'\n",
        "k_holdout = 0\n",
        "print('Using holdout fold:', k_holdout, flush=True)\n",
        "\n",
        "# Targets and mask\n",
        "y_b = train_b['pressure'].to_numpy(np.float32)\n",
        "mask_b = (train_b['u_out'].to_numpy()==0)\n",
        "t_idx_b = train_b['t_idx'].astype(np.int16).to_numpy()\n",
        "\n",
        "T = int(train_b['t_idx'].max()) + 1\n",
        "B = train_b['breath_id'].nunique()\n",
        "print('Timesteps:', T, 'Breaths:', B, flush=True)\n",
        "\n",
        "# Containers\n",
        "oof_lgb = np.zeros(train_b.shape[0], dtype=np.float32)  # only holdout positions will be non-zero\n",
        "test_pred_all_lgb = np.zeros(test_b.shape[0], dtype=np.float32)\n",
        "\n",
        "# LGB params (expert-suggested fast settings)\n",
        "lgb_params = {\n",
        "  'objective': 'regression_l1',\n",
        "  'metric': 'mae',\n",
        "  'learning_rate': 0.05,\n",
        "  'num_leaves': 127,\n",
        "  'min_child_samples': 20,\n",
        "  'feature_fraction': 0.8,\n",
        "  'bagging_fraction': 0.8,\n",
        "  'bagging_freq': 1,\n",
        "  'lambda_l1': 1.0,\n",
        "  'lambda_l2': 5.0,\n",
        "  'num_threads': os.cpu_count() or 8,\n",
        "  'force_row_wise': True,\n",
        "  'deterministic': True,\n",
        "  'seed': 42,\n",
        "  'verbosity': -1\n",
        "}\n",
        "num_boost_round = 800\n",
        "early_stopping_rounds = 80\n",
        "\n",
        "t0 = time.time()\n",
        "t_vec_test = test_b['t_idx'].to_numpy()\n",
        "for t in range(T):\n",
        "    idx_t_all = (t_idx_b == t)\n",
        "    idx_fit = idx_t_all & mask_b\n",
        "    if idx_fit.sum() == 0:\n",
        "        continue\n",
        "    X_t = train_b.loc[idx_fit, FEATS].to_numpy(np.float32, copy=False)\n",
        "    y_t = y_b[idx_fit]\n",
        "    f_t = folds_b[idx_fit]\n",
        "    m_tr = (f_t != k_holdout)\n",
        "    m_va = (f_t == k_holdout)\n",
        "    if m_tr.sum() == 0 or m_va.sum() == 0:\n",
        "        n = X_t.shape[0]\n",
        "        cut = int(n*0.9)\n",
        "        m_tr = np.zeros(n, dtype=bool); m_tr[:cut] = True\n",
        "        m_va = ~m_tr\n",
        "    dtr = lgb.Dataset(X_t[m_tr], label=y_t[m_tr])\n",
        "    dva = lgb.Dataset(X_t[m_va], label=y_t[m_va], reference=dtr)\n",
        "    callbacks = [lgb.early_stopping(stopping_rounds=early_stopping_rounds, verbose=False)]\n",
        "    booster = lgb.train(lgb_params, dtr, num_boost_round=num_boost_round, valid_sets=[dtr, dva], valid_names=['tr','va'], callbacks=callbacks)\n",
        "    # Map holdout preds back to full positions of timestep t\n",
        "    pos_all_t = np.where(idx_t_all)[0]\n",
        "    pos_fit_t = np.where(idx_fit)[0]\n",
        "    pos_va_fit = pos_fit_t[m_va]\n",
        "    fold_pred_val = np.zeros(idx_t_all.sum(), dtype=np.float32)\n",
        "    best_iter = getattr(booster, 'best_iteration', None)\n",
        "    if best_iter is None or best_iter <= 0:\n",
        "        best_iter = booster.num_trees()\n",
        "    pred_va = booster.predict(X_t[m_va], num_iteration=best_iter).astype(np.float32)\n",
        "    fold_pred_val_indices = np.searchsorted(pos_all_t, pos_va_fit)\n",
        "    fold_pred_val[fold_pred_val_indices] = pred_va\n",
        "    oof_lgb[idx_t_all] = fold_pred_val\n",
        "    # Test slice for this t\n",
        "    mt = (t_vec_test == t)\n",
        "    if mt.any():\n",
        "        X_te_t = test_b.loc[mt, FEATS].to_numpy(np.float32, copy=False)\n",
        "        test_pred_all_lgb[mt] = booster.predict(X_te_t, num_iteration=best_iter).astype(np.float32)\n",
        "    if (t+1) % 10 == 0 or t < 3:\n",
        "        m_slice = mask_b & (t_idx_b == t) & (folds_b == k_holdout)\n",
        "        mae_t = mean_absolute_error(y_b[m_slice], oof_lgb[m_slice]) if m_slice.any() else np.nan\n",
        "        print(f'LGB t={t:02d} | fit_rows={int(idx_fit.sum())} | holdout MAE_masked={mae_t:.4f} | elapsed={time.time()-t0:.1f}s', flush=True)\n",
        "    gc.collect()\n",
        "\n",
        "# Holdout masked MAE for monitoring\n",
        "mae_hold = mean_absolute_error(y_b[mask_b & (folds_b==k_holdout)], oof_lgb[mask_b & (folds_b==k_holdout)])\n",
        "print(f'LGB Holdout fold {k_holdout} masked MAE: {mae_hold:.6f}', flush=True)\n",
        "\n",
        "# Save raw LGB test preds (id-order)\n",
        "sub_lgb_raw = test_b[['id']].copy(); sub_lgb_raw['pressure'] = test_pred_all_lgb.astype(np.float32)\n",
        "sub_lgb_raw = sub_lgb_raw.sort_values('id').reset_index(drop=True)\n",
        "sub_lgb_raw.to_csv('submission_lgb_raw.csv', index=False)\n",
        "print('Saved submission_lgb_raw.csv (raw, no PP)', flush=True)\n",
        "\n",
        "# Blend with fast XGB raw preds (heuristic weight if no tuning):\n",
        "xgb_raw_path = Path('submission_raw_xgb_fast.csv')\n",
        "assert xgb_raw_path.exists(), 'submission_raw_xgb_fast.csv not found (run fast XGB cell first)'\n",
        "sub_xgb_raw = pd.read_csv(xgb_raw_path).sort_values('id').reset_index(drop=True)\n",
        "assert (sub_xgb_raw['id'].values == sub_lgb_raw['id'].values).all(), 'ID mismatch between XGB and LGB raw submissions'\n",
        "w_lgb = 0.30  # heuristic (cap <= 0.5)\n",
        "blend_raw = sub_xgb_raw[['id']].copy()\n",
        "blend_raw['pressure'] = ((1.0 - w_lgb) * sub_xgb_raw['pressure'].astype(np.float32) + w_lgb * sub_lgb_raw['pressure'].astype(np.float32)).astype(np.float32)\n",
        "blend_raw.to_csv('submission_raw_xgb_lgb_blend.csv', index=False)\n",
        "print(f'Saved submission_raw_xgb_lgb_blend.csv (w_lgb={w_lgb:.2f})', flush=True)\n",
        "\n",
        "# RC snap-only on blended preds\n",
        "test_id  = test.sort_values('id').reset_index(drop=True)\n",
        "press_id_order = blend_raw['pressure'].to_numpy(np.float32)\n",
        "id_to_pos_te = dict(zip(test_id['id'].to_numpy(), np.arange(len(test_id), dtype=np.int64)))\n",
        "idx_test_breath_order = np.array([id_to_pos_te[i] for i in test_b['id'].to_numpy()], dtype=np.int64)\n",
        "test_vals_breath = press_id_order[idx_test_breath_order].astype(np.float32)\n",
        "\n",
        "# Build per-(R,C) grids from full train\n",
        "grid_all = np.unique(train_b['pressure'].values.astype(np.float32)); grid_all.sort()\n",
        "rc_train = (train_b['R'].astype(np.int32)*100 + train_b['C'].astype(np.int32)).to_numpy()\n",
        "rc_press = {}\n",
        "tmp_df = pd.DataFrame({'rc': rc_train, 'p': train_b['pressure'].values.astype(np.float32)})\n",
        "for rc, grp in tmp_df.groupby('rc'):\n",
        "    g = np.unique(grp['p'].values); g.sort(); rc_press[int(rc)] = g\n",
        "\n",
        "def snap_to_grid(arr, grid):\n",
        "    idx = np.searchsorted(grid, arr)\n",
        "    idx0 = np.clip(idx-1, 0, grid.size-1); idx1 = np.clip(idx, 0, grid.size-1)\n",
        "    left = grid[idx0]; right = grid[idx1]\n",
        "    return np.where(np.abs(arr-left) <= np.abs(arr-right), left, right).astype(np.float32)\n",
        "\n",
        "out_vals = np.zeros_like(test_vals_breath, dtype=np.float32)\n",
        "start = 0\n",
        "t1 = time.time()\n",
        "for bid, g in test_b.groupby('breath_id', sort=False):\n",
        "    g = g.sort_values('t_idx')\n",
        "    L = len(g)\n",
        "    vals = test_vals_breath[start:start+L].copy()\n",
        "    rc = int(g['R'].iloc[0])*100 + int(g['C'].iloc[0])\n",
        "    grid = rc_press.get(rc, grid_all)\n",
        "    vals = snap_to_grid(vals, grid)\n",
        "    out_vals[start:start+L] = vals.astype(np.float32)\n",
        "    start += L\n",
        "print('Snap-only (blend) done in', round(time.time()-t1,1), 's', flush=True)\n",
        "\n",
        "sub_blend_breath = pd.DataFrame({'id': test_b['id'].to_numpy(), 'pressure': out_vals})\n",
        "sub_blend = sub_blend_breath.sort_values('id').reset_index(drop=True)\n",
        "sub_blend.to_csv('submission_blend_xgb_lgb_snap.csv', index=False)\n",
        "sub_blend.to_csv('submission.csv', index=False)\n",
        "print('Saved submission_blend_xgb_lgb_snap.csv and updated submission.csv with RC snap-only.', flush=True)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Per-t LightGBM (CPU, MAE) fast run with holdout; blend with fast XGB; RC snap-only ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num features: 58\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using holdout fold: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timesteps: 80 Breaths: 67905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGB t=00 | fit_rows=67905 | holdout MAE_masked=0.2008 | elapsed=17.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGB t=01 | fit_rows=67905 | holdout MAE_masked=0.1885 | elapsed=35.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGB t=02 | fit_rows=67905 | holdout MAE_masked=0.2008 | elapsed=55.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGB t=09 | fit_rows=67905 | holdout MAE_masked=0.3605 | elapsed=202.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGB t=19 | fit_rows=67905 | holdout MAE_masked=0.3533 | elapsed=407.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGB t=29 | fit_rows=47285 | holdout MAE_masked=0.3772 | elapsed=616.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGB Holdout fold 0 masked MAE: 0.334499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_lgb_raw.csv (raw, no PP)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_raw_xgb_lgb_blend.csv (w_lgb=0.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Snap-only (blend) done in 1.1 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_blend_xgb_lgb_snap.csv and updated submission.csv with RC snap-only.\n"
          ]
        }
      ]
    },
    {
      "id": "84485250-0b7f-4731-bb0b-81363d983b89",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "print('=== Postprocess full 5-fold XGB outputs (RC snap-only) when ready ===', flush=True)\n",
        "\n",
        "tr_path = Path('train_fe_v3.parquet')\n",
        "te_path = Path('test_fe_v3.parquet')\n",
        "raw_sub_path = Path('submission_xgb_full.csv')\n",
        "oof_path = Path('oof_xgb_full.npy')\n",
        "\n",
        "if not tr_path.exists() or not te_path.exists():\n",
        "    raise SystemExit('Missing FE parquet files')\n",
        "\n",
        "if not raw_sub_path.exists():\n",
        "    print('submission_xgb_full.csv not found yet. Run this cell after train_xgb_full.py finishes.', flush=True)\n",
        "else:\n",
        "    # Load FE and raw submission\n",
        "    train_b = pd.read_parquet(tr_path).sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "    test_b  = pd.read_parquet(te_path).sort_values(['breath_id','t_idx']).reset_index(drop=True)\n",
        "    test_id = pd.read_parquet(te_path).sort_values('id').reset_index(drop=True)\n",
        "    sub_raw = pd.read_csv(raw_sub_path).sort_values('id').reset_index(drop=True)\n",
        "    assert {'id','pressure'}.issubset(sub_raw.columns), 'Bad columns in submission_xgb_full.csv'\n",
        "    assert len(sub_raw)==len(test_id), 'Row count mismatch vs test'\n",
        "    assert (sub_raw['id'].values == test_id['id'].values).all(), 'ID order mismatch vs test'\n",
        "\n",
        "    # Build per-(R,C) pressure grids from full train\n",
        "    grid_all = np.unique(train_b['pressure'].values.astype(np.float32)); grid_all.sort()\n",
        "    rc_train = (train_b['R'].astype(np.int32)*100 + train_b['C'].astype(np.int32)).to_numpy()\n",
        "    rc_press = {}\n",
        "    tmp_df = pd.DataFrame({'rc': rc_train, 'p': train_b['pressure'].values.astype(np.float32)})\n",
        "    for rc, grp in tmp_df.groupby('rc'):\n",
        "        g = np.unique(grp['p'].values); g.sort(); rc_press[int(rc)] = g\n",
        "\n",
        "    def snap_to_grid(arr, grid):\n",
        "        idx = np.searchsorted(grid, arr)\n",
        "        idx0 = np.clip(idx-1, 0, grid.size-1); idx1 = np.clip(idx, 0, grid.size-1)\n",
        "        left = grid[idx0]; right = grid[idx1]\n",
        "        return np.where(np.abs(arr-left) <= np.abs(arr-right), left, right).astype(np.float32)\n",
        "\n",
        "    # Map raw preds to breath-order\n",
        "    id_to_pos_te = dict(zip(test_id['id'].to_numpy(), np.arange(len(test_id), dtype=np.int64)))\n",
        "    idx_test_breath_order = np.array([id_to_pos_te[i] for i in test_b['id'].to_numpy()], dtype=np.int64)\n",
        "    vals_breath = sub_raw['pressure'].to_numpy(np.float32)[idx_test_breath_order]\n",
        "\n",
        "    out_vals = np.zeros_like(vals_breath, dtype=np.float32)\n",
        "    start = 0\n",
        "    t0 = time.time()\n",
        "    for bid, g in test_b.groupby('breath_id', sort=False):\n",
        "        g = g.sort_values('t_idx')\n",
        "        L = len(g)\n",
        "        v = vals_breath[start:start+L].copy()\n",
        "        rc = int(g['R'].iloc[0])*100 + int(g['C'].iloc[0])\n",
        "        grid = rc_press.get(rc, grid_all)\n",
        "        v = snap_to_grid(v, grid)\n",
        "        out_vals[start:start+L] = v.astype(np.float32)\n",
        "        start += L\n",
        "    print('Snap-only done in', round(time.time()-t0,1), 's', flush=True)\n",
        "\n",
        "    # Map back to id-order and save\n",
        "    sub_snap = pd.DataFrame({'id': test_b['id'].to_numpy(), 'pressure': out_vals}).sort_values('id').reset_index(drop=True)\n",
        "    sub_snap.to_csv('submission_xgb_full_snap.csv', index=False)\n",
        "    sub_snap.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission_xgb_full_snap.csv and updated submission.csv (RC snap-only).', flush=True)\n",
        "\n",
        "    # Optional: if OOF exists, report masked MAE for raw vs snap (fold-safe grids not applied here)\n",
        "    if oof_path.exists():\n",
        "        from sklearn.metrics import mean_absolute_error\n",
        "        train_id = pd.read_parquet(tr_path).sort_values('id').reset_index(drop=True)\n",
        "        oof_id = np.load(oof_path).astype(np.float32)\n",
        "        id_to_pos_tr = dict(zip(train_id['id'].to_numpy(), np.arange(len(train_id), dtype=np.int64)))\n",
        "        idx_breath_tr = np.array([id_to_pos_tr[i] for i in train_b['id'].to_numpy()], dtype=np.int64)\n",
        "        oof_breath = oof_id[idx_breath_tr]\n",
        "        y = train_b['pressure'].to_numpy(np.float32)\n",
        "        mask = (train_b['u_out'].to_numpy()==0)\n",
        "        mae_raw = mean_absolute_error(y[mask], oof_breath[mask])\n",
        "        print(f'OOF masked MAE (full XGB raw): {mae_raw:.6f}', flush=True)\n",
        "    else:\n",
        "        print('oof_xgb_full.npy not found; skipping OOF report.', flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}