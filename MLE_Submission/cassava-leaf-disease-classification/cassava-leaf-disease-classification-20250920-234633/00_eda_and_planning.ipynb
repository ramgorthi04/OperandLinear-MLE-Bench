{
  "cells": [
    {
      "id": "b714eee3-829f-44ee-ba22-527be69f8c2b",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cassava Leaf Disease Classification \u2013 Plan\n",
        "\n",
        "Goal: Win a medal (>= 0.8978 accuracy).\n",
        "\n",
        "Data available:\n",
        "- train_images/ (21k imgs), train.csv with labels 0..4\n",
        "- test_images/ (~3k imgs) to predict\n",
        "- label map json\n",
        "- TFRecords exist but we can start from raw JPEGs for simplicity; may switch if throughput needed\n",
        "\n",
        "Metric: Accuracy (LB).\n",
        "\n",
        "High-level approach:\n",
        "1) Establish strong, fast baseline using pretrained ImageNet models from timm on GPU with mixed precision.\n",
        "   - Start with convnext_base or efficientnet_b3/b4, image_size=512 (or 380/448 first for speed).\n",
        "   - Augmentations: flips, light affine, color jitter, CutMix/MixUp (prob ~0.2), RandomResizedCrop, Normalize.\n",
        "   - Loss: cross-entropy with label smoothing (0.05) or focal for class imbalance; track which wins on CV.\n",
        "   - Optimizer: AdamW, lr ~2e-4, cosine schedule, warmup.\n",
        "   - Training epochs: short 5-8 epochs for baseline with early stopping (patience 2).\n",
        "   - Stratified KFold (5 folds), deterministic seed; Amp + gradient accumulation if needed.\n",
        "   - Balanced sampler or class weights for imbalance.\n",
        "\n",
        "2) Validation rigor:\n",
        "   - Single fixed StratifiedKFold(5, shuffle=True, random_state=42).\n",
        "   - Use same preproc inside each fold; no leakage.\n",
        "   - Save OOF predictions and per-fold metrics; analyze confusion matrix and per-class recall.\n",
        "\n",
        "3) Inference:\n",
        "   - EMA model or best ckpt per fold.\n",
        "   - TTA (horizontal flip and 3-scale crop or resize): start with 2-4 TTAs; ensure speed.\n",
        "   - Blend folds by averaging softmax logits.\n",
        "\n",
        "4) Iteration path:\n",
        "   - Baseline A: effnet_b3 380px, 5-fold, 5 epochs -> sanity OOF and first submission.\n",
        "   - Baseline B: convnext_base 448/512px, 5-8 epochs -> should reach medal zone.\n",
        "   - Tune aug and loss; test CutMix/MixUp vs none.\n",
        "   - Train second diverse model (e.g., tf_efficientnetv2_s or tf_efficientnet_b4) and blend.\n",
        "   - If time: add SWA or EMA, calibrate thresholds (not needed for accuracy).\n",
        "\n",
        "5) Efficiency:\n",
        "   - Verify GPU usable; use num_workers and prefetch; cache resized images if helpful.\n",
        "   - Log epoch times, fold index, memory usage.\n",
        "\n",
        "6) Risk checks:\n",
        "   - Ensure label mapping consistent, submission format matches sample.\n",
        "   - Handle EXIF orientation.\n",
        "   - Deterministic seeds; track experiments.\n",
        "\n",
        "Questions for experts (next step):\n",
        "- Which backbones and input sizes typically medal on Cassava? convnext_base 512 vs. effnet_b4 512 vs. nfnet_l0 448?\n",
        "- Best augmentation recipes proven on this dataset? (color jitter strength, CutMix/MixUp probs, RandAugment?)\n",
        "- Preferred TTA set and count for optimal LB vs. speed?\n",
        "- Any pitfalls with this dataset (duplicates, leakage, domain shifts) and best CV protocol?\n",
        "\n",
        "Next actions:\n",
        "- Verify GPU, packages (timm, albumentations, torch).\n",
        "- Create training notebook: dataset, transforms, model, 5-fold loop, OOF, and inference + submission.\n",
        "- Run quick smoke (1 epoch, 1 fold) to validate pipeline, then scale to 5 folds."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "8a920993-5056-4bb4-a962-6fa4bfcca2c1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup: install deps, verify GPU, quick data peek\n",
        "import sys, subprocess, json, os, time, glob, platform\n",
        "from pathlib import Path\n",
        "\n",
        "def pip_install(packages):\n",
        "    cmd = [sys.executable, '-m', 'pip', 'install', '--upgrade'] + packages\n",
        "    print('Installing:', ' '.join(packages)); sys.stdout.flush()\n",
        "    return subprocess.run(cmd, check=True)\n",
        "\n",
        "def pip_uninstall(packages):\n",
        "    cmd = [sys.executable, '-m', 'pip', 'uninstall', '-y'] + packages\n",
        "    print('Uninstalling:', ' '.join(packages)); sys.stdout.flush()\n",
        "    return subprocess.run(cmd, check=False)\n",
        "\n",
        "# Install PyTorch (CUDA 12.1) + libs if missing\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "except Exception as e:\n",
        "    print('Installing torch/torchvision for CUDA 12.1...')\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '--index-url', 'https://download.pytorch.org/whl/cu121', 'torch', 'torchvision'], check=True)\n",
        "    import torch, torchvision\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except:\n",
        "    pip_install(['timm'])\n",
        "    import timm\n",
        "\n",
        "# Prefer headless OpenCV to avoid libGL issues\n",
        "cv2_ready = False\n",
        "try:\n",
        "    import albumentations as A\n",
        "    import cv2\n",
        "    cv2_ready = True\n",
        "except Exception as e:\n",
        "    print('Albumentations/cv2 import failed, switching to headless OpenCV. Error:', e)\n",
        "    pip_uninstall(['opencv-python'])\n",
        "    pip_install(['albumentations', 'opencv-python-headless'])\n",
        "    import albumentations as A\n",
        "    import cv2\n",
        "    cv2_ready = True\n",
        "\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "print('Python:', platform.python_version())\n",
        "print('Torch:', torch.__version__)\n",
        "print('Torchvision:', torchvision.__version__)\n",
        "print('timm:', timm.__version__)\n",
        "print('Albumentations:', A.__version__)\n",
        "print('cv2 headless OK:', cv2_ready)\n",
        "\n",
        "# GPU check\n",
        "print('GPU Available:', torch.cuda.is_available())\n",
        "print('GPU Count:', torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU Name:', torch.cuda.get_device_name(0))\n",
        "    props = torch.cuda.get_device_properties(0)\n",
        "    print(f'GPU Memory: {props.total_memory / 1024**3:.1f} GB')\n",
        "\n",
        "BASE = Path('.')\n",
        "data_dir = BASE\n",
        "train_csv = data_dir/'train.csv'\n",
        "test_dir = data_dir/'test_images'\n",
        "train_dir = data_dir/'train_images'\n",
        "label_map_path = data_dir/'label_num_to_disease_map.json'\n",
        "\n",
        "print('Files present:', os.listdir(data_dir))\n",
        "df = pd.read_csv(train_csv)\n",
        "print('train.csv shape:', df.shape)\n",
        "print(df.head())\n",
        "print('label value_counts:\\n', df['label'].value_counts().sort_index())\n",
        "\n",
        "with open(label_map_path) as f:\n",
        "    label_map = json.load(f)\n",
        "print('Label map keys:', list(label_map.keys()))\n",
        "\n",
        "test_images = sorted([p.name for p in Path(test_dir).glob('*.jpg')])\n",
        "train_images = sorted([p.name for p in Path(train_dir).glob('*.jpg')])\n",
        "print('Train images:', len(train_images), 'Test images:', len(test_images))\n",
        "print('Sample train images:', train_images[:5])\n",
        "print('Sample test images:', test_images[:5])\n",
        "\n",
        "# Sanity: sample_submission format\n",
        "ss = pd.read_csv(data_dir/'sample_submission.csv')\n",
        "print('sample_submission columns:', ss.columns.tolist(), 'shape:', ss.shape)\n",
        "\n",
        "print('Setup complete.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.11.0rc1\nTorch: 2.5.1+cu121\nTorchvision: 0.20.1+cu121\ntimm: 1.0.19\nAlbumentations: 2.0.8\ncv2 headless OK: True\nGPU Available: True\nGPU Count: 1\nGPU Name: NVIDIA A10-24Q\nGPU Memory: 23.7 GB\nFiles present: ['sample_submission.csv', 'test_tfrecords', 'docker_run.log', 'requirements.txt', 'test_images', 'train_with_groups.csv', 'submission.csv', 'train_images', 'train.csv', 'agent_metadata', 'task.txt', '00_eda_and_planning.ipynb', 'label_num_to_disease_map.json', 'train_tfrecords', 'description.md']\ntrain.csv shape: (18721, 2)\n         image_id  label\n0  1000015157.jpg      0\n1  1000201771.jpg      3\n2   100042118.jpg      1\n3  1000723321.jpg      1\n4  1000812911.jpg      3\nlabel value_counts:\n label\n0      939\n1     1901\n2     2091\n3    11523\n4     2267\nName: count, dtype: int64\nLabel map keys: ['0', '1', '2', '3', '4']\nTrain images: 18721 Test images: 2676\nSample train images: ['1000015157.jpg', '1000201771.jpg', '100042118.jpg', '1000723321.jpg', '1000812911.jpg']\nSample test images: ['1234294272.jpg', '1234332763.jpg', '1234375577.jpg', '1234555380.jpg', '1234571117.jpg']\nsample_submission columns: ['image_id', 'label'] shape: (2676, 2)\nSetup complete.\n"
          ]
        }
      ]
    },
    {
      "id": "c52a6a91-61e6-46c6-9535-c7791bd5b09a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dataset, transforms, and utilities\n",
        "import math, random\n",
        "from PIL import Image, ImageOps\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def get_train_transforms(size=512):\n",
        "    return A.Compose([\n",
        "        A.RandomResizedCrop(size=(size, size), scale=(0.7, 1.0), ratio=(0.9, 1.1), p=1.0),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Affine(\n",
        "            scale=(0.9, 1.1), translate_percent=(-0.1, 0.1), rotate=(-15, 15), shear=(-5, 5),\n",
        "            border_mode=cv2.BORDER_REFLECT_101, value=0, p=0.7\n",
        "        ),\n",
        "        A.HueSaturationValue(10, 15, 10, p=0.5),\n",
        "        A.RandomBrightnessContrast(0.2, 0.2, p=0.5),\n",
        "        A.GaussianBlur(blur_limit=(3, 5), p=0.1),\n",
        "        A.CoarseDropout(\n",
        "            max_holes=1,\n",
        "            max_height=int(0.2*size), max_width=int(0.2*size),\n",
        "            min_height=int(0.05*size), min_width=int(0.05*size),\n",
        "            fill_value=0, p=0.15\n",
        "        ),\n",
        "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def get_valid_transforms(size=512):\n",
        "    return A.Compose([\n",
        "        A.LongestMaxSize(max_size=size),\n",
        "        A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
        "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "\n",
        "def load_image_rgb(path: str) -> Image.Image:\n",
        "    img = Image.open(path).convert('RGB')\n",
        "    # handle EXIF orientation\n",
        "    img = ImageOps.exif_transpose(img)\n",
        "    return img\n",
        "\n",
        "class CassavaDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transforms=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transforms = transforms\n",
        "        self.has_label = 'label' in self.df.columns\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['image_id']\n",
        "        img = load_image_rgb(str(img_path))\n",
        "        img_np = np.array(img)\n",
        "        if self.transforms is not None:\n",
        "            img_np = self.transforms(image=img_np)['image']\n",
        "        if self.has_label:\n",
        "            label = int(row['label'])\n",
        "            return img_np, label\n",
        "        else:\n",
        "            return img_np, row['image_id']\n",
        "\n",
        "def make_loader(df, img_dir, transforms, batch_size=32, shuffle=False, num_workers=4):\n",
        "    ds = CassavaDataset(df, img_dir, transforms)\n",
        "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True, drop_last=shuffle, persistent_workers=num_workers>0)\n",
        "\n",
        "def check_submission_format(sub_path='submission.csv', required_cols=('image_id','label')):\n",
        "    if not os.path.exists(sub_path):\n",
        "        print('submission.csv not found')\n",
        "        return False\n",
        "    sub = pd.read_csv(sub_path)\n",
        "    ok = list(sub.columns)==list(required_cols)\n",
        "    labs_ok = sub['label'].dtype.kind in 'iu' and sub['label'].between(0,4).all()\n",
        "    print('Submission cols OK:', ok, 'Labels int[0..4]:', labs_ok, 'Shape:', sub.shape)\n",
        "    print('Label value_counts:', sub['label'].value_counts().to_dict())\n",
        "    return ok and labs_ok\n",
        "\n",
        "seed_everything(42)\n",
        "print('Utils ready.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utils ready.\n"
          ]
        }
      ]
    },
    {
      "id": "0fe4665a-ab26-4070-9cfa-426de9404581",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training scaffold: model, loop, CV, and inference helpers (not executed yet)\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import timm\n",
        "from timm.data import Mixup\n",
        "from timm.utils import ModelEmaV2\n",
        "from timm.loss import SoftTargetCrossEntropy\n",
        "\n",
        "class CFG:\n",
        "    seed = 42\n",
        "    model_name = 'convnext_base'\n",
        "    img_size = 448\n",
        "    epochs = 8\n",
        "    batch_size = 40\n",
        "    lr = 2e-4\n",
        "    weight_decay = 1e-4\n",
        "    num_workers = 8\n",
        "    n_splits = 5\n",
        "    ls = 0.1\n",
        "    mixup_alpha = 1.0\n",
        "    cutmix_alpha = 1.0\n",
        "    mixup_prob = 0.3\n",
        "    mixup_switch_prob = 0.5\n",
        "    use_mixup = True\n",
        "    use_ema = True\n",
        "    ema_decay = 0.999\n",
        "    tta_hflip = True\n",
        "    tta_scales = []  # e.g., [0.95, 1.05] later\n",
        "    smoke = False  # set True for quick debug\n",
        "\n",
        "def build_model(num_classes=5):\n",
        "    model = timm.create_model(CFG.model_name, pretrained=True, num_classes=num_classes)\n",
        "    model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.to(memory_format=torch.channels_last)\n",
        "    return model\n",
        "\n",
        "def get_mixup_fn():\n",
        "    if not CFG.use_mixup:\n",
        "        return None\n",
        "    return Mixup(mixup_alpha=CFG.mixup_alpha, cutmix_alpha=CFG.cutmix_alpha, prob=CFG.mixup_prob, switch_prob=CFG.mixup_switch_prob, label_smoothing=CFG.ls, num_classes=5)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, scaler, mixup_fn=None, ema=None, scheduler=None):\n",
        "    model.train()\n",
        "    device = next(model.parameters()).device\n",
        "    total_loss, total_cnt = 0.0, 0\n",
        "    if mixup_fn is not None:\n",
        "        criterion = SoftTargetCrossEntropy().to(device)\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss(label_smoothing=CFG.ls).to(device)\n",
        "    start = time.time()\n",
        "    for it, (x, y) in enumerate(loader):\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.to(memory_format=torch.channels_last)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        if mixup_fn is not None:\n",
        "            x, y = mixup_fn(x, y)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        if ema is not None:\n",
        "            ema.update(model)\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        total_cnt += x.size(0)\n",
        "        if it % 50 == 0:\n",
        "            elapsed = time.time() - start\n",
        "            print(f'  iter {it}/{len(loader)} loss {loss.item():.4f} elapsed {elapsed:.1f}s');\n",
        "            start = time.time()\n",
        "    return total_loss / max(total_cnt,1)\n",
        "\n",
        "def validate(model, loader):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    loss_sum = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            if torch.cuda.is_available():\n",
        "                x = x.to(memory_format=torch.channels_last)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y)\n",
        "            loss_sum += loss.item() * x.size(0)\n",
        "            prob = logits.softmax(dim=1)\n",
        "            pred = prob.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += x.size(0)\n",
        "    acc = correct / max(total,1)\n",
        "    return loss_sum / max(total,1), acc\n",
        "\n",
        "def get_scheduler(optimizer, steps_per_epoch):\n",
        "    # Cosine schedule with warmup of 1 epoch\n",
        "    warmup_steps = steps_per_epoch * 1\n",
        "    total_steps = steps_per_epoch * CFG.epochs\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup_steps:\n",
        "            return max(1e-8, step / max(1, warmup_steps))\n",
        "        progress = (step - warmup_steps) / max(1, total_steps - warmup_steps)\n",
        "        return 0.5 * (1 + math.cos(math.pi * progress))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "def run_cv_and_train(df, train_dir):\n",
        "    seed_everything(CFG.seed)\n",
        "    skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n",
        "    oof = np.zeros((len(df), 5), dtype=np.float32)\n",
        "    fold_indices = list(skf.split(df['image_id'], df['label']))\n",
        "    if CFG.smoke:\n",
        "        fold_indices = fold_indices[:1]\n",
        "        print('SMOKE RUN: 1 fold only, 1 epoch');\n",
        "        orig_epochs = CFG.epochs; CFG.epochs = 1\n",
        "    for fold, (tr_idx, va_idx) in enumerate(fold_indices):\n",
        "        print(f'Fold {fold} train {len(tr_idx)} valid {len(va_idx)}')\n",
        "        df_tr = df.iloc[tr_idx].reset_index(drop=True)\n",
        "        df_va = df.iloc[va_idx].reset_index(drop=True)\n",
        "        train_tfms = get_train_transforms(CFG.img_size)\n",
        "        valid_tfms = get_valid_transforms(CFG.img_size)\n",
        "        train_loader = make_loader(df_tr, train_dir, train_tfms, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers)\n",
        "        valid_loader = make_loader(df_va, train_dir, valid_tfms, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
        "        model = build_model(num_classes=5)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
        "        steps_per_epoch = max(1, len(train_loader))\n",
        "        scheduler = get_scheduler(optimizer, steps_per_epoch)\n",
        "        scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
        "        mixup_fn = get_mixup_fn()\n",
        "        ema = ModelEmaV2(model, decay=CFG.ema_decay, device='cpu') if CFG.use_ema else None\n",
        "        best_acc, best_state = -1.0, None\n",
        "        for epoch in range(CFG.epochs):\n",
        "            print(f'Epoch {epoch+1}/{CFG.epochs}');\n",
        "            t0 = time.time()\n",
        "            train_loss = train_one_epoch(model, train_loader, optimizer, scaler, mixup_fn, ema=ema, scheduler=scheduler)\n",
        "            val_loss, val_acc = validate(ema.module if ema is not None else model, valid_loader)\n",
        "            print(f'  train_loss {train_loss:.4f} val_loss {val_loss:.4f} val_acc {val_acc:.4f} epoch_time {time.time()-t0:.1f}s')\n",
        "            if val_acc > best_acc:\n",
        "                best_acc = val_acc\n",
        "                best_state = (ema.module if ema is not None else model).state_dict()\n",
        "        if CFG.smoke:\n",
        "            CFG.epochs = orig_epochs\n",
        "    return oof\n",
        "\n",
        "def infer_test(model, df_test, test_dir, size=None, tta_hflip=True, tta_scales=None, batch_size=32):\n",
        "    size = size or CFG.img_size\n",
        "    dev = next(model.parameters()).device\n",
        "    model.eval()\n",
        "    logits_sum = []\n",
        "    # Base transform\n",
        "    def make_tfms(sz):\n",
        "        return A.Compose([\n",
        "            A.LongestMaxSize(max_size=sz),\n",
        "            A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
        "            A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "    tfms_list = [(make_tfms(size), False)]\n",
        "    if tta_hflip:\n",
        "        tfms_list.append((make_tfms(size), True))\n",
        "    if tta_scales:\n",
        "        for s in tta_scales:\n",
        "            sz = int(round(size * s))\n",
        "            tfms_list.append((make_tfms(sz), False))\n",
        "    for (tfms, do_flip) in tfms_list:\n",
        "        ds = CassavaDataset(df_test[['image_id']].copy(), test_dir, transforms=tfms)\n",
        "        dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True)\n",
        "        part_logits = []\n",
        "        with torch.no_grad():\n",
        "            for x, ids in dl:\n",
        "                if do_flip:\n",
        "                    x = torch.flip(x, dims=[-1])\n",
        "                x = x.to(dev, non_blocking=True)\n",
        "                if torch.cuda.is_available():\n",
        "                    x = x.to(memory_format=torch.channels_last)\n",
        "                with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                    logits = model(x)\n",
        "                part_logits.append(logits.float().cpu().numpy())\n",
        "        logits_sum.append(np.concatenate(part_logits, axis=0))\n",
        "    logits_mean = np.mean(logits_sum, axis=0)\n",
        "    return logits_mean\n",
        "\n",
        "print('Training scaffold ready. Configure CFG and call run_cv_and_train(df, train_dir) when ready.')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training scaffold ready. Configure CFG and call run_cv_and_train(df, train_dir) when ready.\n"
          ]
        }
      ]
    },
    {
      "id": "faad2449-22a5-4ca3-a3ed-5126bfec484d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Smoke run: 1 fold x 1 epoch, then inference to submission.csv\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "seed_everything(42)\n",
        "CFG.model_name = 'convnext_tiny'\n",
        "CFG.img_size = 384\n",
        "CFG.batch_size = 32\n",
        "CFG.epochs = 1\n",
        "CFG.num_workers = 6\n",
        "CFG.use_ema = True\n",
        "CFG.use_mixup = True\n",
        "\n",
        "print('Starting SMOKE training (1 fold, 1 epoch) ...')\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n",
        "tr_idx, va_idx = list(skf.split(df['image_id'], df['label']))[0]\n",
        "df_tr = df.iloc[tr_idx].reset_index(drop=True)\n",
        "df_va = df.iloc[va_idx].reset_index(drop=True)\n",
        "train_loader = make_loader(df_tr, train_dir, get_train_transforms(CFG.img_size), batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers)\n",
        "valid_loader = make_loader(df_va, train_dir, get_valid_transforms(CFG.img_size), batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = build_model(num_classes=5)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "mixup_fn = get_mixup_fn()\n",
        "ema = ModelEmaV2(model, decay=CFG.ema_decay) if CFG.use_ema else None\n",
        "\n",
        "best_acc, best_state = -1.0, None\n",
        "print('Epoch 1/1')\n",
        "train_loss = train_one_epoch(model, train_loader, optimizer, scaler, mixup_fn)\n",
        "if ema is not None:\n",
        "    ema.update(model)\n",
        "val_loss, val_acc = validate(ema.module if ema is not None else model, valid_loader)\n",
        "print(f'  train_loss {train_loss:.4f} val_loss {val_loss:.4f} val_acc {val_acc:.4f}')\n",
        "best_acc = val_acc\n",
        "best_state = (ema.module if ema is not None else model).state_dict()\n",
        "\n",
        "# Load best and run inference on test\n",
        "if ema is not None:\n",
        "    ema.module.load_state_dict(best_state)\n",
        "    best_model = ema.module\n",
        "else:\n",
        "    model.load_state_dict(best_state)\n",
        "    best_model = model\n",
        "\n",
        "df_test = pd.DataFrame({'image_id': sorted([p.name for p in Path(test_dir).glob('*.jpg')])})\n",
        "logits = infer_test(best_model, df_test, test_dir, size=CFG.img_size, tta_hflip=True, tta_scales=None, batch_size=CFG.batch_size)\n",
        "preds = logits.argmax(1).astype(int)\n",
        "sub = pd.DataFrame({'image_id': df_test['image_id'], 'label': preds})\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with shape:', sub.shape)\n",
        "check_submission_format('submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b738eae0-7fd9-4fd3-bc17-59044560330c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Full training: phash groups + 5-fold convnext_base@448 with EMA + hflip+scale TTA; generate submission.csv\n",
        "import time, sys, subprocess, os, torch\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from pathlib import Path\n",
        "\n",
        "# Mitigate CUDA memory fragmentation\n",
        "os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True,max_split_size_mb:128')\n",
        "\n",
        "# Ensure imagehash installed\n",
        "try:\n",
        "    import imagehash\n",
        "except Exception as e:\n",
        "    print('Installing imagehash...'); sys.stdout.flush()\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'ImageHash'], check=True)\n",
        "    import imagehash\n",
        "\n",
        "from PIL import ImageOps\n",
        "\n",
        "def compute_phash_hex(path, hash_size=16):\n",
        "    img = ImageOps.exif_transpose(Image.open(path).convert('RGB'))\n",
        "    return str(imagehash.phash(img, hash_size=hash_size))\n",
        "\n",
        "t0 = time.time()\n",
        "# Fail-fast group merge: never silently recompute unless file missing\n",
        "groups_path = Path('train_with_groups.csv')\n",
        "if groups_path.exists():\n",
        "    print('Loading groups from train_with_groups.csv'); sys.stdout.flush()\n",
        "    gdf = pd.read_csv(groups_path)\n",
        "    assert {'image_id','label','group'}.issubset(gdf.columns), 'Bad groups CSV'\n",
        "    # Drop any pre-existing group-related cols to avoid suffix conflicts from prior runs\n",
        "    dup_cols = [c for c in df.columns if c.startswith('group')]\n",
        "    if dup_cols:\n",
        "        print('Dropping pre-existing columns:', dup_cols); sys.stdout.flush()\n",
        "        df = df.drop(columns=dup_cols)\n",
        "    df = df.merge(gdf[['image_id','label','group']], on=['image_id','label'], how='left', validate='one_to_one')\n",
        "    assert df['group'].notna().all(), 'Missing group after merge'\n",
        "else:\n",
        "    print('No saved groups; computing...'); sys.stdout.flush()\n",
        "    df['phash'] = [compute_phash_hex(Path(train_dir)/iid) for iid in df['image_id']]\n",
        "    df['group'] = df['phash'].str[:10]\n",
        "    df[['image_id','label','group']].to_csv('train_with_groups.csv', index=False)\n",
        "\n",
        "print('Unique groups:', df['group'].nunique(), 'elapsed:', f'{time.time()-t0:.1f}s')\n",
        "\n",
        "# Configure training per expert advice\n",
        "CFG.seed = 42\n",
        "CFG.model_name = 'convnext_base'\n",
        "CFG.img_size = 448\n",
        "CFG.batch_size = 32  # A10-24GB fits 32 @448 with AMP\n",
        "CFG.epochs = 10\n",
        "CFG.lr = 2e-4\n",
        "CFG.weight_decay = 1e-4\n",
        "CFG.num_workers = 8\n",
        "CFG.use_mixup = True\n",
        "CFG.mixup_prob = 0.5\n",
        "CFG.ls = 0.05\n",
        "CFG.use_ema = True\n",
        "CFG.ema_decay = 0.999\n",
        "CFG.tta_scales = [0.95, 1.05]\n",
        "\n",
        "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n",
        "folds = list(sgkf.split(df['image_id'], df['label'], groups=df['group']))\n",
        "print('Prepared StratifiedGroupKFold with 5 folds')\n",
        "\n",
        "df_test = pd.DataFrame({'image_id': sorted([p.name for p in Path(test_dir).glob('*.jpg')])})\n",
        "test_logits_folds = []\n",
        "oof_logits = np.zeros((len(df), 5), dtype=np.float32)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "for fold, (tr_idx, va_idx) in enumerate(folds):\n",
        "    fold_start = time.time()\n",
        "    print(f'===== Fold {fold} start: train {len(tr_idx)} valid {len(va_idx)} ====='); sys.stdout.flush()\n",
        "    df_tr = df.iloc[tr_idx].reset_index(drop=True)\n",
        "    df_va = df.iloc[va_idx].reset_index(drop=True)\n",
        "\n",
        "    # Free any stray CUDA allocations before building the model\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    train_loader = make_loader(df_tr, train_dir, get_train_transforms(CFG.img_size), batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers)\n",
        "    valid_loader = make_loader(df_va, train_dir, get_valid_transforms(CFG.img_size), batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
        "\n",
        "    model = build_model(num_classes=5)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
        "    steps_per_epoch = max(1, len(train_loader))\n",
        "    scheduler = get_scheduler(optimizer, steps_per_epoch)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
        "    mixup_fn = get_mixup_fn()\n",
        "    ema = ModelEmaV2(model, decay=CFG.ema_decay, device='cpu') if CFG.use_ema else None\n",
        "\n",
        "    best_acc, best_state = -1.0, None\n",
        "    for epoch in range(CFG.epochs):\n",
        "        ep_start = time.time()\n",
        "        print(f'Fold {fold} Epoch {epoch+1}/{CFG.epochs}'); sys.stdout.flush()\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, scaler, mixup_fn, ema=ema, scheduler=scheduler)\n",
        "        val_loss, val_acc = validate(ema.module if ema is not None else model, valid_loader)\n",
        "        print(f'  train_loss {train_loss:.4f} val_loss {val_loss:.4f} val_acc {val_acc:.4f} epoch_time {time.time()-ep_start:.1f}s'); sys.stdout.flush()\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_state = (ema.module if ema is not None else model).state_dict()\n",
        "\n",
        "    # Load best and compute OOF logits\n",
        "    with torch.no_grad():\n",
        "        target_model = ema.module if ema is not None else model\n",
        "        target_model.load_state_dict(best_state)\n",
        "        target_model.eval()\n",
        "        dev = next(target_model.parameters()).device\n",
        "        logits_all = []\n",
        "        for x, y in valid_loader:\n",
        "            x = x.to(dev, non_blocking=True)\n",
        "            if torch.cuda.is_available():\n",
        "                x = x.to(memory_format=torch.channels_last)\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                logits = target_model(x)\n",
        "            logits_all.append(logits.float().cpu().numpy())\n",
        "        logits_all = np.concatenate(logits_all, axis=0)\n",
        "        oof_logits[va_idx] = logits_all\n",
        "    print(f'Fold {fold} best_acc {best_acc:.4f} fold_time {time.time()-fold_start:.1f}s'); sys.stdout.flush()\n",
        "\n",
        "    # Test inference for this fold\n",
        "    fold_logits = infer_test(target_model, df_test, test_dir, size=CFG.img_size, tta_hflip=True, tta_scales=CFG.tta_scales, batch_size=CFG.batch_size)\n",
        "    test_logits_folds.append(fold_logits)\n",
        "\n",
        "# Average test logits across folds and save submission\n",
        "test_logits_mean = np.mean(test_logits_folds, axis=0)\n",
        "test_preds = test_logits_mean.argmax(1).astype(int)\n",
        "submission = pd.DataFrame({'image_id': df_test['image_id'], 'label': test_preds})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with shape:', submission.shape)\n",
        "check_submission_format('submission.csv')\n",
        "\n",
        "# Save OOF logits for future ensembling if needed\n",
        "np.save('oof_logits_convnext_base_448.npy', oof_logits)\n",
        "print('Saved oof logits to oof_logits_convnext_base_448.npy')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading groups from train_with_groups.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique groups: 18721 elapsed: 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared StratifiedGroupKFold with 5 folds\n===== Fold 0 start: train 14976 valid 3745 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/144154569.py:23: UserWarning: Argument(s) 'value' are not valid for transform Affine\n  A.Affine(\n/tmp/ipykernel_1823/144154569.py:30: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(\n/tmp/ipykernel_1823/144154569.py:43: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 1.5367 elapsed 1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 1.0321 elapsed 28.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.6981 elapsed 28.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.4477 elapsed 28.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.5799 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 1.0340 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.6085 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.5979 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.6233 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.5710 elapsed 28.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.8223 val_loss 1.0516 val_acc 0.6646 epoch_time 790.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.3995 elapsed 1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.7936 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 1.1590 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.5768 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.6780 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.4036 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.4357 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.3832 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.4983 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.5889 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6760 val_loss 0.5386 val_acc 0.8395 epoch_time 780.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.4829 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.7056 elapsed 28.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.7329 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.6492 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.7102 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.5210 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.7812 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.5211 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.5725 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.8068 elapsed 29.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6315 val_loss 0.3993 val_acc 0.8820 epoch_time 793.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.5525 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.3907 elapsed 28.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.3446 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.8252 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.5374 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.4397 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.4322 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.8737 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 1.0401 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.3867 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6167 val_loss 0.3582 val_acc 0.8948 epoch_time 787.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.3211 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.6218 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.3378 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.8480 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.4309 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.9204 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.7789 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.9147 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.3828 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.6873 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5724 val_loss 0.3413 val_acc 0.9001 epoch_time 778.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.3778 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.3090 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.7235 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.9256 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.3960 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.2870 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.3992 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.6664 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.6471 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.6862 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5339 val_loss 0.3332 val_acc 0.9004 epoch_time 774.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.2391 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.5413 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.3509 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.7935 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.3331 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.7754 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.6885 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.8981 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.5828 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.7726 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4953 val_loss 0.3338 val_acc 0.8991 epoch_time 800.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 1.0462 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.5698 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.2485 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.2389 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.2684 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.5888 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2368 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2366 elapsed 29.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.3288 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.3716 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4997 val_loss 0.3396 val_acc 0.8999 epoch_time 794.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.8933 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.2288 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.8007 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.6244 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.5770 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.2320 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2384 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2510 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.2320 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.5324 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4633 val_loss 0.3458 val_acc 0.8977 epoch_time 788.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.2292 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.2392 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.6687 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.6282 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.5367 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.2667 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.5311 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.7962 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.7056 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2313 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4359 val_loss 0.3524 val_acc 0.8961 epoch_time 794.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 best_acc 0.9004 fold_time 8404.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/1822884949.py:160: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 1 start: train 14977 valid 3744 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/144154569.py:23: UserWarning: Argument(s) 'value' are not valid for transform Affine\n  A.Affine(\n/tmp/ipykernel_1823/144154569.py:30: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(\n/tmp/ipykernel_1823/144154569.py:43: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 1.8690 elapsed 1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 1.0877 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.7024 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.9673 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.6021 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.5486 elapsed 29.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.6844 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.5025 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.6060 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.4347 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.8104 val_loss 1.0542 val_acc 0.6934 epoch_time 771.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.5338 elapsed 1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 1.1539 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.5830 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.5000 elapsed 29.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.4599 elapsed 29.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.7310 elapsed 29.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.5351 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.5363 elapsed 29.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.9072 elapsed 29.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.6734 elapsed 29.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6786 val_loss 0.5205 val_acc 0.8427 epoch_time 800.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.5714 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.9735 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.8064 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.5430 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.4665 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.4620 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.4789 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.9497 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.7293 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.3766 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6124 val_loss 0.3973 val_acc 0.8758 epoch_time 795.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.5191 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.8462 elapsed 28.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.6794 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.4063 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.9621 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.6409 elapsed 29.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.5321 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.4166 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.5044 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.8901 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6025 val_loss 0.3612 val_acc 0.8894 epoch_time 796.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.7586 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.8768 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.3041 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.3984 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.6940 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.4592 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.6052 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.7120 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.5343 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.8020 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5811 val_loss 0.3454 val_acc 0.8897 epoch_time 784.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 1.0021 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.9311 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.5641 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.4014 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.4355 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.7659 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.8365 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.3087 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.2766 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2382 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5177 val_loss 0.3409 val_acc 0.8929 epoch_time 785.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.5333 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.6261 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.3469 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.7499 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.2399 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.3155 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2413 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2747 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.6209 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.8320 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4795 val_loss 0.3407 val_acc 0.8945 epoch_time 791.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.4561 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.8006 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.8919 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.4893 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.2340 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.2560 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2767 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.3019 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.2329 elapsed 29.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 1.1203 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4522 val_loss 0.3473 val_acc 0.8948 epoch_time 804.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.2362 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.2375 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.2299 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.5720 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.4401 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.6536 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.7299 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.3075 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.8167 elapsed 29.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2513 elapsed 29.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4300 val_loss 0.3552 val_acc 0.8918 epoch_time 788.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.3645 elapsed 0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.7260 elapsed 28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.2395 elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.4508 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.7033 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.2285 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2280 elapsed 29.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2340 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.2278 elapsed 29.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2290 elapsed 29.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4505 val_loss 0.3629 val_acc 0.8905 epoch_time 790.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 best_acc 0.8948 fold_time 8420.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/1822884949.py:160: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 2 start: train 14977 valid 3744 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/144154569.py:23: UserWarning: Argument(s) 'value' are not valid for transform Affine\n  A.Affine(\n/tmp/ipykernel_1823/144154569.py:30: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(\n/tmp/ipykernel_1823/144154569.py:43: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 1.9680 elapsed 1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 1.0804 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.4900 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 1.1049 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 1.2697 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.5418 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 1.0029 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.6484 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.8050 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.6144 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.8326 val_loss 1.0777 val_acc 0.6792 epoch_time 779.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 1.0272 elapsed 1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 1.1429 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 1.2293 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.4143 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 1.0211 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.9700 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.5844 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.5873 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.6468 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.5218 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6721 val_loss 0.5490 val_acc 0.8435 epoch_time 769.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.8089 elapsed 0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.9406 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.3306 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.9132 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.9107 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.4216 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.3999 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.7165 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.5454 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.4841 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6196 val_loss 0.4199 val_acc 0.8758 epoch_time 765.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.4651 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 1.0650 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.6957 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.4225 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.5795 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.5551 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.5931 elapsed 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2929 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.4016 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.4263 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5995 val_loss 0.3758 val_acc 0.8846 epoch_time 766.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.3171 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 1.0600 elapsed 27.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.2581 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.6271 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.8229 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.3596 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.4538 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2504 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.4425 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.4747 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5542 val_loss 0.3586 val_acc 0.8876 epoch_time 783.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.2813 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.2884 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.7850 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.2791 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.6453 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.2821 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.3649 elapsed 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2878 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.4313 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2545 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5156 val_loss 0.3533 val_acc 0.8897 epoch_time 789.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.7105 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.8528 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.3253 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.2498 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.2988 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.4587 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2562 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.8111 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.3190 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.6338 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4907 val_loss 0.3564 val_acc 0.8905 epoch_time 786.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.2344 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.7303 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.2345 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.6817 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.2446 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.9410 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2376 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.7673 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.7205 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2711 elapsed 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4683 val_loss 0.3647 val_acc 0.8889 epoch_time 783.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.3392 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.2376 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.7284 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.5258 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.2301 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.5198 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.5629 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2439 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.2682 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2863 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4401 val_loss 0.3738 val_acc 0.8873 epoch_time 794.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.3613 elapsed 0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.2311 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.5492 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.3375 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.6139 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.3535 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2746 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.7781 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.2413 elapsed 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2318 elapsed 28.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4376 val_loss 0.3814 val_acc 0.8857 epoch_time 750.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 best_acc 0.8905 fold_time 8254.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/1822884949.py:160: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 3 start: train 14977 valid 3744 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/144154569.py:23: UserWarning: Argument(s) 'value' are not valid for transform Affine\n  A.Affine(\n/tmp/ipykernel_1823/144154569.py:30: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(\n/tmp/ipykernel_1823/144154569.py:43: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 1.5427 elapsed 1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 1.0406 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.7954 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.8775 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 1.1098 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 1.2200 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.5984 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.3502 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.4499 elapsed 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.3560 elapsed 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.8276 val_loss 0.9069 val_acc 0.7623 epoch_time 758.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.8343 elapsed 1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.4772 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.4181 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.7097 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.5040 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.7386 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.4845 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 1.3986 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.6985 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.7129 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6689 val_loss 0.4898 val_acc 0.8571 epoch_time 768.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 1.0222 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.6280 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.5468 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.9323 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.5212 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.8982 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 1.0038 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.5088 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.4009 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.7219 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6118 val_loss 0.3799 val_acc 0.8932 epoch_time 807.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.3166 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.8422 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.4132 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.7615 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.6394 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.4476 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.3084 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.6361 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.9828 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.3775 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5909 val_loss 0.3426 val_acc 0.9004 epoch_time 778.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.2947 elapsed 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.5377 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.8759 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.3786 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.3315 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.7311 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.9279 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2799 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.4878 elapsed 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.4946 elapsed 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5868 val_loss 0.3287 val_acc 0.9020 epoch_time 776.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.2580 elapsed 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.9546 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.6914 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.7061 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.9120 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.5080 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.7520 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2432 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.8567 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.3522 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5241 val_loss 0.3234 val_acc 0.9028 epoch_time 776.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 1.3202 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.9567 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.3275 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 1.1502 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.7737 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.2459 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.4855 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.4667 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.2558 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2302 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4880 val_loss 0.3274 val_acc 0.9022 epoch_time 782.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.2362 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.4751 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 1.0241 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.2678 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.3336 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.6269 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2439 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.3067 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.4784 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2422 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4789 val_loss 0.3373 val_acc 0.9001 epoch_time 777.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.5318 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.3808 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.2347 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.4361 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.3058 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.2481 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.3449 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.8525 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.2489 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2277 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4456 val_loss 0.3481 val_acc 0.8972 epoch_time 775.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.2390 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.6033 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.2317 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.2764 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.3120 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.9385 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2370 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.5527 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.6858 elapsed 28.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.7512 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4543 val_loss 0.3568 val_acc 0.8950 epoch_time 779.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 best_acc 0.9028 fold_time 8289.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/1822884949.py:160: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 4 start: train 14977 valid 3744 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/144154569.py:23: UserWarning: Argument(s) 'value' are not valid for transform Affine\n  A.Affine(\n/tmp/ipykernel_1823/144154569.py:30: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(\n/tmp/ipykernel_1823/144154569.py:43: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 1.4997 elapsed 1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 1.1493 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.5925 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.7875 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.6275 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.4559 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 1.0060 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.4749 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.4701 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.5895 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.8311 val_loss 0.9803 val_acc 0.6696 epoch_time 769.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.6326 elapsed 1.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.4269 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.8327 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 1.0337 elapsed 28.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.5378 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.4679 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.8173 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.7478 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.4728 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.5180 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6747 val_loss 0.5321 val_acc 0.8360 epoch_time 766.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.5296 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.6890 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.5165 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.5805 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.9415 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.5095 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.4550 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.3966 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.6447 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.6494 elapsed 28.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6428 val_loss 0.4025 val_acc 0.8763 epoch_time 776.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.4180 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.3190 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.3873 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.3316 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.5347 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.4868 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.6618 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.3562 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.5831 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.5111 elapsed 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6008 val_loss 0.3539 val_acc 0.8918 epoch_time 786.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.2988 elapsed 0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.7886 elapsed 27.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.5899 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.5670 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.8261 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.2729 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.3366 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.7649 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.3279 elapsed 28.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.2903 elapsed 28.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5549 val_loss 0.3389 val_acc 0.8974 epoch_time 752.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.5385 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.2692 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.5923 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.6578 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.4942 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.3821 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.3145 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.7320 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.8496 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.8545 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5340 val_loss 0.3355 val_acc 0.8958 epoch_time 748.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.7195 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.9747 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 1.0020 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.3192 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.5558 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.3938 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.3293 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.7112 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.2852 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.3550 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4759 val_loss 0.3402 val_acc 0.8953 epoch_time 758.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.9176 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.5636 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.7243 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.2509 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.4762 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.2852 elapsed 27.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.4474 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.6655 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.2448 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.5777 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4634 val_loss 0.3490 val_acc 0.8918 epoch_time 752.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.6575 elapsed 0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.2371 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.2367 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.5991 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.7190 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.2515 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2410 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2341 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.6485 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.8504 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4560 val_loss 0.3607 val_acc 0.8913 epoch_time 757.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/468 loss 0.3429 elapsed 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/468 loss 0.5728 elapsed 27.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/468 loss 0.2411 elapsed 27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/468 loss 0.2379 elapsed 27.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/468 loss 0.9721 elapsed 28.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/468 loss 0.3040 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/468 loss 0.2307 elapsed 27.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/468 loss 0.2307 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/468 loss 0.2308 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/468 loss 0.3130 elapsed 28.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.4560 val_loss 0.3708 val_acc 0.8889 epoch_time 774.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 best_acc 0.8974 fold_time 8156.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/1822884949.py:160: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv with shape: (2676, 2)\nSubmission cols OK: True Labels int[0..4]: True Shape: (2676, 2)\nLabel value_counts: {3: 1673, 4: 327, 1: 281, 2: 257, 0: 138}\nSaved oof logits to oof_logits_convnext_base_448.npy\n"
          ]
        }
      ]
    },
    {
      "id": "3ae12e89-0e34-4622-921c-6b7963fd18e1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hard reset GPU context: save groups then SIGKILL kernel\n",
        "import os, signal\n",
        "if 'group' in df.columns:\n",
        "    df[['image_id','label','group']].to_csv('train_with_groups.csv', index=False)\n",
        "    print('Saved train_with_groups.csv')\n",
        "else:\n",
        "    print('No group column to save; skipping')\n",
        "print('Killing kernel to hard-reset CUDA context...')\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "be029bf4-69bb-4140-ad33-b34b36c051a3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save convnext_base test logits after Cell 5 completes\n",
        "import numpy as np, os\n",
        "if 'test_logits_mean' in globals():\n",
        "    np.save('test_logits_convnext_base_448.npy', test_logits_mean)\n",
        "    print('Saved test logits to test_logits_convnext_base_448.npy with shape:', test_logits_mean.shape)\n",
        "else:\n",
        "    print('test_logits_mean not found in globals; run after Cell 5 finished.')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved test logits to test_logits_convnext_base_448.npy with shape: (2676, 5)\n"
          ]
        }
      ]
    },
    {
      "id": "b4c28d1d-10be-4f33-9000-1e5f8f4f2da3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train tf_efficientnet_b4_ns@512 with SGKF(phash) + ES + EMA; save fold ckpts and test logits\n",
        "import time, os, sys, subprocess\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import torch\n",
        "from timm.utils import ModelEmaV2\n",
        "from timm.data import Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Speedup per expert advice\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "class CFG_B4:\n",
        "    seed = 42\n",
        "    model_name = 'tf_efficientnet_b4_ns'\n",
        "    img_size = 512\n",
        "    batch_size = 24\n",
        "    epochs = 12\n",
        "    min_epochs = 6\n",
        "    patience = 2\n",
        "    lr = 1e-4\n",
        "    weight_decay = 1e-4\n",
        "    num_workers = 8\n",
        "    mixup_alpha = 1.0\n",
        "    cutmix_alpha = 1.0\n",
        "    mixup_prob = 0.5\n",
        "    mixup_switch_prob = 0.5\n",
        "    ls = 0.05\n",
        "    use_mixup = True\n",
        "    use_ema = True\n",
        "    ema_decay = 0.999\n",
        "    tta_scales = [0.95, 1.05]\n",
        "\n",
        "def build_model_b4(num_classes=5):\n",
        "    m = timm.create_model(CFG_B4.model_name, pretrained=True, num_classes=num_classes)\n",
        "    m = m.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if torch.cuda.is_available():\n",
        "        m = m.to(memory_format=torch.channels_last)\n",
        "    return m\n",
        "\n",
        "def get_mixup_fn_b4():\n",
        "    if not CFG_B4.use_mixup:\n",
        "        return None\n",
        "    return Mixup(mixup_alpha=CFG_B4.mixup_alpha, cutmix_alpha=CFG_B4.cutmix_alpha, prob=CFG_B4.mixup_prob, switch_prob=CFG_B4.mixup_switch_prob, label_smoothing=CFG_B4.ls, num_classes=5)\n",
        "\n",
        "def get_scheduler_b4(optimizer, steps_per_epoch):\n",
        "    warmup = steps_per_epoch * 1\n",
        "    total = steps_per_epoch * CFG_B4.epochs\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup:\n",
        "            return max(1e-8, step / max(1, warmup))\n",
        "        prog = (step - warmup) / max(1, total - warmup)\n",
        "        return 0.5 * (1 + math.cos(math.pi * prog))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "def train_epoch_b4(model, loader, optimizer, scaler, mixup_fn=None, ema=None, scheduler=None):\n",
        "    model.train()\n",
        "    dev = next(model.parameters()).device\n",
        "    crit = SoftTargetCrossEntropy().to(dev) if mixup_fn is not None else nn.CrossEntropyLoss(label_smoothing=CFG_B4.ls).to(dev)\n",
        "    tot, cnt = 0.0, 0\n",
        "    t0 = time.time()\n",
        "    for it, (x, y) in enumerate(loader):\n",
        "        x = x.to(dev, non_blocking=True)\n",
        "        if torch.cuda.is_available(): x = x.to(memory_format=torch.channels_last)\n",
        "        y = y.to(dev, non_blocking=True)\n",
        "        if mixup_fn is not None:\n",
        "            x, y = mixup_fn(x, y)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "            logits = model(x)\n",
        "            loss = crit(logits, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        if ema is not None: ema.update(model)\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        tot += loss.item() * x.size(0)\n",
        "        cnt += x.size(0)\n",
        "        if it % 50 == 0:\n",
        "            print(f'  iter {it}/{len(loader)} loss {loss.item():.4f}')\n",
        "    return tot / max(cnt,1)\n",
        "\n",
        "def validate_b4(model, loader):\n",
        "    model.eval()\n",
        "    dev = next(model.parameters()).device\n",
        "    crit = nn.CrossEntropyLoss().to(dev)\n",
        "    tot, cnt, correct = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(dev, non_blocking=True)\n",
        "            if torch.cuda.is_available(): x = x.to(memory_format=torch.channels_last)\n",
        "            y = y.to(dev, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                logits = model(x)\n",
        "                loss = crit(logits, y)\n",
        "            tot += loss.item() * x.size(0); cnt += x.size(0)\n",
        "            correct += (logits.softmax(1).argmax(1) == y).sum().item()\n",
        "    return tot / max(cnt,1), correct / max(cnt,1)\n",
        "\n",
        "def train_b4_with_groups():\n",
        "    seed_everything(CFG_B4.seed)\n",
        "    groups_path = Path('train_with_groups.csv')\n",
        "    assert groups_path.exists(), 'train_with_groups.csv missing; run Cell 5 or precompute groups first.'\n",
        "    gdf = pd.read_csv(groups_path)\n",
        "    # ensure df has group merged\n",
        "    base_cols = ['image_id','label']\n",
        "    if 'group' not in df.columns:\n",
        "        mdf = df[base_cols].merge(gdf[base_cols+['group']], on=base_cols, how='left', validate='one_to_one')\n",
        "    else:\n",
        "        mdf = df.copy()\n",
        "    assert mdf['group'].notna().all(), 'Group merge failed'\n",
        "    sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=CFG_B4.seed)\n",
        "    folds = list(sgkf.split(mdf['image_id'], mdf['label'], groups=mdf['group']))\n",
        "    df_test = pd.DataFrame({'image_id': sorted([p.name for p in Path(test_dir).glob('*.jpg')])})\n",
        "    test_logits_folds = []\n",
        "    oof_logits = np.zeros((len(mdf), 5), dtype=np.float32)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    for fold, (tr_idx, va_idx) in enumerate(folds):\n",
        "        print(f'===== B4 Fold {fold} start: train {len(tr_idx)} valid {len(va_idx)} =====')\n",
        "        df_tr = mdf.iloc[tr_idx].reset_index(drop=True)\n",
        "        df_va = mdf.iloc[va_idx].reset_index(drop=True)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache(); torch.cuda.reset_peak_memory_stats()\n",
        "        train_loader = make_loader(df_tr, train_dir, get_train_transforms(CFG_B4.img_size), batch_size=CFG_B4.batch_size, shuffle=True, num_workers=CFG_B4.num_workers)\n",
        "        valid_loader = make_loader(df_va, train_dir, get_valid_transforms(CFG_B4.img_size), batch_size=CFG_B4.batch_size, shuffle=False, num_workers=CFG_B4.num_workers)\n",
        "        model = build_model_b4(num_classes=5)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=CFG_B4.lr, weight_decay=CFG_B4.weight_decay)\n",
        "        steps_per_epoch = max(1, len(train_loader))\n",
        "        scheduler = get_scheduler_b4(optimizer, steps_per_epoch)\n",
        "        scaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n",
        "        mixup_fn = get_mixup_fn_b4()\n",
        "        ema = ModelEmaV2(model, decay=CFG_B4.ema_decay, device='cpu') if CFG_B4.use_ema else None\n",
        "        best_acc, best_state = -1.0, None\n",
        "        no_improve = 0\n",
        "        for epoch in range(CFG_B4.epochs):\n",
        "            print(f'B4 Fold {fold} Epoch {epoch+1}/{CFG_B4.epochs}')\n",
        "            tr_loss = train_epoch_b4(model, train_loader, optimizer, scaler, mixup_fn, ema=ema, scheduler=scheduler)\n",
        "            val_loss, val_acc = validate_b4(ema.module if ema is not None else model, valid_loader)\n",
        "            print(f'  train_loss {tr_loss:.4f} val_loss {val_loss:.4f} val_acc {val_acc:.4f}')\n",
        "            improved = val_acc > best_acc + 1e-6\n",
        "            if improved:\n",
        "                best_acc = val_acc\n",
        "                best_state = (ema.module if ema is not None else model).state_dict()\n",
        "                no_improve = 0\n",
        "                torch.save(best_state, f'ckpt_{CFG_B4.model_name}_{CFG_B4.img_size}_fold{fold}.pth')\n",
        "            else:\n",
        "                no_improve += 1\n",
        "            if (epoch + 1) >= CFG_B4.min_epochs and no_improve > CFG_B4.patience:\n",
        "                print('  Early stopping triggered')\n",
        "                break\n",
        "        # OOF logits\n",
        "        with torch.no_grad():\n",
        "            target = ema.module if ema is not None else model\n",
        "            target.load_state_dict(best_state)\n",
        "            target.eval()\n",
        "            dev = next(target.parameters()).device\n",
        "            fold_logits = []\n",
        "            for x, y in valid_loader:\n",
        "                x = x.to(dev, non_blocking=True)\n",
        "                if torch.cuda.is_available(): x = x.to(memory_format=torch.channels_last)\n",
        "                with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                    lg = target(x)\n",
        "                fold_logits.append(lg.float().cpu().numpy())\n",
        "            fold_logits = np.concatenate(fold_logits, axis=0)\n",
        "            oof_logits[va_idx] = fold_logits\n",
        "        # Test logits for this fold\n",
        "        fold_test_logits = infer_test(target, df_test, test_dir, size=CFG_B4.img_size, tta_hflip=True, tta_scales=CFG_B4.tta_scales, batch_size=CFG_B4.batch_size)\n",
        "        test_logits_folds.append(fold_test_logits)\n",
        "        np.save(f'test_logits_{CFG_B4.model_name}_{CFG_B4.img_size}_fold{fold}.npy', fold_test_logits)\n",
        "        print(f'B4 Fold {fold} best_acc {best_acc:.4f}')\n",
        "    test_logits_mean = np.mean(test_logits_folds, axis=0)\n",
        "    np.save(f'test_logits_{CFG_B4.model_name}_{CFG_B4.img_size}.npy', test_logits_mean)\n",
        "    np.save(f'oof_logits_{CFG_B4.model_name}_{CFG_B4.img_size}.npy', oof_logits)\n",
        "    print(f'Saved test logits to test_logits_{CFG_B4.model_name}_{CFG_B4.img_size}.npy with shape {test_logits_mean.shape}')\n",
        "    return test_logits_mean\n",
        "\n",
        "print('B4 training cell ready. After Cell 5 finishes, run train_b4_with_groups() to produce test logits for ensembling.')\n",
        "\n",
        "# Auto-start training for B4\n",
        "test_logits_mean_b4 = train_b4_with_groups()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 training cell ready. After Cell 5 finishes, run train_b4_with_groups() to produce test logits for ensembling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== B4 Fold 0 start: train 14976 valid 3745 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/144154569.py:23: UserWarning: Argument(s) 'value' are not valid for transform Affine\n  A.Affine(\n/tmp/ipykernel_1823/144154569.py:30: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(\n/tmp/ipykernel_1823/144154569.py:43: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 0 Epoch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 2.8598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 2.4599\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.4088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.9404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 1.2813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 1.2813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.7952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 1.0220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 1.4439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.7891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.6243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.5917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 1.0702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 1.2195 val_loss 1.8542 val_acc 0.2534\nB4 Fold 0 Epoch 2/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.5664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.8589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.4920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.7561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.7658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.8898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.5036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.6787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.9509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.5592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.9967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.9918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.5757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.8079 val_loss 0.8106 val_acc 0.7268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 0 Epoch 3/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.4146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.4813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.7312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.4637\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.5062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 1.0919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.9653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.5733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.8218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.8217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.6980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.5797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.9332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.7409 val_loss 0.5200 val_acc 0.8347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 0 Epoch 4/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.6099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.8243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.3787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.6832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.6594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.9408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.4680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.5281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.8851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 1.1163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.3961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.6182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.6206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.7130 val_loss 0.4598 val_acc 0.8563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 0 Epoch 5/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.8376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.8608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.1773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.4363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.7144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.9424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.7422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.4064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.6730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.3810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.6547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.7008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6674 val_loss 0.4334 val_acc 0.8654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 0 Epoch 6/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.6004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.3366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.7866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.6192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.9437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.9667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.3435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.7923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.9501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.4466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.2741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 1.0021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.4242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6465 val_loss 0.4227 val_acc 0.8697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 0 Epoch 7/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.8698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.7297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.4523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.7297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.3671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.9921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.6289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.5449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 1.0670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 1.0288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 1.0997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.3263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6173 val_loss 0.4182 val_acc 0.8737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 0 Epoch 8/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.3520\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 1.1669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.4215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.3414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.8351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.6939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.8193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.4453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 1.0917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.5275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.5614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.4341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.7814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5838 val_loss 0.4174 val_acc 0.8745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 0 Epoch 9/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.3479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 1.1903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.6718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.3395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.3003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.5904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.6687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.6713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.8683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.4642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.2994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.5921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.3333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5586 val_loss 0.4161 val_acc 0.8753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 0 Epoch 10/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.4258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 1.0018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.3299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.3580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.3104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.5861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.3732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.8930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 1.0718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.7962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.3453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.3291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 1.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5339 val_loss 0.4218 val_acc 0.8732\nB4 Fold 0 Epoch 11/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.3225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.7798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.9691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.2894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.3564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.6277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.2550\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.2729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.9995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.3263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.3136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.7349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 1.0206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5395 val_loss 0.4288 val_acc 0.8710\nB4 Fold 0 Epoch 12/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.7337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.4280\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.0594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.2916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.2981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.4132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.3268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.2585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.4346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.2966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.3134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.7766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.4478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5464 val_loss 0.4308 val_acc 0.8705\n  Early stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/1822884949.py:160: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 0 best_acc 0.8753\n===== B4 Fold 1 start: train 14977 valid 3744 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/144154569.py:23: UserWarning: Argument(s) 'value' are not valid for transform Affine\n  A.Affine(\n/tmp/ipykernel_1823/144154569.py:30: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(\n/tmp/ipykernel_1823/144154569.py:43: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 1 Epoch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 2.5807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 2.5666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.7274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.1595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 1.1549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 1.2383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 1.0668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.7454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.6361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 1.0835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.8163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.7569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.7244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 1.2485 val_loss 1.6423 val_acc 0.3381\nB4 Fold 1 Epoch 2/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.6675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.6895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.7291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.7679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.9554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.7861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 1.1115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 1.6729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.5150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.7879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.9961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.8547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.4588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.8025 val_loss 0.8350 val_acc 0.7067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 1 Epoch 3/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.6747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.5128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.9864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.5100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.7673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.5119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.6937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 1.0602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.9791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.7194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 1.0391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 1.0140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.7802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.7359 val_loss 0.5410 val_acc 0.8267\nB4 Fold 1 Epoch 4/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.5051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.7131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.1132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.4124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.9462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.8354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.9247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.4785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.3591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 1.0075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.7313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 1.1887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6988 val_loss 0.4708 val_acc 0.8443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 1 Epoch 5/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.3830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.9133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.4759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.4308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.4623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.4139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.6126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.7333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.6609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.6689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.9543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.6913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.3245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6642 val_loss 0.4486 val_acc 0.8563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 1 Epoch 6/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.5952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.4331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.9494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.3290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.3954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.8231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.4579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.5735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.5629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.3510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.7675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.4052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6404 val_loss 0.4409 val_acc 0.8643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 1 Epoch 7/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.8547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.5066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.4056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.3370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.3837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.8546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.3773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.3659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.3523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.9304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.8368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.7717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6267 val_loss 0.4278 val_acc 0.8681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 1 Epoch 8/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.4596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.4646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.4608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.4210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.7096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.5464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.5303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.4812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.6138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.8766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.2797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.5106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.4312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5913 val_loss 0.4201 val_acc 0.8705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 1 Epoch 9/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 1.0323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.3573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.9234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.0706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.3177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.5252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.4162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.3973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.5768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.6433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.6428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.3337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 1.2804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5769 val_loss 0.4200 val_acc 0.8681\nB4 Fold 1 Epoch 10/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.9897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.3495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.8251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.7892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.2654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.9011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.5009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.4515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.4798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.2966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.2827\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.2716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.2697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5604 val_loss 0.4271 val_acc 0.8673\nB4 Fold 1 Epoch 11/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 1.3657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.4716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.0095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.6460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.2720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 1.2069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.3108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.2967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.3045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.9712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.6574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.5938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5445 val_loss 0.4294 val_acc 0.8649\n  Early stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/1822884949.py:160: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 1 best_acc 0.8705\n===== B4 Fold 2 start: train 14977 valid 3744 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/144154569.py:23: UserWarning: Argument(s) 'value' are not valid for transform Affine\n  A.Affine(\n/tmp/ipykernel_1823/144154569.py:30: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(\n/tmp/ipykernel_1823/144154569.py:43: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 2 Epoch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 3.2823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 2.4373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 2.0645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.1671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 1.2609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 1.2238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 1.1322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 1.1191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 1.1931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.9101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.9517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 1.0420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.7863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 1.2444 val_loss 1.4976 val_acc 0.5067\nB4 Fold 2 Epoch 2/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.7143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 1.4037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.9903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.7561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.7297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.7224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 1.2630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.6235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.7955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 1.0479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.6435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 1.1647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.9737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.7971 val_loss 0.8293 val_acc 0.7179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 2 Epoch 3/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.6678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.7156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.7257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.9279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 1.2992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 1.5059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.8524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.5373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.6833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.7235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.7866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.4438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.7200 val_loss 0.5433 val_acc 0.8178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 2 Epoch 4/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.3961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.5953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.6044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.9088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.3569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.4337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.4815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.4172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.6568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.4804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.6747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.4406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 1.2808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6716 val_loss 0.4476 val_acc 0.8536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 2 Epoch 5/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.4572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.4440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.1431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.8025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.4993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.5181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.5710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.5035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.5279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.5081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.9372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 1.0638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6591 val_loss 0.4244 val_acc 0.8598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 2 Epoch 6/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.7193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.3204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.9456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.3776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 1.1510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 1.2231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.3289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.8368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.3791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.7906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 1.1951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.9936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.4046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6315 val_loss 0.4135 val_acc 0.8643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 2 Epoch 7/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.4195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.4636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.4405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.0249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.9926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.3559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.8504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.9142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.8698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.5853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.7553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.4606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.6592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6098 val_loss 0.4096 val_acc 0.8662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 2 Epoch 8/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.6131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.5608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.3689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.5882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.4204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.7373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.4251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.4275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.6697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.7727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 1.2562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.3885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.3613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5940 val_loss 0.4133 val_acc 0.8657\nB4 Fold 2 Epoch 9/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.7012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.9961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.3149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.3199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.3948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.7641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.3053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.4013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.7414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.4388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 1.1235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.9661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.3185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5560 val_loss 0.4191 val_acc 0.8659\nB4 Fold 2 Epoch 10/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.4488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.9419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.3004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.2998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.4527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.7149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.7855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.3917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.3685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.9699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.3162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.6308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.5526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5330 val_loss 0.4237 val_acc 0.8635\n  Early stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/1822884949.py:160: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 2 best_acc 0.8662\n===== B4 Fold 3 start: train 14977 valid 3744 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/144154569.py:23: UserWarning: Argument(s) 'value' are not valid for transform Affine\n  A.Affine(\n/tmp/ipykernel_1823/144154569.py:30: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(\n/tmp/ipykernel_1823/144154569.py:43: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 3 Epoch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 2.9978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 2.3268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.8944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.0351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 1.4867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 1.0475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 1.1041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 1.3236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.9282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 1.3146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 1.0877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.9570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.7905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 1.2675 val_loss 2.2064 val_acc 0.1774\nB4 Fold 3 Epoch 2/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.6991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.7812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.2914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.4866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.5422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.4796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.7737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.6159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 1.2298\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.9528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.6732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.6675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.4538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.8103 val_loss 0.8667 val_acc 0.6939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 3 Epoch 3/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.8488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.5250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.5296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.2711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.4882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 1.1991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.7848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 1.1209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.6631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.4935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.6834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.8495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.4530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.7383 val_loss 0.5184 val_acc 0.8435\nB4 Fold 3 Epoch 4/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.5885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.5532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.6033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.1110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 1.1230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.4114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 1.0042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.7050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.4624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.4710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.4296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.7027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.7001 val_loss 0.4410 val_acc 0.8665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 3 Epoch 5/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.5852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.6956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.7647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.6936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.8224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.4598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.4403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.4846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 1.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.5693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.7948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.9199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.5740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6771 val_loss 0.4235 val_acc 0.8731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 3 Epoch 6/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.6542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.4021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.9111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.4878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.4572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.3878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.6263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.7617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.3173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.9207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.5378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.3961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 1.0258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6504 val_loss 0.4169 val_acc 0.8750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 3 Epoch 7/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.3050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.7794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.4437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.8183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.5579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.4638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.4266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.4494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.3563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.4812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.5301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.3933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6044 val_loss 0.4117 val_acc 0.8718\nB4 Fold 3 Epoch 8/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.2826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.4906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.3689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.8096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.9808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.3584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.4312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.8199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.9001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.4140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.5555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.9521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.5451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6042 val_loss 0.4135 val_acc 0.8723\nB4 Fold 3 Epoch 9/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.3114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.4029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.1603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.3250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.4313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.6652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.9580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.3752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.4482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.8609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.3155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.2688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 1.3286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5632 val_loss 0.4162 val_acc 0.8715\n  Early stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/1822884949.py:160: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 3 best_acc 0.8750\n===== B4 Fold 4 start: train 14977 valid 3744 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/144154569.py:23: UserWarning: Argument(s) 'value' are not valid for transform Affine\n  A.Affine(\n/tmp/ipykernel_1823/144154569.py:30: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n  A.CoarseDropout(\n/tmp/ipykernel_1823/144154569.py:43: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=size, min_width=size, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 4 Epoch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 3.1940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 2.5770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.4517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.9734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 1.4398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 1.1588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.8997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.6635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 1.1189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 1.5604\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.8363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.8168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.7419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 1.2465 val_loss 1.1654 val_acc 0.5855\nB4 Fold 4 Epoch 2/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.7122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.5386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.9397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.5838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.8413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.5485\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 1.3687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 1.3984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 1.1732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 1.1624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.8518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.6621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.9896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.8149 val_loss 0.7389 val_acc 0.7372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 4 Epoch 3/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.9738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.9241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.9023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.6743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.5874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.8252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.5360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.3551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.7765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.4645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 1.0762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.8032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.5363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.7182 val_loss 0.5028 val_acc 0.8355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 4 Epoch 4/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.7358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.6965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.7655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.4263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.4994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.5813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.7240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.6159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.5846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.5165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.9528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.7258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.7191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.7015 val_loss 0.4405 val_acc 0.8576\nB4 Fold 4 Epoch 5/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.3216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.8441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 1.0773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.3798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 1.2502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.9454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.4166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 1.0986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.8147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 1.1123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.7952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.4023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.7655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6543 val_loss 0.4191 val_acc 0.8683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 4 Epoch 6/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.4174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.4470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.5015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.3117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.9164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 1.3831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.4397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.3939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.7984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 1.0101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.3139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.4252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.3518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6263 val_loss 0.4075 val_acc 0.8683\nB4 Fold 4 Epoch 7/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.3002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.5934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.4732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 1.3081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.6225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.5077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.3407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.5997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 1.1783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.3712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.6992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.5698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.3891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.6268 val_loss 0.4077 val_acc 0.8710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 4 Epoch 8/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.8565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.6147\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.4916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.4221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.9570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.7501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.8455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.2706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.9076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.5072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.3204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.8560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.4101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5871 val_loss 0.4133 val_acc 0.8702\nB4 Fold 4 Epoch 9/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.2667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 1.1506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.8952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.8380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.6669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.8083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.4114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 1.1431\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 1.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.8886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.3116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 1.1394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5790 val_loss 0.4241 val_acc 0.8721\nB4 Fold 4 Epoch 10/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.3049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.3819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.8468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.2959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.6345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.5052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.7154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.5091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.2679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.6548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.8087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.3114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5545 val_loss 0.4319 val_acc 0.8713\nB4 Fold 4 Epoch 11/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 1.1243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.3806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.2676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.2830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.7178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.2713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.3465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.9792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.3344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.8262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.4426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.3436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.2514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5505 val_loss 0.4370 val_acc 0.8694\nB4 Fold 4 Epoch 12/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 0/624 loss 0.8564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 50/624 loss 0.8863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 100/624 loss 0.3461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 150/624 loss 0.3093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 200/624 loss 0.3103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 250/624 loss 0.6685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 300/624 loss 0.9020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 350/624 loss 0.7570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 400/624 loss 0.2982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 450/624 loss 0.6664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 500/624 loss 0.2918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 550/624 loss 0.6268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  iter 600/624 loss 0.9666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  train_loss 0.5509 val_loss 0.4418 val_acc 0.8691\n  Early stopping triggered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/1822884949.py:160: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B4 Fold 4 best_acc 0.8721\nSaved test logits to test_logits_tf_efficientnet_b4_ns_512.npy with shape (2676, 5)\n"
          ]
        }
      ]
    },
    {
      "id": "5e9d28f3-2ded-44d7-93f3-17167848ea0b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ensemble utility: blend convnext and effnet logits to submission\n",
        "import numpy as np, pandas as pd, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def make_df_test():\n",
        "    return pd.DataFrame({'image_id': sorted([p.name for p in Path(test_dir).glob('*.jpg')])})\n",
        "\n",
        "def blend_and_write_submission(weights=(0.5, 0.5),\n",
        "                               cnx_path='test_logits_convnext_base_448.npy',\n",
        "                               b4_path='test_logits_tf_efficientnet_b4_ns_512.npy',\n",
        "                               out_csv='submission_blend.csv'):\n",
        "    w0, w1 = weights\n",
        "    assert abs(w0 + w1 - 1.0) < 1e-6, 'weights must sum to 1'\n",
        "    paths = [cnx_path, b4_path]\n",
        "    avail = [Path(p).exists() for p in paths]\n",
        "    if not all(avail):\n",
        "        missing = [p for p, ok in zip(paths, avail) if not ok]\n",
        "        print('Missing logits:', missing);\n",
        "        return None\n",
        "    L0 = np.load(cnx_path)\n",
        "    L1 = np.load(b4_path)\n",
        "    assert L0.shape == L1.shape, f'Logit shapes differ: {L0.shape} vs {L1.shape}'\n",
        "    logits = w0 * L0 + w1 * L1\n",
        "    preds = logits.argmax(1).astype(int)\n",
        "    df_test = make_df_test()\n",
        "    assert len(df_test) == len(preds), f'Test length mismatch: {len(df_test)} vs {len(preds)}'\n",
        "    sub = pd.DataFrame({'image_id': df_test['image_id'], 'label': preds})\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print(f'Saved {out_csv} (weights={weights}) shape:', sub.shape)\n",
        "    return out_csv\n",
        "\n",
        "print('Ensembling cell ready. After both logits .npy exist, call blend_and_write_submission().')\n",
        "\n",
        "# Auto-blend when both logits are present; also copy to submission.csv for grading\n",
        "cnx_p = 'test_logits_convnext_base_448.npy'\n",
        "b4_p = 'test_logits_tf_efficientnet_b4_ns_512.npy'\n",
        "if Path(cnx_p).exists() and Path(b4_p).exists():\n",
        "    out = blend_and_write_submission((0.5, 0.5), cnx_path=cnx_p, b4_path=b4_p, out_csv='submission_blend.csv')\n",
        "    if out is not None:\n",
        "        shutil.copyfile(out, 'submission.csv')\n",
        "        print('Copied blend to submission.csv')\n",
        "else:\n",
        "    print('Blend not run yet: waiting for both logits .npy files to exist.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c458d17a-ce17-47dc-950a-255439db1192",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OOF-based probability blend with optional temperature scaling; writes final submission.csv\n",
        "import numpy as np, pandas as pd, shutil, os\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "\n",
        "def softmax_np(x):\n",
        "    x = x - x.max(axis=1, keepdims=True)\n",
        "    ex = np.exp(x)\n",
        "    return ex / ex.sum(axis=1, keepdims=True)\n",
        "\n",
        "def nll_loss(probs, y_true):\n",
        "    probs = np.clip(probs, 1e-9, 1.0)\n",
        "    return log_loss(y_true, probs, labels=[0,1,2,3,4])\n",
        "\n",
        "def temperature_scale_logits(logits, T):\n",
        "    return logits / float(T)\n",
        "\n",
        "def find_temperature_on_oof(logits, y_true, T_grid=None):\n",
        "    if T_grid is None:\n",
        "        T_grid = [round(t,2) for t in np.arange(0.7, 1.81, 0.1)]\n",
        "    best_T, best_nll = 1.0, 1e9\n",
        "    for T in T_grid:\n",
        "        probs = softmax_np(temperature_scale_logits(logits, T))\n",
        "        nll = nll_loss(probs, y_true)\n",
        "        if nll < best_nll:\n",
        "            best_nll, best_T = nll, T\n",
        "    return best_T, best_nll\n",
        "\n",
        "def grid_search_weight(P0, P1, y_true, w_grid=None):\n",
        "    if w_grid is None:\n",
        "        # Include endpoints 0.0 (B4-only) and 1.0 (ConvNeXt-only)\n",
        "        w_grid = [round(w,2) for w in np.arange(0.0, 1.0001, 0.01)]\n",
        "    best_w, best_acc = 0.5, -1\n",
        "    for w in w_grid:\n",
        "        P = w * P0 + (1 - w) * P1\n",
        "        preds = P.argmax(1)\n",
        "        acc = accuracy_score(y_true, preds)\n",
        "        if acc > best_acc:\n",
        "            best_acc, best_w = acc, w\n",
        "    return best_w, best_acc\n",
        "\n",
        "def run_oof_tuned_blend_and_submit(\n",
        "    cnx_oof_path='oof_logits_convnext_base_448.npy',\n",
        "    b4_oof_path='oof_logits_tf_efficientnet_b4_ns_512.npy',\n",
        "    cnx_test_path='test_logits_convnext_base_448.npy',\n",
        "    b4_test_path='test_logits_tf_efficientnet_b4_ns_512.npy',\n",
        "    do_temperature=True,\n",
        "    out_csv='submission_blend_optimized.csv'\n",
        "):\n",
        "    paths = [cnx_oof_path, b4_oof_path, cnx_test_path, b4_test_path]\n",
        "    missing = [p for p in paths if not Path(p).exists()]\n",
        "    if missing:\n",
        "        print('Missing artifacts, cannot blend yet:', missing)\n",
        "        return None\n",
        "    # Load\n",
        "    L0_oof = np.load(cnx_oof_path)\n",
        "    L1_oof = np.load(b4_oof_path)\n",
        "    L0_test = np.load(cnx_test_path)\n",
        "    L1_test = np.load(b4_test_path)\n",
        "    assert L0_oof.shape == L1_oof.shape, f'OOF shapes mismatch: {L0_oof.shape} vs {L1_oof.shape}'\n",
        "    assert L0_test.shape == L1_test.shape, f'Test shapes mismatch: {L0_test.shape} vs {L1_test.shape}'\n",
        "    # True labels from current df (aligned with training order)\n",
        "    y_true = df['label'].to_numpy().astype(int)\n",
        "    assert len(y_true) == L0_oof.shape[0], 'OOF rows must match df length'\n",
        "    # Optional temperature scaling per model (fit on OOF NLL)\n",
        "    if do_temperature:\n",
        "        T0, nll0 = find_temperature_on_oof(L0_oof, y_true)\n",
        "        T1, nll1 = find_temperature_on_oof(L1_oof, y_true)\n",
        "        print(f'ConvNeXt T*={T0} OOF-NLL={nll0:.4f}; B4 T*={T1} OOF-NLL={nll1:.4f}')\n",
        "        L0_oof, L0_test = L0_oof / T0, L0_test / T0\n",
        "        L1_oof, L1_test = L1_oof / T1, L1_test / T1\n",
        "    # Convert to probabilities\n",
        "    P0_oof = softmax_np(L0_oof)\n",
        "    P1_oof = softmax_np(L1_oof)\n",
        "    # Weight search on OOF accuracy\n",
        "    w_best, acc_best = grid_search_weight(P0_oof, P1_oof, y_true)\n",
        "    print(f'Best OOF blend weight w (convnext) = {w_best:.2f}, OOF-acc={acc_best:.5f}')\n",
        "    # Apply to test\n",
        "    P0_test = softmax_np(L0_test)\n",
        "    P1_test = softmax_np(L1_test)\n",
        "    P_test = w_best * P0_test + (1 - w_best) * P1_test\n",
        "    preds = P_test.argmax(1).astype(int)\n",
        "    df_test = pd.DataFrame({'image_id': sorted([p.name for p in Path(test_dir).glob('*.jpg')])})\n",
        "    assert len(df_test) == len(preds), 'Test length mismatch'\n",
        "    sub = pd.DataFrame({'image_id': df_test['image_id'], 'label': preds})\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print('Saved', out_csv, 'and copied to submission.csv. Shape:', sub.shape)\n",
        "    return out_csv, w_best, acc_best\n",
        "\n",
        "print('OOF-tuned blending cell ready. After B4 finishes and npys exist, call:')\n",
        "print(\"run_oof_tuned_blend_and_submit(out_csv='submission.csv')\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF-tuned blending cell ready. After B4 finishes and npys exist, call:\nrun_oof_tuned_blend_and_submit(out_csv='submission.csv')\n"
          ]
        }
      ]
    },
    {
      "id": "44cd6030-7a96-4719-9f81-d38d0d993539",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Execute OOF-tuned blend and write submission.csv\n",
        "res = run_oof_tuned_blend_and_submit(out_csv='submission_blend_optimized.csv')\n",
        "print('Blend result:', res)\n",
        "check_submission_format('submission.csv')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNeXt T*=1.0 OOF-NLL=0.3648; B4 T*=0.8 OOF-NLL=0.4138\nBest OOF blend weight w (convnext) = 0.72, OOF-acc=0.89397\nSaved submission_blend_optimized.csv and copied to submission.csv. Shape: (2676, 2)\nBlend result: ('submission_blend_optimized.csv', 0.72, 0.8939693392446985)\nSubmission cols OK: True Labels int[0..4]: True Shape: (2676, 2)\nLabel value_counts: {3: 1669, 4: 337, 1: 279, 2: 257, 0: 134}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "id": "9ba8865c-fcfc-4d02-887d-ee9bcaf33b8f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Try multiple ensemble options (no-temp vs temp) and convnext-only; pick best by OOF acc; write submission.csv\n",
        "import numpy as np, pandas as pd, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def eval_oof_acc_from_logits(logits, y_true):\n",
        "    preds = logits.argmax(1)\n",
        "    return (preds == y_true).mean()\n",
        "\n",
        "def run_ensemble_search_and_submit():\n",
        "    # Load artifacts\n",
        "    L0_oof = np.load('oof_logits_convnext_base_448.npy')\n",
        "    L1_oof = np.load('oof_logits_tf_efficientnet_b4_ns_512.npy')\n",
        "    L0_test = np.load('test_logits_convnext_base_448.npy')\n",
        "    L1_test = np.load('test_logits_tf_efficientnet_b4_ns_512.npy')\n",
        "    y_true = df['label'].to_numpy().astype(int)\n",
        "    # Baselines: single-model OOF accuracies\n",
        "    acc_cnx = eval_oof_acc_from_logits(L0_oof, y_true)\n",
        "    acc_b4  = eval_oof_acc_from_logits(L1_oof, y_true)\n",
        "    print(f'OOF acc single: convnext={acc_cnx:.5f}, b4={acc_b4:.5f}')\n",
        "    # Option A: no temperature\n",
        "    P0_oof_nt = softmax_np(L0_oof); P1_oof_nt = softmax_np(L1_oof)\n",
        "    wA, accA = grid_search_weight(P0_oof_nt, P1_oof_nt, y_true)\n",
        "    print(f'No-temp best w={wA:.2f} OOF-acc={accA:.5f}')\n",
        "    # Option B: with temperature (refit)\n",
        "    T0, _ = find_temperature_on_oof(L0_oof, y_true);\n",
        "    T1, _ = find_temperature_on_oof(L1_oof, y_true);\n",
        "    P0_oof_t = softmax_np(L0_oof / T0); P1_oof_t = softmax_np(L1_oof / T1)\n",
        "    wB, accB = grid_search_weight(P0_oof_t, P1_oof_t, y_true)\n",
        "    print(f'Temp best w={wB:.2f} (T0={T0}, T1={T1}) OOF-acc={accB:.5f}')\n",
        "    # Decide best option by OOF acc among: convnext-only, no-temp blend, temp blend\n",
        "    choices = [\n",
        "        ('convnext_only', acc_cnx, 1.0, False, 1.0, 1.0),\n",
        "        ('blend_no_temp', accA, wA, False, 1.0, 1.0),\n",
        "        ('blend_temp', accB, wB, True, T0, T1)\n",
        "    ]\n",
        "    choices.sort(key=lambda x: x[1], reverse=True)\n",
        "    name_best, acc_best, w_best, use_temp, t0, t1 = choices[0]\n",
        "    print(f'Chosen {name_best} with OOF-acc={acc_best:.5f}, w={w_best:.2f}, use_temp={use_temp}')\n",
        "    # Build test probabilities per choice\n",
        "    if name_best == 'convnext_only':\n",
        "        preds = L0_test.argmax(1).astype(int)\n",
        "        out_csv = 'submission_convnext_only.csv'\n",
        "    else:\n",
        "        if use_temp:\n",
        "            P0_test = softmax_np(L0_test / t0)\n",
        "            P1_test = softmax_np(L1_test / t1)\n",
        "        else:\n",
        "            P0_test = softmax_np(L0_test)\n",
        "            P1_test = softmax_np(L1_test)\n",
        "        P_test = w_best * P0_test + (1 - w_best) * P1_test\n",
        "        preds = P_test.argmax(1).astype(int)\n",
        "        out_csv = f'submission_{name_best}.csv'\n",
        "    df_test = pd.DataFrame({'image_id': sorted([p.name for p in Path(test_dir).glob('*.jpg')])})\n",
        "    sub = pd.DataFrame({'image_id': df_test['image_id'], 'label': preds})\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print('Wrote', out_csv, 'and copied to submission.csv')\n",
        "    check_submission_format('submission.csv')\n",
        "    return {'choice': name_best, 'oof_acc': float(acc_best), 'w': float(w_best), 'use_temp': use_temp, 'T0': float(t0), 'T1': float(t1)}\n",
        "\n",
        "print('Ensemble search cell ready. Call run_ensemble_search_and_submit() to regenerate submission.csv with the best OOF option.')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble search cell ready. Call run_ensemble_search_and_submit() to regenerate submission.csv with the best OOF option.\n"
          ]
        }
      ]
    },
    {
      "id": "a4013964-ae41-45ba-81df-0222ce6aba5f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run ensemble search and regenerate submission.csv with best OOF option\n",
        "res_search = run_ensemble_search_and_submit()\n",
        "print('Search result:', res_search)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF acc single: convnext=0.89125, b4=0.86790\nNo-temp best w=0.66 OOF-acc=0.89386\nTemp best w=0.72 (T0=1.0, T1=0.8) OOF-acc=0.89397\nChosen blend_temp with OOF-acc=0.89397, w=0.72, use_temp=True\nWrote submission_blend_temp.csv and copied to submission.csv\nSubmission cols OK: True Labels int[0..4]: True Shape: (2676, 2)\nLabel value_counts: {3: 1669, 4: 337, 1: 279, 2: 257, 0: 134}\nSearch result: {'choice': 'blend_temp', 'oof_acc': 0.8939693392446985, 'w': 0.72, 'use_temp': True, 'T0': 1.0, 'T1': 0.8}\n"
          ]
        }
      ]
    },
    {
      "id": "451a5d24-be1b-46c2-9dcd-adc664ecd83d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate stronger B4 test logits with extended TTA (base, hflip, vflip, rot\u00b110) across 5 folds\n",
        "import numpy as np, torch, timm, os, math, time\n",
        "from pathlib import Path\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "\n",
        "def build_b4_for_infer(num_classes=5):\n",
        "    m = timm.create_model('tf_efficientnet_b4_ns', pretrained=False, num_classes=num_classes)\n",
        "    m = m.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    if torch.cuda.is_available():\n",
        "        m = m.to(memory_format=torch.channels_last)\n",
        "    m.eval()\n",
        "    return m\n",
        "\n",
        "def make_infer_tfms(sz=512, angle=0):\n",
        "    # Rotate around center before pad/normalize\n",
        "    return A.Compose([\n",
        "        A.LongestMaxSize(max_size=sz),\n",
        "        A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n",
        "        A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n",
        "        A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "def infer_model_with_tta(model, df_test, img_dir, batch_size=32, size=512):\n",
        "    device = next(model.parameters()).device\n",
        "    # TTA plan: (angle, hflip, vflip) - add -10 with hflip for symmetry\n",
        "    tta_specs = [\n",
        "        (0, False, False),\n",
        "        (0, True,  False),\n",
        "        (0, False, True),\n",
        "        (+10, False, False),\n",
        "        (-10, False, False),\n",
        "        (+10, True,  False),\n",
        "        (-10, True,  False),\n",
        "    ]\n",
        "    logits_accum = None\n",
        "    for (ang, hf, vf) in tta_specs:\n",
        "        tfms = make_infer_tfms(size, angle=ang)\n",
        "        ds = CassavaDataset(df_test[['image_id']].copy(), img_dir, transforms=tfms)\n",
        "        dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=CFG_B4.num_workers, pin_memory=True)\n",
        "        part_logits = []\n",
        "        with torch.no_grad():\n",
        "            for x, ids in dl:\n",
        "                if hf:\n",
        "                    x = torch.flip(x, dims=[-1])\n",
        "                if vf:\n",
        "                    x = torch.flip(x, dims=[-2])\n",
        "                x = x.to(device, non_blocking=True)\n",
        "                if torch.cuda.is_available():\n",
        "                    x = x.to(memory_format=torch.channels_last)\n",
        "                with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n",
        "                    lg = model(x)\n",
        "                part_logits.append(lg.float().cpu().numpy())\n",
        "        logits_tta = np.concatenate(part_logits, axis=0)\n",
        "        if logits_accum is None:\n",
        "            logits_accum = logits_tta\n",
        "        else:\n",
        "            logits_accum += logits_tta\n",
        "    logits_mean = logits_accum / len(tta_specs)\n",
        "    return logits_mean\n",
        "\n",
        "def build_df_test():\n",
        "    return pd.DataFrame({'image_id': sorted([p.name for p in Path(test_dir).glob('*.jpg')])})\n",
        "\n",
        "def compute_b4_test_logits_extended_tta():\n",
        "    df_test_local = build_df_test()\n",
        "    fold_paths = [f'ckpt_tf_efficientnet_b4_ns_512_fold{i}.pth' for i in range(5)]\n",
        "    for p in fold_paths:\n",
        "        assert Path(p).exists(), f'Missing {p}'\n",
        "    fold_logits = []\n",
        "    start_all = time.time()\n",
        "    for i, ckpt_path in enumerate(fold_paths):\n",
        "        t0 = time.time()\n",
        "        model = build_b4_for_infer(num_classes=5)\n",
        "        state = torch.load(ckpt_path, map_location='cpu')\n",
        "        model.load_state_dict(state, strict=True)\n",
        "        lg = infer_model_with_tta(model, df_test_local, test_dir, batch_size=CFG_B4.batch_size, size=CFG_B4.img_size)\n",
        "        fold_logits.append(lg)\n",
        "        print(f'Fold {i} TTA inference done. Shape {lg.shape}. Elapsed {time.time()-t0:.1f}s')\n",
        "        del model; torch.cuda.empty_cache()\n",
        "    logits_mean = np.mean(fold_logits, axis=0)\n",
        "    np.save('test_logits_tf_efficientnet_b4_ns_512_tta7.npy', logits_mean)\n",
        "    # Also overwrite the default path so downstream blend uses improved logits without code changes\n",
        "    np.save('test_logits_tf_efficientnet_b4_ns_512.npy', logits_mean)\n",
        "    print('Saved enhanced B4 test logits to test_logits_tf_efficientnet_b4_ns_512_tta7.npy and updated default .npy. Total elapsed', f'{time.time()-start_all:.1f}s')\n",
        "    return logits_mean\n",
        "\n",
        "print('Extended TTA cell ready. Call compute_b4_test_logits_extended_tta() to refresh B4 test logits and then re-run the ensemble cell.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extended TTA cell ready. Call compute_b4_test_logits_extended_tta() to refresh B4 test logits and then re-run the ensemble cell.\n"
          ]
        }
      ]
    },
    {
      "id": "7bf9fbf9-da42-4938-bd1e-bc80e4249a6d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run extended B4 TTA inference, then re-run ensemble search and regenerate submission.csv\n",
        "res_tta = compute_b4_test_logits_extended_tta()\n",
        "print('Enhanced B4 test logits shape:', res_tta.shape)\n",
        "res_search2 = run_ensemble_search_and_submit()\n",
        "print('Updated search result:', res_search2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location='cpu')\n/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 TTA inference done. Shape (2676, 5). Elapsed 63.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n/tmp/ipykernel_1823/2396798903.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 TTA inference done. Shape (2676, 5). Elapsed 63.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n/tmp/ipykernel_1823/2396798903.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 TTA inference done. Shape (2676, 5). Elapsed 63.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n/tmp/ipykernel_1823/2396798903.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location='cpu')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 TTA inference done. Shape (2676, 5). Elapsed 63.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:76: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(ckpt_path, map_location='cpu')\n/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1823/2396798903.py:20: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n  A.PadIfNeeded(min_height=sz, min_width=sz, border_mode=cv2.BORDER_CONSTANT, value=0),\n/tmp/ipykernel_1823/2396798903.py:21: UserWarning: Argument(s) 'value' are not valid for transform Rotate\n  A.Rotate(limit=(angle, angle), border_mode=cv2.BORDER_CONSTANT, value=0, p=1.0) if angle != 0 else A.NoOp(),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 TTA inference done. Shape (2676, 5). Elapsed 63.5s\nSaved enhanced B4 test logits to test_logits_tf_efficientnet_b4_ns_512_tta6.npy and updated default .npy. Total elapsed 316.7s\nEnhanced B4 test logits shape: (2676, 5)\nOOF acc single: convnext=0.89125, b4=0.86790\nNo-temp best w=0.66 OOF-acc=0.89386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temp best w=0.72 (T0=1.0, T1=0.8) OOF-acc=0.89397\nChosen blend_temp with OOF-acc=0.89397, w=0.72, use_temp=True\nWrote submission_blend_temp.csv and copied to submission.csv\nSubmission cols OK: True Labels int[0..4]: True Shape: (2676, 2)\nLabel value_counts: {3: 1675, 4: 337, 1: 279, 2: 250, 0: 135}\nUpdated search result: {'choice': 'blend_temp', 'oof_acc': 0.8939693392446985, 'w': 0.72, 'use_temp': True, 'T0': 1.0, 'T1': 0.8}\n"
          ]
        }
      ]
    },
    {
      "id": "70072bfa-5839-4328-a95f-dc5dadc4f0b6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Stacking: multinomial logistic regression on concatenated OOF logits; apply to test\n",
        "import numpy as np, pandas as pd, shutil\n",
        "from pathlib import Path\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def stack_lr_on_oof_and_submit(\n",
        "    cnx_oof='oof_logits_convnext_base_448.npy',\n",
        "    b4_oof='oof_logits_tf_efficientnet_b4_ns_512.npy',\n",
        "    cnx_test='test_logits_convnext_base_448.npy',\n",
        "    b4_test='test_logits_tf_efficientnet_b4_ns_512.npy',\n",
        "    C_grid=(0.2, 0.5, 1.0),\n",
        "    max_iter=300,\n",
        "    out_csv='submission_stack_lr.csv'\n",
        "):\n",
        "    if not (Path(cnx_oof).exists() and Path(b4_oof).exists() and Path(cnx_test).exists() and Path(b4_test).exists()):\n",
        "        print('Missing npy artifacts for stacking.'); return None\n",
        "    L0_oof = np.load(cnx_oof); L1_oof = np.load(b4_oof)\n",
        "    L0_test = np.load(cnx_test); L1_test = np.load(b4_test)\n",
        "    assert L0_oof.shape == L1_oof.shape and L0_test.shape == L1_test.shape, 'Shape mismatch'\n",
        "    y = df['label'].to_numpy().astype(int)\n",
        "    X_oof = np.hstack([L0_oof, L1_oof])\n",
        "    X_test = np.hstack([L0_test, L1_test])\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
        "    X_oof_std = scaler.fit_transform(X_oof)\n",
        "    X_test_std = scaler.transform(X_test)\n",
        "    # CV to pick C\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    best_C, best_cv = None, -1.0\n",
        "    for C in C_grid:\n",
        "        accs = []\n",
        "        for tr_idx, va_idx in skf.split(X_oof_std, y):\n",
        "            Xtr, Xva = X_oof_std[tr_idx], X_oof_std[va_idx]\n",
        "            ytr, yva = y[tr_idx], y[va_idx]\n",
        "            clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=C, max_iter=max_iter, n_jobs=None)\n",
        "            clf.fit(Xtr, ytr)\n",
        "            pva = clf.predict(Xva)\n",
        "            accs.append(accuracy_score(yva, pva))\n",
        "        cv_mean = float(np.mean(accs))\n",
        "        print(f'C={C} CV-acc={cv_mean:.5f} fold-accs={accs}')\n",
        "        if cv_mean > best_cv:\n",
        "            best_cv, best_C = cv_mean, C\n",
        "    print(f'Chosen C={best_C} with CV-acc={best_cv:.5f}')\n",
        "    # Fit on all OOF and predict test\n",
        "    clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=best_C, max_iter=max_iter, n_jobs=None)\n",
        "    clf.fit(X_oof_std, y)\n",
        "    proba_test = clf.predict_proba(X_test_std)\n",
        "    preds = proba_test.argmax(1).astype(int)\n",
        "    df_test = pd.DataFrame({'image_id': sorted([p.name for p in Path(test_dir).glob('*.jpg')])})\n",
        "    sub = pd.DataFrame({'image_id': df_test['image_id'], 'label': preds})\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print('Stacking wrote', out_csv, 'and copied to submission.csv; shape:', sub.shape)\n",
        "    check_submission_format('submission.csv')\n",
        "    return {'C': best_C, 'cv_acc': best_cv}\n",
        "\n",
        "print('Stacking cell ready. Call stack_lr_on_oof_and_submit() to try LR meta-ensemble and regenerate submission.csv.')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking cell ready. Call stack_lr_on_oof_and_submit() to try LR meta-ensemble and regenerate submission.csv.\n"
          ]
        }
      ]
    },
    {
      "id": "d146be89-92b7-422f-b771-8da39e600160",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run stacking LR meta-ensemble and regenerate submission.csv\n",
        "res_stack = stack_lr_on_oof_and_submit()\n",
        "print('Stack result:', res_stack)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.2 CV-acc=0.89376 fold-accs=[0.8878504672897196, 0.8987713675213675, 0.9019764957264957, 0.8966346153846154, 0.8835470085470085]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.5 CV-acc=0.89349 fold-accs=[0.8878504672897196, 0.8985042735042735, 0.9017094017094017, 0.8961004273504274, 0.8832799145299145]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=1.0 CV-acc=0.89376 fold-accs=[0.8881174899866489, 0.8987713675213675, 0.9022435897435898, 0.8961004273504274, 0.8835470085470085]\nChosen C=0.2 with CV-acc=0.89376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking wrote submission_stack_lr.csv and copied to submission.csv; shape: (2676, 2)\nSubmission cols OK: True Labels int[0..4]: True Shape: (2676, 2)\nLabel value_counts: {3: 1675, 4: 320, 1: 282, 2: 264, 0: 135}\nStack result: {'C': 0.2, 'cv_acc': 0.8937559908938415}\n"
          ]
        }
      ]
    },
    {
      "id": "1c0b9a07-28d9-4ced-9a1b-9e4bda0b2dbf",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final temp-scaled geometric-mean vs arithmetic blend with fine weight sweep; write submission.csv\n",
        "import numpy as np, pandas as pd, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def row_normalize(P):\n",
        "    P = np.clip(P, 1e-12, 1.0)\n",
        "    P /= P.sum(axis=1, keepdims=True)\n",
        "    return P\n",
        "\n",
        "def geo_mean_blend(P0, P1, w):\n",
        "    # P_final \u221d (P0^w) * (P1^(1-w))\n",
        "    return row_normalize((P0 ** w) * (P1 ** (1.0 - w)))\n",
        "\n",
        "def acc_from_probs(P, y_true):\n",
        "    return (P.argmax(1) == y_true).mean(),\n",
        "\n",
        "def final_geo_arith_blend_and_submit(\n",
        "    cnx_oof='oof_logits_convnext_base_448.npy',\n",
        "    b4_oof='oof_logits_tf_efficientnet_b4_ns_512.npy',\n",
        "    cnx_test='test_logits_convnext_base_448.npy',\n",
        "    b4_test='test_logits_tf_efficientnet_b4_ns_512.npy',\n",
        "    T0=1.0, T1=0.8,\n",
        "    w_lo=0.70, w_hi=0.75, w_step=0.005,\n",
        "    fallback_acc=0.89397,\n",
        "    out_prefix='submission_final_blend'\n",
        "):\n",
        "    paths = [cnx_oof, b4_oof, cnx_test, b4_test]\n",
        "    miss = [p for p in paths if not Path(p).exists()]\n",
        "    if miss:\n",
        "        print('Missing artifacts:', miss); return None\n",
        "    L0_oof = np.load(cnx_oof); L1_oof = np.load(b4_oof)\n",
        "    L0_test = np.load(cnx_test); L1_test = np.load(b4_test)\n",
        "    y = df['label'].to_numpy().astype(int)\n",
        "    # Temp-scaled probabilities\n",
        "    P0_oof = softmax_np(L0_oof / T0); P1_oof = softmax_np(L1_oof / T1)\n",
        "    P0_test = softmax_np(L0_test / T0); P1_test = softmax_np(L1_test / T1)\n",
        "    # Fine grid\n",
        "    W = np.arange(w_lo, w_hi + 1e-9, w_step)\n",
        "    best_geo = (-1.0, None)  # (acc, w)\n",
        "    best_lin = (-1.0, None)\n",
        "    for w in W:\n",
        "        P_geo = geo_mean_blend(P0_oof, P1_oof, w)\n",
        "        acc_geo = (P_geo.argmax(1) == y).mean()\n",
        "        if acc_geo > best_geo[0]: best_geo = (float(acc_geo), float(w))\n",
        "        P_lin = row_normalize(w * P0_oof + (1.0 - w) * P1_oof)\n",
        "        acc_lin = (P_lin.argmax(1) == y).mean()\n",
        "        if acc_lin > best_lin[0]: best_lin = (float(acc_lin), float(w))\n",
        "    print(f'Geo-best: acc={best_geo[0]:.5f} w={best_geo[1]:.3f}; Lin-best: acc={best_lin[0]:.5f} w={best_lin[1]:.3f}')\n",
        "    # Choose method\n",
        "    acc_geo, w_geo = best_geo; acc_lin, w_lin = best_lin\n",
        "    method = 'geo' if acc_geo >= acc_lin and acc_geo >= fallback_acc else ('lin' if acc_lin >= fallback_acc else ('geo' if acc_geo >= acc_lin else 'lin'))\n",
        "    if method == 'geo':\n",
        "        w_sel = w_geo\n",
        "        # Tie-bias toward slightly lower w if extremely close\n",
        "        if abs(acc_geo - acc_lin) < 1e-6 and w_sel > 0.72:\n",
        "            w_sel = max(w_lo, w_sel - 0.01)\n",
        "        P_test = geo_mean_blend(P0_test, P1_test, w_sel)\n",
        "    else:\n",
        "        w_sel = w_lin\n",
        "        P_test = row_normalize(w_sel * P0_test + (1.0 - w_sel) * P1_test)\n",
        "    preds = P_test.argmax(1).astype(int)\n",
        "    df_test = pd.DataFrame({'image_id': sorted([p.name for p in Path(test_dir).glob('*.jpg')])})\n",
        "    sub = pd.DataFrame({'image_id': df_test['image_id'], 'label': preds})\n",
        "    out_csv = f'{out_prefix}_{method}_w{w_sel:.3f}.csv'\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    shutil.copyfile(out_csv, 'submission.csv')\n",
        "    print(f'Wrote {out_csv} using method={method}, w={w_sel:.3f} (OOF geo={acc_geo:.5f}, lin={acc_lin:.5f}); copied to submission.csv')\n",
        "    check_submission_format('submission.csv')\n",
        "    return {'method': method, 'w': w_sel, 'acc_geo': acc_geo, 'acc_lin': acc_lin, 'out_csv': out_csv}\n",
        "\n",
        "print('Final geo/arithmetic blend cell ready. Call final_geo_arith_blend_and_submit() after updating B4 TTA logits.')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final geo/arithmetic blend cell ready. Call final_geo_arith_blend_and_submit() after updating B4 TTA logits.\n"
          ]
        }
      ]
    },
    {
      "id": "1bda523b-aa7c-487d-889b-6d6b41382fdc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final call: run geometric vs arithmetic blend with fine weight sweep and write submission.csv\n",
        "res_final = final_geo_arith_blend_and_submit()\n",
        "print('Final blend result:', res_final)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geo-best: acc=0.89349 w=0.750; Lin-best: acc=0.89402 w=0.730\nWrote submission_final_blend_lin_w0.730.csv using method=lin, w=0.730 (OOF geo=0.89349, lin=0.89402); copied to submission.csv\nSubmission cols OK: True Labels int[0..4]: True Shape: (2676, 2)\nLabel value_counts: {3: 1674, 4: 337, 1: 280, 2: 250, 0: 135}\nFinal blend result: {'method': 'lin', 'w': 0.73, 'acc_geo': 0.8934885956946744, 'acc_lin': 0.8940227551947011, 'out_csv': 'submission_final_blend_lin_w0.730.csv'}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}