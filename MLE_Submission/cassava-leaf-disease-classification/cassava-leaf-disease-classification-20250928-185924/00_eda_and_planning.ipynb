{
  "cells": [
    {
      "id": "5194e873-cc59-4e83-85a7-283d71ceb92e",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cassava Leaf Disease - Plan\n",
        "\n",
        "Objectives:\n",
        "- Win a medal (target accuracy \u2265 0.898 on LB).\n",
        "\n",
        "Initial Plan:\n",
        "1) Environment check (GPU a must).\n",
        "2) Data audit: train.csv, label map, images counts; verify classes.\n",
        "3) Validation: StratifiedKFold (5 folds), fixed seed, deterministic, save OOF.\n",
        "4) Baseline model (fast): timm pretrained CNN (e.g., tf_efficientnet_b3_ns or convnext_small), img_size\u2248384, CE loss with label smoothing, basic augs, cosine LR, 1\u20132 epochs smoke, then full.\n",
        "5) Improve: resolutions (448/512), stronger augs (RandAug/AA + CutMix/MixUp), EMA, amp, balance sampler.\n",
        "6) Ensembling: 2\u20133 diverse backbones + seeds; weighted average of logits.\n",
        "7) Error analysis from OOF by class; tweak augs/resize.\n",
        "\n",
        "Milestones (request expert review at each):\n",
        "- After plan (now), after data audit/EDA, after baseline OOF, after improved model, before long trainings, before blending.\n",
        "\n",
        "Submission:\n",
        "- Predict test_images, save submission.csv with columns: image_id, label.\n",
        "\n",
        "Timing:\n",
        "- Start with smoke (1 epoch, 1 fold) to validate pipeline; then 5-fold full.\n",
        "\n",
        "Notes:\n",
        "- Use AMP, cudnn benchmark, deterministic seed.\n",
        "- Log times and per-epoch metrics; save best per fold.\n",
        "- Cache test preds/logits for blends."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "342fc6d7-8c47-457b-a179-3cf561327ae9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment check, GPU, and data audit\n",
        "import os, sys, json, time, shutil, subprocess\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "def run(cmd):\n",
        "    print(\"$\", \" \".join(cmd), flush=True)\n",
        "    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True).stdout\n",
        "\n",
        "start_ts = time.time()\n",
        "print(\"=== NVIDIA SMI ===\", flush=True)\n",
        "print(run(['bash','-lc','nvidia-smi || true']))\n",
        "\n",
        "# Try import torch; if missing or wrong CUDA build, install the cu121 stack\n",
        "need_install = False\n",
        "try:\n",
        "    import torch, torchvision, torchaudio  # noqa\n",
        "    from importlib.metadata import version\n",
        "    torch_cuda = getattr(torch.version, 'cuda', None)\n",
        "    has_cuda = torch.cuda.is_available()\n",
        "    print(f\"torch: {torch.__version__}, built CUDA: {torch_cuda}, CUDA available: {has_cuda}\")\n",
        "    if not (torch_cuda and str(torch_cuda).startswith('12.1') and has_cuda):\n",
        "        need_install = True\n",
        "except Exception as e:\n",
        "    print(\"Torch import failed:\", e)\n",
        "    need_install = True\n",
        "\n",
        "if need_install:\n",
        "    print(\"Installing PyTorch cu121 stack...\", flush=True)\n",
        "    # Uninstall any existing\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'torch', 'torchvision', 'torchaudio'], check=False)\n",
        "    # Clean potential shadow dirs\n",
        "    for d in (\n",
        "        \"/app/.pip-target/torch\",\n",
        "        \"/app/.pip-target/torchvision\",\n",
        "        \"/app/.pip-target/torchaudio\",\n",
        "        \"/app/.pip-target/torchgen\",\n",
        "        \"/app/.pip-target/functorch\",\n",
        "    ):\n",
        "        if os.path.exists(d):\n",
        "            print(\"Removing\", d); shutil.rmtree(d, ignore_errors=True)\n",
        "    # Install exact versions for CUDA 12.1\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install',\n",
        "                    '--index-url', 'https://download.pytorch.org/whl/cu121',\n",
        "                    '--extra-index-url', 'https://pypi.org/simple',\n",
        "                    'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1'], check=True)\n",
        "    Path('constraints.txt').write_text(\"torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n\")\n",
        "    import torch\n",
        "    print(\"torch:\", torch.__version__, \"built CUDA:\", getattr(torch.version, 'cuda', None))\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f\"Wrong CUDA build: {torch.version.cuda}\"\n",
        "    assert torch.cuda.is_available(), \"CUDA not available\"\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "print(\"=== Paths ===\")\n",
        "CWD = Path.cwd()\n",
        "DATA_DIR = CWD\n",
        "train_csv_path = DATA_DIR / 'train.csv'\n",
        "sample_sub_path = DATA_DIR / 'sample_submission.csv'\n",
        "label_map_path = DATA_DIR / 'label_num_to_disease_map.json'\n",
        "train_img_dir = DATA_DIR / 'train_images'\n",
        "test_img_dir = DATA_DIR / 'test_images'\n",
        "\n",
        "print(\"CWD:\", CWD)\n",
        "print(\"Train CSV exists:\", train_csv_path.exists())\n",
        "print(\"Sample submission exists:\", sample_sub_path.exists())\n",
        "print(\"Label map exists:\", label_map_path.exists())\n",
        "print(\"Train images dir:\", train_img_dir.exists(), \"count:\", len(list(train_img_dir.glob('*.jpg'))))\n",
        "print(\"Test images dir:\", test_img_dir.exists(), \"count:\", len(list(test_img_dir.glob('*.jpg'))))\n",
        "\n",
        "df = pd.read_csv(train_csv_path)\n",
        "print(\"Train shape:\", df.shape)\n",
        "print(df.head(3))\n",
        "print(\"Label value counts:\\n\", df['label'].value_counts())\n",
        "\n",
        "with open(label_map_path) as f:\n",
        "    label_map = json.load(f)\n",
        "print(\"Label map:\", label_map)\n",
        "\n",
        "ss = pd.read_csv(sample_sub_path)\n",
        "print(\"Sample submission shape:\", ss.shape)\n",
        "print(ss.head(3))\n",
        "\n",
        "# Sanity: all train files exist\n",
        "missing_train = [im for im in df['image_id'].tolist() if not (train_img_dir / im).exists()]\n",
        "print(\"Missing train images:\", len(missing_train))\n",
        "if missing_train[:5]:\n",
        "    print(\"Example missing:\", missing_train[:5])\n",
        "\n",
        "# Sanity: test files match sample submission\n",
        "test_ids = set([p.name for p in test_img_dir.glob('*.jpg')])\n",
        "ss_ids = set(ss['image_id'].astype(str))\n",
        "missing_in_fs = [im for im in ss_ids if im not in test_ids]\n",
        "extra_in_fs = [im for im in test_ids if im not in ss_ids]\n",
        "print(f\"SampleSub ids not in test dir: {len(missing_in_fs)} | test files not in sampleSub: {len(extra_in_fs)}\")\n",
        "\n",
        "elapsed = time.time() - start_ts\n",
        "print(f\"Setup and audit done in {elapsed:.1f}s\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NVIDIA SMI ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ bash -lc nvidia-smi || true\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 28 19:10:10 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\nTorch import failed: No module named 'torch'\nInstalling PyTorch cu121 stack...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\nWARNING: Skipping torchvision as it is not installed.\nWARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 553.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 450.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 266.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 197.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 161.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 257.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 237.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 301.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 334.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 509.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 231.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 267.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 191.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 498.9 MB/s eta 0:00:00\nCollecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 525.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 93.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 198.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 454.8 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 509.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 122.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 205.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 289.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 202.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.3 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 built CUDA: 12.1\nCUDA available: True\nGPU: NVIDIA A10-24Q\n=== Paths ===\nCWD: /var/lib/simon/agent_run_states/cassava-leaf-disease-classification-20250928-185924\nTrain CSV exists: True\nSample submission exists: True\nLabel map exists: True\nTrain images dir: True count: 18721\nTest images dir: True count: 2676\nTrain shape: (18721, 2)\n         image_id  label\n0  1000015157.jpg      0\n1  1000201771.jpg      3\n2   100042118.jpg      1\nLabel value counts:\n label\n3    11523\n4     2267\n2     2091\n1     1901\n0      939\nName: count, dtype: int64\nLabel map: {'0': 'Cassava Bacterial Blight (CBB)', '1': 'Cassava Brown Streak Disease (CBSD)', '2': 'Cassava Green Mottle (CGM)', '3': 'Cassava Mosaic Disease (CMD)', '4': 'Healthy'}\nSample submission shape: (2676, 2)\n         image_id  label\n0  1234294272.jpg      4\n1  1234332763.jpg      4\n2  1234375577.jpg      4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing train images: 0\nSampleSub ids not in test dir: 0 | test files not in sampleSub: 0\nSetup and audit done in 66.3s\n"
          ]
        }
      ]
    },
    {
      "id": "08d4e9bc-0544-491a-82a0-fbb584e1d9b4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Dependencies, folds, and dataset setup (baseline)\n",
        "import sys, subprocess, os, random\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Install missing deps: timm, albumentations, albucore, opencv (without pulling torch deps)\n",
        "def pip_install_pkgs():\n",
        "    need = []\n",
        "    try:\n",
        "        import timm  # noqa\n",
        "    except Exception:\n",
        "        need.append('timm==0.9.16')\n",
        "    try:\n",
        "        import albumentations  # noqa\n",
        "    except Exception:\n",
        "        need.append('albumentations==1.4.14')\n",
        "    # Ensure albucore for recent albumentations\n",
        "    try:\n",
        "        import albucore  # noqa\n",
        "    except Exception:\n",
        "        need.append('albucore==0.0.33')\n",
        "    try:\n",
        "        import cv2  # noqa\n",
        "    except Exception:\n",
        "        need.append('opencv-python-headless')\n",
        "    if need:\n",
        "        print('Installing (no-deps to avoid torch re-install):', need, flush=True)\n",
        "        cmd = [sys.executable, '-m', 'pip', 'install', '--no-deps', *need, '--upgrade-strategy', 'only-if-needed']\n",
        "        subprocess.run(cmd, check=True)\n",
        "    else:\n",
        "        print('All deps present.')\n",
        "\n",
        "pip_install_pkgs()\n",
        "\n",
        "import cv2\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "print('Versions -> torch:', torch.__version__, 'timm:', getattr(timm, '__version__', 'n/a'), 'albumentations:', getattr(A, '__version__', 'n/a'), 'cv2:', cv2.__version__)\n",
        "\n",
        "# Seed and perf setup\n",
        "SEED = 42\n",
        "def seed_everything(seed=SEED):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "    cudnn.deterministic = False; cudnn.benchmark = True\n",
        "seed_everything(SEED)\n",
        "\n",
        "# Paths\n",
        "CWD = Path.cwd()\n",
        "train_csv_path = CWD / 'train.csv'\n",
        "train_img_dir = CWD / 'train_images'\n",
        "test_img_dir = CWD / 'test_images'\n",
        "\n",
        "# Create stratified folds\n",
        "df = pd.read_csv(train_csv_path)\n",
        "if 'fold' not in df.columns:\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    df['fold'] = -1\n",
        "    for i, (_, val_idx) in enumerate(skf.split(df, df['label'])):\n",
        "        df.loc[val_idx, 'fold'] = i\n",
        "    df.to_csv('folds.csv', index=False)\n",
        "    print('Saved folds.csv with 5 folds')\n",
        "else:\n",
        "    df.to_csv('folds.csv', index=False)\n",
        "    print('Found existing fold column; saved folds.csv')\n",
        "\n",
        "# Transforms\n",
        "IMG_SIZE = 384\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "train_tfms = A.Compose([\n",
        "    A.RandomResizedCrop(IMG_SIZE, IMG_SIZE, scale=(0.8, 1.0), ratio=(0.9, 1.1), p=1.0),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.2),\n",
        "    A.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.02, p=0.5),\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "valid_tfms = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.CenterCrop(IMG_SIZE, IMG_SIZE),\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "class CassavaDS(Dataset):\n",
        "    def __init__(self, df, img_dir, transform):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transform = transform\n",
        "        self.has_labels = 'label' in df.columns\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['image_id']\n",
        "        img = cv2.imread(str(img_path))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)['image']\n",
        "        if self.has_labels:\n",
        "            label = int(row['label'])\n",
        "            return img, label\n",
        "        else:\n",
        "            return img, row['image_id']\n",
        "\n",
        "def get_model(num_classes=5):\n",
        "    model = timm.create_model('tf_efficientnet_b3_ns', pretrained=True, num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "print('Setup complete. Ready to train a smoke 1-fold run next.')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KernelDied",
          "evalue": "Kernel died unexpectedly.",
          "traceback": []
        }
      ]
    },
    {
      "id": "dad7efee-e0e1-416b-ad12-7262d67066ea",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Smoke training loop (self-contained, uses torchvision transforms to avoid albumentations deps) + submission\n",
        "import time\n",
        "import torch\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tqdm.auto import tqdm\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms as T\n",
        "import timm\n",
        "\n",
        "# Ensure df, paths, and transforms exist\n",
        "CWD = Path.cwd()\n",
        "if 'df' not in globals():\n",
        "    if (CWD / 'folds.csv').exists():\n",
        "        df = pd.read_csv(CWD / 'folds.csv')\n",
        "    else:\n",
        "        df = pd.read_csv(CWD / 'train.csv')\n",
        "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        df['fold'] = -1\n",
        "        for i, (_, val_idx) in enumerate(skf.split(df, df['label'])):\n",
        "            df.loc[val_idx, 'fold'] = i\n",
        "        df.to_csv('folds.csv', index=False)\n",
        "\n",
        "if 'train_img_dir' not in globals():\n",
        "    train_img_dir = CWD / 'train_images'\n",
        "if 'test_img_dir' not in globals():\n",
        "    test_img_dir = CWD / 'test_images'\n",
        "\n",
        "IMG_SIZE = 384\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "train_tfms = T.Compose([\n",
        "    T.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomVerticalFlip(p=0.2),\n",
        "    T.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15, hue=0.02),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=mean, std=std),\n",
        "])\n",
        "valid_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=mean, std=std),\n",
        "])\n",
        "\n",
        "class CassavaDS(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, img_dir, transform):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.transform = transform\n",
        "        self.has_labels = 'label' in df.columns\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.img_dir / row['image_id']\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.has_labels:\n",
        "            label = int(row['label'])\n",
        "            return img, label\n",
        "        else:\n",
        "            return img, row['image_id']\n",
        "\n",
        "def get_model(num_classes=5):\n",
        "    return timm.create_model('tf_efficientnet_b3_ns', pretrained=True, num_classes=num_classes)\n",
        "\n",
        "def get_loaders(df, fold, batch_size=16, num_workers=2):\n",
        "    trn_df = df[df.fold != fold].reset_index(drop=True)\n",
        "    val_df = df[df.fold == fold].reset_index(drop=True)\n",
        "    trn_ds = CassavaDS(trn_df, train_img_dir, train_tfms)\n",
        "    val_ds = CassavaDS(val_df, train_img_dir, valid_tfms)\n",
        "    trn_loader = DataLoader(trn_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "    return trn_loader, val_loader, trn_df, val_df\n",
        "\n",
        "def accuracy(outputs, targets):\n",
        "    preds = outputs.argmax(dim=1)\n",
        "    return (preds == targets).float().mean().item()\n",
        "\n",
        "def train_one_fold(fold=0, epochs=2, lr=2e-4, wd=1e-5):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    trn_loader, val_loader, trn_df, val_df = get_loaders(df, fold)\n",
        "    model = get_model(num_classes=5).to(device)\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=(device=='cuda'))\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    optimizer = AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
        "    best_acc = 0.0\n",
        "    best_path = f'model_fold{fold}.pt'\n",
        "    t0 = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        trn_loss = 0.0; trn_acc = 0.0; n_steps = 0\n",
        "        ep_start = time.time()\n",
        "        for xb, yb in tqdm(trn_loader, desc=f'Fold {fold} Epoch {epoch+1}/{epochs} train'):\n",
        "            xb = xb.to(device, non_blocking=True); yb = torch.tensor(yb).to(device, non_blocking=True)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n",
        "                out = model(xb)\n",
        "                loss = criterion(out, yb)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            trn_loss += loss.item()\n",
        "            trn_acc += accuracy(out.detach(), yb)\n",
        "            n_steps += 1\n",
        "        scheduler.step()\n",
        "        trn_loss /= max(1, n_steps); trn_acc /= max(1, n_steps)\n",
        "        model.eval(); val_loss = 0.0; val_acc = 0.0; v_steps = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in tqdm(val_loader, desc=f'Fold {fold} Epoch {epoch+1}/{epochs} valid'):\n",
        "                xb = xb.to(device, non_blocking=True); yb = torch.tensor(yb).to(device, non_blocking=True)\n",
        "                with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n",
        "                    out = model(xb)\n",
        "                    loss = criterion(out, yb)\n",
        "                val_loss += loss.item()\n",
        "                val_acc += accuracy(out, yb)\n",
        "                v_steps += 1\n",
        "        val_loss /= max(1, v_steps); val_acc /= max(1, v_steps)\n",
        "        print(f\"Fold {fold} Epoch {epoch+1}: trn_loss {trn_loss:.4f} trn_acc {trn_acc:.4f} | val_loss {val_loss:.4f} val_acc {val_acc:.4f} | epoch_time {time.time()-ep_start:.1f}s\", flush=True)\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save({'model': model.state_dict(), 'acc': best_acc}, best_path)\n",
        "            print(f\"Saved best to {best_path} (val_acc={best_acc:.4f})\", flush=True)\n",
        "    print(f\"Fold {fold} done in {time.time()-t0:.1f}s, best_acc={best_acc:.4f}\")\n",
        "    return best_path, best_acc\n",
        "\n",
        "def infer_test(model_path, tta_hflip=True, batch_size=64):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    ss = pd.read_csv('sample_submission.csv')\n",
        "    test_df = ss[['image_id']].copy()\n",
        "    test_ds = CassavaDS(test_df, test_img_dir, valid_tfms)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    model = get_model(num_classes=5).to(device)\n",
        "    ckpt = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(ckpt['model'], strict=True)\n",
        "    model.eval()\n",
        "    logits1_list = []\n",
        "    with torch.no_grad():\n",
        "        for xb, ids in tqdm(test_loader, desc='Test infer pass 1'):\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n",
        "                out = model(xb)\n",
        "            logits1_list.append(out.float().cpu())\n",
        "        logits = torch.cat(logits1_list, dim=0)\n",
        "        if tta_hflip:\n",
        "            logits2_list = []\n",
        "            for xb, ids in tqdm(test_loader, desc='Test infer hflip'):\n",
        "                xb = xb.to(device, non_blocking=True)\n",
        "                xb = torch.flip(xb, dims=[3])\n",
        "                with torch.cuda.amp.autocast(enabled=(device=='cuda')):\n",
        "                    out = model(xb)\n",
        "                logits2_list.append(out.float().cpu())\n",
        "            logits2 = torch.cat(logits2_list, dim=0)\n",
        "            logits = (logits + logits2) / 2.0\n",
        "    preds = logits.argmax(dim=1).numpy()\n",
        "    sub = pd.DataFrame({'image_id': test_df['image_id'], 'label': preds})\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv with shape', sub.shape)\n",
        "\n",
        "# Run smoke: train fold 0 for 2 epochs and infer\n",
        "best_path, best_acc = train_one_fold(fold=0, epochs=2, lr=2e-4, wd=1e-5)\n",
        "infer_test(best_path, tta_hflip=True)\n",
        "print('Smoke run complete. Best val_acc:', best_acc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KernelDied",
          "evalue": "Kernel died unexpectedly.",
          "traceback": []
        }
      ]
    },
    {
      "id": "2131d549-a36d-4dae-b6e1-c155caf64ecf",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Simple baseline: majority-class submission (sanity check, no GPU needed)\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "ss = pd.read_csv('sample_submission.csv')\n",
        "majority_label = Counter(train_df['label']).most_common(1)[0][0]\n",
        "print('Majority label:', majority_label)\n",
        "sub = ss.copy()\n",
        "sub['label'] = majority_label\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv shape:', sub.shape, 'label distribution:', sub['label'].value_counts().to_dict())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Majority label: 3\nWrote submission.csv shape: (2676, 2) label distribution: {3: 2676}\n"
          ]
        }
      ]
    },
    {
      "id": "7d88c59f-b2ed-46c6-aaa4-860222c95c7b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Copy fine-tuned submission to canonical filename for grading\n",
        "import shutil, os, time\n",
        "src = 'submission_ft512.csv'\n",
        "dst = 'submission.csv'\n",
        "assert os.path.exists(src), f\"Missing {src}\"\n",
        "shutil.copyfile(src, dst)\n",
        "print('Copied', src, '->', dst, 'at', time.strftime('%Y-%m-%d %H:%M:%S'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied submission_ft512.csv -> submission.csv at 2025-09-28 23:09:24\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}