{
  "cells": [
    {
      "id": "f3e08aa4-49e9-4e3e-ab07-e914d95e0237",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kuzushiji Recognition: Plan and Checklist\n",
        "\n",
        "Objectives:\n",
        "- Achieve medal-level f1-score by building a robust detection+recognition pipeline.\n",
        "- Ship a working baseline ASAP; iterate with CV rigor and expert feedback.\n",
        "\n",
        "Milestones:\n",
        "1) Environment & GPU\n",
        "- Verify GPU availability (nvidia-smi).\n",
        "- Install PyTorch CUDA 12.1 stack if needed.\n",
        "\n",
        "2) Data Audit & EDA\n",
        "- Inspect train.csv, sample_submission.csv, unicode_translation.csv.\n",
        "- Determine exact schema: image_id, bbox/points, unicode labels, etc.\n",
        "- Verify submission format: triples per image: `Unicode cx cy`.\n",
        "- Unzip train_images.zip and test_images.zip; count images, sizes.\n",
        "\n",
        "3) Validation Protocol\n",
        "- Stratify by page and character distribution if possible.\n",
        "- Use image-level KFold; ensure transforms fit per fold only.\n",
        "- Save folds to disk for reuse.\n",
        "\n",
        "4) Baseline Model (Fast)\n",
        "- Detector: Faster R-CNN (torchvision) or YOLOv5/8 if feasible.\n",
        "- Single-stage baseline: torchvision FasterRCNN with ResNet50-FPN; train on resized images.\n",
        "- Recognition: Treat as classification on detected crops (shared classifier head) or directly predict Unicode via detector\u2019s class head if label space manageable.\n",
        "- Start with modest image size (e.g., 1024 short-side), AMP, 1\u20133 epochs smoke test.\n",
        "\n",
        "5) Improved Pipeline\n",
        "- Increase resolution, stronger aug (Albumentations), longer training with early stopping.\n",
        "- Class imbalance handling (focal loss or class weights).\n",
        "- TTA for detection; NMS tuning.\n",
        "- Unicode normalization via unicode_translation.csv mapping.\n",
        "\n",
        "6) Inference & Submission\n",
        "- Convert detections to required `Unicode cx cy` per image.\n",
        "- Validate format vs sample_submission; sanity-check outputs.\n",
        "\n",
        "7) Iteration & Ensembling\n",
        "- If time, train 2\u20133 seeds or a second backbone and blend.\n",
        "- Error analysis on OOF: per-class f1, confidence calibration, fix top buckets.\n",
        "\n",
        "Risks & Mitigations:\n",
        "- Heavy training time: start with small subset smoke runs; print progress/elapsed per epoch.\n",
        "- Incorrect format: validate against sample and small hand-crafted files.\n",
        "- CV mismatch: lock folds early; mirror test distribution if available.\n",
        "\n",
        "Next Actions:\n",
        "- A) GPU check and install torch cu121.\n",
        "- B) Unzip data; inspect CSV schemas; preview images.\n",
        "- C) Define folds and baseline training loop skeleton.\n",
        "- D) Request expert review on plan and CV before heavy training."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "1301b850-23d6-4e6b-a833-37ad493a944a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment check, data unzip, and CSV audit\n",
        "import os, sys, subprocess, shutil, time, zipfile, math, json, re\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "def run(cmd):\n",
        "    print('$', ' '.join(cmd), flush=True)\n",
        "    return subprocess.run(cmd, check=False, text=True, capture_output=True)\n",
        "\n",
        "# 1) GPU check\n",
        "print('=== NVIDIA SMI ===', flush=True)\n",
        "print(run(['bash','-lc','nvidia-smi || true']).stdout)\n",
        "\n",
        "# 2) Torch cu121 install (idempotent)\n",
        "def ensure_torch_cu121():\n",
        "    import importlib\n",
        "    try:\n",
        "        torch = importlib.import_module('torch')\n",
        "        import torch as _t\n",
        "        print('torch version present:', _t.__version__, 'cuda:', getattr(_t.version,'cuda',None), 'is_available:', _t.cuda.is_available())\n",
        "        # If CUDA not available or wrong build, reinstall\n",
        "        if not _t.cuda.is_available() or not str(getattr(_t.version,'cuda','')).startswith('12.1'):\n",
        "            raise RuntimeError('Reinstall torch stack for cu121')\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print('Installing torch cu121 stack...', e)\n",
        "        # Uninstall possible conflicting stacks (best-effort)\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'torch', 'torchvision', 'torchaudio'], check=False)\n",
        "        # Clean stray site dirs that can shadow correct wheels\n",
        "        for d in (\n",
        "            '/app/.pip-target/torch',\n",
        "            '/app/.pip-target/torchvision',\n",
        "            '/app/.pip-target/torchaudio',\n",
        "            '/app/.pip-target/torch-2.8.0.dist-info',\n",
        "            '/app/.pip-target/torchvision-0.23.0.dist-info',\n",
        "            '/app/.pip-target/torchaudio-2.8.0.dist-info',\n",
        "            '/app/.pip-target/torch-2.4.1.dist-info',\n",
        "            '/app/.pip-target/torchvision-0.19.1.dist-info',\n",
        "            '/app/.pip-target/torchaudio-2.4.1.dist-info',\n",
        "        ):\n",
        "            if os.path.exists(d):\n",
        "                shutil.rmtree(d, ignore_errors=True)\n",
        "        def pip(*args):\n",
        "            print('> pip', *args, flush=True)\n",
        "            subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "        pip('install', '--index-url', 'https://download.pytorch.org/whl/cu121', '--extra-index-url', 'https://pypi.org/simple', 'torch==2.4.1', 'torchvision==0.19.1', 'torchaudio==2.4.1')\n",
        "        Path('constraints.txt').write_text('torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n')\n",
        "        # Sanity\n",
        "        import torch\n",
        "        print('torch:', torch.__version__, 'built CUDA:', getattr(torch.version, 'cuda', None))\n",
        "        print('CUDA available:', torch.cuda.is_available())\n",
        "        assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f'Wrong CUDA build: {torch.version.cuda}'\n",
        "        assert torch.cuda.is_available(), 'CUDA not available'\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "ensure_torch_cu121()\n",
        "\n",
        "CWD = Path('.')\n",
        "train_csv = CWD / 'train.csv'\n",
        "trans_csv = CWD / 'unicode_translation.csv'\n",
        "sample_sub_csv = CWD / 'sample_submission.csv'\n",
        "train_zip = CWD / 'train_images.zip'\n",
        "test_zip = CWD / 'test_images.zip'\n",
        "train_dir = CWD / 'train_images'\n",
        "test_dir = CWD / 'test_images'\n",
        "\n",
        "# 3) Unzip datasets if needed\n",
        "def safe_unzip(zpath: Path, out_dir: Path):\n",
        "    if out_dir.exists() and any(out_dir.iterdir()):\n",
        "        print(f'{out_dir} exists; skipping unzip')\n",
        "        return\n",
        "    assert zpath.exists(), f'Missing zip: {zpath}'\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    print(f'Unzipping {zpath} -> {out_dir} ...', flush=True)\n",
        "    t0 = time.time()\n",
        "    with zipfile.ZipFile(zpath) as zf:\n",
        "        zf.extractall(out_dir)\n",
        "    print(f'Done in {time.time()-t0:.1f}s')\n",
        "\n",
        "safe_unzip(train_zip, train_dir)\n",
        "safe_unzip(test_zip, test_dir)\n",
        "\n",
        "def count_images(img_dir: Path):\n",
        "    exts = {'.jpg','.jpeg','.png','.bmp','.tif','.tiff'}\n",
        "    n = 0\n",
        "    for p in img_dir.rglob('*'):\n",
        "        if p.suffix.lower() in exts:\n",
        "            n += 1\n",
        "    return n\n",
        "\n",
        "print('Train images:', count_images(train_dir))\n",
        "print('Test images:', count_images(test_dir))\n",
        "\n",
        "# 4) CSV audit\n",
        "assert train_csv.exists(), 'train.csv missing'\n",
        "assert trans_csv.exists(), 'unicode_translation.csv missing'\n",
        "assert sample_sub_csv.exists(), 'sample_submission.csv missing'\n",
        "\n",
        "df_train = pd.read_csv(train_csv)\n",
        "df_trans = pd.read_csv(trans_csv)\n",
        "df_sample = pd.read_csv(sample_sub_csv)\n",
        "print('train.csv shape:', df_train.shape)\n",
        "print('train.csv columns:', df_train.columns.tolist())\n",
        "print(df_train.head(3))\n",
        "print('unicode_translation.csv shape:', df_trans.shape)\n",
        "print(df_trans.head(3))\n",
        "print('sample_submission.csv shape:', df_sample.shape)\n",
        "print(df_sample.head(3))\n",
        "\n",
        "# 5) Parse labels format guess: space-separated triples: unicode cx cy\n",
        "def parse_labels_to_unicodes(labels: str):\n",
        "    if not isinstance(labels, str) or labels.strip() == '':\n",
        "        return []\n",
        "    toks = labels.strip().split()\n",
        "    # Expect groups of 3; if not, try groups of 5 (unicode x y w h) as fallback\n",
        "    if len(toks) % 3 == 0:\n",
        "        return [toks[i] for i in range(0, len(toks), 3)]\n",
        "    elif len(toks) % 5 == 0:\n",
        "        return [toks[i] for i in range(0, len(toks), 5)]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "sample_labels = df_train.iloc[0]['labels'] if 'labels' in df_train.columns else None\n",
        "print('Sample labels string:', sample_labels)\n",
        "\n",
        "uniq = {}\n",
        "cnt_per_image = []\n",
        "for s in df_train.get('labels', pd.Series([], dtype=str)).fillna(''):\n",
        "    ulist = parse_labels_to_unicodes(s)\n",
        "    cnt_per_image.append(len(ulist))\n",
        "    for u in ulist:\n",
        "        uniq[u] = uniq.get(u, 0) + 1\n",
        "print('Images with any labels:', sum(c>0 for c in cnt_per_image), 'of', len(cnt_per_image))\n",
        "print('Total labeled instances:', sum(cnt_per_image))\n",
        "print('Unique unicode tokens (raw):', len(uniq))\n",
        "print('Top 10 tokens:', sorted(uniq.items(), key=lambda x: -x[1])[:10])\n",
        "\n",
        "# 6) Tiny submission validator: mirror sample format\n",
        "def make_tiny_submission(df_samp: pd.DataFrame) -> pd.DataFrame:\n",
        "    sub = df_samp.copy()\n",
        "    # leave empty predictions\n",
        "    return sub\n",
        "\n",
        "df_tiny = make_tiny_submission(df_sample)\n",
        "out_path = Path('submission.csv')\n",
        "df_tiny.to_csv(out_path, index=False)\n",
        "print('Wrote tiny submission.csv with shape', df_tiny.shape, 'Head:')\n",
        "print(df_tiny.head(2))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NVIDIA SMI ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ bash -lc nvidia-smi || true\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 29 18:18:20 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\nInstalling torch cu121 stack... No module named 'torch'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install --index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.org/simple torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\nWARNING: Skipping torchvision as it is not installed.\nWARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 481.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 475.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 437.2 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 3.2 MB/s eta 0:00:00\nCollecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 142.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 518.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 517.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 507.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 529.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 515.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 471.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 487.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 527.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 530.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 455.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 534.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 524.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 538.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 531.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 517.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 259.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 135.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 302.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 504.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.3 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 built CUDA: 12.1\nCUDA available: True\nGPU: NVIDIA A10-24Q\nUnzipping train_images.zip -> train_images ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 8.2s\nUnzipping test_images.zip -> test_images ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 0.9s\nTrain images: 3244\nTest images: 361\ntrain.csv shape: (3244, 2)\ntrain.csv columns: ['image_id', 'labels']\n            image_id                                             labels\n0  200004148_00015_1  U+306F 1187 361 47 27 U+306F 1487 2581 48 28 U...\n1  200021712-00008_2  U+4E00 1543 1987 58 11 U+4E00 1296 1068 91 11 ...\n2  100249416_00034_1  U+4E00 1214 415 73 11 U+4E00 1386 412 72 13 U+...\nunicode_translation.csv shape: (4781, 2)\n  Unicode char\n0  U+0031    1\n1  U+0032    2\n2  U+0034    4\nsample_submission.csv shape: (361, 2)\n            image_id                 labels\n0        umgy007-028  U+003F 1 1 U+FF2F 2 2\n1        hnsd004-026  U+003F 1 1 U+FF2F 2 2\n2  200003076_00034_2  U+003F 1 1 U+FF2F 2 2\nSample labels string: U+306F 1187 361 47 27 U+306F 1487 2581 48 28 U+3070 1187 1063 74 30 U+3070 594 1154 93 31 U+306F 1192 1842 52 32 U+309D 755 2601 24 33 U+3070 1336 531 88 33 U+3044 1326 444 60 34 U+53E3 1342 2649 44 35 U+306F 1485 1427 46 35 U+306F 450 1642 51 35 U+306F 156 1453 47 36 U+306F 742 1817 51 36 U+3051 23 938 33 37 U+304C 27 1695 42 38 U+304B 29 1176 21 39 U+3044 149 1510 70 39 U+3079 1467 2251 101 39 U+3078 726 2351 78 40 U+308B 1497 2204 34 41 U+304B 463 2470 29 42 U+3078 571 1644 86 42 U+3078 571 1112 92 42 U+3081 152 1318 51 43 U+306E 589 2464 53 43 U+3078 880 1839 79 43 U+3070 1035 1025 88 43 U+304B 602 917 27 44 U+306B 897 2229 43 44 U+5019 1489 2541 48 44 U+306F 1185 1180 53 44 U+3070 23 1053 75 44 U+304C 1343 1837 78 44 U+308B 602 746 31 45 U+304C 1494 1666 71 45 U+3078 1169 1012 83 45 U+3078 427 2204 91 45 U+306E 299 1779 52 46 U+3044 438 2423 64 46 U+3078 1317 482 87 46 U+3079 572 800 104 46 U+3079 136 635 110 46 U+309D 1199 1254 23 47 U+308B 168 2161 30 47 U+305F 601 2582 32 47 U+306B 1049 1299 33 47 U+3053 746 2552 38 47 U+306E 1178 1382 57 47 U+3078 288 1318 80 47 U+304B 460 2235 29 48 U+306B 1196 513 42 48 U+306E 1480 847 51 48 U+306B 580 2120 63 48 U+3044 139 830 67 48 U+3044 727 2301 68 48 U+3064 137 2124 74 48 U+3070 739 774 84 48 U+306B 894 1131 40 49 U+3068 296 2337 50 49 U+308D 734 2635 68 49 U+306E 300 1526 54 50 U+3092 1181 2390 58 50 U+306E 733 1766 62 50 U+305B 279 2639 68 50 U+306E 1030 2241 56 51 U+304B 905 1630 29 53 U+308A 607 2631 31 53 U+304B 1185 1433 35 53 U+3044 584 1052 60 53 U+516B 576 1960 79 53 U+3082 747 1711 34 54 U+306B 1497 1800 37 54 U+306E 22 1580 39 54 U+304A 21 1508 49 54 U+304A 18 2513 49 54 U+3055 24 2256 31 55 U+308B 455 1199 32 55 U+306E 19 1947 42 55 U+306E 1039 562 53 55 U+306B 441 688 59 55 U+3090 130 433 80 55 U+4E94 429 534 82 55 U+304B 1352 2031 25 56 U+3068 1502 446 26 56 U+308B 752 1291 35 56 U+308B 1198 1201 40 56 U+306E 1474 2063 63 56 U+3044 1171 1119 75 56 U+3056 1343 1670 79 56 U+305B 1317 1611 85 56 U+3079 732 1347 89 56 U+34DB 1015 633 90 56 U+3089 904 1684 36 57 U+3044 1176 956 67 57 U+3068 755 575 21 58 U+3082 26 2566 26 58 U+3088 1047 2447 30 58 U+897F 143 1023 68 58 U+5207 1176 2542 80 58 U+306B 309 612 38 59 U+3082 1339 1547 38 59 U+306B 589 435 58 59 U+897F 1330 664 70 59 U+3065 868 1569 118 59 U+3068 904 631 21 60 U+305F 27 536 22 60 U+3082 1496 2356 30 60 U+305B 752 722 33 60 U+3082 748 919 34 60 U+3082 305 2109 37 60 U+305F 160 1550 39 60 U+3066 434 835 56 60 U+3072 1327 2567 64 60 U+3072 1029 1786 65 60 U+306E 1183 1989 66 60 U+304C 1017 1509 105 60 U+5FA1 881 1350 69 61 U+304F 309 2254 25 62 U+305F 890 504 36 62 U+3082 890 682 38 62 U+3092 438 1799 62 62 U+3075 125 874 81 62 U+5F7C 867 2620 93 62 U+308F 896 2495 34 63 U+305F 1048 1562 38 63 U+3066 1176 894 58 63 U+308C 22 1640 68 63 U+306B 136 2622 72 63 U+5730 1314 1973 93 63 U+3068 171 1900 23 64 U+3082 156 1085 34 64 U+306A 296 1913 62 64 U+306E 1032 1918 66 64 U+3070 1333 1216 87 64 U+3046 1502 2284 23 65 U+3072 16 2617 53 65 U+3093 18 2304 61 65 U+306E 1029 1147 64 65 U+305B 281 855 75 65 U+305A 1488 2610 81 65 U+767E 1462 692 89 65 U+3068 316 2045 22 66 U+306B 162 2210 39 66 U+3055 158 1791 48 66 U+3092 587 602 51 66 U+3092 1188 2129 58 66 U+3050 755 2157 59 66 U+3072 873 360 69 66 U+4E07 1474 766 71 66 U+5341 878 848 74 66 U+308C 873 2550 81 66 U+6975 1007 1223 96 66 U+308B 24 597 25 67 U+8DDD 1181 2206 81 67 U+305B 272 1175 88 67 U+308A 1200 737 29 68 U+3082 454 1865 34 68 U+3072 140 2050 74 68 U+56DE 1319 1383 78 68 U+3068 1353 2247 29 69 U+3082 305 680 34 69 U+3089 899 2355 55 69 U+3056 1044 870 74 69 U+53C8 723 982 88 69 U+3068 160 757 26 70 U+3089 1353 2082 32 70 U+3082 1495 2001 36 70 U+3055 306 1105 39 70 U+53D6 566 679 88 70 U+5927 287 1357 88 70 U+304F 167 1607 24 71 U+305F 1198 676 30 71 U+305D 1039 1075 47 71 U+62D9 422 1564 93 71 U+3068 756 2224 20 72 U+3088 747 1928 40 72 U+305D 1046 1851 42 72 U+306F 152 1158 47 72 U+3084 18 2446 51 72 U+3061 1036 2368 53 72 U+3092 1035 697 60 72 U+7A0B 17 2007 63 72 U+7FD2 1023 2612 63 72 U+3057 1318 1140 75 72 U+8941 1018 2069 81 72 U+5C04 712 444 100 72 U+305A 429 2342 110 72 U+3068 1348 360 22 73 U+307F 902 1504 27 73 U+7D66 307 1249 38 73 U+3059 151 561 40 73 U+51FA 1475 1863 79 73 U+305A 890 1268 84 73 U+4F2F 422 358 88 73 U+8913 1008 2151 89 73 U+4ECA 732 2475 95 73 U+3082 1192 1308 39 74 U+3089 458 2286 41 74 U+3055 155 2468 41 74 U+3092 738 1145 52 74 U+306A 1182 1477 52 74 U+3092 1485 1079 57 74 U+3093 1473 1254 69 74 U+601D 141 1975 80 74 U+5F37 1463 902 82 74 U+307E 154 358 43 75 U+3092 738 360 56 75 U+4FE1 1320 577 79 75 U+53C8 729 1863 87 75 U+5076 867 2144 93 75 U+3082 598 1476 29 76 U+3088 739 1474 49 76 U+308C 23 975 54 76 U+3061 1333 2391 58 76 U+3092 1478 358 63 76 U+5FFD 1328 1888 74 76 U+5E2B 578 2516 78 76 U+671D 1467 1581 79 76 U+898B 274 2552 80 76 U+305A 888 2416 82 76 U+7A0B 138 1370 89 76 U+7422 1011 359 104 76 U+3068 28 2360 21 77 U+307F 601 352 27 77 U+3068 602 958 28 77 U+308A 311 2379 33 77 U+3092 21 2083 44 77 U+51E1 1182 1551 76 77 U+601D 878 1752 77 77 U+5F97 865 436 79 77 U+76CA 426 441 80 77 U+5DE7 427 1477 83 77 U+308A 1055 1438 33 78 U+3075 25 1097 37 78 U+306A 25 859 41 78 U+3089 155 493 44 78 U+9632 729 2083 76 78 U+4FE1 134 931 77 78 U+8863 574 1877 94 78 U+3057 761 1381 12 79 U+3057 612 2175 17 79 U+304F 27 1214 18 79 U+308A 1049 2506 27 79 U+3089 165 2544 34 79 U+60B2 291 1433 77 79 U+7E26 1018 1700 83 79 U+3046 1047 2293 24 80 U+308A 897 552 29 80 U+3092 443 985 58 80 U+3042 583 1557 59 80 U+8EAB 1025 1979 67 80 U+3042 878 2278 71 80 U+305A 449 2117 73 80 U+81F3 1020 1358 74 80 U+7D99 276 451 84 80 U+4EBA 862 1880 103 80 U+3057 35 460 9 81 U+3068 1198 810 29 81 U+308B 434 2603 73 81 U+5F7C 716 829 87 81 U+6728 871 2051 95 81 U+8F19 273 2173 104 81 U+304F 750 1998 27 82 U+304F 748 1546 29 82 U+308C 1027 939 57 82 U+3058 168 1230 57 82 U+77E2 295 1835 68 82 U+3042 1472 2128 70 82 U+5DEE 1175 2603 81 82 U+50C5 866 755 84 82 U+671D 566 1294 92 82 U+308A 1344 1727 33 83 U+6708 1187 2051 64 83 U+304D 593 834 43 84 U+904E 879 1191 58 84 U+65E9 279 531 76 84 U+53F3 1465 1718 84 84 U+305A 592 1678 85 84 U+671D 123 2380 91 84 U+8E30 1174 2450 92 84 U+308A 23 1411 32 85 U+3057 1041 1608 56 85 U+667A 286 1583 76 85 U+8AD6 426 2028 95 85 U+3046 1341 2319 31 86 U+793A 17 2164 49 86 U+5446 1324 937 67 86 U+3093 138 1842 78 86 U+5C04 717 1228 91 86 U+308A 756 2383 27 87 U+308A 314 1968 30 87 U+306A 441 2517 63 87 U+308A 1497 499 31 88 U+3066 601 2253 31 88 U+5C48 25 372 44 88 U+706B 439 906 68 88 U+679C 1323 1036 79 88 U+6A2A 1169 415 80 88 U+8EAB 861 1412 87 88 U+4EF0 274 763 94 88 U+6C17 25 673 60 89 U+611A 433 1376 74 89 U+5C04 712 1625 103 89 U+3057 169 661 12 90 U+77E2 287 360 64 90 U+805E 582 1388 71 90 U+4F59 866 920 89 90 U+7A4D 1009 778 95 90 U+5C04 276 1016 93 91 U+7B54 1305 1456 99 91 U+3066 307 2448 22 92 U+3066 1492 583 31 92 U+8272 22 772 49 92 U+6075 293 1671 77 92 U+9000 1467 1167 78 92 U+3093 1466 1928 87 92 U+8853 1166 1749 93 92 U+3057 1354 1279 11 93 U+3066 308 919 23 94 U+4E8B 1488 1329 45 94 U+805E 1322 737 72 95 U+77E2 579 516 73 95 U+6B32 723 635 83 95 U+61A4 25 1306 56 96 U+5A01 20 1741 57 96 U+70BA 583 1192 72 96 U+3093 729 498 81 96 U+6211 722 1052 82 96 U+7B11 1323 2471 90 96 U+61F2 134 1692 91 96 U+6575 1468 984 78 97 U+6B73 429 594 88 97 U+3057 453 741 24 98 U+3066 1343 829 28 98 U+6089 873 1941 84 98 U+6B73 574 2014 94 98 U+3057 1329 1736 68 99 U+5925 1169 1886 89 99 U+52E2 20 1826 62 102 U+78E8 1016 444 89 102 U+88C2 1169 574 80 103 U+3066 458 1931 26 104 U+84B2 575 1771 92 104 U+899A 1466 2426 83 105 U+5E74 1174 2276 79 107 U+70BA 143 2278 74 108 U+821C 581 2346 76 109 U+8CE2 435 1263 81 109 U+5E74 864 1011 87 109 U+3031 1344 2127 41 110 U+82B8 1165 1636 98 111 U+70BA 1474 1468 79 112 U+5E74 428 1681 87 112 U+638C 433 1072 77 121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images with any labels: 3244 of 3244\nTotal labeled instances: 747579\nUnique unicode tokens (raw): 7819\nTop 10 tokens: [('U+306B', 17289), ('U+306E', 16954), ('U+3057', 15561), ('U+3066', 14297), ('U+3068', 11609), ('U+3092', 11102), ('U+306F', 10320), ('U+304B', 9997), ('U+308A', 9848), ('U+306A', 9592)]\nWrote tiny submission.csv with shape (361, 2) Head:\n      image_id                 labels\n0  umgy007-028  U+003F 1 1 U+FF2F 2 2\n1  hnsd004-026  U+003F 1 1 U+FF2F 2 2\n"
          ]
        }
      ]
    },
    {
      "id": "e6ead993-8d4a-4261-9899-c1ea01c434b2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Parse bbox stats and create CV folds\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def parse_labels_full(labels: str):\n",
        "    if not isinstance(labels, str) or labels.strip() == '':\n",
        "        return []\n",
        "    toks = labels.strip().split()\n",
        "    out = []\n",
        "    if len(toks) % 5 == 0:\n",
        "        for i in range(0, len(toks), 5):\n",
        "            u, x, y, w, h = toks[i:i+5]\n",
        "            try:\n",
        "                out.append((u, int(x), int(y), int(w), int(h)))\n",
        "            except:\n",
        "                pass\n",
        "    elif len(toks) % 3 == 0:\n",
        "        # triples fallback (unicode, cx, cy); synthesize tiny boxes for stats\n",
        "        for i in range(0, len(toks), 3):\n",
        "            u, cx, cy = toks[i:i+3]\n",
        "            try:\n",
        "                out.append((u, int(cx), int(cy), 1, 1))\n",
        "            except:\n",
        "                pass\n",
        "    return out\n",
        "\n",
        "# Build per-image annotations and bbox stats\n",
        "anns = []\n",
        "per_image_counts = []\n",
        "for r in df_train.itertuples(index=False):\n",
        "    image_id = getattr(r, 'image_id') if hasattr(r, 'image_id') else r[0]\n",
        "    labels = getattr(r, 'labels') if hasattr(r, 'labels') else r[1]\n",
        "    boxes = parse_labels_full(labels)\n",
        "    per_image_counts.append((image_id, len(boxes)))\n",
        "    for (u,x,y,w,h) in boxes:\n",
        "        anns.append((image_id, u, x, y, w, h))\n",
        "\n",
        "df_anns = pd.DataFrame(anns, columns=['image_id','unicode','x','y','w','h'])\n",
        "df_counts = pd.DataFrame(per_image_counts, columns=['image_id','count'])\n",
        "print('Annotations dataframe:', df_anns.shape, 'unique images:', df_anns.image_id.nunique())\n",
        "print('Counts per image stats:', df_counts['count'].describe().to_dict())\n",
        "if len(df_anns):\n",
        "    print('w stats:', df_anns['w'].describe().to_dict())\n",
        "    print('h stats:', df_anns['h'].describe().to_dict())\n",
        "\n",
        "# Recommend crop size ~ 2-3x median h\n",
        "if len(df_anns):\n",
        "    med_h = float(df_anns['h'].median())\n",
        "    crop_rec = int(np.clip(2.5 * med_h, 64, 192))\n",
        "    print('Median bbox height:', med_h, '=> recommended crop size:', crop_rec)\n",
        "\n",
        "# 5-fold CV grouped by image, stratified by binned counts\n",
        "df_counts = df_counts.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
        "bins = pd.qcut(df_counts['count'], q=min(10, max(2, df_counts['count'].nunique())), duplicates='drop')\n",
        "df_counts['bin'] = bins.cat.codes if hasattr(bins, 'cat') else 0\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "folds = []\n",
        "for fold, (_, val_idx) in enumerate(kf.split(df_counts, df_counts['bin'])):\n",
        "    img_ids = df_counts.loc[val_idx, 'image_id'].values\n",
        "    folds.extend([(iid, fold) for iid in img_ids])\n",
        "df_folds = pd.DataFrame(folds, columns=['image_id','fold'])\n",
        "df_folds.to_csv('folds.csv', index=False)\n",
        "print('Saved folds.csv with shape', df_folds.shape)\n",
        "print(df_folds['fold'].value_counts().sort_index().to_dict())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotations dataframe: (613505, 6) unique images: 3244\nCounts per image stats: {'count': 3244.0, 'mean': 189.1199136868064, 'std': 89.52639349462329, 'min': 2.0, '25%': 132.0, '50%': 188.0, '75%': 228.0, 'max': 597.0}\nw stats: {'count': 613505.0, 'mean': 77.17600834549026, 'std': 30.474135132977892, 'min': 6.0, '25%': 55.0, '50%': 77.0, '75%': 96.0, 'max': 520.0}\nh stats: {'count': 613505.0, 'mean': 94.98453476336786, 'std': 34.537406387764584, 'min': 5.0, '25%': 72.0, '50%': 91.0, '75%': 112.0, 'max': 993.0}\nMedian bbox height: 91.0 => recommended crop size: 192\nSaved folds.csv with shape (3244, 2)\n{0: 649, 1: 649, 2: 649, 3: 649, 4: 648}\n"
          ]
        }
      ]
    },
    {
      "id": "7c12c4ca-1265-4456-b16c-566bb4a06563",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optional: Regenerate folds with GroupKFold by book prefix (before '-')\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def get_book_prefix(image_id: str):\n",
        "    return str(image_id).split('-')[0] if isinstance(image_id, str) else ''\n",
        "\n",
        "df_counts2 = df_counts.copy()\n",
        "df_counts2['group'] = df_counts2['image_id'].apply(get_book_prefix)\n",
        "print('Unique groups:', df_counts2['group'].nunique())\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "folds_g = []\n",
        "for fold, (_, val_idx) in enumerate(gkf.split(df_counts2, groups=df_counts2['group'])):\n",
        "    img_ids = df_counts2.loc[val_idx, 'image_id'].values\n",
        "    folds_g.extend([(iid, fold) for iid in img_ids])\n",
        "df_folds_g = pd.DataFrame(folds_g, columns=['image_id','fold'])\n",
        "df_folds_g.to_csv('folds_group.csv', index=False)\n",
        "print('Saved folds_group.csv with shape', df_folds_g.shape)\n",
        "print(df_folds_g['fold'].value_counts().sort_index().to_dict())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique groups: 1371\nSaved folds_group.csv with shape (3244, 2)\n{0: 649, 1: 649, 2: 649, 3: 649, 4: 648}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}