{
  "cells": [
    {
      "id": "d9d009db-8b38-44fc-81b1-11183d21ab2c",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Class-agnostic Detector Training (Faster R-CNN R50-FPN)\n",
        "\n",
        "Plan:\n",
        "- Use torchvision Faster R-CNN ResNet50-FPN, 1-class (glyph) + background.\n",
        "- Model handles resizing internally; set min_size=1333, max_size~2000; AMP on; bs=2 if fits.\n",
        "- Data: train.csv (unicode x y w h); folds from folds_group.csv; images in train_images/.\n",
        "- Train a 1-epoch smoke test on fold 0 (or capped steps) with logging and checkpoint.\n",
        "- Next: extend to 6\u20138 epochs and add OOF eval + threshold sweep."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "4b09febb-c5b9-449b-9478-1bef5e69d7c7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# One-class Faster R-CNN training: 1-epoch smoke test (fold 0)\n",
        "import os, sys, time, math, random, gc, json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import torchvision\n",
        "from torchvision.ops import box_convert\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Torch:', torch.__version__, 'CUDA:', torch.cuda.is_available(), 'Device:', device)\n",
        "if device.type == 'cuda':\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "CWD = Path('.')\n",
        "train_csv = CWD / 'train.csv'\n",
        "folds_csv = CWD / 'folds_group.csv'\n",
        "train_dir = CWD / 'train_images'\n",
        "assert train_csv.exists(), 'train.csv missing'\n",
        "assert folds_csv.exists(), 'folds_group.csv missing'\n",
        "assert train_dir.exists(), 'train_images dir missing'\n",
        "\n",
        "df_train = pd.read_csv(train_csv)\n",
        "df_folds = pd.read_csv(folds_csv)\n",
        "\n",
        "# Parse labels: quintuplets unicode x y w h\n",
        "def parse_labels_full(labels: str):\n",
        "    if not isinstance(labels, str) or labels.strip() == '':\n",
        "        return []\n",
        "    toks = labels.strip().split()\n",
        "    out = []\n",
        "    if len(toks) % 5 != 0:\n",
        "        return out\n",
        "    for i in range(0, len(toks), 5):\n",
        "        u, x, y, w, h = toks[i:i+5]\n",
        "        try:\n",
        "            x = int(x); y = int(y); w = int(w); h = int(h)\n",
        "            out.append((u, x, y, w, h))\n",
        "        except Exception:\n",
        "            continue\n",
        "    return out\n",
        "\n",
        "class KuzDetDataset(Dataset):\n",
        "    def __init__(self, df_train: pd.DataFrame, df_folds: pd.DataFrame, fold: int, split: str='train'):\n",
        "        self.split = split\n",
        "        folds_map = dict(df_folds.values)\n",
        "        self.items = []\n",
        "        for r in df_train.itertuples(index=False):\n",
        "            image_id = getattr(r, 'image_id') if hasattr(r, 'image_id') else r[0]\n",
        "            labels = getattr(r, 'labels') if hasattr(r, 'labels') else r[1]\n",
        "            f = folds_map.get(image_id, None)\n",
        "            if f is None:\n",
        "                continue\n",
        "            if (split == 'train' and f != fold) or (split == 'val' and f == fold):\n",
        "                boxes = parse_labels_full(labels)\n",
        "                self.items.append((image_id, boxes))\n",
        "        print(f'{split} items:', len(self.items))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_id, boxes = self.items[idx]\n",
        "        img_path = train_dir / f'{image_id}.jpg'\n",
        "        if not img_path.exists():\n",
        "            # fallback to png if any\n",
        "            png = train_dir / f'{image_id}.png'\n",
        "            if png.exists():\n",
        "                img_path = png\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        w0, h0 = img.size\n",
        "        # Build targets\n",
        "        if len(boxes) > 0:\n",
        "            xyxy = []\n",
        "            for (_, x, y, w, h) in boxes:\n",
        "                x1 = max(0, x); y1 = max(0, y); x2 = min(w0, x + w); y2 = min(h0, y + h)\n",
        "                if x2 > x1 and y2 > y1:\n",
        "                    xyxy.append([x1, y1, x2, y2])\n",
        "            if len(xyxy) == 0:\n",
        "                xyxy = np.zeros((0, 4), dtype=np.float32)\n",
        "            boxes_t = torch.as_tensor(xyxy, dtype=torch.float32)\n",
        "            labels_t = torch.ones((boxes_t.shape[0],), dtype=torch.int64)  # class-agnostic: 1\n",
        "            area_t = (boxes_t[:, 2] - boxes_t[:, 0]) * (boxes_t[:, 3] - boxes_t[:, 1]) if boxes_t.numel() else torch.zeros((0,), dtype=torch.float32)\n",
        "        else:\n",
        "            boxes_t = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            labels_t = torch.zeros((0,), dtype=torch.int64)\n",
        "            area_t = torch.zeros((0,), dtype=torch.float32)\n",
        "        target = {\n",
        "            'boxes': boxes_t,\n",
        "            'labels': labels_t,\n",
        "            'image_id': torch.tensor([idx]),\n",
        "            'area': area_t,\n",
        "            'iscrowd': torch.zeros((labels_t.shape[0],), dtype=torch.int64)\n",
        "        }\n",
        "        return torchvision.transforms.functional.pil_to_tensor(img).float() / 255.0, target, image_id\n",
        "\n",
        "def collate_fn(batch):\n",
        "    imgs, targets, ids = list(zip(*batch))\n",
        "    return list(imgs), list(targets), list(ids)\n",
        "\n",
        "fold = 0\n",
        "batch_size = 2\n",
        "num_workers = min(4, os.cpu_count() or 2)\n",
        "train_ds = KuzDetDataset(df_train, df_folds, fold=fold, split='train')\n",
        "val_ds = KuzDetDataset(df_train, df_folds, fold=fold, split='val')\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True)\n",
        "\n",
        "# Model\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
        "model = fasterrcnn_resnet50_fpn(weights=weights)\n",
        "# Replace head for 2 classes (background + glyph)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=2)\n",
        "# Resize settings\n",
        "model.transform.min_size = (1333,)\n",
        "model.transform.max_size = 2000\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[1], gamma=0.1)\n",
        "scaler = GradScaler(enabled=(device.type=='cuda'))\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, scaler, epoch, max_steps=None):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    t0 = time.time()\n",
        "    last_log = t0\n",
        "    steps = 0\n",
        "    for i, (imgs, targets, ids) in enumerate(loader):\n",
        "        imgs = [im.to(device, non_blocking=True) for im in imgs]\n",
        "        tgts = [{k: v.to(device) if torch.is_tensor(v) else v for k, v in t.items()} for t in targets]\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast(enabled=(device.type=='cuda')):\n",
        "            loss_dict = model(imgs, tgts)\n",
        "            loss = sum(loss for loss in loss_dict.values())\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running += loss.item()\n",
        "        steps += 1\n",
        "        if (time.time() - last_log) > 5:\n",
        "            mem = torch.cuda.memory_allocated()/1024**3 if device.type=='cuda' else 0.0\n",
        "            print(f'Epoch {epoch} Iter {i} loss {loss.item():.3f} avg {running/steps:.3f} mem {mem:.2f}GB elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "            last_log = time.time()\n",
        "        if max_steps and steps >= max_steps:\n",
        "            break\n",
        "    dt = time.time() - t0\n",
        "    print(f'Epoch {epoch} done: {steps} steps, avg loss {running/max(1,steps):.4f}, time {dt:.1f}s')\n",
        "\n",
        "# Smoke test: 1 epoch, cap steps\n",
        "max_steps = 200\n",
        "epochs = 1\n",
        "for ep in range(1, epochs+1):\n",
        "    train_one_epoch(model, train_loader, optimizer, scaler, ep, max_steps=max_steps)\n",
        "    try:\n",
        "        lr_scheduler.step()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# Save checkpoint\n",
        "ckpt_path = Path(f'detector_frcnn_r50_1cls_fold{fold}_ep{epochs}.pth')\n",
        "torch.save({'model': model.state_dict(), 'epoch': epochs}, ckpt_path)\n",
        "print('Saved checkpoint to', ckpt_path.resolve())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.4.1+cu121 CUDA: True Device: cuda\nGPU: NVIDIA A10-24Q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train items: 2595\nval items: 649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /app/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0.00/160M [00:00<?, ?B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|\u2588\u2588\u2588\u258e      | 52.0M/160M [00:00<00:00, 545MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 108M/160M [00:00<00:00, 568MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 160M/160M [00:00<00:00, 570MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_600/3742264880.py:130: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler(enabled=(device.type=='cuda'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_600/3742264880.py:142: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=(device.type=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 1 loss 5.403 avg 5.491 mem 0.64GB elapsed 6.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 4 loss 1.507 avg 3.127 mem 0.69GB elapsed 11.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 12 loss 1.485 avg 2.140 mem 0.62GB elapsed 16.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 24 loss 1.121 avg 1.708 mem 0.62GB elapsed 23.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 37 loss 0.874 avg 1.450 mem 0.63GB elapsed 29.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 51 loss 1.088 avg 1.294 mem 0.72GB elapsed 34.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 64 loss 0.685 avg 1.207 mem 0.62GB elapsed 39.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 78 loss 0.633 avg 1.130 mem 0.62GB elapsed 44.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 91 loss 0.807 avg 1.070 mem 0.74GB elapsed 50.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 105 loss 0.634 avg 1.026 mem 0.60GB elapsed 55.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 119 loss 0.603 avg 0.978 mem 0.62GB elapsed 60.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 132 loss 0.711 avg 0.947 mem 0.70GB elapsed 65.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 146 loss 0.479 avg 0.910 mem 0.65GB elapsed 70.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 154 loss 0.587 avg 0.896 mem 0.67GB elapsed 76.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 167 loss 0.455 avg 0.870 mem 0.70GB elapsed 81.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 179 loss 0.720 avg 0.850 mem 0.61GB elapsed 86.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iter 192 loss 0.513 avg 0.828 mem 0.62GB elapsed 91.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 done: 200 steps, avg loss 0.8223, time 94.2s\nSaved checkpoint to /var/lib/simon/agent_run_states/kuzushiji-recognition-20250929-180012/detector_frcnn_r50_1cls_fold0_ep1.pth\n"
          ]
        }
      ]
    },
    {
      "id": "007496ff-1d73-41b6-a526-439f3dd0d587",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference: generate detections for val fold and test; save to parquet for recognizer\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "model.eval()\n",
        "# Raise detector caps as per expert advice\n",
        "try:\n",
        "    model.roi_heads.detections_per_img = 2000\n",
        "    model.rpn.pre_nms_top_n_test = 12000\n",
        "    model.rpn.post_nms_top_n_test = 6000\n",
        "    print('Applied raised detection caps: detections_per_img=2000, pre_nms_top_n_test=12000, post_nms_top_n_test=6000')\n",
        "except Exception as e:\n",
        "    print('Warning: could not set raised caps:', e)\n",
        "\n",
        "# Use dense threshold; filter later during sweeps\n",
        "score_thresh = 0.01\n",
        "\n",
        "def run_inference(loader, desc):\n",
        "    preds = []\n",
        "    t0 = time.time()\n",
        "    with torch.no_grad():\n",
        "        for imgs, targets, ids in tqdm(loader, desc=desc, total=len(loader), mininterval=1.0):\n",
        "            imgs = [im.to(device) for im in imgs]\n",
        "            outputs = model(imgs)\n",
        "            for out, image_id in zip(outputs, ids):\n",
        "                boxes = out['boxes'].detach().cpu().numpy() if out is not None and 'boxes' in out else np.zeros((0,4),dtype=np.float32)\n",
        "                scores = out['scores'].detach().cpu().numpy() if out is not None and 'scores' in out else np.zeros((0,),dtype=np.float32)\n",
        "                keep = scores >= score_thresh\n",
        "                boxes = boxes[keep]\n",
        "                scores = scores[keep]\n",
        "                for (x1,y1,x2,y2), s in zip(boxes, scores):\n",
        "                    w = max(0.0, x2 - x1); h = max(0.0, y2 - y1)\n",
        "                    preds.append((image_id, float(x1), float(y1), float(w), float(h), float(s)))\n",
        "    dt = time.time() - t0\n",
        "    print(f'{desc} done in {dt:.1f}s; total preds: {len(preds)}')\n",
        "    return pd.DataFrame(preds, columns=['image_id','x','y','w','h','score'])\n",
        "\n",
        "# Val predictions (fold 0 only) to oof parquet\n",
        "val_preds = run_inference(val_loader, desc='Val infer fold0')\n",
        "val_preds.to_parquet(f'det_oof_fold{fold}.parquet', index=False)\n",
        "print('Saved val preds to', f'det_oof_fold{fold}.parquet')\n",
        "\n",
        "# Test loader\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, img_dir: Path):\n",
        "        self.imgs = []\n",
        "        for p in sorted(img_dir.iterdir()):\n",
        "            if p.suffix.lower() in {'.jpg','.jpeg','.png','.bmp','.tif','.tiff'}:\n",
        "                self.imgs.append(p)\n",
        "        print('Test images:', len(self.imgs))\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.imgs[idx]\n",
        "        img = Image.open(p).convert('RGB')\n",
        "        image_id = p.stem\n",
        "        return torchvision.transforms.functional.pil_to_tensor(img).float()/255.0, {'image_id': torch.tensor([idx])}, image_id\n",
        "\n",
        "test_dir = CWD / 'test_images'\n",
        "test_ds = TestDataset(test_dir)\n",
        "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True)\n",
        "test_preds = run_inference(test_loader, desc='Test infer')\n",
        "test_preds.to_parquet('det_test_preds.parquet', index=False)\n",
        "print('Saved test preds to det_test_preds.parquet')\n",
        "\n",
        "# Also prepare a quick detector-only submission with placeholder unicode (will be replaced after recognizer)\n",
        "df_sample = pd.read_csv('sample_submission.csv')\n",
        "g = test_preds.groupby('image_id')\n",
        "rows = []\n",
        "for image_id in df_sample['image_id']:\n",
        "    if image_id in g.groups:\n",
        "        grp = g.get_group(image_id)\n",
        "        # convert to centers and round\n",
        "        cx = (grp['x'] + grp['w']/2.0).round().astype(int).tolist()\n",
        "        cy = (grp['y'] + grp['h']/2.0).round().astype(int).tolist()\n",
        "        # placeholder unicode token (will be replaced later by recognizer), keep minimal to validate format\n",
        "        toks = []\n",
        "        for x_, y_ in zip(cx, cy):\n",
        "            toks.extend(['U+003F', str(int(x_)), str(int(y_))])\n",
        "        rows.append(' '.join(toks))\n",
        "    else:\n",
        "        rows.append('')\n",
        "sub = pd.DataFrame({'image_id': df_sample['image_id'], 'labels': rows})\n",
        "sub.to_csv('submission_detector_only.csv', index=False)\n",
        "print('Wrote submission_detector_only.csv (placeholder unicodes). Will replace after recognizer.')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied raised detection caps: detections_per_img=2000, pre_nms_top_n_test=12000, post_nms_top_n_test=6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:   0%|          | 0/649 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:   1%|\u258f         | 9/649 [00:01<01:13,  8.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:   3%|\u258e         | 21/649 [00:02<01:02, 10.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:   5%|\u258c         | 33/649 [00:03<00:58, 10.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:   7%|\u258b         | 45/649 [00:04<00:56, 10.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  10%|\u2588         | 68/649 [00:06<00:53, 10.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  12%|\u2588\u258f        | 79/649 [00:07<00:52, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  14%|\u2588\u258d        | 90/649 [00:08<00:51, 10.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  16%|\u2588\u258c        | 102/649 [00:09<00:49, 10.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  17%|\u2588\u258b        | 113/649 [00:10<00:49, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  19%|\u2588\u2589        | 124/649 [00:11<00:48, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  21%|\u2588\u2588        | 136/649 [00:12<00:46, 10.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  23%|\u2588\u2588\u258e       | 148/649 [00:13<00:45, 11.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  25%|\u2588\u2588\u258d       | 160/649 [00:14<00:44, 11.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  27%|\u2588\u2588\u258b       | 172/649 [00:15<00:43, 11.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  28%|\u2588\u2588\u258a       | 184/649 [00:16<00:42, 11.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  30%|\u2588\u2588\u2588       | 196/649 [00:17<00:41, 11.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  32%|\u2588\u2588\u2588\u258f      | 208/649 [00:19<00:40, 10.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  34%|\u2588\u2588\u2588\u258e      | 219/649 [00:20<00:39, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  35%|\u2588\u2588\u2588\u258c      | 230/649 [00:21<00:38, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  37%|\u2588\u2588\u2588\u258b      | 241/649 [00:22<00:37, 10.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  39%|\u2588\u2588\u2588\u2589      | 253/649 [00:23<00:36, 10.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  41%|\u2588\u2588\u2588\u2588      | 264/649 [00:24<00:35, 10.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  42%|\u2588\u2588\u2588\u2588\u258f     | 275/649 [00:25<00:34, 10.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  44%|\u2588\u2588\u2588\u2588\u258d     | 286/649 [00:26<00:33, 10.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  46%|\u2588\u2588\u2588\u2588\u258c     | 297/649 [00:27<00:32, 10.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  47%|\u2588\u2588\u2588\u2588\u258b     | 308/649 [00:28<00:31, 10.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  49%|\u2588\u2588\u2588\u2588\u2589     | 319/649 [00:29<00:30, 10.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  51%|\u2588\u2588\u2588\u2588\u2588     | 331/649 [00:30<00:29, 10.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 342/649 [00:31<00:28, 10.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  55%|\u2588\u2588\u2588\u2588\u2588\u258d    | 354/649 [00:32<00:26, 10.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 366/649 [00:33<00:25, 11.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 378/649 [00:34<00:24, 10.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 389/649 [00:35<00:23, 10.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 401/649 [00:36<00:22, 11.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 413/649 [00:37<00:21, 10.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 424/649 [00:38<00:20, 10.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 435/649 [00:39<00:19, 10.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 446/649 [00:40<00:18, 10.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 457/649 [00:41<00:17, 10.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 468/649 [00:42<00:16, 10.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 480/649 [00:43<00:15, 10.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 491/649 [00:44<00:14, 10.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 503/649 [00:46<00:13, 10.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 514/649 [00:47<00:12, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 525/649 [00:48<00:11, 10.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 536/649 [00:49<00:10, 10.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 548/649 [00:50<00:09, 10.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 559/649 [00:51<00:08, 10.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 570/649 [00:52<00:07, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 581/649 [00:53<00:06, 10.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 592/649 [00:54<00:05, 10.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 603/649 [00:55<00:04, 10.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 614/649 [00:56<00:03, 10.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 625/649 [00:57<00:02, 10.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 636/649 [00:58<00:01, 10.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 647/649 [00:59<00:00, 10.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rVal infer fold0: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 649/649 [00:59<00:00, 10.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val infer fold0 done in 59.5s; total preds: 134993\nSaved val preds to det_oof_fold0.parquet\nTest images: 361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:   0%|          | 0/361 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:   2%|\u258f         | 7/361 [00:01<00:51,  6.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:   5%|\u258c         | 19/361 [00:02<00:36,  9.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:   8%|\u258a         | 30/361 [00:03<00:32, 10.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  12%|\u2588\u258f        | 42/361 [00:04<00:30, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  15%|\u2588\u258d        | 54/361 [00:05<00:28, 10.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  18%|\u2588\u258a        | 66/361 [00:06<00:27, 10.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  22%|\u2588\u2588\u258f       | 78/361 [00:07<00:25, 10.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  25%|\u2588\u2588\u258d       | 90/361 [00:08<00:24, 11.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  28%|\u2588\u2588\u258a       | 102/361 [00:09<00:23, 11.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  32%|\u2588\u2588\u2588\u258f      | 114/361 [00:10<00:22, 11.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  35%|\u2588\u2588\u2588\u258d      | 126/361 [00:11<00:21, 11.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  38%|\u2588\u2588\u2588\u258a      | 138/361 [00:12<00:20, 10.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  41%|\u2588\u2588\u2588\u2588\u258f     | 149/361 [00:13<00:19, 10.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  45%|\u2588\u2588\u2588\u2588\u258d     | 161/361 [00:14<00:18, 10.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  48%|\u2588\u2588\u2588\u2588\u258a     | 172/361 [00:15<00:17, 10.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  51%|\u2588\u2588\u2588\u2588\u2588     | 183/361 [00:16<00:16, 10.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 195/361 [00:18<00:15, 11.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 207/361 [00:19<00:15, 10.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 218/361 [00:20<00:13, 10.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 231/361 [00:21<00:11, 10.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 243/361 [00:22<00:10, 10.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 254/361 [00:23<00:09, 10.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 265/361 [00:24<00:08, 10.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 276/361 [00:25<00:07, 10.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 287/361 [00:26<00:06, 10.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 298/361 [00:27<00:05, 10.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 310/361 [00:28<00:04, 10.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 322/361 [00:29<00:03, 11.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 334/361 [00:30<00:02, 11.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 346/361 [00:32<00:01, 11.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer:  99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 358/361 [00:33<00:00, 11.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTest infer: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 361/361 [00:33<00:00, 10.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test infer done in 33.4s; total preds: 78959\nSaved test preds to det_test_preds.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission_detector_only.csv (placeholder unicodes). Will replace after recognizer.\n"
          ]
        }
      ]
    },
    {
      "id": "0c0c2d4d-03c8-452d-838d-d8ec6cf13f92",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OOF threshold sweep on fold 0 detections to maximize micro-F1 with center-distance matching\n",
        "import math, json, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "CWD = Path('.')\n",
        "train_csv = CWD / 'train.csv'\n",
        "folds_csv = CWD / 'folds_group.csv'\n",
        "oof_path = CWD / f'det_oof_fold{fold}.parquet'\n",
        "assert train_csv.exists() and folds_csv.exists() and oof_path.exists(), 'Required files missing for sweep'\n",
        "\n",
        "df_train = pd.read_csv(train_csv)\n",
        "df_folds = pd.read_csv(folds_csv)\n",
        "fold_map = dict(df_folds.values)\n",
        "\n",
        "def parse_labels_full(labels: str):\n",
        "    if not isinstance(labels, str) or labels.strip() == '':\n",
        "        return []\n",
        "    toks = labels.strip().split()\n",
        "    if len(toks) % 5 != 0:\n",
        "        return []\n",
        "    out = []\n",
        "    for i in range(0, len(toks), 5):\n",
        "        u, x, y, w, h = toks[i:i+5]\n",
        "        try:\n",
        "            x = int(x); y = int(y); w = int(w); h = int(h)\n",
        "            out.append((u, x, y, w, h))\n",
        "        except:\n",
        "            pass\n",
        "    return out\n",
        "\n",
        "# Build GT centers for fold 0 images\n",
        "gt_rows = []\n",
        "for r in df_train.itertuples(index=False):\n",
        "    image_id = getattr(r, 'image_id') if hasattr(r, 'image_id') else r[0]\n",
        "    if fold_map.get(image_id, None) != 0:\n",
        "        continue\n",
        "    labels = getattr(r, 'labels') if hasattr(r, 'labels') else r[1]\n",
        "    for (_, x, y, w, h) in parse_labels_full(labels):\n",
        "        cx = x + w/2.0; cy = y + h/2.0\n",
        "        gt_rows.append((image_id, float(cx), float(cy)))\n",
        "df_gt = pd.DataFrame(gt_rows, columns=['image_id','cx','cy'])\n",
        "print('Fold0 GT points:', df_gt.shape)\n",
        "\n",
        "# Load OOF predictions and compute centers\n",
        "df_pred = pd.read_parquet(oof_path)\n",
        "df_pred = df_pred.copy()\n",
        "df_pred['cx'] = df_pred['x'] + df_pred['w']/2.0\n",
        "df_pred['cy'] = df_pred['y'] + df_pred['h']/2.0\n",
        "print('OOF preds loaded:', df_pred.shape, 'score stats:', df_pred['score'].describe().to_dict())\n",
        "\n",
        "def eval_threshold(th, cap=None, dmax=25.0):\n",
        "    # Filter by score and optional per-image cap (after filtering)\n",
        "    dd = df_pred.loc[df_pred['score'] >= th, ['image_id','cx','cy','score']].copy()\n",
        "    if cap is not None:\n",
        "        dd = dd.sort_values(['image_id','score'], ascending=[True, False])\n",
        "        dd['rn'] = dd.groupby('image_id').cumcount()\n",
        "        dd = dd[dd['rn'] < cap].drop(columns=['rn'])\n",
        "    # Group by image for matching\n",
        "    g_gt = df_gt.groupby('image_id')\n",
        "    g_pr = dd.groupby('image_id')\n",
        "    TP = 0; FP = 0; FN = 0\n",
        "    # Iterate over union of image ids present in GT for fold 0\n",
        "    for image_id, gt_g in g_gt:\n",
        "        gt_pts = gt_g[['cx','cy']].to_numpy() if len(gt_g) else np.zeros((0,2), dtype=np.float32)\n",
        "        pr_g = g_pr.get_group(image_id) if image_id in g_pr.groups else None\n",
        "        pr_pts = pr_g[['cx','cy','score']].to_numpy() if pr_g is not None else np.zeros((0,3), dtype=np.float32)\n",
        "        # Greedy matching by score desc\n",
        "        matched_gt = np.zeros((len(gt_pts),), dtype=bool) if len(gt_pts) else np.zeros((0,), dtype=bool)\n",
        "        if len(pr_pts) and len(gt_pts):\n",
        "            pr_ord = np.argsort(-pr_pts[:,2])\n",
        "            for idx in pr_ord:\n",
        "                px, py, _ = pr_pts[idx]\n",
        "                # Find nearest unmatched GT within dmax\n",
        "                if not len(gt_pts):\n",
        "                    continue\n",
        "                d2 = ((gt_pts[:,0]-px)**2 + (gt_pts[:,1]-py)**2)\n",
        "                j = int(np.argmin(d2))\n",
        "                if matched_gt[j]:\n",
        "                    continue\n",
        "                if math.sqrt(float(d2[j])) <= dmax:\n",
        "                    matched_gt[j] = True\n",
        "                    TP += 1\n",
        "                else:\n",
        "                    FP += 1\n",
        "            # Remaining unmatched GTs are FN\n",
        "            FN += int((~matched_gt).sum())\n",
        "        else:\n",
        "            # No preds -> all GT are FN; preds exist but no GT shouldn't happen on fold val\n",
        "            FN += len(gt_pts)\n",
        "            FP += 0 if len(pr_pts)==0 else len(pr_pts)\n",
        "    prec = TP / max(1, TP+FP)\n",
        "    rec = TP / max(1, TP+FN)\n",
        "    f1 = 2*prec*rec / max(1e-12, (prec+rec)) if (prec+rec) > 0 else 0.0\n",
        "    return dict(TP=TP, FP=FP, FN=FN, precision=prec, recall=rec, f1=f1)\n",
        "\n",
        "thresholds = [round(x,3) for x in np.arange(0.05, 0.50, 0.05)]\n",
        "caps = [1500, 2000]\n",
        "dmax_list = [25.0, 30.0]\n",
        "results = []\n",
        "t_start = time.time()\n",
        "for dmax in dmax_list:\n",
        "    for cap in caps:\n",
        "        best = (-1.0, None)\n",
        "        print(f'-- Sweep dmax={dmax} cap={cap} --', flush=True)\n",
        "        for th in thresholds:\n",
        "            m = eval_threshold(th, cap=cap, dmax=dmax)\n",
        "            results.append(dict(threshold=th, cap=cap, dmax=dmax, **m))\n",
        "            if m['f1'] > best[0]:\n",
        "                best = (m['f1'], th)\n",
        "            print(f\"th={th:.3f} F1={m['f1']:.4f} P={m['precision']:.4f} R={m['recall']:.4f} TP={m['TP']} FP={m['FP']} FN={m['FN']}\")\n",
        "        print(f'Best for dmax={dmax} cap={cap}: th={best[1]} F1={best[0]:.4f}', flush=True)\n",
        "print('Sweep took', f'{time.time()-t_start:.1f}s')\n",
        "\n",
        "df_res = pd.DataFrame(results)\n",
        "df_res.to_csv('det_threshold_sweep_fold0.csv', index=False)\n",
        "best_row = df_res.sort_values('f1', ascending=False).iloc[0]\n",
        "best_cfg = {\n",
        "    'fold': int(fold),\n",
        "    'best_threshold': float(best_row['threshold']),\n",
        "    'best_cap': int(best_row['cap']),\n",
        "    'best_dmax': float(best_row['dmax']),\n",
        "    'best_f1': float(best_row['f1'])\n",
        "}\n",
        "Path('det_threshold_best_fold0.json').write_text(json.dumps(best_cfg, indent=2))\n",
        "print('Best config:', best_cfg)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold0 GT points: (115648, 3)\nOOF preds loaded: (134993, 8) score stats: {'count': 134993.0, 'mean': 0.752571961456331, 'std': 0.303068402622556, 'min': 0.05000726506114006, '25%': 0.6306458711624146, '50%': 0.9149374961853027, '75%': 0.9648087620735168, 'max': 0.9984909296035767}\n-- Sweep dmax=25.0 cap=1500 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.050 F1=0.9233 P=0.9441 R=0.9034 TP=104475 FP=6181 FN=11173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.100 F1=0.9235 P=0.9482 R=0.9001 TP=104094 FP=5688 FN=11554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.150 F1=0.9233 P=0.9508 R=0.8973 TP=103770 FP=5364 FN=11878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.200 F1=0.9227 P=0.9530 R=0.8943 TP=103427 FP=5101 FN=12221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.250 F1=0.9215 P=0.9547 R=0.8906 TP=102998 FP=4887 FN=12650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.300 F1=0.9201 P=0.9563 R=0.8865 TP=102520 FP=4688 FN=13128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.350 F1=0.9182 P=0.9579 R=0.8817 TP=101965 FP=4485 FN=13683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.400 F1=0.9157 P=0.9592 R=0.8760 TP=101306 FP=4313 FN=14342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.450 F1=0.9125 P=0.9604 R=0.8692 TP=100523 FP=4142 FN=15125\nBest for dmax=25.0 cap=1500: th=0.1 F1=0.9235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Sweep dmax=25.0 cap=2000 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.050 F1=0.9233 P=0.9441 R=0.9034 TP=104475 FP=6181 FN=11173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.100 F1=0.9235 P=0.9482 R=0.9001 TP=104094 FP=5688 FN=11554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.150 F1=0.9233 P=0.9508 R=0.8973 TP=103770 FP=5364 FN=11878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.200 F1=0.9227 P=0.9530 R=0.8943 TP=103427 FP=5101 FN=12221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.250 F1=0.9215 P=0.9547 R=0.8906 TP=102998 FP=4887 FN=12650\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.300 F1=0.9201 P=0.9563 R=0.8865 TP=102520 FP=4688 FN=13128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.350 F1=0.9182 P=0.9579 R=0.8817 TP=101965 FP=4485 FN=13683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.400 F1=0.9157 P=0.9592 R=0.8760 TP=101306 FP=4313 FN=14342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.450 F1=0.9125 P=0.9604 R=0.8692 TP=100523 FP=4142 FN=15125\nBest for dmax=25.0 cap=2000: th=0.1 F1=0.9235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Sweep dmax=30.0 cap=1500 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.050 F1=0.9356 P=0.9593 R=0.9130 TP=105587 FP=4477 FN=10061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.100 F1=0.9354 P=0.9626 R=0.9096 TP=105199 FP=4092 FN=10449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.150 F1=0.9348 P=0.9647 R=0.9067 TP=104863 FP=3834 FN=10785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.200 F1=0.9340 P=0.9664 R=0.9037 TP=104510 FP=3634 FN=11138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.250 F1=0.9326 P=0.9678 R=0.9000 TP=104078 FP=3467 FN=11570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.300 F1=0.9310 P=0.9690 R=0.8958 TP=103595 FP=3313 FN=12053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.350 F1=0.9288 P=0.9702 R=0.8909 TP=103027 FP=3164 FN=12621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.400 F1=0.9261 P=0.9711 R=0.8851 TP=102361 FP=3041 FN=13287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.450 F1=0.9228 P=0.9721 R=0.8783 TP=101570 FP=2916 FN=14078\nBest for dmax=30.0 cap=1500: th=0.05 F1=0.9356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Sweep dmax=30.0 cap=2000 --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.050 F1=0.9356 P=0.9593 R=0.9130 TP=105587 FP=4477 FN=10061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.100 F1=0.9354 P=0.9626 R=0.9096 TP=105199 FP=4092 FN=10449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.150 F1=0.9348 P=0.9647 R=0.9067 TP=104863 FP=3834 FN=10785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.200 F1=0.9340 P=0.9664 R=0.9037 TP=104510 FP=3634 FN=11138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.250 F1=0.9326 P=0.9678 R=0.9000 TP=104078 FP=3467 FN=11570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.300 F1=0.9310 P=0.9690 R=0.8958 TP=103595 FP=3313 FN=12053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.350 F1=0.9288 P=0.9702 R=0.8909 TP=103027 FP=3164 FN=12621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.400 F1=0.9261 P=0.9711 R=0.8851 TP=102361 FP=3041 FN=13287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.450 F1=0.9228 P=0.9721 R=0.8783 TP=101570 FP=2916 FN=14078\nBest for dmax=30.0 cap=2000: th=0.05 F1=0.9356\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweep took 39.4s\nBest config: {'fold': 0, 'best_threshold': 0.05, 'best_cap': 1500, 'best_dmax': 30.0, 'best_f1': 0.9355904869922733}\n"
          ]
        }
      ]
    },
    {
      "id": "78a880fe-999a-432c-89dc-21727e583cd9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Full detector training: Faster R-CNN R50-FPN, 1-class, 6-8 epochs with raised caps\n",
        "import time, math, json, gc\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device, 'GPU:', torch.cuda.get_device_name(0) if device.type=='cuda' else None)\n",
        "\n",
        "# Rebuild datasets/loaders if not in scope\n",
        "if 'train_loader' not in globals() or 'val_loader' not in globals():\n",
        "    df_train = pd.read_csv(train_csv)\n",
        "    df_folds = pd.read_csv(folds_csv)\n",
        "    train_ds = KuzDetDataset(df_train, df_folds, fold=fold, split='train')\n",
        "    val_ds = KuzDetDataset(df_train, df_folds, fold=fold, split='val')\n",
        "    batch_size = 2\n",
        "    num_workers = min(4, os.cpu_count() or 2)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True)\n",
        "\n",
        "# Build model fresh for full training\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT\n",
        "model = fasterrcnn_resnet50_fpn(weights=weights)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes=2)\n",
        "# Transform and size\n",
        "model.transform.min_size = (1333,)\n",
        "model.transform.max_size = 2000\n",
        "# Raise caps\n",
        "model.roi_heads.detections_per_img = 2000\n",
        "model.rpn.pre_nms_top_n_train = 4000\n",
        "model.rpn.post_nms_top_n_train = 2000\n",
        "model.rpn.pre_nms_top_n_test = 12000\n",
        "model.rpn.post_nms_top_n_test = 6000\n",
        "model.to(device)\n",
        "\n",
        "# Optim and scheduler per expert advice\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=5e-4)\n",
        "milestones = [4, 6]\n",
        "lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
        "scaler = torch.amp.GradScaler('cuda') if device.type=='cuda' else None\n",
        "\n",
        "def train_one_epoch_full(model, loader, epoch):\n",
        "    model.train()\n",
        "    t0 = time.time(); last = t0; tot=0.0; n=0\n",
        "    for i,(imgs,targets,ids) in enumerate(loader):\n",
        "        imgs = [im.to(device, non_blocking=True) for im in imgs]\n",
        "        tgts = [{k:(v.to(device) if torch.is_tensor(v) else v) for k,v in t.items()} for t in targets]\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        if scaler is not None:\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                loss_dict = model(imgs, tgts)\n",
        "                loss = sum(loss for loss in loss_dict.values())\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss_dict = model(imgs, tgts)\n",
        "            loss = sum(loss for loss in loss_dict.values())\n",
        "            loss.backward(); optimizer.step()\n",
        "        tot += float(loss.detach().item()); n += 1\n",
        "        if time.time()-last > 10:\n",
        "            mem = torch.cuda.memory_allocated()/1024**3 if device.type=='cuda' else 0.0\n",
        "            print(f'Epoch {epoch} iter {i} loss {loss.item():.4f} avg {tot/n:.4f} mem {mem:.2f}GB elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "            last = time.time()\n",
        "    print(f'Epoch {epoch} done avg {tot/max(1,n):.4f} time {time.time()-t0:.1f}s')\n",
        "\n",
        "# Train 8 epochs; save after each\n",
        "epochs = 8\n",
        "for ep in range(1, epochs+1):\n",
        "    train_one_epoch_full(model, train_loader, ep)\n",
        "    try:\n",
        "        lr_scheduler.step()\n",
        "    except Exception:\n",
        "        pass\n",
        "    ckpt = Path(f'detector_frcnn_r50_1cls_fold{fold}_ep{ep}.pth')\n",
        "    torch.save({'model': model.state_dict(), 'epoch': ep}, ckpt)\n",
        "    print('Saved', ckpt)\n",
        "    # quick val forward pass timing only (optional)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        cnt = 0; t0 = time.time()\n",
        "        for imgs,targets,ids in val_loader:\n",
        "            imgs = [im.to(device) for im in imgs]\n",
        "            _ = model(imgs)\n",
        "            cnt += 1\n",
        "            if cnt >= 5:\n",
        "                break\n",
        "        print(f'Val smoke infer {cnt} batches in {time.time()-t0:.1f}s')\n",
        "    model.train()\n",
        "    gc.collect();\n",
        "    if device.type=='cuda': torch.cuda.empty_cache()\n",
        "print('Full detector training finished.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0791e18c-d3ad-4e80-9895-7fa8ecdbe39e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Refinement sweep: th in [0.04..0.08], cap=1500, dmax=30; optional dedup radius=6\n",
        "import math, json, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "CWD = Path('.')\n",
        "train_csv = CWD / 'train.csv'\n",
        "folds_csv = CWD / 'folds_group.csv'\n",
        "oof_path = CWD / f'det_oof_fold{fold}.parquet'\n",
        "assert train_csv.exists() and folds_csv.exists() and oof_path.exists(), 'Missing inputs for refinement sweep'\n",
        "\n",
        "df_train = pd.read_csv(train_csv)\n",
        "df_folds = pd.read_csv(folds_csv)\n",
        "fold_map = dict(df_folds.values)\n",
        "\n",
        "def parse_labels_full(labels: str):\n",
        "    if not isinstance(labels, str) or labels.strip() == '':\n",
        "        return []\n",
        "    toks = labels.strip().split()\n",
        "    if len(toks) % 5 != 0:\n",
        "        return []\n",
        "    out = []\n",
        "    for i in range(0, len(toks), 5):\n",
        "        u, x, y, w, h = toks[i:i+5]\n",
        "        try:\n",
        "            x = int(x); y = int(y); w = int(w); h = int(h)\n",
        "            out.append((u, x, y, w, h))\n",
        "        except:\n",
        "            pass\n",
        "    return out\n",
        "\n",
        "# GT centers for fold 0\n",
        "gt_rows = []\n",
        "for r in df_train.itertuples(index=False):\n",
        "    image_id = getattr(r, 'image_id') if hasattr(r, 'image_id') else r[0]\n",
        "    if fold_map.get(image_id, None) != 0:\n",
        "        continue\n",
        "    labels = getattr(r, 'labels') if hasattr(r, 'labels') else r[1]\n",
        "    for (_, x, y, w, h) in parse_labels_full(labels):\n",
        "        gt_rows.append((image_id, x + w/2.0, y + h/2.0))\n",
        "df_gt = pd.DataFrame(gt_rows, columns=['image_id','cx','cy'])\n",
        "\n",
        "df_pred = pd.read_parquet(oof_path).copy()\n",
        "df_pred['cx'] = df_pred['x'] + df_pred['w']/2.0\n",
        "df_pred['cy'] = df_pred['y'] + df_pred['h']/2.0\n",
        "\n",
        "def dedup_centers(dd: pd.DataFrame, radius: float = 6.0) -> pd.DataFrame:\n",
        "    out = []\n",
        "    for img_id, g in dd.groupby('image_id'):\n",
        "        g = g.sort_values('score', ascending=False).reset_index(drop=True)\n",
        "        keep_idx = []\n",
        "        kept = []\n",
        "        for i, (cx, cy, sc) in enumerate(g[['cx','cy','score']].itertuples(index=False, name=None)):\n",
        "            ok = True\n",
        "            for (kx, ky) in kept:\n",
        "                if (cx - kx)**2 + (cy - ky)**2 <= radius*radius:\n",
        "                    ok = False; break\n",
        "            if ok:\n",
        "                keep_idx.append(i); kept.append((cx, cy))\n",
        "        out.append(g.iloc[keep_idx])\n",
        "    if len(out) == 0:\n",
        "        return dd.iloc[0:0]\n",
        "    return pd.concat(out, axis=0).reset_index(drop=True)\n",
        "\n",
        "def eval_threshold(th, cap=1500, dmax=30.0, use_dedup=False, radius=6.0):\n",
        "    dd = df_pred.loc[df_pred['score'] >= th, ['image_id','cx','cy','score']].copy()\n",
        "    dd = dd.sort_values(['image_id','score'], ascending=[True, False])\n",
        "    dd['rn'] = dd.groupby('image_id').cumcount()\n",
        "    dd = dd[dd['rn'] < cap].drop(columns=['rn'])\n",
        "    if use_dedup:\n",
        "        dd = dedup_centers(dd, radius=radius)\n",
        "    g_gt = df_gt.groupby('image_id')\n",
        "    g_pr = dd.groupby('image_id')\n",
        "    TP = 0; FP = 0; FN = 0\n",
        "    for image_id, gt_g in g_gt:\n",
        "        gt_pts = gt_g[['cx','cy']].to_numpy()\n",
        "        pr_g = g_pr.get_group(image_id) if image_id in g_pr.groups else None\n",
        "        pr_pts = pr_g[['cx','cy','score']].to_numpy() if pr_g is not None else np.zeros((0,3), dtype=np.float32)\n",
        "        matched_gt = np.zeros((len(gt_pts),), dtype=bool)\n",
        "        if len(pr_pts) and len(gt_pts):\n",
        "            pr_ord = np.argsort(-pr_pts[:,2])\n",
        "            for idx in pr_ord:\n",
        "                px, py, _ = pr_pts[idx]\n",
        "                d2 = ((gt_pts[:,0]-px)**2 + (gt_pts[:,1]-py)**2)\n",
        "                j = int(np.argmin(d2))\n",
        "                if matched_gt[j]:\n",
        "                    FP += 1; continue\n",
        "                if math.sqrt(float(d2[j])) <= dmax:\n",
        "                    matched_gt[j] = True; TP += 1\n",
        "                else:\n",
        "                    FP += 1\n",
        "            FN += int((~matched_gt).sum())\n",
        "        else:\n",
        "            FN += len(gt_pts)\n",
        "            FP += 0 if len(pr_pts)==0 else len(pr_pts)\n",
        "    prec = TP / max(1, TP+FP); rec = TP / max(1, TP+FN)\n",
        "    f1 = 2*prec*rec / max(1e-12, (prec+rec)) if (prec+rec) > 0 else 0.0\n",
        "    return dict(TP=TP, FP=FP, FN=FN, precision=prec, recall=rec, f1=f1)\n",
        "\n",
        "thresholds = [0.04, 0.045, 0.05, 0.055, 0.06, 0.07, 0.08]\n",
        "results = []\n",
        "t0 = time.time()\n",
        "for th in thresholds:\n",
        "    m0 = eval_threshold(th, cap=1500, dmax=30.0, use_dedup=False)\n",
        "    m1 = eval_threshold(th, cap=1500, dmax=30.0, use_dedup=True, radius=6.0)\n",
        "    results.append(dict(threshold=th, cap=1500, dmax=30.0, dedup=False, **m0))\n",
        "    results.append(dict(threshold=th, cap=1500, dmax=30.0, dedup=True, **m1))\n",
        "    print(f'th={th:.3f} no-dedup F1={m0[\"f1\"]:.4f} P={m0[\"precision\"]:.4f} R={m0[\"recall\"]:.4f} | dedup F1={m1[\"f1\"]:.4f} P={m1[\"precision\"]:.4f} R={m1[\"recall\"]:.4f}')\n",
        "print('Refinement sweep took', f'{time.time()-t0:.1f}s')\n",
        "\n",
        "df_ref = pd.DataFrame(results)\n",
        "df_ref.to_csv('det_threshold_sweep_refined_fold0.csv', index=False)\n",
        "df_sorted = df_ref.sort_values(['f1','precision'], ascending=[False, False]).reset_index(drop=True)\n",
        "best_row = df_sorted.iloc[0]\n",
        "best_cfg = {\n",
        "    'fold': int(fold),\n",
        "    'best_threshold': float(best_row['threshold']),\n",
        "    'best_cap': int(best_row['cap']),\n",
        "    'best_dmax': float(best_row['dmax']),\n",
        "    'best_f1': float(best_row['f1']),\n",
        "    'dedup': bool(best_row['dedup']),\n",
        "    'dedup_radius': 6.0\n",
        "}\n",
        "Path('det_threshold_best_fold0.json').write_text(json.dumps(best_cfg, indent=2))\n",
        "print('Refined best config (overwrote det_threshold_best_fold0.json):', best_cfg)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.040 no-dedup F1=0.8425 P=0.7822 R=0.9130 | dedup F1=0.8447 P=0.7860 R=0.9130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.045 no-dedup F1=0.8425 P=0.7822 R=0.9130 | dedup F1=0.8447 P=0.7860 R=0.9130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.050 no-dedup F1=0.8425 P=0.7822 R=0.9130 | dedup F1=0.8447 P=0.7860 R=0.9130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.055 no-dedup F1=0.8458 P=0.7880 R=0.9127 | dedup F1=0.8479 P=0.7916 R=0.9127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.060 no-dedup F1=0.8490 P=0.7939 R=0.9123 | dedup F1=0.8509 P=0.7973 R=0.9123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.070 no-dedup F1=0.8542 P=0.8037 R=0.9115 | dedup F1=0.8560 P=0.8068 R=0.9115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "th=0.080 no-dedup F1=0.8588 P=0.8124 R=0.9109 | dedup F1=0.8603 P=0.8151 R=0.9108\nRefinement sweep took 31.4s\nRefined best config (overwrote det_threshold_best_fold0.json): {'fold': 0, 'best_threshold': 0.08, 'best_cap': 1500, 'best_dmax': 30.0, 'best_f1': 0.8603257962160595, 'dedup': True, 'dedup_radius': 6.0}\n"
          ]
        }
      ]
    },
    {
      "id": "9c715d67-6981-48a0-ac4e-838abe24153c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Assemble submission using tuned detector filter (+optional dedup) and best recognizer EMA checkpoint (optimized I/O: open image once per page)\n",
        "import json, time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageOps\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms as T\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "CWD = Path('.')\n",
        "best_cfg_path = CWD / 'det_threshold_best_fold0.json'\n",
        "det_test_path = CWD / 'det_test_preds.parquet'\n",
        "classes_path = CWD / 'recognizer_classes.json'\n",
        "best_ckpt_path = CWD / 'recognizer_resnet50_fold0_best.pth'\n",
        "test_dir = CWD / 'test_images'\n",
        "sample_path = CWD / 'sample_submission.csv'\n",
        "assert best_cfg_path.exists() and det_test_path.exists() and classes_path.exists() and best_ckpt_path.exists() and sample_path.exists(), 'Missing artifacts for assembly'\n",
        "\n",
        "best_cfg = json.loads(best_cfg_path.read_text())\n",
        "th = float(best_cfg['best_threshold']); cap = int(best_cfg['best_cap'])\n",
        "use_dedup = bool(best_cfg.get('dedup', False))\n",
        "dedup_radius = float(best_cfg.get('dedup_radius', 6.0))\n",
        "print('Using detector filter:', best_cfg)\n",
        "\n",
        "det_df = pd.read_parquet(det_test_path)\n",
        "print('Raw test preds:', det_df.shape, 'score stats:', det_df['score'].describe().to_dict())\n",
        "det_df = det_df[det_df['score'] >= th].copy()\n",
        "det_df.sort_values(['image_id','score'], ascending=[True, False], inplace=True)\n",
        "det_df['rn'] = det_df.groupby('image_id').cumcount()\n",
        "det_df = det_df[det_df['rn'] < cap].drop(columns=['rn'])\n",
        "\n",
        "def dedup_centers_df(df_img: pd.DataFrame, radius: float = 6.0) -> pd.DataFrame:\n",
        "    if len(df_img) <= 1:\n",
        "        return df_img\n",
        "    g = df_img.sort_values('score', ascending=False).reset_index(drop=True)\n",
        "    keep_idx = []\n",
        "    kept = []\n",
        "    for i in range(len(g)):\n",
        "        cx = float(g.loc[i, 'x'] + g.loc[i, 'w']/2.0)\n",
        "        cy = float(g.loc[i, 'y'] + g.loc[i, 'h']/2.0)\n",
        "        ok = True\n",
        "        for (kx, ky) in kept:\n",
        "            if (cx - kx)*(cx - kx) + (cy - ky)*(cy - ky) <= radius*radius:\n",
        "                ok = False; break\n",
        "        if ok:\n",
        "            keep_idx.append(i); kept.append((cx, cy))\n",
        "    return g.iloc[keep_idx].reset_index(drop=True)\n",
        "\n",
        "if use_dedup:\n",
        "    parts = []\n",
        "    for img_id, g in det_df.groupby('image_id'):\n",
        "        parts.append(dedup_centers_df(g, radius=dedup_radius))\n",
        "    det_df = pd.concat(parts, axis=0).reset_index(drop=True) if parts else det_df.iloc[0:0]\n",
        "print('Filtered test preds:', det_df.shape, 'dedup applied:' , use_dedup)\n",
        "\n",
        "class_to_idx = json.loads(classes_path.read_text())\n",
        "idx_to_class = {int(v): k for k, v in class_to_idx.items()}\n",
        "num_classes = len(idx_to_class)\n",
        "rec_model = resnet50(weights=None)\n",
        "rec_model.fc = nn.Linear(rec_model.fc.in_features, num_classes)\n",
        "state = torch.load(best_ckpt_path, map_location='cpu')\n",
        "rec_model.load_state_dict(state['model'], strict=False)\n",
        "rec_model.to(device)\n",
        "rec_model.eval()\n",
        "\n",
        "val_tf = T.Compose([T.ToTensor(), T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n",
        "\n",
        "def clamp(v, lo, hi):\n",
        "    return max(lo, min(hi, v))\n",
        "\n",
        "def crop_from_box_img(img: Image.Image, x: float, y: float, w: float, h: float, pad_ratio: float=0.25, img_size: int=192):\n",
        "    W, H = img.size\n",
        "    dx = int(round(w * pad_ratio)); dy = int(round(h * pad_ratio))\n",
        "    x1 = clamp(int(x) - dx, 0, W-1); y1 = clamp(int(y) - dy, 0, H-1)\n",
        "    x2 = clamp(int(x + w) + dx, 1, W); y2 = clamp(int(y + h) + dy, 1, H)\n",
        "    crop = img.crop((x1, y1, x2, y2))\n",
        "    cw, ch = crop.size\n",
        "    if cw != ch:\n",
        "        m = max(cw, ch)\n",
        "        pad_w = m - cw; pad_h = m - ch\n",
        "        crop = ImageOps.expand(crop, border=(0,0,pad_w,pad_h), fill=0)\n",
        "    return crop.resize((192, 192), Image.BILINEAR)\n",
        "\n",
        "df_sample = pd.read_csv(sample_path)\n",
        "grp = det_df.groupby('image_id')\n",
        "rows_out = []\n",
        "t0 = time.time()\n",
        "for i, image_id in enumerate(df_sample['image_id'].tolist(), 1):\n",
        "    if image_id in grp.groups:\n",
        "        g = grp.get_group(image_id)\n",
        "        # Open the page once (major speed-up vs opening per box)\n",
        "        p = test_dir / f'{image_id}.jpg'\n",
        "        if not p.exists():\n",
        "            alt = test_dir / f'{image_id}.png'\n",
        "            if alt.exists():\n",
        "                p = alt\n",
        "        img = Image.open(p).convert('RGB')\n",
        "        # Build crops from the single opened image\n",
        "        crops = [crop_from_box_img(img, x, y, w, h) for x,y,w,h in zip(g['x'].values, g['y'].values, g['w'].values, g['h'].values)]\n",
        "        if len(crops) == 0:\n",
        "            rows_out.append('')\n",
        "        else:\n",
        "            xs = torch.stack([val_tf(c) for c in crops]).to(device)\n",
        "            with torch.no_grad():\n",
        "                logits = rec_model(xs)\n",
        "                pred_idx = logits.argmax(1).detach().cpu().numpy().tolist()\n",
        "            pred_unicodes = [idx_to_class.get(int(k), 'U+003F') for k in pred_idx]\n",
        "            cx = (g['x'].values + g['w'].values/2.0).round().astype(int).tolist()\n",
        "            cy = (g['y'].values + g['h'].values/2.0).round().astype(int).tolist()\n",
        "            toks = []\n",
        "            for u, x_, y_ in zip(pred_unicodes, cx, cy):\n",
        "                toks.extend([u, str(int(x_)), str(int(y_))])\n",
        "            rows_out.append(' '.join(toks))\n",
        "    else:\n",
        "        rows_out.append('')\n",
        "    if i % 25 == 0:\n",
        "        print(f'Assembled {i}/{len(df_sample)} in {time.time()-t0:.1f}s', flush=True)\n",
        "\n",
        "sub_df = pd.DataFrame({'image_id': df_sample['image_id'], 'labels': rows_out})\n",
        "sub_df.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv with shape', sub_df.shape)\n",
        "print(sub_df.head(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using detector filter: {'fold': 0, 'best_threshold': 0.08, 'best_cap': 1500, 'best_dmax': 30.0, 'best_f1': 0.8603257962160595, 'dedup': True, 'dedup_radius': 6.0}\nRaw test preds: (78959, 6) score stats: {'count': 78959.0, 'mean': 0.7546936687092951, 'std': 0.29837606507519804, 'min': 0.05002911761403084, '25%': 0.6375642716884613, '50%': 0.9123088717460632, '75%': 0.9650175869464874, 'max': 0.9979872703552246}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered test preds: (75767, 6) dedup applied: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_600/3598089559.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(best_ckpt_path, map_location='cpu')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}