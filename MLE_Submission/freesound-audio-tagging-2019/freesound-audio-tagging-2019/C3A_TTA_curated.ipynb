{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d31c08b",
   "metadata": {},
   "source": [
    "\n",
    "# C3A: Multi-Crop Embedding TTA (K=5) â€” Curated Only Stage\n",
    "\n",
    "This staged notebook implements K=5 deterministic multi-crop TTA at the embedding level using PANNs CNN14 for curated data only, computes OOF LWLRAP, and caches artifacts.\n",
    "- Crops per clip (target T=10s @ 32kHz): begin, center, end, 25% offset, 75% offset.\n",
    "- Aggregation: mean across the 5 embeddings (no pre-normalization).\n",
    "- CV: fixed 5-fold MLSKF from train_curated_folds.csv (seed=42).\n",
    "- Outputs: embeddings_curated_mc5.npy, metadata_c3a.json; OOF (oof_tta.npy), per-fold LWLRAP.\n",
    "- Test MC5 extraction and submission are deferred to a separate follow-up stage after OOF verification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269ab47f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T04:09:59.008447Z",
     "iopub.status.busy": "2025-08-12T04:09:59.007804Z",
     "iopub.status.idle": "2025-08-12T04:10:07.288306Z",
     "shell.execute_reply": "2025-08-12T04:10:07.287622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soundfile already available\n",
      "librosa already available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed: iterative-stratification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joblib already available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed: scikit-learn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panns-inference already available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions: {'librosa': '0.11.0', 'torch': '2.4.1+cu121', 'sklearn': '1.5.2'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, subprocess, os, json, time, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "def pip_install(pkg):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--quiet', pkg])\n",
    "        print(f'Installed: {pkg}')\n",
    "    except Exception as e:\n",
    "        print(f'Failed to install {pkg}: {e}')\n",
    "\n",
    "for pkg in ['soundfile', 'librosa', 'iterative-stratification', 'joblib', 'scikit-learn', 'panns-inference']:\n",
    "    try:\n",
    "        __import__(pkg.split('==')[0].replace('-', '_'))\n",
    "        print(f\"{pkg.split('==')[0]} already available\")\n",
    "    except Exception:\n",
    "        pip_install(pkg)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "import joblib\n",
    "BASE = Path('.')\n",
    "np.random.seed(42)\n",
    "print('Versions:', {k:__import__(k).__version__ if hasattr(__import__(k), '__version__') else 'n/a' for k in ['librosa','torch','sklearn']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f363edfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T04:10:07.291356Z",
     "iopub.status.busy": "2025-08-12T04:10:07.290982Z",
     "iopub.status.idle": "2025-08-12T04:10:07.299599Z",
     "shell.execute_reply": "2025-08-12T04:10:07.298938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels CSV exists at /app/panns_data/class_labels_indices.csv\n",
      "CNN14 checkpoint present: /app/panns_data/Cnn14_mAP=0.431.pth size: 327428481\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "assets_dir = Path('/app/panns_data')\n",
    "assets_dir.mkdir(parents=True, exist_ok=True)\n",
    "labels_csv = assets_dir / 'class_labels_indices.csv'\n",
    "if not labels_csv.exists():\n",
    "    import csv\n",
    "    with open(labels_csv, 'w', newline='') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['index','mid','display_name'])\n",
    "        for i in range(527):\n",
    "            w.writerow([i, f'/m/{i}', f'class_{i:03d}'])\n",
    "    print('Created labels stub at', labels_csv)\n",
    "else:\n",
    "    print('Labels CSV exists at', labels_csv)\n",
    "\n",
    "ckpt_path = assets_dir / 'Cnn14_mAP=0.431.pth'\n",
    "url = 'https://zenodo.org/record/3987831/files/Cnn14_mAP=0.431.pth?download=1'\n",
    "if not ckpt_path.exists() or ckpt_path.stat().st_size == 0:\n",
    "    print('Downloading CNN14 weights ...')\n",
    "    with urllib.request.urlopen(url) as resp, open(ckpt_path, 'wb') as out:\n",
    "        while True:\n",
    "            chunk = resp.read(1<<20)\n",
    "            if not chunk:\n",
    "                break\n",
    "            out.write(chunk)\n",
    "    print('Saved CNN14 to', ckpt_path, 'size:', ckpt_path.stat().st_size)\n",
    "else:\n",
    "    print('CNN14 checkpoint present:', ckpt_path, 'size:', ckpt_path.stat().st_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63daf611",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T04:10:07.302264Z",
     "iopub.status.busy": "2025-08-12T04:10:07.302041Z",
     "iopub.status.idle": "2025-08-12T04:10:07.488116Z",
     "shell.execute_reply": "2025-08-12T04:10:07.487330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded folds and helpers. Fold counts: {0: 999, 1: 994, 2: 992, 3: 997, 4: 988}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import json\n",
    "BASE = Path('.')\n",
    "df_cur = pd.read_csv(BASE / 'train_curated_folds.csv')\n",
    "df_ss  = pd.read_csv(BASE / 'sample_submission.csv')\n",
    "class_names = [c for c in df_ss.columns if c != 'fname']\n",
    "label_to_idx = {c:i for i,c in enumerate(class_names)}\n",
    "n_classes = len(class_names)\n",
    "\n",
    "def parse_labels_str(s):\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    toks = [t.strip() for t in s.replace(';', ',').split(',') if t.strip()]\n",
    "    unknown = [t for t in toks if t not in label_to_idx]\n",
    "    if unknown:\n",
    "        raise ValueError(f'Unknown labels: {unknown[:5]} (total {len(unknown)})')\n",
    "    return toks\n",
    "\n",
    "def encode_tokens(toks):\n",
    "    y = np.zeros(n_classes, dtype=np.float32)\n",
    "    for t in toks:\n",
    "        y[label_to_idx[t]] = 1.0\n",
    "    return y\n",
    "\n",
    "def encode_labels(s):\n",
    "    return encode_tokens(parse_labels_str(s))\n",
    "\n",
    "def lwlrap_np(truth, scores):\n",
    "    assert truth.shape == scores.shape\n",
    "    n_samples, n_labels = truth.shape\n",
    "    precisions = np.zeros(n_labels)\n",
    "    labels_per_class = np.maximum(truth.sum(axis=0), 1)\n",
    "    for i in range(n_samples):\n",
    "        pos = np.where(truth[i] > 0)[0]\n",
    "        if pos.size == 0:\n",
    "            continue\n",
    "        ranking = np.argsort(-scores[i])\n",
    "        ranked_truth = truth[i][ranking]\n",
    "        cumsum = np.cumsum(ranked_truth)\n",
    "        pos_rank = np.where(ranked_truth > 0)[0]\n",
    "        prec = cumsum[pos_rank] / (pos_rank + 1)\n",
    "        ranked_labels = ranking[pos_rank]\n",
    "        for lbl, p in zip(ranked_labels, prec):\n",
    "            precisions[lbl] += p\n",
    "    per_class = precisions / labels_per_class\n",
    "    weights = truth.sum(axis=0) / max(truth.sum(), 1)\n",
    "    return float((per_class * weights).sum()), per_class\n",
    "\n",
    "print('Loaded folds and helpers. Fold counts:', df_cur['fold'].value_counts().sort_index().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36127702",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T04:10:07.491451Z",
     "iopub.status.busy": "2025-08-12T04:10:07.491206Z",
     "iopub.status.idle": "2025-08-12T04:10:07.990336Z",
     "shell.execute_reply": "2025-08-12T04:10:07.989624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached curated MC5 embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata_c3a.json written with provenance.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, time, json, hashlib\n",
    "import librosa, torch\n",
    "from panns_inference import AudioTagging\n",
    "\n",
    "BASE = Path('.')\n",
    "SR = 32000\n",
    "T_SEC = 10.0\n",
    "T = int(SR * T_SEC)\n",
    "K = 5\n",
    "EMB_DIM = 2048\n",
    "CKPT_PATH = Path('/app/panns_data/Cnn14_mAP=0.431.pth')\n",
    "assert CKPT_PATH.exists(), 'Checkpoint missing; run Cell 3.'\n",
    "\n",
    "def load_audio(path, sr=SR):\n",
    "    y, s = librosa.load(path, sr=sr, mono=True)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "def crop_starts(L, T):\n",
    "    if L <= T:\n",
    "        return [0, 0, 0, 0, 0]\n",
    "    starts = [0, (L - T)//2, L - T, int(0.25*(L - T)), int(0.75*(L - T))]\n",
    "    starts = [max(0, min(s, L - T)) for s in starts]\n",
    "    return starts\n",
    "\n",
    "def crops_for_wave(y, T):\n",
    "    L = len(y)\n",
    "    starts = crop_starts(L, T)\n",
    "    crops = []\n",
    "    for s in starts:\n",
    "        if L >= T:\n",
    "            crops.append(y[s:s+T])\n",
    "        else:\n",
    "            pad = np.pad(y, (0, T - L))\n",
    "            crops.append(pad)\n",
    "    return np.stack(crops, 0)  # (K, T)\n",
    "\n",
    "def sha1_of_file(path: Path, block_size=1<<20):\n",
    "    h = hashlib.sha1()\n",
    "    with open(path, 'rb') as f:\n",
    "        while True:\n",
    "            b = f.read(block_size)\n",
    "            if not b:\n",
    "                break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def extract_mc5_embeddings_curated(file_list, root_dir, log_every=100):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    at = AudioTagging(checkpoint_path=str(CKPT_PATH), device=device)\n",
    "    X = np.zeros((len(file_list), EMB_DIM), dtype=np.float32)\n",
    "    t0 = time.time()\n",
    "    for i, fname in enumerate(file_list):\n",
    "        y = load_audio(str(Path(root_dir) / fname), sr=SR)\n",
    "        crops = crops_for_wave(y, T)  # (5, T)\n",
    "        with torch.no_grad():\n",
    "            out = at.inference(crops)  # batched inference on (5, T)\n",
    "        if isinstance(out, tuple) and len(out)==2:\n",
    "            embs = np.asarray(out[1], dtype=np.float32)  # (5, 2048)\n",
    "        elif isinstance(out, dict) and 'embedding' in out:\n",
    "            embs = np.asarray(out['embedding'], dtype=np.float32)\n",
    "        else:\n",
    "            raise RuntimeError('Unexpected AudioTagging output type')\n",
    "        assert embs.ndim == 2 and embs.shape[1] == EMB_DIM, f'Bad embedding shape: {embs.shape}'\n",
    "        X[i] = embs.mean(axis=0)\n",
    "        if (i+1) % log_every == 0:\n",
    "            dt = time.time() - t0\n",
    "            print(f'  Curated MC5: {i+1}/{len(file_list)} in {dt/60:.1f} min')\n",
    "    assert X.shape == (len(file_list), EMB_DIM), f'Output shape mismatch: {X.shape}'\n",
    "    return X\n",
    "\n",
    "df_cur = pd.read_csv(BASE / 'train_curated_folds.csv')\n",
    "train_files = df_cur['fname'].values\n",
    "\n",
    "emb_cur_mc5_path = BASE / 'embeddings_curated_mc5.npy'\n",
    "if emb_cur_mc5_path.exists():\n",
    "    X_cur = np.load(emb_cur_mc5_path)\n",
    "    print('Loaded cached curated MC5 embeddings.')\n",
    "else:\n",
    "    print('Extracting curated MC5 embeddings ...')\n",
    "    X_cur = extract_mc5_embeddings_curated(train_files, root_dir=BASE/'train_curated', log_every=100)\n",
    "    np.save(emb_cur_mc5_path, X_cur)\n",
    "    print('Saved curated MC5 embeddings.')\n",
    "\n",
    "import torch as _torch, librosa as _librosa\n",
    "ckpt_size = CKPT_PATH.stat().st_size if CKPT_PATH.exists() else None\n",
    "ckpt_sha1 = sha1_of_file(CKPT_PATH) if CKPT_PATH.exists() else None\n",
    "meta = {\n",
    "    'tta': 'mc5',\n",
    "    'sr': SR, 'T_sec': T_SEC, 'T': T,\n",
    "    'crops': 'begin,center,end,25%,75%',\n",
    "    'aggregation': 'mean',\n",
    "    'stage': 'curated_only',\n",
    "    'versions': {'torch': getattr(_torch, '__version__', 'n/a'), 'librosa': getattr(_librosa, '__version__', 'n/a')},\n",
    "    'checkpoint': {'path': str(CKPT_PATH), 'size_bytes': ckpt_size, 'sha1': ckpt_sha1}\n",
    "}\n",
    "with open('metadata_c3a.json', 'w') as f:\n",
    "    json.dump(meta, f)\n",
    "print('metadata_c3a.json written with provenance.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb92646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T04:10:07.993323Z",
     "iopub.status.busy": "2025-08-12T04:10:07.993098Z",
     "iopub.status.idle": "2025-08-12T04:11:15.561617Z",
     "shell.execute_reply": "2025-08-12T04:11:15.560293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 LWLRAP (MC5 curated)=0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 LWLRAP (MC5 curated)=0.8058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 LWLRAP (MC5 curated)=0.8127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 LWLRAP (MC5 curated)=0.8160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 LWLRAP (MC5 curated)=0.7810\n",
      "OOF LWLRAP (MC5 curated)=0.8049; per-fold=[0.8125134119899252, 0.8058232379476366, 0.8127316131414057, 0.8160070710672407, 0.7809753987693859]\n",
      "Persisted metrics to metrics_c3a_curated.json: {'stage': 'C3A_curated_mc5', 'oof_lwlrap': 0.8049036654978639, 'per_fold_lwlrap': [0.8125134119899252, 0.8058232379476366, 0.8127316131414057, 0.8160070710672407, 0.7809753987693859], 'delta_vs_c2_baseline': 0.004803665497863818, 'tta_scheme': 'mc5_mean', 'checkpoint_sha1': '5f73e32676afd7a763ddec6693d975be16859f90'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "BASE = Path('.')\n",
    "df_cur = pd.read_csv(BASE / 'train_curated_folds.csv')\n",
    "df_ss  = pd.read_csv(BASE / 'sample_submission.csv')\n",
    "class_names = [c for c in df_ss.columns if c != 'fname']\n",
    "label_to_idx = {c:i for i,c in enumerate(class_names)}\n",
    "n_classes = len(class_names)\n",
    "\n",
    "def parse_labels_str(s):\n",
    "    if not isinstance(s, str):\n",
    "        return []\n",
    "    toks = [t.strip() for t in s.replace(';', ',').split(',') if t.strip()]\n",
    "    return toks\n",
    "\n",
    "def encode_labels(s):\n",
    "    y = np.zeros(n_classes, dtype=np.float32)\n",
    "    for t in parse_labels_str(s):\n",
    "        if t in label_to_idx:\n",
    "            y[label_to_idx[t]] = 1.0\n",
    "    return y\n",
    "\n",
    "def lwlrap_np(truth, scores):\n",
    "    assert truth.shape == scores.shape\n",
    "    n_samples, n_labels = truth.shape\n",
    "    precisions = np.zeros(n_labels)\n",
    "    labels_per_class = np.maximum(truth.sum(axis=0), 1)\n",
    "    for i in range(n_samples):\n",
    "        pos = np.where(truth[i] > 0)[0]\n",
    "        if pos.size == 0:\n",
    "            continue\n",
    "        ranking = np.argsort(-scores[i])\n",
    "        ranked_truth = truth[i][ranking]\n",
    "        cumsum = np.cumsum(ranked_truth)\n",
    "        pos_rank = np.where(ranked_truth > 0)[0]\n",
    "        prec = cumsum[pos_rank] / (pos_rank + 1)\n",
    "        ranked_labels = ranking[pos_rank]\n",
    "        for lbl, p in zip(ranked_labels, prec):\n",
    "            precisions[lbl] += p\n",
    "    per_class = precisions / labels_per_class\n",
    "    weights = truth.sum(axis=0) / max(truth.sum(), 1)\n",
    "    return float((per_class * weights).sum()), per_class\n",
    "\n",
    "X_cur = np.load('embeddings_curated_mc5.npy')\n",
    "assert X_cur.ndim == 2 and X_cur.shape[1] == 2048, f'Embeddings shape invalid: {X_cur.shape}'\n",
    "Y_cur = np.stack(df_cur['labels'].apply(encode_labels).values).astype(np.float32)\n",
    "\n",
    "oof = np.zeros((len(df_cur), n_classes), dtype=np.float32)\n",
    "fold_scores = []\n",
    "for k in range(5):\n",
    "    trn_idx = np.where(df_cur['fold'].values != k)[0]\n",
    "    val_idx = np.where(df_cur['fold'].values == k)[0]\n",
    "    X_tr, X_va = X_cur[trn_idx], X_cur[val_idx]\n",
    "    y_tr, y_va = Y_cur[trn_idx], Y_cur[val_idx]\n",
    "    base_lr = LogisticRegression(solver='lbfgs', max_iter=1000, C=2.0, n_jobs=16, verbose=0)\n",
    "    clf = OneVsRestClassifier(make_pipeline(StandardScaler(with_mean=True, with_std=True), base_lr), n_jobs=-1)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    proba = clf.predict_proba(X_va)\n",
    "    oof[val_idx] = proba.astype(np.float32)\n",
    "    lw, _ = lwlrap_np(y_va, proba)\n",
    "    fold_scores.append(lw)\n",
    "    print(f'Fold {k} LWLRAP (MC5 curated)={lw:.4f}')\n",
    "oof_lw, _ = lwlrap_np(Y_cur, oof)\n",
    "print(f'OOF LWLRAP (MC5 curated)={oof_lw:.4f}; per-fold={fold_scores}')\n",
    "np.save('oof_tta.npy', oof)\n",
    "\n",
    "# Mandatory metrics persistence\n",
    "BASELINE = 0.8001\n",
    "delta = float(oof_lw - BASELINE)\n",
    "ck_sha1 = None\n",
    "try:\n",
    "    with open('metadata_c3a.json', 'r') as f:\n",
    "        meta = json.load(f)\n",
    "    ck_sha1 = meta.get('checkpoint', {}).get('sha1')\n",
    "except Exception:\n",
    "    pass\n",
    "metrics = {\n",
    "    'stage': 'C3A_curated_mc5',\n",
    "    'oof_lwlrap': float(oof_lw),\n",
    "    'per_fold_lwlrap': [float(x) for x in fold_scores],\n",
    "    'delta_vs_c2_baseline': delta,\n",
    "    'tta_scheme': 'mc5_mean',\n",
    "    'checkpoint_sha1': ck_sha1\n",
    "}\n",
    "with open('metrics_c3a_curated.json', 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "print('Persisted metrics to metrics_c3a_curated.json:', metrics)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
