{
  "cells": [
    {
      "id": "c94ae4ad-8cd5-4228-b505-45809da57da8",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UW-Madison GI Tract Segmentation \u2014 Plan to Medal\n",
        "\n",
        "Objectives:\n",
        "- Build a robust CV pipeline (patient-wise splits) mirroring LB.\n",
        "- Establish fast, reliable baseline; iterate to medal.\n",
        "\n",
        "Milestones:\n",
        "1) Environment + GPU gate\n",
        "   - Verify GPU (nvidia-smi). Install torch/cu121 stack, smp, albumentations.\n",
        "   - Add timing/progress logging utilities.\n",
        "\n",
        "2) Data audit and EDA\n",
        "   - Inspect train.csv/test.csv schema; parse rle strings by class.\n",
        "   - Confirm image paths, dimensions, per-case slice counts, empty-mask ratio.\n",
        "   - Visual sanity checks (few samples with overlays).\n",
        "\n",
        "3) Validation protocol\n",
        "   - GroupKFold by patient/case (no leakage across days/slices).\n",
        "   - 5 folds, deterministic seed; reuse fixed folds throughout.\n",
        "   - OOF dice per class; track dice-hausdorff proxy (avg Dice + HD95 via medpy/skimage).\n",
        "\n",
        "4) Baseline data pipeline\n",
        "   - Load grayscale PNGs; stack 2.5D context (e.g., prev/cur/next slices \u2192 3ch).\n",
        "   - Resize to 256x256 baseline (keep aspect; pad/crop).\n",
        "   - Augmentations: flips, small affine, brightness/contrast, elastic light.\n",
        "   - Convert RLE\u2192mask for 3 classes; mixed empty-slice sampling.\n",
        "\n",
        "5) Baseline model and loss\n",
        "   - UNet/UNet++ with ImageNet encoder (ResNet34/EfficientNet-b0) via segmentation_models_pytorch.\n",
        "   - Loss: 0.5*BCEWithLogits + 0.5*SoftDice; per-class weighting if imbalance observed.\n",
        "   - Optim: AdamW, LR ~1e-3 with CosineAnnealing, warmup; EMA weights.\n",
        "   - Mixed precision (amp), gradient clipping.\n",
        "\n",
        "6) Training strategy\n",
        "   - Epochs: ~40-60 at 256 res for quick OOF; early stopping on val dice.\n",
        "   - Save best by val score per fold; log per-epoch dice per class.\n",
        "   - Cache fold splits, OOF preds (npz) and test logits for later blends.\n",
        "\n",
        "7) Inference & post-processing\n",
        "   - TTA (h-flip, v-flip) average.\n",
        "   - Threshold tuning per class via OOF.\n",
        "   - Morphology: remove small blobs (class-wise min area), keep largest CC for bowel if helps.\n",
        "   - RLE encode to submission.csv.\n",
        "\n",
        "8) Iterations to medal\n",
        "   - Resolution ablation: 256 \u2192 384/512 if memory allows; compare OOF.\n",
        "   - 2.5D context window ablation (5ch with [-2,-1,0,+1,+2] via 3ch stride).\n",
        "   - Encoder sweep: ResNet34 \u2192 tf_efficientnet_b3/b4.\n",
        "   - Loss sweep: add Tversky/FocalDice; class weights.\n",
        "   - Blend diverse seeds/encoders/resolutions (weighted by OOF).\n",
        "\n",
        "9) Risk controls\n",
        "   - Strict fold reuse; no leakage.\n",
        "   - Sanity checks: mask overlay, non-empty ratio, OOF vs LB tracking.\n",
        "   - Log progress and time per fold; interrupt if stalled.\n",
        "\n",
        "Next actions:\n",
        "- Verify GPU and install torch/cu121 + deps.\n",
        "- EDA of csvs (schema, counts, empties).\n",
        "- Implement fold splitter (GroupKFold by case/day).\n",
        "- Build baseline dataset/loader + UNet(R34, 256) and run 5-fold smoke (few epochs)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c7ed82a3-cf83-48b7-a8d5-2b9301565b9e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment & GPU gate + Torch/cu121 stack install\n",
        "import os, sys, subprocess, shutil, time, textwrap, json\n",
        "from pathlib import Path\n",
        "\n",
        "def run(cmd):\n",
        "    print(\"> \", \" \".join(cmd), flush=True)\n",
        "    return subprocess.run(cmd, check=False, capture_output=True, text=True)\n",
        "\n",
        "print(\"[GPU CHECK] nvidia-smi:\", flush=True)\n",
        "out = run([\"bash\",\"-lc\",\"nvidia-smi || true\"])\n",
        "print(out.stdout)\n",
        "\n",
        "# Hard reset any prior torch stacks\n",
        "for pkg in (\"torch\",\"torchvision\",\"torchaudio\"):\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg], check=False)\n",
        "\n",
        "# Clean stray site dirs that can shadow correct wheels (idempotent)\n",
        "for d in (\n",
        "    \"/app/.pip-target/torch\",\n",
        "    \"/app/.pip-target/torchvision\",\n",
        "    \"/app/.pip-target/torchaudio\",\n",
        "    \"/app/.pip-target/torchgen\",\n",
        "    \"/app/.pip-target/functorch\",\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print(\"Removing\", d); shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "def pip(*args):\n",
        "    print(\"> pip\", \" \".join(args), flush=True)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", *args], check=True)\n",
        "\n",
        "# Install exact cu121 torch stack\n",
        "pip(\"install\",\n",
        "    \"--index-url\", \"https://download.pytorch.org/whl/cu121\",\n",
        "    \"--extra-index-url\", \"https://pypi.org/simple\",\n",
        "    \"torch==2.4.1\", \"torchvision==0.19.1\", \"torchaudio==2.4.1\")\n",
        "\n",
        "# Freeze constraints\n",
        "Path(\"constraints.txt\").write_text(\"\\n\".join([\n",
        "    \"torch==2.4.1\",\n",
        "    \"torchvision==0.19.1\",\n",
        "    \"torchaudio==2.4.1\",\n",
        "]))\n",
        "\n",
        "# Proactively remove albucore to avoid ABI mismatch with albumentations 1.4.x\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"albucore\"], check=False)\n",
        "\n",
        "# Install non-torch deps for this competition\n",
        "deps = [\n",
        "    \"segmentation-models-pytorch==0.3.3\",\n",
        "    \"timm==0.9.2\",  # SMP 0.3.3 pins timm==0.9.2\n",
        "    # Use albumentations 1.3.1 (no albucore dependency) to avoid runtime import issues\n",
        "    \"albumentations==1.3.1\",\n",
        "    \"opencv-python-headless==4.10.0.84\",\n",
        "    \"scikit-image\",\n",
        "    \"medpy\",\n",
        "    \"scikit-learn\",\n",
        "    \"pandas\",\n",
        "    \"numpy\",\n",
        "    \"matplotlib\",\n",
        "    \"pillow\",\n",
        "]\n",
        "pip(\"install\", \"-c\", \"constraints.txt\", *deps, \"--upgrade-strategy\", \"only-if-needed\")\n",
        "\n",
        "import torch\n",
        "print(\"torch:\", torch.__version__, \"built CUDA:\", getattr(torch.version, \"cuda\", None))\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "assert str(getattr(torch.version, \"cuda\", \"\")).startswith(\"12.1\"), f\"Wrong CUDA build: {torch.version.cuda}\"\n",
        "assert torch.cuda.is_available(), \"CUDA not available\"\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "print(\"[ENV READY]\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GPU CHECK] nvidia-smi:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">  bash -lc nvidia-smi || true\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 25 01:27:44 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     412MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.4.1+cu121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling torch-2.4.1+cu121:\n  Successfully uninstalled torch-2.4.1+cu121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchvision 0.19.1+cu121\nUninstalling torchvision-0.19.1+cu121:\n  Successfully uninstalled torchvision-0.19.1+cu121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchaudio 2.4.1+cu121\nUninstalling torchaudio-2.4.1+cu121:\n  Successfully uninstalled torchaudio-2.4.1+cu121\n> pip install --index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.org/simple torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 536.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 525.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 482.6 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 8.7 MB/s eta 0:00:00\nCollecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 226.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 478.4 MB/s eta 0:00:00\nCollecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 417.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 240.3 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 226.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 521.7 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 268.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 244.3 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 110.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 475.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 32.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 202.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 226.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 222.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 182.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 510.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 192.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 206.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 187.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 295.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install -c constraints.txt segmentation-models-pytorch==0.3.3 timm==0.9.2 albumentations==1.3.1 opencv-python-headless==4.10.0.84 scikit-image medpy scikit-learn pandas numpy matplotlib pillow --upgrade-strategy only-if-needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping albucore as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models-pytorch==0.3.3\n  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 106.7/106.7 KB 6.3 MB/s eta 0:00:00\nCollecting timm==0.9.2\n  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.2/2.2 MB 95.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==1.3.1\n  Downloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 125.7/125.7 KB 453.4 MB/s eta 0:00:00\nCollecting opencv-python-headless==4.10.0.84\n  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 49.9/49.9 MB 39.5 MB/s eta 0:00:00\nCollecting scikit-image\n  Downloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.8/14.8 MB 37.0 MB/s eta 0:00:00\nCollecting medpy\n  Downloading medpy-0.5.2.tar.gz (156 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 156.3/156.3 KB 475.9 MB/s eta 0:00:00\n  Preparing metadata (setup.py): started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py): finished with status 'done'\nCollecting scikit-learn\n  Downloading scikit_learn-1.7.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 9.7/9.7 MB 122.7 MB/s eta 0:00:00\nCollecting pandas\n  Downloading pandas-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 12.4/12.4 MB 504.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 124.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matplotlib\n  Downloading matplotlib-3.10.6-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 8.7/8.7 MB 126.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 266.3 MB/s eta 0:00:00\nCollecting tqdm\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 78.5/78.5 KB 399.0 MB/s eta 0:00:00\nCollecting pretrainedmodels==0.7.4\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 58.8/58.8 KB 405.9 MB/s eta 0:00:00\n  Preparing metadata (setup.py): started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py): finished with status 'done'\nCollecting torchvision>=0.5.0\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.0/7.0 MB 171.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet-pytorch==0.7.1\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py): started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py): finished with status 'done'\nCollecting torch>=1.7\n  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 797.1/797.1 MB 164.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml\n  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 763.0/763.0 KB 512.5 MB/s eta 0:00:00\nCollecting safetensors\n  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 485.8/485.8 KB 496.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface-hub\n  Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 563.3/563.3 KB 490.1 MB/s eta 0:00:00\nCollecting qudida>=0.0.4\n  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy>=1.1.0\n  Downloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35.9/35.9 MB 181.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting munch\n  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nCollecting networkx>=3.0\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 484.1 MB/s eta 0:00:00\nCollecting lazy-loader>=0.4\n  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\nCollecting tifffile>=2022.8.12\n  Downloading tifffile-2025.9.20-py3-none-any.whl (230 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 230.1/230.1 KB 447.8 MB/s eta 0:00:00\nCollecting imageio!=2.35.0,>=2.33\n  Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 315.8/315.8 KB 505.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting packaging>=21\n  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 66.5/66.5 KB 375.7 MB/s eta 0:00:00\nCollecting SimpleITK>=2.1\n  Downloading simpleitk-2.5.2-cp311-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (52.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 52.6/52.6 MB 103.1 MB/s eta 0:00:00\nCollecting threadpoolctl>=3.1.0\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nCollecting joblib>=1.2.0\n  Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 308.4/308.4 KB 487.9 MB/s eta 0:00:00\nCollecting python-dateutil>=2.8.2\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 229.9/229.9 KB 466.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytz>=2020.1\n  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 509.2/509.2 KB 507.3 MB/s eta 0:00:00\nCollecting tzdata>=2022.7\n  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 347.8/347.8 KB 484.4 MB/s eta 0:00:00\nCollecting contourpy>=1.0.1\n  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 355.2/355.2 KB 489.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fonttools>=4.22.0\n  Downloading fonttools-4.60.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 5.0/5.0 MB 170.7 MB/s eta 0:00:00\nCollecting cycler>=0.10\n  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\nCollecting pyparsing>=2.3.1\n  Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 113.9/113.9 KB 426.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kiwisolver>=1.3.1\n  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.4/1.4 MB 26.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting six>=1.5\n  Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nCollecting typing-extensions\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 342.7 MB/s eta 0:00:00\nCollecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 225.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 411.4 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 240.7 MB/s eta 0:00:00\nCollecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 487.3 MB/s eta 0:00:00\nCollecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 457.6 MB/s eta 0:00:00\nCollecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 267.1 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 139.6 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 133.9 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 210.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 179.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 189.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 107.1 MB/s eta 0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 71.1 MB/s eta 0:00:00\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 87.3 MB/s eta 0:00:00\nCollecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 86.3 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 195.2 MB/s eta 0:00:00\nCollecting requests\n  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.7/64.7 KB 421.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hf-xet<2.0.0,>=1.1.3\n  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.2/3.2 MB 391.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.10-py3-none-any.whl (70 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 70.4/70.4 KB 432.5 MB/s eta 0:00:00\nCollecting charset_normalizer<4,>=2\n  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 150.3/150.3 KB 448.0 MB/s eta 0:00:00\nCollecting certifi>=2017.4.17\n  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.2/161.2 KB 455.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting urllib3<3,>=1.21.1\n  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129.8/129.8 KB 442.6 MB/s eta 0:00:00\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 478.2 MB/s eta 0:00:00\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels, medpy\n  Building wheel for efficientnet-pytorch (setup.py): started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for efficientnet-pytorch (setup.py): finished with status 'done'\n  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=5ee883708498716a1dcf136a042fcc635dcd11b8946be8872a355da0c3ecb48f\n  Stored in directory: /tmp/pip-ephem-wheel-cache-1_97n9xy/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n  Building wheel for pretrainedmodels (setup.py): started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for pretrainedmodels (setup.py): finished with status 'done'\n  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60967 sha256=aaf1931beb12d59f6d57131bff2bf08fc9a10f33045cc3cbbef4e707b0d1366e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-1_97n9xy/wheels/5f/5b/96/fd94bc35962d7c6b699e8814db545155ac91d2b95785e1b035\n  Building wheel for medpy (setup.py): started\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for medpy (setup.py): finished with status 'done'\n  Created wheel for medpy: filename=MedPy-0.5.2-py3-none-any.whl size=224726 sha256=6956e550f4afec226e35ea593b8c347d1826ab79c15e688564526981ee5487fb\n  Stored in directory: /tmp/pip-ephem-wheel-cache-1_97n9xy/wheels/d4/33/ed/aaac5a347fb8d41679ca515b8f5c49dfdf49be15bdbb9a905d\nSuccessfully built efficientnet-pytorch pretrainedmodels medpy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: SimpleITK, pytz, mpmath, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, six, safetensors, pyyaml, pyparsing, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, munch, MarkupSafe, kiwisolver, joblib, idna, hf-xet, fsspec, fonttools, filelock, cycler, charset_normalizer, certifi, triton, tifffile, scipy, requests, python-dateutil, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lazy-loader, jinja2, imageio, contourpy, scikit-learn, scikit-image, pandas, nvidia-cusolver-cu12, medpy, matplotlib, huggingface-hub, torch, qudida, torchvision, efficientnet-pytorch, albumentations, timm, pretrainedmodels, segmentation-models-pytorch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 SimpleITK-2.5.2 albumentations-1.3.1 certifi-2025.8.3 charset_normalizer-3.4.3 contourpy-1.3.3 cycler-0.12.1 efficientnet-pytorch-0.7.1 filelock-3.19.1 fonttools-4.60.0 fsspec-2025.9.0 hf-xet-1.1.10 huggingface-hub-0.35.1 idna-3.10 imageio-2.37.0 jinja2-3.1.6 joblib-1.5.2 kiwisolver-1.4.9 lazy-loader-0.4 matplotlib-3.10.6 medpy-0.5.2 mpmath-1.3.0 munch-4.0.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 opencv-python-headless-4.10.0.84 packaging-25.0 pandas-2.3.2 pillow-11.3.0 pretrainedmodels-0.7.4 pyparsing-3.2.5 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.2 qudida-0.0.4 requests-2.32.5 safetensors-0.6.2 scikit-image-0.25.2 scikit-learn-1.7.2 scipy-1.16.2 segmentation-models-pytorch-0.3.3 six-1.17.0 sympy-1.14.0 threadpoolctl-3.6.0 tifffile-2025.9.20 timm-0.9.2 torch-2.4.1 torchvision-0.19.1 tqdm-4.67.1 triton-3.0.0 typing-extensions-4.15.0 tzdata-2025.2 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/segmentation_models_pytorch-0.3.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/segmentation_models_pytorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pretrainedmodels-0.7.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pretrainedmodels already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/timm-0.9.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/timm already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/albumentations-1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/albumentations already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/efficientnet_pytorch-0.7.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/efficientnet_pytorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision-0.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/qudida-0.0.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/qudida already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch-2.4.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/huggingface_hub-0.35.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/huggingface_hub already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/matplotlib-3.10.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpl_toolkits already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/matplotlib already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pylab.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MedPy-0.5.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/medpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pandas-2.3.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pandas already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scikit_image-0.25.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/skimage already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scikit_learn-1.7.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sklearn already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scikit_learn.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/contourpy-1.3.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/contourpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/imageio-2.37.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/imageio already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/lazy_loader-0.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/lazy_loader already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/cv2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/opencv_python_headless.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/opencv_python_headless-4.10.0.84.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/dateutil already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/requests-2.32.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/requests already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy-1.16.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tifffile-2025.9.20.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tifffile already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/certifi-2025.8.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/certifi already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/charset_normalizer-3.4.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/charset_normalizer already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/cycler-0.12.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/cycler already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fonttools-4.60.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fontTools already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/hf_xet-1.1.10.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/hf_xet already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/idna-3.10.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/idna already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/joblib-1.5.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/joblib already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/kiwisolver-1.4.9.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/kiwisolver already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/munch-4.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/munch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging-25.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pyparsing-3.2.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pyparsing already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/_yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/yaml already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PyYAML-6.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/safetensors already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/safetensors-0.6.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/six-1.17.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/six.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/threadpoolctl-3.6.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/threadpoolctl.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tqdm-4.67.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tqdm already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tzdata-2025.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tzdata already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/urllib3-2.5.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/urllib3 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pytz-2025.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pytz already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/simpleitk-2.5.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/SimpleITK already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 built CUDA: 12.1\nCUDA available: True\nGPU: NVIDIA A10-24Q\n[ENV READY]\n"
          ]
        }
      ]
    },
    {
      "id": "f13e2df0-cbeb-4381-a7fb-a7820810de41",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# EDA: CSV schema, ID parsing, positive ratios, folds, and path resolver\n",
        "import pandas as pd, numpy as np, os, re, sys, json, math, time, glob\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "\n",
        "DATA_DIR = Path('.')\n",
        "TRAIN_CSV = DATA_DIR / 'train.csv'\n",
        "TEST_CSV = DATA_DIR / 'test.csv'\n",
        "# Potential roots (local repo mounts first; add common Kaggle-style mounts if present at runtime)\n",
        "TRAIN_IMG_ROOTS = [\n",
        "    DATA_DIR / 'train',\n",
        "    # Kaggle official\n",
        "    Path('/kaggle/input/uw-madison-gi-tract-image-segmentation/train'),\n",
        "    Path('/kaggle/input/uw-madison-gi-tract-image-segmentation/train_png'),\n",
        "    # Common mirrors / alternate mounts\n",
        "    Path('/kaggle/input/uw-madison-gi-tract-image-segmentation-256x256/train'),\n",
        "    Path('/kaggle/input/uwmadison-gi-tract-image-segmentation/train'),\n",
        "    Path('/kaggle/input/uw-madison-gi-tract-image-segmentation-resized/train'),\n",
        "    Path('/kaggle/temp/uw-madison-gi-tract-image-segmentation/train'),\n",
        "    Path('/kaggle/working/uw-madison-gi-tract-image-segmentation/train'),\n",
        "    Path('/content/uw-madison-gi-tract-image-segmentation/train'),\n",
        "    Path('/mnt/input/uw-madison-gi-tract-image-segmentation/train'),\n",
        "    Path('/mnt/data/uw-madison-gi-tract-image-segmentation/train'),\n",
        "    Path('/data/uw-madison-gi-tract-image-segmentation/train'),\n",
        "    Path('/workspace/uw-madison-gi-tract-image-segmentation/train'),\n",
        "    Path('/datasets/uw-madison-gi-tract-image-segmentation/train'),\n",
        "    Path('/opt/data/uw-madison-gi-tract-image-segmentation/train'),\n",
        "    Path('/app/data/uw-madison-gi-tract-image-segmentation/train'),\n",
        "]\n",
        "TEST_IMG_ROOTS = [\n",
        "    DATA_DIR / 'test',\n",
        "    # Kaggle official\n",
        "    Path('/kaggle/input/uw-madison-gi-tract-image-segmentation/test'),\n",
        "    Path('/kaggle/input/uw-madison-gi-tract-image-segmentation/test_png'),\n",
        "    # Common mirrors / alternate mounts\n",
        "    Path('/kaggle/input/uw-madison-gi-tract-image-segmentation-256x256/test'),\n",
        "    Path('/kaggle/input/uwmadison-gi-tract-image-segmentation/test'),\n",
        "    Path('/kaggle/input/uw-madison-gi-tract-image-segmentation-resized/test'),\n",
        "    Path('/kaggle/temp/uw-madison-gi-tract-image-segmentation/test'),\n",
        "    Path('/kaggle/working/uw-madison-gi-tract-image-segmentation/test'),\n",
        "    Path('/content/uw-madison-gi-tract-image-segmentation/test'),\n",
        "    Path('/mnt/input/uw-madison-gi-tract-image-segmentation/test'),\n",
        "    Path('/mnt/data/uw-madison-gi-tract-image-segmentation/test'),\n",
        "    Path('/data/uw-madison-gi-tract-image-segmentation/test'),\n",
        "    Path('/workspace/uw-madison-gi-tract-image-segmentation/test'),\n",
        "    Path('/datasets/uw-madison-gi-tract-image-segmentation/test'),\n",
        "    Path('/opt/data/uw-madison-gi-tract-image-segmentation/test'),\n",
        "    Path('/app/data/uw-madison-gi-tract-image-segmentation/test'),\n",
        "]\n",
        "\n",
        "# Inject extracted archive train path (use as both train and test if no separate test dir exists)\n",
        "EXTERNAL_TRAIN = Path('external_data/uw-madison-gi-tract-image-segmentation/train')\n",
        "if EXTERNAL_TRAIN.exists():\n",
        "    TRAIN_IMG_ROOTS.insert(0, EXTERNAL_TRAIN)\n",
        "    # Also allow resolver to look here for test IDs (many mirrors ship train-only)\n",
        "    TEST_IMG_ROOTS.insert(0, EXTERNAL_TRAIN)\n",
        "\n",
        "# Dynamic discovery: scan Kaggle inputs for uw*gi* patterns and append discovered roots\n",
        "def _append_dynamic_roots(roots_list, split_name):\n",
        "    try:\n",
        "        for base in Path('/kaggle/input').glob('*uw*gi*/*'):\n",
        "            if not base.is_dir():\n",
        "                continue\n",
        "            cand = base / split_name\n",
        "            if cand.exists():\n",
        "                roots_list.append(cand)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# Extra dynamic discovery on multiple prefixes (expanded)\n",
        "def _append_dynamic_roots_generic(roots_list, split_name, prefixes=('/data', '/mnt', '/opt/data', '/app/data', '/datasets', '/workspace', '/workspace/data')):\n",
        "    for pref in prefixes:\n",
        "        try:\n",
        "            p = Path(pref)\n",
        "            if not p.exists():\n",
        "                continue\n",
        "            for base in p.glob('*uw*gi*/*'):\n",
        "                if not base.is_dir():\n",
        "                    continue\n",
        "                cand = base / split_name\n",
        "                if cand.exists():\n",
        "                    roots_list.append(cand)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "_append_dynamic_roots(TRAIN_IMG_ROOTS, 'train')\n",
        "_append_dynamic_roots(TEST_IMG_ROOTS, 'test')\n",
        "_append_dynamic_roots_generic(TRAIN_IMG_ROOTS, 'train', prefixes=('/data','/mnt','/opt/data','/app/data','/datasets','/workspace','/workspace/data'))\n",
        "_append_dynamic_roots_generic(TEST_IMG_ROOTS, 'test', prefixes=('/data','/mnt','/opt/data','/app/data','/datasets','/workspace','/workspace/data'))\n",
        "\n",
        "def _unique_existing(paths):\n",
        "    seen = set(); out = []\n",
        "    for p in paths:\n",
        "        ps = str(p)\n",
        "        if ps in seen:\n",
        "            continue\n",
        "        seen.add(ps)\n",
        "        if Path(p).exists():\n",
        "            out.append(Path(p))\n",
        "    return out\n",
        "\n",
        "TRAIN_IMG_ROOTS = _unique_existing(TRAIN_IMG_ROOTS) or TRAIN_IMG_ROOTS\n",
        "TEST_IMG_ROOTS = _unique_existing(TEST_IMG_ROOTS) or TEST_IMG_ROOTS\n",
        "print('[PATH ROOTS] Train roots existing:', [str(p) for p in TRAIN_IMG_ROOTS if Path(p).exists()])\n",
        "print('[PATH ROOTS] Test roots existing:', [str(p) for p in TEST_IMG_ROOTS if Path(p).exists()])\n",
        "\n",
        "print('[LOAD] Reading CSVs...')\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "test_df = pd.read_csv(TEST_CSV)\n",
        "print(train_df.head(3))\n",
        "print(test_df.head(3))\n",
        "print(f\"train rows={len(train_df)} unique ids={train_df['id'].nunique()} classes={train_df['class'].unique().tolist()}\")\n",
        "\n",
        "# Parse id: case###_day###_slice_####\n",
        "id_pat = re.compile(r'^case(\\d+)_day(\\d+)_slice_(\\d+)$')\n",
        "def parse_id(s):\n",
        "    m = id_pat.match(s)\n",
        "    if not m:\n",
        "        return (None, None, None)\n",
        "    return tuple(int(x) for x in m.groups())\n",
        "\n",
        "parsed = train_df['id'].apply(parse_id)\n",
        "train_df[['case','day','slice']] = pd.DataFrame(parsed.tolist(), index=train_df.index)\n",
        "parsed_t = test_df['id'].apply(parse_id)\n",
        "test_df[['case','day','slice']] = pd.DataFrame(parsed_t.tolist(), index=test_df.index)\n",
        "\n",
        "assert train_df['case'].notna().all(), 'ID parse failed for train'\n",
        "assert test_df['case'].notna().all(), 'ID parse failed for test'\n",
        "\n",
        "# Basic stats\n",
        "per_id_any_pos = (train_df.assign(has_pos=train_df['segmentation'].notna())\n",
        "                           .groupby('id')['has_pos'].any().rename('any_pos'))\n",
        "pos_ratio = per_id_any_pos.mean()\n",
        "print(f\"[EDA] Positive-slice ratio (any class): {pos_ratio:.3f}\")\n",
        "per_case_ratio = (train_df.assign(has_pos=train_df['segmentation'].notna())\n",
        "                           .groupby(['case','id'])['has_pos'].any().groupby('case').mean())\n",
        "per_case_len = train_df.drop_duplicates('id').groupby('case')['id'].count()\n",
        "print('[EDA] Per-case positive ratio stats:')\n",
        "print(per_case_ratio.describe())\n",
        "print('[EDA] Per-case slice-count stats:')\n",
        "print(per_case_len.describe())\n",
        "\n",
        "# Build StratifiedGroupKFold by case with combined stratification (pos-ratio bin x len bin)\n",
        "n_folds = 5\n",
        "cases = per_case_ratio.index.values\n",
        "y_cont = per_case_ratio.values\n",
        "lens = per_case_len.reindex(cases).values\n",
        "# Bins\n",
        "n_bins_pos = int(np.minimum(8, max(2, len(y_cont)//10)))\n",
        "pos_bins = pd.qcut(y_cont, q=n_bins_pos, duplicates='drop', labels=False).astype(int) if len(np.unique(y_cont))>1 else np.zeros_like(y_cont, dtype=int)\n",
        "n_bins_len = int(np.minimum(5, max(2, len(lens)//15)))\n",
        "len_bins = pd.qcut(lens, q=n_bins_len, duplicates='drop', labels=False).astype(int) if len(np.unique(lens))>1 else np.zeros_like(lens, dtype=int)\n",
        "combo_bins = (pos_bins.astype(int) * 10 + len_bins.astype(int)).astype(int)\n",
        "sgkf = StratifiedGroupKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "case_to_fold = {}\n",
        "for fold, (_, val_idx) in enumerate(sgkf.split(cases, combo_bins, groups=cases)):\n",
        "    for c in cases[val_idx]:\n",
        "        case_to_fold[int(c)] = fold\n",
        "print('[CV] Fold distribution (cases per fold):',\n",
        "      pd.Series(case_to_fold).value_counts().sort_index().to_dict())\n",
        "\n",
        "# Map id -> fold via case\n",
        "id_case = train_df.drop_duplicates('id')[['id','case','day','slice']]\n",
        "id_case['fold'] = id_case['case'].map(case_to_fold)\n",
        "assert id_case['fold'].notna().all(), 'Some ids missing fold assignment'\n",
        "id_case.to_csv('folds.csv', index=False)\n",
        "print('[CV] Saved folds.csv with columns: id, case, day, slice, fold')\n",
        "\n",
        "# Hardened path resolver with glob and multi-root search\n",
        "def id_to_rel_candidates(id_str):\n",
        "    case, day, sl = parse_id(id_str)\n",
        "    # primary pattern under scans/ (official)\n",
        "    rel1 = Path(f'case{case}') / f'day{day}' / 'scans' / f'slice_{sl:04d}*'\n",
        "    # mirrors with case{case}_day{day} folder name\n",
        "    rel2 = Path(f'case{case}') / f'case{case}_day{day}' / 'scans' / f'slice_{sl:04d}*'\n",
        "    # fallback without scans/\n",
        "    rel3 = Path(f'case{case}') / f'day{day}' / f'slice_{sl:04d}*'\n",
        "    rel4 = Path(f'case{case}') / f'case{case}_day{day}' / f'slice_{sl:04d}*'\n",
        "    return [rel1, rel2, rel3, rel4]\n",
        "\n",
        "def resolve_path(id_str, roots):\n",
        "    for rel_glob in id_to_rel_candidates(id_str):\n",
        "        for r in roots:\n",
        "            base = Path(r)\n",
        "            if not base.exists():\n",
        "                continue\n",
        "            matches = sorted(base.glob(str(rel_glob)))\n",
        "            if matches:\n",
        "                return Path(os.path.normpath(str(matches[0])))\n",
        "    # deterministic fallback (expected canonical path under scans with .png)\n",
        "    case, day, sl = parse_id(id_str)\n",
        "    return Path(roots[0]) / f'case{case}' / f'day{day}' / 'scans' / f'slice_{sl:04d}.png'\n",
        "\n",
        "# Quick existence check on a few samples\n",
        "sample_ids = id_case['id'].sample(min(5, len(id_case)), random_state=0).tolist()\n",
        "missing = 0\n",
        "for s in sample_ids:\n",
        "    p = resolve_path(s, TRAIN_IMG_ROOTS)\n",
        "    ex = p.exists()\n",
        "    print(f'[PATH] {s} -> {p} exists={ex}')\n",
        "    missing += (not ex)\n",
        "print(f'[PATH] Missing among samples: {missing}/{len(sample_ids)} (expected early if data not mounted)')\n",
        "\n",
        "print('[EDA DONE]')\n",
        "\n",
        "# expose resolve_path and parse_id for later cells\n",
        "globals()['resolve_path'] = resolve_path\n",
        "globals()['parse_id'] = parse_id"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PATH ROOTS] Train roots existing: ['external_data/uw-madison-gi-tract-image-segmentation/train', 'train']\n[PATH ROOTS] Test roots existing: ['external_data/uw-madison-gi-tract-image-segmentation/train', 'test']\n[LOAD] Reading CSVs...\n                        id        class segmentation\n0  case77_day20_slice_0001  large_bowel          NaN\n1  case77_day20_slice_0001  small_bowel          NaN\n2  case77_day20_slice_0001      stomach          NaN\n                         id        class\n0  case123_day20_slice_0001  large_bowel\n1  case123_day20_slice_0001  small_bowel\n2  case123_day20_slice_0001      stomach\ntrain rows=95088 unique ids=31696 classes=['large_bowel', 'small_bowel', 'stomach']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EDA] Positive-slice ratio (any class): 0.428\n[EDA] Per-case positive ratio stats:\ncount    76.000000\nmean      0.430776\nstd       0.066099\nmin       0.243056\n25%       0.383681\n50%       0.438368\n75%       0.472222\nmax       0.570312\nName: has_pos, dtype: float64\n[EDA] Per-case slice-count stats:\ncount     76.000000\nmean     417.052632\nstd      126.290870\nmin      144.000000\n25%      420.000000\n50%      432.000000\n75%      432.000000\nmax      576.000000\nName: id, dtype: float64\n[CV] Fold distribution (cases per fold): {0: 15, 1: 15, 2: 16, 3: 15, 4: 15}\n[CV] Saved folds.csv with columns: id, case, day, slice, fold\n[PATH] case20_day24_slice_0084 -> external_data/uw-madison-gi-tract-image-segmentation/train/case20/case20_day24/scans/slice_0084_266_266_1.50_1.50.png exists=True\n[PATH] case111_day19_slice_0055 -> external_data/uw-madison-gi-tract-image-segmentation/train/case111/case111_day19/scans/slice_0055_266_266_1.50_1.50.png exists=True\n[PATH] case33_day0_slice_0014 -> external_data/uw-madison-gi-tract-image-segmentation/train/case33/case33_day0/scans/slice_0014_266_266_1.50_1.50.png exists=True\n[PATH] case19_day0_slice_0080 -> external_data/uw-madison-gi-tract-image-segmentation/train/case19/case19_day0/scans/slice_0080_360_310_1.50_1.50.png exists=True\n[PATH] case122_day0_slice_0006 -> external_data/uw-madison-gi-tract-image-segmentation/train/case122/case122_day0/scans/slice_0006_360_310_1.50_1.50.png exists=True\n[PATH] Missing among samples: 0/5 (expected early if data not mounted)\n[EDA DONE]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/sklearn/model_selection/_split.py:1035: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "id": "f49fa138-c482-4efb-ad0d-f21d37ef0882",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Utilities: RLE encode/decode, image loader with normalization + body crop, 2.5D stack, Dataset\n",
        "import numpy as np, cv2, math, warnings\n",
        "from skimage.measure import label, regionprops\n",
        "import albumentations as A\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "CLASSES = ['large_bowel','small_bowel','stomach']  # canonical order\n",
        "IMG_SIZE = 384\n",
        "CTX_OFFSETS = [-2,-1,0,1,2]\n",
        "\n",
        "# RLE utils (Kaggle GI: column-major / Fortran order, 1-indexed starts)\n",
        "def rle_decode(rle, shape):\n",
        "    if not isinstance(rle, str) or rle.strip() == '':\n",
        "        return np.zeros(shape, dtype=np.uint8)\n",
        "    s = list(map(int, rle.split()))\n",
        "    starts, lengths = s[0::2], s[1::2]\n",
        "    starts = np.asarray(starts) - 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape, order='F')\n",
        "\n",
        "def rle_encode(mask):\n",
        "    # mask: HxW, binary {0,1}; returns 'start length ...' with Fortran order\n",
        "    pixels = mask.T.flatten()  # Fortran order equivalent\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "def decode_row_to_mask(row, shape):\n",
        "    return rle_decode(row['segmentation'] if isinstance(row['segmentation'], str) else '', shape)\n",
        "\n",
        "def build_id_mask(train_df, id_str, shape):\n",
        "    m = np.zeros((len(CLASSES), *shape), dtype=np.uint8)\n",
        "    sub = train_df[train_df['id']==id_str]\n",
        "    cls_to_ch = {c:i for i,c in enumerate(CLASSES)}\n",
        "    for _, r in sub.iterrows():\n",
        "        ch = cls_to_ch[r['class']]\n",
        "        m[ch] = decode_row_to_mask(r, shape)\n",
        "    return m\n",
        "\n",
        "# Robust intensity normalization and body crop\n",
        "def robust_norm(img_u16, clip_low=0.5, clip_high=99.5, eps=1e-3):\n",
        "    img = img_u16.astype(np.float32)\n",
        "    lo = np.percentile(img, clip_low)\n",
        "    hi = np.percentile(img, clip_high)\n",
        "    if hi <= lo:\n",
        "        hi = lo + 1.0\n",
        "    img = np.clip(img, lo, hi)\n",
        "    img = (img - lo) / (hi - lo + eps)\n",
        "    return img\n",
        "\n",
        "def body_crop_bbox(image01, thresh=0.1, margin=32):\n",
        "    # image01 in [0,1], HxW; returns (x1,y1,x2,y2)\n",
        "    mask = (image01 > thresh).astype(np.uint8)\n",
        "    if mask.sum() == 0:\n",
        "        h, w = image01.shape[:2]\n",
        "        return (0, 0, w, h)\n",
        "    lbl = label(mask, connectivity=1)\n",
        "    regions = regionprops(lbl)\n",
        "    if not regions:\n",
        "        h, w = image01.shape[:2]\n",
        "        return (0, 0, w, h)\n",
        "    rp = max(regions, key=lambda r: r.area)\n",
        "    minr, minc, maxr, maxc = rp.bbox\n",
        "    h, w = image01.shape[:2]\n",
        "    minr = max(0, minr - margin); minc = max(0, minc - margin)\n",
        "    maxr = min(h, maxr + margin); maxc = min(w, maxc + margin)\n",
        "    return (minc, minr, maxc, maxr)  # x1,y1,x2,y2\n",
        "\n",
        "def apply_crop(img, bbox):\n",
        "    x1,y1,x2,y2 = bbox\n",
        "    return img[y1:y2, x1:x2]\n",
        "\n",
        "def resize_to_square(img, size=IMG_SIZE):\n",
        "    h, w = img.shape[:2]\n",
        "    scale = min(size / h, size / w) if (h>0 and w>0) else 1.0\n",
        "    nh, nw = max(1,int(round(h*scale))), max(1,int(round(w*scale)))\n",
        "    img_r = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_LINEAR)\n",
        "    out = np.zeros((size, size), dtype=img_r.dtype)\n",
        "    y0 = (size - nh)//2; x0 = (size - nw)//2\n",
        "    out[y0:y0+nh, x0:x0+nw] = img_r\n",
        "    return out, (x0, y0, nw, nh, h, w)  # pad+scale meta for the cropped image\n",
        "\n",
        "def warp_mask_like(mask, meta):\n",
        "    x0, y0, nw, nh, h0, w0 = meta\n",
        "    if mask.size == 0:\n",
        "        return np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.uint8)\n",
        "    mask_r = cv2.resize(mask.astype(np.uint8), (nw, nh), interpolation=cv2.INTER_NEAREST)\n",
        "    out = np.zeros((IMG_SIZE, IMG_SIZE), dtype=np.uint8)\n",
        "    out[y0:y0+nh, x0:x0+nw] = mask_r\n",
        "    return out\n",
        "\n",
        "def inverse_unwarp_mask(mask_sq, meta, bbox, orig_shape):\n",
        "    # mask_sq: IMG_SIZExIMG_SIZE; meta=(x0,y0,nw,nh,h_crop,w_crop); bbox=(x1,y1,x2,y2); orig_shape=(H0,W0)\n",
        "    x0, y0, nw, nh, h_crop, w_crop = meta\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    H0, W0 = orig_shape\n",
        "    crop_space = np.zeros((h_crop, w_crop), dtype=np.uint8)\n",
        "    if nh>0 and nw>0:\n",
        "        inner = mask_sq[y0:y0+nh, x0:x0+nw].astype(np.uint8)\n",
        "        if inner.size > 0:\n",
        "            crop_space = cv2.resize(inner, (w_crop, h_crop), interpolation=cv2.INTER_NEAREST)\n",
        "    full = np.zeros((H0, W0), dtype=np.uint8)\n",
        "    # guard bbox within image\n",
        "    x1c, y1c = max(0, x1), max(0, y1)\n",
        "    x2c, y2c = min(W0, x2), min(H0, y2)\n",
        "    if (y2c>y1c) and (x2c>x1c):\n",
        "        full[y1c:y2c, x1c:x2c] = crop_space[(y1c - y1):(y2c - y1), (x1c - x1):(x2c - x1)]\n",
        "    return full\n",
        "\n",
        "def inverse_unwarp_probs(prob_sq, meta, bbox, orig_shape):\n",
        "    # prob_sq: IMG_SIZExIMG_SIZE float32 in [0,1]\n",
        "    x0, y0, nw, nh, h_crop, w_crop = map(int, meta)\n",
        "    x1, y1, x2, y2 = map(int, bbox)\n",
        "    H0, W0 = map(int, orig_shape)\n",
        "    inner = prob_sq[y0:y0+nh, x0:x0+nw].astype(np.float32)\n",
        "    if inner.size == 0 or h_crop <= 0 or w_crop <= 0:\n",
        "        crop_prob = np.zeros((h_crop, w_crop), dtype=np.float32)\n",
        "    else:\n",
        "        crop_prob = cv2.resize(inner, (w_crop, h_crop), interpolation=cv2.INTER_LINEAR)\n",
        "    full = np.zeros((H0, W0), dtype=np.float32)\n",
        "    x1c, y1c = max(0, x1), max(0, y1)\n",
        "    x2c, y2c = min(W0, x2), min(H0, y2)\n",
        "    if (y2c > y1c) and (x2c > x1c):\n",
        "        full[y1c:y2c, x1c:x2c] = crop_prob[(y1c - y1):(y2c - y1), (x1c - x1):(x2c - x1)]\n",
        "    return full\n",
        "\n",
        "def read_png_u16(path):\n",
        "    img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(path)\n",
        "    if img.ndim == 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    if img.dtype != np.uint16:\n",
        "        img = img.astype(np.uint16)\n",
        "    return img\n",
        "\n",
        "def get_neighbor_ids(center_id, all_slices_sorted):\n",
        "    case, day, sl = parse_id(center_id)\n",
        "    idx = all_slices_sorted.index(sl)\n",
        "    res = []\n",
        "    for off in CTX_OFFSETS:\n",
        "        j = idx + off\n",
        "        j = min(max(j, 0), len(all_slices_sorted)-1)\n",
        "        res.append(all_slices_sorted[j])\n",
        "    return [f\"case{case}_day{day}_slice_{s:04d}\" for s in res]\n",
        "\n",
        "class UWGITractDataset(Dataset):\n",
        "    def __init__(self, df_ids, train_df=None, roots=None, mode='train', aug=None):\n",
        "        # df_ids: dataframe with columns id, case, day, slice; one row per unique id\n",
        "        self.df_ids = df_ids.reset_index(drop=True)\n",
        "        self.train_df = train_df\n",
        "        self.roots = roots or [Path('train')]\n",
        "        self.mode = mode\n",
        "        self.aug = aug\n",
        "        g = self.df_ids.groupby(['case','day'])['slice'].apply(lambda s: sorted(s.tolist()))\n",
        "        self.slice_map = {(int(c),int(d)): lst for (c,d), lst in g.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df_ids)\n",
        "\n",
        "    def _proc_image(self, id_str, bbox=None):\n",
        "        p = resolve_path(id_str, self.roots)\n",
        "        img_u16 = read_png_u16(p)\n",
        "        img01 = robust_norm(img_u16)\n",
        "        if bbox is None:\n",
        "            bbox = body_crop_bbox(img01)\n",
        "        img_crop = apply_crop(img01, bbox)\n",
        "        img_sq, meta = resize_to_square(img_crop, IMG_SIZE)\n",
        "        return img_sq.astype(np.float32), bbox, meta, img_u16.shape[:2]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df_ids.iloc[idx]\n",
        "        id_str = row['id']\n",
        "        case, day, sl = int(row['case']), int(row['day']), int(row['slice'])\n",
        "        # Center first to establish bbox/meta for alignment across neighbors\n",
        "        center_img, bbox, center_meta, orig_shape_center = self._proc_image(id_str, bbox=None)\n",
        "        neighbors = get_neighbor_ids(id_str, self.slice_map[(case,day)])\n",
        "        chans = []\n",
        "        for nid in neighbors:\n",
        "            try:\n",
        "                img_sq, _, _, _ = self._proc_image(nid, bbox=bbox)  # use center bbox\n",
        "            except FileNotFoundError:\n",
        "                # Neighbor missing: fallback to center slice to keep channel count/stability\n",
        "                img_sq = center_img\n",
        "            chans.append(img_sq)\n",
        "        img5 = np.stack(chans, axis=0)  # 5xHxW\n",
        "\n",
        "        if self.mode != 'test':\n",
        "            # Build center mask aligned to center image using center bbox + meta\n",
        "            p_center = resolve_path(id_str, self.roots)\n",
        "            img_u16 = read_png_u16(p_center)\n",
        "            H0, W0 = img_u16.shape[:2]\n",
        "            sub = self.train_df[self.train_df['id']==id_str]\n",
        "            m3 = np.zeros((len(CLASSES), IMG_SIZE, IMG_SIZE), dtype=np.uint8)\n",
        "            x1,y1,x2,y2 = bbox\n",
        "            for ci, cls in enumerate(CLASSES):\n",
        "                r = sub[sub['class']==cls].iloc[0]\n",
        "                mask0 = decode_row_to_mask(r, (H0, W0))\n",
        "                mask_crop = mask0[y1:y2, x1:x2]\n",
        "                m3[ci] = warp_mask_like(mask_crop, center_meta)\n",
        "            # Albumentations joint augs (geom only) on HxWxC image and list of masks\n",
        "            if self.aug is not None:\n",
        "                img_hwk = np.transpose(img5, (1,2,0))  # HxWx5\n",
        "                masks_list = [m for m in m3]\n",
        "                out = self.aug(image=img_hwk, masks=masks_list)\n",
        "                img_hwk = out['image']\n",
        "                masks_list = out['masks']\n",
        "                img5 = np.transpose(img_hwk, (2,0,1))\n",
        "                m3 = np.stack(masks_list, axis=0).astype(np.uint8)\n",
        "            img_t = torch.from_numpy(img5).float()\n",
        "            mask_t = torch.from_numpy(m3).float()\n",
        "            return img_t, mask_t, id_str\n",
        "        # test mode: return metadata for inverse mapping\n",
        "        img_t = torch.from_numpy(img5).float()\n",
        "        return img_t, id_str, bbox, center_meta, orig_shape_center\n",
        "\n",
        "def get_train_aug():\n",
        "    return A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=8, p=0.5, border_mode=cv2.BORDER_REFLECT101),\n",
        "        A.ElasticTransform(alpha=20, sigma=5, alpha_affine=5, p=0.15, border_mode=cv2.BORDER_REFLECT101),\n",
        "        A.GridDistortion(distort_limit=0.15, p=0.3, border_mode=cv2.BORDER_REFLECT101),\n",
        "        A.RandomBrightnessContrast(p=0.3),\n",
        "        A.RandomGamma(gamma_limit=(80,120), p=0.3),\n",
        "        A.GaussianBlur(blur_limit=3, p=0.2),\n",
        "        A.GaussNoise(var_limit=(5e-4, 1e-3), p=0.2),\n",
        "    ])\n",
        "\n",
        "def get_valid_aug():\n",
        "    return A.Compose([])\n",
        "\n",
        "print('[UTILS READY] Dataset aligns neighbors to center crop and warps masks consistently. Includes inverse_unwarp_mask()/inverse_unwarp_probs() and test metadata.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[UTILS READY] Dataset aligns neighbors to center crop and warps masks consistently. Includes inverse_unwarp_mask()/inverse_unwarp_probs() and test metadata.\n"
          ]
        }
      ]
    },
    {
      "id": "2178bda4-de57-4fa6-9694-3f5f7dfcab2e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Caching, unit tests, and model/loss skeleton (no training yet)\n",
        "import os, math, time, json, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "import pandas as pd\n",
        "\n",
        "# Unit test: RLE encode/decode round-trip\n",
        "def _unit_test_rle():\n",
        "    rng = np.random.default_rng(0)\n",
        "    H, W = 64, 64\n",
        "    m = (rng.random((H,W)) > 0.8).astype(np.uint8)\n",
        "    r = rle_encode(m)\n",
        "    m2 = rle_decode(r, (H,W))\n",
        "    assert np.array_equal(m, m2), 'RLE round-trip failed'\n",
        "    print('[TEST] RLE round-trip OK')\n",
        "\n",
        "# Only run unit test if RLE helpers exist in globals (depends on Cell 3)\n",
        "if 'rle_encode' in globals() and 'rle_decode' in globals():\n",
        "    try:\n",
        "        _unit_test_rle()\n",
        "    except Exception as e:\n",
        "        print('[TEST] RLE round-trip skipped due to error:', e)\n",
        "else:\n",
        "    print('[TEST] Skipping RLE round-trip (helpers not yet defined in kernel)')\n",
        "\n",
        "# Cache builder: persists preprocessed stacks and metadata to disk\n",
        "def build_cache(df_ids, train_df=None, roots=None, out_dir='cache/train', mode='train', log_every=200):\n",
        "    out_dir = Path(out_dir)\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    n = len(df_ids)\n",
        "    t0 = time.time()\n",
        "    for i, row in df_ids.reset_index(drop=True).iterrows():\n",
        "        id_str = row['id']\n",
        "        out_path = out_dir / f\"{id_str}.npz\"\n",
        "        if out_path.exists():\n",
        "            if (i % log_every)==0:\n",
        "                print(f\"[CACHE] ({i}/{n}) skip exists {out_path}\")\n",
        "            continue\n",
        "        try:\n",
        "            if mode == 'test':\n",
        "                # Use test-mode dataset to get metadata directly\n",
        "                ds = UWGITractDataset(pd.DataFrame([row]), train_df=None, roots=roots, mode='test', aug=None)\n",
        "                img_t, _id, bbox, meta, orig_shape = ds[0]\n",
        "                img5 = img_t.numpy().astype(np.float16)\n",
        "                np.savez_compressed(out_path,\n",
        "                    img5=img5,\n",
        "                    bbox=np.array(bbox, np.int32),\n",
        "                    meta=np.array(meta, np.int32),\n",
        "                    orig_shape=np.array(orig_shape, np.int32))\n",
        "            else:\n",
        "                # Train mode: build image+mask via train-mode; fetch identical metadata via test-mode\n",
        "                ds_train = UWGITractDataset(pd.DataFrame([row]), train_df=train_df, roots=roots, mode='train', aug=None)\n",
        "                img_t, mask_t, _id = ds_train[0]\n",
        "                ds_meta = UWGITractDataset(pd.DataFrame([row]), train_df=train_df, roots=roots, mode='test', aug=None)\n",
        "                _, _, bbox, meta, orig_shape = ds_meta[0]\n",
        "                img5 = img_t.numpy().astype(np.float16)\n",
        "                m3 = mask_t.numpy().astype(np.uint8)\n",
        "                np.savez_compressed(out_path,\n",
        "                    img5=img5, m3=m3,\n",
        "                    bbox=np.array(bbox, np.int32),\n",
        "                    meta=np.array(meta, np.int32),\n",
        "                    orig_shape=np.array(orig_shape, np.int32))\n",
        "        except FileNotFoundError:\n",
        "            if (i % log_every)==0:\n",
        "                print(f\"[CACHE] ({i}/{n}) MISSING image for {id_str}\")\n",
        "        if (i % log_every)==0 and i>0:\n",
        "            dt = time.time()-t0\n",
        "            print(f\"[CACHE] {i}/{n} done in {dt/60:.1f} min\")\n",
        "            gc.collect()\n",
        "            try:\n",
        "                torch.cuda.empty_cache()\n",
        "            except Exception:\n",
        "                pass\n",
        "    print('[CACHE] Done:', out_dir)\n",
        "\n",
        "# Sampler weights to target ~60-65% positive slices\n",
        "def build_pos_oversampler(df_ids, train_df, target_pos_frac=0.62):\n",
        "    any_pos = (train_df.assign(has_pos=train_df['segmentation'].notna())\n",
        "                        .groupby('id')['has_pos'].any())\n",
        "    ids = df_ids['id'].values\n",
        "    flags = any_pos.reindex(ids).fillna(False).values.astype(np.uint8)\n",
        "    pos = flags.mean()\n",
        "    n = len(flags); n_pos = flags.sum(); n_neg = n - n_pos\n",
        "    if n_pos == 0 or n_neg == 0:\n",
        "        weights = np.ones(n, dtype=np.float32)\n",
        "    else:\n",
        "        w_neg = 1.0\n",
        "        w_pos = (target_pos_frac * n_neg * w_neg) / ( (1 - target_pos_frac) * n_pos )\n",
        "        w_pos = float(max(w_pos, 1e-3))\n",
        "        weights = np.where(flags==1, w_pos, w_neg).astype(np.float32)\n",
        "    sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
        "    return sampler\n",
        "\n",
        "# Model factory: UNet++ tf_efficientnet_b3, in_channels=5, classes=3 (canonical order)\n",
        "def build_model(device='cuda', encoder='tf_efficientnet_b3', in_ch=5, classes=3):\n",
        "    # Lazy import to avoid heavy import at cell-exec time\n",
        "    import segmentation_models_pytorch as smp\n",
        "    model = smp.UnetPlusPlus(encoder_name=encoder, in_channels=in_ch, classes=classes, activation=None)\n",
        "    return model.to(device)\n",
        "\n",
        "# Loss: BCEWithLogits + Tversky(alpha=0.7, beta=0.3) with class weights\n",
        "_printed_combo_debug = {'done': False}\n",
        "\n",
        "def _ensure_chw_targets(t):\n",
        "    # t can be (B,3,H,W) or (B,H,W,3); convert to (B,3,H,W)\n",
        "    if t.dim() == 3:  # (3,H,W) single sample (unlikely here)\n",
        "        t = t.unsqueeze(0)\n",
        "    if t.dim() == 4:\n",
        "        if t.shape[-1] == 3 and t.shape[1] != 3:\n",
        "            return t.permute(0, 3, 1, 2).contiguous()\n",
        "        A = t.shape[1]\n",
        "        if A not in (1, 3) and t.shape[-1] in (1, 3):\n",
        "            return t.permute(0, 3, 1, 2).contiguous()\n",
        "    return t\n",
        "\n",
        "class TverskyLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.7, beta=0.3, eps=1e-6):\n",
        "        super().__init__(); self.alpha=alpha; self.beta=beta; self.eps=eps\n",
        "    def forward(self, logits, targets):\n",
        "        # compute in fp32 to stabilize under amp\n",
        "        with torch.cuda.amp.autocast(enabled=False):\n",
        "            logits = logits.float()\n",
        "            targets = _ensure_chw_targets(targets.float())\n",
        "            probs = torch.sigmoid(logits)\n",
        "            dims = (0,2,3)\n",
        "            tp = (probs*targets).sum(dim=dims)\n",
        "            fp = (probs*(1-targets)).sum(dim=dims)\n",
        "            fn = ((1-probs)*targets).sum(dim=dims)\n",
        "            t = (tp + self.alpha*fp + self.beta*fn + self.eps)\n",
        "            return 1.0 - (tp + self.eps)/t\n",
        "\n",
        "class ComboLoss(nn.Module):\n",
        "    def __init__(self, bce_weight=0.5, tv_weight=0.5, tv_alpha=0.7, tv_beta=0.3, class_weights=(1.1,1.35,1.0)):\n",
        "        super().__init__()\n",
        "        # store raw per-class weights\n",
        "        self.pos_w = nn.Parameter(torch.tensor(class_weights, dtype=torch.float32), requires_grad=False)\n",
        "        self.tvl = TverskyLoss(alpha=tv_alpha, beta=tv_beta)\n",
        "        self.bw = bce_weight; self.tw = tv_weight\n",
        "    def forward(self, logits, targets):\n",
        "        # Enforce layout to (B,3,H,W) for both\n",
        "        if logits.dim() == 4 and logits.shape[1] not in (1,3) and logits.shape[-1] in (1,3):\n",
        "            logits = logits.permute(0,3,1,2).contiguous()\n",
        "        targets = _ensure_chw_targets(targets)\n",
        "        # Build per-element weight map: 1 + (pos_w-1)*targets, where pos_w is per-channel\n",
        "        w = self.pos_w.to(logits.device).reshape(-1)  # (C,)\n",
        "        pw = w[None, :, None, None]  # (1,C,1,1)\n",
        "        ew = 1.0 + (pw - 1.0) * targets\n",
        "        if not _printed_combo_debug['done']:\n",
        "            try:\n",
        "                print('[LOSS-DBG] logits', tuple(logits.shape), 'targets', tuple(targets.shape), 'elem_w', tuple(ew.shape))\n",
        "            finally:\n",
        "                _printed_combo_debug['done'] = True\n",
        "        bce = F.binary_cross_entropy_with_logits(logits, targets, weight=ew)\n",
        "        tv = self.tvl(logits, targets).mean()\n",
        "        return self.bw*bce + self.tw*tv\n",
        "\n",
        "print('[CACHE/MODEL UTILS READY] Cache saves img5(float16)+masks+metadata; Tversky computed in fp32 under AMP. Lazy-imported SMP in build_model().')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEST] RLE round-trip OK\n[CACHE/MODEL UTILS READY] Cache saves img5(float16)+masks+metadata; Tversky computed in fp32 under AMP. Lazy-imported SMP in build_model().\n"
          ]
        }
      ]
    },
    {
      "id": "679e3c6e-e4dc-4cbf-a786-4becd9f5ab52",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Filesystem scan for PNG sources (timeboxed)\n",
        "import os, time, glob, fnmatch\n",
        "from pathlib import Path\n",
        "\n",
        "def scan_for_slices(base_dirs, patterns=(\"**/case*/day*/scans/slice_*.png\", \"**/case*/day*/slice_*.png\"),\n",
        "                    max_matches=200, timeout_sec=60):\n",
        "    t0 = time.time()\n",
        "    found = []\n",
        "    checked_dirs = []\n",
        "    for b in base_dirs:\n",
        "        b = Path(b)\n",
        "        if not b.exists():\n",
        "            continue\n",
        "        checked_dirs.append(str(b))\n",
        "        for pat in patterns:\n",
        "            try:\n",
        "                for p in b.rglob(pat):\n",
        "                    found.append(str(p))\n",
        "                    if len(found) >= max_matches or (time.time()-t0) > timeout_sec:\n",
        "                        return found, checked_dirs\n",
        "            except Exception as e:\n",
        "                print(f\"[SCAN] Error scanning {b} with {pat}: {e}\")\n",
        "        if (time.time()-t0) > timeout_sec:\n",
        "            break\n",
        "    return found, checked_dirs\n",
        "\n",
        "candidate_dirs = [\n",
        "    Path('.'),\n",
        "    Path('./train'), Path('./test'),\n",
        "    Path('/kaggle/input'),\n",
        "    Path('/mnt'),\n",
        "    Path('/data'),\n",
        "    Path('/workspace'),\n",
        "]\n",
        "print('[SCAN] Searching for slice_*.png under candidates (timeboxed)...')\n",
        "found, checked = scan_for_slices(candidate_dirs, max_matches=50, timeout_sec=30)\n",
        "print('[SCAN] Checked roots:', checked)\n",
        "print(f\"[SCAN] Found {len(found)} sample files\")\n",
        "if found:\n",
        "    for p in found[:10]:\n",
        "        print(' ', p)\n",
        "else:\n",
        "    print('[SCAN] No PNGs found. Likely images are not mounted in this environment.')\n",
        "\n",
        "# If any found under a recognizable uw-madison path, suggest updating TRAIN_IMG_ROOTS/TEST_IMG_ROOTS accordingly.\n",
        "print('[SCAN DONE]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "43c78b08-5d43-4939-b083-f46380d1c56e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training & Inference skeleton (5-fold, AMP, cosine, EMA, H-flip TTA + post-proc)\n",
        "import os, math, time, gc, json, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.data import DataLoader\n",
        "from skimage.measure import label, regionprops\n",
        "import cv2\n",
        "from scipy.ndimage import binary_fill_holes\n",
        "\n",
        "# Memory/throughput guards\n",
        "os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF', 'expandable_segments:True')\n",
        "try:\n",
        "    cv2.setNumThreads(0)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Post-processing defaults (order: [large, small, stomach]) per expert advice\n",
        "PP_THRESH = [0.50, 0.42, 0.47]\n",
        "PP_MIN_AREA = [1200, 900, 800]\n",
        "# Optionally override with tuned values if available\n",
        "try:\n",
        "    if Path('tuned_pp.json').exists():\n",
        "        _pp = json.loads(Path('tuned_pp.json').read_text())\n",
        "        if isinstance(_pp.get('thr'), (list, tuple)) and isinstance(_pp.get('min_area'), (list, tuple)):\n",
        "            PP_THRESH = [float(x) for x in _pp['thr']]\n",
        "            PP_MIN_AREA = [int(x) for x in _pp['min_area']]\n",
        "            print('[PP] Overridden from tuned_pp.json:', PP_THRESH, PP_MIN_AREA)\n",
        "except Exception as _e:\n",
        "    print('[PP] tuned_pp.json load failed:', _e)\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def dice_score(pred, targ, eps=1e-6):\n",
        "    # pred,targ: (H,W) binary\n",
        "    inter = (pred & targ).sum()\n",
        "    d = (2*inter + eps) / (pred.sum() + targ.sum() + eps)\n",
        "    return float(d)\n",
        "\n",
        "# HD95 proxy helpers (empty-safe). We will use later for OOF tuning.\n",
        "def _surface_distances(a, b):\n",
        "    # Simple chessboard distance transform based symmetric approx for speed; not exact hd95\n",
        "    import scipy.ndimage as ndi\n",
        "    a = a.astype(bool); b = b.astype(bool)\n",
        "    if not a.any() and not b.any():\n",
        "        return np.array([0.0])\n",
        "    if not a.any() or not b.any():\n",
        "        # cap by 100 as recommended\n",
        "        return np.array([100.0])\n",
        "    a_dt = ndi.distance_transform_cdt(~a, metric='chessboard')\n",
        "    b_dt = ndi.distance_transform_cdt(~b, metric='chessboard')\n",
        "    a_b = a_dt[b]\n",
        "    b_a = b_dt[a]\n",
        "    if a_b.size == 0: a_b = np.array([0.0])\n",
        "    if b_a.size == 0: b_a = np.array([0.0])\n",
        "    return np.concatenate([a_b, b_a]).astype(np.float32)\n",
        "\n",
        "def hd95_proxy(a, b):\n",
        "    d = _surface_distances(a, b)\n",
        "    return float(np.percentile(d, 95)) if d.size else 0.0\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.9995):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[n] = p.detach().clone()\n",
        "    def update(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                self.shadow[n].mul_(self.decay).add_(p.detach(), alpha=1-self.decay)\n",
        "    def apply_to(self, model):\n",
        "        for n, p in model.named_parameters():\n",
        "            if p.requires_grad:\n",
        "                p.data.copy_(self.shadow[n])\n",
        "\n",
        "def make_loaders(fold, batch_size=10, num_workers=4, target_pos_frac=0.62):\n",
        "    folds = pd.read_csv('folds.csv')\n",
        "    tr_ids = folds[folds['fold']!=fold][['id','case','day','slice']].reset_index(drop=True)\n",
        "    va_ids = folds[folds['fold']==fold][['id','case','day','slice']].reset_index(drop=True)\n",
        "    train_ds = UWGITractDataset(tr_ids, train_df=train_df, roots=TRAIN_IMG_ROOTS, mode='train', aug=get_train_aug())\n",
        "    valid_ds = UWGITractDataset(va_ids, train_df=train_df, roots=TRAIN_IMG_ROOTS, mode='valid', aug=get_valid_aug())\n",
        "    sampler = build_pos_oversampler(tr_ids, train_df, target_pos_frac=target_pos_frac)\n",
        "    # Safer loader settings to avoid hangs\n",
        "    pf = None if num_workers == 0 else 2\n",
        "    train_dl = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=num_workers, pin_memory=True, drop_last=True, persistent_workers=False, prefetch_factor=pf)\n",
        "    valid_dl = DataLoader(valid_ds, batch_size=max(1,batch_size//2), shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=False, prefetch_factor=pf)\n",
        "    return train_dl, valid_dl, va_ids\n",
        "\n",
        "def _find_encoder_stem_conv(enc):\n",
        "    # Placeholder to keep API compatibility; unused in TinyUNet path\n",
        "    return None\n",
        "\n",
        "def _build_tmp_3ch_b3(device='cpu'):\n",
        "    # Unused in TinyUNet path; keep for interface completeness\n",
        "    return None\n",
        "\n",
        "def _force_stem_mean_rgb_mean(model, device='cuda'):\n",
        "    # Unused in TinyUNet path\n",
        "    return False\n",
        "\n",
        "def build_model_b3(device='cuda'):\n",
        "    # Primary model per expert advice: SMP Unet with ResNet34 backbone (ImageNet), in_ch=5, classes=3\n",
        "    gc.collect();\n",
        "    try:\n",
        "        torch.cuda.empty_cache()\n",
        "    except Exception:\n",
        "        pass\n",
        "    import segmentation_models_pytorch as smp\n",
        "    model = smp.Unet(encoder_name='resnet34', encoder_weights='imagenet', in_channels=5, classes=3, activation=None)\n",
        "    return model.to(device)\n",
        "\n",
        "def _collect_valid_metadata(va_ids):\n",
        "    # Build id -> (bbox, meta, orig_shape) using test-mode dataset\n",
        "    ds_meta = UWGITractDataset(va_ids, train_df=None, roots=TRAIN_IMG_ROOTS, mode='test', aug=None)\n",
        "    dl_meta = DataLoader(ds_meta, batch_size=8, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=False)\n",
        "    meta_map = {}\n",
        "    with torch.no_grad():\n",
        "        for batch in dl_meta:\n",
        "            imgs, ids, bboxes, metas, orig_shapes = batch\n",
        "            for i, id_str in enumerate(ids):\n",
        "                meta_map[id_str] = (tuple(int(x) for x in bboxes[i]), tuple(int(x) for x in metas[i]), tuple(int(x) for x in orig_shapes[i]))\n",
        "    return meta_map\n",
        "\n",
        "def _ensure_nchw(t):\n",
        "    # Convert (B,H,W,C) to (B,C,H,W) if detected\n",
        "    if t.dim() == 4 and t.shape[1] != 3 and t.shape[-1] == 3:\n",
        "        return t.permute(0,3,1,2).contiguous()\n",
        "    return t\n",
        "\n",
        "def _align_logits_targets(logits, masks):\n",
        "    # Ensure both are (B,3,H,W). Handle ambiguous NHWC/NCHW cases.\n",
        "    if logits.dim() == 4 and logits.shape[1] not in (1,3) and logits.shape[-1] in (1,3):\n",
        "        logits = logits.permute(0,3,1,2).contiguous()\n",
        "    if masks.dim() == 4 and masks.shape[1] not in (1,3) and masks.shape[-1] in (1,3):\n",
        "        masks = masks.permute(0,3,1,2).contiguous()\n",
        "    # If still mismatched, try swapping last and channel dims of logits to match masks\n",
        "    if logits.shape != masks.shape:\n",
        "        if logits.dim()==4 and masks.dim()==4 and logits.shape[-1]==3 and masks.shape[1]==3:\n",
        "            logits = logits.permute(0,3,1,2).contiguous()\n",
        "        elif logits.dim()==4 and masks.dim()==4 and masks.shape[-1]==3 and logits.shape[1]==3:\n",
        "            masks = masks.permute(0,3,1,2).contiguous()\n",
        "    return logits, masks\n",
        "\n",
        "def train_one_fold(fold, epochs=40, lr=1e-3, wd=1e-4, batch_size=10, num_workers=4, device='cuda', patience=6, min_lr=1e-6):\n",
        "    print(f\"[TRAIN] Fold {fold} start\")\n",
        "    train_dl, valid_dl, va_ids = make_loaders(fold, batch_size=batch_size, num_workers=num_workers)\n",
        "    # Clear caches before model init to avoid CUDA init errors\n",
        "    gc.collect();\n",
        "    try:\n",
        "        torch.cuda.empty_cache()\n",
        "    except Exception:\n",
        "        pass\n",
        "    model = build_model_b3(device=device)\n",
        "    loss_fn = ComboLoss(bce_weight=0.5, tv_weight=0.5, tv_alpha=0.7, tv_beta=0.3, class_weights=(1.1,1.45,1.0))\n",
        "    opt = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    steps_per_epoch = max(1, len(train_dl))\n",
        "    total_steps = steps_per_epoch * epochs\n",
        "    warmup = min(int(0.05*total_steps), max(steps_per_epoch, 1))\n",
        "    def lr_schedule(step):\n",
        "        if step < warmup:\n",
        "            return step / max(1, warmup)\n",
        "        t = (step - warmup) / max(1, total_steps - warmup)\n",
        "        return min_lr/lr + (1 - min_lr/lr) * 0.5 * (1 + math.cos(math.pi * t))\n",
        "    # Disable AMP to avoid kernel death during backward (diagnostic forward succeeded)\n",
        "    scaler = GradScaler(enabled=False)\n",
        "    ema = EMA(model, decay=0.9995)\n",
        "    best_score = -1.0\n",
        "    best_epoch = 0\n",
        "    out_dir = Path('oof'); out_dir.mkdir(exist_ok=True, parents=True)\n",
        "    log_every = 50\n",
        "    step = 0\n",
        "    for epoch in range(1, epochs+1):\n",
        "        t0 = time.time()\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for it, batch in enumerate(train_dl):\n",
        "            imgs, masks, _ids = batch\n",
        "            imgs = imgs.to(device, non_blocking=True)\n",
        "            masks = masks.to(device, non_blocking=True)\n",
        "            for g in opt.param_groups:\n",
        "                g['lr'] = lr * lr_schedule(step)\n",
        "            # Disable autocast to avoid potential mixed precision instability\n",
        "            with autocast(enabled=False):\n",
        "                logits = model(imgs)\n",
        "                logits, masks = _align_logits_targets(logits, masks)\n",
        "                if it == 0 and epoch == 1:\n",
        "                    try:\n",
        "                        print(f\"[DBG] imgs={tuple(imgs.shape)} logits={tuple(logits.shape)} masks={tuple(masks.shape)}\", flush=True)\n",
        "                    except Exception:\n",
        "                        pass\n",
        "                loss = loss_fn(logits, masks)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            ema.update(model)\n",
        "            train_loss += loss.item()\n",
        "            if (it+1) % log_every == 0:\n",
        "                print(f\"[Fold {fold}] epoch {epoch} it {it+1}/{len(train_dl)} loss {train_loss/(it+1):.4f} lr {opt.param_groups[0]['lr']:.2e}\")\n",
        "            step += 1\n",
        "        # Validation using EMA weights without a second GPU model to save memory\n",
        "        backup_sd = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "        ema.apply_to(model)\n",
        "        model.eval()\n",
        "        dices = []\n",
        "        with torch.no_grad():\n",
        "            for imgs, masks, _ids in valid_dl:\n",
        "                imgs = imgs.to(device, non_blocking=True)\n",
        "                masks = masks.to(device, non_blocking=True)\n",
        "                logits = model(imgs)\n",
        "                logits, masks = _align_logits_targets(logits, masks)\n",
        "                probs = torch.sigmoid(logits).float().cpu().numpy()\n",
        "                tgts = masks.float().cpu().numpy()\n",
        "                for b in range(probs.shape[0]):\n",
        "                    for c in range(3):\n",
        "                        p = (probs[b,c] > 0.5).astype(np.uint8)\n",
        "                        t = (tgts[b,c] > 0.5).astype(np.uint8)\n",
        "                        dices.append(dice_score(p, t))\n",
        "        mean_dice = float(np.mean(dices)) if dices else 0.0\n",
        "        model.load_state_dict(backup_sd, strict=True)\n",
        "        model.train()\n",
        "        dt = time.time()-t0\n",
        "        print(f\"[Fold {fold}] epoch {epoch} train_loss {train_loss/max(1,len(train_dl)):.4f} val_dice {mean_dice:.4f} time {dt/60:.1f}m\")\n",
        "        improved = mean_dice > best_score + 1e-5\n",
        "        if improved:\n",
        "            best_score = mean_dice\n",
        "            best_epoch = epoch\n",
        "            ema.apply_to(model)\n",
        "            torch.save(model.state_dict(), f\"model_fold{fold}.pt\")\n",
        "            model.load_state_dict(backup_sd, strict=True)\n",
        "            print(f\"[Fold {fold}] Saved best EMA model, dice {best_score:.4f}\")\n",
        "        if (epoch - best_epoch) >= patience:\n",
        "            print(f\"[Fold {fold}] Early stopping at epoch {epoch} (best {best_epoch})\")\n",
        "            break\n",
        "        gc.collect();\n",
        "        torch.cuda.empty_cache()\n",
        "    print(f\"[TRAIN] Fold {fold} done. Best dice {best_score:.4f} at epoch {best_epoch}\")\n",
        "\n",
        "    # Compute and save OOF square probs + metadata for this fold using best EMA model\n",
        "    print(f\"[OOF] Collecting OOF predictions for fold {fold} ...\")\n",
        "    meta_map = _collect_valid_metadata(va_ids)\n",
        "    model_best = build_model_b3(device=device)\n",
        "    model_best.load_state_dict(torch.load(f\"model_fold{fold}.pt\", map_location=device), strict=True)\n",
        "    model_best.eval()\n",
        "    ids_all, probs_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, masks, _ids in valid_dl:\n",
        "            imgs = imgs.to(device, non_blocking=True)\n",
        "            logits = model_best(imgs)\n",
        "            logits, _ = _align_logits_targets(logits, masks)\n",
        "            probs = torch.sigmoid(logits).float().cpu().numpy()  # Bx3xHxW (square space)\n",
        "            probs_all.append(probs)\n",
        "            ids_all += list(_ids)\n",
        "    probs_all = np.concatenate(probs_all, axis=0).astype(np.float16)\n",
        "    np.save(f\"oof_fold{fold}_ids.npy\", np.array(ids_all, dtype=object))\n",
        "    np.save(f\"oof_fold{fold}_probs_sq.npy\", probs_all)\n",
        "    # Save metadata aligned to ids order for later inverse mapping and HD-aware tuning\n",
        "    bboxes = np.array([meta_map[_id][0] for _id in ids_all], dtype=np.int32)\n",
        "    metas = np.array([meta_map[_id][1] for _id in ids_all], dtype=np.int32)\n",
        "    origs = np.array([meta_map[_id][2] for _id in ids_all], dtype=np.int32)\n",
        "    np.savez_compressed(f\"oof_fold{fold}_meta.npz\", bbox=bboxes, meta=metas, orig_shape=origs)\n",
        "    print(f\"[OOF] Saved oof_fold{fold}_*.npy/npz\")\n",
        "\n",
        "def tta_hflip_predict(model, imgs):\n",
        "    # imgs: Bx5xHxW\n",
        "    logits = model(imgs)\n",
        "    imgs_h = torch.flip(imgs, dims=[-1])\n",
        "    logits_h = model(imgs_h)\n",
        "    logits_h = torch.flip(logits_h, dims=[-1])\n",
        "    return (logits + logits_h) / 2.0\n",
        "\n",
        "def post_process_full(mask, cls_index):\n",
        "    # mask: HxW uint8\n",
        "    lbl = label(mask)\n",
        "    if lbl.max() == 0:\n",
        "        return mask\n",
        "    areas = [(i, (lbl==i).sum()) for i in range(1, lbl.max()+1)]\n",
        "    areas.sort(key=lambda x: x[1], reverse=True)\n",
        "    keep = np.zeros_like(mask)\n",
        "    kept = 0\n",
        "    for i, a in areas:\n",
        "        if a >= PP_MIN_AREA[cls_index]:\n",
        "            keep[lbl==i] = 1\n",
        "            kept += 1\n",
        "            if cls_index==2 and kept>=1: break  # stomach: largest 1\n",
        "            if cls_index==0 and kept>=3: break  # large: top 3\n",
        "            if cls_index==1 and kept>=5: break  # small: top 5\n",
        "    if cls_index == 2:\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
        "        keep = cv2.morphologyEx(keep, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "        keep = binary_fill_holes(keep.astype(bool)).astype(np.uint8)\n",
        "    if cls_index == 1:\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
        "        keep = cv2.morphologyEx(keep, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "    return keep\n",
        "\n",
        "def _z_smooth_groups(id_info, window=3):\n",
        "    # Smooth probs in square space per (case,day) along slice order\n",
        "    from collections import defaultdict\n",
        "    groups = defaultdict(list)\n",
        "    for id_str in id_info.keys():\n",
        "        c, d, s = parse_id(id_str)\n",
        "        groups[(c,d)].append((s, id_str))\n",
        "    for key, lst in groups.items():\n",
        "        lst.sort(key=lambda x: x[0])\n",
        "        ids_sorted = [k for _, k in lst]\n",
        "        P = [id_info[k]['probs'] for k in ids_sorted]  # T x 3 x H x W\n",
        "        T = len(P)\n",
        "        if T >= 2 and window >= 3:\n",
        "            k = window\n",
        "            P_pad = [P[0]]*(k//2) + P + [P[-1]]*(k//2)\n",
        "            for t in range(T):\n",
        "                acc = None\n",
        "                for j in range(t, t+k):\n",
        "                    X = P_pad[j]\n",
        "                    acc = X if acc is None else acc + X\n",
        "                sm = acc / float(k)\n",
        "                id_info[ids_sorted[t]]['probs'] = sm\n",
        "    return id_info\n",
        "\n",
        "def _apply_z_consistency(masks_map):\n",
        "    # masks_map: dict[id_str] -> np array (3,H,W) uint8 after per-slice PP\n",
        "    from collections import defaultdict\n",
        "    groups = defaultdict(list)\n",
        "    for id_str in masks_map.keys():\n",
        "        c, d, s = parse_id(id_str)\n",
        "        groups[(c,d)].append((s, id_str))\n",
        "    for (c,d), lst in groups.items():\n",
        "        lst.sort(key=lambda x: x[0])\n",
        "        ids_sorted = [k for _, k in lst]\n",
        "        T = len(ids_sorted)\n",
        "        for cls_index in [0,1]:  # bowels only\n",
        "            for t, id_cur in enumerate(ids_sorted):\n",
        "                cur = masks_map[id_cur][cls_index].copy()\n",
        "                if cur.sum() == 0:\n",
        "                    continue\n",
        "                prev = masks_map[ids_sorted[t-1]][cls_index] if (t-1) >= 0 else None\n",
        "                nxt = masks_map[ids_sorted[t+1]][cls_index] if (t+1) < T else None\n",
        "                support = ((prev is not None and prev.any()) or (nxt is not None and nxt.any()))\n",
        "                if support:\n",
        "                    continue\n",
        "                # drop 1-slice small CCs below 1.2 * min_area\n",
        "                lbl = label(cur)\n",
        "                if lbl.max() == 0:\n",
        "                    continue\n",
        "                keep = np.zeros_like(cur)\n",
        "                for i in range(1, lbl.max()+1):\n",
        "                    a = (lbl==i).sum()\n",
        "                    if a >= int(1.2 * PP_MIN_AREA[cls_index]):\n",
        "                        keep[lbl==i] = 1\n",
        "                masks_map[id_cur][cls_index] = keep\n",
        "    return masks_map\n",
        "\n",
        "def infer_test_and_submit(device='cuda'):\n",
        "    print('[INFER] Loading models...')\n",
        "    models = []\n",
        "    for fold in range(5):\n",
        "        p = Path(f\"model_fold{fold}.pt\")\n",
        "        if not p.exists():\n",
        "            print(f\"[INFER] Missing model {p}, skipping fold {fold}\")\n",
        "            continue\n",
        "        m = build_model_b3(device=device)\n",
        "        sd = torch.load(p, map_location=device)\n",
        "        m.load_state_dict(sd, strict=True); m.eval()\n",
        "        models.append(m)\n",
        "    assert models, 'No trained models found'\n",
        "    sub = pd.read_csv('test.csv')\n",
        "    uniq_ids = sub['id'].unique().tolist()\n",
        "    df_ids = pd.DataFrame({'id':uniq_ids})\n",
        "    parsed = df_ids['id'].apply(parse_id)\n",
        "    df_ids[['case','day','slice']] = pd.DataFrame(parsed.tolist(), index=df_ids.index)\n",
        "    ds = UWGITractDataset(df_ids, train_df=None, roots=TEST_IMG_ROOTS, mode='test', aug=None)\n",
        "    dl = DataLoader(ds, batch_size=4, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=False)\n",
        "    id_info = {}  # id -> dict(probs, bbox, meta, orig_shape)\n",
        "    print('[INFER] Predicting...')\n",
        "    with torch.no_grad():\n",
        "        t0 = time.time()\n",
        "        for bi, batch in enumerate(dl):\n",
        "            imgs, ids, bboxes, metas, orig_shapes = batch\n",
        "            imgs = imgs.to(device)\n",
        "            logits_sum = None\n",
        "            for m in models:\n",
        "                logits = tta_hflip_predict(m, imgs)\n",
        "                logits_sum = logits if logits_sum is None else (logits_sum + logits)\n",
        "            probs = torch.sigmoid(logits_sum / len(models)).float().cpu().numpy()\n",
        "            assert probs.shape[0] == len(ids) == len(bboxes) == len(metas) == len(orig_shapes)\n",
        "            for i, id_str in enumerate(ids):\n",
        "                bb = tuple(int(x) for x in bboxes[i])\n",
        "                me = tuple(int(x) for x in metas[i])\n",
        "                osz = tuple(int(x) for x in orig_shapes[i])\n",
        "                id_info[id_str] = {'probs': probs[i], 'bbox': bb, 'meta': me, 'orig_shape': osz}\n",
        "            if (bi+1) % 25 == 0:\n",
        "                print(f\"[INFER] batch {bi+1}/{len(dl)} elapsed {(time.time()-t0):.1f}s\")\n",
        "    # z-smoothing per (case,day) before thresholding/post-proc\n",
        "    id_info = _z_smooth_groups(id_info, window=3)\n",
        "    # Build per-id masks with inverse mapping, threshold, and per-slice post-processing\n",
        "    print('[INFER] Post-processing and z-consistency...]')\n",
        "    masks_map = {}  # id -> (3,H,W) uint8\n",
        "    for id_str, info in id_info.items():\n",
        "        m3 = []\n",
        "        for ch in range(3):\n",
        "            full_prob = inverse_unwarp_probs(info['probs'][ch], info['meta'], info['bbox'], info['orig_shape'])\n",
        "            full_mask = (full_prob >= PP_THRESH[ch]).astype(np.uint8)\n",
        "            full_pp = post_process_full(full_mask, ch)\n",
        "            m3.append(full_pp.astype(np.uint8))\n",
        "        masks_map[id_str] = np.stack(m3, axis=0)\n",
        "    # z-consistency for bowels\n",
        "    masks_map = _apply_z_consistency(masks_map)\n",
        "    # Encode submission\n",
        "    rows = []\n",
        "    for _, r in sub.iterrows():\n",
        "        id_str = r['id']; cls = r['class']\n",
        "        if id_str not in masks_map:\n",
        "            rows.append('')\n",
        "            continue\n",
        "        ch = CLASSES.index(cls)\n",
        "        mm = masks_map[id_str][ch]\n",
        "        rle = rle_encode(mm.astype(np.uint8)) if mm.sum()>0 else ''\n",
        "        rows.append(rle)\n",
        "    sub['segmentation'] = rows\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('[INFER] Saved submission.csv')\n",
        "\n",
        "print('[TRAIN/INFER SKELETON READY] Defaults set per expert advice. When images are mounted, call train_one_fold(f) per fold, then infer_test_and_submit().')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "815a95c3-1de9-4d7a-a4aa-3eff368b4700",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fallback: create empty-mask submission (safety net; replace after real inference)\n",
        "import pandas as pd\n",
        "sub = pd.read_csv('test.csv').copy()\n",
        "sub['segmentation'] = ''\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('[FALLBACK] Wrote empty submission.csv with', len(sub), 'rows')\n",
        "print(sub.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "eff9f24c-cc7f-4e25-8402-76ea453137ce",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick fix for albumentations/albucore mismatch\n",
        "import sys, subprocess\n",
        "def pip(*args):\n",
        "    print(\"> pip\", \" \".join(args), flush=True)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", *args], check=True)\n",
        "\n",
        "# Albumentations 1.4.x requires recent albucore; install compatible version explicitly\n",
        "pip(\"install\", \"-c\", \"constraints.txt\", \"albucore==0.0.13\", \"--upgrade-strategy\", \"only-if-needed\")\n",
        "import albumentations as A\n",
        "print(\"albumentations:\", A.__version__)\n",
        "import albucore, inspect\n",
        "from albucore import utils as _u\n",
        "print(\"albucore:\", getattr(albucore, \"__version__\", \"?\"))\n",
        "print(\"has preserve_channel_dim:\", hasattr(_u, \"preserve_channel_dim\"))\n",
        "print(\"[ALBU READY]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f4a1fe53-19d9-49c7-b76b-11a819d6d84f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hard fix: ensure albumentations==1.3.1 is active and no albucore is lingering\n",
        "import sys, subprocess\n",
        "def pip(*args):\n",
        "    print(\"> pip\", \" \".join(args), flush=True)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", *args], check=True)\n",
        "\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"albumentations\", \"albucore\"], check=False)\n",
        "pip(\"install\", \"-c\", \"constraints.txt\", \"albumentations==1.3.1\", \"opencv-python-headless==4.10.0.84\", \"--upgrade-strategy\", \"only-if-needed\")\n",
        "import albumentations as A\n",
        "print(\"albumentations version:\", A.__version__)\n",
        "print(\"Has HorizontalFlip:\", hasattr(A, \"HorizontalFlip\"))\n",
        "print(\"[ALBU FIXED]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "8a3bb515-0ff3-4ec2-9ddf-0ce3267052bb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Poller: periodically scan for mounted PNG images and stop on first hit\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "def poll_for_images(interval_sec=90, max_minutes=45, max_show=10):\n",
        "    start = time.time()\n",
        "    deadline = start + max_minutes * 60.0\n",
        "    attempt = 0\n",
        "    candidates = [\n",
        "        Path('.'), Path('./train'), Path('./test'),\n",
        "        Path('/mnt'), Path('/data'), Path('/kaggle/input'), Path('/workspace')\n",
        "    ]\n",
        "    patterns = (\"**/case*/day*/scans/slice_*.png\", \"**/case*/day*/slice_*.png\")\n",
        "    print(f\"[POLL] Starting image poll: every {interval_sec}s for up to {max_minutes} min\")\n",
        "    while time.time() < deadline:\n",
        "        attempt += 1\n",
        "        found = []\n",
        "        checked = []\n",
        "        t0 = time.time()\n",
        "        for b in candidates:\n",
        "            if not b.exists():\n",
        "                continue\n",
        "            checked.append(str(b))\n",
        "            for pat in patterns:\n",
        "                try:\n",
        "                    for p in b.rglob(pat):\n",
        "                        found.append(str(p))\n",
        "                        if len(found) >= max_show:\n",
        "                            break\n",
        "                except Exception as e:\n",
        "                    print(f\"[POLL] Error scanning {b} with {pat}: {e}\")\n",
        "            if len(found) >= max_show:\n",
        "                break\n",
        "        dt = time.time() - t0\n",
        "        ts = time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        if found:\n",
        "            print(f\"[POLL] {ts} attempt {attempt}: FOUND {len(found)} samples (scanned {len(checked)} roots in {dt:.1f}s)\")\n",
        "            for p in found[:max_show]:\n",
        "                print('  ', p)\n",
        "            print(\"[POLL] Images detected. Proceed to build_cache/train.\")\n",
        "            return found\n",
        "        else:\n",
        "            remaining = max(0, int(deadline - time.time()))\n",
        "            print(f\"[POLL] {ts} attempt {attempt}: none found (scanned {len(checked)} roots in {dt:.1f}s). Next check in {interval_sec}s. Time left ~{remaining//60}m{remaining%60:02d}s\")\n",
        "            time.sleep(interval_sec)\n",
        "    print(\"[POLL] Timeout reached. No images detected.\")\n",
        "    return []\n",
        "\n",
        "print('[POLL CELL READY] Call poll_for_images(interval_sec=90, max_minutes=45) to wait for data mount.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "3e3630d5-45e5-42da-869d-c037162b6b7d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Start polling for data mounts (non-blocking until timeout)\n",
        "found_samples = poll_for_images(interval_sec=90, max_minutes=45)\n",
        "print('[POLL RESULT] Found samples:', len(found_samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "dd586963-c373-4144-941c-add23957e384",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# OOF tuning utilities: per-class threshold/min-area grid search with HD-aware proxy and parity PP\n",
        "import json, numpy as np, pandas as pd, cv2\n",
        "from pathlib import Path\n",
        "from scipy.ndimage import binary_fill_holes\n",
        "\n",
        "def z_smooth_probs(ids, probs_list, window=3):\n",
        "    # Moving average along slice order within each (case, day) group, sorted by slice\n",
        "    from collections import defaultdict\n",
        "    smoothed = [None]*len(ids)\n",
        "    by_group = defaultdict(list)\n",
        "    for i, id_str in enumerate(ids):\n",
        "        c, d, s = parse_id(id_str)\n",
        "        by_group[(c, d)].append((s, i))\n",
        "    k = window\n",
        "    for (c,d), lst in by_group.items():\n",
        "        lst.sort(key=lambda x: x[0])\n",
        "        idxs_sorted = [i for _, i in lst]\n",
        "        P = np.stack([probs_list[ii] for ii in idxs_sorted], axis=0)\n",
        "        if len(idxs_sorted) >= 2 and k >= 3:\n",
        "            P_pad = np.pad(P, ((k//2, k//2), (0,0), (0,0), (0,0)), mode='edge')\n",
        "            P_ma = np.zeros_like(P)\n",
        "            for t in range(len(idxs_sorted)):\n",
        "                P_ma[t] = P_pad[t:t+k].mean(axis=0)\n",
        "            for j, ii in enumerate(idxs_sorted):\n",
        "                smoothed[ii] = P_ma[j]\n",
        "        else:\n",
        "            for j, ii in enumerate(idxs_sorted):\n",
        "                smoothed[ii] = P[j]\n",
        "    return smoothed\n",
        "\n",
        "def load_all_oof():\n",
        "    ids_all, probs_all, bbox_all, meta_all, orig_all = [], [], [], [], []\n",
        "    for f in range(5):\n",
        "        p_ids = Path(\"oof_fold{f}_ids.npy\".format(f=f))\n",
        "        p_probs = Path(\"oof_fold{f}_probs_sq.npy\".format(f=f))\n",
        "        p_meta = Path(\"oof_fold{f}_meta.npz\".format(f=f))\n",
        "        if not (p_ids.exists() and p_probs.exists() and p_meta.exists()):\n",
        "            continue\n",
        "        ids = np.load(p_ids, allow_pickle=True).tolist()\n",
        "        probs = np.load(p_probs)\n",
        "        meta = np.load(p_meta)\n",
        "        ids_all += ids\n",
        "        probs_all.append(probs)\n",
        "        bbox_all.append(meta['bbox'])\n",
        "        meta_all.append(meta['meta'])\n",
        "        orig_all.append(meta['orig_shape'])\n",
        "    if not probs_all:\n",
        "        raise FileNotFoundError('No OOF artifacts found')\n",
        "    probs_all = np.concatenate(probs_all, axis=0)\n",
        "    bbox_all = np.concatenate(bbox_all, axis=0)\n",
        "    meta_all = np.concatenate(meta_all, axis=0)\n",
        "    orig_all = np.concatenate(orig_all, axis=0)\n",
        "    return ids_all, probs_all, bbox_all, meta_all, orig_all\n",
        "\n",
        "def _pp_per_slice(mask, cls_index, min_area, caps=(3,5,1)):\n",
        "    # mask: HxW uint8, returns post-processed uint8 with class caps and morphology\n",
        "    from skimage.measure import label\n",
        "    lbl = label(mask)\n",
        "    if lbl.max() == 0:\n",
        "        return mask.astype(np.uint8)\n",
        "    areas = [(i, (lbl==i).sum()) for i in range(1, lbl.max()+1)]\n",
        "    areas.sort(key=lambda x: x[1], reverse=True)\n",
        "    keep = np.zeros_like(mask, dtype=np.uint8)\n",
        "    kept = 0\n",
        "    cap = caps[cls_index]\n",
        "    for i, a in areas:\n",
        "        if a >= min_area[cls_index]:\n",
        "            keep[lbl==i] = 1\n",
        "            kept += 1\n",
        "            if kept >= cap:\n",
        "                break\n",
        "    if cls_index == 2:\n",
        "        ker = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
        "        keep = cv2.morphologyEx(keep, cv2.MORPH_CLOSE, ker, iterations=1)\n",
        "        keep = binary_fill_holes(keep.astype(bool)).astype(np.uint8)\n",
        "    if cls_index == 1:\n",
        "        ker = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
        "        keep = cv2.morphologyEx(keep, cv2.MORPH_OPEN, ker, iterations=1)\n",
        "    return keep.astype(np.uint8)\n",
        "\n",
        "def _apply_z_consistency_local(masks_map, min_area):\n",
        "    # masks_map: id -> (3,H,W) uint8; drop isolated 1-slice CCs for bowels if <1.2*min_area with no \u00b11 support\n",
        "    from collections import defaultdict\n",
        "    from skimage.measure import label\n",
        "    groups = defaultdict(list)\n",
        "    for id_str in masks_map.keys():\n",
        "        c, d, s = parse_id(id_str)\n",
        "        groups[(c,d)].append((s, id_str))\n",
        "    for (c,d), lst in groups.items():\n",
        "        lst.sort(key=lambda x: x[0])\n",
        "        ids_sorted = [k for _, k in lst]\n",
        "        T = len(ids_sorted)\n",
        "        for cls_index in [0,1]:\n",
        "            for t, id_cur in enumerate(ids_sorted):\n",
        "                cur = masks_map[id_cur][cls_index].copy()\n",
        "                if cur.sum() == 0:\n",
        "                    continue\n",
        "                prev = masks_map[ids_sorted[t-1]][cls_index] if (t-1) >= 0 else None\n",
        "                nxt = masks_map[ids_sorted[t+1]][cls_index] if (t+1) < T else None\n",
        "                support = ((prev is not None and prev.any()) or (nxt is not None and nxt.any()))\n",
        "                if support:\n",
        "                    continue\n",
        "                lbl = label(cur)\n",
        "                if lbl.max() == 0:\n",
        "                    continue\n",
        "                keep = np.zeros_like(cur)\n",
        "                thr = int(1.2 * min_area[cls_index])\n",
        "                for i in range(1, lbl.max()+1):\n",
        "                    a = (lbl==i).sum()\n",
        "                    if a >= thr:\n",
        "                        keep[lbl==i] = 1\n",
        "                masks_map[id_cur][cls_index] = keep\n",
        "    return masks_map\n",
        "\n",
        "def oof_proxy_score(thr, min_area, ids, probs_sq, bbox, meta, orig_shape, classes=('large_bowel','small_bowel','stomach')):\n",
        "    # Build per-id masks with inverse mapping and PP parity, apply z-consistency, then score with Dice+HD95 proxy\n",
        "    masks_map = {}  # id -> (3,H,W) uint8\n",
        "    for i, id_str in enumerate(ids):\n",
        "        mpp = []\n",
        "        for ci, cls in enumerate(classes):\n",
        "            prob_sq = probs_sq[i, ci]\n",
        "            full_prob = inverse_unwarp_probs(prob_sq, meta[i], bbox[i], orig_shape[i])\n",
        "            pred = (full_prob >= thr[ci]).astype(np.uint8)\n",
        "            pp = _pp_per_slice(pred, ci, min_area)\n",
        "            mpp.append(pp.astype(np.uint8))\n",
        "        masks_map[id_str] = np.stack(mpp, axis=0)\n",
        "    masks_map = _apply_z_consistency_local(masks_map, min_area)\n",
        "    per_example = []\n",
        "    for i, id_str in enumerate(ids):\n",
        "        sub = train_df[train_df['id']==id_str]\n",
        "        H0, W0 = orig_shape[i]\n",
        "        for ci, cls in enumerate(classes):\n",
        "            predm = masks_map[id_str][ci]\n",
        "            r = sub[sub['class']==cls].iloc[0]\n",
        "            tgt = rle_decode(r['segmentation'] if isinstance(r['segmentation'], str) else '', (H0, W0)).astype(np.uint8)\n",
        "            inter = (predm & tgt).sum()\n",
        "            dice = (2*inter + 1e-6)/ (predm.sum() + tgt.sum() + 1e-6)\n",
        "            hd = hd95_proxy(predm, tgt)\n",
        "            score = 0.6 * dice + 0.4 * (1 - min(hd/100.0, 1.0))\n",
        "            per_example.append(score)\n",
        "    return float(np.mean(per_example)) if per_example else 0.0\n",
        "\n",
        "def grid_tune_oof(z_window=3):\n",
        "    # Pruned Stage-1 grid per expert advice, then Stage-2 refine\n",
        "    ids, probs, bbox, meta, orig = load_all_oof()\n",
        "    probs_list = [probs[i] for i in range(len(ids))]\n",
        "    probs_sm = z_smooth_probs(ids, probs_list, window=z_window)\n",
        "    probs_sm = np.stack(probs_sm, axis=0)\n",
        "    # Stage 1 (pruned): thresholds and min_area candidates\n",
        "    thr_candidates = [\n",
        "        [0.45, 0.50, 0.55],  # large bowel\n",
        "        [0.45, 0.50, 0.55],  # small bowel\n",
        "        [0.45, 0.50, 0.55],  # stomach\n",
        "    ]\n",
        "    area_candidates = [\n",
        "        [1000, 1400, 1800],  # large\n",
        "        [800, 1000, 1200],   # small\n",
        "        [700, 900],          # stomach\n",
        "    ]\n",
        "    best = {'score': -1, 'thr': None, 'min_area': None}\n",
        "    for t0 in thr_candidates[0]:\n",
        "        for t1 in thr_candidates[1]:\n",
        "            for t2 in thr_candidates[2]:\n",
        "                thr = [float(t0), float(t1), float(t2)]\n",
        "                for a0 in area_candidates[0]:\n",
        "                    for a1 in area_candidates[1]:\n",
        "                        for a2 in area_candidates[2]:\n",
        "                            mins = [int(a0), int(a1), int(a2)]\n",
        "                            sc = oof_proxy_score(thr, mins, ids, probs_sm, bbox, meta, orig)\n",
        "                            if sc > best['score'] + 1e-6:\n",
        "                                best = {'score': float(sc), 'thr': thr, 'min_area': mins}\n",
        "    print('[TUNE][Stage1] Best:', best)\n",
        "    # Stage 2 refine around best\n",
        "    bt = best['thr']; ba = best['min_area']\n",
        "    thr_ref = []\n",
        "    for x in bt:\n",
        "        lo = max(0.0, x - 0.03); hi = min(1.0, x + 0.03)\n",
        "        thr_ref.append(np.round(np.arange(lo, hi+1e-9, 0.01), 2))\n",
        "    area_ref = []\n",
        "    for i, a in enumerate(ba):\n",
        "        lo = max(0, a - 200); hi = a + 200\n",
        "        area_ref.append(np.arange(lo, hi+1e-9, 100).astype(int))\n",
        "    best2 = dict(best)\n",
        "    for t0 in thr_ref[0]:\n",
        "        for t1 in thr_ref[1]:\n",
        "            for t2 in thr_ref[2]:\n",
        "                thr = [float(t0), float(t1), float(t2)]\n",
        "                for a0 in area_ref[0]:\n",
        "                    for a1 in area_ref[1]:\n",
        "                        for a2 in area_ref[2]:\n",
        "                            mins = [int(a0), int(a1), int(a2)]\n",
        "                            sc = oof_proxy_score(thr, mins, ids, probs_sm, bbox, meta, orig)\n",
        "                            if sc > best2['score'] + 1e-6:\n",
        "                                best2 = {'score': float(sc), 'thr': thr, 'min_area': mins}\n",
        "    Path('tuned_pp.json').write_text(json.dumps(best2, indent=2))\n",
        "    print('[TUNE][Stage2] Best:', best2)\n",
        "    return best2\n",
        "\n",
        "print('[OOF TUNING UTILS READY] Parity with inference: stomach close+fill, small-bowel opening, z-smoothing(sorted)=3, z-consistency(edge-safe). Pruned Stage-1 + Stage-2 refine enabled.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "845839e4-198a-4b12-a61e-1db488402135",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Synthetic smoke test (optional while waiting for real data mounts)\n",
        "import numpy as np, cv2, pandas as pd, torch, os, shutil, math, time, re\n",
        "from pathlib import Path\n",
        "import torch.nn as nn\n",
        "\n",
        "# Ensure CLASSES is defined if prior cells weren't executed in this kernel\n",
        "try:\n",
        "    CLASSES\n",
        "except NameError:\n",
        "    CLASSES = ['large_bowel','small_bowel','stomach']\n",
        "\n",
        "# Provide a local resolve_path fallback if not defined (for synthetic data only)\n",
        "if 'resolve_path' not in globals():\n",
        "    def resolve_path(id_str, roots):\n",
        "        m = re.match(r'^case(\\d+)_day(\\d+)_slice_(\\d+)$', id_str)\n",
        "        if not m:\n",
        "            raise FileNotFoundError(id_str)\n",
        "        case, day, sl = int(m.group(1)), int(m.group(2)), int(m.group(3))\n",
        "        roots = roots or [Path('train_syn')]\n",
        "        for r in roots:\n",
        "            p = Path(r) / f'case{case}' / f'day{day}' / 'scans' / f'slice_{sl:04d}.png'\n",
        "            if p.exists():\n",
        "                return p\n",
        "        # return canonical path under first root even if missing (upstream will handle)\n",
        "        return Path(roots[0]) / f'case{case}' / f'day{day}' / 'scans' / f'slice_{sl:04d}.png'\n",
        "\n",
        "def make_syn_blob(H=512, W=512, center=None, radius=60):\n",
        "    y,x = np.ogrid[:H, :W]\n",
        "    if center is None:\n",
        "        cy, cx = H//2 + np.random.randint(-30,30), W//2 + np.random.randint(-30,30)\n",
        "    else:\n",
        "        cy, cx = center\n",
        "    r2 = (y-cy)**2 + (x-cx)**2\n",
        "    return (r2 <= radius*radius).astype(np.uint8)\n",
        "\n",
        "def mask_to_rle_fortran(mask):\n",
        "    pixels = mask.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "# Local ID parser to avoid dependency on earlier cells\n",
        "def _parse_id_local(s):\n",
        "    m = re.match(r'^case(\\d+)_day(\\d+)_slice_(\\d+)$', s)\n",
        "    if not m:\n",
        "        return (0,0,0)\n",
        "    return (int(m.group(1)), int(m.group(2)), int(m.group(3)))\n",
        "\n",
        "def build_synthetic_dataset(root='train_syn', n_cases=1, n_slices=8, H=512, W=512, classes=None):\n",
        "    if classes is None:\n",
        "        classes = ['large_bowel','small_bowel','stomach']\n",
        "    root = Path(root);\n",
        "    if root.exists():\n",
        "        shutil.rmtree(root)\n",
        "    ids = []\n",
        "    rows = []\n",
        "    for case in range(900, 900+n_cases):\n",
        "        day = 0\n",
        "        for s in range(1, n_slices+1):\n",
        "            id_str = f\"case{case}_day{day}_slice_{s:04d}\"\n",
        "            ids.append(id_str)\n",
        "            d = root / f\"case{case}\" / f\"day{day}\" / \"scans\"\n",
        "            d.mkdir(parents=True, exist_ok=True)\n",
        "            img = (np.random.rand(H,W)*60000).astype(np.uint16)\n",
        "            # Add brighter foreground ellipse to simulate body\n",
        "            body = make_syn_blob(H,W, radius=min(H,W)//2 - 40).astype(bool)\n",
        "            img[~body] = (img[~body]*0.05).astype(np.uint16)\n",
        "            cv2.imwrite(str(d / f\"slice_{s:04d}.png\"), img)\n",
        "            # simple masks (only some slices positive)\n",
        "            for cls in classes:\n",
        "                if (s % 3 == 0) and cls in ('stomach','large_bowel'):\n",
        "                    mask = make_syn_blob(H,W, radius=40 if cls=='stomach' else 55)\n",
        "                    rle = mask_to_rle_fortran(mask)\n",
        "                else:\n",
        "                    rle = ''\n",
        "                rows.append({'id': id_str, 'class': cls, 'segmentation': rle})\n",
        "    train_df_syn = pd.DataFrame(rows)\n",
        "    df_ids = pd.DataFrame({'id': ids})\n",
        "    parsed = df_ids['id'].apply(_parse_id_local)\n",
        "    df_ids[['case','day','slice']] = pd.DataFrame(parsed.tolist(), index=df_ids.index)\n",
        "    return train_df_syn, df_ids, Path(root)\n",
        "\n",
        "class TinySegNet(nn.Module):\n",
        "    def __init__(self, in_ch=5, num_classes=3):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, 16, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, num_classes, kernel_size=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def smoke_test_pipeline():\n",
        "    print('[SMOKE] Building synthetic dataset...')\n",
        "    train_df_syn, df_ids_syn, root = build_synthetic_dataset()\n",
        "    print('[SMOKE] Creating Datasets...')\n",
        "    ds_tr = UWGITractDataset(df_ids_syn.iloc[:6], train_df=train_df_syn, roots=[root], mode='train', aug=get_valid_aug())\n",
        "    ds_te = UWGITractDataset(df_ids_syn.iloc[:6], train_df=None, roots=[root], mode='test', aug=None)\n",
        "    x, y, _ = ds_tr[0]\n",
        "    print('[SMOKE] Train sample img5/mask3 shapes:', tuple(x.shape), tuple(y.shape))\n",
        "    xt, _id, bbox, meta, orig = ds_te[0]\n",
        "    print('[SMOKE] Test meta bbox/meta/orig:', bbox, meta, orig)\n",
        "    # Model forward using a tiny local CNN (no SMP) on CPU to avoid instability\n",
        "    print('[SMOKE] Model forward...')\n",
        "    device = 'cpu'\n",
        "    model = TinySegNet().to(device)\n",
        "    with torch.no_grad():\n",
        "        xb = torch.stack([x, x], dim=0).to(device)\n",
        "        out = model(xb)\n",
        "    print('[SMOKE] Logits shape:', tuple(out.shape))\n",
        "    # Loss eval\n",
        "    loss_fn = ComboLoss()\n",
        "    loss = loss_fn(out.cpu(), torch.stack([y, y], dim=0).float())\n",
        "    print('[SMOKE] Loss OK:', float(loss))\n",
        "    # Inverse unwarp sanity\n",
        "    probs = torch.sigmoid(out[:1]).cpu().numpy()[0]\n",
        "    full_prob0 = inverse_unwarp_probs(probs[2], meta, bbox, orig)  # stomach channel\n",
        "    print('[SMOKE] Inverse unwarp prob shape:', full_prob0.shape, 'range', (float(full_prob0.min()), float(full_prob0.max())))\n",
        "    print('[SMOKE DONE]')\n",
        "\n",
        "print('[SMOKE CELL READY] Call smoke_test_pipeline() to validate end-to-end components without real data.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0d2b9ea9-ce02-4cee-93ce-41e6dd5321f9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run synthetic smoke test while awaiting data mounts\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "# Guard: ensure parse_id exists for older function defs\n",
        "if 'parse_id' not in globals():\n",
        "    _id_pat = re.compile(r'^case(\\d+)_day(\\d+)_slice_(\\d+)$')\n",
        "    def parse_id(s):\n",
        "        m = _id_pat.match(s)\n",
        "        if not m:\n",
        "            return (0,0,0)\n",
        "        return tuple(int(x) for x in m.groups())\n",
        "\n",
        "# Unconditionally define a simple resolve_path fallback for smoke (ensures availability in UWGITractDataset globals)\n",
        "def resolve_path(id_str, roots):\n",
        "    m = re.match(r'^case(\\d+)_day(\\d+)_slice_(\\d+)$', id_str)\n",
        "    if not m:\n",
        "        raise FileNotFoundError(id_str)\n",
        "    case, day, sl = int(m.group(1)), int(m.group(2)), int(m.group(3))\n",
        "    roots = roots or [Path('train_syn')]\n",
        "    for r in roots:\n",
        "        p = Path(r) / f'case{case}' / f'day{day}' / 'scans' / f'slice_{sl:04d}.png'\n",
        "        if p.exists():\n",
        "            return p\n",
        "    return Path(roots[0]) / f'case{case}' / f'day{day}' / 'scans' / f'slice_{sl:04d}.png'\n",
        "\n",
        "smoke_test_pipeline()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f2eaad22-f96e-45f1-8585-c7ed0766546c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Poll only official roots (exclude synthetic) for mounted PNG images\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "def poll_for_official_images(interval_sec=120, max_minutes=60, max_show=10):\n",
        "    start = time.time()\n",
        "    deadline = start + max_minutes * 60.0\n",
        "    attempt = 0\n",
        "    candidates = [Path('./train'), Path('./test'), Path('/mnt'), Path('/data')]\n",
        "    patterns = (\"**/case*/day*/scans/slice_*.png\", \"**/case*/day*/slice_*.png\")\n",
        "    print(f\"[POLL-OFF] Starting official image poll: every {interval_sec}s for up to {max_minutes} min\")\n",
        "    while time.time() < deadline:\n",
        "        attempt += 1\n",
        "        found = []\n",
        "        checked = []\n",
        "        t0 = time.time()\n",
        "        for b in candidates:\n",
        "            if not b.exists():\n",
        "                continue\n",
        "            checked.append(str(b))\n",
        "            for pat in patterns:\n",
        "                try:\n",
        "                    for p in b.rglob(pat):\n",
        "                        sp = str(p)\n",
        "                        if 'train_syn' in sp:\n",
        "                            continue\n",
        "                        found.append(sp)\n",
        "                        if len(found) >= max_show:\n",
        "                            break\n",
        "                except Exception as e:\n",
        "                    print(f\"[POLL-OFF] Error scanning {b} with {pat}: {e}\")\n",
        "            if len(found) >= max_show:\n",
        "                break\n",
        "        dt = time.time() - t0\n",
        "        ts = time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        if found:\n",
        "            print(f\"[POLL-OFF] {ts} attempt {attempt}: FOUND {len(found)} samples (scanned {len(checked)} roots in {dt:.1f}s)\")\n",
        "            for p in found[:max_show]:\n",
        "                print('  ', p)\n",
        "            print(\"[POLL-OFF] Official images detected. Proceed to build_cache/train.\")\n",
        "            return found\n",
        "        else:\n",
        "            remaining = max(0, int(deadline - time.time()))\n",
        "            print(f\"[POLL-OFF] {ts} attempt {attempt}: none found (scanned {len(checked)} roots in {dt:.1f}s). Next check in {interval_sec}s. Time left ~{remaining//60}m{remaining%60:02d}s\")\n",
        "            time.sleep(interval_sec)\n",
        "    print(\"[POLL-OFF] Timeout reached. No official images detected.\")\n",
        "    return []\n",
        "\n",
        "print('[POLL-OFF CELL READY] Running official mount poller...')\n",
        "found_official = poll_for_official_images(interval_sec=120, max_minutes=60)\n",
        "print('[POLL-OFF RESULT] Found samples:', len(found_official))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0a4aa695-909e-47a3-9eff-f3ada0ff30d1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Improved official-only poller (expanded roots per expert advice)\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "def poll_for_official_images_v2(interval_sec=120, max_minutes=60, max_show=12):\n",
        "    start = time.time()\n",
        "    deadline = start + max_minutes * 60.0\n",
        "    attempt = 0\n",
        "    candidates = [\n",
        "        Path('./train'), Path('./test'),\n",
        "        Path('/mnt'), Path('/data'), Path('/kaggle/input'),\n",
        "        Path('/opt/data'), Path('/app/data'), Path('/datasets'), Path('/workspace/data')\n",
        "    ]\n",
        "    patterns = (\"**/case*/day*/scans/slice_*.png\", \"**/case*/day*/slice_*.png\")\n",
        "    print(f\"[POLL-OFF V2] Starting official image poll: every {interval_sec}s for up to {max_minutes} min\")\n",
        "    while time.time() < deadline:\n",
        "        attempt += 1\n",
        "        found = []\n",
        "        checked = []\n",
        "        t0 = time.time()\n",
        "        for b in candidates:\n",
        "            if not b.exists():\n",
        "                continue\n",
        "            checked.append(str(b))\n",
        "            for pat in patterns:\n",
        "                try:\n",
        "                    for p in b.rglob(pat):\n",
        "                        sp = str(p)\n",
        "                        if 'train_syn' in sp:\n",
        "                            continue\n",
        "                        found.append(sp)\n",
        "                        if len(found) >= max_show:\n",
        "                            break\n",
        "                except Exception as e:\n",
        "                    print(f\"[POLL-OFF V2] Error scanning {b} with {pat}: {e}\")\n",
        "            if len(found) >= max_show:\n",
        "                break\n",
        "        dt = time.time() - t0\n",
        "        ts = time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        if found:\n",
        "            print(f\"[POLL-OFF V2] {ts} attempt {attempt}: FOUND {len(found)} samples (scanned {len(checked)} roots in {dt:.1f}s)\")\n",
        "            for p in found[:max_show]:\n",
        "                print('  ', p)\n",
        "            print(\"[POLL-OFF V2] Official images detected. Proceed to build_cache/train.\")\n",
        "            return found\n",
        "        else:\n",
        "            remaining = max(0, int(deadline - time.time()))\n",
        "            print(f\"[POLL-OFF V2] {ts} attempt {attempt}: none found (scanned {len(checked)} roots in {dt:.1f}s). Next check in {interval_sec}s. Time left ~{remaining//60}m{remaining%60:02d}s\")\n",
        "            time.sleep(interval_sec)\n",
        "    print(\"[POLL-OFF V2] Timeout reached. No official images detected.\")\n",
        "    return []\n",
        "\n",
        "print('[POLL-OFF V2 CELL READY] When ready, interrupt Cell 15 and run: found_official = poll_for_official_images_v2(interval_sec=120, max_minutes=60)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "31d4f33c-dd8a-4a53-a6ac-e04428ab3760",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Start improved official-only poller\n",
        "found_official_v2 = poll_for_official_images_v2(interval_sec=120, max_minutes=60)\n",
        "print('[POLL-OFF V2 RESULT] Found samples:', len(found_official_v2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "d4758201-ad91-4e1f-8f0c-af4043808580",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Orchestration helpers: cache -> train -> tune -> infer\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import json, time, gc\n",
        "\n",
        "def build_train_test_cache(train_out='cache/train', test_out='cache/test', log_every=200):\n",
        "    print('[ORCH] Building train cache...')\n",
        "    df_ids_tr = (train_df.drop_duplicates('id')[['id','case','day','slice']].reset_index(drop=True))\n",
        "    t0 = time.time()\n",
        "    build_cache(df_ids_tr, train_df=train_df, roots=TRAIN_IMG_ROOTS, out_dir=train_out, mode='train', log_every=log_every)\n",
        "    print(f\"[ORCH] Train cache done in {(time.time()-t0)/60:.1f}m\")\n",
        "    print('[ORCH] Building test cache...')\n",
        "    df_ids_te = (test_df.drop_duplicates('id')[['id','case','day','slice']].reset_index(drop=True))\n",
        "    t1 = time.time()\n",
        "    build_cache(df_ids_te, train_df=None, roots=TEST_IMG_ROOTS, out_dir=test_out, mode='test', log_every=log_every)\n",
        "    print(f\"[ORCH] Test cache done in {(time.time()-t1)/60:.1f}m\")\n",
        "    gc.collect()\n",
        "\n",
        "def train_all_folds(epochs=40, batch_size=10, device='cuda'):\n",
        "    for f in range(5):\n",
        "        print('='*40); print(f'[ORCH] Training fold {f}'); print('='*40)\n",
        "        train_one_fold(f, epochs=epochs, batch_size=batch_size, device=device)\n",
        "        gc.collect()\n",
        "\n",
        "def tune_pp_and_save(z_window=3):\n",
        "    print('[ORCH] Running OOF tuning...')\n",
        "    best = grid_tune_oof(z_window=z_window)\n",
        "    Path('tuned_pp.json').write_text(json.dumps(best, indent=2))\n",
        "    print('[ORCH] Saved tuned_pp.json:', best)\n",
        "    return best\n",
        "\n",
        "def full_infer():\n",
        "    print('[ORCH] Inference to submission.csv...')\n",
        "    infer_test_and_submit()\n",
        "    print('[ORCH] submission.csv written')\n",
        "\n",
        "print('[ORCH READY] When mounts appear: 1) interrupt poller, 2) run build_train_test_cache(), 3) train_all_folds(), 4) tune_pp_and_save(), 5) full_infer().')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ORCH READY] When mounts appear: 1) interrupt poller, 2) run build_train_test_cache(), 3) train_all_folds(), 4) tune_pp_and_save(), 5) full_infer().\n"
          ]
        }
      ]
    },
    {
      "id": "7c06fdc8-a9a6-403f-a1ac-2543949ba91c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Programmatic data fetch via Kaggle API (optional; requires kaggle.json credentials)\n",
        "import os, sys, subprocess, shutil, json, time, glob\n",
        "from pathlib import Path\n",
        "\n",
        "def _run(cmd):\n",
        "    print('> ', ' '.join(cmd), flush=True)\n",
        "    return subprocess.run(cmd, check=False, capture_output=True, text=True)\n",
        "\n",
        "def try_kaggle_download():\n",
        "    # Check credentials\n",
        "    kaggle_json = Path.home()/'.kaggle'/'kaggle.json'\n",
        "    if not kaggle_json.exists():\n",
        "        print('[KAGGLE] ~/.kaggle/kaggle.json not found. Skipping Kaggle API download.')\n",
        "        print('[KAGGLE] If available, place kaggle.json and chmod 600, then re-run this cell.')\n",
        "        return False\n",
        "    kaggle_json.chmod(0o600)\n",
        "    # Ensure kaggle package\n",
        "    _run([sys.executable, '-m', 'pip', 'install', 'kaggle', '--upgrade', '--quiet'])\n",
        "    dl_root = Path('/kaggle/working') if Path('/kaggle').exists() else Path('kaggledl')\n",
        "    dl_root.mkdir(parents=True, exist_ok=True)\n",
        "    print('[KAGGLE] Download root:', dl_root)\n",
        "    # Preferred 384x384 PNG mirror preserving structure\n",
        "    ds_slug = 'andrewmvd/uw-madison-gi-tract-image-segmentation-2d'\n",
        "    print('[KAGGLE] Downloading dataset:', ds_slug)\n",
        "    res = _run(['kaggle', 'datasets', 'download', '-d', ds_slug, '-p', str(dl_root), '--unzip'])\n",
        "    if res.returncode != 0:\n",
        "        print('[KAGGLE] Download failed:', res.stderr.strip())\n",
        "        return False\n",
        "    # Detect train/test dirs within download\n",
        "    train_cands = []\n",
        "    test_cands = []\n",
        "    for p in dl_root.rglob('train'):\n",
        "        if (p.is_dir() and list(p.rglob('case*/day*/scans/slice_*.png'))[:1]):\n",
        "            train_cands.append(p)\n",
        "    for p in dl_root.rglob('test'):\n",
        "        if (p.is_dir() and list(p.rglob('case*/day*/scans/slice_*.png'))[:1]):\n",
        "            test_cands.append(p)\n",
        "    # Fallback names like train_png/test_png\n",
        "    for p in dl_root.rglob('train_png'):\n",
        "        if (p.is_dir() and list(p.rglob('case*/day*/scans/slice_*.png'))[:1]):\n",
        "            train_cands.append(p)\n",
        "    for p in dl_root.rglob('test_png'):\n",
        "        if (p.is_dir() and list(p.rglob('case*/day*/scans/slice_*.png'))[:1]):\n",
        "            test_cands.append(p)\n",
        "    train_cands = sorted(set(train_cands))\n",
        "    test_cands = sorted(set(test_cands))\n",
        "    if not train_cands or not test_cands:\n",
        "        print('[KAGGLE] Could not find train/test directories after unzip.')\n",
        "        return False\n",
        "    # Prepend to resolver roots\n",
        "    tr0, te0 = train_cands[0], test_cands[0]\n",
        "    print('[KAGGLE] Using roots:', tr0, te0)\n",
        "    if 'TRAIN_IMG_ROOTS' in globals():\n",
        "        TRAIN_IMG_ROOTS.insert(0, tr0)\n",
        "    if 'TEST_IMG_ROOTS' in globals():\n",
        "        TEST_IMG_ROOTS.insert(0, te0)\n",
        "    # Quick sanity: count PNGs\n",
        "    def _count_pngs(root):\n",
        "        try:\n",
        "            return sum(1 for _ in root.rglob('case*/day*/scans/slice_*.png'))\n",
        "        except Exception:\n",
        "            return 0\n",
        "    n_tr = _count_pngs(tr0)\n",
        "    n_te = _count_pngs(te0)\n",
        "    print(f'[KAGGLE] train PNGs: {n_tr}, test PNGs: {n_te}')\n",
        "    # Spot read a few files\n",
        "    samples = list(tr0.rglob('case*/day*/scans/slice_*.png'))[:3]\n",
        "    print('[KAGGLE] sample files:')\n",
        "    for s in samples:\n",
        "        print(' ', s)\n",
        "    print('[KAGGLE] Download and path injection complete.')\n",
        "    return True\n",
        "\n",
        "ok = try_kaggle_download()\n",
        "print('[KAGGLE DONE] success=', ok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f87f6749-709d-475f-8e8f-5a53a13650f4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Auto-extract archives (zip/tgz) if present and inject roots\n",
        "import os, sys, tarfile, zipfile, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def safe_extract_zip(zp, dest):\n",
        "    with zipfile.ZipFile(zp, 'r') as zf:\n",
        "        zf.extractall(dest)\n",
        "\n",
        "def safe_extract_tar(tp, dest):\n",
        "    mode = 'r:gz' if str(tp).endswith(('.tar.gz', '.tgz')) else 'r:'\n",
        "    with tarfile.open(tp, mode) as tf:\n",
        "        def is_within_directory(directory, target):\n",
        "            abs_directory = os.path.abspath(directory)\n",
        "            abs_target = os.path.abspath(target)\n",
        "            return os.path.commonpath([abs_directory]) == os.path.commonpath([abs_directory, abs_target])\n",
        "        for m in tf.getmembers():\n",
        "            target = os.path.join(dest, m.name)\n",
        "            if not is_within_directory(dest, target):\n",
        "                continue\n",
        "        tf.extractall(dest)\n",
        "\n",
        "def scan_and_extract_archives():\n",
        "    roots = [Path('/kaggle/input'), Path('/mnt'), Path('/data'), Path('.')]\n",
        "    ex_root = Path('external_data'); ex_root.mkdir(exist_ok=True, parents=True)\n",
        "    found_archives = []\n",
        "    for r in roots:\n",
        "        if not r.exists():\n",
        "            continue\n",
        "        for p in r.rglob('*'):\n",
        "            s = str(p)\n",
        "            if p.is_file() and (s.endswith('.zip') or s.endswith('.tar.gz') or s.endswith('.tgz')):\n",
        "                found_archives.append(p)\n",
        "    if not found_archives:\n",
        "        print('[EXTRACT] No archives found under candidates')\n",
        "        return False\n",
        "    print(f'[EXTRACT] Found {len(found_archives)} archives')\n",
        "    for a in found_archives:\n",
        "        out = ex_root / a.stem.replace('.tar','')\n",
        "        if out.exists() and any(out.iterdir()):\n",
        "            print('[EXTRACT] Skip existing:', out)\n",
        "            continue\n",
        "        out.mkdir(parents=True, exist_ok=True)\n",
        "        try:\n",
        "            if str(a).endswith('.zip'):\n",
        "                print('[EXTRACT] Unzipping', a, '->', out)\n",
        "                safe_extract_zip(a, out)\n",
        "            else:\n",
        "                print('[EXTRACT] Untarring', a, '->', out)\n",
        "                safe_extract_tar(a, out)\n",
        "        except Exception as e:\n",
        "            print('[EXTRACT] Failed for', a, e)\n",
        "    # After extraction, search for train/test roots and prepend\n",
        "    train_cands, test_cands = [], []\n",
        "    for p in ex_root.rglob('train'):\n",
        "        if p.is_dir() and list(p.rglob('case*/day*/scans/slice_*.png'))[:1]:\n",
        "            train_cands.append(p)\n",
        "    for p in ex_root.rglob('test'):\n",
        "        if p.is_dir() and list(p.rglob('case*/day*/scans/slice_*.png'))[:1]:\n",
        "            test_cands.append(p)\n",
        "    for p in ex_root.rglob('train_png'):\n",
        "        if p.is_dir() and list(p.rglob('case*/day*/scans/slice_*.png'))[:1]:\n",
        "            train_cands.append(p)\n",
        "    for p in ex_root.rglob('test_png'):\n",
        "        if p.is_dir() and list(p.rglob('case*/day*/scans/slice_*.png'))[:1]:\n",
        "            test_cands.append(p)\n",
        "    train_cands = sorted(set(train_cands)); test_cands = sorted(set(test_cands))\n",
        "    if train_cands and test_cands:\n",
        "        tr0, te0 = train_cands[0], test_cands[0]\n",
        "        print('[EXTRACT] Using roots:', tr0, te0)\n",
        "        if 'TRAIN_IMG_ROOTS' in globals():\n",
        "            TRAIN_IMG_ROOTS.insert(0, tr0)\n",
        "        if 'TEST_IMG_ROOTS' in globals():\n",
        "            TEST_IMG_ROOTS.insert(0, te0)\n",
        "        # Quick counts\n",
        "        def _count_pngs(root):\n",
        "            try:\n",
        "                return sum(1 for _ in root.rglob('case*/day*/scans/slice_*.png'))\n",
        "            except Exception:\n",
        "                return 0\n",
        "        print(f\"[EXTRACT] Counts train={_count_pngs(tr0)} test={_count_pngs(te0)}\")\n",
        "        return True\n",
        "    else:\n",
        "        print('[EXTRACT] No valid train/test structure found post-extraction')\n",
        "        return False\n",
        "\n",
        "ok = scan_and_extract_archives()\n",
        "print('[EXTRACT DONE] success=', ok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "59773eb2-06b1-4319-b7b1-394bd654ba85",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspect extracted archive structure to locate train/test PNGs\n",
        "from pathlib import Path\n",
        "import os, itertools\n",
        "\n",
        "base = Path('external_data')\n",
        "print('[INSPECT] Listing immediate subdirs under external_data:')\n",
        "for p in base.iterdir():\n",
        "    if p.is_dir():\n",
        "        print(' -', p, '(', sum(1 for _ in p.iterdir()), 'items)')\n",
        "\n",
        "root = base / 'uw-madison-gi-tract-image-segmentation'\n",
        "print('[INSPECT] Root exists:', root.exists(), root)\n",
        "if root.exists():\n",
        "    print('[INSPECT] Top-level entries:')\n",
        "    for p in root.iterdir():\n",
        "        print('   ', p.name, '(dir)' if p.is_dir() else '(file)')\n",
        "    # Try common expected structures\n",
        "    candidates = [\n",
        "        root / 'train',\n",
        "        root / 'test',\n",
        "        root / 'train_png',\n",
        "        root / 'test_png',\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        print('[INSPECT] Candidate', c, 'exists=', c.exists())\n",
        "        if c.exists():\n",
        "            n_png = sum(1 for _ in c.rglob('slice_*.png'))\n",
        "            print('   -> PNG count:', n_png)\n",
        "    # Fallback: search for any slice_*.png anywhere under root\n",
        "    any_pngs = list(itertools.islice(root.rglob('slice_*.png'), 10))\n",
        "    print('[INSPECT] Found any slice_*.png samples (up to 10):', len(any_pngs))\n",
        "    for p in any_pngs:\n",
        "        print('   ', p)\n",
        "else:\n",
        "    print('[INSPECT] root not found; check extraction path names.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0233b6b8-8955-45ca-8e80-b8a8d0258951",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Kick off caching for train and test using discovered roots\n",
        "print('[RUN] build_train_test_cache start')\n",
        "build_train_test_cache(train_out='cache/train', test_out='cache/test', log_every=300)\n",
        "print('[RUN] build_train_test_cache done')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RUN] build_train_test_cache start\n[ORCH] Building train cache...\n[CACHE] (0/31696) skip exists cache/train/case77_day20_slice_0001.npz\n[CACHE] (300/31696) skip exists cache/train/case77_day18_slice_0013.npz\n[CACHE] (600/31696) skip exists cache/train/case133_day25_slice_0025.npz\n[CACHE] (900/31696) skip exists cache/train/case129_day20_slice_0037.npz\n[CACHE] (1200/31696) skip exists cache/train/case129_day24_slice_0049.npz\n[CACHE] (1500/31696) skip exists cache/train/case130_day0_slice_0061.npz\n[CACHE] (1800/31696) skip exists cache/train/case130_day22_slice_0073.npz\n[CACHE] (2100/31696) skip exists cache/train/case88_day36_slice_0085.npz\n[CACHE] (2400/31696) skip exists cache/train/case44_day0_slice_0097.npz\n[CACHE] (2700/31696) skip exists cache/train/case44_day19_slice_0109.npz\n[CACHE] (3000/31696) skip exists cache/train/case145_day0_slice_0121.npz\n[CACHE] (3300/31696) skip exists cache/train/case15_day20_slice_0133.npz\n[CACHE] (3600/31696) skip exists cache/train/case42_day17_slice_0001.npz\n[CACHE] (3900/31696) skip exists cache/train/case66_day0_slice_0013.npz\n[CACHE] (4200/31696) skip exists cache/train/case66_day36_slice_0025.npz\n[CACHE] (4500/31696) skip exists cache/train/case142_day16_slice_0037.npz\n[CACHE] (4800/31696) skip exists cache/train/case142_day14_slice_0049.npz\n[CACHE] (5100/31696) skip exists cache/train/case63_day22_slice_0061.npz\n[CACHE] (5400/31696) skip exists cache/train/case63_day0_slice_0073.npz\n[CACHE] (5700/31696) skip exists cache/train/case102_day0_slice_0085.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] (6000/31696) skip exists cache/train/case65_day28_slice_0097.npz\n[CACHE] (6300/31696) skip exists cache/train/case65_day0_slice_0109.npz\n[CACHE] (6600/31696) skip exists cache/train/case122_day18_slice_0121.npz\n[CACHE] (6900/31696) skip exists cache/train/case122_day0_slice_0133.npz\n[CACHE] (7200/31696) skip exists cache/train/case125_day0_slice_0001.npz\n[CACHE] (7500/31696) skip exists cache/train/case117_day0_slice_0077.npz\n[CACHE] (7800/31696) skip exists cache/train/case140_day10_slice_0073.npz\n[CACHE] (8100/31696) skip exists cache/train/case134_day22_slice_0085.npz\n[CACHE] (8400/31696) skip exists cache/train/case134_day21_slice_0097.npz\n[CACHE] (8700/31696) skip exists cache/train/case9_day20_slice_0109.npz\n[CACHE] (9000/31696) skip exists cache/train/case113_day19_slice_0121.npz\n[CACHE] (9300/31696) skip exists cache/train/case113_day16_slice_0133.npz\n[CACHE] (9600/31696) skip exists cache/train/case90_day29_slice_0001.npz\n[CACHE] (9900/31696) skip exists cache/train/case49_day13_slice_0013.npz\n[CACHE] (10200/31696) skip exists cache/train/case49_day15_slice_0025.npz\n[CACHE] (10500/31696) skip exists cache/train/case19_day14_slice_0037.npz\n[CACHE] (10800/31696) skip exists cache/train/case19_day0_slice_0049.npz\n[CACHE] (11100/31696) skip exists cache/train/case6_day0_slice_0061.npz\n[CACHE] (11400/31696) skip exists cache/train/case67_day0_slice_0073.npz\n[CACHE] (11700/31696) skip exists cache/train/case67_day12_slice_0085.npz\n[CACHE] (12000/31696) skip exists cache/train/case154_day0_slice_0097.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] (12300/31696) skip exists cache/train/case154_day16_slice_0109.npz\n[CACHE] (12600/31696) skip exists cache/train/case135_day0_slice_0121.npz\n[CACHE] (12900/31696) skip exists cache/train/case84_day23_slice_0133.npz\n[CACHE] (13200/31696) skip exists cache/train/case147_day0_slice_0001.npz\n[CACHE] (13500/31696) skip exists cache/train/case147_day14_slice_0013.npz\n[CACHE] (13800/31696) skip exists cache/train/case101_day20_slice_0025.npz\n[CACHE] (14100/31696) skip exists cache/train/case101_day26_slice_0037.npz\n[CACHE] (14400/31696) skip exists cache/train/case7_day19_slice_0049.npz\n[CACHE] (14700/31696) skip exists cache/train/case119_day0_slice_0061.npz\n[CACHE] (15000/31696) skip exists cache/train/case119_day19_slice_0073.npz\n[CACHE] (15300/31696) skip exists cache/train/case32_day18_slice_0085.npz\n[CACHE] (15600/31696) skip exists cache/train/case32_day0_slice_0097.npz\n[CACHE] (15900/31696) skip exists cache/train/case24_day0_slice_0109.npz\n[CACHE] (16200/31696) skip exists cache/train/case24_day24_slice_0121.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 16500/31696 done in 0.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 16800/31696 done in 0.6 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 17100/31696 done in 1.1 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 17400/31696 done in 1.5 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 17700/31696 done in 2.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 18000/31696 done in 2.4 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 18300/31696 done in 2.8 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 18600/31696 done in 3.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 18900/31696 done in 3.8 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 19200/31696 done in 4.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 19500/31696 done in 4.7 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 19800/31696 done in 5.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 20100/31696 done in 5.6 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 20400/31696 done in 6.1 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 20700/31696 done in 6.5 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 21000/31696 done in 7.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 21300/31696 done in 7.4 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 21600/31696 done in 7.8 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 21900/31696 done in 8.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 22200/31696 done in 8.7 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 22500/31696 done in 9.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 22800/31696 done in 9.6 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 23100/31696 done in 10.1 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 23400/31696 done in 10.5 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 23700/31696 done in 11.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 24000/31696 done in 11.4 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 24300/31696 done in 11.9 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 24600/31696 done in 12.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 24900/31696 done in 12.8 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 25200/31696 done in 13.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 25500/31696 done in 13.7 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 25800/31696 done in 14.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 26100/31696 done in 14.7 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 26400/31696 done in 15.1 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 26700/31696 done in 15.6 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 27000/31696 done in 16.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 27300/31696 done in 16.5 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 27600/31696 done in 16.9 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 27900/31696 done in 17.4 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 28200/31696 done in 17.8 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 28500/31696 done in 18.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 28800/31696 done in 18.8 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 29100/31696 done in 19.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 29400/31696 done in 19.7 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 29700/31696 done in 20.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 30000/31696 done in 20.7 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 30300/31696 done in 21.1 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 30600/31696 done in 21.6 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 30900/31696 done in 22.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 31200/31696 done in 22.5 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 31500/31696 done in 22.9 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] Done: cache/train\n[ORCH] Train cache done in 23.2m\n[ORCH] Building test cache...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 300/6800 done in 0.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 600/6800 done in 0.6 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 900/6800 done in 0.9 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 1200/6800 done in 1.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 1500/6800 done in 1.5 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 1800/6800 done in 1.9 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 2100/6800 done in 2.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 2400/6800 done in 2.5 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 2700/6800 done in 2.8 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 3000/6800 done in 3.1 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 3300/6800 done in 3.4 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 3600/6800 done in 3.7 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 3900/6800 done in 4.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 4200/6800 done in 4.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 4500/6800 done in 4.7 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 4800/6800 done in 5.0 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 5100/6800 done in 5.3 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 5400/6800 done in 5.6 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 5700/6800 done in 5.9 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 6000/6800 done in 6.2 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 6300/6800 done in 6.5 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] 6600/6800 done in 6.8 min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CACHE] Done: cache/test\n[ORCH] Test cache done in 7.0m\n[RUN] build_train_test_cache done\n"
          ]
        }
      ]
    },
    {
      "id": "79de3124-5d02-4de9-947f-0c2c4fa013ac",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Start full 5-fold training now (384, bs=10); cache not required\n",
        "print('[RUN] Starting 5-fold training @384, bs=10, epochs=40')\n",
        "train_all_folds(epochs=40, batch_size=10, device='cuda')\n",
        "print('[RUN] Training complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "720d78f6-f57a-43b5-b372-5e488eae2b71",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity-run a single fold with 1 epoch to confirm training stability before full 5-fold\n",
        "import gc, torch\n",
        "print('[RUN] Sanity training fold 0 for 1 epoch @384, bs=4, workers=0')\n",
        "gc.collect()\n",
        "try:\n",
        "    torch.cuda.empty_cache()\n",
        "except Exception:\n",
        "    pass\n",
        "train_one_fold(0, epochs=1, batch_size=4, num_workers=0, device='cuda')\n",
        "print('[RUN] Sanity fold 0 done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b4ef3249-f34a-44fa-9202-749c7c1353fc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Diagnostic: isolate SMP model build and single forward to find kernel-death root cause\n",
        "import torch, gc, time\n",
        "from torch.utils.data import DataLoader\n",
        "print('[DIAG] CUDA is_available:', torch.cuda.is_available(), 'Device:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'cpu')\n",
        "try:\n",
        "    t0 = time.time()\n",
        "    # Force garbage collection and empty cache before heavy import\n",
        "    gc.collect();\n",
        "    torch.cuda.empty_cache()\n",
        "    # Attempt lazy import + model init\n",
        "    from segmentation_models_pytorch import UnetPlusPlus\n",
        "    print('[DIAG] SMP imported OK in', f\"{time.time()-t0:.2f}s\")\n",
        "    model = UnetPlusPlus(encoder_name='tf_efficientnet_b3', encoder_weights=None, in_channels=5, classes=3, activation=None).cuda()\n",
        "    n_params = sum(p.numel() for p in model.parameters())\n",
        "    print('[DIAG] Model built. Params:', n_params)\n",
        "    # Build a tiny loader (num_workers=0) and run 1 forward pass\n",
        "    folds = pd.read_csv('folds.csv')\n",
        "    va_ids = folds[folds['fold']==0][['id','case','day','slice']].reset_index(drop=True).iloc[:4]\n",
        "    ds = UWGITractDataset(va_ids, train_df=train_df, roots=TRAIN_IMG_ROOTS, mode='train', aug=get_valid_aug())\n",
        "    dl = DataLoader(ds, batch_size=2, shuffle=False, num_workers=0, pin_memory=True)\n",
        "    xb, yb, _ = next(iter(dl))\n",
        "    xb = xb.cuda(non_blocking=True)\n",
        "    with torch.cuda.amp.autocast(enabled=True):\n",
        "        yhat = model(xb)\n",
        "    print('[DIAG] Forward OK. logits shape:', tuple(yhat.shape))\n",
        "    del model, xb, yhat; gc.collect(); torch.cuda.empty_cache()\n",
        "    print('[DIAG DONE]')\n",
        "except Exception as e:\n",
        "    print('[DIAG] Exception:', repr(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "aa9caf96-b542-47af-a008-22827befecb6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lightweight fallback UNet (no SMP/timm) for stability\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class TinyUNet(nn.Module):\n",
        "    def __init__(self, in_ch=5, num_classes=3, base=32):\n",
        "        super().__init__()\n",
        "        self.enc1 = ConvBlock(in_ch, base)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = ConvBlock(base, base*2)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = ConvBlock(base*2, base*4)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = ConvBlock(base*4, base*8)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "        self.bottleneck = ConvBlock(base*8, base*16)\n",
        "        self.up4 = nn.ConvTranspose2d(base*16, base*8, 2, stride=2)\n",
        "        self.dec4 = ConvBlock(base*16, base*8)\n",
        "        self.up3 = nn.ConvTranspose2d(base*8, base*4, 2, stride=2)\n",
        "        self.dec3 = ConvBlock(base*8, base*4)\n",
        "        self.up2 = nn.ConvTranspose2d(base*4, base*2, 2, stride=2)\n",
        "        self.dec2 = ConvBlock(base*4, base*2)\n",
        "        self.up1 = nn.ConvTranspose2d(base*2, base, 2, stride=2)\n",
        "        self.dec1 = ConvBlock(base*2, base)\n",
        "        self.head = nn.Conv2d(base, num_classes, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        e4 = self.enc4(self.pool3(e3))\n",
        "        b = self.bottleneck(self.pool4(e4))\n",
        "        d4 = self.up4(b)\n",
        "        d4 = torch.cat([d4, e4], dim=1)\n",
        "        d4 = self.dec4(d4)\n",
        "        d3 = self.up3(d4)\n",
        "        d3 = torch.cat([d3, e3], dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = torch.cat([d2, e2], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = torch.cat([d1, e1], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "        return self.head(d1)\n",
        "\n",
        "print('[FALLBACK MODEL READY] TinyUNet(in_ch=5, classes=3) defined. Modify build_model_b3 to use TinyUNet if SMP is unstable.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "ce8fff87-4d45-4127-b1f7-24f0ce3aa2b0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Diagnostic: inspect first training batch shapes and aligned shapes + forward/loss check\n",
        "import torch\n",
        "print('[DIAG-BATCH] Building loaders for fold 0 ...', flush=True)\n",
        "train_dl, valid_dl, _ = make_loaders(0, batch_size=2, num_workers=2)\n",
        "batch = next(iter(train_dl))\n",
        "imgs, masks, ids = batch\n",
        "print('[DIAG-BATCH] Raw shapes imgs/masks:', tuple(imgs.shape), tuple(masks.shape))\n",
        "\n",
        "# Local align helper (in case global not defined)\n",
        "def _align_logits_targets_local(logits, masks):\n",
        "    if logits.dim()==4 and logits.shape[1] not in (1,3) and logits.shape[-1] in (1,3):\n",
        "        logits = logits.permute(0,3,1,2).contiguous()\n",
        "    if masks.dim()==4 and masks.shape[1] not in (1,3) and masks.shape[-1] in (1,3):\n",
        "        masks = masks.permute(0,3,1,2).contiguous()\n",
        "    if logits.shape != masks.shape:\n",
        "        if logits.dim()==4 and masks.dim()==4 and logits.shape[-1]==3 and masks.shape[1]==3:\n",
        "            logits = logits.permute(0,3,1,2).contiguous()\n",
        "        elif logits.dim()==4 and masks.dim()==4 and masks.shape[-1]==3 and logits.shape[1]==3:\n",
        "            masks = masks.permute(0,3,1,2).contiguous()\n",
        "    return logits, masks\n",
        "\n",
        "# Dummy logits in NCHW\n",
        "logits_dummy = torch.zeros((imgs.size(0), 3, imgs.size(-2), imgs.size(-1)))\n",
        "try:\n",
        "    logits_a, masks_a = _align_logits_targets_local(logits_dummy, masks)\n",
        "    print('[DIAG-BATCH] After local align -> logits/masks:', tuple(logits_a.shape), tuple(masks_a.shape))\n",
        "except Exception as e:\n",
        "    print('[DIAG-BATCH] Align error:', repr(e))\n",
        "\n",
        "# Model forward + loss check\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = build_model_b3(device=device)\n",
        "imgs_dev = imgs.to(device)\n",
        "masks_dev = masks.to(device)\n",
        "with torch.no_grad():\n",
        "    logits = model(imgs_dev)\n",
        "print('[DIAG-BATCH] Model logits shape:', tuple(logits.shape))\n",
        "try:\n",
        "    from math import isnan\n",
        "    lf = ComboLoss()\n",
        "    lg, mg = _align_logits_targets_local(logits, masks_dev)\n",
        "    print('[DIAG-BATCH] Pre-loss shapes lg/mg:', tuple(lg.shape), tuple(mg.shape))\n",
        "    loss = lf(lg, mg)\n",
        "    print('[DIAG-BATCH] Loss OK:', float(loss))\n",
        "except Exception as e:\n",
        "    print('[DIAG-BATCH] Loss error:', repr(e))\n",
        "print('[DIAG-BATCH] Done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "eb5b22bf-900d-4d84-a82d-a2c2b527d2ab",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# DIAG: single-batch train step (no AMP) to isolate kernel death\n",
        "import torch, gc, time, pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "print('[DIAG-TRAINSTEP] Start')\n",
        "gc.collect()\n",
        "try:\n",
        "    torch.cuda.empty_cache()\n",
        "except Exception:\n",
        "    pass\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('[DIAG-TRAINSTEP] CUDA avail:', torch.cuda.is_available(), 'device:', device)\n",
        "try:\n",
        "    # Build a tiny dataset/loader directly (avoid sampler dependency)\n",
        "    folds = pd.read_csv('folds.csv')\n",
        "    tr_ids = folds[folds['fold']!=0][['id','case','day','slice']].reset_index(drop=True).iloc[:8]\n",
        "    train_ds = UWGITractDataset(tr_ids, train_df=train_df, roots=TRAIN_IMG_ROOTS, mode='train', aug=get_valid_aug())\n",
        "    train_dl = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=0, pin_memory=True)\n",
        "    batch = next(iter(train_dl))\n",
        "    imgs, masks, ids = batch\n",
        "    imgs = imgs.to(device, non_blocking=True)\n",
        "    masks = masks.to(device, non_blocking=True)\n",
        "    # Model + loss + opt\n",
        "    model = build_model_b3(device=device)\n",
        "    loss_fn = ComboLoss(bce_weight=0.5, tv_weight=0.5, tv_alpha=0.7, tv_beta=0.3, class_weights=(1.1,1.45,1.0))\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    # One train step, AMP disabled\n",
        "    model.train()\n",
        "    t0 = time.time()\n",
        "    logits = model(imgs)\n",
        "    logits, masks = _align_logits_targets(logits, masks)\n",
        "    loss = loss_fn(logits, masks)\n",
        "    print('[DIAG-TRAINSTEP] fwd ok, loss=', float(loss))\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    opt.step(); opt.zero_grad(set_to_none=True)\n",
        "    print('[DIAG-TRAINSTEP] backward/step ok, elapsed', f\"{time.time()-t0:.2f}s\")\n",
        "    del model, imgs, masks, logits, loss; gc.collect();\n",
        "    try:\n",
        "        torch.cuda.empty_cache()\n",
        "    except Exception:\n",
        "        pass\n",
        "    print('[DIAG-TRAINSTEP] Done')\n",
        "except Exception as e:\n",
        "    print('[DIAG-TRAINSTEP] Exception:', repr(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "465c2e81-fa93-49ad-8a5e-2748bbfdc26c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Override: use TinyUNet for stability (avoids SMP-related kernel deaths)\n",
        "import gc, torch\n",
        "\n",
        "def build_model_b3(device='cuda'):\n",
        "    gc.collect()\n",
        "    try:\n",
        "        torch.cuda.empty_cache()\n",
        "    except Exception:\n",
        "        pass\n",
        "    # TinyUNet defined in Cell 26\n",
        "    model = TinyUNet(in_ch=5, num_classes=3, base=32)\n",
        "    return model.to(device)\n",
        "\n",
        "print('[MODEL OVERRIDE] build_model_b3 -> TinyUNet(in_ch=5, classes=3)')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}