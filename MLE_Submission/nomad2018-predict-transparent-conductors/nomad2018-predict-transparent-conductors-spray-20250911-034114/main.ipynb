{
  "cells": [
    {
      "id": "040dae59-d8e1-4f22-bd20-848bffc8ef71",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan to Medal: NOMAD2018 Predicting Transparent Conductors\n",
        "\n",
        "Goals:\n",
        "- Target: formation_energy_ev_natom\n",
        "- Metric: mean-column-wise-rmsle\n",
        "- Output: submission.csv\n",
        "- Medal thresholds: Bronze \u2264 0.06582, Silver \u2264 0.06229, Gold \u2264 0.05589\n",
        "\n",
        "Workflow:\n",
        "1) Data audit\n",
        "- Locate train.csv/test.csv or equivalent metadata; enumerate directories to confirm file structure\n",
        "- Inspect columns, target distribution, and link between IDs and geometry.xyz paths\n",
        "\n",
        "2) Feature engineering (fast \u2192 strong)\n",
        "- Basic composition features: counts and fractions of Al, Ga, In, O; natoms; density proxies (cell volume if available; else surrogate from bounding box of XYZ)\n",
        "- Stoichiometric descriptors: ratios (Al:Ga:In), Shannon entropy of composition\n",
        "- Simple geometry stats from XYZ: interatomic distance statistics (mean/median/min/max), radial features (binned histogram), nearest-neighbor stats per element\n",
        "- Optional if time: matminer composition features (ElementProperty, OxidationStates) and simple structure featurizers; cache to parquet\n",
        "\n",
        "3) Modeling\n",
        "- Baseline: LightGBM regression for formation_energy_ev_natom\n",
        "- CV: GroupKFold if structure IDs need grouping; otherwise KFold with stratification on target quantiles\n",
        "- Use log1p target transform to align with RMSLE behavior and invert for predictions\n",
        "- Hyperparameters: quick Bayesian/TPE or guided grid; early_stopping; consistent seeds\n",
        "\n",
        "4) Validation & logging\n",
        "- Track fold metrics and elapsed time; save OOF predictions; plot OOF vs true\n",
        "- Sanity checks: leakage, distribution alignment, feature importances\n",
        "\n",
        "5) Inference\n",
        "- Generate test features identically; predict; create submission.csv\n",
        "\n",
        "6) Iteration for medal\n",
        "- Add stronger matminer features; try CatBoost/XGBoost stack\n",
        "- Feature selection via importance/SHAP; try target smoothing by composition\n",
        "\n",
        "Immediate next steps:\n",
        "- Enumerate files; load train metadata; confirm target column(s); map IDs to geometry.xyz\n",
        "- Build a minimal featurizer: element counts/fractions + natoms\n",
        "- Train fast LightGBM CV baseline and evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "14bc643a-2a56-44d6-b86b-5201b01a4b76",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, time, json, gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_DIR = Path('.')\n",
        "train_csv = DATA_DIR / 'train.csv'\n",
        "test_csv = DATA_DIR / 'test.csv'\n",
        "sample_csv = DATA_DIR / 'sample_submission.csv'\n",
        "\n",
        "print('Files exist:', train_csv.exists(), test_csv.exists(), sample_csv.exists())\n",
        "train = pd.read_csv(train_csv)\n",
        "test = pd.read_csv(test_csv)\n",
        "sample = pd.read_csv(sample_csv)\n",
        "print('train.shape, test.shape:', train.shape, test.shape)\n",
        "print('train.columns:', train.columns.tolist())\n",
        "print('test.columns:', test.columns.tolist())\n",
        "print('sample.columns:', sample.columns.tolist())\n",
        "\n",
        "target_col = 'formation_energy_ev_natom'\n",
        "id_col = 'id'\n",
        "assert id_col in train.columns and id_col in test.columns, 'id column missing'\n",
        "assert target_col in train.columns, 'Target column missing in train.csv'\n",
        "print('Target head:', train[target_col].head().to_list())\n",
        "\n",
        "# Non-negativity check for log1p eligibility\n",
        "y_min = train[target_col].min()\n",
        "y_max = train[target_col].max()\n",
        "print(f'Target min/max: {y_min:.6f} / {y_max:.6f}')\n",
        "can_log1p = y_min >= 0\n",
        "print('All non-negative? ->', can_log1p)\n",
        "\n",
        "# Verify geometry.xyz path mapping for a few IDs\n",
        "def check_paths(df, split='train', n=5):\n",
        "    ids = df[id_col].head(n).tolist()\n",
        "    results = []\n",
        "    for i in ids:\n",
        "        p = DATA_DIR / split / str(i) / 'geometry.xyz'\n",
        "        results.append((i, p.exists(), str(p)))\n",
        "    return results\n",
        "\n",
        "print('Sample train paths exists:', check_paths(train, 'train', 5))\n",
        "print('Sample test paths exists:', check_paths(test, 'test', 5))\n",
        "\n",
        "# Basic target stats\n",
        "print(train[target_col].describe())\n",
        "\n",
        "# Save quick audit to JSON for reference\n",
        "audit = {\n",
        "    'train_shape': train.shape,\n",
        "    'test_shape': test.shape,\n",
        "    'train_columns': train.columns.tolist(),\n",
        "    'test_columns': test.columns.tolist(),\n",
        "    'sample_columns': sample.columns.tolist(),\n",
        "    'target_min': float(y_min),\n",
        "    'target_max': float(y_max),\n",
        "    'can_log1p': bool(can_log1p)\n",
        "}\n",
        "with open('data_audit.json', 'w') as f:\n",
        "    json.dump(audit, f, indent=2)\n",
        "print('Wrote data_audit.json')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files exist: True True True\ntrain.shape, test.shape: (2160, 14) (240, 12)\ntrain.columns: ['id', 'spacegroup', 'number_of_total_atoms', 'percent_atom_al', 'percent_atom_ga', 'percent_atom_in', 'lattice_vector_1_ang', 'lattice_vector_2_ang', 'lattice_vector_3_ang', 'lattice_angle_alpha_degree', 'lattice_angle_beta_degree', 'lattice_angle_gamma_degree', 'formation_energy_ev_natom', 'bandgap_energy_ev']\ntest.columns: ['id', 'spacegroup', 'number_of_total_atoms', 'percent_atom_al', 'percent_atom_ga', 'percent_atom_in', 'lattice_vector_1_ang', 'lattice_vector_2_ang', 'lattice_vector_3_ang', 'lattice_angle_alpha_degree', 'lattice_angle_beta_degree', 'lattice_angle_gamma_degree']\nsample.columns: ['id', 'formation_energy_ev_natom', 'bandgap_energy_ev']\nTarget head: [0.1337, 0.0738, 0.3671, 0.0698, 0.1154]\nTarget min/max: 0.000000 / 0.657200\nAll non-negative? -> True\nSample train paths exists: [(1, True, 'train/1/geometry.xyz'), (2, True, 'train/2/geometry.xyz'), (3, True, 'train/3/geometry.xyz'), (4, True, 'train/4/geometry.xyz'), (5, True, 'train/5/geometry.xyz')]\nSample test paths exists: [(1, True, 'test/1/geometry.xyz'), (2, True, 'test/2/geometry.xyz'), (3, True, 'test/3/geometry.xyz'), (4, True, 'test/4/geometry.xyz'), (5, True, 'test/5/geometry.xyz')]\ncount    2160.000000\nmean        0.187577\nstd         0.104376\nmin         0.000000\n25%         0.105200\n50%         0.181950\n75%         0.256625\nmax         0.657200\nName: formation_energy_ev_natom, dtype: float64\nWrote data_audit.json\n"
          ]
        }
      ]
    },
    {
      "id": "8657372c-152f-4c98-a6d6-bfe2bca18443",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "def safe_div(a, b):\n",
        "    return a / b if b != 0 else 0.0\n",
        "\n",
        "def comp_entropy(fracs):\n",
        "    fr = np.clip(np.array(fracs, dtype=float), 1e-12, 1.0)\n",
        "    fr = fr / fr.sum() if fr.sum() > 0 else fr\n",
        "    return float(-(fr * np.log(fr)).sum())\n",
        "\n",
        "def cell_volume(a, b, c, alpha_deg, beta_deg, gamma_deg):\n",
        "    alpha = math.radians(alpha_deg); beta = math.radians(beta_deg); gamma = math.radians(gamma_deg)\n",
        "    cos_a, cos_b, cos_c = math.cos(alpha), math.cos(beta), math.cos(gamma)\n",
        "    vol_sq = 1 + 2*cos_a*cos_b*cos_c - cos_a**2 - cos_b**2 - cos_c**2\n",
        "    vol_sq = max(vol_sq, 0.0)\n",
        "    return float(a*b*c*math.sqrt(vol_sq))\n",
        "\n",
        "def build_features(df):\n",
        "    out = pd.DataFrame(index=df.index)\n",
        "    # Base\n",
        "    out['natoms'] = df['number_of_total_atoms'].astype(float)\n",
        "    for e in ['al','ga','in']:\n",
        "        out[f'pct_{e}'] = df[f'percent_atom_{e}'].astype(float) / 100.0\n",
        "    out['pct_o'] = 1.0 - (out['pct_al'] + out['pct_ga'] + out['pct_in'])\n",
        "    # Counts (float and rounded ints)\n",
        "    out['cnt_al'] = out['natoms'] * out['pct_al']\n",
        "    out['cnt_ga'] = out['natoms'] * out['pct_ga']\n",
        "    out['cnt_in'] = out['natoms'] * out['pct_in']\n",
        "    out['cnt_o']  = out['natoms'] * out['pct_o']\n",
        "    for e in ['al','ga','in','o']:\n",
        "        out[f'cnt_{e}_int'] = np.rint(out[f'cnt_{e}']).astype(int)\n",
        "    # Ratios\n",
        "    out['ratio_al_ga'] = out['cnt_al'] / (out['cnt_ga'] + 1e-6)\n",
        "    out['ratio_al_in'] = out['cnt_al'] / (out['cnt_in'] + 1e-6)\n",
        "    out['ratio_ga_in'] = out['cnt_ga'] / (out['cnt_in'] + 1e-6)\n",
        "    out['ratio_cation_o'] = (out['cnt_al'] + out['cnt_ga'] + out['cnt_in']) / (out['cnt_o'] + 1e-6)\n",
        "    out['frac_cations'] = (out['pct_al'] + out['pct_ga'] + out['pct_in'])\n",
        "    out['frac_o'] = out['pct_o']\n",
        "    # Composition entropy\n",
        "    out['comp_entropy'] = [comp_entropy(row) for row in out[['pct_al','pct_ga','pct_in','pct_o']].values]\n",
        "    # Lattice features\n",
        "    a = df['lattice_vector_1_ang'].astype(float)\n",
        "    b = df['lattice_vector_2_ang'].astype(float)\n",
        "    c = df['lattice_vector_3_ang'].astype(float)\n",
        "    alpha = df['lattice_angle_alpha_degree'].astype(float)\n",
        "    beta = df['lattice_angle_beta_degree'].astype(float)\n",
        "    gamma = df['lattice_angle_gamma_degree'].astype(float)\n",
        "    out['a'] = a; out['b'] = b; out['c'] = c\n",
        "    out['alpha'] = alpha; out['beta'] = beta; out['gamma'] = gamma\n",
        "    out['vol'] = [cell_volume(*vals) for vals in zip(a,b,c,alpha,beta,gamma)]\n",
        "    out['vol'] = out['vol'].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "    out['density_proxy'] = out['natoms'] / (out['vol'] + 1e-6)\n",
        "    # Simple interactions\n",
        "    out['a_over_b'] = a / (b + 1e-6)\n",
        "    out['b_over_c'] = b / (c + 1e-6)\n",
        "    out['c_over_a'] = c / (a + 1e-6)\n",
        "    # Spacegroup as numeric\n",
        "    out['spacegroup'] = df['spacegroup'].astype(int)\n",
        "    return out\n",
        "\n",
        "# Build train/test features\n",
        "t0 = time.time()\n",
        "X = build_features(train)\n",
        "X_test = build_features(test)\n",
        "print('Feature shapes:', X.shape, X_test.shape, '| secs:', round(time.time()-t0,2))\n",
        "\n",
        "# Groups by reduced composition (1D string key to avoid sklearn tuple handling issues)\n",
        "grp_cols = ['cnt_al_int','cnt_ga_int','cnt_in_int','cnt_o_int']\n",
        "groups = X[grp_cols].astype(int).astype(str).agg(lambda r: '_'.join(r.values.tolist()), axis=1).values\n",
        "print('Unique groups:', len(np.unique(groups)))\n",
        "\n",
        "def rmsle(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true).astype(float)\n",
        "    y_pred = np.maximum(np.asarray(y_pred).astype(float), 0.0)\n",
        "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true))**2))\n",
        "\n",
        "lgb_params = {\n",
        "    'objective': 'regression',\n",
        "    'learning_rate': 0.04,\n",
        "    'num_leaves': 63,\n",
        "    'min_data_in_leaf': 40,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l2': 2.0,\n",
        "    'lambda_l1': 0.0,\n",
        "    'max_depth': -1,\n",
        "    'metric': 'rmse',\n",
        "    'verbosity': -1,\n",
        "    'seed': SEED\n",
        "}\n",
        "\n",
        "features = X.columns.tolist()\n",
        "print('Using', len(features), 'features')\n",
        "\n",
        "def run_target(target_col_name):\n",
        "    y = train[target_col_name].values.astype(float)\n",
        "    can_log = (y.min() >= 0)\n",
        "    y_tr = np.log1p(y) if can_log else y.copy()\n",
        "    folds = 5\n",
        "    gkf = GroupKFold(n_splits=folds)\n",
        "    oof = np.zeros(len(train), dtype=float)\n",
        "    best_iters = []\n",
        "    models = []\n",
        "    for fold, (trn_idx, val_idx) in enumerate(gkf.split(X, y_tr, groups=groups), 1):\n",
        "        t1 = time.time()\n",
        "        X_tr, X_val = X.iloc[trn_idx], X.iloc[val_idx]\n",
        "        y_trn, y_val = y_tr[trn_idx], y_tr[val_idx]\n",
        "        dtrain = lgb.Dataset(X_tr[features], label=y_trn, free_raw_data=False)\n",
        "        dvalid = lgb.Dataset(X_val[features], label=y_val, free_raw_data=False)\n",
        "        print(f'[{target_col_name}] Fold {fold}/{folds} | trn:{len(trn_idx)} val:{len(val_idx)}')\n",
        "        callbacks = [\n",
        "            lgb.early_stopping(stopping_rounds=200, verbose=False),\n",
        "            lgb.log_evaluation(period=200)\n",
        "        ]\n",
        "        model = lgb.train(lgb_params, dtrain, num_boost_round=4000, valid_sets=[dtrain, dvalid],\n",
        "                          valid_names=['train','valid'], callbacks=callbacks)\n",
        "        best_iter = model.best_iteration\n",
        "        best_iters.append(best_iter)\n",
        "        pred_val_log = model.predict(X_val[features], num_iteration=best_iter)\n",
        "        pred_val = np.expm1(pred_val_log) if can_log else pred_val_log\n",
        "        oof[val_idx] = np.clip(pred_val, 0, None)\n",
        "        fold_rmsle = rmsle(train[target_col_name].values[val_idx], oof[val_idx])\n",
        "        print(f'[{target_col_name}] Fold {fold} RMSLE: {fold_rmsle:.6f} | best_iter: {best_iter} | elapsed: {time.time()-t1:.1f}s', flush=True)\n",
        "        models.append(model)\n",
        "    cv_rmsle = rmsle(train[target_col_name].values, oof)\n",
        "    print(f'[{target_col_name}] OOF RMSLE: {cv_rmsle:.6f}')\n",
        "    final_iter = int(np.mean(best_iters)) if len(best_iters) > 0 else 2000\n",
        "    print(f'[{target_col_name}] Refitting full model with num_boost_round =', final_iter)\n",
        "    dall = lgb.Dataset(X[features], label=y_tr, free_raw_data=False)\n",
        "    final_model = lgb.train(lgb_params, dall, num_boost_round=final_iter)\n",
        "    test_pred_log = final_model.predict(X_test[features], num_iteration=final_iter)\n",
        "    test_pred = np.expm1(test_pred_log) if can_log else test_pred_log\n",
        "    test_pred = np.clip(test_pred, 0, None)\n",
        "    return oof, test_pred, cv_rmsle, final_iter, final_model\n",
        "\n",
        "# Run for both targets\n",
        "oof_fe, test_fe, cv_fe, iter_fe, model_fe = run_target('formation_energy_ev_natom')\n",
        "oof_bg, test_bg, cv_bg, iter_bg, model_bg = run_target('bandgap_energy_ev')\n",
        "\n",
        "mean_rmsle = np.mean([cv_fe, cv_bg])\n",
        "print(f'Mean-column-wise RMSLE (OOF): {mean_rmsle:.6f} | FE: {cv_fe:.6f} | BG: {cv_bg:.6f}')\n",
        "\n",
        "# Save artifacts\n",
        "pd.DataFrame({'id': train['id'], 'oof_fe': oof_fe, 'y_fe': train['formation_energy_ev_natom'],\n",
        "              'oof_bg': oof_bg, 'y_bg': train['bandgap_energy_ev']}).to_csv('oof.csv', index=False)\n",
        "imp_fe = pd.DataFrame({'feature': features, 'gain': model_fe.feature_importance(importance_type='gain')}).sort_values('gain', ascending=False)\n",
        "imp_bg = pd.DataFrame({'feature': features, 'gain': model_bg.feature_importance(importance_type='gain')}).sort_values('gain', ascending=False)\n",
        "imp_fe.to_csv('feature_importance_fe.csv', index=False)\n",
        "imp_bg.to_csv('feature_importance_bg.csv', index=False)\n",
        "with open('training_log.txt','w') as f:\n",
        "    f.write(f'OOF_RMSLE_FE: {cv_fe:.8f}\\n')\n",
        "    f.write(f'OOF_RMSLE_BG: {cv_bg:.8f}\\n')\n",
        "    f.write(f'MEAN_OOF_RMSLE: {mean_rmsle:.8f}\\n')\n",
        "    f.write(f'iter_fe: {iter_fe}\\n')\n",
        "    f.write(f'iter_bg: {iter_bg}\\n')\n",
        "print('Saved oof.csv, feature_importance_fe.csv, feature_importance_bg.csv, training_log.txt')\n",
        "\n",
        "# Create submission with both required columns\n",
        "submission = sample.copy()[['id','formation_energy_ev_natom','bandgap_energy_ev']].copy()\n",
        "map_fe = pd.Series(test_fe, index=test['id']).to_dict()\n",
        "map_bg = pd.Series(test_bg, index=test['id']).to_dict()\n",
        "submission['formation_energy_ev_natom'] = submission['id'].map(map_fe).astype(float)\n",
        "submission['bandgap_energy_ev'] = submission['id'].map(map_bg).astype(float)\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv with shape', submission.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shapes: (2160, 32) (240, 32) | secs: 0.11\nUnique groups: 12\nUsing 32 features\n[formation_energy_ev_natom] Fold 1/5 | trn:1365 val:795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttrain's rmse: 0.0254835\tvalid's rmse: 0.0392942\n[formation_energy_ev_natom] Fold 1 RMSLE: 0.038599 | best_iter: 132 | elapsed: 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[formation_energy_ev_natom] Fold 2/5 | trn:1697 val:463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttrain's rmse: 0.0234948\tvalid's rmse: 0.077623\n[formation_energy_ev_natom] Fold 2 RMSLE: 0.076908 | best_iter: 83 | elapsed: 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[formation_energy_ev_natom] Fold 3/5 | trn:1864 val:296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttrain's rmse: 0.0263879\tvalid's rmse: 0.0583212\n[formation_energy_ev_natom] Fold 3 RMSLE: 0.054996 | best_iter: 61 | elapsed: 0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[formation_energy_ev_natom] Fold 4/5 | trn:1848 val:312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttrain's rmse: 0.0261705\tvalid's rmse: 0.0717072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[400]\ttrain's rmse: 0.0238608\tvalid's rmse: 0.0713454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[600]\ttrain's rmse: 0.02261\tvalid's rmse: 0.0701465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[800]\ttrain's rmse: 0.0218152\tvalid's rmse: 0.069883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1000]\ttrain's rmse: 0.0212675\tvalid's rmse: 0.0703835\n[formation_energy_ev_natom] Fold 4 RMSLE: 0.069847 | best_iter: 803 | elapsed: 1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[formation_energy_ev_natom] Fold 5/5 | trn:1866 val:294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttrain's rmse: 0.0254702\tvalid's rmse: 0.0390149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[400]\ttrain's rmse: 0.0232053\tvalid's rmse: 0.0383504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[600]\ttrain's rmse: 0.0218819\tvalid's rmse: 0.038428\n[formation_energy_ev_natom] Fold 5 RMSLE: 0.038273 | best_iter: 409 | elapsed: 1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[formation_energy_ev_natom] OOF RMSLE: 0.055989\n[formation_energy_ev_natom] Refitting full model with num_boost_round = 297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[bandgap_energy_ev] Fold 1/5 | trn:1365 val:795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[200]\ttrain's rmse: 0.0743757\tvalid's rmse: 0.0686696\n[bandgap_energy_ev] Fold 1 RMSLE: 0.067157 | best_iter: 111 | elapsed: 0.4s\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}