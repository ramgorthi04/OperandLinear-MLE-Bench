{
  "cells": [
    {
      "id": "6f8cdbb7-81b7-43d7-ab6a-4d080e39342d",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Denoising Dirty Documents \u2014 Plan and Experiment Log\n",
        "\n",
        "Objective\n",
        "- Competition: denoising-dirty-documents\n",
        "- Metric: RMSE on pixel intensities\n",
        "- Output: submission.csv with id,value pairs (ids are image_index_pixel for test set).\n",
        "- Non-negotiable rule: WIN A MEDAL.\n",
        "\n",
        "Performance Targets\n",
        "- Gold: RMSE \u2264 0.01794\n",
        "- Silver: RMSE \u2264 0.02609\n",
        "- Bronze: RMSE \u2264 0.04517\n",
        "\n",
        "Data\n",
        "- train/: noisy PNGs\n",
        "- train_cleaned/: clean PNGs (same filenames) for supervised validation\n",
        "- test/: noisy PNGs\n",
        "- sampleSubmission.csv: id,value format\n",
        "\n",
        "High-level Strategy\n",
        "1) Establish fast, strong classical denoising baselines that historically perform well on this comp:\n",
        "   - Median filtering (various kernel sizes)\n",
        "   - Bilateral filter\n",
        "   - Non-Local Means (fastNlMeans)\n",
        "   - Morphological open/close and tophat/blackhat with adaptive thresholds\n",
        "   - Simple background estimation via large-kernel median/gaussian and subtract/normalize\n",
        "2) Validate on train vs train_cleaned using per-image RMSE.\n",
        "3) Select per-image best method or learn a blending (linear regression) on the methods' outputs to minimize RMSE.\n",
        "4) Optionally refine with tuned parameters per-image (grid over kernel sizes, sigma values) with early stopping.\n",
        "5) Generate predictions for test and write submission.csv in correct order.\n",
        "\n",
        "Why classical first?\n",
        "- Fast, low-risk, strong on this dataset (text documents). Deep models add setup and time; we can add later if needed.\n",
        "\n",
        "Milestones (request expert review at each):\n",
        "A) Plan (this cell)\n",
        "B) Data loading + EDA\n",
        "C) Baseline methods implemented + CV on train\n",
        "D) Model selection/blending results\n",
        "E) Final test inference + submission\n",
        "\n",
        "Experiment Log\n",
        "- 00: Plan drafted. Next: implement loaders and quick RMSE evaluation for baseline filters.\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "9c45047a-b558-4284-9c60-a819c6c303a4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pip -q install opencv-python-headless"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "9bc3a743-e734-442e-990a-103b6ce071c0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fix OpenCV libGL issue by forcing headless build and removing conflicting builds\n",
        "%pip -q uninstall -y opencv-python opencv-contrib-python opencv-python-headless opencv-contrib-python-headless\n",
        "%pip -q install --no-cache-dir opencv-python-headless==4.9.0.80\n",
        "import cv2, sys\n",
        "print('cv2 version:', cv2.__version__)\n",
        "print('Python:', sys.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c62b63e9-ec10-4cc1-8152-0e22b8abe63d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import glob\n",
        "import csv\n",
        "from typing import Dict, Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from skimage import exposure, morphology, filters, restoration, util\n",
        "from scipy.ndimage import median_filter\n",
        "\n",
        "# Paths\n",
        "TRAIN_DIR = 'train'\n",
        "CLEAN_DIR = 'train_cleaned'\n",
        "TEST_DIR = 'test'\n",
        "SAMPLE_SUB = 'sampleSubmission.csv'\n",
        "SUBMISSION_OUT = 'submission.csv'\n",
        "\n",
        "# Utilities\n",
        "def read_gray_float(path: str) -> np.ndarray:\n",
        "    img = Image.open(path).convert('L')\n",
        "    arr = np.asarray(img, dtype=np.float32) / 255.0\n",
        "    return arr\n",
        "\n",
        "def to_uint8(img: np.ndarray) -> np.ndarray:\n",
        "    return np.clip(img * 255.0, 0, 255).astype(np.uint8)\n",
        "\n",
        "def rmse(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    return float(np.sqrt(np.mean((a - b) ** 2)))\n",
        "\n",
        "# Core processing blocks (cv2-free implementations)\n",
        "def clahe_enhance(img01: np.ndarray, clip_limit: float = 0.01, tile_grid: Tuple[int, int] = (8, 8)) -> np.ndarray:\n",
        "    # skimage's clip_limit is fraction of tiles; 0.01-0.03 is typical\n",
        "    # For tile_grid we can approximate via kernel size; equalize_adapthist handles automatically\n",
        "    res = exposure.equalize_adapthist(util.img_as_float(img01), clip_limit=clip_limit)\n",
        "    return res.astype(np.float32)\n",
        "\n",
        "def white_tophat(img01: np.ndarray, radius: int = 21) -> np.ndarray:\n",
        "    selem = morphology.disk(radius)\n",
        "    opened = morphology.opening(img01, selem)\n",
        "    wt = img01 - opened\n",
        "    return np.clip(wt, 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "def background_sub_gaussian(img01: np.ndarray, sigma: int = 41) -> np.ndarray:\n",
        "    bg = filters.gaussian(img01, sigma=sigma, preserve_range=True)\n",
        "    res = img01 - bg\n",
        "    return np.clip(res, 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "def gentle_denoise(img01: np.ndarray, method: str = 'bilateral', **kwargs) -> np.ndarray:\n",
        "    if method == 'bilateral':\n",
        "        sigma_color = float(kwargs.get('sigmaColor', 0.10))\n",
        "        sigma_spatial = float(kwargs.get('sigmaSpace', 5.0))\n",
        "        den = restoration.denoise_bilateral(img01, sigma_color=sigma_color, sigma_spatial=sigma_spatial, channel_axis=None)\n",
        "    elif method == 'tv':\n",
        "        weight = float(kwargs.get('weight', 0.1))\n",
        "        den = restoration.denoise_tv_chambolle(img01, weight=weight, channel_axis=None)\n",
        "    else:\n",
        "        ksize = int(kwargs.get('ksize', 3)) | 1\n",
        "        den = median_filter(img01, size=ksize, mode='reflect')\n",
        "    return np.clip(den, 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "def final_cleanup(img01: np.ndarray, median_ksize: int = 3) -> np.ndarray:\n",
        "    med = median_filter(img01, size=(median_ksize | 1), mode='reflect')\n",
        "    return np.clip(med, 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "# Robust Global Pipeline (per expert guidance)\n",
        "def pipeline_robust(img01: np.ndarray,\n",
        "                    bg_mode: str = 'tophat',\n",
        "                    radius: int = 21,\n",
        "                    gauss_sigma: int = 41,\n",
        "                    clahe_clip: float = 0.01,\n",
        "                    clahe_tile: Tuple[int, int] = (8,8),\n",
        "                    denoise_method: str = 'bilateral',\n",
        "                    bilateral_d: int = 9,  # unused in skimage impl\n",
        "                    bilateral_sigmaColor: float = 0.10,\n",
        "                    bilateral_sigmaSpace: float = 5.0,\n",
        "                    nlm_h: float = 10.0,  # unused\n",
        "                    final_median: int = 3) -> np.ndarray:\n",
        "    if bg_mode == 'tophat':\n",
        "        base = white_tophat(img01, radius=radius)\n",
        "    else:\n",
        "        base = background_sub_gaussian(img01, sigma=gauss_sigma)\n",
        "    enh = clahe_enhance(base, clip_limit=clahe_clip, tile_grid=clahe_tile)\n",
        "    if denoise_method == 'bilateral':\n",
        "        den = gentle_denoise(enh, method='bilateral', sigmaColor=bilateral_sigmaColor, sigmaSpace=bilateral_sigmaSpace)\n",
        "    elif denoise_method == 'tv':\n",
        "        den = gentle_denoise(enh, method='tv', weight=0.12)\n",
        "    else:\n",
        "        den = gentle_denoise(enh, method='median', ksize=3)\n",
        "    out = final_cleanup(den, median_ksize=final_median)\n",
        "    return np.clip(out, 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "# Simple alternative pipeline (Gaussian BG subtraction)\n",
        "def pipeline_gaussbg(img01: np.ndarray) -> np.ndarray:\n",
        "    base = background_sub_gaussian(img01, sigma=51)\n",
        "    enh = clahe_enhance(base, clip_limit=0.015, tile_grid=(8,8))\n",
        "    den = gentle_denoise(enh, method='bilateral', sigmaColor=0.12, sigmaSpace=6.0)\n",
        "    out = final_cleanup(den, median_ksize=3)\n",
        "    return np.clip(out, 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "# CV evaluation\n",
        "def list_image_ids(dir_path: str) -> List[str]:\n",
        "    files = glob.glob(os.path.join(dir_path, '*.png'))\n",
        "    ids = [os.path.splitext(os.path.basename(p))[0] for p in files]\n",
        "    return sorted(ids, key=lambda x: int(x))\n",
        "\n",
        "def evaluate_pipeline_on_train(pipeline_name: str = 'robust', n_show: int = 3) -> None:\n",
        "    train_ids = list_image_ids(TRAIN_DIR)\n",
        "    clean_ids = set(list_image_ids(CLEAN_DIR))\n",
        "    ids = [i for i in train_ids if i in clean_ids]\n",
        "    print(f'Train images found: {len(ids)}')\n",
        "    t0 = time.time()\n",
        "    rmses = []\n",
        "    for idx, img_id in enumerate(ids):\n",
        "        if idx % 10 == 0:\n",
        "            elapsed = time.time() - t0\n",
        "            print(f'Processing {idx}/{len(ids)} (elapsed {elapsed:.1f}s) ...', flush=True)\n",
        "        noisy = read_gray_float(os.path.join(TRAIN_DIR, f'{img_id}.png'))\n",
        "        clean = read_gray_float(os.path.join(CLEAN_DIR, f'{img_id}.png'))\n",
        "        if pipeline_name == 'robust':\n",
        "            pred = pipeline_robust(noisy)\n",
        "        else:\n",
        "            pred = pipeline_gaussbg(noisy)\n",
        "        score = rmse(pred, clean)\n",
        "        rmses.append(score)\n",
        "    avg = float(np.mean(rmses)) if rmses else math.inf\n",
        "    print(f'Average RMSE ({pipeline_name}): {avg:.6f}')\n",
        "\n",
        "# Test inference + submission writer\n",
        "def predict_test_images(pipeline_name: str = 'robust') -> Dict[str, np.ndarray]:\n",
        "    ids = list_image_ids(TEST_DIR)\n",
        "    preds = {}\n",
        "    t0 = time.time()\n",
        "    for i, img_id in enumerate(ids):\n",
        "        if i % 5 == 0:\n",
        "            print(f'Test {i}/{len(ids)} ... elapsed {time.time() - t0:.1f}s', flush=True)\n",
        "        noisy = read_gray_float(os.path.join(TEST_DIR, f'{img_id}.png'))\n",
        "        if pipeline_name == 'robust':\n",
        "            pred = pipeline_robust(noisy)\n",
        "        else:\n",
        "            pred = pipeline_gaussbg(noisy)\n",
        "        preds[img_id] = pred\n",
        "    return preds\n",
        "\n",
        "def write_submission_streaming(preds: Dict[str, np.ndarray], sample_path: str = SAMPLE_SUB, out_path: str = SUBMISSION_OUT) -> None:\n",
        "    # Stream over sampleSubmission order and write values directly\n",
        "    with open(sample_path, 'r') as fin, open(out_path, 'w', newline='') as fout:\n",
        "        reader = csv.reader(fin)\n",
        "        writer = csv.writer(fout)\n",
        "        header = next(reader)\n",
        "        writer.writerow(header)\n",
        "        line_ct = 0\n",
        "        for row in reader:\n",
        "            id_str = row[0]\n",
        "            parts = id_str.split('_')\n",
        "            if len(parts) != 3:\n",
        "                continue\n",
        "            img_id, r_str, c_str = parts\n",
        "            # Sample file is 1-based indexed\n",
        "            r = int(r_str) - 1\n",
        "            c = int(c_str) - 1\n",
        "            arr = preds.get(img_id)\n",
        "            if arr is None:\n",
        "                raise KeyError(f'Missing prediction for image id {img_id}')\n",
        "            if r < 0 or c < 0 or r >= arr.shape[0] or c >= arr.shape[1]:\n",
        "                raise IndexError(f'Index out of bounds for {img_id}: ({r},{c}) vs shape {arr.shape}')\n",
        "            val = float(np.clip(arr[r, c], 0.0, 1.0))\n",
        "            writer.writerow([id_str, f'{val:.6f}'])\n",
        "            line_ct += 1\n",
        "            if line_ct % 1000000 == 0:\n",
        "                print(f'Wrote {line_ct} rows ...', flush=True)\n",
        "    print(f'Submission written to {out_path}')\n",
        "\n",
        "print('Setup complete (cv2-free). Next steps:')\n",
        "print('- Run evaluate_pipeline_on_train(\"robust\") to gauge baseline RMSE')\n",
        "print('- If acceptable, run preds = predict_test_images(\"robust\"); then write_submission_streaming(preds)')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete (cv2-free). Next steps:\n- Run evaluate_pipeline_on_train(\"robust\") to gauge baseline RMSE\n- If acceptable, run preds = predict_test_images(\"robust\"); then write_submission_streaming(preds)\n"
          ]
        }
      ]
    },
    {
      "id": "47a251a0-7e9c-4154-ae63-bfae0247693a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pip -q install scikit-image imageio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "ddabde22-c821-414b-b326-c5e0605f9277",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n",
        "t0 = time.time()\n",
        "print('Evaluating pipeline: robust')\n",
        "evaluate_pipeline_on_train('robust')\n",
        "print(f'Elapsed: {time.time()-t0:.1f}s')\n",
        "\n",
        "t1 = time.time()\n",
        "print('\\nEvaluating pipeline: gaussbg')\n",
        "evaluate_pipeline_on_train('gaussbg')\n",
        "print(f'Elapsed: {time.time()-t1:.1f}s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "170d6477-d26d-4269-a2b9-97767cac134a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define Sauvola-based pipeline without extra imports (use skimage.filters from cell 3)\n",
        "def pipeline_sauvola(img01: np.ndarray,\n",
        "                      bg_mode: str = 'gauss',\n",
        "                      radius: int = 25,\n",
        "                      gauss_sigma: int = 45,\n",
        "                      clahe_clip: float = 0.012,\n",
        "                      sauvola_window: int = 31,\n",
        "                      sauvola_k: float = 0.34,\n",
        "                      unsharp_radius: float = 1.5,\n",
        "                      unsharp_amount: float = 1.0) -> np.ndarray:\n",
        "    # Background/illumination correction\n",
        "    if bg_mode == 'tophat':\n",
        "        base = white_tophat(img01, radius=radius)\n",
        "    else:\n",
        "        base = background_sub_gaussian(img01, sigma=gauss_sigma)\n",
        "    # Contrast enhancement\n",
        "    enh = clahe_enhance(base, clip_limit=clahe_clip)\n",
        "    # Gentle sharpening to crispen text edges\n",
        "    sharp = filters.unsharp_mask(enh, radius=unsharp_radius, amount=unsharp_amount, preserve_range=True)\n",
        "    sharp = np.clip(sharp, 0.0, 1.0).astype(np.float32)\n",
        "    # Sauvola adaptive threshold (text is dark -> background should be True/1)\n",
        "    window = sauvola_window | 1\n",
        "    thr = filters.threshold_sauvola(sharp, window_size=window, k=sauvola_k)\n",
        "    binary_bg_white = (sharp > thr).astype(np.float32)  # background=1, text=0\n",
        "    return binary_bg_white\n",
        "\n",
        "def evaluate_custom_pipeline(func, max_images: int = 20) -> float:\n",
        "    ids = list_image_ids(TRAIN_DIR)\n",
        "    clean_ids = set(list_image_ids(CLEAN_DIR))\n",
        "    ids = [i for i in ids if i in clean_ids]\n",
        "    if max_images is not None:\n",
        "        ids = ids[:max_images]\n",
        "    print(f'Evaluating custom pipeline on {len(ids)} images ...')\n",
        "    t0 = time.time()\n",
        "    scores = []\n",
        "    for idx, img_id in enumerate(ids):\n",
        "        if idx % 10 == 0:\n",
        "            print(f'  {idx}/{len(ids)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "        noisy = read_gray_float(os.path.join(TRAIN_DIR, f'{img_id}.png'))\n",
        "        clean = read_gray_float(os.path.join(CLEAN_DIR, f'{img_id}.png'))\n",
        "        pred = func(noisy)\n",
        "        scores.append(rmse(pred, clean))\n",
        "    avg = float(np.mean(scores)) if scores else math.inf\n",
        "    print(f'Custom pipeline RMSE: {avg:.6f} (elapsed {time.time()-t0:.1f}s)')\n",
        "    return avg\n",
        "\n",
        "print('New pipeline added: pipeline_sauvola(). Use evaluate_custom_pipeline(lambda img: pipeline_sauvola(img)) to test.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "835f56f4-f60b-4021-9054-847310ee956f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('Evaluating Sauvola pipeline on subset (15 images) ...')\n",
        "subset_rmse = evaluate_custom_pipeline(lambda img: pipeline_sauvola(img), max_images=15)\n",
        "print('Subset RMSE:', subset_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "00c9e84e-2940-4fa9-abe0-70ecdccc7459",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from skimage.filters import threshold_otsu\n",
        "\n",
        "def pipeline_div_otsu(img01: np.ndarray, sigma: int = 41) -> np.ndarray:\n",
        "    # Divide normalization so background ~1.0, text darker\n",
        "    bg = filters.gaussian(img01, sigma=sigma, preserve_range=True)\n",
        "    corrected = img01 / (bg + 1e-3)\n",
        "    # Robust rescale\n",
        "    p1, p99 = np.percentile(corrected, 1), np.percentile(corrected, 99)\n",
        "    corrected = exposure.rescale_intensity(corrected, in_range=(p1, p99), out_range=(0, 1)).astype(np.float32)\n",
        "    thr = threshold_otsu(corrected)\n",
        "    binary = (corrected > thr)\n",
        "    # Cleanup\n",
        "    binary = morphology.remove_small_holes(binary, area_threshold=64)\n",
        "    binary = morphology.remove_small_objects(binary, min_size=16)\n",
        "    return binary.astype(np.float32)\n",
        "\n",
        "def pipeline_sub_inv_sauvola(img01: np.ndarray, sigma: int = 41, window: int = 31, k: float = 0.25) -> np.ndarray:\n",
        "    # Subtract background, invert to get white background, then Sauvola\n",
        "    bg = filters.gaussian(img01, sigma=sigma, preserve_range=True)\n",
        "    corrected = img01 - bg  # residual; text negative\n",
        "    inv = -corrected  # invert so background white\n",
        "    p1, p99 = np.percentile(inv, 1), np.percentile(inv, 99)\n",
        "    inv = exposure.rescale_intensity(inv, in_range=(p1, p99), out_range=(0, 1)).astype(np.float32)\n",
        "    thr = filters.threshold_sauvola(inv, window_size=(window | 1), k=k)\n",
        "    binary = (inv > thr)\n",
        "    # Cleanup\n",
        "    binary = morphology.remove_small_holes(binary, area_threshold=64)\n",
        "    binary = morphology.remove_small_objects(binary, min_size=16)\n",
        "    return binary.astype(np.float32)\n",
        "\n",
        "# Quick subset eval for the two corrected pipelines\n",
        "print('Evaluating divide+Otsu on 15 images ...')\n",
        "rmse_div = evaluate_custom_pipeline(lambda img: pipeline_div_otsu(img), max_images=15)\n",
        "print('Evaluating sub+invert+Sauvola on 15 images ...')\n",
        "rmse_sau = evaluate_custom_pipeline(lambda img: pipeline_sub_inv_sauvola(img), max_images=15)\n",
        "print('Subset RMSEs -> div+Otsu:', rmse_div, '| sub+inv+Sauvola:', rmse_sau)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "bd3c42f0-c6a6-4d48-9a3a-4e40c4b80eeb",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sanity checks + continuous pipelines (no hard threshold)\n",
        "def baseline_sanity(max_images: int = 15):\n",
        "    ids = list_image_ids(TRAIN_DIR)\n",
        "    clean_ids = set(list_image_ids(CLEAN_DIR))\n",
        "    ids = [i for i in ids if i in clean_ids][:max_images]\n",
        "    r_noisy, r_white, r_black = [], [], []\n",
        "    for img_id in ids:\n",
        "        noisy = read_gray_float(os.path.join(TRAIN_DIR, f'{img_id}.png'))\n",
        "        clean = read_gray_float(os.path.join(CLEAN_DIR, f'{img_id}.png'))\n",
        "        r_noisy.append(rmse(noisy, clean))\n",
        "        r_white.append(rmse(np.ones_like(clean, dtype=np.float32), clean))\n",
        "        r_black.append(rmse(np.zeros_like(clean, dtype=np.float32), clean))\n",
        "    print('Baseline RMSE (subset): noisy:', float(np.mean(r_noisy))), print('white:', float(np.mean(r_white))), print('black:', float(np.mean(r_black)))\n",
        "\n",
        "def pipeline_div_continuous(img01: np.ndarray, sigma: int = 41, tv_weight: float = 0.08) -> np.ndarray:\n",
        "    bg = filters.gaussian(img01, sigma=sigma, preserve_range=True)\n",
        "    corrected = img01 / (bg + 1e-3)\n",
        "    p1, p99 = np.percentile(corrected, 1), np.percentile(corrected, 99)\n",
        "    corrected = exposure.rescale_intensity(corrected, in_range=(p1, p99), out_range=(0, 1)).astype(np.float32)\n",
        "    den = restoration.denoise_tv_chambolle(corrected, weight=tv_weight, channel_axis=None)\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def pipeline_sub_invert_continuous(img01: np.ndarray, sigma: int = 41, tv_weight: float = 0.08) -> np.ndarray:\n",
        "    bg = filters.gaussian(img01, sigma=sigma, preserve_range=True)\n",
        "    resid = img01 - bg\n",
        "    inv = 1.0 - resid  # invert polarity so background tends to white\n",
        "    p1, p99 = np.percentile(inv, 1), np.percentile(inv, 99)\n",
        "    inv = exposure.rescale_intensity(inv, in_range=(p1, p99), out_range=(0, 1)).astype(np.float32)\n",
        "    den = restoration.denoise_tv_chambolle(inv, weight=tv_weight, channel_axis=None)\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "print('Running sanity baselines on 15 images ...')\n",
        "baseline_sanity(15)\n",
        "print('\\nEvaluating continuous divide pipeline on 15 images ...')\n",
        "rmse_div_cont = evaluate_custom_pipeline(lambda img: pipeline_div_continuous(img), max_images=15)\n",
        "print('Evaluating continuous sub-invert pipeline on 15 images ...')\n",
        "rmse_sub_cont = evaluate_custom_pipeline(lambda img: pipeline_sub_invert_continuous(img), max_images=15)\n",
        "print('Subset RMSEs -> div_cont:', rmse_div_cont, '| sub_invert_cont:', rmse_sub_cont)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "306e3c93-e582-4ffa-a00c-30747b34927b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Simple continuous denoising pipelines (no BG subtraction/binarization)\n",
        "def pipeline_identity(img01: np.ndarray) -> np.ndarray:\n",
        "    return img01.astype(np.float32)\n",
        "\n",
        "def pipeline_median3(img01: np.ndarray) -> np.ndarray:\n",
        "    return np.clip(median_filter(img01, size=3, mode='reflect').astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def pipeline_median5(img01: np.ndarray) -> np.ndarray:\n",
        "    return np.clip(median_filter(img01, size=5, mode='reflect').astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def pipeline_bilateral_soft(img01: np.ndarray) -> np.ndarray:\n",
        "    den = restoration.denoise_bilateral(img01, sigma_color=0.06, sigma_spatial=3.0, channel_axis=None)\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def pipeline_tv_soft(img01: np.ndarray) -> np.ndarray:\n",
        "    den = restoration.denoise_tv_chambolle(img01, weight=0.06, channel_axis=None)\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def pipeline_clahe_median(img01: np.ndarray) -> np.ndarray:\n",
        "    enh = exposure.equalize_adapthist(util.img_as_float(img01), clip_limit=0.01).astype(np.float32)\n",
        "    den = median_filter(enh, size=3, mode='reflect')\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def eval_pipelines_subset(max_images: int = 15):\n",
        "    pipes = {\n",
        "        'identity': pipeline_identity,\n",
        "        'median3': pipeline_median3,\n",
        "        'median5': pipeline_median5,\n",
        "        'bilateral_soft': pipeline_bilateral_soft,\n",
        "        'tv_soft': pipeline_tv_soft,\n",
        "        'clahe_median': pipeline_clahe_median,\n",
        "    }\n",
        "    ids = list_image_ids(TRAIN_DIR)\n",
        "    clean_ids = set(list_image_ids(CLEAN_DIR))\n",
        "    ids = [i for i in ids if i in clean_ids][:max_images]\n",
        "    results = {}\n",
        "    for name, func in pipes.items():\n",
        "        t0 = time.time()\n",
        "        scores = []\n",
        "        for idx, img_id in enumerate(ids):\n",
        "            if idx % 10 == 0:\n",
        "                print(f'{name}: {idx}/{len(ids)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "            noisy = read_gray_float(os.path.join(TRAIN_DIR, f'{img_id}.png'))\n",
        "            clean = read_gray_float(os.path.join(CLEAN_DIR, f'{img_id}.png'))\n",
        "            pred = func(noisy)\n",
        "            scores.append(rmse(pred, clean))\n",
        "        results[name] = float(np.mean(scores)) if scores else math.inf\n",
        "        print(f'{name}: RMSE {results[name]:.6f} (elapsed {time.time()-t0:.1f}s)')\n",
        "    print('Subset RMSE summary:', results)\n",
        "    return results\n",
        "\n",
        "print('Ready: call eval_pipelines_subset(15) to compare simple continuous denoisers.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "915483d8-c1fe-48d6-807c-81e4c65efe78",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('Comparing simple continuous denoisers on 15 images ...')\n",
        "results = eval_pipelines_subset(15)\n",
        "best_name = min(results, key=results.get)\n",
        "print('Best pipeline on subset:', best_name, 'RMSE:', results[best_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "0471f91d-b22c-42dd-aa6e-804abfd2e586",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate test predictions with best quick pipeline (bilateral_soft) and write submission\n",
        "import time\n",
        "print('Predicting test images with bilateral_soft ...')\n",
        "test_ids = list_image_ids(TEST_DIR)\n",
        "preds = {}\n",
        "t0 = time.time()\n",
        "for i, img_id in enumerate(test_ids):\n",
        "    if i % 5 == 0:\n",
        "        print(f'  {i}/{len(test_ids)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "    noisy = read_gray_float(os.path.join(TEST_DIR, f'{img_id}.png'))\n",
        "    pred = pipeline_bilateral_soft(noisy)\n",
        "    preds[img_id] = np.clip(pred.astype(np.float32), 0.0, 1.0)\n",
        "print('Writing submission.csv ...')\n",
        "write_submission_streaming(preds, sample_path=SAMPLE_SUB, out_path=SUBMISSION_OUT)\n",
        "print('Done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f1824d5a-6047-4a64-8d3b-1153253ee17c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Linear blending of simple denoisers (Ridge) with leak-free image-wise CV and test inference\n",
        "from sklearn.linear_model import Ridge\n",
        "import random\n",
        "import csv\n",
        "\n",
        "# Expanded set of diverse pipelines (lighter set to keep runtime reasonable)\n",
        "BLEND_PIPES = {\n",
        "    'identity': pipeline_identity,\n",
        "    'bilateral_soft': pipeline_bilateral_soft,\n",
        "    'tv_soft': pipeline_tv_soft,\n",
        "    'median3': pipeline_median3,\n",
        "    'gaussian_07': pipeline_gaussian_07,\n",
        "    'bilateral_soft2': pipeline_bilateral_soft2,\n",
        "    'tv_w003': pipeline_tv_w003,\n",
        "    'nlm_fast': pipeline_nlm_fast,\n",
        "    'median5': pipeline_median5,\n",
        "    'local_mean3': pipeline_local_mean3,\n",
        "}\n",
        "\n",
        "def compute_pipe_outputs(img: np.ndarray, pipes: dict) -> dict:\n",
        "    out = {}\n",
        "    for name, fn in pipes.items():\n",
        "        out[name] = fn(img).astype(np.float32)\n",
        "    return out\n",
        "\n",
        "def sample_pixels(h: int, w: int, n_samples: int) -> np.ndarray:\n",
        "    total = h * w\n",
        "    n = min(n_samples, total)\n",
        "    idx = np.random.choice(total, size=n, replace=False)\n",
        "    return idx\n",
        "\n",
        "def build_train_samples(pipes: dict, n_per_image: int = 4000, seed: int = 42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    ids = list_image_ids(TRAIN_DIR)\n",
        "    clean_ids = set(list_image_ids(CLEAN_DIR))\n",
        "    ids = [i for i in ids if i in clean_ids]\n",
        "    X_list, y_list, meta = [], [], []\n",
        "    image_indices = []  # row -> image index mapping\n",
        "    print(f'Building samples from {len(ids)} train images ...')\n",
        "    t0 = time.time()\n",
        "    for k, img_id in enumerate(ids):\n",
        "        if k % 10 == 0: print(f'  {k}/{len(ids)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "        noisy = read_gray_float(os.path.join(TRAIN_DIR, f'{img_id}.png'))\n",
        "        clean = read_gray_float(os.path.join(CLEAN_DIR, f'{img_id}.png'))\n",
        "        outs = compute_pipe_outputs(noisy, pipes)\n",
        "        h, w = clean.shape\n",
        "        flat_idx = sample_pixels(h, w, n_per_image)\n",
        "        feats = []\n",
        "        for name in pipes.keys():\n",
        "            feats.append(outs[name].reshape(-1)[flat_idx])\n",
        "        Xi = np.stack(feats, axis=1)\n",
        "        yi = clean.reshape(-1)[flat_idx]\n",
        "        X_list.append(Xi.astype(np.float32))\n",
        "        y_list.append(yi.astype(np.float32))\n",
        "        image_indices.append(np.full(Xi.shape[0], k, dtype=np.int32))\n",
        "        meta.append({'id': img_id, 'shape': (h, w)})\n",
        "    X = np.concatenate(X_list, axis=0).astype(np.float32)\n",
        "    y = np.concatenate(y_list, axis=0).astype(np.float32)\n",
        "    image_indices = np.concatenate(image_indices, axis=0).astype(np.int32)\n",
        "    return ids, meta, X, y, image_indices\n",
        "\n",
        "def ridge_cv_and_fit(pipes: dict, k_folds: int = 5, n_per_image: int = 4000, alpha: float = 0.1):\n",
        "    ids, meta, X, y, img_idx_map = build_train_samples(pipes, n_per_image=n_per_image, seed=42)\n",
        "    # Prepare folds by image index (contiguous split for determinism)\n",
        "    n_images = len(ids)\n",
        "    idxs = np.arange(n_images)\n",
        "    folds = []\n",
        "    fold_sizes = [n_images // k_folds + (1 if i < (n_images % k_folds) else 0) for i in range(k_folds)]\n",
        "    start = 0\n",
        "    for fs in fold_sizes:\n",
        "        folds.append(idxs[start:start+fs])\n",
        "        start += fs\n",
        "    cv_scores = []\n",
        "    for f, val_img_idx in enumerate(folds):\n",
        "        print(f'Fold {f+1}/{k_folds}: training Ridge(alpha={alpha}) ...', flush=True)\n",
        "        train_img_idx = np.setdiff1d(idxs, val_img_idx, assume_unique=True)\n",
        "        train_rows_mask = np.isin(img_idx_map, train_img_idx)\n",
        "        tr_rows = np.where(train_rows_mask)[0]\n",
        "        model = Ridge(alpha=alpha, fit_intercept=True)\n",
        "        model.fit(X[tr_rows], y[tr_rows])\n",
        "        # Validate by predicting full images of val set via weighted sum\n",
        "        fold_rmses = []\n",
        "        for vi in val_img_idx:\n",
        "            img_id = ids[vi]\n",
        "            noisy = read_gray_float(os.path.join(TRAIN_DIR, f'{img_id}.png'))\n",
        "            clean = read_gray_float(os.path.join(CLEAN_DIR, f'{img_id}.png'))\n",
        "            outs = compute_pipe_outputs(noisy, pipes)\n",
        "            names = list(pipes.keys())\n",
        "            coefs = model.coef_\n",
        "            intercept = float(model.intercept_)\n",
        "            pred = intercept\n",
        "            for j, name in enumerate(names):\n",
        "                pred = pred + coefs[j] * outs[name]\n",
        "            pred = np.clip(pred, 0.0, 1.0).astype(np.float32)\n",
        "            fold_rmses.append(rmse(pred, clean))\n",
        "        cv_scores.append(float(np.mean(fold_rmses)))\n",
        "        print(f'  Fold {f+1} RMSE: {cv_scores[-1]:.6f}', flush=True)\n",
        "    print('CV RMSE scores:', cv_scores, 'Avg:', float(np.mean(cv_scores)))\n",
        "    # Fit final model on all samples\n",
        "    final_model = Ridge(alpha=alpha, fit_intercept=True)\n",
        "    final_model.fit(X, y)\n",
        "    print('Final model coef:', final_model.coef_, 'intercept:', float(final_model.intercept_))\n",
        "    return final_model\n",
        "\n",
        "def predict_test_with_model(model, pipes: dict) -> Dict[str, np.ndarray]:\n",
        "    test_ids = list_image_ids(TEST_DIR)\n",
        "    preds = {}\n",
        "    names = list(pipes.keys())\n",
        "    coefs = model.coef_\n",
        "    intercept = float(model.intercept_)\n",
        "    t0 = time.time()\n",
        "    for i, img_id in enumerate(test_ids):\n",
        "        if i % 5 == 0: print(f'Test blend {i}/{len(test_ids)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "        noisy = read_gray_float(os.path.join(TEST_DIR, f'{img_id}.png'))\n",
        "        outs = compute_pipe_outputs(noisy, pipes)\n",
        "        pred = intercept\n",
        "        for j, name in enumerate(names):\n",
        "            pred = pred + coefs[j] * outs[name]\n",
        "        preds[img_id] = np.clip(pred, 0.0, 1.0).astype(np.float32)\n",
        "    return preds\n",
        "\n",
        "def write_submission_streaming_prec(preds: Dict[str, np.ndarray], sample_path: str = SAMPLE_SUB, out_path: str = 'submission_blend_leakfix.csv', precision: int = 4) -> None:\n",
        "    fmt = '{:.' + str(precision) + 'f}'\n",
        "    with open(sample_path, 'r') as fin, open(out_path, 'w', newline='') as fout:\n",
        "        reader = csv.reader(fin)\n",
        "        writer = csv.writer(fout)\n",
        "        header = next(reader)\n",
        "        writer.writerow(header)\n",
        "        line_ct = 0\n",
        "        for row in reader:\n",
        "            id_str = row[0]\n",
        "            parts = id_str.split('_')\n",
        "            if len(parts) != 3:\n",
        "                continue\n",
        "            img_id, r_str, c_str = parts\n",
        "            r = int(r_str) - 1\n",
        "            c = int(c_str) - 1\n",
        "            arr = preds.get(img_id)\n",
        "            if arr is None:\n",
        "                raise KeyError(f'Missing prediction for image id {img_id}')\n",
        "            val = float(np.clip(arr[r, c], 0.0, 1.0))\n",
        "            writer.writerow([id_str, fmt.format(val)])\n",
        "            line_ct += 1\n",
        "            if line_ct % 1000000 == 0:\n",
        "                print(f'Wrote {line_ct} rows ...', flush=True)\n",
        "    print(f'Submission written to {out_path}')\n",
        "\n",
        "print('Training Ridge blend with leak-free image-wise CV ...')\n",
        "# Reduce n_per_image a bit to accommodate more features while keeping runtime manageable\n",
        "model = ridge_cv_and_fit(BLEND_PIPES, k_folds=5, n_per_image=2000, alpha=0.1)\n",
        "print('Predicting test with blended model ...')\n",
        "preds_blend = predict_test_with_model(model, BLEND_PIPES)\n",
        "print('Writing blended submission (4-decimal precision) ...')\n",
        "write_submission_streaming_prec(preds_blend, sample_path=SAMPLE_SUB, out_path='submission_blend_leakfix.csv', precision=4)\n",
        "print('Blended submission written to submission_blend_leakfix.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "82cf25d2-6f09-4f2d-a1d9-f5fcc6489af9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Prepare final submission.csv from leak-fixed blend\n",
        "import shutil, os\n",
        "src = 'submission_blend_leakfix.csv'\n",
        "dst = 'submission.csv'\n",
        "if not os.path.exists(src):\n",
        "    raise FileNotFoundError(src)\n",
        "shutil.copyfile(src, dst)\n",
        "print('Copied', src, '->', dst, 'Size:', os.path.getsize(dst)/1e6, 'MB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b861969d-e770-4300-b87b-9a2a301d5a45",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Additional denoising pipelines for richer blending features\n",
        "from skimage import restoration as sk_restoration\n",
        "from scipy.ndimage import gaussian_filter, uniform_filter\n",
        "\n",
        "def pipeline_gaussian_07(img01: np.ndarray) -> np.ndarray:\n",
        "    den = gaussian_filter(img01, sigma=0.7, mode='reflect')\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def pipeline_bilateral_soft2(img01: np.ndarray) -> np.ndarray:\n",
        "    den = sk_restoration.denoise_bilateral(img01, sigma_color=0.08, sigma_spatial=4.0, channel_axis=None)\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def pipeline_bilateral_strong(img01: np.ndarray) -> np.ndarray:\n",
        "    den = sk_restoration.denoise_bilateral(img01, sigma_color=0.12, sigma_spatial=6.0, channel_axis=None)\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def pipeline_tv_w003(img01: np.ndarray) -> np.ndarray:\n",
        "    den = sk_restoration.denoise_tv_chambolle(img01, weight=0.03, channel_axis=None)\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def pipeline_tv_w010(img01: np.ndarray) -> np.ndarray:\n",
        "    den = sk_restoration.denoise_tv_chambolle(img01, weight=0.10, channel_axis=None)\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def pipeline_nlm_fast(img01: np.ndarray) -> np.ndarray:\n",
        "    # h tuned to be gentle; adjust if needed\n",
        "    den = sk_restoration.denoise_nl_means(img01, h=0.08, patch_size=3, patch_distance=5, fast_mode=True, preserve_range=True)\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)\n",
        "\n",
        "def pipeline_clahe_lowclip(img01: np.ndarray) -> np.ndarray:\n",
        "    enh = exposure.equalize_adapthist(util.img_as_float(img01), clip_limit=0.015).astype(np.float32)\n",
        "    return np.clip(enh, 0.0, 1.0)\n",
        "\n",
        "def pipeline_local_mean3(img01: np.ndarray) -> np.ndarray:\n",
        "    den = uniform_filter(img01, size=3, mode='reflect')\n",
        "    return np.clip(den.astype(np.float32), 0.0, 1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "f55787af-38b8-4aee-95f3-70f54712630c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pip -q install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
        "import torch, torchvision\n",
        "print('Torch:', torch.__version__, 'CUDA available:', torch.cuda.is_available())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision-0.20.1+cu121.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch-2.5.1+cu121.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2-3.1.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton-3.1.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.13.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2024.6.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-2.1.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.21.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.13.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.12.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.5.1+cu121 CUDA available: True\n"
          ]
        }
      ]
    },
    {
      "id": "86bba87d-e257-482a-8920-c33ca2aa2183",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# DnCNN denoiser: dataset, model, AMP training loop, validation, and tiled inference\n",
        "import math, random, os, time\n",
        "from typing import List, Tuple\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def load_train_arrays() -> Tuple[List[str], List[np.ndarray], List[np.ndarray]]:\n",
        "    ids = list_image_ids(TRAIN_DIR)\n",
        "    clean_ids = set(list_image_ids(CLEAN_DIR))\n",
        "    ids = [i for i in ids if i in clean_ids]\n",
        "    noisy_list, clean_list = [], []\n",
        "    t0 = time.time()\n",
        "    for k, img_id in enumerate(ids):\n",
        "        if k % 20 == 0:\n",
        "            print(f'  preload {k}/{len(ids)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "        noisy = read_gray_float(os.path.join(TRAIN_DIR, f'{img_id}.png'))\n",
        "        clean = read_gray_float(os.path.join(CLEAN_DIR, f'{img_id}.png'))\n",
        "        noisy_list.append(noisy.astype(np.float32))\n",
        "        clean_list.append(clean.astype(np.float32))\n",
        "    return ids, noisy_list, clean_list\n",
        "\n",
        "def split_ids(ids: List[str], val_frac: float = 0.1, seed: int = 42) -> Tuple[List[int], List[int]]:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = np.arange(len(ids))\n",
        "    rng.shuffle(idx)\n",
        "    n_val = max(1, int(len(ids) * val_frac))\n",
        "    val_idx = idx[:n_val].tolist()\n",
        "    tr_idx = idx[n_val:].tolist()\n",
        "    return tr_idx, val_idx\n",
        "\n",
        "def random_crop_pair(noisy: np.ndarray, clean: np.ndarray, size: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    h, w = noisy.shape\n",
        "    if h < size or w < size:\n",
        "        pad_h = max(0, size - h)\n",
        "        pad_w = max(0, size - w)\n",
        "        noisy = np.pad(noisy, ((0, pad_h), (0, pad_w)), mode='reflect')\n",
        "        clean = np.pad(clean, ((0, pad_h), (0, pad_w)), mode='reflect')\n",
        "        h, w = noisy.shape\n",
        "    y = random.randint(0, h - size)\n",
        "    x = random.randint(0, w - size)\n",
        "    return noisy[y:y+size, x:x+size], clean[y:y+size, x:x+size]\n",
        "\n",
        "def augment_pair(a: np.ndarray, b: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    k = random.randint(0, 3)\n",
        "    a = np.rot90(a, k).copy()\n",
        "    b = np.rot90(b, k).copy()\n",
        "    if random.random() < 0.5:\n",
        "        a = np.fliplr(a).copy(); b = np.fliplr(b).copy()\n",
        "    if random.random() < 0.5:\n",
        "        a = np.flipud(a).copy(); b = np.flipud(b).copy()\n",
        "    return a, b\n",
        "\n",
        "class PatchDataset(Dataset):\n",
        "    def __init__(self, noisy_list: List[np.ndarray], clean_list: List[np.ndarray], patch_size: int = 128, length: int = 20000):\n",
        "        self.noisy = noisy_list\n",
        "        self.clean = clean_list\n",
        "        self.patch = patch_size\n",
        "        self.length = length\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    def __getitem__(self, idx):\n",
        "        i = random.randint(0, len(self.noisy) - 1)\n",
        "        n, c = random_crop_pair(self.noisy[i], self.clean[i], self.patch)\n",
        "        n, c = augment_pair(n, c)\n",
        "        n = torch.from_numpy(n).unsqueeze(0)  # 1,H,W\n",
        "        c = torch.from_numpy(c).unsqueeze(0)\n",
        "        return n, c\n",
        "\n",
        "class DnCNN(nn.Module):\n",
        "    def __init__(self, depth: int = 15, n_feats: int = 64, in_ch: int = 1, out_ch: int = 1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        layers += [nn.Conv2d(in_ch, n_feats, 3, 1, 1), nn.ReLU(inplace=True)]\n",
        "        for _ in range(depth - 2):\n",
        "            layers += [nn.Conv2d(n_feats, n_feats, 3, 1, 1), nn.BatchNorm2d(n_feats), nn.ReLU(inplace=True)]\n",
        "        layers += [nn.Conv2d(n_feats, out_ch, 3, 1, 1)]\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        noise = self.net(x)\n",
        "        return x - noise  # residual learning\n",
        "\n",
        "class CharbonnierLoss(nn.Module):\n",
        "    def __init__(self, eps: float = 1e-3):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "    def forward(self, pred, target):\n",
        "        return torch.mean(torch.sqrt((pred - target) ** 2 + self.eps ** 2))\n",
        "\n",
        "def rmse_torch(pred: torch.Tensor, target: torch.Tensor) -> float:\n",
        "    return float(torch.sqrt(torch.mean((pred - target) ** 2)).item())\n",
        "\n",
        "def validate_random_patches(model: nn.Module, noisy_list: List[np.ndarray], clean_list: List[np.ndarray], patch: int = 128, samples_per_img: int = 8) -> float:\n",
        "    model.eval()\n",
        "    errs = []\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=True):\n",
        "        for n_img, c_img in zip(noisy_list, clean_list):\n",
        "            for _ in range(samples_per_img):\n",
        "                n, c = random_crop_pair(n_img, c_img, patch)\n",
        "                n_t = torch.from_numpy(n).unsqueeze(0).unsqueeze(0).to(device)\n",
        "                c_t = torch.from_numpy(c).unsqueeze(0).unsqueeze(0).to(device)\n",
        "                out = model(n_t)\n",
        "                errs.append(rmse_torch(out, c_t))\n",
        "    return float(np.mean(errs)) if errs else math.inf\n",
        "\n",
        "def train_dncnn(epochs: int = 30, patch: int = 128, train_len: int = 40000, batch: int = 16, lr: float = 1e-3, wd: float = 1e-5, val_frac: float = 0.1, seed: int = 42, patience: int = 6):\n",
        "    torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
        "    print('Preloading train arrays ...')\n",
        "    ids, noisy_all, clean_all = load_train_arrays()\n",
        "    tr_idx, val_idx = split_ids(ids, val_frac=val_frac, seed=seed)\n",
        "    noisy_tr = [noisy_all[i] for i in tr_idx]; clean_tr = [clean_all[i] for i in tr_idx]\n",
        "    noisy_val = [noisy_all[i] for i in val_idx]; clean_val = [clean_all[i] for i in val_idx]\n",
        "    print(f'Train images: {len(tr_idx)} | Val images: {len(val_idx)}')\n",
        "    ds = PatchDataset(noisy_tr, clean_tr, patch_size=patch, length=train_len)\n",
        "    dl = DataLoader(ds, batch_size=batch, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
        "    model = DnCNN(depth=15, n_feats=64).to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
        "    criterion = CharbonnierLoss()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
        "    best_rmse = float('inf'); best_path = 'dncnn_best.pt'; no_improve = 0\n",
        "    iters_per_epoch = len(dl)\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        t0 = time.time(); running = 0.0\n",
        "        for it, (n, c) in enumerate(dl):\n",
        "            n = n.to(device, non_blocking=True)\n",
        "            c = c.to(device, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=True):\n",
        "                out = model(n)\n",
        "                loss = criterion(out, c)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            running += float(loss.item())\n",
        "            if (it + 1) % 200 == 0:\n",
        "                print(f'Ep {ep} Iter {it+1}/{iters_per_epoch} loss {running/(it+1):.5f}', flush=True)\n",
        "        sched.step()\n",
        "        tr_loss = running / max(1, iters_per_epoch)\n",
        "        val_rmse = validate_random_patches(model, noisy_val, clean_val, patch=patch, samples_per_img=8)\n",
        "        print(f'Epoch {ep}: train_loss {tr_loss:.5f} | val_RMSE {val_rmse:.5f} | lr {sched.get_last_lr()[0]:.6f} | elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "        if val_rmse < best_rmse - 1e-4:\n",
        "            best_rmse = val_rmse; no_improve = 0\n",
        "            torch.save({'state_dict': model.state_dict(), 'epoch': ep, 'val_rmse': best_rmse}, best_path)\n",
        "            print(f'  Saved new best to {best_path} (RMSE {best_rmse:.5f})')\n",
        "        else:\n",
        "            no_improve += 1\n",
        "        if no_improve >= patience:\n",
        "            print('Early stopping triggered')\n",
        "            break\n",
        "    print('Best val RMSE:', best_rmse)\n",
        "    return best_rmse\n",
        "\n",
        "def cosine_window(h: int, w: int) -> torch.Tensor:\n",
        "    y = 0.5 * (1 - torch.cos(torch.linspace(0, math.pi, steps=h, device=device)))\n",
        "    x = 0.5 * (1 - torch.cos(torch.linspace(0, math.pi, steps=w, device=device)))\n",
        "    win = torch.ger(y, x)\n",
        "    return win\n",
        "\n",
        "def inference_tiled(model: nn.Module, img: np.ndarray, tile: int = 256, stride: int = 128) -> np.ndarray:\n",
        "    model.eval()\n",
        "    H, W = img.shape\n",
        "    pad_h = (math.ceil((H - tile) / stride) * stride + tile) - H if H > tile else tile - H\n",
        "    pad_w = (math.ceil((W - tile) / stride) * stride + tile) - W if W > tile else tile - W\n",
        "    pad_top = pad_h // 2; pad_bottom = pad_h - pad_top\n",
        "    pad_left = pad_w // 2; pad_right = pad_w - pad_left\n",
        "    img_pad = np.pad(img, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='reflect')\n",
        "    Hp, Wp = img_pad.shape\n",
        "    out = torch.zeros((1, 1, Hp, Wp), device=device)\n",
        "    weight = torch.zeros((1, 1, Hp, Wp), device=device)\n",
        "    win = cosine_window(tile, tile).view(1, 1, tile, tile)\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=True):\n",
        "        for y in range(0, Hp - tile + 1, stride):\n",
        "            for x in range(0, Wp - tile + 1, stride):\n",
        "                patch = torch.from_numpy(img_pad[y:y+tile, x:x+tile]).to(device).view(1, 1, tile, tile)\n",
        "                pred = model(patch)\n",
        "                out[:, :, y:y+tile, x:x+tile] += pred * win\n",
        "                weight[:, :, y:y+tile, x:x+tile] += win\n",
        "    out = out / torch.clamp(weight, min=1e-6)\n",
        "    out_np = out.squeeze().detach().cpu().numpy()\n",
        "    out_np = out_np[pad_top:pad_top+H, pad_left:pad_left+W]\n",
        "    return np.clip(out_np, 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "def predict_test_dncnn(model_path: str = 'dncnn_best.pt', tile: int = 256, stride: int = 128) -> Dict[str, np.ndarray]:\n",
        "    test_ids = list_image_ids(TEST_DIR)\n",
        "    model = DnCNN(depth=15, n_feats=64).to(device)\n",
        "    ckpt = torch.load(model_path, map_location=device)\n",
        "    model.load_state_dict(ckpt['state_dict'])\n",
        "    preds = {}\n",
        "    t0 = time.time()\n",
        "    for i, img_id in enumerate(test_ids):\n",
        "        if i % 5 == 0:\n",
        "            print(f'Test DL {i}/{len(test_ids)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "        noisy = read_gray_float(os.path.join(TEST_DIR, f'{img_id}.png'))\n",
        "        pred = inference_tiled(model, noisy, tile=tile, stride=stride)\n",
        "        preds[img_id] = pred\n",
        "    return preds\n",
        "\n",
        "print('DnCNN utilities ready: call train_dncnn(...) to train, then predict_test_dncnn(...) and write with write_submission_streaming_prec.')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DnCNN utilities ready: call train_dncnn(...) to train, then predict_test_dncnn(...) and write with write_submission_streaming_prec.\n"
          ]
        }
      ]
    },
    {
      "id": "7759b43e-5b43-4367-91ac-01945b72ba4c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Kick off DnCNN training\n",
        "print('Starting DnCNN training ...')\n",
        "best = train_dncnn(epochs=30, patch=128, train_len=60000, batch=16, lr=1e-3, wd=1e-5, val_frac=0.1, seed=42, patience=6)\n",
        "print('Training complete. Best val RMSE:', best)\n",
        "print('Best model saved to dncnn_best.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "91198179-2042-4230-bcc9-06cb668414d0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inference with DnCNN best model and write compact submission (explicit per-image logging)\n",
        "import time, os\n",
        "from typing import Dict\n",
        "print('Running DnCNN test inference (tile=512, stride=256) ...', flush=True)\n",
        "test_ids = list_image_ids(TEST_DIR)\n",
        "# Load model once\n",
        "model = DnCNN(depth=15, n_feats=64).to(device)\n",
        "ckpt = torch.load('dncnn_best.pt', map_location=device)\n",
        "model.load_state_dict(ckpt['state_dict'])\n",
        "preds_dl: Dict[str, np.ndarray] = {}\n",
        "t0 = time.time()\n",
        "for i, img_id in enumerate(test_ids):\n",
        "    t_img = time.time()\n",
        "    noisy = read_gray_float(os.path.join(TEST_DIR, f'{img_id}.png'))\n",
        "    pred = inference_tiled(model, noisy, tile=512, stride=256)\n",
        "    preds_dl[img_id] = pred\n",
        "    print(f'DL pred {i+1}/{len(test_ids)} id={img_id} elapsed_img {time.time()-t_img:.1f}s total {time.time()-t0:.1f}s', flush=True)\n",
        "print('Inference complete. Writing submission.csv with 3-decimal precision ...', flush=True)\n",
        "write_submission_streaming_prec(preds_dl, sample_path=SAMPLE_SUB, out_path='submission.csv', precision=3)\n",
        "print('submission.csv size (MB):', os.path.getsize('submission.csv')/1e6, flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "6b29514e-275b-4fce-a358-d8f0cb936a95",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CPU fallback inference for DnCNN with per-image logging and compact submission\n",
        "import os, time, math\n",
        "from typing import Dict\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def cosine_window_cpu(h: int, w: int) -> torch.Tensor:\n",
        "    y = 0.5 * (1 - torch.cos(torch.linspace(0, math.pi, steps=h)))\n",
        "    x = 0.5 * (1 - torch.cos(torch.linspace(0, math.pi, steps=w)))\n",
        "    return torch.ger(y, x)\n",
        "\n",
        "def inference_tiled_cpu(model: nn.Module, img: np.ndarray, tile: int = 512, stride: int = 256) -> np.ndarray:\n",
        "    model.eval()\n",
        "    device_cpu = torch.device('cpu')\n",
        "    H, W = img.shape\n",
        "    pad_h = (max(H, tile) - H)\n",
        "    pad_w = (max(W, tile) - W)\n",
        "    pad_top = pad_h // 2; pad_bottom = pad_h - pad_top\n",
        "    pad_left = pad_w // 2; pad_right = pad_w - pad_left\n",
        "    img_pad = np.pad(img, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='reflect')\n",
        "    Hp, Wp = img_pad.shape\n",
        "    # Ensure grid covers entire image\n",
        "    ys = list(range(0, max(1, Hp - tile + 1), stride))\n",
        "    xs = list(range(0, max(1, Wp - tile + 1), stride))\n",
        "    if ys[-1] != Hp - tile:\n",
        "        ys.append(max(0, Hp - tile))\n",
        "    if xs[-1] != Wp - tile:\n",
        "        xs.append(max(0, Wp - tile))\n",
        "    out = torch.zeros((1, 1, Hp, Wp), device=device_cpu)\n",
        "    weight = torch.zeros((1, 1, Hp, Wp), device=device_cpu)\n",
        "    win = cosine_window_cpu(tile, tile).view(1, 1, tile, tile).to(device_cpu)\n",
        "    with torch.no_grad():\n",
        "        for y in ys:\n",
        "            for x in xs:\n",
        "                patch = torch.from_numpy(img_pad[y:y+tile, x:x+tile]).view(1, 1, tile, tile).to(device_cpu)\n",
        "                pred = model(patch)\n",
        "                out[:, :, y:y+tile, x:x+tile] += pred * win\n",
        "                weight[:, :, y:y+tile, x:x+tile] += win\n",
        "    out = out / torch.clamp(weight, min=1e-6)\n",
        "    out_np = out.squeeze().cpu().numpy()\n",
        "    out_np = out_np[pad_top:pad_top+H, pad_left:pad_left+W]\n",
        "    return np.clip(out_np, 0.0, 1.0).astype(np.float32)\n",
        "\n",
        "print('CPU inference fallback: loading model and running per-image tiling ...', flush=True)\n",
        "test_ids = list_image_ids(TEST_DIR)\n",
        "device_cpu = torch.device('cpu')\n",
        "model_cpu = DnCNN(depth=15, n_feats=64).to(device_cpu)\n",
        "ckpt = torch.load('dncnn_best.pt', map_location=device_cpu)\n",
        "model_cpu.load_state_dict(ckpt['state_dict'])\n",
        "preds_dl: Dict[str, np.ndarray] = {}\n",
        "t0 = time.time()\n",
        "for i, img_id in enumerate(test_ids):\n",
        "    t_img = time.time()\n",
        "    noisy = read_gray_float(os.path.join(TEST_DIR, f'{img_id}.png'))\n",
        "    pred = inference_tiled_cpu(model_cpu, noisy, tile=512, stride=256)\n",
        "    preds_dl[img_id] = pred\n",
        "    print(f'CPU DL pred {i+1}/{len(test_ids)} id={img_id} elapsed_img {time.time()-t_img:.1f}s total {time.time()-t0:.1f}s', flush=True)\n",
        "print('CPU inference complete. Writing submission.csv (precision=3) ...', flush=True)\n",
        "write_submission_streaming_prec(preds_dl, sample_path=SAMPLE_SUB, out_path='submission.csv', precision=3)\n",
        "print('submission.csv size (MB):', os.path.getsize('submission.csv')/1e6, flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "8edd2737-96df-47de-a4e6-b0d40128f9ca",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick sanity: run DL inference on first 2 test images and print progress\n",
        "print('Sanity DL inference on first 2 test images ...', flush=True)\n",
        "test_ids = list_image_ids(TEST_DIR)\n",
        "print('Test count:', len(test_ids), 'First IDs:', test_ids[:2], flush=True)\n",
        "model = DnCNN(depth=15, n_feats=64).to(device)\n",
        "ckpt = torch.load('dncnn_best.pt', map_location=device)\n",
        "model.load_state_dict(ckpt['state_dict'])\n",
        "for i, img_id in enumerate(test_ids[:2]):\n",
        "    t0 = time.time()\n",
        "    noisy = read_gray_float(os.path.join(TEST_DIR, f'{img_id}.png'))\n",
        "    pred = inference_tiled(model, noisy, tile=256, stride=128)\n",
        "    print(f'OK {i+1}/2 id={img_id} shape={pred.shape} elapsed {time.time()-t0:.2f}s', flush=True)\n",
        "print('Sanity inference finished.', flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c791458e-b65c-4af2-8313-a034ecc8e183",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Simple full-image DnCNN inference (no tiling) + write submission (precision=3)\n",
        "import os, time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "print('Running simple full-image DnCNN inference (no tiling) ...', flush=True)\n",
        "test_ids = list_image_ids(TEST_DIR)\n",
        "model = DnCNN(depth=15, n_feats=64).to(device)\n",
        "ckpt = torch.load('dncnn_best.pt', map_location=device)\n",
        "model.load_state_dict(ckpt['state_dict'])\n",
        "model.eval()\n",
        "preds = {}\n",
        "t0 = time.time()\n",
        "with torch.no_grad():\n",
        "    for i, img_id in enumerate(test_ids):\n",
        "        if i % 5 == 0:\n",
        "            print(f'  {i}/{len(test_ids)} elapsed {time.time()-t0:.1f}s', flush=True)\n",
        "        noisy = read_gray_float(os.path.join(TEST_DIR, f'{img_id}.png'))\n",
        "        inp = torch.from_numpy(noisy).to(device).view(1,1,*noisy.shape)\n",
        "        out = model(inp).squeeze().detach().cpu().numpy().astype(np.float32)\n",
        "        preds[img_id] = np.clip(out, 0.0, 1.0)\n",
        "print('Inference done. Writing submission.csv (precision=3) ...', flush=True)\n",
        "write_submission_streaming_prec(preds, sample_path=SAMPLE_SUB, out_path='submission.csv', precision=3)\n",
        "print('submission.csv size (MB):', os.path.getsize('submission.csv')/1e6, flush=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running simple full-image DnCNN inference (no tiling) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  0/29 elapsed 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_744/2170194961.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load('dncnn_best.pt', map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  5/29 elapsed 0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  10/29 elapsed 0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  15/29 elapsed 0.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  20/29 elapsed 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  25/29 elapsed 1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference done. Writing submission.csv (precision=3) ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 1000000 rows ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 2000000 rows ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 3000000 rows ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 4000000 rows ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 5000000 rows ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission written to submission.csv\nsubmission.csv size (MB): 104.718754\n"
          ]
        }
      ]
    },
    {
      "id": "a086d47c-e874-4746-b89c-593e29c546b7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Re-define write_submission_streaming_prec to fix NameError without re-running blend pipeline\n",
        "import csv\n",
        "from typing import Dict\n",
        "import numpy as np\n",
        "\n",
        "def write_submission_streaming_prec(preds: Dict[str, np.ndarray], sample_path: str = SAMPLE_SUB, out_path: str = 'submission.csv', precision: int = 3) -> None:\n",
        "    fmt = '{:.' + str(precision) + 'f}'\n",
        "    with open(sample_path, 'r') as fin, open(out_path, 'w', newline='') as fout:\n",
        "        reader = csv.reader(fin)\n",
        "        writer = csv.writer(fout)\n",
        "        header = next(reader)\n",
        "        writer.writerow(header)\n",
        "        line_ct = 0\n",
        "        for row in reader:\n",
        "            id_str = row[0]\n",
        "            parts = id_str.split('_')\n",
        "            if len(parts) != 3:\n",
        "                continue\n",
        "            img_id, r_str, c_str = parts\n",
        "            r = int(r_str) - 1\n",
        "            c = int(c_str) - 1\n",
        "            arr = preds.get(img_id)\n",
        "            if arr is None:\n",
        "                raise KeyError(f'Missing prediction for image id {img_id}')\n",
        "            val = float(np.clip(arr[r, c], 0.0, 1.0))\n",
        "            writer.writerow([id_str, fmt.format(val)])\n",
        "            line_ct += 1\n",
        "            if line_ct % 1000000 == 0:\n",
        "                print(f'Wrote {line_ct} rows ...', flush=True)\n",
        "    print(f'Submission written to {out_path}')"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}