{
  "cells": [
    {
      "id": "1ac63ce7-e2d4-4ff3-99a6-83c7b8b1a0a9",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 3: Final Submission\n",
        "\n",
        "This notebook implements the final inference and submission pipeline. Based on the analysis in `03_planning_and_cv.ipynb`, the YOLOX models trained for only 2 epochs are unusable. Therefore, this notebook will use a hybrid strategy:\n",
        "\n",
        "1.  **Detector:** Use the single, stronger **YOLOv5s model** trained on fold 0 from Phase 1 (`yolov5_runs/train/baseline_fold0/weights/best.pt`).\n",
        "2.  **Classifier:** Use the **5-fold ensembled EfficientNet-B5 models**, which were trained successfully and represent our best classifier asset.\n",
        "\n",
        "## Plan\n",
        "\n",
        "1.  **Setup & Configuration:**\n",
        "    *   Import libraries.\n",
        "    *   Define paths to the 5 classifier models and the single YOLOv5 detector model.\n",
        "\n",
        "2.  **Load Metadata:**\n",
        "    *   Load `sample_submission.csv` and prepare test dataframes.\n",
        "    *   Get image dimensions for scaling bounding boxes.\n",
        "\n",
        "3.  **Classifier Inference:**\n",
        "    *   Run inference on the test set with all 5 `EfficientNet-B5` models.\n",
        "    *   Average the predictions to get the ensembled study-level probabilities.\n",
        "\n",
        "4.  **Detector (YOLOv5) Inference:**\n",
        "    *   Load the trained YOLOv5s model using `torch.hub`.\n",
        "    *   Run batched inference on the test images.\n",
        "    *   Collect all bounding box predictions.\n",
        "\n",
        "5.  **Submission Formatting:**\n",
        "    *   Combine the study-level and image-level predictions into the required format.\n",
        "    *   Save the final predictions to `submission.csv`."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7910ecf0-d147-4427-95e3-a1652bc0a9e6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 1. Setup & Configuration ---\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_DIR = './'\n",
        "TEST_DIR = 'test/'\n",
        "TEST_PNG_3CH_DIR = 'test_png_3ch/' # For classifier\n",
        "TEST_PNG_1CH_DIR = 'test_png/'     # For YOLOv5 detector\n",
        "\n",
        "N_SPLITS = 5\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Classifier Config\n",
        "IMG_SIZE_CLS = 512\n",
        "MODEL_NAME_CLS = 'tf_efficientnet_b5_ns'\n",
        "NUM_CLASSES_CLS = 4\n",
        "CLASSIFIER_MODEL_PATHS = [f'classifier_fold{i}_best.pth' for i in range(N_SPLITS)]\n",
        "BATCH_SIZE_CLS = 32\n",
        "\n",
        "# Detector Config (YOLOv5)\n",
        "IMG_SIZE_DET = 640\n",
        "DETECTOR_MODEL_PATH = 'yolov5_runs/train/baseline_fold0/weights/best.pt'\n",
        "BATCH_SIZE_DET = 8 # Reduced from 16 to prevent OOM\n",
        "CONF_TH = 0.001 # YOLOv5 confidence threshold\n",
        "\n",
        "# Add yolov5 to path\n",
        "sys.path.append('yolov5')\n",
        "\n",
        "print(f\"Setup complete. Using device: {DEVICE}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "id": "5234a910-df75-4825-8a17-12f1c247f440",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 2. Load Metadata ---\n",
        "\n",
        "df_sub = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
        "\n",
        "# Create image-level and study-level test dataframes\n",
        "df_sub['image_id'] = df_sub['id'].apply(lambda x: x.replace('_image', '') if '_image' in x else '')\n",
        "df_sub['StudyInstanceUID'] = df_sub['id'].apply(lambda x: x.replace('_study', '') if '_study' in x else '')\n",
        "\n",
        "df_test_img = df_sub[df_sub['image_id'] != ''].copy()\n",
        "df_test_study = df_sub[df_sub['StudyInstanceUID'] != ''].copy()\n",
        "\n",
        "# Get image paths and merge study info\n",
        "test_png_paths = glob.glob(f'{TEST_PNG_3CH_DIR}/*.png')\n",
        "image_id_to_path = {os.path.basename(p).replace('.png', ''): p for p in test_png_paths}\n",
        "df_test_img['filepath'] = df_test_img['image_id'].map(image_id_to_path)\n",
        "\n",
        "# Get StudyInstanceUID for each image_id from the test folder structure\n",
        "test_dcm_files = glob.glob(f'{TEST_DIR}/*/*/*.dcm')\n",
        "image_id_to_study_uid = {\n",
        "    os.path.basename(p).replace('.dcm', ''): p.split('/')[-3] for p in test_dcm_files\n",
        "}\n",
        "df_test_img['StudyInstanceUID'] = df_test_img['image_id'].map(image_id_to_study_uid)\n",
        "\n",
        "print(f\"Found {len(df_test_img)} test images.\")\n",
        "print(f\"Found {len(df_test_study)} test studies.\")\n",
        "display(df_test_img.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 638 test images.\nFound 606 test studies.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                     id PredictionString      image_id StudyInstanceUID  \\\n606  004cbd797cd1_image   none 1 0 0 1 1  004cbd797cd1     30e45593ba08   \n607  008ca392cff3_image   none 1 0 0 1 1  008ca392cff3     39a80a14bfda   \n608  00b8180bd3a8_image   none 1 0 0 1 1  00b8180bd3a8     dadc2e3842e5   \n609  00e3a7e91a34_image   none 1 0 0 1 1  00e3a7e91a34     74ba8f2badcb   \n610  0124f624dacb_image   none 1 0 0 1 1  0124f624dacb     0acf45b01bdf   \n\n                          filepath  \n606  test_png_3ch/004cbd797cd1.png  \n607  test_png_3ch/008ca392cff3.png  \n608  test_png_3ch/00b8180bd3a8.png  \n609  test_png_3ch/00e3a7e91a34.png  \n610  test_png_3ch/0124f624dacb.png  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>PredictionString</th>\n      <th>image_id</th>\n      <th>StudyInstanceUID</th>\n      <th>filepath</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>606</th>\n      <td>004cbd797cd1_image</td>\n      <td>none 1 0 0 1 1</td>\n      <td>004cbd797cd1</td>\n      <td>30e45593ba08</td>\n      <td>test_png_3ch/004cbd797cd1.png</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>008ca392cff3_image</td>\n      <td>none 1 0 0 1 1</td>\n      <td>008ca392cff3</td>\n      <td>39a80a14bfda</td>\n      <td>test_png_3ch/008ca392cff3.png</td>\n    </tr>\n    <tr>\n      <th>608</th>\n      <td>00b8180bd3a8_image</td>\n      <td>none 1 0 0 1 1</td>\n      <td>00b8180bd3a8</td>\n      <td>dadc2e3842e5</td>\n      <td>test_png_3ch/00b8180bd3a8.png</td>\n    </tr>\n    <tr>\n      <th>609</th>\n      <td>00e3a7e91a34_image</td>\n      <td>none 1 0 0 1 1</td>\n      <td>00e3a7e91a34</td>\n      <td>74ba8f2badcb</td>\n      <td>test_png_3ch/00e3a7e91a34.png</td>\n    </tr>\n    <tr>\n      <th>610</th>\n      <td>0124f624dacb_image</td>\n      <td>none 1 0 0 1 1</td>\n      <td>0124f624dacb</td>\n      <td>0acf45b01bdf</td>\n      <td>test_png_3ch/0124f624dacb.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "id": "7a8059d4-609e-4f68-95bd-9cb8486cd02a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 3. Classifier Inference ---\n",
        "\n",
        "# --- Dataset and Transforms (adapted from training) ---\n",
        "class SIIMCVClassifierDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.image_ids = df['image_id'].values\n",
        "        self.filepaths = df['filepath'].values\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.filepaths[idx]\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        return image, self.image_ids[idx]\n",
        "\n",
        "def get_cls_test_transforms(img_size):\n",
        "    return A.Compose([\n",
        "        A.Resize(img_size, img_size),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "# --- Inference Function ---\n",
        "def run_classifier_inference(df_test, model_paths):\n",
        "    test_dataset = SIIMCVClassifierDataset(df_test, TEST_PNG_3CH_DIR, transform=get_cls_test_transforms(IMG_SIZE_CLS))\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_CLS, shuffle=False, num_workers=4, pin_memory=True)\n",
        "    \n",
        "    all_fold_logits = []\n",
        "    image_ids_ordered = []\n",
        "\n",
        "    for i, model_path in enumerate(model_paths):\n",
        "        print(f\"--- Running Inference with Fold {i} Model --- ({model_path})\")\n",
        "        model = timm.create_model(MODEL_NAME_CLS, pretrained=False, num_classes=NUM_CLASSES_CLS).to(DEVICE)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "        model.eval()\n",
        "\n",
        "        fold_logits = []\n",
        "        current_image_ids = []\n",
        "        with torch.no_grad():\n",
        "            for images, img_ids in tqdm(test_loader, desc=f'Fold {i} Inference'):\n",
        "                images = images.to(DEVICE, non_blocking=True)\n",
        "                with autocast():\n",
        "                    outputs = model(images)\n",
        "                fold_logits.append(outputs.cpu().numpy())\n",
        "                if i == 0: # Only need to get the order once\n",
        "                    current_image_ids.extend(img_ids)\n",
        "        \n",
        "        all_fold_logits.append(np.concatenate(fold_logits))\n",
        "        if i == 0:\n",
        "            image_ids_ordered = current_image_ids\n",
        "            \n",
        "    # Average logits across folds\n",
        "    avg_logits = np.mean(all_fold_logits, axis=0)\n",
        "    \n",
        "    # Create a dataframe with results\n",
        "    df_preds = pd.DataFrame(avg_logits, columns=['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance'])\n",
        "    df_preds['image_id'] = image_ids_ordered\n",
        "    \n",
        "    return df_preds\n",
        "\n",
        "print(\"Classifier inference functions defined.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier inference functions defined.\n"
          ]
        }
      ]
    },
    {
      "id": "bf8115b5-b394-470e-9311-a63d2eb83f5e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 4. Detector (YOLOv5) Inference ---\n",
        "\n",
        "def run_detector_inference(df_test, model_path):\n",
        "    \"\"\"Runs inference using a trained YOLOv5 model with manual batching to prevent OOM.\"\"\"\n",
        "    # Create a list of image paths for the 1-channel PNGs, which YOLOv5 was trained on.\n",
        "    image_paths = [os.path.join(TEST_PNG_1CH_DIR, f'{img_id}.png') for img_id in df_test['image_id'].values]\n",
        "    \n",
        "    print(\"Loading YOLOv5 model...\")\n",
        "    model = torch.hub.load(\n",
        "        'yolov5', \n",
        "        'custom', \n",
        "        path=model_path, \n",
        "        source='local',\n",
        "        force_reload=True\n",
        "    )\n",
        "    model.to(DEVICE)\n",
        "    model.conf = CONF_TH\n",
        "    model.iou = 0.5\n",
        "    model.agnostic = True\n",
        "    \n",
        "    print(f\"Running YOLOv5 inference on {len(image_paths)} images...\")\n",
        "    all_preds = {}\n",
        "    \n",
        "    # Manually batch the inference to avoid OOM error\n",
        "    # The torch.hub model loads all images into memory at once if given the full list.\n",
        "    for i in tqdm(range(0, len(image_paths), BATCH_SIZE_DET), desc=\"YOLOv5 Batched Inference\"):\n",
        "        batch_paths = image_paths[i : i + BATCH_SIZE_DET]\n",
        "        \n",
        "        results = model(batch_paths, size=IMG_SIZE_DET)\n",
        "        \n",
        "        preds_dfs = results.pandas().xyxy\n",
        "        \n",
        "        # The results.files attribute holds the original file paths for the batch.\n",
        "        for j, pred_df in enumerate(preds_dfs):\n",
        "            image_id = os.path.basename(results.files[j]).replace('.png', '')\n",
        "            all_preds[image_id] = pred_df[['xmin', 'ymin', 'xmax', 'ymax', 'confidence']].values\n",
        "            \n",
        "    return all_preds\n",
        "\n",
        "print(\"Detector (YOLOv5) inference functions defined.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detector (YOLOv5) inference functions defined.\n"
          ]
        }
      ]
    },
    {
      "id": "44824523-091e-4fbc-9b80-d287628bc2d1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 5. Submission Formatting ---\n",
        "\n",
        "# Map model output class names to the required submission format class names\n",
        "CLASS_NAME_MAP = {\n",
        "    'Negative for Pneumonia': 'negative',\n",
        "    'Typical Appearance': 'typical',\n",
        "    'Indeterminate Appearance': 'indeterminate',\n",
        "    'Atypical Appearance': 'atypical'\n",
        "}\n",
        "\n",
        "def format_study_prediction(df_study_preds):\n",
        "    \"\"\"Formats the study-level predictions into the required submission string.\"\"\"\n",
        "    # Find the class with the highest probability\n",
        "    pred_class_model = df_study_preds.idxmax()\n",
        "    # Map to the correct submission class name\n",
        "    pred_class_submission = CLASS_NAME_MAP[pred_class_model]\n",
        "    # Format: 'class_name 1 0 0 1 1'\n",
        "    return f\"{pred_class_submission} 1 0 0 1 1\"\n",
        "\n",
        "def format_image_prediction(preds):\n",
        "    \"\"\"Formats the image-level predictions from YOLOv5 into the required submission string.\"\"\"\n",
        "    # preds is a numpy array of [xmin, ymin, xmax, ymax, confidence]\n",
        "    if preds is None or len(preds) == 0:\n",
        "        return \"none 1 0 0 1 1\"\n",
        "        \n",
        "    pred_strings = []\n",
        "    for p in preds:\n",
        "        x_min, y_min, x_max, y_max, score = p\n",
        "        # Ensure coordinates are positive\n",
        "        x_min, y_min, x_max, y_max = max(0, x_min), max(0, y_min), max(0, x_max), max(0, y_max)\n",
        "        pred_strings.append(f\"opacity {score:.4f} {x_min:.2f} {y_min:.2f} {x_max:.2f} {y_max:.2f}\")\n",
        "    \n",
        "    return ' '.join(pred_strings)\n",
        "\n",
        "print(\"Submission formatting functions defined.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission formatting functions defined.\n"
          ]
        }
      ]
    },
    {
      "id": "08a07065-5fc3-4096-8b92-872f5b7983c1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 6. Main Execution Block ---\n",
        "\n",
        "# --- Run Classifier Inference ---\n",
        "print(\"Starting classifier inference...\")\n",
        "df_cls_preds = run_classifier_inference(df_test_img, CLASSIFIER_MODEL_PATHS)\n",
        "print(\"Classifier inference complete.\")\n",
        "\n",
        "# --- Aggregate to Study Level ---\n",
        "print(\"Aggregating classifier predictions to study level...\")\n",
        "df_cls_preds = df_cls_preds.merge(df_test_img[['image_id', 'StudyInstanceUID']], on='image_id', how='left')\n",
        "# Using max for Typical/Atypical, mean for Indeterminate, min for Negative\n",
        "df_study_preds = df_cls_preds.groupby('StudyInstanceUID').agg({\n",
        "    'Negative for Pneumonia': 'min',\n",
        "    'Typical Appearance': 'max',\n",
        "    'Indeterminate Appearance': 'mean',\n",
        "    'Atypical Appearance': 'max'\n",
        "}).reset_index()\n",
        "print(\"Study-level aggregation complete.\")\n",
        "\n",
        "# --- Run Detector Inference ---\n",
        "print(\"Starting detector inference...\")\n",
        "all_detector_preds = run_detector_inference(df_test_img, DETECTOR_MODEL_PATH)\n",
        "print(\"Detector inference complete.\")\n",
        "\n",
        "# --- Generate Submission ---\n",
        "print(\"Generating final submission file...\")\n",
        "submission_rows = []\n",
        "\n",
        "# Image-level predictions\n",
        "for image_id in tqdm(df_test_img['image_id'].values, desc=\"Processing Images\"):\n",
        "    preds = all_detector_preds.get(image_id)\n",
        "    pred_str = format_image_prediction(preds)\n",
        "    submission_rows.append({'id': f'{image_id}_image', 'PredictionString': pred_str})\n",
        "\n",
        "# Study-level predictions\n",
        "for _, row in tqdm(df_study_preds.iterrows(), total=len(df_study_preds), desc=\"Processing Studies\"):\n",
        "    study_id = row['StudyInstanceUID']\n",
        "    pred_str = format_study_prediction(row[['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']])\n",
        "    submission_rows.append({'id': f'{study_id}_study', 'PredictionString': pred_str})\n",
        "\n",
        "df_submission = pd.DataFrame(submission_rows)\n",
        "\n",
        "# --- Check for duplicate IDs before reindexing ---\n",
        "if df_submission['id'].duplicated().any():\n",
        "    print(\"!!! WARNING: Found duplicate IDs in generated submission rows before reindexing!\")\n",
        "    display(df_submission[df_submission['id'].duplicated(keep=False)])\n",
        "\n",
        "# Ensure the submission is in the same order as sample_submission.csv\n",
        "df_submission = df_submission.set_index('id')\n",
        "df_submission = df_submission.reindex(df_sub['id']).reset_index()\n",
        "\n",
        "# --- Final Check for NaNs and Fallback ---\n",
        "print(\"Checking for any null values in the final submission dataframe...\")\n",
        "if df_submission['PredictionString'].isnull().any():\n",
        "    print(\"!!! WARNING: Found null values in PredictionString column! This will cause a submission error.\")\n",
        "    print(\"Rows with null values:\")\n",
        "    display(df_submission[df_submission['PredictionString'].isnull()])\n",
        "    print(\"Filling NaNs with 'none 1 0 0 1 1' as a fallback.\")\n",
        "    df_submission['PredictionString'].fillna('none 1 0 0 1 1', inplace=True)\n",
        "else:\n",
        "    print(\"No null values found. The submission dataframe appears to be complete.\")\n",
        "\n",
        "df_submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' created successfully!\")\n",
        "display(df_submission.head())"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "id": "e7c3d1b6-e9ba-4736-a37a-16950c7537b3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- 7. Final Submission Sanity Check ---\n",
        "import pandas as pd\n",
        "\n",
        "print(\"--- Reading and Verifying Generated submission.csv ---\")\n",
        "df_check = pd.read_csv('submission.csv')\n",
        "df_sample = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "print(\"\\nMy Submission Info:\")\n",
        "df_check.info()\n",
        "\n",
        "print(\"\\nSample Submission Info:\")\n",
        "df_sample.info()\n",
        "\n",
        "print(f\"\\nMy submission has {len(df_check)} rows.\")\n",
        "print(f\"Sample submission has {len(df_sample)} rows.\")\n",
        "\n",
        "ids_match = df_check['id'].equals(df_sample['id'])\n",
        "print(f\"\\nAre the 'id' columns identical in content and order? {ids_match}\")\n",
        "\n",
        "print(\"\\nMy Submission Head:\")\n",
        "display(df_check.head())\n",
        "\n",
        "print(\"\\nMy Submission Tail:\")\n",
        "display(df_check.tail())\n",
        "\n",
        "print(\"\\nSample Submission Head:\")\n",
        "display(df_sample.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Reading and Verifying Generated submission.csv ---\n\nMy Submission Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1244 entries, 0 to 1243\nData columns (total 2 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   id                1244 non-null   object\n 1   PredictionString  1244 non-null   object\ndtypes: object(2)\nmemory usage: 19.6+ KB\n\nSample Submission Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1244 entries, 0 to 1243\nData columns (total 2 columns):\n #   Column            Non-Null Count  Dtype \n---  ------            --------------  ----- \n 0   id                1244 non-null   object\n 1   PredictionString  1244 non-null   object\ndtypes: object(2)\nmemory usage: 19.6+ KB\n\nMy submission has 1244 rows.\nSample submission has 1244 rows.\n\nAre the 'id' columns identical in content and order? True\n\nMy Submission Head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                   id    PredictionString\n0  000c9c05fd14_study   typical 1 0 0 1 1\n1  00c74279c5b7_study   typical 1 0 0 1 1\n2  00ccd633fb0e_study  negative 1 0 0 1 1\n3  00e936c58da6_study   typical 1 0 0 1 1\n4  01206a422293_study   typical 1 0 0 1 1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>PredictionString</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000c9c05fd14_study</td>\n      <td>typical 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00c74279c5b7_study</td>\n      <td>typical 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00ccd633fb0e_study</td>\n      <td>negative 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00e936c58da6_study</td>\n      <td>typical 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01206a422293_study</td>\n      <td>typical 1 0 0 1 1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nMy Submission Tail:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                      id PredictionString\n1239  ff03d1d41968_image   none 1 0 0 1 1\n1240  ff0743bee789_image   none 1 0 0 1 1\n1241  ffab0f8f27f0_image   none 1 0 0 1 1\n1242  ffbeafe30b77_image   none 1 0 0 1 1\n1243  ffe942c8655f_image   none 1 0 0 1 1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>PredictionString</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1239</th>\n      <td>ff03d1d41968_image</td>\n      <td>none 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>1240</th>\n      <td>ff0743bee789_image</td>\n      <td>none 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>1241</th>\n      <td>ffab0f8f27f0_image</td>\n      <td>none 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>1242</th>\n      <td>ffbeafe30b77_image</td>\n      <td>none 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>1243</th>\n      <td>ffe942c8655f_image</td>\n      <td>none 1 0 0 1 1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\nSample Submission Head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "                   id    PredictionString\n0  000c9c05fd14_study  negative 1 0 0 1 1\n1  00c74279c5b7_study  negative 1 0 0 1 1\n2  00ccd633fb0e_study  negative 1 0 0 1 1\n3  00e936c58da6_study  negative 1 0 0 1 1\n4  01206a422293_study  negative 1 0 0 1 1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>PredictionString</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000c9c05fd14_study</td>\n      <td>negative 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00c74279c5b7_study</td>\n      <td>negative 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00ccd633fb0e_study</td>\n      <td>negative 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00e936c58da6_study</td>\n      <td>negative 1 0 0 1 1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01206a422293_study</td>\n      <td>negative 1 0 0 1 1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}