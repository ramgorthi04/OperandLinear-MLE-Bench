{
  "cells": [
    {
      "id": "4b79670d-94e0-40ad-8836-3b3747d47fab",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Stable Baseline\n",
        "\n",
        "## Goal\n",
        "The primary goal of this notebook is to execute a complete, end-to-end training and inference pipeline without encountering the catastrophic CUDA OOM errors from the previous session. This serves as a sanity check for the environment's stability.\n",
        "\n",
        "## Strategy\n",
        "To ensure stability, we are using smaller, more memory-efficient models:\n",
        "1.  **Classifier:** `EfficientNet-B2` (a step down from the unstable `EfficientNet-B5`).\n",
        "2.  **Detector:** `YOLOv5s` (which was generally stable).\n",
        "\n",
        "The entire process will be run on a **single fold (fold 0)** for a limited number of epochs to establish a baseline and confirm the workflow is viable.\n",
        "\n",
        "## Workflow\n",
        "1.  **Setup:** Configure paths and parameters.\n",
        "2.  **Classifier Training:** Train `EfficientNet-B2` on fold 0 for 5 epochs.\n",
        "3.  **Detector Training:** Train `YOLOv5s` on fold 0 for 10 epochs.\n",
        "4.  **Inference:** Run both trained models on the test set.\n",
        "5.  **Submission:** Generate a `submission.csv` file.\n",
        "\n",
        "**Success Criterion:** The notebook completes all cells without a CUDA OOM error."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b1723b61-9d62-4415-9fd1-a3aa39c6700f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Part 1: Setup & Classifier Training ---\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import timm\n",
        "import gc\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import average_precision_score\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Configuration ---\n",
        "FOLD = 0\n",
        "TRAIN_IMAGE_DIR = 'train_png_3ch/'\n",
        "MODEL_NAME = 'efficientnet_b2'\n",
        "IMG_SIZE = 384\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "CLASSES = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "CLASSIFIER_MODEL_PATH = f'stable_classifier_fold{FOLD}.pth'\n",
        "\n",
        "print(f'Using device: {DEVICE}')\n",
        "print(f'Training classifier: {MODEL_NAME} on fold {FOLD} for {EPOCHS} epochs')\n",
        "\n",
        "# --- Data Loading ---\n",
        "df = pd.read_csv('df_train_folds.csv')\n",
        "df_train = df[df['fold'] != FOLD].reset_index(drop=True)\n",
        "df_valid = df[df['fold'] == FOLD].reset_index(drop=True)\n",
        "\n",
        "# --- Dataset ---\n",
        "class CovidStudyDataset(Dataset):\n",
        "    def __init__(self, df, image_dir):\n",
        "        self.df = df\n",
        "        self.image_dir = image_dir\n",
        "        self.labels = self.df[CLASSES].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image_path = os.path.join(self.image_dir, row['image_id'] + '.png')\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "        image = image.astype(np.float32) / 255.0\n",
        "        image = image.transpose(2, 0, 1)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        return torch.from_numpy(image), label\n",
        "\n",
        "train_dataset = CovidStudyDataset(df_train, TRAIN_IMAGE_DIR)\n",
        "valid_dataset = CovidStudyDataset(df_valid, TRAIN_IMAGE_DIR)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "# --- Training Loop ---\n",
        "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=NUM_CLASSES)\n",
        "model.to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "best_score = 0.0\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Train]'):\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(valid_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Valid]'):\n",
        "            images = images.to(DEVICE)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(images)\n",
        "            val_preds.append(torch.sigmoid(outputs).cpu().numpy())\n",
        "            val_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    val_preds = np.concatenate(val_preds)\n",
        "    val_labels = np.concatenate(val_labels)\n",
        "    score = average_precision_score(val_labels, val_preds, average='macro')\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Train Loss: {train_loss/len(train_loader):.4f}, Val mAP: {score:.4f}')\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        torch.save(model.state_dict(), CLASSIFIER_MODEL_PATH)\n",
        "        print(f'New best score: {best_score:.4f}. Model saved to {CLASSIFIER_MODEL_PATH}')\n",
        "\n",
        "print('\\nClassifier training complete.')\n",
        "del model, train_loader, valid_loader, train_dataset, valid_dataset\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\nTraining classifier: efficientnet_b2 on fold 0 for 5 epochs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AcceleratorError",
          "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# --- Training Loop ---\u001b[39;00m\n\u001b[32m     60\u001b[39m model = timm.create_model(MODEL_NAME, pretrained=\u001b[38;5;28;01mTrue\u001b[39;00m, num_classes=NUM_CLASSES)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m optimizer = torch.optim.AdamW(model.parameters(), lr=\u001b[32m1e-4\u001b[39m)\n\u001b[32m     63\u001b[39m criterion = torch.nn.BCEWithLogitsLoss()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/nn/modules/module.py:1369\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1366\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1367\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/nn/modules/module.py:928\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    932\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    933\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    938\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    939\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/nn/modules/module.py:955\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    952\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    953\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    956\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1349\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1350\u001b[39m             device,\n\u001b[32m   1351\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1352\u001b[39m             non_blocking,\n\u001b[32m   1353\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1354\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1361\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
            "\u001b[31mAcceleratorError\u001b[39m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}