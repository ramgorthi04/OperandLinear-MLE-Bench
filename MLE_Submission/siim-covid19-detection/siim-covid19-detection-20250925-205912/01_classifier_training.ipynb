{
  "cells": [
    {
      "id": "30d0d04e-a0cb-4059-886b-a5a0352bd26b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "# Set this before importing PyTorch to reduce memory fragmentation, as suggested by the OOM error message and expert advice.\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "print(f\"PYTORCH_CUDA_ALLOC_CONF set to: {os.environ.get('PYTORCH_CUDA_ALLOC_CONF')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "5ea30c9a-b322-436e-addb-7e06fcdb8541",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SIIM-COVID19: Classifier Training\n",
        "\n",
        "This notebook focuses on the second part of the two-model pipeline: training an image classifier for the study-level task.\n",
        "\n",
        "## Plan\n",
        "1.  **Setup:** Load data and define configurations.\n",
        "2.  **Dataset & DataLoaders:** Create a PyTorch `Dataset` to load the pre-processed PNG images and their corresponding study-level labels.\n",
        "3.  **Model Definition:** Use `timm` to create a pre-trained EfficientNet model.\n",
        "4.  **Training Loop:** Implement a standard training and validation loop.\n",
        "5.  **Train Model:** Train the classifier on a single fold to establish a baseline."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "e2641b87-10a1-40d3-9b88-af2f54d21809",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import torch\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_DIR = './'\n",
        "PNG_DIR = 'train_png/'\n",
        "N_SPLITS = 5\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"timm version: {timm.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c3013172-8478-44ab-af18-3ed24a409a93",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Load Data and Create Folds ---\n",
        "print(\"Loading and preparing metadata...\")\n",
        "\n",
        "# Load original data\n",
        "df_study = pd.read_csv(os.path.join(DATA_DIR, 'train_study_level.csv'))\n",
        "df_image = pd.read_csv(os.path.join(DATA_DIR, 'train_image_level.csv'))\n",
        "\n",
        "# Clean up IDs and merge\n",
        "df_study['StudyInstanceUID'] = df_study['id'].apply(lambda x: x.replace('_study', ''))\n",
        "df_image['image_id'] = df_image['id'].apply(lambda x: x.replace('_image', ''))\n",
        "df_merged = df_image.merge(df_study, on='StudyInstanceUID', how='left')\n",
        "\n",
        "# Add image path\n",
        "df_merged['image_path'] = df_merged['image_id'].apply(lambda x: os.path.join(PNG_DIR, f\"{x}.png\"))\n",
        "\n",
        "# Create a single target column for stratification and labels\n",
        "label_cols = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\n",
        "df_merged['label_name'] = df_merged[label_cols].idxmax(axis=1)\n",
        "label_map = {name: i for i, name in enumerate(label_cols)}\n",
        "df_merged['label_id'] = df_merged['label_name'].map(label_map)\n",
        "\n",
        "# Create Folds (reproducing the exact same folds as in the detector notebook)\n",
        "df_folds = df_merged.drop_duplicates('StudyInstanceUID').reset_index(drop=True)\n",
        "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
        "groups = df_folds['StudyInstanceUID']\n",
        "y_stratify = df_folds['label_name']\n",
        "df_folds['fold'] = -1\n",
        "for fold, (train_idx, val_idx) in enumerate(sgkf.split(df_folds, y_stratify, groups)):\n",
        "    df_folds.loc[val_idx, 'fold'] = fold\n",
        "\n",
        "# Merge fold info back into the main dataframe\n",
        "df_merged = df_merged.merge(df_folds[['StudyInstanceUID', 'fold']], on='StudyInstanceUID', how='left')\n",
        "\n",
        "print(\"Data loaded and folds created.\")\n",
        "print(f\"Total images: {len(df_merged)}\")\n",
        "print(\"Fold distribution:\")\n",
        "print(df_merged['fold'].value_counts())\n",
        "df_merged.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "8070606b-4d5c-4b05-be53-0a0a74513a6e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import cv2\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# --- Dataset Class ---\n",
        "class SIIMClassifierDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df\n",
        "        self.image_paths = df['image_path'].values\n",
        "        self.labels = df['label_id'].values\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- Augmentations ---\n",
        "def get_transforms(img_size, is_train=True):\n",
        "    if is_train:\n",
        "        return A.Compose([\n",
        "            A.Resize(img_size, img_size),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "            A.RandomBrightnessContrast(p=0.5),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            A.Resize(img_size, img_size),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "print(\"Dataset class and augmentation functions defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "8860fbc8-a7be-479b-92bd-c8b005897881",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Create DataLoaders ---\n",
        "IMG_SIZE = 512\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 4\n",
        "FOLD_TO_TRAIN = 0\n",
        "\n",
        "print(f\"Preparing DataLoaders for Fold {FOLD_TO_TRAIN}...\")\n",
        "\n",
        "# Get data for the specific fold\n",
        "df_train = df_merged[df_merged['fold'] != FOLD_TO_TRAIN].reset_index(drop=True)\n",
        "df_val = df_merged[df_merged['fold'] == FOLD_TO_TRAIN].reset_index(drop=True)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SIIMClassifierDataset(df_train, transform=get_transforms(IMG_SIZE, is_train=True))\n",
        "val_dataset = SIIMClassifierDataset(df_val, transform=get_transforms(IMG_SIZE, is_train=False))\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c138059f-2d99-4a2f-a797-9a1fe3754cd6",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Model, Loss, Optimizer ---\n",
        "MODEL_NAME = 'tf_efficientnet_b4_ns'\n",
        "NUM_CLASSES = 4\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Creating model: {MODEL_NAME}\")\n",
        "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=NUM_CLASSES)\n",
        "model.to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "print(f\"Model loaded on {device}\")\n",
        "print(f\"Loss function: CrossEntropyLoss\")\n",
        "print(f\"Optimizer: AdamW with LR={LEARNING_RATE}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "102af91c-3ac0-44b6-ba85-0a7b19b06788",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "def train_one_epoch(model, train_loader, optimizer, criterion, device, scaler):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "    for images, labels in progress_bar:\n",
        "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "        \n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        \n",
        "        with autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "        \n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def validate_one_epoch(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
        "        for images, labels in progress_bar:\n",
        "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "            \n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            all_preds.append(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "            all_labels.append(labels.cpu().numpy())\n",
        "            \n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    \n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    \n",
        "    try:\n",
        "        auc_score = roc_auc_score(all_labels, all_preds, multi_class='ovo', labels=np.unique(all_labels))\n",
        "    except ValueError:\n",
        "        auc_score = -1\n",
        "        \n",
        "    return avg_loss, auc_score\n",
        "\n",
        "print(\"Training and validation functions defined (with AMP).\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "df9ceea5-f331-4ba1-891a-574eb67bb587",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n",
        "from torch.cuda.amp import GradScaler\n",
        "\n",
        "NUM_EPOCHS = 10 # Start with a reasonable number of epochs for the baseline\n",
        "BEST_MODEL_PATH = f'classifier_fold{FOLD_TO_TRAIN}_best.pth'\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "scaler = GradScaler()\n",
        "\n",
        "print(\"--- Starting Classifier Training with AMP ---\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device, scaler)\n",
        "    val_loss, val_auc = validate_one_epoch(model, val_loader, criterion, device)\n",
        "    \n",
        "    elapsed_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | \"\n",
        "          f\"Time: {elapsed_time:.0f}s | \"\n",
        "          f\"Train Loss: {train_loss:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f} | \"\n",
        "          f\"Val AUC: {val_auc:.4f}\")\n",
        "    \n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "        print(f\"  -> New best model saved to {BEST_MODEL_PATH} (Val Loss: {best_val_loss:.4f})\")\n",
        "        \n",
        "print(\"\\n--- Classifier Training Finished ---\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}