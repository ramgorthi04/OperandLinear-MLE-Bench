{
  "cells": [
    {
      "id": "5c795852-7b41-4caa-b4fa-54e32661add8",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 6: WBF Ensemble & Post-Processing Tuning\n",
        "\n",
        "The previous submission using a 5-fold YOLOv5s ensemble with NMS did not medal (offline CV `0.3156`). With limited time remaining, a full retraining of a larger model is not feasible. This notebook focuses on improving the score by optimizing the post-processing and ensembling of the *existing* YOLOv5s models.\n",
        "\n",
        "## Plan\n",
        "\n",
        "### 1. Advanced Ensemble Technique\n",
        "*   **Weighted Boxes Fusion (WBF):** Replace the simple Non-Maximum Suppression (NMS) with WBF. WBF can produce more accurate boxes by averaging the coordinates of overlapping predictions instead of just discarding them. This will be applied to the existing `oof_detector_yolov5.csv` predictions.\n",
        "\n",
        "### 2. Systematic Post-Processing Tuning\n",
        "*   **Grid Search:** Perform a grid search on the OOF predictions to find the optimal combination of hyperparameters for post-processing:\n",
        "    *   `confidence_threshold`: The minimum confidence for a box to be considered.\n",
        "    *   `wbf_iou_threshold`: The IoU threshold for WBF to merge boxes.\n",
        "    *   `negative_filter_threshold`: The classifier confidence threshold for removing boxes from 'Negative' studies.\n",
        "\n",
        "## Workflow\n",
        "1.  **Load OOF Data:** Load `oof_detector_yolov5.csv` and `oof_classifier.csv`.\n",
        "2.  **Install WBF:** Add a cell to `pip install ensemble-boxes`.\n",
        "3.  **Implement Tuning Loop:** Create a CV calculation cell that:\n",
        "    *   Loops through different hyperparameter values (`conf_threshold`, `wbf_iou_threshold`, `negative_filter_threshold`).\n",
        "    *   For each combination:\n",
        "        *   Filters detector predictions by `conf_threshold`.\n",
        "        *   Applies classifier filtering using `negative_filter_threshold`.\n",
        "        *   Applies WBF using `wbf_iou_threshold`.\n",
        "        *   Calculates the blended mAP score.\n",
        "4.  **Identify Best Parameters:** Select the parameter set that yields the highest offline blended CV score.\n",
        "5.  **Generate New Submission:** Create a new submission notebook that uses these optimal parameters."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "df8cf254-2fc4-4b6c-8e76-b4fba7e18d18",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install --quiet ensemble-boxes"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udd27 Intercepting pip install command: pip install --quiet ensemble-boxes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u2705 Package installation completed and import cache refreshed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/pandas-2.3.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pandas already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/dateutil already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/six-1.17.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/six.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tzdata-2025.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tzdata already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pytz-2025.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pytz already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "id": "465f092e-4c68-4fec-af7d-f78517da71c8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --- Part 2: Hyperparameter Tuning (Confidence & Classifier Filter) ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "\n",
        "# --- Helper Functions for mAP Calculation (from notebook 05) ---\n",
        "def calculate_iou(box1, box2):\n",
        "    x1_inter = max(box1[0], box2[0])\n",
        "    y1_inter = max(box1[1], box2[1])\n",
        "    x2_inter = min(box1[2], box2[2])\n",
        "    y2_inter = min(box1[3], box2[3])\n",
        "    inter_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    if union_area == 0: return 0.0\n",
        "    return inter_area / union_area\n",
        "\n",
        "def calculate_ap_per_class(gt_boxes, pred_boxes, iou_threshold=0.5):\n",
        "    if not pred_boxes:\n",
        "        return 0.0 if gt_boxes else 1.0\n",
        "    pred_boxes = sorted(pred_boxes, key=lambda x: x[4], reverse=True)\n",
        "    true_positives = np.zeros(len(pred_boxes))\n",
        "    false_positives = np.zeros(len(pred_boxes))\n",
        "    num_gt_boxes = len(gt_boxes)\n",
        "    gt_matched = [False] * num_gt_boxes\n",
        "    for i, pred_box in enumerate(pred_boxes):\n",
        "        best_iou = 0\n",
        "        best_gt_idx = -1\n",
        "        for j, gt_box in enumerate(gt_boxes):\n",
        "            iou = calculate_iou(pred_box[:4], gt_box)\n",
        "            if iou > best_iou:\n",
        "                best_iou = iou\n",
        "                best_gt_idx = j\n",
        "        if best_iou >= iou_threshold and best_gt_idx != -1 and not gt_matched[best_gt_idx]:\n",
        "            true_positives[i] = 1\n",
        "            gt_matched[best_gt_idx] = True\n",
        "        else:\n",
        "            false_positives[i] = 1\n",
        "    cum_tp = np.cumsum(true_positives)\n",
        "    cum_fp = np.cumsum(false_positives)\n",
        "    recalls = cum_tp / num_gt_boxes if num_gt_boxes > 0 else np.zeros_like(cum_tp)\n",
        "    precisions = cum_tp / (cum_tp + cum_fp)\n",
        "    precisions = np.concatenate(([0.], precisions, [0.]))\n",
        "    recalls = np.concatenate(([0.], recalls, [1.]))\n",
        "    for i in range(len(precisions) - 2, -1, -1):\n",
        "        precisions[i] = max(precisions[i], precisions[i + 1])\n",
        "    ap = 0.0\n",
        "    for i in range(len(recalls) - 1):\n",
        "        if recalls[i+1] != recalls[i]:\n",
        "            ap += (recalls[i+1] - recalls[i]) * precisions[i+1]\n",
        "    return ap\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "print(\"Loading OOF and ground truth data...\")\n",
        "df_gt = pd.read_csv('df_train_folds.csv')\n",
        "df_gt['image_id'] = df_gt['id'].str.replace('_image', '')\n",
        "df_clf_oof = pd.read_csv('oof_classifier.csv')\n",
        "df_det_oof = pd.read_csv('oof_detector_yolov5.csv')\n",
        "\n",
        "# Pre-process GT data for faster lookup\n",
        "image_gt = df_gt[['id', 'boxes', 'image_id']].rename(columns={'id': 'image_id_with_suffix'})\n",
        "gt_boxes_map = {}\n",
        "for _, row in tqdm(image_gt.iterrows(), total=len(image_gt), desc=\"Processing GT boxes\"):\n",
        "    gt_boxes = []\n",
        "    if isinstance(row['boxes'], str) and row['boxes'].startswith('['):\n",
        "        try:\n",
        "            boxes_list = ast.literal_eval(row['boxes'])\n",
        "            for box in boxes_list:\n",
        "                gt_boxes.append([box['x'], box['y'], box['x'] + box['width'], box['y'] + box['height']])\n",
        "        except (ValueError, SyntaxError): pass\n",
        "    gt_boxes_map[row['image_id']] = gt_boxes\n",
        "\n",
        "# Pre-process classifier OOF and merge with detector OOF\n",
        "classes = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\n",
        "df_clf_oof_img = df_clf_oof.rename(columns={c: f'pred_{c}' for c in classes})\n",
        "df_det_oof_with_clf = df_det_oof.merge(df_clf_oof_img[['image_id', 'pred_Negative for Pneumonia']], on='image_id', how='left')\n",
        "\n",
        "# --- 2. Define Hyperparameter Grid ---\n",
        "conf_thresholds = [0.01, 0.05, 0.1, 0.15, 0.2, 0.25]\n",
        "neg_filter_thresholds = [0.4, 0.5, 0.6, 0.7, 0.8, 1.0] # 1.0 means no filtering\n",
        "\n",
        "# --- 3. Run Tuning Loop ---\n",
        "results = []\n",
        "study_map = 0.3537 # From previous notebook run, this is constant\n",
        "print(f\"Using pre-calculated Study mAP: {study_map:.4f}\")\n",
        "\n",
        "param_grid = list(itertools.product(conf_thresholds, neg_filter_thresholds))\n",
        "\n",
        "for conf_th, neg_th in tqdm(param_grid, desc=\"Tuning Hyperparameters\"):\n",
        "    # Filter by confidence\n",
        "    df_det_conf_filtered = df_det_oof_with_clf[df_det_oof_with_clf['confidence'] > conf_th]\n",
        "    \n",
        "    # Filter by classifier prediction\n",
        "    df_det_postprocessed = df_det_conf_filtered[df_det_conf_filtered['pred_Negative for Pneumonia'] < neg_th]\n",
        "    \n",
        "    # Group predictions by image_id for faster lookup\n",
        "    preds_by_image = df_det_postprocessed.groupby('image_id')[['x_min', 'y_min', 'x_max', 'y_max', 'confidence']].apply(lambda x: x.values.tolist()).to_dict()\n",
        "\n",
        "    # Calculate image mAP\n",
        "    ap_scores = []\n",
        "    for image_id in image_gt['image_id'].unique():\n",
        "        gt_boxes = gt_boxes_map.get(image_id, [])\n",
        "        pred_boxes = preds_by_image.get(image_id, [])\n",
        "        ap = calculate_ap_per_class(gt_boxes, pred_boxes, iou_threshold=0.5)\n",
        "        ap_scores.append(ap)\n",
        "    \n",
        "    image_map = np.mean(ap_scores)\n",
        "    blended_map = (study_map + image_map) / 2\n",
        "    \n",
        "    results.append({\n",
        "        'conf_th': conf_th,\n",
        "        'neg_th': neg_th,\n",
        "        'image_map': image_map,\n",
        "        'blended_map': blended_map\n",
        "    })\n",
        "\n",
        "# --- 4. Analyze Results ---\n",
        "df_results = pd.DataFrame(results)\n",
        "best_result = df_results.loc[df_results['blended_map'].idxmax()]\n",
        "\n",
        "print(\"\\n--- Tuning Results ---\")\n",
        "print(df_results.sort_values('blended_map', ascending=False).to_string())\n",
        "\n",
        "print(\"\\n--- Best Parameters ---\")\n",
        "print(best_result)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading OOF and ground truth data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing GT boxes:   0%|          | 0/5696 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing GT boxes:  37%|\u2588\u2588\u2588\u258b      | 2116/5696 [00:00<00:00, 21148.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing GT boxes:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 4269/5696 [00:00<00:00, 21370.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing GT boxes: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5696/5696 [00:00<00:00, 21299.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pre-calculated Study mAP: 0.3537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning Hyperparameters:   0%|          | 0/36 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning Hyperparameters:   3%|\u258e         | 1/36 [00:00<00:15,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning Hyperparameters:   6%|\u258c         | 2/36 [00:00<00:15,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning Hyperparameters:   8%|\u258a         | 3/36 [00:01<00:15,  2.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning Hyperparameters:  11%|\u2588         | 4/36 [00:01<00:15,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning Hyperparameters:  14%|\u2588\u258d        | 5/36 [00:02<00:14,  2.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning Hyperparameters:  17%|\u2588\u258b        | 6/36 [00:02<00:14,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning Hyperparameters:  25%|\u2588\u2588\u258c       | 9/36 [00:03<00:06,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning Hyperparameters:  33%|\u2588\u2588\u2588\u258e      | 12/36 [00:03<00:03,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning Hyperparameters:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 29/36 [00:03<00:00, 28.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTuning Hyperparameters: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 36/36 [00:03<00:00, 10.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n--- Tuning Results ---\n    conf_th  neg_th  image_map  blended_map\n15     0.10     0.7   0.322200     0.337950\n14     0.10     0.6   0.322112     0.337906\n13     0.10     0.5   0.322112     0.337906\n12     0.10     0.4   0.322112     0.337906\n17     0.10     1.0   0.322024     0.337862\n16     0.10     0.8   0.322024     0.337862\n18     0.15     0.4   0.320503     0.337101\n23     0.15     1.0   0.320503     0.337101\n21     0.15     0.7   0.320503     0.337101\n20     0.15     0.6   0.320503     0.337101\n19     0.15     0.5   0.320503     0.337101\n22     0.15     0.8   0.320503     0.337101\n26     0.20     0.6   0.319698     0.336699\n27     0.20     0.7   0.319698     0.336699\n28     0.20     0.8   0.319698     0.336699\n29     0.20     1.0   0.319698     0.336699\n24     0.20     0.4   0.319698     0.336699\n25     0.20     0.5   0.319698     0.336699\n30     0.25     0.4   0.318996     0.336348\n31     0.25     0.5   0.318996     0.336348\n32     0.25     0.6   0.318996     0.336348\n33     0.25     0.7   0.318996     0.336348\n34     0.25     0.8   0.318996     0.336348\n35     0.25     1.0   0.318996     0.336348\n6      0.05     0.4   0.284679     0.319189\n7      0.05     0.5   0.279763     0.316732\n8      0.05     0.6   0.277437     0.315568\n9      0.05     0.7   0.275593     0.314647\n10     0.05     0.8   0.273487     0.313593\n11     0.05     1.0   0.272609     0.313154\n0      0.01     0.4   0.159673     0.256687\n1      0.01     0.5   0.119707     0.236704\n2      0.01     0.6   0.094462     0.224081\n3      0.01     0.7   0.075837     0.214769\n4      0.01     0.8   0.065739     0.209719\n5      0.01     1.0   0.059827     0.206764\n\n--- Best Parameters ---\nconf_th        0.10000\nneg_th         0.70000\nimage_map      0.32220\nblended_map    0.33795\nName: 15, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}