{
  "cells": [
    {
      "id": "74b6726b-e757-4876-bc0f-9917f3f7e0bc",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Labels\n",
        "labels = ['patient_overall', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']\n",
        "\n",
        "# Compute Laplace-smoothed priors\n",
        "priors = {}\n",
        "for label in labels:\n",
        "    pos = train[label].sum()\n",
        "    total = len(train)\n",
        "    prior = (pos + 1) / (total + 2)\n",
        "    priors[label] = prior\n",
        "    print(f'{label}: {prior:.4f}')\n",
        "\n",
        "# Map to test\n",
        "submission = test.copy()\n",
        "submission['fractured'] = submission['prediction_type'].map(priors)\n",
        "\n",
        "# Clip probabilities\n",
        "submission['fractured'] = submission['fractured'].clip(1e-6, 1 - 1e-6)\n",
        "\n",
        "# Save submission\n",
        "submission[['row_id', 'fractured']].to_csv('submission.csv', index=False)\n",
        "print('\\nSubmission saved. Shape:', submission.shape)\n",
        "print('\\nSubmission head:')\n",
        "print(submission.head())\n",
        "\n",
        "# Simulate CV log loss on train (using priors as predictions)\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "train_preds = np.column_stack([train[label].map(lambda x: priors[label]) for label in labels])\n",
        "train_true = train[labels].values\n",
        "\n",
        "# Weighted log loss: patient_overall weight 2, others 1\n",
        "weights = np.array([2.0] + [1.0] * 7)\n",
        "per_label_ll = [log_loss(train_true[:, i], train_preds[:, i]) for i in range(8)]\n",
        "weighted_ll = np.average(per_label_ll, weights=weights)\n",
        "print(f'\\nSimulated weighted log loss on train: {weighted_ll:.4f}')\n",
        "\n",
        "# Note: This is not true CV, but gives baseline metric"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patient_overall: 0.4657\nC1: 0.1029\nC2: 0.1471\nC3: 0.0490\nC4: 0.0588\nC5: 0.1127\nC6: 0.1716\nC7: 0.1667\n\nSubmission saved. Shape: (14536, 4)\n\nSubmission head:\n            StudyInstanceUID  prediction_type  \\\n0   1.2.826.0.1.3680043.6200  patient_overall   \n1  1.2.826.0.1.3680043.27262  patient_overall   \n2  1.2.826.0.1.3680043.12351  patient_overall   \n3   1.2.826.0.1.3680043.1363  patient_overall   \n4   1.2.826.0.1.3680043.4859  patient_overall   \n\n                                      row_id  fractured  \n0   1.2.826.0.1.3680043.6200_patient_overall   0.465686  \n1  1.2.826.0.1.3680043.27262_patient_overall   0.465686  \n2  1.2.826.0.1.3680043.12351_patient_overall   0.465686  \n3   1.2.826.0.1.3680043.1363_patient_overall   0.465686  \n4   1.2.826.0.1.3680043.4859_patient_overall   0.465686  \n\nSimulated weighted log loss on train: 0.4170\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}