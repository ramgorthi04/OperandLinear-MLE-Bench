{
  "cells": [
    {
      "id": "ed7e5fd6-e9ee-4590-810a-47b1452a514c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, subprocess\n",
        "# Reduce fragmentation\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Kill all other GPU users (keep current PID)\n",
        "try:\n",
        "    me = str(os.getpid())\n",
        "    out = subprocess.check_output(\n",
        "        ['nvidia-smi','--query-compute-apps=pid','--format=csv,noheader']\n",
        "    ).decode().strip().splitlines()\n",
        "    for pid in out:\n",
        "        pid = pid.strip()\n",
        "        if pid and pid != me:\n",
        "            try: os.kill(int(pid), 9)\n",
        "            except: pass\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'monai', 'scikit-image', 'pydicom', '-q'])\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from monai.networks.nets import ResNet\n",
        "from monai.networks.layers import Norm\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.metrics import log_loss\n",
        "from scipy.special import expit as sigmoid\n",
        "import gc\n",
        "import SimpleITK as sitk\n",
        "from scipy.ndimage import zoom\n",
        "import pydicom\n",
        "import copy\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "# Safer kernels + TF32\n",
        "try:\n",
        "    torch.backends.cuda.enable_flash_sdp(False)\n",
        "    torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "    torch.backends.cuda.enable_math_sdp(True)\n",
        "except Exception:\n",
        "    pass\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# Fixed-window normalization\n",
        "def win_norm(v, c, w):\n",
        "    lo, hi = c - w/2, c + w/2\n",
        "    v = np.clip(v, lo, hi)\n",
        "    return (v - lo) / (hi - lo + 1e-6)\n",
        "\n",
        "# Precompute cached 2-channel volumes (soft + bone) with ROI crop\n",
        "print('Checking/Precomputing 128^3 2-channel (soft+bone) fixed-window volumes with ROI...')\n",
        "cache_dir = 'temp_3d_vols'\n",
        "train_df = pd.read_csv('train.csv')\n",
        "image_dir = 'train_images'\n",
        "# Filter to imaged studies only\n",
        "train_df = train_df[train_df['StudyInstanceUID'].apply(lambda u: os.path.isdir(os.path.join(image_dir, str(u))))].reset_index(drop=True)\n",
        "label_cols = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']\n",
        "y = train_df[label_cols].values.astype(np.float32)\n",
        "y_overall = y.max(axis=1).astype(np.float32)\n",
        "precompute_needed = True\n",
        "if os.path.exists(cache_dir):\n",
        "    cached_files = set(f[:-4] for f in os.listdir(cache_dir) if f.endswith('.npy'))\n",
        "    uids_set = set(train_df['StudyInstanceUID'])\n",
        "    if cached_files == uids_set:\n",
        "        print('Cache complete, skipping precompute.')\n",
        "        precompute_needed = False\n",
        "if precompute_needed:\n",
        "    print('Precomputing...')\n",
        "    os.system('rm -rf temp_3d_vols')\n",
        "    os.makedirs('temp_3d_vols', exist_ok=True)\n",
        "    for uid in tqdm(train_df['StudyInstanceUID']):\n",
        "        uid_dir = os.path.join(image_dir, uid)\n",
        "        if not os.path.exists(uid_dir):\n",
        "            print(f'Skipping missing {uid}')\n",
        "            continue\n",
        "        series_reader = sitk.ImageSeriesReader()\n",
        "        series_ids = series_reader.GetGDCMSeriesIDs(uid_dir)\n",
        "        if not series_ids:\n",
        "            print(f'No series for {uid}')\n",
        "            continue\n",
        "        # Prefer bone-kernel series\n",
        "        best_dicom_names = None\n",
        "        max_slices = 0\n",
        "        bone_score = 0\n",
        "        for sid in series_ids:\n",
        "            dicom_names = series_reader.GetGDCMSeriesFileNames(uid_dir, sid)\n",
        "            if len(dicom_names) < 50: continue  # Skip thin series if too few\n",
        "            # Check first DICOM for kernel\n",
        "            try:\n",
        "                ds = pydicom.dcmread(dicom_names[0])\n",
        "                kernel = ds.get((0x0018, 0x1210), '').value if hasattr(ds.get((0x0018, 0x1210), ''), 'value') else ''\n",
        "                filter_type = ds.get((0x0028, 0x0060), '').value if hasattr(ds.get((0x0028, 0x0060), ''), 'value') else ''\n",
        "                is_bone = ('BONE' in str(kernel).upper() or 'B70' in str(kernel) or 'B75' in str(kernel) or 'CB' in str(filter_type))\n",
        "                score = 100 if is_bone else 0\n",
        "            except:\n",
        "                score = 0\n",
        "            score += len(dicom_names)\n",
        "            if score > bone_score:\n",
        "                bone_score = score\n",
        "                best_dicom_names = dicom_names\n",
        "                max_slices = len(dicom_names)\n",
        "        if best_dicom_names is None:\n",
        "            continue\n",
        "        reader = sitk.ImageSeriesReader()\n",
        "        reader.SetFileNames(best_dicom_names)\n",
        "        img = reader.Execute()\n",
        "        # Resample to 1.0mm isotropic\n",
        "        orig_spacing = np.array(img.GetSpacing())[::-1]  # (Z,Y,X)\n",
        "        orig_size = np.array(img.GetSize())[::-1]  # (Z,Y,X)\n",
        "        new_spacing = np.array([1.0, 1.0, 1.0])\n",
        "        new_size = np.round(orig_size * orig_spacing / new_spacing).astype(int)\n",
        "        resampler = sitk.ResampleImageFilter()\n",
        "        resampler.SetOutputSpacing(new_spacing[::-1].tolist())\n",
        "        resampler.SetSize(new_size[::-1].tolist())\n",
        "        resampler.SetOutputOrigin(img.GetOrigin())\n",
        "        resampler.SetOutputDirection(img.GetDirection())\n",
        "        resampler.SetInterpolator(sitk.sitkLinear)\n",
        "        resampled_img = resampler.Execute(img)\n",
        "        vol_hu = sitk.GetArrayFromImage(resampled_img)  # (Z, Y, X)\n",
        "        if vol_hu.size == 0:\n",
        "            print(f'Empty volume for {uid}; skipping')\n",
        "            continue\n",
        "        # Cervical ROI crop using bone mask\n",
        "        bone_mask = (vol_hu > 200).astype(np.float32)\n",
        "        z_profile = bone_mask.sum(axis=(1,2))\n",
        "        total_bone = z_profile.sum()\n",
        "        if total_bone > 0:\n",
        "            z_com = np.average(np.arange(len(z_profile)), weights=z_profile)\n",
        "            start_z = max(0, int(z_com - 64))\n",
        "            end_z = min(len(vol_hu), int(z_com + 64))\n",
        "            vol_roi = vol_hu[start_z:end_z]\n",
        "            if len(vol_roi) < 128:\n",
        "                need = 128 - len(vol_roi)\n",
        "                pad0, pad1 = need // 2, need - need // 2\n",
        "                vol_roi = np.pad(vol_roi, ((pad0, pad1), (0,0), (0,0)), mode='constant', constant_values=0)\n",
        "        else:\n",
        "            # Fallback to central crop\n",
        "            z_mid = len(vol_hu) // 2\n",
        "            start_z = max(0, z_mid - 64)\n",
        "            end_z = min(len(vol_hu), z_mid + 64)\n",
        "            vol_roi = vol_hu[start_z:end_z]\n",
        "            if len(vol_roi) < 128:\n",
        "                need = 128 - len(vol_roi)\n",
        "                pad0, pad1 = need // 2, need - need // 2\n",
        "                vol_roi = np.pad(vol_roi, ((pad0, pad1), (0,0), (0,0)), mode='constant', constant_values=0)\n",
        "        # Resize to 128^3\n",
        "        target_size = (128, 128, 128)\n",
        "        zoom_factors = [ts / s for ts, s in zip(target_size, vol_roi.shape)]\n",
        "        vol_soft = zoom(win_norm(vol_roi, 40, 400), zoom_factors, order=1)\n",
        "        vol_bone = zoom(win_norm(vol_roi, 300, 1500), zoom_factors, order=1)\n",
        "        volume = np.stack([vol_soft, vol_bone], 0).astype(np.float32)  # (2, Z, Y, X)\n",
        "        volume = np.ascontiguousarray(volume)\n",
        "        np.save(os.path.join('temp_3d_vols', f'{uid}.npy'), volume)\n",
        "# Enforce cache exists\n",
        "have = train_df['StudyInstanceUID'].map(lambda u: os.path.exists(os.path.join(cache_dir, f'{u}.npy')))\n",
        "train_df = train_df[have].reset_index(drop=True)\n",
        "y = train_df[label_cols].values.astype(np.float32)\n",
        "y_overall = y.max(axis=1).astype(np.float32)\n",
        "np.save('oof_uids_3d.npy', train_df['StudyInstanceUID'].values)\n",
        "print('Precompute complete. Filtered to', len(train_df), 'studies.')\n",
        "class RSNA3DDataset(Dataset):\n",
        "    def __init__(self, df, cache_dir, is_train=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.cache_dir = cache_dir\n",
        "        self.is_train = is_train\n",
        "        self.label_cols = label_cols\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        uid = row['StudyInstanceUID']\n",
        "        volume_path = os.path.join(self.cache_dir, f'{uid}.npy')\n",
        "        volume = np.ascontiguousarray(np.load(volume_path))\n",
        "        if self.is_train:\n",
        "            # existing flips/rot90\n",
        "            if np.random.rand() < 0.5:\n",
        "                volume = np.ascontiguousarray(np.flip(volume, axis=2))  # Y (axis=2 for (C,Z,Y,X))\n",
        "            if np.random.rand() < 0.5:\n",
        "                volume = np.ascontiguousarray(np.flip(volume, axis=3))  # X (axis=3)\n",
        "            if np.random.rand() < 0.5:\n",
        "                k = np.random.randint(1, 4)\n",
        "                volume = np.ascontiguousarray(np.rot90(volume, k=k, axes=(2, 3)))  # Y, X\n",
        "            # z-shift along Z (axis=1 for (C,Z,Y,X))\n",
        "            if np.random.rand() < 0.5:\n",
        "                dz = np.random.randint(-8, 9)\n",
        "                volume = np.roll(volume, shift=dz, axis=1)\n",
        "            # intensity jitter\n",
        "            if np.random.rand() < 0.8:\n",
        "                alpha = 1.0 + np.random.uniform(-0.10, 0.10)\n",
        "                beta  = np.random.uniform(-0.05, 0.05)\n",
        "                volume = np.clip(volume * alpha + beta, 0.0, 1.0)\n",
        "            # tiny Gaussian noise\n",
        "            if np.random.rand() < 0.5:\n",
        "                noise = np.random.normal(0, 0.01, size=volume.shape).astype(np.float32)\n",
        "                volume = np.clip(volume + noise, 0.0, 1.0)\n",
        "        volume = np.ascontiguousarray(volume)\n",
        "        volume = volume.copy()\n",
        "        volume = torch.from_numpy(volume).float()\n",
        "        labels7 = row[self.label_cols].values.astype(np.float32)\n",
        "        any_label = np.float32(labels7.max())\n",
        "        labels = torch.tensor(np.concatenate([labels7, [any_label]]), dtype=torch.float32)\n",
        "        return {'image': volume, 'label': labels}\n",
        "\n",
        "# Helper to replace BatchNorm with GroupNorm\n",
        "def replace_bn_with_gn(module, default_groups=8):\n",
        "    for name, child in list(module.named_children()):\n",
        "        if isinstance(child, (nn.BatchNorm3d, nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "            C = child.num_features\n",
        "            g = min(default_groups, C)\n",
        "            while g > 1 and C % g != 0:\n",
        "                g -= 1\n",
        "            setattr(module, name, nn.GroupNorm(g, C, eps=child.eps, affine=True))\n",
        "        else:\n",
        "            replace_bn_with_gn(child, default_groups)\n",
        "\n",
        "# Helper to replace BatchNorm with InstanceNorm\n",
        "def replace_bn_with_in(module):\n",
        "    for name, child in list(module.named_children()):\n",
        "        if isinstance(child, nn.BatchNorm3d):\n",
        "            C = child.num_features\n",
        "            inorm = nn.InstanceNorm3d(C, eps=child.eps, momentum=child.momentum, affine=True, track_running_stats=False)\n",
        "            setattr(module, name, inorm)\n",
        "        else:\n",
        "            replace_bn_with_in(child)\n",
        "\n",
        "# Checkpointed ResNet\n",
        "class CheckpointedResNet(ResNet):\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.conv1(x); x = self.bn1(x); x = self.act(x)\n",
        "        if not self.no_max_pool: x = self.maxpool(x)\n",
        "        x = checkpoint(self.layer1, x, use_reentrant=False)\n",
        "        x = checkpoint(self.layer2, x, use_reentrant=False)\n",
        "        x = checkpoint(self.layer3, x, use_reentrant=False)\n",
        "        x = checkpoint(self.layer4, x, use_reentrant=False)\n",
        "        x = self.avgpool(x); x = torch.flatten(x, 1); x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Model: MONAI 3D ResNet18 with GroupNorm3d (affine=True) and dropout\n",
        "def build_3d_resnet(use_gn=True):\n",
        "    model = CheckpointedResNet(\n",
        "        spatial_dims=3,\n",
        "        n_input_channels=2,\n",
        "        num_classes=8,                        # 8 outputs (C1..C7 + any)\n",
        "        block='basic',\n",
        "        layers=(2, 2, 2, 2),                 # ResNet18 depth\n",
        "        block_inplanes=(48, 96, 192, 384),  # reduced for memory\n",
        "        norm=Norm.BATCH,\n",
        "    )\n",
        "    if use_gn:\n",
        "        replace_bn_with_gn(model, default_groups=8)   # recommended\n",
        "    else:\n",
        "        replace_bn_with_in(model)                     # InstanceNorm(affine=True)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(nn.Dropout(0.2), nn.Linear(in_features, 8))\n",
        "    model = model.to(device)  # move AFTER replacements\n",
        "    return model\n",
        "\n",
        "# Training params (ACCUM_STEPS=8 for memory safety)\n",
        "N_FOLDS = 5\n",
        "BATCH_SIZE = 1\n",
        "VAL_BATCH_SIZE = 1\n",
        "NUM_EPOCHS = 40\n",
        "LR = 3e-4\n",
        "PATIENCE = 12\n",
        "SEED = 792\n",
        "ACCUM_STEPS = 8\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Data\n",
        "y_overall = y.max(axis=1).astype(int)\n",
        "groups = train_df['StudyInstanceUID'].values\n",
        "cache_dir = 'temp_3d_vols'\n",
        "\n",
        "# Compute clamped pos_weight\n",
        "col_sums7 = y.sum(axis=0)\n",
        "pos_weight7 = (len(train_df) - col_sums7) / np.clip(col_sums7, 1, None)\n",
        "pos_weight7 = np.clip(pos_weight7, 1, 4)\n",
        "pos_any = (len(train_df) - y_overall.sum()) / max(y_overall.sum(), 1.0)\n",
        "pos_any = np.clip(pos_any, 1, 4)\n",
        "pos_weight = torch.tensor(np.concatenate([pos_weight7, [pos_any]]), dtype=torch.float32).to(device)\n",
        "\n",
        "# SGKF\n",
        "skf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "# OOF logits\n",
        "oof_logits = np.zeros((len(train_df), 8), dtype=np.float32)\n",
        "fold_scores = []\n",
        "\n",
        "# LR lambda for warmup + cosine\n",
        "def lr_lambda(epoch):\n",
        "    if epoch < 5:\n",
        "        return (epoch + 1) / 5.0\n",
        "    else:\n",
        "        return 0.5 * (1 + np.cos(np.pi * (epoch - 5) / max(1, NUM_EPOCHS - 5)))\n",
        "\n",
        "for fold in range(1, N_FOLDS + 1):\n",
        "    print(f'\\n=== Fold {fold}/{N_FOLDS} ===')\n",
        "    train_idx, val_idx = list(skf.split(train_df, y_overall, groups))[fold - 1]\n",
        "    train_ds = RSNA3DDataset(train_df.iloc[train_idx], cache_dir, is_train=True)\n",
        "    val_ds = RSNA3DDataset(train_df.iloc[val_idx], cache_dir, is_train=False)\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
        "    model = build_3d_resnet(use_gn=True)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    scaler = None  # No GradScaler for bfloat16\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            images = batch['image'].to(device, non_blocking=True)\n",
        "            labels = batch['label'].to(device, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n",
        "                logits = model(images)\n",
        "                loss = criterion(logits, labels) / ACCUM_STEPS\n",
        "            loss.backward()\n",
        "            if (batch_idx + 1) % ACCUM_STEPS == 0 or (batch_idx + 1) == len(train_loader):\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "            train_loss += loss.item() * ACCUM_STEPS\n",
        "        train_loss /= len(train_loader)\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                images = batch['image'].to(device, non_blocking=True)\n",
        "                labels = batch['label'].to(device, non_blocking=True)\n",
        "                with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n",
        "                    logits = model(images)\n",
        "                    loss = criterion(logits, labels)\n",
        "                val_loss += loss.item()\n",
        "        val_loss /= len(val_loader)\n",
        "        scheduler.step()\n",
        "        print(f'Epoch {epoch+1}: Train {train_loss:.4f}, Val {val_loss:.4f}')\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            best_model_state = copy.deepcopy({k: v.detach().cpu() for k, v in model.state_dict().items()})\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= PATIENCE:\n",
        "                print(f'Early stopping at epoch {epoch+1}')\n",
        "                break\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        torch.save(model.state_dict(), f'fold_{fold}_3d_resnet.pth')\n",
        "    else:\n",
        "        print(f'No best model for fold {fold}')\n",
        "        continue\n",
        "    # OOF with 3-way TTA: orig + flips on dims 3,4 (Y,X)\n",
        "    model.eval()\n",
        "    fold_oof_logits = []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            images = batch['image'].to(device, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda', dtype=torch.bfloat16):\n",
        "                logits_list = [model(images)]\n",
        "                # Flip Y (dim=3)\n",
        "                logits_list.append(model(torch.flip(images, dims=[3])))\n",
        "                # Flip X (dim=4)\n",
        "                logits_list.append(model(torch.flip(images, dims=[4])))\n",
        "                logits_avg = torch.stack(logits_list).mean(0)\n",
        "            fold_oof_logits.append(logits_avg.cpu().numpy())\n",
        "    fold_oof = np.concatenate(fold_oof_logits, axis=0)\n",
        "    oof_logits[val_idx] = fold_oof\n",
        "    # Fold WLL\n",
        "    p8 = sigmoid(fold_oof)\n",
        "    fold_y7 = y[val_idx]\n",
        "    fold_y_any = y_overall[val_idx].astype(int)\n",
        "    vert_losses = [log_loss(fold_y7[:, i], p8[:, i], labels=[0,1]) for i in range(7)]\n",
        "    overall_loss = log_loss(fold_y_any, p8[:, 7], labels=[0,1])\n",
        "    fold_score = np.average(vert_losses + [overall_loss], weights=[1]*7 + [2])\n",
        "    fold_scores.append(fold_score)\n",
        "    print(f'Fold {fold} full WLL: {fold_score:.4f}')\n",
        "    del model, train_loader, val_loader, train_ds, val_ds\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Save OOF\n",
        "np.save('oof_logits_3d_2ch.npy', oof_logits)\n",
        "\n",
        "# CV WLL\n",
        "cv_wll = np.mean(fold_scores)\n",
        "print(f'5-fold CV full WLL: {cv_wll:.4f} (target ~0.45, leakage-free)')\n",
        "p8_oof = sigmoid(oof_logits)\n",
        "vert_losses = [log_loss(y[:, i], p8_oof[:, i], labels=[0,1]) for i in range(7)]\n",
        "overall_loss = log_loss(y_overall.astype(int), p8_oof[:, 7], labels=[0,1])\n",
        "cv_wll = np.average(vert_losses + [overall_loss], weights=[1]*7 + [2])\n",
        "print('Vertebrae-only OOF WLL:', np.mean(vert_losses))\n",
        "print('''Improved 3D ResNet18 2ch with GroupNorm3d (affine=True), ROI crop, 1.0mm resample, bone series pref, clamped pos_weight, LR warmup+cosine, dropout=0.2, 8-heads, reduced channels, augs, bfloat16, checkpointing complete. OOF oof_logits_3d_2ch.npy (N,8). Next: execute 03 cell 8 gate vs 4-way 0.4197 (expect CV~0.44 gain>0.001 accept), if yes execute cell 1 5-way submission OOF<=0.41, submit_final_answer medal.''')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchaudio 2.4.1+cu121 requires torch==2.4.1, but you have torch 2.8.0 which is incompatible.\ndatasets 2.21.0 requires fsspec[http]<=2024.6.1,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\nWARNING: Target directory /app/.pip-target/monai-1.5.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tests already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/monai already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch-2.8.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.7.3.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scikit_image-0.25.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/skimage already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/imageio-2.37.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/imageio already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/lazy_loader-0.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/lazy_loader already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.10.2.21.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.3.3.83.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.5.8.93.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy-1.16.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/scipy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tifffile-2025.9.20.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/tifffile already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton-3.4.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.8.4.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.8.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.8.93.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.8.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufile_cu12-1.13.1.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.9.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.27.3.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.8.93.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.8.90.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging-25.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/packaging already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pydicom-3.0.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pydicom already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/setuptools-80.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/setuptools already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pkg_resources already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/_distutils_hack already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/distutils-precedence.pth already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparselt_cu12-0.7.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\nChecking/Precomputing 128^3 2-channel (soft+bone) fixed-window volumes with ROI...\nCache complete, skipping precompute.\nPrecompute complete. Filtered to 202 studies.\n\n=== Fold 1/5 ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 23.72 GiB of which 398.12 MiB is free. Process 42479 has 3.88 GiB memory in use. Process 343136 has 565.00 MiB memory in use. Process 388383 has 6.64 GiB memory in use. Process 406842 has 2.90 GiB memory in use. Process 431889 has 539.00 MiB memory in use. Process 455298 has 1.20 GiB memory in use. Process 461173 has 741.00 MiB memory in use. Process 728162 has 589.00 MiB memory in use. Process 977910 has 833.00 MiB memory in use. Process 1198413 has 407.00 MiB memory in use. Process 1472380 has 2.82 GiB memory in use. Of the allocated memory 2.26 GiB is allocated by PyTorch, and 221.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 329\u001b[39m\n\u001b[32m    327\u001b[39m labels = batch[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m].to(device, non_blocking=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.amp.autocast(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m, dtype=torch.bfloat16):\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m     loss = criterion(logits, labels) / ACCUM_STEPS\n\u001b[32m    331\u001b[39m loss.backward()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 238\u001b[39m, in \u001b[36mCheckpointedResNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv1(x); x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m; x = \u001b[38;5;28mself\u001b[39m.act(x)\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.no_max_pool: x = \u001b[38;5;28mself\u001b[39m.maxpool(x)\n\u001b[32m    240\u001b[39m     x = checkpoint(\u001b[38;5;28mself\u001b[39m.layer1, x, use_reentrant=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/nn/modules/normalization.py:288\u001b[39m, in \u001b[36mGroupNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pip-target/torch/nn/functional.py:2606\u001b[39m, in \u001b[36mgroup_norm\u001b[39m\u001b[34m(input, num_groups, weight, bias, eps)\u001b[39m\n\u001b[32m   2604\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected at least 2 dimensions for input tensor but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   2605\u001b[39m _verify_batch_size([\u001b[38;5;28minput\u001b[39m.size(\u001b[32m0\u001b[39m) * \u001b[38;5;28minput\u001b[39m.size(\u001b[32m1\u001b[39m) // num_groups, num_groups] + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m.size()[\u001b[32m2\u001b[39m:]))\n\u001b[32m-> \u001b[39m\u001b[32m2606\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackends\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcudnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 23.72 GiB of which 398.12 MiB is free. Process 42479 has 3.88 GiB memory in use. Process 343136 has 565.00 MiB memory in use. Process 388383 has 6.64 GiB memory in use. Process 406842 has 2.90 GiB memory in use. Process 431889 has 539.00 MiB memory in use. Process 455298 has 1.20 GiB memory in use. Process 461173 has 741.00 MiB memory in use. Process 728162 has 589.00 MiB memory in use. Process 977910 has 833.00 MiB memory in use. Process 1198413 has 407.00 MiB memory in use. Process 1472380 has 2.82 GiB memory in use. Of the allocated memory 2.26 GiB is allocated by PyTorch, and 221.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}