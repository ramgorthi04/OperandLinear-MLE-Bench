{
  "cells": [
    {
      "id": "bab2d4a8-272d-42ed-af55-a732bbc40e55",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, cv2, numpy as np, pandas as pd, torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "device = torch.device('cuda')\n",
        "label_cols = ['C1','C2','C3','C4','C5','C6','C7']\n",
        "\n",
        "train_df = pd.read_csv('data/train_mips.csv')             # StudyInstanceUID + labels\n",
        "y_df = pd.read_csv('train.csv')                           # StudyInstanceUID + C1..C7\n",
        "bbox_df = pd.read_csv('train_bounding_boxes.csv')         # must include StudyInstanceUID, vertebra in C1..C7, and box columns\n",
        "mip_root = 'data/mips/train'\n",
        "\n",
        "# Debug: Print columns of bbox_df\n",
        "print('Bounding boxes columns:', bbox_df.columns.tolist())\n",
        "print('First few rows:'); print(bbox_df.head())\n",
        "\n",
        "def normalize_boxes(df, img_size=384):\n",
        "    df = df.copy()\n",
        "    if all(c in df.columns for c in ['x1','y1','x2','y2']):\n",
        "        print('Using x1,y1,x2,y2 format')\n",
        "        pass\n",
        "    elif all(c in df.columns for c in ['x','y','width','height']):\n",
        "        print('Using x,y,width,height format')\n",
        "        df['w'] = df['width']\n",
        "        df['h'] = df['height']\n",
        "        # assume pixels; if normalized, multiply by 384 here\n",
        "        df['x1'] = df['x'] - df['w']/2.0\n",
        "        df['y1'] = df['y'] - df['h']/2.0\n",
        "        df['x2'] = df['x'] + df['w']/2.0\n",
        "        df['y2'] = df['y'] + df['h']/2.0\n",
        "    elif all(c in df.columns for c in ['x','y','w','h']):\n",
        "        print('Using x,y,w,h format')\n",
        "        # assume pixels; if normalized, multiply by 384 here\n",
        "        df['x1'] = df['x'] - df['w']/2.0\n",
        "        df['y1'] = df['y'] - df['h']/2.0\n",
        "        df['x2'] = df['x'] + df['w']/2.0\n",
        "        df['y2'] = df['y'] + df['h']/2.0\n",
        "    else:\n",
        "        print('Available columns:', df.columns.tolist())\n",
        "        raise ValueError('train_bounding_boxes.csv must have x1,y1,x2,y2 or x,y,width,height or x,y,w,h')\n",
        "    for c in ['x1','x2','y1','y2']: df[c] = df[c].clip(0, img_size-1)\n",
        "    return df\n",
        "\n",
        "bbox_df = normalize_boxes(bbox_df)\n",
        "\n",
        "def make_patch_index(train_df, y_df, bbox_df, img_size=384, expand=1.5, min_side=96, target=224):\n",
        "    lbl = train_df[['StudyInstanceUID']].merge(\n",
        "        y_df[['StudyInstanceUID'] + label_cols], on='StudyInstanceUID', how='left'\n",
        "    ).set_index('StudyInstanceUID')\n",
        "    rows = []\n",
        "    for uid, g in bbox_df.groupby('StudyInstanceUID'):\n",
        "        if uid not in lbl.index:\n",
        "            continue\n",
        "        y7 = lbl.loc[uid, label_cols].values.astype(int)\n",
        "\n",
        "        if {'x1','x2','y1','y2'}.issubset(g.columns):\n",
        "            xs = ((g['x1'] + g['x2']) / 2.0).values\n",
        "            ys = ((g['y1'] + g['y2']) / 2.0).values\n",
        "            w_arr = (g['x2'] - g['x1']).values\n",
        "            h_arr = (g['y2'] - g['y1']).values\n",
        "        else:\n",
        "            xs = g['x'].values\n",
        "            ys = g['y'].values\n",
        "            w_arr = g['width'].values\n",
        "            h_arr = g['height'].values\n",
        "\n",
        "        if len(xs) >= 5:\n",
        "            x_c = float(np.median(xs))\n",
        "            y_lo, y_hi = np.quantile(ys, [0.02, 0.98])\n",
        "            base_side = float(np.median(np.maximum(w_arr, h_arr)))\n",
        "        else:\n",
        "            x_c = img_size / 2.0\n",
        "            y_lo, y_hi = img_size * 0.1, img_size * 0.9\n",
        "            base_side = img_size * 0.25\n",
        "\n",
        "        side = int(max(min_side, base_side * expand))\n",
        "        for i, v in enumerate(label_cols):\n",
        "            y_c = float(y_lo + (i + 0.5) * (y_hi - y_lo) / 7.0)\n",
        "            x1 = int(np.clip(x_c - side / 2, 0, img_size - 1))\n",
        "            y1 = int(np.clip(y_c - side / 2, 0, img_size - 1))\n",
        "            x2 = x1 + side\n",
        "            y2 = y1 + side\n",
        "            if x2 > img_size: x1 -= (x2 - img_size); x2 = img_size\n",
        "            if y2 > img_size: y1 -= (y2 - img_size); y2 = img_size\n",
        "            x1 = max(0, x1); y1 = max(0, y1)\n",
        "            rows.append(dict(StudyInstanceUID=uid, v=v, v_idx=i, y=int(y7[i]),\n",
        "                             x1=x1, y1=y1, x2=x2, y2=y2, target=target))\n",
        "    df = pd.DataFrame(rows)\n",
        "    if df.empty:\n",
        "        raise RuntimeError('make_patch_index produced no rows. Check bbox_df content.')\n",
        "    return df\n",
        "\n",
        "patch_idx = make_patch_index(train_df, y_df, bbox_df)\n",
        "\n",
        "class PatchDataset(Dataset):\n",
        "    def __init__(self, patch_idx, mip_root, transform=None, jitter=0.1):\n",
        "        self.df = patch_idx.reset_index(drop=True)\n",
        "        self.root = mip_root\n",
        "        self.tfm = transform\n",
        "        self.jitter = jitter\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        arr = np.load(os.path.join(self.root, f'{r.StudyInstanceUID}.npy')).astype(np.float32)[0]\n",
        "        x1,y1,x2,y2 = int(r.x1),int(r.y1),int(r.x2),int(r.y2)\n",
        "        # jitter box\n",
        "        cx = (x1+x2)/2; cy=(y1+y2)/2; side = max(x2-x1, y2-y1)\n",
        "        cx += np.random.uniform(-side*self.jitter, side*self.jitter)\n",
        "        cy += np.random.uniform(-side*self.jitter, side*self.jitter)\n",
        "        scale = np.random.uniform(1-self.jitter, 1+self.jitter)\n",
        "        side = int(side*scale)\n",
        "        x1 = int(max(0, cx - side/2)); y1 = int(max(0, cy - side/2))\n",
        "        x2 = x1 + side; y2 = y1 + side\n",
        "        x2 = min(x2, arr.shape[1]); y2 = min(y2, arr.shape[0])\n",
        "        crop = arr[y1:y2, x1:x2]\n",
        "        crop = cv2.resize(crop, (r.target, r.target), interpolation=cv2.INTER_LINEAR)\n",
        "        img = np.stack([crop,crop,crop], axis=2)\n",
        "        if self.tfm: img = self.tfm(image=img)['image']\n",
        "        y = torch.tensor([r.y], dtype=torch.float32)\n",
        "        meta = {'uid': r.StudyInstanceUID, 'v_idx': int(r.v_idx)}\n",
        "        return img, y, meta\n",
        "\n",
        "train_tfm = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=15, p=0.8),\n",
        "    A.RandomBrightnessContrast(0.15, 0.15, p=0.5),\n",
        "    A.Normalize(mean=0.5, std=0.5),\n",
        "    ToTensorV2()\n",
        "])\n",
        "val_tfm = A.Compose([A.Normalize(mean=0.5, std=0.5), ToTensorV2()])\n",
        "\n",
        "def build_model():\n",
        "    return timm.create_model('tf_efficientnet_b0_ns', pretrained=True, in_chans=3, num_classes=1, drop_rate=0.2, drop_path_rate=0.1).to(device)\n",
        "\n",
        "mlskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "X_ids = train_df[['StudyInstanceUID']]\n",
        "y7 = X_ids.merge(y_df[['StudyInstanceUID']+label_cols], on='StudyInstanceUID', how='left')[label_cols].values\n",
        "\n",
        "oof_patch = np.zeros((len(train_df), 7), np.float32)\n",
        "\n",
        "for fold,(tr,va) in enumerate(mlskf.split(X_ids, y7),1):\n",
        "    tr_uids = set(X_ids.iloc[tr]['StudyInstanceUID'])\n",
        "    va_uids = set(X_ids.iloc[va]['StudyInstanceUID'])\n",
        "    tr_idx = patch_idx[patch_idx['StudyInstanceUID'].isin(tr_uids)]\n",
        "    va_idx = patch_idx[patch_idx['StudyInstanceUID'].isin(va_uids)]\n",
        "    tr_ds = PatchDataset(tr_idx, mip_root, train_tfm, jitter=0.2)\n",
        "    va_ds = PatchDataset(va_idx, mip_root, val_tfm, jitter=0.0)\n",
        "    # balance positives\n",
        "    wts = np.where(tr_idx['y'].values==1, 3.0, 1.0).astype(np.float32)\n",
        "    sampler = WeightedRandomSampler(torch.from_numpy(wts), num_samples=len(wts), replacement=True)\n",
        "    tr_loader = DataLoader(tr_ds, batch_size=64, sampler=sampler, num_workers=4, pin_memory=True)\n",
        "    va_loader = DataLoader(va_ds, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "    model = build_model()\n",
        "    opt = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "    sch = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=2, min_lr=1e-6)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([2.0], device=device))\n",
        "\n",
        "    best = (1e9, None)\n",
        "    for epoch in range(8):\n",
        "        model.train(); tr_loss=0\n",
        "        for img,y,meta_batch in tr_loader:\n",
        "            img=img.to(device); y=y.to(device).squeeze(1)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logit = model(img).squeeze(1)\n",
        "            loss = criterion(logit, y)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "            tr_loss += loss.item()*img.size(0)\n",
        "        # val aggregate to study x 7\n",
        "        model.eval()\n",
        "        m = {}\n",
        "        with torch.no_grad():\n",
        "            for img,y,meta_batch in va_loader:\n",
        "                logit = model(img.to(device)).squeeze(1)\n",
        "                p = torch.sigmoid(logit).cpu().numpy()\n",
        "                uids = meta_batch['uid']\n",
        "                vidxs = meta_batch['v_idx']\n",
        "                for j in range(len(p)):\n",
        "                    uid = uids[j]\n",
        "                    i = int(vidxs[j].item()) if torch.is_tensor(vidxs[j]) else int(vidxs[j])\n",
        "                    m.setdefault(uid, {k:[] for k in range(7)})[i].append(float(p[j]))\n",
        "        va_ids = X_ids.iloc[va]['StudyInstanceUID'].tolist()\n",
        "        val_mat = np.zeros((len(va_ids),7), np.float32)\n",
        "        for a,uid in enumerate(va_ids):\n",
        "            for i in range(7): \n",
        "                xs = m.get(uid,{}).get(i,[])\n",
        "                val_mat[a,i] = np.mean(xs) if xs else 0.0\n",
        "        # quick early-stop by overall WLL\n",
        "        y_true = y_df.set_index('StudyInstanceUID').loc[va_ids, label_cols].values\n",
        "        overall = val_mat.max(1, keepdims=True)\n",
        "        wll = np.average([log_loss(y_true[:,i], val_mat[:,i], labels=[0,1]) for i in range(7)] + [log_loss(y_true.max(1), overall[:,0], labels=[0,1])], weights=[1]*7+[2])\n",
        "        sch.step(wll)\n",
        "        if wll < best[0]: best = (wll, model.state_dict())\n",
        "        print(f'Fold {fold} Epoch {epoch+1}: Val WLL={wll:.4f}')\n",
        "    torch.save(best[1], f'patch_fold_{fold}.pth')\n",
        "\n",
        "    # fill OOF\n",
        "    model.load_state_dict(best[1]); model.eval()\n",
        "    m = {}\n",
        "    with torch.no_grad():\n",
        "        for img,y,meta_batch in va_loader:\n",
        "            logit = model(img.to(device)).squeeze(1)\n",
        "            p = torch.sigmoid(logit).cpu().numpy()\n",
        "            uids = meta_batch['uid']\n",
        "            vidxs = meta_batch['v_idx']\n",
        "            for j in range(len(p)):\n",
        "                uid = uids[j]\n",
        "                i = int(vidxs[j].item()) if torch.is_tensor(vidxs[j]) else int(vidxs[j])\n",
        "                m.setdefault(uid, {k:[] for k in range(7)})[i].append(float(p[j]))\n",
        "    for uid in X_ids.iloc[va]['StudyInstanceUID']:\n",
        "        ridx = train_df.index[train_df['StudyInstanceUID']==uid][0]\n",
        "        arr = np.zeros(7, np.float32)\n",
        "        for i in range(7):\n",
        "            xs = m.get(uid, {}).get(i, [])\n",
        "            arr[i] = np.mean(xs) if xs else 0.0\n",
        "        oof_patch[ridx] = arr\n",
        "\n",
        "patch_oof_df = train_df[['StudyInstanceUID']].copy()\n",
        "patch_oof_df[label_cols] = oof_patch\n",
        "patch_oof_df['patient_overall'] = oof_patch.max(axis=1)\n",
        "patch_oof_df.to_csv('oof_patch_probs.csv', index=False)\n",
        "p_clip = np.clip(oof_patch, 1e-6, 1 - 1e-6)\n",
        "np.save('oof_logits_patch.npy', np.log(p_clip / (1.0 - p_clip)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bounding boxes columns: ['StudyInstanceUID', 'x', 'y', 'width', 'height', 'slice_number']\nFirst few rows:\n            StudyInstanceUID      x      y  width  height  slice_number\n0  1.2.826.0.1.3680043.12152  177.0  242.0  107.0    96.0           330\n1  1.2.826.0.1.3680043.12152  178.0  243.0  106.0    94.0           331\n2  1.2.826.0.1.3680043.12152  180.0  244.0  104.0    92.0           332\n3  1.2.826.0.1.3680043.12152  181.0  244.0  102.0    91.0           333\n4  1.2.826.0.1.3680043.12152  182.0  245.0  101.0    89.0           334\nUsing x,y,width,height format\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 1: Val WLL=2.8165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 2: Val WLL=2.8482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 3: Val WLL=2.7971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 4: Val WLL=2.7704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 5: Val WLL=2.7190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 6: Val WLL=2.7045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 7: Val WLL=2.7228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Epoch 8: Val WLL=2.7501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 1: Val WLL=2.6302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 2: Val WLL=2.6242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 3: Val WLL=2.6230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 4: Val WLL=2.6309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 5: Val WLL=2.6653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 6: Val WLL=2.7461\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 7: Val WLL=2.7935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Epoch 8: Val WLL=2.8290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 1: Val WLL=2.3293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 2: Val WLL=2.4325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 3: Val WLL=2.4851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 4: Val WLL=2.3983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 5: Val WLL=2.3633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 6: Val WLL=2.4296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 7: Val WLL=2.4743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Epoch 8: Val WLL=2.5878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 1: Val WLL=2.1028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 2: Val WLL=2.0013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 3: Val WLL=2.0026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 4: Val WLL=2.0530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 5: Val WLL=2.0218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 6: Val WLL=2.0182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 7: Val WLL=2.0560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Epoch 8: Val WLL=2.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b0_ns to current tf_efficientnet_b0.ns_jft_in1k.\n  model = create_fn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 1: Val WLL=2.3118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 2: Val WLL=2.1934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 3: Val WLL=2.1040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 4: Val WLL=1.9848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 5: Val WLL=2.0041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 6: Val WLL=2.0059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 7: Val WLL=1.9841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Epoch 8: Val WLL=1.9808\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}