{
  "cells": [
    {
      "id": "0dd48a25-aff7-4417-8995-288e1476adf7",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.metrics import log_loss\n",
        "from scipy.special import expit as sigmoid\n",
        "import gc\n",
        "from itertools import chain\n",
        "import torch.amp as amp\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# 6-channel multi-MIP files from mip_prep.py (bone_sag, bone_cor, bone_ax, soft_ax, soft_sag, soft_cor)\n",
        "train_df = pd.read_csv('data/train_mips_multi.csv')\n",
        "multi_dir = 'data/mips_multi/train'\n",
        "\n",
        "# Labels\n",
        "label_cols = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7']\n",
        "y = train_df[label_cols].values\n",
        "y_overall = y.max(axis=1).astype(int)\n",
        "groups = train_df['StudyInstanceUID'].values\n",
        "\n",
        "# Normalization for 6-channel: replicate ImageNet avg RGB (bone/soft MIPs [0,1])\n",
        "mean = [0.485] * 6\n",
        "std = [0.229] * 6\n",
        "\n",
        "# Fixed augmentations: apply to (H,W,C=6)\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(384, 384),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.GaussianBlur(blur_limit=3, p=0.1),\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2()  # (C,H,W)\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(384, 384),\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "class MultiChannelDataset(Dataset):\n",
        "    def __init__(self, df, mip_dir, transform):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.mip_dir = mip_dir\n",
        "        self.transform = transform\n",
        "        self.label_cols = label_cols\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        uid = row['StudyInstanceUID']\n",
        "        img_path = os.path.join(self.mip_dir, f'{uid}.npy')\n",
        "        mips6 = np.load(img_path).astype(np.float32)  # (6,384,384)\n",
        "        # Transpose to (H,W,C=6) for albumentations\n",
        "        img_hwc = np.transpose(mips6, (1,2,0))\n",
        "        augmented = self.transform(image=img_hwc)['image']  # (C,H,W)\n",
        "        labels = torch.tensor(row[self.label_cols].values.astype(np.float32))\n",
        "        return augmented, labels\n",
        "\n",
        "# Training parameters - BATCH_SIZE=1, ACCUM_STEPS=8 to avoid OOM with in_chans=6\n",
        "N_FOLDS = 5\n",
        "BATCH_SIZE = 1\n",
        "VAL_BATCH_SIZE = 1\n",
        "NUM_EPOCHS = 15\n",
        "LR = 1e-4\n",
        "PATIENCE = 4\n",
        "SEED = 791\n",
        "ACCUM_STEPS = 8\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# CV splitter - FIXED: Use StratifiedGroupKFold to prevent patient leakage\n",
        "skf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "\n",
        "# OOF logits collection (will include HFlip TTA averaging)\n",
        "oof_logits = np.zeros((len(train_df), 7), dtype=np.float32)\n",
        "fold_scores = []\n",
        "\n",
        "for fold in range(1, N_FOLDS + 1):\n",
        "    print(f'\\n=== Fold {fold}/{N_FOLDS} ===')\n",
        "    train_idx, val_idx = list(skf.split(train_df, y_overall, groups))[fold-1]\n",
        "    train_ds = MultiChannelDataset(train_df.iloc[train_idx], multi_dir, train_transform)\n",
        "    val_ds = MultiChannelDataset(train_df.iloc[val_idx], multi_dir, val_transform)\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = timm.create_model('regnety_004', pretrained=True, num_classes=7, in_chans=6,\n",
        "                              drop_rate=0.3, drop_path_rate=0.15)\n",
        "    try:\n",
        "        model.set_grad_checkpointing(True)\n",
        "    except:\n",
        "        pass\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    scaler = amp.GradScaler('cuda')\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        # Train with AMP, float16, channels_last, grad accum\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
        "            imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(dtype=torch.float16):\n",
        "                logits = model(imgs)\n",
        "                loss = criterion(logits, labels) / ACCUM_STEPS\n",
        "            scaler.scale(loss).backward()\n",
        "            if (batch_idx + 1) % ACCUM_STEPS == 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "            train_loss += loss.item() * ACCUM_STEPS\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        # Val (BCE loss only, no TTA here)\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for imgs, lbls in val_loader:\n",
        "                imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "                lbls = lbls.to(device, non_blocking=True)\n",
        "                with torch.cuda.amp.autocast(dtype=torch.float16):\n",
        "                    logits = model(imgs)\n",
        "                    loss = criterion(logits, lbls)\n",
        "                val_loss += loss.item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        scheduler.step()\n",
        "        print(f'Epoch {epoch+1}: Train {train_loss:.4f}, Val {val_loss:.4f}')\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            best_model_state = model.state_dict().copy()\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= PATIENCE:\n",
        "                print(f'Early stopping at epoch {epoch+1}')\n",
        "                break\n",
        "\n",
        "    # Load best model\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        torch.save(model.state_dict(), f'fold_{fold}_regnet_multi_fixed.pth')\n",
        "    else:\n",
        "        print(f'No best model for fold {fold}')\n",
        "        continue\n",
        "\n",
        "    # Collect true OOF logits with HFlip TTA for this fold's val\n",
        "    model.eval()\n",
        "    fold_oof_logits = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in val_loader:\n",
        "            imgs = imgs.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n",
        "            with torch.cuda.amp.autocast(dtype=torch.float16):\n",
        "                logits_orig = model(imgs)\n",
        "                imgs_flip = torch.flip(imgs, dims=[3])  # HFlip on W dim (dim=3 in C,H,W)\n",
        "                logits_flip = model(imgs_flip)\n",
        "                logits_avg = 0.5 * (logits_orig + logits_flip)\n",
        "            fold_oof_logits.append(logits_avg.cpu().numpy())\n",
        "    fold_oof = np.concatenate(fold_oof_logits, axis=0)\n",
        "    oof_logits[val_idx] = fold_oof\n",
        "\n",
        "    # Fold score (full WLL with patient_overall=max(p7)) - FIXED: Add labels=[0,1]\n",
        "    p7 = sigmoid(fold_oof)\n",
        "    fold_y7 = y[val_idx]\n",
        "    fold_y_overall = fold_y7.max(axis=1).astype(int)\n",
        "    p_overall = p7.max(axis=1)\n",
        "    vert_losses = [log_loss(fold_y7[:, i], p7[:, i], labels=[0,1]) for i in range(7)]\n",
        "    overall_loss = log_loss(fold_y_overall, p_overall, labels=[0,1])\n",
        "    fold_score = np.average(vert_losses + [overall_loss], weights=[1]*7 + [2])\n",
        "    fold_scores.append(fold_score)\n",
        "    print(f'Fold {fold} full WLL: {fold_score:.4f}')\n",
        "\n",
        "    # Cleanup\n",
        "    del model, train_loader, val_loader, train_ds, val_ds, scaler\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Save OOF logits (with TTA)\n",
        "np.save('oof_logits_multi_fixed.npy', oof_logits)\n",
        "\n",
        "# Overall CV full WLL\n",
        "cv_wll = np.mean(fold_scores)\n",
        "print(f'5-fold CV full WLL: {cv_wll:.4f} (target ~0.45-0.47 standalone, leakage-free)')\n",
        "\n",
        "# Also vertebrae-only for reference - FIXED: Add labels=[0,1]\n",
        "p7_oof = sigmoid(oof_logits)\n",
        "vert_losses = [log_loss(y[:, i], p7_oof[:, i], labels=[0,1]) for i in range(7)]\n",
        "vert_wll = np.mean(vert_losses)\n",
        "print(f'Vertebrae-only OOF WLL: {vert_wll:.4f}')\n",
        "\n",
        "print('Leakage-fixed 6-channel multi-MIP training complete. OOF logits (HFlip TTA) saved as oof_logits_multi_fixed.npy. CV scores reliable (expect ~0.45 diversity from bone/soft MIPs). Next: re-execute cell 6 in 03_inference_tta.ipynb to gate \"Multi\" (add gate_model(np.load(\"oof_logits_multi_fixed.npy\"), \"Multi\")), if accepted (gain >0.001), update cell 1 for 5-way inference (add def predict_multi(ckpt_pattern): timm regnety_004 in_chans=6 load fold pth TTA HFlip mean over folds; multi_logits = predict_multi(\"fold_{}_regnet_multi_fixed.pth\"); X5 = X4_swin + s_multi * multi_logits; refit full postproc on X5 OOF stack), execute cell 1 to generate submission.csv (OOF <=0.41 target), submit_final_answer.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n\n=== Fold 1/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n  original_init(self, **validated_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:123: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:143: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train 0.5994, Val 0.5266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train 0.4272, Val 0.4216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train 0.3597, Val 0.3515\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train 0.3533, Val 0.4317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train 0.3532, Val 0.3466\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train 0.3570, Val 0.3610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train 0.3566, Val 0.3833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train 0.3516, Val 0.4016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train 0.3542, Val 0.3289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train 0.3496, Val 0.3492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train 0.3517, Val 0.3133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train 0.3550, Val 0.3500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train 0.3468, Val 0.3318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Train 0.3516, Val 0.3192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Train 0.3499, Val 0.3669\nEarly stopping at epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 full WLL: 0.4407\n\n=== Fold 2/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:123: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n/app/.pip-target/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:143: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train 0.5797, Val 0.5703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train 0.4135, Val 0.4245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train 0.3526, Val 0.4891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train 0.3461, Val 0.4081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train 0.3468, Val 0.3873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train 0.3404, Val 0.4392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train 0.3420, Val 0.3753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train 0.3424, Val 0.4060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train 0.3376, Val 0.3615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train 0.3450, Val 0.3825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train 0.3397, Val 0.3775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Train 0.3448, Val 0.3657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Train 0.3350, Val 0.3855\nEarly stopping at epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 full WLL: 0.4629\n\n=== Fold 3/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:123: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n/app/.pip-target/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:143: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train 0.5643, Val 0.6486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train 0.4127, Val 0.5934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train 0.3415, Val 0.5458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train 0.3311, Val 0.4944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train 0.3318, Val 0.4209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train 0.3310, Val 0.5273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train 0.3234, Val 0.4183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train 0.3292, Val 0.4898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train 0.3299, Val 0.4271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train 0.3218, Val 0.4367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Train 0.3211, Val 0.4193\nEarly stopping at epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 full WLL: 0.5620\n\n=== Fold 4/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:123: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n/app/.pip-target/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:143: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train 0.5952, Val 0.5228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train 0.4290, Val 0.4616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train 0.3545, Val 0.3641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train 0.3540, Val 0.3506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train 0.3466, Val 0.4262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train 0.3411, Val 0.3574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train 0.3496, Val 0.4639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train 0.3507, Val 0.3734\nEarly stopping at epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 full WLL: 0.4733\n\n=== Fold 5/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:123: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n/app/.pip-target/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:143: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train 0.6012, Val 0.5740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train 0.4309, Val 0.4391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train 0.3561, Val 0.3313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train 0.3580, Val 0.4733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train 0.3484, Val 0.3116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train 0.3436, Val 0.3851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train 0.3552, Val 0.3414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train 0.3478, Val 0.3366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train 0.3513, Val 0.3296\nEarly stopping at epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_1072429/3717605950.py:176: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 full WLL: 0.4141\n5-fold CV full WLL: 0.4706 (target ~0.45-0.47 standalone, leakage-free)\nVertebrae-only OOF WLL: 0.3769\nLeakage-fixed 6-channel multi-MIP training complete. OOF logits (HFlip TTA) saved as oof_logits_multi_fixed.npy. CV scores reliable (expect ~0.45 diversity from bone/soft MIPs). Next: re-execute cell 6 in 03_inference_tta.ipynb to gate \"Multi\" (add gate_model(np.load(\"oof_logits_multi_fixed.npy\"), \"Multi\")), if accepted (gain >0.001), update cell 1 for 5-way inference (add def predict_multi(ckpt_pattern): timm regnety_004 in_chans=6 load fold pth TTA HFlip mean over folds; multi_logits = predict_multi(\"fold_{}_regnet_multi_fixed.pth\"); X5 = X4_swin + s_multi * multi_logits; refit full postproc on X5 OOF stack), execute cell 1 to generate submission.csv (OOF <=0.41 target), submit_final_answer.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}