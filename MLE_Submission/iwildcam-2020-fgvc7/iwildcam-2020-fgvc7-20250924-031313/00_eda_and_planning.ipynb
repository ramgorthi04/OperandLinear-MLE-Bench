{
  "cells": [
    {
      "id": "094ae1a4-e195-4bb3-8a38-56c70a0148c3",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# iWildCam 2020 (FGVC7) \u2013 Medal Plan\n",
        "\n",
        "Objectives:\n",
        "- Build a robust, GPU-accelerated image classification pipeline.\n",
        "- Establish trustworthy CV mirroring test distribution (camera/location-wise).\n",
        "- Ship a strong baseline fast; iterate with augmentations, sampler, and better backbones.\n",
        "- Cache OOF/logits and ensemble diverse seeds/backbones to reach medal.\n",
        "\n",
        "Milestones:\n",
        "1) Environment & GPU gate\n",
        "   - Verify CUDA 12.1, install torch 2.4.1/cu121 + torchvision 0.19.1.\n",
        "   - Sanity-check nvidia-smi, torch.cuda, GPU name.\n",
        "\n",
        "2) Data audit & EDA\n",
        "   - Load JSONs: train annotations, test info, megadetector detections.\n",
        "   - Inspect fields: image_id \u2192 file, category_id, location/camera/site, sequence_id, empty images.\n",
        "   - Count classes, class imbalance, per-location distribution.\n",
        "   - Verify train/ test paths and file existence.\n",
        "\n",
        "3) Validation protocol\n",
        "   - Primary: GroupKFold by location/camera_id to simulate domain shift.\n",
        "   - Alternative fallback: StratifiedKFold on category with group on sequence if location missing.\n",
        "   - Fix seed and persist folds to disk.\n",
        "\n",
        "4) Baseline model (deliver ASAP)\n",
        "   - TorchVision pretrained backbone (e.g., resnet50 or efficientnet_b3).\n",
        "   - 224\u2192384 short-side resize with RandAugment/AutoAug, RandomResizedCrop, horizontal flip.\n",
        "   - Class-balanced sampler or weighted CE; label smoothing.\n",
        "   - Mixed precision, EMA, cosine LR with warmup; early stopping.\n",
        "   - Save best by val accuracy per fold.\n",
        "\n",
        "5) Iteration for gains\n",
        "   - Backbones: ConvNeXt-T/S, EfficientNetV2-S, ResNet101, NFNet-F0 (if available).\n",
        "   - Resolutions: 380\u2192448; CutMix/MixUp; stronger aug.\n",
        "   - Use MegaDetector crops (animal boxes) vs full-image; blend logits.\n",
        "   - TTA (flips, multi-scale).\n",
        "\n",
        "6) Ensembling\n",
        "   - Weighted average of fold and seed logits across backbones and crop/full variants.\n",
        "   - Calibrate (temperature scaling) on OOF if helpful.\n",
        "\n",
        "7) Submission & Error analysis\n",
        "   - Verify submission.csv format: image_id, category_id prediction.\n",
        "   - Analyze OOF by class/location; address top error buckets.\n",
        "\n",
        "Checkpoints with Expert Review:\n",
        "- After plan (this cell).\n",
        "- After EDA/validation lock-in.\n",
        "- After baseline OOF results.\n",
        "- After adding MD crops/ensembling.\n",
        "\n",
        "Risks & Mitigations:\n",
        "- Heavy training time: start with fast 224 baseline; log progress and allow early stop.\n",
        "- CV mismatch: enforce location-grouped folds; verify distribution.\n",
        "- Class imbalance: use per-class weights and/or sampler.\n",
        "\n",
        "Next action:\n",
        "- Run environment/GPU checks, list data, and parse JSON schemas; then set up folds and baseline dataloader."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "9c4ecda1-1dd1-4635-8b9e-206fedf6126c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# GPU/Env gate + quick data sanity\n",
        "import os, sys, json, time, shutil, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "def run(cmd):\n",
        "    print(\"$\", \" \".join(cmd), flush=True)\n",
        "    return subprocess.run(cmd, check=False)\n",
        "\n",
        "t0 = time.time()\n",
        "print(\"=== NVIDIA-SMI ===\", flush=True)\n",
        "run(['bash','-lc','nvidia-smi || true'])\n",
        "\n",
        "# Clean any preinstalled torch stack to avoid CUDA mismatch\n",
        "for pkg in (\"torch\",\"torchvision\",\"torchaudio\"):\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg], check=False)\n",
        "\n",
        "for d in (\n",
        "    \"/app/.pip-target/torch\",\n",
        "    \"/app/.pip-target/torchvision\",\n",
        "    \"/app/.pip-target/torchaudio\",\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print(\"Removing\", d); shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "def pip(*args):\n",
        "    print(\"> pip\", *args, flush=True)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", *args], check=True)\n",
        "\n",
        "print(\"=== Installing PyTorch cu121 stack ===\", flush=True)\n",
        "pip(\"install\",\n",
        "    \"--index-url\", \"https://download.pytorch.org/whl/cu121\",\n",
        "    \"--extra-index-url\", \"https://pypi.org/simple\",\n",
        "    \"torch==2.4.1\", \"torchvision==0.19.1\", \"torchaudio==2.4.1\")\n",
        "\n",
        "Path(\"constraints.txt\").write_text(\"torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n\")\n",
        "\n",
        "import torch\n",
        "print(\"torch:\", torch.__version__, \"built CUDA:\", getattr(torch.version, \"cuda\", None))\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f\"Wrong CUDA build: {torch.version.cuda}\"\n",
        "assert torch.cuda.is_available(), \"CUDA not available\"\n",
        "print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "print(\"=== Quick data sanity ===\", flush=True)\n",
        "base = Path('.')\n",
        "train_dir = base/\"train\"\n",
        "test_dir = base/\"test\"\n",
        "ann_path = base/\"iwildcam2020_train_annotations.json\"\n",
        "test_info_path = base/\"iwildcam2020_test_information.json\"\n",
        "sample_sub_path = base/\"sample_submission.csv\"\n",
        "\n",
        "n_train = len(os.listdir(train_dir))\n",
        "n_test = len(os.listdir(test_dir))\n",
        "print(f\"Train images: {n_train}\")\n",
        "print(f\"Test images:  {n_test}\")\n",
        "\n",
        "with open(ann_path,'r') as f:\n",
        "    ann = json.load(f)\n",
        "print(\"Annotation keys:\", list(ann.keys()))\n",
        "images = ann.get('images', [])\n",
        "annotations = ann.get('annotations', [])\n",
        "categories = ann.get('categories', [])\n",
        "print(f\"Images in JSON: {len(images)} | Annotations: {len(annotations)} | Categories: {len(categories)}\")\n",
        "cat_ids = [c.get('id') for c in categories]\n",
        "print(\"Min/Max category_id:\", min(cat_ids), max(cat_ids))\n",
        "\n",
        "with open(test_info_path,'r') as f:\n",
        "    test_info = json.load(f)\n",
        "test_images = test_info.get('images', [])\n",
        "print(f\"Test JSON images: {len(test_images)}\")\n",
        "\n",
        "import pandas as pd\n",
        "samp = pd.read_csv(sample_sub_path)\n",
        "print(\"Sample submission head:\\n\", samp.head())\n",
        "print(\"Sample submission shape:\", samp.shape)\n",
        "\n",
        "print(f\"Setup done in {time.time()-t0:.1f}s\", flush=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NVIDIA-SMI ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$ bash -lc nvidia-smi || true\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep 24 04:12:14 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchvision as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Installing PyTorch cu121 stack ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> pip install --index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.org/simple torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 423.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 457.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 408.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 66.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 86.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 151.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 348.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 481.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 435.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 55.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 60.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 65.7 MB/s eta 0:00:00\nCollecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 77.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 390.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 231.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 39.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 133.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 507.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 374.5 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 72.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 177.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 144.1 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 75.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 525.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 built CUDA: 12.1\nCUDA available: True\nGPU: NVIDIA A10-24Q\n=== Quick data sanity ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: 157199\nTest images:  60760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotation keys: ['annotations', 'images', 'categories', 'info']\nImages in JSON: 157199 | Annotations: 157199 | Categories: 267\nMin/Max category_id: 0 675\nTest JSON images: 60760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample submission head:\n                                      Id  Category\n0  879d74d8-21bc-11ea-a13a-137349068a90       559\n1  90243894-21bc-11ea-a13a-137349068a90       629\n2  944adb30-21bc-11ea-a13a-137349068a90       192\n3  8ced2424-21bc-11ea-a13a-137349068a90       359\n4  8aac3a4c-21bc-11ea-a13a-137349068a90         9\nSample submission shape: (60760, 2)\nSetup done in 76.6s\n"
          ]
        }
      ]
    },
    {
      "id": "ea9643fb-5c03-4228-aed5-6dde9d704552",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build grouped 5-fold CV (group = location + sequence), persist folds and label mapping\n",
        "import json, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "base = Path('.')\n",
        "ann_path = base/\"iwildcam2020_train_annotations.json\"\n",
        "with open(ann_path, 'r') as f:\n",
        "    ann = json.load(f)\n",
        "\n",
        "images = pd.DataFrame(ann[\"images\"]).copy()\n",
        "annots = pd.DataFrame(ann[\"annotations\"]).copy()\n",
        "cats = pd.DataFrame(ann[\"categories\"]).copy()\n",
        "print(\"images columns:\", images.columns.tolist())\n",
        "print(\"annotations columns:\", annots.columns.tolist())\n",
        "print(\"categories columns:\", cats.columns.tolist())\n",
        "\n",
        "# Merge annotation to image rows (1:1 here, annotation per image)\n",
        "df = images.merge(annots, left_on='id', right_on='image_id', how='inner')\n",
        "\n",
        "# Derive grouping keys robustly\n",
        "def pick(d, keys, default=None):\n",
        "    for k in keys:\n",
        "        if k in d and pd.notna(d[k]):\n",
        "            return d[k]\n",
        "    return default\n",
        "\n",
        "loc_key_candidates = ['location','location_id','loc']\n",
        "seq_key_candidates = ['sequence_id','seq_id','sequence','seq']\n",
        "cam_key_candidates = ['camera_id','camera','cam_id']\n",
        "\n",
        "# Apply to dataframe\n",
        "df['__location'] = df.apply(lambda r: pick(r, loc_key_candidates, 'NA_LOC'), axis=1)\n",
        "df['__sequence'] = df.apply(lambda r: pick(r, seq_key_candidates, None), axis=1)\n",
        "df['__camera'] = df.apply(lambda r: pick(r, cam_key_candidates, None), axis=1)\n",
        "\n",
        "def make_group(r):\n",
        "    loc = str(r['__location'])\n",
        "    if r['__sequence'] is not None:\n",
        "        return f\"{loc}_{r['__sequence']}\"\n",
        "    elif r['__camera'] is not None:\n",
        "        return f\"{loc}_{r['__camera']}\"\n",
        "    else:\n",
        "        return f\"{loc}_NASEQ\"\n",
        "\n",
        "df['group'] = df.apply(make_group, axis=1)\n",
        "\n",
        "# Build category_id -> index mapping using the order in categories list\n",
        "cat_ids_ordered = cats['id'].tolist()\n",
        "id2index = {int(cid): i for i, cid in enumerate(cat_ids_ordered)}\n",
        "index2id = {i: int(cid) for i, cid in enumerate(cat_ids_ordered)}\n",
        "df['label_index'] = df['category_id'].map(id2index).astype(int)\n",
        "assert df['label_index'].notnull().all(), \"Some category_ids not in mapping\"\n",
        "num_classes = len(cat_ids_ordered)\n",
        "print(\"Num classes:\", num_classes)\n",
        "\n",
        "# GroupKFold split\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "df['fold'] = -1\n",
        "for fold, (trn_idx, val_idx) in enumerate(gkf.split(df, groups=df['group'])):\n",
        "    df.loc[df.index[val_idx], 'fold'] = fold\n",
        "assert (df['fold']>=0).all(), \"Fold assignment failed\"\n",
        "\n",
        "# Quick diagnostics\n",
        "print(df.groupby('fold').size())\n",
        "print(\"Unique groups per fold:\", df.groupby('fold')['group'].nunique().to_dict())\n",
        "\n",
        "# Persist\n",
        "out_folds = base/\"folds.csv\"\n",
        "# Harmonize IDs: use image_id as the canonical image identifier; include file path fields\n",
        "df['img_id'] = df['image_id']\n",
        "cols = ['img_id','file_name','image_id','category_id','label_index','group','fold','__location','__sequence','__camera']\n",
        "df[cols].to_csv(out_folds, index=False)\n",
        "print(\"Saved folds to\", out_folds.resolve())\n",
        "\n",
        "# Save label mapping\n",
        "mapping = {\"id2index\": id2index, \"index2id\": index2id, \"num_classes\": num_classes}\n",
        "with open(base/\"label_mapping.json\", 'w') as f:\n",
        "    json.dump(mapping, f)\n",
        "print(\"Saved label_mapping.json\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images columns: ['seq_num_frames', 'location', 'datetime', 'id', 'frame_num', 'seq_id', 'width', 'height', 'file_name']\nannotations columns: ['count', 'image_id', 'id', 'category_id']\ncategories columns: ['count', 'id', 'name']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num classes: 267\nfold\n0    31440\n1    31440\n2    31440\n3    31440\n4    31439\ndtype: int64\nUnique groups per fold: {0: 3031, 1: 3032, 2: 3032, 3: 3032, 4: 3030}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved folds to /var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/folds.csv\nSaved label_mapping.json\n"
          ]
        }
      ]
    },
    {
      "id": "a4ebe48c-fbdd-421a-83f8-95248d01edb3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Strict location-only CV + diagnostics; persist as folds_location.csv\n",
        "import json, pandas as pd, numpy as np\n",
        "from pathlib import Path\n",
        "base = Path('.')\n",
        "\n",
        "df = pd.read_csv(base/\"folds.csv\")\n",
        "\n",
        "# Recreate label mapping for safety\n",
        "with open(base/\"label_mapping.json\", 'r') as f:\n",
        "    mapping = json.load(f)\n",
        "num_classes = mapping[\"num_classes\"]\n",
        "\n",
        "# Strict folds: groups = __location; prefer StratifiedGroupKFold if available\n",
        "use_sgkf = False\n",
        "try:\n",
        "    from sklearn.model_selection import StratifiedGroupKFold\n",
        "    use_sgkf = True\n",
        "except Exception:\n",
        "    from sklearn.model_selection import GroupKFold\n",
        "\n",
        "df_strict = df.copy()\n",
        "df_strict['fold'] = -1\n",
        "if use_sgkf:\n",
        "    sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    for f, (_, val_idx) in enumerate(sgkf.split(X=df_strict, y=df_strict['label_index'], groups=df_strict['__location'])):\n",
        "        df_strict.loc[val_idx, 'fold'] = f\n",
        "else:\n",
        "    gkf = GroupKFold(n_splits=5)\n",
        "    for f, (_, val_idx) in enumerate(gkf.split(df_strict, groups=df_strict['__location'])):\n",
        "        df_strict.loc[df_strict.index[val_idx], 'fold'] = f\n",
        "assert (df_strict['fold']>=0).all(), \"Strict fold assignment failed\"\n",
        "\n",
        "# Leakage guards\n",
        "# Ensure locations are not split across folds\n",
        "max_loc_folds = df_strict.groupby('__location')['fold'].nunique().max()\n",
        "print(\"Max folds per location (should be 1):\", max_loc_folds)\n",
        "assert max_loc_folds == 1, \"Location split across folds!\"\n",
        "\n",
        "# Within each location, ensure sequences are not split across folds\n",
        "if df_strict['__sequence'].notna().any():\n",
        "    grp = df_strict[df_strict['__sequence'].notna()].groupby(['__location','__sequence'])['fold'].nunique()\n",
        "    max_seq_loc = grp.max() if len(grp) else 1\n",
        "    print(\"Max folds per (location,sequence) (should be 1):\", max_seq_loc)\n",
        "    assert max_seq_loc == 1, \"A (location,sequence) group split across folds!\"\n",
        "\n",
        "# Class balance diagnostics\n",
        "ct = pd.crosstab(df_strict['fold'], df_strict['label_index'])\n",
        "per_class = (ct.max()-ct.min())/ct.replace(0, np.nan).mean()\n",
        "print(\"Per-class fold count deviation (summary):\")\n",
        "print(per_class.describe())\n",
        "missing_any = (ct==0).any()\n",
        "print(\"Any class missing in a fold?\", bool(missing_any.any()))\n",
        "\n",
        "# Location vs fold distribution summary\n",
        "loc_dist = pd.crosstab(df_strict['__location'], df_strict['fold']).sum().to_dict()\n",
        "print(\"Counts per fold (strict):\", loc_dist)\n",
        "\n",
        "# Persist strict folds\n",
        "out_strict = base/\"folds_location.csv\"\n",
        "df_strict.to_csv(out_strict, index=False)\n",
        "print(\"Saved strict location folds to\", out_strict.resolve())\n",
        "\n",
        "# Note: We'll train with strict location-only folds moving forward for honest CV. Keep folds.csv as secondary split."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:994: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max folds per location (should be 1): 1\nMax folds per (location,sequence) (should be 1): 1\nPer-class fold count deviation (summary):\ncount    185.000000\nmean       1.527365\nstd        0.642848\nmin        0.342321\n25%        1.000000\n50%        1.400000\n75%        1.871287\nmax        3.862434\ndtype: float64\nAny class missing in a fold? True\nCounts per fold (strict): {0: 20033, 1: 33416, 2: 42820, 3: 35755, 4: 25175}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved strict location folds to /var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/folds_location.csv\n"
          ]
        }
      ]
    },
    {
      "id": "e4dd5f88-c1a6-4d32-9b7e-a78ee24e77ea",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write baseline training script: ConvNeXt-Tiny @320 with strict folds\n",
        "import json, os, sys, time\n",
        "from pathlib import Path\n",
        "\n",
        "script = r'''\n",
        "import os, json, time, math, random, argparse\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as T\n",
        "import timm\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "class IWCDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, label_mapping, img_size=320, train=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.id2index = label_mapping['id2index']\n",
        "        self.train = train\n",
        "        self.size = img_size\n",
        "        self.mean = (0.485,0.456,0.406); self.std = (0.229,0.224,0.225)\n",
        "        if train:\n",
        "            self.tf = T.Compose([\n",
        "                T.RandomResizedCrop(self.size, scale=(0.2,1.0), interpolation=T.InterpolationMode.BICUBIC),\n",
        "                T.RandomHorizontalFlip(),\n",
        "                T.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "                T.RandAugment(num_ops=2, magnitude=8),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(self.mean, self.std),\n",
        "            ])\n",
        "        else:\n",
        "            self.tf = T.Compose([\n",
        "                T.Resize(int(self.size*1.15), interpolation=T.InterpolationMode.BICUBIC),\n",
        "                T.CenterCrop(self.size),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(self.mean, self.std),\n",
        "            ])\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        img_path = self.img_dir / r['file_name']\n",
        "        with Image.open(img_path) as im:\n",
        "            im = im.convert('RGB')\n",
        "            x = self.tf(im)\n",
        "        y = int(r['label_index']) if 'label_index' in r and not pd.isna(r['label_index']) else -1\n",
        "        return x, y, r['img_id']\n",
        "\n",
        "def build_model(num_classes):\n",
        "    model = timm.create_model('convnext_tiny.in12k', pretrained=True, num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "def get_class_weights(df, num_classes):\n",
        "    counts = df['label_index'].value_counts().reindex(range(num_classes), fill_value=0).values.astype(np.float32)\n",
        "    counts[counts==0] = 1.0\n",
        "    weights = 1.0 / np.sqrt(counts)\n",
        "    weights = weights / weights.mean()\n",
        "    return torch.tensor(weights, dtype=torch.float32)\n",
        "\n",
        "def train_fold(args, fold, df, mapping, device):\n",
        "    num_classes = mapping['num_classes']\n",
        "    df_tr = df[df['fold']!=fold].copy()\n",
        "    df_va = df[df['fold']==fold].copy()\n",
        "    print(f\"Fold {fold}: train {len(df_tr)} | val {len(df_va)}\", flush=True)\n",
        "\n",
        "    train_ds = IWCDataset(df_tr, args.train_dir, mapping, img_size=args.img_size, train=True)\n",
        "    val_ds   = IWCDataset(df_va, args.train_dir, mapping, img_size=args.img_size, train=False)\n",
        "\n",
        "    # Use standard loader; optionally weighted CE\n",
        "    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True, drop_last=True)\n",
        "    val_loader   = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True)\n",
        "\n",
        "    model = build_model(num_classes).to(device)\n",
        "    ema_model = None\n",
        "    if args.ema:\n",
        "        ema_model = timm.utils.ModelEmaV2(model, decay=0.9998)\n",
        "\n",
        "    lr = args.lr\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=args.weight_decay)\n",
        "    lf = lambda x: 0.5*(1+math.cos(math.pi*x/args.epochs))  # cosine\n",
        "    sched = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda=lf)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=args.label_smoothing).to(device)\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=args.amp)\n",
        "    best_acc = 0.0\n",
        "    oof_logits = np.zeros((len(df_va), num_classes), dtype=np.float32)\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        t0 = time.time()\n",
        "        model.train()\n",
        "        total, correct, loss_sum = 0, 0, 0.0\n",
        "        for it,(xb,yb,_) in enumerate(train_loader):\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=args.amp):\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt); scaler.update()\n",
        "            if ema_model is not None:\n",
        "                ema_model.update(model)\n",
        "            loss_sum += loss.item()*xb.size(0)\n",
        "            preds = logits.argmax(1)\n",
        "            correct += (preds==yb).sum().item()\n",
        "            total += xb.size(0)\n",
        "            if (it+1)%100==0:\n",
        "                print(f\"Epoch {epoch+1}/{args.epochs} It {it+1} Train acc={correct/total:.4f} loss={loss_sum/total:.4f}\", flush=True)\n",
        "        sched.step()\n",
        "        # Val\n",
        "        model.eval()\n",
        "        if ema_model is not None:\n",
        "            eval_model = ema_model.module\n",
        "        else:\n",
        "            eval_model = model\n",
        "        val_total, val_correct = 0, 0\n",
        "        val_logits = []\n",
        "        with torch.no_grad():\n",
        "            for xb,yb,_ids in val_loader:\n",
        "                xb = xb.to(device, non_blocking=True); yb = yb.to(device, non_blocking=True)\n",
        "                with torch.cuda.amp.autocast(enabled=args.amp):\n",
        "                    lg = eval_model(xb)\n",
        "                val_logits.append(lg.float().cpu().numpy())\n",
        "                preds = lg.argmax(1)\n",
        "                val_correct += (preds==yb).sum().item()\n",
        "                val_total += xb.size(0)\n",
        "        val_acc = val_correct/val_total if val_total else 0.0\n",
        "        val_logits = np.concatenate(val_logits, axis=0) if len(val_logits) else np.zeros((0, num_classes), dtype=np.float32)\n",
        "        # Store OOF in original val order\n",
        "        oof_logits = val_logits\n",
        "        dt = time.time()-t0\n",
        "        print(f\"Fold {fold} Epoch {epoch+1}: val_acc={val_acc:.4f} time={dt:.1f}s\", flush=True)\n",
        "        if val_acc>best_acc:\n",
        "            best_acc=val_acc\n",
        "            ckpt = {'state_dict': model.state_dict(), 'acc': best_acc, 'epoch': epoch+1}\n",
        "            torch.save(ckpt, Path(args.out_dir)/f\"ckpt_fold{fold}.pt\")\n",
        "    # Save OOF logits\n",
        "    np.save(Path(args.out_dir)/f\"oof_logits_fold{fold}.npy\", oof_logits)\n",
        "    print(f\"Saved OOF logits for fold {fold}\", flush=True)\n",
        "\n",
        "def infer_test(args, df_test, mapping, ckpt_paths, device, tta_flip=True):\n",
        "    num_classes = mapping['num_classes']\n",
        "    class TestDS(Dataset):\n",
        "        def __init__(self, df, img_dir, size):\n",
        "            self.df=df.reset_index(drop=True); self.dir=Path(img_dir); self.size=size\n",
        "            self.mean=(0.485,0.456,0.406); self.std=(0.229,0.224,0.225)\n",
        "            self.tf = T.Compose([\n",
        "                T.Resize(int(size*1.15), interpolation=T.InterpolationMode.BICUBIC),\n",
        "                T.CenterCrop(size), T.ToTensor(), T.Normalize(self.mean,self.std) ])\n",
        "            self.tf_h = T.Compose([\n",
        "                T.Resize(int(size*1.15), interpolation=T.InterpolationMode.BICUBIC),\n",
        "                T.CenterCrop(size), T.functional.hflip, T.ToTensor(), T.Normalize(self.mean,self.std) ])\n",
        "        def __len__(self): return len(self.df)\n",
        "        def __getitem__(self, i):\n",
        "            r=self.df.iloc[i]\n",
        "            p=self.dir/r['file_name']\n",
        "            with Image.open(p) as im:\n",
        "                im=im.convert('RGB')\n",
        "                x=self.tf(im);\n",
        "                if {tta_flip}:\n",
        "                    xh=T.functional.hflip(im)\n",
        "                    xh=self.tf.transforms[0](xh) if False else None\n",
        "            return x, r['img_id']\n",
        "    # Simpler: do only no-flip to avoid complexity in script; flip TTA can be added later\n",
        "    ds = IWCDataset(df_test, args.test_dir, mapping, img_size=args.img_size, train=False)\n",
        "    loader = DataLoader(ds, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True)\n",
        "    logits_sum = np.zeros((len(df_test), num_classes), dtype=np.float32)\n",
        "    for ckpt in ckpt_paths:\n",
        "        model = build_model(num_classes).to(device)\n",
        "        sd = torch.load(ckpt, map_location='cpu')['state_dict']\n",
        "        model.load_state_dict(sd, strict=True)\n",
        "        model.eval()\n",
        "        all_logits=[]\n",
        "        with torch.no_grad():\n",
        "            for xb,_,_ids in loader:\n",
        "                xb = xb.to(device, non_blocking=True)\n",
        "                with torch.cuda.amp.autocast(enabled=args.amp):\n",
        "                    lg = model(xb)\n",
        "                all_logits.append(lg.float().cpu().numpy())\n",
        "        logits = np.concatenate(all_logits, axis=0)\n",
        "        logits_sum += logits\n",
        "    logits_avg = logits_sum/len(ckpt_paths)\n",
        "    np.save(Path(args.out_dir)/\"test_logits.npy\", logits_avg)\n",
        "    print(\"Saved test logits\", flush=True)\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument('--train_dir', default='train')\n",
        "    ap.add_argument('--test_dir', default='test')\n",
        "    ap.add_argument('--ann_train', default='iwildcam2020_train_annotations.json')\n",
        "    ap.add_argument('--test_info', default='iwildcam2020_test_information.json')\n",
        "    ap.add_argument('--folds_csv', default='folds_location.csv')\n",
        "    ap.add_argument('--mapping_json', default='label_mapping.json')\n",
        "    ap.add_argument('--out_dir', default='out_baseline')\n",
        "    ap.add_argument('--img_size', type=int, default=320)\n",
        "    ap.add_argument('--batch_size', type=int, default=64)\n",
        "    ap.add_argument('--workers', type=int, default=8)\n",
        "    ap.add_argument('--epochs', type=int, default=10)\n",
        "    ap.add_argument('--lr', type=float, default=3e-4)\n",
        "    ap.add_argument('--weight_decay', type=float, default=5e-2)\n",
        "    ap.add_argument('--label_smoothing', type=float, default=0.1)\n",
        "    ap.add_argument('--amp', action='store_true')\n",
        "    ap.add_argument('--ema', action='store_true')\n",
        "    ap.add_argument('--folds', type=str, default='0')\n",
        "    ap.add_argument('--seed', type=int, default=42)\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    set_seed(args.seed)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    Path(args.out_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    with open(args.mapping_json,'r') as f:\n",
        "        mapping = json.load(f)\n",
        "\n",
        "    df = pd.read_csv(args.folds_csv)\n",
        "    # Prepare test df\n",
        "    test_info = json.load(open(args.test_info,'r'))\n",
        "    test_images = pd.DataFrame(test_info['images'])\n",
        "    test_df = test_images[['id','file_name']].copy()\n",
        "    test_df.rename(columns={'id':'img_id'}, inplace=True)\n",
        "    # Add dummy label_index for Dataset\n",
        "    test_df['label_index'] = 0\n",
        "\n",
        "    folds = [int(f) for f in args.folds.split(',')]\n",
        "    for f in folds:\n",
        "        print(f\"=== Training fold {f} ===\", flush=True)\n",
        "        train_fold(args, f, df, mapping, device)\n",
        "\n",
        "    # Collect ckpts for provided folds\n",
        "    ckpts = [str(Path(args.out_dir)/f\"ckpt_fold{f}.pt\") for f in folds if Path(args.out_dir)/f\"ckpt_fold{f}.pt\" ]\n",
        "    if len(ckpts)>0:\n",
        "        infer_test(args, test_df, mapping, ckpts, device)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "'''\n",
        "\n",
        "Path('train_full_baseline.py').write_text(script)\n",
        "print('Wrote train_full_baseline.py')\n",
        "\n",
        "# Install deps for training\n",
        "import subprocess, sys\n",
        "def pip(*args):\n",
        "    print('> pip', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "pip('install','-c','constraints.txt','timm==1.0.9','albumentations==1.4.14','opencv-python-headless==4.10.0.84','--upgrade-strategy','only-if-needed')\n",
        "print('Deps installed')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote train_full_baseline.py\n> pip install -c constraints.txt timm==1.0.9 albumentations==1.4.14 opencv-python-headless==4.10.0.84 --upgrade-strategy only-if-needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm==1.0.9\n  Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.3/2.3 MB 30.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==1.4.14\n  Downloading albumentations-1.4.14-py3-none-any.whl (177 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 178.0/178.0 KB 365.2 MB/s eta 0:00:00\nCollecting opencv-python-headless==4.10.0.84\n  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 49.9/49.9 MB 64.5 MB/s eta 0:00:00\nCollecting huggingface_hub\n  Downloading huggingface_hub-0.35.1-py3-none-any.whl (563 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 563.3/563.3 KB 455.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision\n  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.0/7.0 MB 124.7 MB/s eta 0:00:00\nCollecting pyyaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 763.0/763.0 KB 110.8 MB/s eta 0:00:00\nCollecting safetensors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 485.8/485.8 KB 495.6 MB/s eta 0:00:00\nCollecting torch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 797.1/797.1 MB 55.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting eval-type-backport\n  Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\nCollecting scipy>=1.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading scipy-1.16.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 35.9/35.9 MB 171.1 MB/s eta 0:00:00\nCollecting typing-extensions>=4.9.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 318.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy>=1.24.4\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 32.1 MB/s eta 0:00:00\nCollecting scikit-image>=0.21.0\n  Downloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.8/14.8 MB 162.4 MB/s eta 0:00:00\nCollecting albucore>=0.0.13\n  Downloading albucore-0.0.33-py3-none-any.whl (18 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic>=2.7.0\n  Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 444.9/444.9 KB 523.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting simsimd>=5.9.2\n  Downloading simsimd-6.5.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.1/1.1 MB 91.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stringzilla>=3.10.4\n  Downloading stringzilla-4.0.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (496 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 496.5/496.5 KB 303.5 MB/s eta 0:00:00\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic-core==2.33.2\n  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 147.6 MB/s eta 0:00:00\nCollecting typing-inspection>=0.4.0\n  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\nCollecting tifffile>=2022.8.12\n  Downloading tifffile-2025.9.20-py3-none-any.whl (230 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 230.1/230.1 KB 490.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting packaging>=21\n  Downloading packaging-25.0-py3-none-any.whl (66 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 66.5/66.5 KB 411.1 MB/s eta 0:00:00\nCollecting lazy-loader>=0.4\n  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow>=10.1\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 60.6 MB/s eta 0:00:00\nCollecting networkx>=3.0\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 283.3 MB/s eta 0:00:00\nCollecting imageio!=2.35.0,>=2.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 315.8/315.8 KB 78.3 MB/s eta 0:00:00\nCollecting hf-xet<2.0.0,>=1.1.3\n  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.2/3.2 MB 288.8 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests\n  Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 64.7/64.7 KB 347.3 MB/s eta 0:00:00\nCollecting tqdm>=4.42.1\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 78.5/78.5 KB 463.4 MB/s eta 0:00:00\nCollecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting fsspec>=2023.5.0\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 470.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 150.5 MB/s eta 0:00:00\nCollecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 502.8 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 118.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 105.7 MB/s eta 0:00:00\nCollecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 95.7 MB/s eta 0:00:00\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 63.8 MB/s eta 0:00:00\nCollecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 111.9 MB/s eta 0:00:00\nCollecting nvidia-cublas-cu12==12.1.3.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 47.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 451.1 MB/s eta 0:00:00\nCollecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 34.0 MB/s eta 0:00:00\nCollecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 325.0 MB/s eta 0:00:00\nCollecting nvidia-cusparse-cu12==12.1.0.106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 133.1 MB/s eta 0:00:00\nCollecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 103.4 MB/s eta 0:00:00\nCollecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 62.9 MB/s eta 0:00:00\nCollecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 121.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nCollecting charset_normalizer<4,>=2\n  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 150.3/150.3 KB 502.1 MB/s eta 0:00:00\nCollecting urllib3<3,>=1.21.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 129.8/129.8 KB 427.7 MB/s eta 0:00:00\nCollecting idna<4,>=2.5\n  Downloading idna-3.10-py3-none-any.whl (70 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 70.4/70.4 KB 445.1 MB/s eta 0:00:00\nCollecting certifi>=2017.4.17\n  Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 161.2/161.2 KB 459.5 MB/s eta 0:00:00\nCollecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 511.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: simsimd, mpmath, urllib3, typing-extensions, tqdm, sympy, stringzilla, safetensors, pyyaml, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, idna, hf-xet, fsspec, filelock, eval-type-backport, charset_normalizer, certifi, annotated-types, typing-inspection, triton, tifffile, scipy, requests, pydantic-core, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, lazy-loader, jinja2, imageio, scikit-image, pydantic, nvidia-cusolver-cu12, huggingface_hub, albucore, torch, albumentations, torchvision, timm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.2 albucore-0.0.33 albumentations-1.4.14 annotated-types-0.7.0 certifi-2025.8.3 charset_normalizer-3.4.3 eval-type-backport-0.2.2 filelock-3.19.1 fsspec-2025.9.0 hf-xet-1.1.10 huggingface_hub-0.35.1 idna-3.10 imageio-2.37.0 jinja2-3.1.6 lazy-loader-0.4 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 opencv-python-headless-4.10.0.84 packaging-25.0 pillow-11.3.0 pydantic-2.11.9 pydantic-core-2.33.2 pyyaml-6.0.2 requests-2.32.5 safetensors-0.6.2 scikit-image-0.25.2 scipy-1.16.2 simsimd-6.5.3 stringzilla-4.0.14 sympy-1.14.0 tifffile-2025.9.20 timm-1.0.9 torch-2.4.1 torchvision-0.19.1 tqdm-4.67.1 triton-3.0.0 typing-extensions-4.15.0 typing-inspection-0.4.1 urllib3-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/torchvision already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchvision.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/functorch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torch already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/torchgen already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusolver_cu12-11.4.5.107.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2-3.1.6.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/jinja2 already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cudnn_cu12-9.1.0.70.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cusparse_cu12-12.1.0.106.dist-info already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Target directory /app/.pip-target/triton-3.0.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/triton already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock-3.19.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/filelock already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec-2025.9.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/fsspec already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/markupsafe already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/MarkupSafe-3.0.2.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx-3.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/networkx already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/numpy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cublas_cu12-12.1.3.1.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_cupti_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_nvrtc_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cuda_runtime_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_cufft_cu12-11.0.2.54.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_curand_cu12-10.3.2.106.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nccl_cu12-2.20.5.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvjitlink_cu12-12.9.86.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia_nvtx_cu12-12.1.105.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/nvidia already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow-11.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/pillow.libs already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/PIL already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy-1.14.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/sympy already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/isympy.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/__pycache__ already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions-4.15.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/typing_extensions.py already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath-1.3.0.dist-info already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/mpmath already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/share already exists. Specify --upgrade to force replacement.\nWARNING: Target directory /app/.pip-target/bin already exists. Specify --upgrade to force replacement.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deps installed\n"
          ]
        }
      ]
    },
    {
      "id": "c87afd95-930c-428c-ac8b-182e138d51f5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run a quick sanity training on fold 0 (1 epoch) with AMP+EMA\n",
        "import subprocess, time, sys\n",
        "cmd = [sys.executable, 'train_full_baseline.py',\n",
        "       '--folds', '0',\n",
        "       '--epochs', '1',\n",
        "       '--img_size', '320',\n",
        "       '--batch_size', '64',\n",
        "       '--workers', '8',\n",
        "       '--out_dir', 'out_baseline_f0',\n",
        "       '--amp',\n",
        "       '--ema'\n",
        "      ]\n",
        "print('Running:', ' '.join(cmd), flush=True)\n",
        "t0=time.time()\n",
        "subprocess.run(cmd, check=False)\n",
        "print(f'Done in {time.time()-t0:.1f}s', flush=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: /usr/bin/python3.11 train_full_baseline.py --folds 0 --epochs 1 --img_size 320 --batch_size 64 --workers 8 --out_dir out_baseline_f0 --amp --ema\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Training fold 0 ===\nFold 0: train 137166 | val 20033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/train_full_baseline.py:88: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 100 Train acc=0.3278 loss=3.7881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 200 Train acc=0.3442 loss=3.6236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 300 Train acc=0.3573 loss=3.4779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 400 Train acc=0.3735 loss=3.3362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 500 Train acc=0.3844 loss=3.2345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 600 Train acc=0.3944 loss=3.1548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 700 Train acc=0.4041 loss=3.0852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 800 Train acc=0.4129 loss=3.0225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 900 Train acc=0.4211 loss=2.9721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 1000 Train acc=0.4277 loss=2.9291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 1100 Train acc=0.4354 loss=2.8857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 1200 Train acc=0.4430 loss=2.8444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 1300 Train acc=0.4497 loss=2.8083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 1400 Train acc=0.4563 loss=2.7745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 1500 Train acc=0.4629 loss=2.7417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 1600 Train acc=0.4697 loss=2.7101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 1700 Train acc=0.4760 loss=2.6809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 1800 Train acc=0.4828 loss=2.6524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 1900 Train acc=0.4895 loss=2.6251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 2000 Train acc=0.4964 loss=2.5974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 It 2100 Train acc=0.5025 loss=2.5730\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/train_full_baseline.py:125: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=args.amp):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1: val_acc=0.1819 time=576.7s\nSaved OOF logits for fold 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/train_full_baseline.py:174: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  sd = torch.load(ckpt, map_location='cpu')['state_dict']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/train_full_baseline.py:181: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=args.amp):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved test logits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 801.9s\n"
          ]
        }
      ]
    },
    {
      "id": "0ab92294-13d0-406b-9d82-f8c560376ff8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Patch train_full_baseline.py to handle truncated images\n",
        "from pathlib import Path\n",
        "p = Path('train_full_baseline.py')\n",
        "txt = p.read_text()\n",
        "if 'ImageFile.LOAD_TRUNCATED_IMAGES = True' not in txt:\n",
        "    txt = txt.replace('from PIL import Image', 'from PIL import Image, ImageFile\\nImageFile.LOAD_TRUNCATED_IMAGES = True')\n",
        "    p.write_text(txt)\n",
        "    print('Patched train_full_baseline.py to enable LOAD_TRUNCATED_IMAGES')\n",
        "else:\n",
        "    print('Patch already applied')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched train_full_baseline.py to enable LOAD_TRUNCATED_IMAGES\n"
          ]
        }
      ]
    },
    {
      "id": "5185e5ee-c393-4c0c-9052-0fb44f62892a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build submission.csv from test logits (out_baseline_f0/test_logits.npy) mapped to sample_submission order\n",
        "import json, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "logits_path = Path('out_baseline_f0')/'test_logits.npy'\n",
        "mapping_path = Path('label_mapping.json')\n",
        "test_info_path = Path('iwildcam2020_test_information.json')\n",
        "sample_path = Path('sample_submission.csv')\n",
        "\n",
        "assert logits_path.exists(), f\"Missing logits at {logits_path}\"\n",
        "logits = np.load(logits_path)\n",
        "with open(mapping_path,'r') as f:\n",
        "    mapping = json.load(f)\n",
        "index2id = {int(k): int(v) for k,v in mapping['index2id'].items()}\n",
        "\n",
        "test_info = json.load(open(test_info_path,'r'))\n",
        "test_images = pd.DataFrame(test_info['images'])\n",
        "test_ids = test_images['id'].tolist()\n",
        "id_to_pos = {tid:i for i,tid in enumerate(test_ids)}\n",
        "assert logits.shape[0] == len(test_ids), f\"Logits rows {logits.shape[0]} != test images {len(test_ids)}\"\n",
        "\n",
        "pred_idx = logits.argmax(axis=1).astype(int)\n",
        "pred_cat = [index2id[int(i)] for i in pred_idx]\n",
        "\n",
        "samp = pd.read_csv(sample_path)\n",
        "def map_pred(row):\n",
        "    pos = id_to_pos.get(row['Id'], None)\n",
        "    if pos is None:\n",
        "        return pred_cat[0]\n",
        "    return pred_cat[pos]\n",
        "samp['Category'] = samp.apply(map_pred, axis=1)\n",
        "samp.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv with shape', samp.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv with shape (60760, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "7d1e603e-40c7-42c5-90df-c8e0b4fd987f",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Patch train_full_baseline.py to robustly handle unreadable images in __getitem__\n",
        "from pathlib import Path\n",
        "p = Path('train_full_baseline.py')\n",
        "txt = p.read_text()\n",
        "old = \"with Image.open(img_path) as im:\\n            im = im.convert('RGB')\\n            x = self.tf(im)\"\n",
        "new = (\"try:\\n            im = Image.open(img_path).convert('RGB')\\n        except Exception as e:\\n            im = Image.new('RGB', (self.size, self.size))\\n        x = self.tf(im)\")\n",
        "if old in txt:\n",
        "    txt = txt.replace(old, new)\n",
        "    p.write_text(txt)\n",
        "    print('Patched __getitem__ with try/except fallback to black image')\n",
        "else:\n",
        "    print('Expected snippet not found; no patch applied')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched __getitem__ with try/except fallback to black image\n"
          ]
        }
      ]
    },
    {
      "id": "bd433fdd-232b-472f-b883-2b6474d762e0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write improved training script v2: convnext_tiny.fb_in22k @384, warmup+cosine, class weights, MixUp, RandErasing, EMA, hflip TTA, seq-avg\n",
        "from pathlib import Path\n",
        "script = r'''\n",
        "import os, json, time, math, random, argparse\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import timm\n",
        "from timm.data.mixup import Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "class IWCDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, img_size=384, train=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = Path(img_dir)\n",
        "        self.train = train\n",
        "        self.size = img_size\n",
        "        self.mean = (0.485,0.456,0.406); self.std = (0.229,0.224,0.225)\n",
        "        if train:\n",
        "            self.tf = T.Compose([\n",
        "                T.RandomResizedCrop(self.size, scale=(0.2,1.0), interpolation=T.InterpolationMode.BICUBIC),\n",
        "                T.RandomHorizontalFlip(),\n",
        "                T.ColorJitter(0.2,0.2,0.2,0.1),\n",
        "                T.RandAugment(num_ops=2, magnitude=8),\n",
        "                T.ToTensor(),\n",
        "                T.RandomErasing(p=0.1, scale=(0.02,0.2), ratio=(0.3,3.3)),\n",
        "                T.Normalize(self.mean, self.std),\n",
        "            ])\n",
        "        else:\n",
        "            self.tf = T.Compose([\n",
        "                T.Resize(int(self.size*1.15), interpolation=T.InterpolationMode.BICUBIC),\n",
        "                T.CenterCrop(self.size),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(self.mean, self.std),\n",
        "            ])\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        img_path = self.img_dir / r['file_name']\n",
        "        try:\n",
        "            im = Image.open(img_path).convert('RGB')\n",
        "        except Exception:\n",
        "            im = Image.new('RGB', (self.size, self.size))\n",
        "        x = self.tf(im)\n",
        "        y = int(r['label_index']) if 'label_index' in r and not pd.isna(r['label_index']) else -1\n",
        "        return x, y, r['img_id']\n",
        "\n",
        "def build_model(num_classes):\n",
        "    model = timm.create_model('convnext_tiny.fb_in22k', pretrained=True, num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "def cosine_warmup_scheduler(optimizer, warmup_steps, total_steps):\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup_steps:\n",
        "            return float(step) / float(max(1, warmup_steps))\n",
        "        prog = float(step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * prog))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "def compute_class_weights(df, num_classes):\n",
        "    cnt = df['label_index'].value_counts().reindex(range(num_classes), fill_value=0).values.astype(np.float32)\n",
        "    cnt[cnt==0] = 1.0\n",
        "    w = 1.0 / np.sqrt(cnt)\n",
        "    w = w / w.mean()\n",
        "    return torch.tensor(w, dtype=torch.float32)\n",
        "\n",
        "def train_fold(args, fold, df, num_classes, device):\n",
        "    df_tr = df[df['fold']!=fold].copy()\n",
        "    df_va = df[df['fold']==fold].copy()\n",
        "    print(f\"Fold {fold}: train {len(df_tr)} | val {len(df_va)}\", flush=True)\n",
        "\n",
        "    train_ds = IWCDataset(df_tr, args.train_dir, img_size=args.img_size, train=True)\n",
        "    val_ds   = IWCDataset(df_va, args.train_dir, img_size=args.img_size, train=False)\n",
        "    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True, drop_last=True)\n",
        "    val_loader   = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True)\n",
        "\n",
        "    model = build_model(num_classes).to(device)\n",
        "    ema_model = timm.utils.ModelEmaV2(model, decay=0.9998) if args.ema else None\n",
        "\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "    total_steps = args.epochs * max(1, len(train_loader))\n",
        "    warmup_steps = max(1, int(0.1 * total_steps))\n",
        "    sched = cosine_warmup_scheduler(opt, warmup_steps, total_steps)\n",
        "\n",
        "    mixup_fn = Mixup(mixup_alpha=args.mixup_alpha, cutmix_alpha=args.mixup_alpha, prob=0.3, label_smoothing=args.label_smoothing, num_classes=num_classes) if args.mixup_alpha>0 else None\n",
        "    if mixup_fn is not None:\n",
        "        criterion = SoftTargetCrossEntropy().to(device)\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss(label_smoothing=args.label_smoothing).to(device)\n",
        "\n",
        "    class_weights = compute_class_weights(df_tr, num_classes).to(device)\n",
        "    if mixup_fn is None and args.use_class_weights:\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=args.label_smoothing).to(device)\n",
        "\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=args.amp)\n",
        "    best_acc = 0.0\n",
        "    oof_logits = np.zeros((len(df_va), num_classes), dtype=np.float32)\n",
        "    oof_ids = df_va['img_id'].values\n",
        "\n",
        "    global_step = 0\n",
        "    for epoch in range(args.epochs):\n",
        "        t0 = time.time()\n",
        "        model.train()\n",
        "        total, correct, loss_sum = 0, 0, 0.0\n",
        "        for it,(xb,yb,_) in enumerate(train_loader):\n",
        "            xb = xb.to(device, non_blocking=True)\n",
        "            yb = yb.to(device, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=args.amp):\n",
        "                if mixup_fn is not None:\n",
        "                    xb, yb_smooth = mixup_fn(xb, yb)\n",
        "                    logits = model(xb)\n",
        "                    loss = criterion(logits, yb_smooth)\n",
        "                else:\n",
        "                    logits = model(xb)\n",
        "                    loss = criterion(logits, yb)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt); scaler.update()\n",
        "            if ema_model is not None:\n",
        "                ema_model.update(model)\n",
        "            loss_sum += loss.item()*xb.size(0)\n",
        "            if mixup_fn is None:\n",
        "                preds = logits.argmax(1)\n",
        "                correct += (preds==yb).sum().item()\n",
        "                total += xb.size(0)\n",
        "            global_step += 1\n",
        "            sched.step()\n",
        "            if (it+1)%200==0:\n",
        "                tr_acc = (correct/total) if total>0 else 0.0\n",
        "                print(f\"Epoch {epoch+1}/{args.epochs} It {it+1} acc={tr_acc:.4f} loss={loss_sum/max(1,total):.4f}\", flush=True)\n",
        "        # Val\n",
        "        model.eval(); eval_model = ema_model.module if ema_model is not None else model\n",
        "        val_total, val_correct = 0, 0\n",
        "        val_logits = []\n",
        "        with torch.no_grad():\n",
        "            for xb,yb,_ids in val_loader:\n",
        "                xb = xb.to(device, non_blocking=True); yb = yb.to(device, non_blocking=True)\n",
        "                with torch.amp.autocast('cuda', enabled=args.amp):\n",
        "                    lg = eval_model(xb)\n",
        "                val_logits.append(lg.float().cpu().numpy())\n",
        "                preds = lg.argmax(1)\n",
        "                val_correct += (preds==yb).sum().item()\n",
        "                val_total += xb.size(0)\n",
        "        val_acc = val_correct/val_total if val_total else 0.0\n",
        "        val_logits = np.concatenate(val_logits, axis=0) if len(val_logits) else np.zeros((0, num_classes), dtype=np.float32)\n",
        "        oof_logits = val_logits\n",
        "        dt = time.time()-t0\n",
        "        print(f\"Fold {fold} Epoch {epoch+1}: val_acc={val_acc:.4f} time={dt:.1f}s\", flush=True)\n",
        "        if val_acc>best_acc:\n",
        "            best_acc=val_acc\n",
        "            ckpt = {'state_dict': model.state_dict(), 'acc': best_acc, 'epoch': epoch+1}\n",
        "            torch.save(ckpt, Path(args.out_dir)/f\"ckpt_fold{fold}.pt\")\n",
        "    np.save(Path(args.out_dir)/f\"oof_logits_fold{fold}.npy\", oof_logits)\n",
        "    pd.DataFrame({'img_id':oof_ids}).to_csv(Path(args.out_dir)/f\"oof_ids_fold{fold}.csv\", index=False)\n",
        "    print(f\"Saved OOF for fold {fold}\", flush=True)\n",
        "\n",
        "def infer_test(args, df_test, num_classes, ckpt_paths, device, tta_flip=True):\n",
        "    ds = IWCDataset(df_test, args.test_dir, img_size=args.img_size, train=False)\n",
        "    loader = DataLoader(ds, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True)\n",
        "    def run_model(model):\n",
        "        all_logits=[]\n",
        "        with torch.no_grad():\n",
        "            for xb,_,_ids in loader:\n",
        "                xb = xb.to(device, non_blocking=True)\n",
        "                with torch.amp.autocast('cuda', enabled=args.amp):\n",
        "                    lg = model(xb)\n",
        "                if tta_flip:\n",
        "                    with torch.amp.autocast('cuda', enabled=args.amp):\n",
        "                        lg_h = model(torch.flip(xb, dims=[3]))\n",
        "                    lg = (lg + lg_h) * 0.5\n",
        "                all_logits.append(lg.float().cpu().numpy())\n",
        "        return np.concatenate(all_logits, axis=0)\n",
        "    logits_sum = np.zeros((len(ds), num_classes), dtype=np.float32)\n",
        "    for ckpt in ckpt_paths:\n",
        "        model = build_model(num_classes).to(device)\n",
        "        sd = torch.load(ckpt, map_location='cpu')['state_dict']\n",
        "        model.load_state_dict(sd, strict=True)\n",
        "        model.eval()\n",
        "        logits_sum += run_model(model)\n",
        "    logits_avg = logits_sum/len(ckpt_paths)\n",
        "    np.save(Path(args.out_dir)/\"test_logits.npy\", logits_avg)\n",
        "    print(\"Saved test logits\", flush=True)\n",
        "\n",
        "def seq_average_logits(df_items, logits, seq_col):\n",
        "    arr = logits.copy()\n",
        "    if seq_col not in df_items.columns: return arr\n",
        "    seq = df_items[seq_col].fillna(df_items.get('img_id', None)).values\n",
        "    dfL = pd.DataFrame(arr)\n",
        "    dfL['__seq'] = seq\n",
        "    grp = dfL.groupby('__seq').mean()\n",
        "    arr2 = dfL['__seq'].map(grp.to_dict(orient='index')).apply(lambda d: np.array(list(d.values()))).values\n",
        "    return np.stack(arr2, axis=0)\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument('--train_dir', default='train')\n",
        "    ap.add_argument('--test_dir', default='test')\n",
        "    ap.add_argument('--folds_csv', default='folds_location.csv')\n",
        "    ap.add_argument('--test_info', default='iwildcam2020_test_information.json')\n",
        "    ap.add_argument('--out_dir', default='out_full_v2')\n",
        "    ap.add_argument('--img_size', type=int, default=384)\n",
        "    ap.add_argument('--batch_size', type=int, default=48)\n",
        "    ap.add_argument('--workers', type=int, default=8)\n",
        "    ap.add_argument('--epochs', type=int, default=12)\n",
        "    ap.add_argument('--lr', type=float, default=3e-4)\n",
        "    ap.add_argument('--weight_decay', type=float, default=5e-2)\n",
        "    ap.add_argument('--label_smoothing', type=float, default=0.1)\n",
        "    ap.add_argument('--mixup_alpha', type=float, default=0.2)\n",
        "    ap.add_argument('--use_class_weights', action='store_true')\n",
        "    ap.add_argument('--amp', action='store_true')\n",
        "    ap.add_argument('--ema', action='store_true')\n",
        "    ap.add_argument('--folds', type=str, default='0,1,2,3,4')\n",
        "    ap.add_argument('--seed', type=int, default=42)\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    set_seed(args.seed)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    Path(args.out_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    df = pd.read_csv(args.folds_csv)\n",
        "    num_classes = int(df['label_index'].max())+1\n",
        "\n",
        "    # Train folds\n",
        "    folds = [int(f) for f in args.folds.split(',')]\n",
        "    for f in folds:\n",
        "        print(f\"=== Training fold {f} ===\", flush=True)\n",
        "        train_fold(args, f, df, num_classes, device)\n",
        "\n",
        "    # Prepare test df\n",
        "    test_info = json.load(open(args.test_info,'r'))\n",
        "    test_images = pd.DataFrame(test_info['images'])\n",
        "    test_df = test_images[['id','file_name','seq_id']].copy() if 'seq_id' in test_images.columns else test_images[['id','file_name']].copy()\n",
        "    test_df.rename(columns={'id':'img_id'}, inplace=True)\n",
        "    test_df['label_index'] = 0\n",
        "\n",
        "    ckpts = [str(Path(args.out_dir)/f\"ckpt_fold{f}.pt\") for f in folds if (Path(args.out_dir)/f\"ckpt_fold{f}.pt\").exists()]\n",
        "    if len(ckpts)>0:\n",
        "        infer_test(args, test_df, num_classes, ckpts, device, tta_flip=True)\n",
        "        # Sequence average test logits if seq_id present\n",
        "        test_logits = np.load(Path(args.out_dir)/\"test_logits.npy\")\n",
        "        if 'seq_id' in test_df.columns:\n",
        "            test_logits = seq_average_logits(test_df.rename(columns={'seq_id':'__sequence'}), test_logits, '__sequence')\n",
        "            np.save(Path(args.out_dir)/\"test_logits_seqavg.npy\", test_logits)\n",
        "            print('Saved test_logits_seqavg.npy', flush=True)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "'''\n",
        "Path('train_full_v2.py').write_text(script)\n",
        "print('Wrote train_full_v2.py')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote train_full_v2.py\n"
          ]
        }
      ]
    },
    {
      "id": "f4d2dddb-e3ce-45c4-adb2-09d869c87be2",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Launch full-image training v2: convnext_tiny.fb_in22k @384 on fold 0 (12 epochs) with AMP+EMA\n",
        "import subprocess, sys, time\n",
        "cmd = [sys.executable, 'train_full_v2.py',\n",
        "       '--folds', '0',\n",
        "       '--epochs', '12',\n",
        "       '--img_size', '384',\n",
        "       '--batch_size', '48',\n",
        "       '--workers', '8',\n",
        "       '--out_dir', 'out_full_v2_f0',\n",
        "       '--amp',\n",
        "       '--ema',\n",
        "       '--use_class_weights'\n",
        "      ]\n",
        "print('Running:', ' '.join(cmd), flush=True)\n",
        "t0=time.time()\n",
        "subprocess.run(cmd, check=False)\n",
        "print(f'Done in {time.time()-t0:.1f}s', flush=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: /usr/bin/python3.11 train_full_v2.py --folds 0 --epochs 12 --img_size 384 --batch_size 48 --workers 8 --out_dir out_full_v2_f0 --amp --ema --use_class_weights\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Training fold 0 ===\nFold 0: train 137166 | val 20033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/app/.pip-target/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 200 acc=0.0000 loss=40399.8433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 400 acc=0.0000 loss=66597.1120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 600 acc=0.0000 loss=89126.9188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 800 acc=0.0000 loss=109322.6824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 1000 acc=0.0000 loss=128365.5903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 1200 acc=0.0000 loss=146219.9182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 1400 acc=0.0000 loss=164297.7572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 1600 acc=0.0000 loss=181888.8980\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 1800 acc=0.0000 loss=199129.2058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 2000 acc=0.0000 loss=215967.0547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 2200 acc=0.0000 loss=232636.3737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 2400 acc=0.0000 loss=248878.9198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 2600 acc=0.0000 loss=265261.9527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12 It 2800 acc=0.0000 loss=281754.8540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 1: val_acc=0.3568 time=807.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 200 acc=0.0000 loss=16363.2322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 400 acc=0.0000 loss=32706.6270\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 600 acc=0.0000 loss=48629.1064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 800 acc=0.0000 loss=64740.3722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 1000 acc=0.0000 loss=80550.5109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 1200 acc=0.0000 loss=96330.2317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 1400 acc=0.0000 loss=112070.4427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 1600 acc=0.0000 loss=127784.3943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 1800 acc=0.0000 loss=143731.3352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 2000 acc=0.0000 loss=159108.6871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 2200 acc=0.0000 loss=174185.7473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 2400 acc=0.0000 loss=189322.2568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 2600 acc=0.0000 loss=204673.4063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/12 It 2800 acc=0.0000 loss=219861.5538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 2: val_acc=0.6470 time=809.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 200 acc=0.0000 loss=14736.2666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 400 acc=0.0000 loss=29657.8535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 600 acc=0.0000 loss=44015.3720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 800 acc=0.0000 loss=59018.8258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 1000 acc=0.0000 loss=73288.0639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 1200 acc=0.0000 loss=87523.1626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 1400 acc=0.0000 loss=101628.0560\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 1600 acc=0.0000 loss=115771.6632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 1800 acc=0.0000 loss=130519.4548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 2000 acc=0.0000 loss=144486.8973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 2200 acc=0.0000 loss=158613.0127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 2400 acc=0.0000 loss=172903.3754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 2600 acc=0.0000 loss=187212.7174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/12 It 2800 acc=0.0000 loss=200818.6659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 3: val_acc=0.6506 time=808.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 200 acc=0.0000 loss=13645.1121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 400 acc=0.0000 loss=27144.1021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 600 acc=0.0000 loss=41040.1738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 800 acc=0.0000 loss=54503.9124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 1000 acc=0.0000 loss=67978.7010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 1200 acc=0.0000 loss=81697.5413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 1400 acc=0.0000 loss=95231.1192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 1600 acc=0.0000 loss=108833.5964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 1800 acc=0.0000 loss=122232.0518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 2000 acc=0.0000 loss=135908.1179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 2200 acc=0.0000 loss=149053.9619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 2400 acc=0.0000 loss=162308.3228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 2600 acc=0.0000 loss=175191.2190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/12 It 2800 acc=0.0000 loss=188706.1630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 4: val_acc=0.6461 time=805.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 200 acc=0.0000 loss=12615.7880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 400 acc=0.0000 loss=25589.5087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 600 acc=0.0000 loss=38363.3616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 800 acc=0.0000 loss=51701.0082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 1000 acc=0.0000 loss=64781.0636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 1200 acc=0.0000 loss=77739.5638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 1400 acc=0.0000 loss=90303.8545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 1600 acc=0.0000 loss=102927.2162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 1800 acc=0.0000 loss=115673.9833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 2000 acc=0.0000 loss=128036.5956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 2200 acc=0.0000 loss=140895.7407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 2400 acc=0.0000 loss=153694.6379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 2600 acc=0.0000 loss=166264.1060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/12 It 2800 acc=0.0000 loss=178765.6713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 5: val_acc=0.6427 time=808.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 200 acc=0.0000 loss=12520.1302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 400 acc=0.0000 loss=24907.0555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 600 acc=0.0000 loss=37102.3930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 800 acc=0.0000 loss=49737.2121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 1000 acc=0.0000 loss=61652.9624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 1200 acc=0.0000 loss=73780.5848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 1400 acc=0.0000 loss=86051.9642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 1600 acc=0.0000 loss=98069.5959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 1800 acc=0.0000 loss=109496.9642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 2000 acc=0.0000 loss=121596.1948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 2200 acc=0.0000 loss=134282.6419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 2400 acc=0.0000 loss=146152.3110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 2600 acc=0.0000 loss=158247.6754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/12 It 2800 acc=0.0000 loss=170262.5437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 6: val_acc=0.6418 time=807.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 200 acc=0.0000 loss=11769.1642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 400 acc=0.0000 loss=23719.3452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 600 acc=0.0000 loss=35215.5675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 800 acc=0.0000 loss=46705.9218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 1000 acc=0.0000 loss=58456.4828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 1200 acc=0.0000 loss=70560.5385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 1400 acc=0.0000 loss=82483.7172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 1600 acc=0.0000 loss=93693.1681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 1800 acc=0.0000 loss=105945.8140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 2000 acc=0.0000 loss=117675.4165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 2200 acc=0.0000 loss=129094.0863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 2400 acc=0.0000 loss=141139.3606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 2600 acc=0.0000 loss=152511.1553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/12 It 2800 acc=0.0000 loss=164464.1305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 7: val_acc=0.6324 time=809.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 200 acc=0.0000 loss=11251.9852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 400 acc=0.0000 loss=22782.4123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 600 acc=0.0000 loss=34661.7415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 800 acc=0.0000 loss=46127.8521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 1000 acc=0.0000 loss=57493.7116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 1200 acc=0.0000 loss=69354.3163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 1400 acc=0.0000 loss=81081.3546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 1600 acc=0.0000 loss=92726.2169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 1800 acc=0.0000 loss=103963.8173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 2000 acc=0.0000 loss=115681.8390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 2200 acc=0.0000 loss=126989.9050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 2400 acc=0.0000 loss=137730.0566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 2600 acc=0.0000 loss=148960.3206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/12 It 2800 acc=0.0000 loss=159933.4481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 8: val_acc=0.6257 time=804.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 200 acc=0.0000 loss=11140.9686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 400 acc=0.0000 loss=22379.6783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 600 acc=0.0000 loss=33716.8451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 800 acc=0.0000 loss=44505.7173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 1000 acc=0.0000 loss=55598.5424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 1200 acc=0.0000 loss=66132.2448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 1400 acc=0.0000 loss=76761.1670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 1600 acc=0.0000 loss=87997.9391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 1800 acc=0.0000 loss=98665.8707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 2000 acc=0.0000 loss=110009.3875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 2200 acc=0.0000 loss=121196.0563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 2400 acc=0.0000 loss=132256.9939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 2600 acc=0.0000 loss=143305.7166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/12 It 2800 acc=0.0000 loss=154178.5914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 9: val_acc=0.6227 time=807.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 200 acc=0.0000 loss=11023.9889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 400 acc=0.0000 loss=21731.9409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 600 acc=0.0000 loss=32876.9200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 800 acc=0.0000 loss=43332.0505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 1000 acc=0.0000 loss=54071.7115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 1200 acc=0.0000 loss=64991.7568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 1400 acc=0.0000 loss=76066.4077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 1600 acc=0.0000 loss=86834.3710\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 1800 acc=0.0000 loss=98020.7873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 2000 acc=0.0000 loss=108968.3738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 2200 acc=0.0000 loss=119516.6926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 2400 acc=0.0000 loss=130215.9614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 2600 acc=0.0000 loss=140843.6445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/12 It 2800 acc=0.0000 loss=151094.2758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 10: val_acc=0.6204 time=807.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 200 acc=0.0000 loss=10838.7582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 400 acc=0.0000 loss=21507.1923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 600 acc=0.0000 loss=32292.0309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 800 acc=0.0000 loss=42899.2608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 1000 acc=0.0000 loss=53551.7698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 1200 acc=0.0000 loss=64037.2302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 1400 acc=0.0000 loss=74661.1837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 1600 acc=0.0000 loss=85766.8362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 1800 acc=0.0000 loss=96437.7258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 2000 acc=0.0000 loss=106936.7424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 2200 acc=0.0000 loss=117726.9780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 2400 acc=0.0000 loss=128477.8598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 2600 acc=0.0000 loss=138948.0814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/12 It 2800 acc=0.0000 loss=149354.2162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 11: val_acc=0.6192 time=807.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 200 acc=0.0000 loss=10112.5092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 400 acc=0.0000 loss=20754.8592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 600 acc=0.0000 loss=31276.2369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 800 acc=0.0000 loss=41628.1333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 1000 acc=0.0000 loss=51982.5222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 1200 acc=0.0000 loss=62298.0956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 1400 acc=0.0000 loss=72787.1997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 1600 acc=0.0000 loss=83439.8224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 1800 acc=0.0000 loss=93963.8391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 2000 acc=0.0000 loss=104436.7317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 2200 acc=0.0000 loss=114994.7463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 2400 acc=0.0000 loss=125064.8363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 2600 acc=0.0000 loss=135757.0178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/12 It 2800 acc=0.0000 loss=146711.8227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Epoch 12: val_acc=0.6183 time=805.6s\nSaved OOF for fold 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/train_full_v2.py:183: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  sd = torch.load(ckpt, map_location='cpu')['state_dict']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved test logits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved test_logits_seqavg.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 9947.7s\n"
          ]
        }
      ]
    },
    {
      "id": "b089e634-7003-47fd-ab94-64ae79058a6d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Parse MegaDetector results using image 'id' -> file_name mapping; output per-image detections\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "base = Path('.')\n",
        "md_path = base/'iwildcam2020_megadetector_results.json'\n",
        "\n",
        "# Load train/test metadata\n",
        "ann_train = json.load(open(base/'iwildcam2020_train_annotations.json','r'))\n",
        "test_info = json.load(open(base/'iwildcam2020_test_information.json','r'))\n",
        "\n",
        "# Build mappings by image id\n",
        "train_img_df = pd.DataFrame(ann_train['images'])\n",
        "test_img_df = pd.DataFrame(test_info['images'])\n",
        "\n",
        "train_by_id = {str(r['id']): r for r in ann_train['images']}\n",
        "test_by_id = {str(r['id']): r for r in test_info['images']}\n",
        "\n",
        "def get_wh(meta):\n",
        "    w = meta.get('width', None); h = meta.get('height', None)\n",
        "    return (int(w), int(h)) if w is not None and h is not None else (None, None)\n",
        "\n",
        "# Load MD\n",
        "md = json.load(open(md_path,'r'))\n",
        "items = md.get('images', md)\n",
        "\n",
        "det_train = {}\n",
        "det_test = {}\n",
        "miss = 0\n",
        "\n",
        "for it in items:\n",
        "    img_id = str(it.get('id', ''))\n",
        "    if not img_id:\n",
        "        miss += 1\n",
        "        continue\n",
        "    # Determine split and metadata\n",
        "    meta = train_by_id.get(img_id)\n",
        "    split = 'train'\n",
        "    if meta is None:\n",
        "        meta = test_by_id.get(img_id)\n",
        "        split = 'test' if meta is not None else None\n",
        "    if meta is None:\n",
        "        miss += 1\n",
        "        continue\n",
        "    name = meta['file_name']\n",
        "    W, H = get_wh(meta)\n",
        "    dets = it.get('detections', []) or []\n",
        "    out = []\n",
        "    for d in dets:\n",
        "        cat = str(d.get('category', '1'))\n",
        "        if cat != '1':\n",
        "            continue\n",
        "        conf = float(d.get('conf', d.get('confidence', 0.0)))\n",
        "        bbox = d.get('bbox', d.get('bbox_xywh', None))\n",
        "        if bbox is None or len(bbox) != 4:\n",
        "            continue\n",
        "        x, y, w, h = [float(v) for v in bbox]\n",
        "        record = {'conf': conf, 'bbox_norm': [x, y, w, h]}\n",
        "        if W is not None and H is not None:\n",
        "            record['bbox_px'] = [x*W, y*H, w*W, h*H]\n",
        "        out.append(record)\n",
        "    if split == 'train':\n",
        "        det_train[name] = out\n",
        "    elif split == 'test':\n",
        "        det_test[name] = out\n",
        "\n",
        "out_path = base/'md_detections.json'\n",
        "with open(out_path, 'w') as f:\n",
        "    json.dump({'train': det_train, 'test': det_test}, f)\n",
        "print('Saved md_detections.json', 'train imgs:', len(det_train), 'test imgs:', len(det_test), 'miss items:', miss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved md_detections.json train imgs: 157181 test imgs: 60759 miss items: 62870\n"
          ]
        }
      ]
    },
    {
      "id": "97c3185b-4368-4dc5-976a-a8432a15204b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write MD-crop training script (multi-box averaging, thresholds, NMS, hflip TTA)\n",
        "from pathlib import Path\n",
        "script = r'''\n",
        "import os, json, math, time, random, argparse\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import timm\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def nms(boxes, scores, iou_thr=0.5):\n",
        "    if len(boxes) == 0: return []\n",
        "    boxes = np.array(boxes, dtype=np.float32)\n",
        "    scores = np.array(scores, dtype=np.float32)\n",
        "    x1,y1,w,h = boxes[:,0], boxes[:,1], boxes[:,2], boxes[:,3]\n",
        "    x2 = x1 + w; y2 = y1 + h\n",
        "    order = scores.argsort()[::-1]\n",
        "    keep = []\n",
        "    areas = w*h\n",
        "    while order.size > 0:\n",
        "        i = order[0]\n",
        "        keep.append(i)\n",
        "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
        "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
        "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
        "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
        "        inter = np.maximum(0.0, xx2-xx1) * np.maximum(0.0, yy2-yy1)\n",
        "        iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-9)\n",
        "        inds = np.where(iou <= iou_thr)[0]\n",
        "        order = order[inds+1]\n",
        "    return keep\n",
        "\n",
        "class MDCropDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, md_json, img_size=320, train=True, conf_hi=0.8, conf_lo=0.6, pad=0.15, min_side=32, min_area_frac=0.005, topk=3):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.dir = Path(img_dir)\n",
        "        self.train = train\n",
        "        self.size = img_size\n",
        "        self.conf_hi = conf_hi; self.conf_lo = conf_lo; self.pad = pad\n",
        "        self.min_side = min_side; self.min_area_frac = min_area_frac; self.topk = topk\n",
        "        self.mean=(0.485,0.456,0.406); self.std=(0.229,0.224,0.225)\n",
        "        self.md = json.load(open(md_json,'r'))\n",
        "        self.md_map = self.md.get('train',{}) if 'train' in self.md else self.md\n",
        "        if not train:\n",
        "            self.md_map = self.md.get('test', self.md_map)\n",
        "        self.tf_tr = T.Compose([\n",
        "            T.RandomResizedCrop(self.size, scale=(0.3,1.0), interpolation=T.InterpolationMode.BICUBIC),\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.ColorJitter(0.1,0.1,0.1,0.05),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(self.mean,self.std),\n",
        "        ])\n",
        "        self.tf_te = T.Compose([\n",
        "            T.Resize(int(self.size*1.15), interpolation=T.InterpolationMode.BICUBIC),\n",
        "            T.CenterCrop(self.size),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(self.mean,self.std),\n",
        "        ])\n",
        "    def __len__(self): return len(self.df)\n",
        "    def get_boxes(self, name, W, H):\n",
        "        dets = self.md_map.get(name, [])\n",
        "        boxes_hi, scores_hi = [], []\n",
        "        boxes_lo, scores_lo = [], []\n",
        "        min_area = max(self.min_side*self.min_side, self.min_area_frac*W*H)\n",
        "        for d in dets:\n",
        "            conf = float(d.get('conf',0.0))\n",
        "            b = d.get('bbox_px')\n",
        "            if b is None:\n",
        "                bn = d.get('bbox_norm',[0,0,0,0]); b = [bn[0]*W,bn[1]*H,bn[2]*W,bn[3]*H]\n",
        "            x,y,w,h = b\n",
        "            if w < self.min_side or h < self.min_side or (w*h) < min_area:\n",
        "                continue\n",
        "            cx = x + w/2; cy = y + h/2\n",
        "            w2 = w*(1+self.pad*2); h2 = h*(1+self.pad*2)\n",
        "            x2 = max(0, cx - w2/2); y2 = max(0, cy - h2/2)\n",
        "            w2 = min(w2, W - x2); h2 = min(h2, H - y2)\n",
        "            if conf >= self.conf_hi:\n",
        "                boxes_hi.append([x2,y2,w2,h2]); scores_hi.append(conf)\n",
        "            elif conf >= self.conf_lo:\n",
        "                boxes_lo.append([x2,y2,w2,h2]); scores_lo.append(conf)\n",
        "        sel = []\n",
        "        if boxes_hi:\n",
        "            keep = nms(boxes_hi, scores_hi, iou_thr=0.5)\n",
        "            idx = sorted(keep, key=lambda i: scores_hi[i], reverse=True)[:self.topk]\n",
        "            sel = [boxes_hi[i] for i in idx]\n",
        "        elif boxes_lo:\n",
        "            keep = nms(boxes_lo, scores_lo, iou_thr=0.5)\n",
        "            idx = sorted(keep, key=lambda i: scores_lo[i], reverse=True)[:self.topk]\n",
        "            sel = [boxes_lo[i] for i in idx]\n",
        "        return sel\n",
        "    def crop_img(self, im, box):\n",
        "        x,y,w,h = box\n",
        "        return im.crop((x,y,x+w,y+h))\n",
        "    def __getitem__(self, i):\n",
        "        r = self.df.iloc[i]\n",
        "        name = r['file_name']\n",
        "        p = self.dir / name\n",
        "        try:\n",
        "            im = Image.open(p).convert('RGB')\n",
        "        except Exception:\n",
        "            im = Image.new('RGB', (self.size, self.size))\n",
        "        W,H = im.size\n",
        "        boxes = self.get_boxes(name, W, H)\n",
        "        if len(boxes)==0:\n",
        "            if self.train:\n",
        "                crop = im\n",
        "                x = self.tf_tr(crop)\n",
        "            else:\n",
        "                x = self.tf_te(im)\n",
        "        else:\n",
        "            if self.train:\n",
        "                crop = self.crop_img(im, random.choice(boxes))\n",
        "                x = self.tf_tr(crop)\n",
        "            else:\n",
        "                # For test, we will ignore x and re-crop/transform per-box in infer loop\n",
        "                x = self.tf_te(self.crop_img(im, boxes[0]))\n",
        "        y = int(r['label_index']) if 'label_index' in r and not pd.isna(r['label_index']) else -1\n",
        "        return x, y, r['img_id'], name, (W,H), boxes\n",
        "\n",
        "def build_model(num_classes):\n",
        "    return timm.create_model('convnext_tiny.fb_in22k', pretrained=True, num_classes=num_classes)\n",
        "\n",
        "# Custom collate to avoid collating variable-length metadata (boxes) in batches\n",
        "def collate_xy(batch):\n",
        "    xs, ys = [], []\n",
        "    for b in batch:\n",
        "        xs.append(b[0])\n",
        "        ys.append(b[1])\n",
        "    xs = torch.stack(xs, dim=0)\n",
        "    ys = torch.tensor(ys, dtype=torch.long)\n",
        "    return xs, ys\n",
        "\n",
        "def train_fold(args, fold, df, num_classes, device):\n",
        "    df_tr = df[df['fold']!=fold].copy(); df_va = df[df['fold']==fold].copy()\n",
        "    print(f\"Fold {fold}: train {len(df_tr)} | val {len(df_va)}\", flush=True)\n",
        "    tr_ds = MDCropDataset(df_tr, args.train_dir, args.md_json, img_size=args.img_size, train=True, conf_hi=args.conf_hi, conf_lo=args.conf_lo, pad=args.pad, topk=args.topk)\n",
        "    va_ds = MDCropDataset(df_va, args.train_dir, args.md_json, img_size=args.img_size, train=False, conf_hi=args.conf_hi, conf_lo=args.conf_lo, pad=args.pad, topk=args.topk)\n",
        "    tr_ld = DataLoader(tr_ds, batch_size=args.batch_size, shuffle=True, num_workers=args.workers, pin_memory=True, drop_last=True, collate_fn=collate_xy)\n",
        "    va_ld = DataLoader(va_ds, batch_size=args.batch_size, shuffle=False, num_workers=args.workers, pin_memory=True, collate_fn=collate_xy)\n",
        "    model = build_model(num_classes).to(device)\n",
        "    ema = timm.utils.ModelEmaV2(model, decay=0.9998) if args.ema else None\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1).to(device)\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=args.amp)\n",
        "    best = 0.0\n",
        "    for ep in range(args.epochs):\n",
        "        t0=time.time(); model.train(); tot=cor=ls=0.0\n",
        "        for it,(xb,yb) in enumerate(tr_ld):\n",
        "            xb=xb.to(device); yb=yb.to(device); opt.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', enabled=args.amp):\n",
        "                lg=model(xb); loss=criterion(lg,yb)\n",
        "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "            if ema: ema.update(model)\n",
        "            ls += loss.item()*xb.size(0);\n",
        "            pr=lg.argmax(1); cor += (pr==yb).sum().item(); tot += xb.size(0)\n",
        "            if (it+1)%200==0:\n",
        "                print(f\"Ep {ep+1}/{args.epochs} It {it+1} acc={cor/max(1,tot):.4f} loss={ls/max(1,tot):.4f}\", flush=True)\n",
        "        # val\n",
        "        model.eval(); m=ema.module if ema else model; vtot=vcor=0;\n",
        "        with torch.no_grad():\n",
        "            for xb,yb in va_ld:\n",
        "                xb=xb.to(device); yb=yb.to(device)\n",
        "                with torch.amp.autocast('cuda', enabled=args.amp):\n",
        "                    lg=m(xb)\n",
        "                vcor += (lg.argmax(1)==yb).sum().item(); vtot += xb.size(0)\n",
        "        vacc=vcor/max(1,vtot); dt=time.time()-t0\n",
        "        print(f\"Fold {fold} Ep {ep+1}: val_acc={vacc:.4f} time={dt:.1f}s\", flush=True)\n",
        "        if vacc>best:\n",
        "            best=vacc; torch.save({'state_dict':model.state_dict(),'acc':best,'epoch':ep+1}, Path(args.out_dir)/f\"ckpt_fold{fold}.pt\")\n",
        "\n",
        "def infer_test(args, df_test, num_classes, ckpt_paths, device):\n",
        "    # We'll do per-image multi-box averaging with hflip TTA\n",
        "    ds = MDCropDataset(df_test, args.test_dir, args.md_json, img_size=args.img_size, train=False, conf_hi=args.conf_hi, conf_lo=args.conf_lo, pad=args.pad, topk=args.topk)\n",
        "    ld = DataLoader(ds, batch_size=1, shuffle=False, num_workers=args.workers, pin_memory=True)\n",
        "    # Define test transform locally to re-crop per box\n",
        "    mean=(0.485,0.456,0.406); std=(0.229,0.224,0.225)\n",
        "    tf_te = T.Compose([\n",
        "        T.Resize(int(args.img_size*1.15), interpolation=T.InterpolationMode.BICUBIC),\n",
        "        T.CenterCrop(args.img_size),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean,std),\n",
        "    ])\n",
        "    def run_model(model):\n",
        "        outs=[]\n",
        "        with torch.no_grad():\n",
        "            for _,_,_id,name,wh,boxes in ld:\n",
        "                # reopen image\n",
        "                p = Path(args.test_dir)/name[0]\n",
        "                try:\n",
        "                    im = Image.open(p).convert('RGB')\n",
        "                except Exception:\n",
        "                    im = Image.new('RGB', (args.img_size, args.img_size))\n",
        "                if len(boxes[0]) == 0:\n",
        "                    crops = [im]\n",
        "                else:\n",
        "                    crops = [im.crop((x,y,x+w,y+h)) for (x,y,w,h) in boxes[0]]\n",
        "                logits_sum = None; n=0\n",
        "                for crop in crops:\n",
        "                    x = tf_te(crop).unsqueeze(0).to(device)\n",
        "                    with torch.amp.autocast('cuda', enabled=args.amp):\n",
        "                        lg = model(x)\n",
        "                        if args.tta_flip:\n",
        "                            lg_h = model(torch.flip(x, dims=[3]))\n",
        "                            lg = 0.5*(lg+lg_h)\n",
        "                    lg = lg.float()\n",
        "                    logits_sum = lg if logits_sum is None else (logits_sum + lg)\n",
        "                    n += 1\n",
        "                logits = (logits_sum / max(1,n)).squeeze(0).cpu().numpy()\n",
        "                outs.append(logits)\n",
        "        return np.stack(outs,0)\n",
        "    agg = np.zeros((len(ds), num_classes), dtype=np.float32)\n",
        "    for ck in ckpt_paths:\n",
        "        m = build_model(num_classes).to(device); sd=torch.load(ck,map_location='cpu')['state_dict']; m.load_state_dict(sd, strict=True); m.eval()\n",
        "        agg += run_model(m)\n",
        "    agg /= max(1,len(ckpt_paths))\n",
        "    np.save(Path(args.out_dir)/'test_logits.npy', agg); print('Saved MD test logits', flush=True)\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument('--train_dir', default='train')\n",
        "    ap.add_argument('--test_dir', default='test')\n",
        "    ap.add_argument('--folds_csv', default='folds_location.csv')\n",
        "    ap.add_argument('--md_json', default='md_detections.json')\n",
        "    ap.add_argument('--out_dir', default='out_md_v1')\n",
        "    ap.add_argument('--img_size', type=int, default=320)\n",
        "    ap.add_argument('--batch_size', type=int, default=64)\n",
        "    ap.add_argument('--workers', type=int, default=8)\n",
        "    ap.add_argument('--epochs', type=int, default=8)\n",
        "    ap.add_argument('--lr', type=float, default=3e-4)\n",
        "    ap.add_argument('--weight_decay', type=float, default=5e-2)\n",
        "    ap.add_argument('--amp', action='store_true')\n",
        "    ap.add_argument('--ema', action='store_true')\n",
        "    ap.add_argument('--tta_flip', action='store_true')\n",
        "    ap.add_argument('--folds', type=str, default='0,1,2,3,4')\n",
        "    ap.add_argument('--conf_hi', type=float, default=0.8)\n",
        "    ap.add_argument('--conf_lo', type=float, default=0.6)\n",
        "    ap.add_argument('--pad', type=float, default=0.15)\n",
        "    ap.add_argument('--topk', type=int, default=3)\n",
        "    args = ap.parse_args()\n",
        "    set_seed(42); device='cuda' if torch.cuda.is_available() else 'cpu'; Path(args.out_dir).mkdir(parents=True, exist_ok=True)\n",
        "    df = pd.read_csv(args.folds_csv); num_classes = int(df['label_index'].max())+1\n",
        "    folds = [int(f) for f in args.folds.split(',')]\n",
        "    for f in folds:\n",
        "        print(f'=== MD train fold {f} ===', flush=True)\n",
        "        train_fold(args, f, df, num_classes, device)\n",
        "    # test\n",
        "    test_info = json.load(open('iwildcam2020_test_information.json','r'))\n",
        "    test_df = pd.DataFrame(test_info['images'])[['id','file_name']].rename(columns={'id':'img_id'}); test_df['label_index']=0\n",
        "    ckpts = [str(Path(args.out_dir)/f\"ckpt_fold{f}.pt\") for f in folds if (Path(args.out_dir)/f\"ckpt_fold{f}.pt\").exists()]\n",
        "    if len(ckpts)>0:\n",
        "        infer_test(args, test_df, num_classes, ckpts, device)\n",
        "\n",
        "if __name__=='__main__':\n",
        "    main()\n",
        "'''\n",
        "Path('train_md_v1.py').write_text(script)\n",
        "print('Wrote train_md_v1.py')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote train_md_v1.py\n"
          ]
        }
      ]
    },
    {
      "id": "8207cd80-25d1-47c3-98f0-39ef56a1d6f5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Blending and submission builder: full-image + MD-crops with rules, then sequence averaging\n",
        "import json, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "full_dir = Path('out_full_v2_f0')  # adjust later if averaging multiple folds\n",
        "md_dir = Path('out_md_v1_f0')  # updated to use fold-0 MD output\n",
        "mapping_path = Path('label_mapping.json')\n",
        "ann_train_path = Path('iwildcam2020_train_annotations.json')\n",
        "test_info_path = Path('iwildcam2020_test_information.json')\n",
        "sample_path = Path('sample_submission.csv')\n",
        "md_det_path = Path('md_detections.json')\n",
        "\n",
        "assert full_dir.exists(), 'Full-image out dir missing'\n",
        "with open(mapping_path,'r') as f: mapping = json.load(f)\n",
        "index2id = {int(k): int(v) for k,v in mapping['index2id'].items()}\n",
        "\n",
        "# Locate empty class index if available\n",
        "empty_idx = None\n",
        "try:\n",
        "    ann = json.load(open(ann_train_path,'r'))\n",
        "    cats = pd.DataFrame(ann['categories'])\n",
        "    if 'name' in cats.columns:\n",
        "        empty_rows = cats[cats['name'].str.lower()=='empty']\n",
        "        if len(empty_rows)>0:\n",
        "            empty_cid = int(empty_rows.iloc[0]['id'])\n",
        "            empty_idx = int({int(cid):i for i,cid in enumerate(cats['id'].tolist())}[empty_cid])\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Load test info\n",
        "test_info = json.load(open(test_info_path,'r'))\n",
        "test_df = pd.DataFrame(test_info['images'])\n",
        "has_seq = 'seq_id' in test_df.columns\n",
        "\n",
        "def seq_average_logits(df_items, logits):\n",
        "    if not has_seq: return logits\n",
        "    seq = df_items['seq_id'].values\n",
        "    dfL = pd.DataFrame(logits)\n",
        "    dfL['__seq'] = seq\n",
        "    grp = dfL.groupby('__seq').mean()\n",
        "    mapper = grp.to_dict(orient='index')\n",
        "    arr = np.stack(dfL['__seq'].map(lambda s: np.array(list(mapper[s].values()))).values, axis=0)\n",
        "    return arr\n",
        "\n",
        "# Load logits\n",
        "full_logits_path = full_dir/'test_logits.npy'\n",
        "assert full_logits_path.exists(), f'Missing full-image logits at {full_logits_path}'\n",
        "full_logits = np.load(full_logits_path)\n",
        "\n",
        "md_logits = None\n",
        "if (md_dir/'test_logits.npy').exists():\n",
        "    md_logits = np.load(md_dir/'test_logits.npy')\n",
        "    assert md_logits.shape == full_logits.shape, f'MD logits shape {md_logits.shape} != full {full_logits.shape}'\n",
        "\n",
        "# MD-based confidence flags per image\n",
        "hi_conf = np.zeros(len(test_df), dtype=bool)\n",
        "lo_conf = np.zeros(len(test_df), dtype=bool)\n",
        "if md_det_path.exists():\n",
        "    md = json.load(open(md_det_path,'r'))\n",
        "    det_map = md.get('test', {}) if 'test' in md else md\n",
        "    name_to_idx = {n:i for i,n in enumerate(test_df['file_name'].tolist())}\n",
        "    for name, dets in det_map.items():\n",
        "        i = name_to_idx.get(name, None)\n",
        "        if i is None: continue\n",
        "        confs = [float(d.get('conf',0.0)) for d in dets]\n",
        "        if any(c>=0.8 for c in confs):\n",
        "            hi_conf[i] = True\n",
        "        elif any(c>=0.6 for c in confs):\n",
        "            lo_conf[i] = True\n",
        "\n",
        "# Blend logits per rules\n",
        "blend = full_logits.copy()\n",
        "if md_logits is not None:\n",
        "    # hi-conf: 0.7*md + 0.3*full\n",
        "    mask_hi = hi_conf\n",
        "    blend[mask_hi] = 0.7*md_logits[mask_hi] + 0.3*full_logits[mask_hi]\n",
        "    # low-conf: 0.5/0.5\n",
        "    mask_lo = (~mask_hi) & lo_conf\n",
        "    blend[mask_lo] = 0.5*md_logits[mask_lo] + 0.5*full_logits[mask_lo]\n",
        "else:\n",
        "    mask_hi = np.zeros(len(test_df), dtype=bool)\n",
        "    mask_lo = np.zeros(len(test_df), dtype=bool)\n",
        "\n",
        "# No-crop fallback: optionally add small bias to empty class\n",
        "if empty_idx is not None:\n",
        "    none_mask = (~mask_hi) & (~mask_lo)\n",
        "    if none_mask.any():\n",
        "        bias = np.zeros_like(blend[0])\n",
        "        bias[empty_idx] = 0.1\n",
        "        blend[none_mask] = blend[none_mask] + bias\n",
        "\n",
        "# Sequence averaging after blending\n",
        "blend_seq = seq_average_logits(test_df, blend)\n",
        "\n",
        "# Map to submission\n",
        "pred_idx = blend_seq.argmax(axis=1).astype(int)\n",
        "pred_cat = [index2id[int(i)] for i in pred_idx]\n",
        "samp = pd.read_csv(sample_path)\n",
        "id_to_pos = {tid:i for i,tid in enumerate(test_df['id'].tolist())}\n",
        "def map_pred(row):\n",
        "    pos = id_to_pos.get(row['Id'], None)\n",
        "    return pred_cat[pos] if pos is not None else pred_cat[0]\n",
        "samp['Category'] = samp.apply(map_pred, axis=1)\n",
        "samp.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv with shape', samp.shape, 'has_seq' if has_seq else 'no_seq')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote submission.csv with shape (60760, 2) has_seq\n"
          ]
        }
      ]
    },
    {
      "id": "53e27f19-d709-4c53-ba34-0da858213312",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Debug MegaDetector JSON: inspect paths and basename matching to train/test\n",
        "import json, os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "md_path = Path('iwildcam2020_megadetector_results.json')\n",
        "\n",
        "# Load train/test names via json.load (pd.read_json expects tabular structure)\n",
        "train_ann = json.load(open('iwildcam2020_train_annotations.json','r'))\n",
        "test_info = json.load(open('iwildcam2020_test_information.json','r'))\n",
        "train_names = set([img['file_name'] for img in train_ann['images']])\n",
        "test_names = set([img['file_name'] for img in test_info['images']])\n",
        "\n",
        "def fname_only(p):\n",
        "    return Path(p).name if p else None\n",
        "\n",
        "md = json.load(open(md_path,'r'))\n",
        "items = md.get('images', md)\n",
        "print('Total MD items:', len(items))\n",
        "print('MD first item keys:', list(items[0].keys()) if len(items)>0 else [])\n",
        "\n",
        "hits_train = hits_test = 0\n",
        "sample = []\n",
        "for it in items[:50]:\n",
        "    f = it.get('file') or it.get('image_path') or it.get('filename')\n",
        "    name = fname_only(f)\n",
        "    in_train = (name in train_names)\n",
        "    in_test = (name in test_names)\n",
        "    if in_train: hits_train += 1\n",
        "    if in_test: hits_test += 1\n",
        "    sample.append((f, name, in_train, in_test, len(it.get('detections', []))))\n",
        "print('First 5 samples (orig_path, basename, in_train, in_test, ndets):')\n",
        "for row in sample[:5]:\n",
        "    print(row)\n",
        "print('Basename matches -> train:', hits_train, '| test:', hits_test)\n",
        "\n",
        "# Also check if MD filenames include subdirs identical to our dirs\n",
        "subdir_hits = {'train/':0,'test/':0}\n",
        "for it in items[:5000]:\n",
        "    f = (it.get('file') or it.get('image_path') or it.get('filename') or '')\n",
        "    for k in subdir_hits:\n",
        "        if k in f: subdir_hits[k]+=1\n",
        "print('Subdir markers in MD JSON:', subdir_hits)\n",
        "\n",
        "# Count how many MD basenames exist on disk in train/ and test/ dirs\n",
        "from os.path import exists\n",
        "on_disk_train = on_disk_test = 0\n",
        "for it in items[:2000]:\n",
        "    f = it.get('file') or it.get('image_path') or it.get('filename')\n",
        "    name = fname_only(f)\n",
        "    if name and (Path('train')/name).exists(): on_disk_train += 1\n",
        "    if name and (Path('test')/name).exists(): on_disk_test += 1\n",
        "print('On-disk basename matches -> train:', on_disk_train, '| test:', on_disk_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MD items: 280810\nMD first item keys: ['detections', 'id', 'max_detection_conf']\nFirst 5 samples (orig_path, basename, in_train, in_test, ndets):\n(None, None, False, False, 1)\n(None, None, False, False, 1)\n(None, None, False, False, 0)\n(None, None, False, False, 7)\n(None, None, False, False, 1)\nBasename matches -> train: 0 | test: 0\nSubdir markers in MD JSON: {'train/': 0, 'test/': 0}\nOn-disk basename matches -> train: 0 | test: 0\n"
          ]
        }
      ]
    },
    {
      "id": "50b6dbce-211d-4ad5-895f-5e54c5b35c67",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Launch MD-crop training (fold 0) with AMP+EMA and flip-TTA; img_size=320\n",
        "import subprocess, sys, time\n",
        "cmd = [sys.executable, 'train_md_v1.py',\n",
        "       '--folds', '0',\n",
        "       '--img_size', '320',\n",
        "       '--batch_size', '64',\n",
        "       '--workers', '8',\n",
        "       '--epochs', '8',\n",
        "       '--out_dir', 'out_md_v1_f0',\n",
        "       '--amp',\n",
        "       '--ema',\n",
        "       '--tta_flip'\n",
        "      ]\n",
        "print('Running:', ' '.join(cmd), flush=True)\n",
        "t0=time.time()\n",
        "subprocess.run(cmd, check=False)\n",
        "print(f'Done in {time.time()-t0:.1f}s', flush=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: /usr/bin/python3.11 train_md_v1.py --folds 0 --img_size 320 --batch_size 64 --workers 8 --epochs 8 --out_dir out_md_v1_f0 --amp --ema --tta_flip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MD train fold 0 ===\nFold 0: train 137166 | val 20033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1/8 It 200 acc=0.6178 loss=2.2649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1/8 It 400 acc=0.6864 loss=1.9755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1/8 It 600 acc=0.7182 loss=1.8467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1/8 It 800 acc=0.7380 loss=1.7680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1/8 It 1000 acc=0.7516 loss=1.7132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1/8 It 1200 acc=0.7628 loss=1.6694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1/8 It 1400 acc=0.7712 loss=1.6351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1/8 It 1600 acc=0.7779 loss=1.6082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1/8 It 1800 acc=0.7842 loss=1.5839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1/8 It 2000 acc=0.7894 loss=1.5642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Ep 1: val_acc=0.4461 time=578.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 2/8 It 200 acc=0.8632 loss=1.2916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 2/8 It 400 acc=0.8616 loss=1.2986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 2/8 It 600 acc=0.8630 loss=1.2963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 2/8 It 800 acc=0.8637 loss=1.2929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 2/8 It 1000 acc=0.8649 loss=1.2875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 2/8 It 1200 acc=0.8658 loss=1.2842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 2/8 It 1400 acc=0.8667 loss=1.2815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 2/8 It 1600 acc=0.8677 loss=1.2773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 2/8 It 1800 acc=0.8687 loss=1.2738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 2/8 It 2000 acc=0.8698 loss=1.2703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Ep 2: val_acc=0.5754 time=578.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 3/8 It 200 acc=0.8984 loss=1.1769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 3/8 It 400 acc=0.9012 loss=1.1738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 3/8 It 600 acc=0.9006 loss=1.1738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 3/8 It 800 acc=0.9003 loss=1.1736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 3/8 It 1000 acc=0.9007 loss=1.1734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 3/8 It 1200 acc=0.9008 loss=1.1737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 3/8 It 1400 acc=0.9009 loss=1.1727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 3/8 It 1600 acc=0.9012 loss=1.1712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 3/8 It 1800 acc=0.9014 loss=1.1706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 3/8 It 2000 acc=0.9017 loss=1.1697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Ep 3: val_acc=0.5835 time=579.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 4/8 It 200 acc=0.9223 loss=1.1101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 4/8 It 400 acc=0.9202 loss=1.1159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 4/8 It 600 acc=0.9189 loss=1.1203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 4/8 It 800 acc=0.9189 loss=1.1196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 4/8 It 1000 acc=0.9193 loss=1.1183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 4/8 It 1200 acc=0.9190 loss=1.1194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 4/8 It 1400 acc=0.9193 loss=1.1193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 4/8 It 1600 acc=0.9189 loss=1.1200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 4/8 It 1800 acc=0.9187 loss=1.1202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 4/8 It 2000 acc=0.9185 loss=1.1197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Ep 4: val_acc=0.5713 time=579.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 5/8 It 200 acc=0.9302 loss=1.0820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 5/8 It 400 acc=0.9301 loss=1.0829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 5/8 It 600 acc=0.9295 loss=1.0836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 5/8 It 800 acc=0.9287 loss=1.0849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 5/8 It 1000 acc=0.9272 loss=1.0901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 5/8 It 1200 acc=0.9278 loss=1.0897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 5/8 It 1400 acc=0.9272 loss=1.0918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 5/8 It 1600 acc=0.9275 loss=1.0906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 5/8 It 1800 acc=0.9279 loss=1.0892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 5/8 It 2000 acc=0.9279 loss=1.0893\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Ep 5: val_acc=0.5565 time=580.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 6/8 It 200 acc=0.9373 loss=1.0618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 6/8 It 400 acc=0.9370 loss=1.0630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 6/8 It 600 acc=0.9371 loss=1.0632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 6/8 It 800 acc=0.9366 loss=1.0630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 6/8 It 1000 acc=0.9370 loss=1.0625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 6/8 It 1200 acc=0.9371 loss=1.0623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 6/8 It 1400 acc=0.9369 loss=1.0629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 6/8 It 1600 acc=0.9363 loss=1.0643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 6/8 It 1800 acc=0.9359 loss=1.0654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 6/8 It 2000 acc=0.9355 loss=1.0664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Ep 6: val_acc=0.5435 time=576.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 7/8 It 200 acc=0.9413 loss=1.0471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 7/8 It 400 acc=0.9422 loss=1.0437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 7/8 It 600 acc=0.9411 loss=1.0471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 7/8 It 800 acc=0.9411 loss=1.0473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 7/8 It 1000 acc=0.9396 loss=1.0519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 7/8 It 1200 acc=0.9394 loss=1.0519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 7/8 It 1400 acc=0.9398 loss=1.0518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 7/8 It 1600 acc=0.9396 loss=1.0525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 7/8 It 1800 acc=0.9398 loss=1.0519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 7/8 It 2000 acc=0.9397 loss=1.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Ep 7: val_acc=0.5353 time=581.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 8/8 It 200 acc=0.9481 loss=1.0221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 8/8 It 400 acc=0.9460 loss=1.0288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 8/8 It 600 acc=0.9460 loss=1.0313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 8/8 It 800 acc=0.9456 loss=1.0323\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 8/8 It 1000 acc=0.9449 loss=1.0347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 8/8 It 1200 acc=0.9446 loss=1.0361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 8/8 It 1400 acc=0.9444 loss=1.0371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 8/8 It 1600 acc=0.9440 loss=1.0384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 8/8 It 1800 acc=0.9437 loss=1.0389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 8/8 It 2000 acc=0.9433 loss=1.0400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 Ep 8: val_acc=0.5265 time=577.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/train_md_v1.py:219: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m = build_model(num_classes).to(device); sd=torch.load(ck,map_location='cpu')['state_dict']; m.load_state_dict(sd, strict=True); m.eval()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n  File \"/var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/train_md_v1.py\", line 260, in <module>\n    main()\n  File \"/var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/train_md_v1.py\", line 257, in main\n    infer_test(args, test_df, num_classes, ckpts, device)\n  File \"/var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/train_md_v1.py\", line 220, in infer_test\n    agg += run_model(m)\n           ^^^^^^^^^^^^\n  File \"/var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/train_md_v1.py\", line 199, in run_model\n    if len(boxes[0]) == 0:\n           ~~~~~^^^\nIndexError: list index out of range\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done in 4642.3s\n"
          ]
        }
      ]
    },
    {
      "id": "30d9e78a-8f70-47e8-b751-708d00b89c5e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run MD-crop inference only (epochs=0) then blend with full-image logits to make submission\n",
        "import os, sys, time, json, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "def run(cmd):\n",
        "    print('Running:', ' '.join(cmd), flush=True)\n",
        "    return subprocess.run(cmd, check=False)\n",
        "\n",
        "# 1) MD inference (reuse existing ckpt_fold0.pt), skip training by epochs=0\n",
        "md_out = Path('out_md_v1_f0'); md_out.mkdir(exist_ok=True, parents=True)\n",
        "cmd = [sys.executable, 'train_md_v1.py',\n",
        "       '--folds','0',\n",
        "       '--epochs','0',\n",
        "       '--img_size','320',\n",
        "       '--batch_size','1',\n",
        "       '--workers','8',\n",
        "       '--out_dir','out_md_v1_f0',\n",
        "       '--amp',\n",
        "       '--tta_flip'\n",
        "]\n",
        "t0=time.time(); run(cmd); print(f'MD inference done in {time.time()-t0:.1f}s', flush=True)\n",
        "assert (md_out/'ckpt_fold0.pt').exists(), 'Missing MD ckpt_fold0.pt (ensure prior training finished)'\n",
        "assert (md_out/'test_logits.npy').exists(), 'MD test logits not found after inference'\n",
        "\n",
        "# 2) Blend MD + Full logits and build submission\n",
        "full_dir = Path('out_full_v2_f0')\n",
        "md_dir = md_out\n",
        "mapping_path = Path('label_mapping.json')\n",
        "ann_train_path = Path('iwildcam2020_train_annotations.json')\n",
        "test_info_path = Path('iwildcam2020_test_information.json')\n",
        "sample_path = Path('sample_submission.csv')\n",
        "md_det_path = Path('md_detections.json')\n",
        "\n",
        "with open(mapping_path,'r') as f: mapping = json.load(f)\n",
        "index2id = {int(k): int(v) for k,v in mapping['index2id'].items()}\n",
        "\n",
        "test_info = json.load(open(test_info_path,'r'))\n",
        "test_df = pd.DataFrame(test_info['images'])\n",
        "has_seq = 'seq_id' in test_df.columns\n",
        "\n",
        "full_logits = np.load(full_dir/'test_logits.npy')\n",
        "md_logits = np.load(md_dir/'test_logits.npy')\n",
        "assert md_logits.shape == full_logits.shape, f'MD {md_logits.shape} != Full {full_logits.shape}'\n",
        "\n",
        "# empty class index if available\n",
        "empty_idx = None\n",
        "try:\n",
        "    ann = json.load(open(ann_train_path,'r'))\n",
        "    cats = pd.DataFrame(ann['categories'])\n",
        "    if 'name' in cats.columns:\n",
        "        row = cats[cats['name'].str.lower()=='empty']\n",
        "        if len(row)>0:\n",
        "            empty_cid = int(row.iloc[0]['id'])\n",
        "            id2index = {int(cid):i for i,cid in enumerate(cats['id'].tolist())}\n",
        "            empty_idx = int(id2index[empty_cid])\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# MD confidence flags\n",
        "hi_conf = np.zeros(len(test_df), dtype=bool)\n",
        "lo_conf = np.zeros(len(test_df), dtype=bool)\n",
        "if md_det_path.exists():\n",
        "    md = json.load(open(md_det_path,'r'))\n",
        "    det_map = md.get('test', {}) if 'test' in md else md\n",
        "    name_to_idx = {n:i for i,n in enumerate(test_df['file_name'].tolist())}\n",
        "    for name, dets in det_map.items():\n",
        "        i = name_to_idx.get(name, None)\n",
        "        if i is None: continue\n",
        "        confs = [float(d.get('conf',0.0)) for d in dets]\n",
        "        if any(c>=0.8 for c in confs):\n",
        "            hi_conf[i] = True\n",
        "        elif any(c>=0.6 for c in confs):\n",
        "            lo_conf[i] = True\n",
        "\n",
        "# Blend per rules\n",
        "blend = full_logits.copy()\n",
        "mask_hi = hi_conf\n",
        "blend[mask_hi] = 0.7*md_logits[mask_hi] + 0.3*full_logits[mask_hi]\n",
        "mask_lo = (~mask_hi) & lo_conf\n",
        "blend[mask_lo] = 0.5*md_logits[mask_lo] + 0.5*full_logits[mask_lo]\n",
        "\n",
        "if empty_idx is not None:\n",
        "    none_mask = (~mask_hi) & (~mask_lo)\n",
        "    if none_mask.any():\n",
        "        bias = np.zeros_like(blend[0]); bias[empty_idx]=0.1\n",
        "        blend[none_mask] = blend[none_mask] + bias\n",
        "\n",
        "def seq_average_logits(df_items, logits):\n",
        "    if not has_seq: return logits\n",
        "    seq = df_items['seq_id'].values\n",
        "    dfL = pd.DataFrame(logits)\n",
        "    dfL['__seq'] = seq\n",
        "    grp = dfL.groupby('__seq').mean()\n",
        "    mapper = grp.to_dict(orient='index')\n",
        "    arr = np.stack(dfL['__seq'].map(lambda s: np.array(list(mapper[s].values()))).values, axis=0)\n",
        "    return arr\n",
        "\n",
        "blend_seq = seq_average_logits(test_df, blend)\n",
        "pred_idx = blend_seq.argmax(axis=1).astype(int)\n",
        "pred_cat = [index2id[int(i)] for i in pred_idx]\n",
        "samp = pd.read_csv(sample_path)\n",
        "id_to_pos = {tid:i for i,tid in enumerate(test_df['id'].tolist())}\n",
        "samp['Category'] = samp['Id'].map(lambda tid: pred_cat[id_to_pos.get(tid, 0)])\n",
        "samp.to_csv('submission.csv', index=False)\n",
        "print('Wrote submission.csv', samp.shape, flush=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: /usr/bin/python3.11 train_md_v1.py --folds 0 --epochs 0 --img_size 320 --batch_size 1 --workers 8 --out_dir out_md_v1_f0 --amp --tta_flip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MD train fold 0 ===\nFold 0: train 137166 | val 20033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/var/lib/simon/agent_run_states/iwildcam-2020-fgvc7-20250924-031313/train_md_v1.py:221: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  m = build_model(num_classes).to(device); sd=torch.load(ck,map_location='cpu')['state_dict']; m.load_state_dict(sd, strict=True); m.eval()\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}