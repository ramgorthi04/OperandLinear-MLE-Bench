{
  "cells": [
    {
      "id": "4d9e8404-3c13-4f46-b4c9-97627397de4a",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plan: iWildCam 2020 - FGVC7 (Goal: Medal)\n",
        "\n",
        "Objectives:\n",
        "- Establish GPU-enabled environment; verify CUDA.\n",
        "- Load/inspect provided artifacts: train/test dirs, annotations JSONs, megadetector results, test info, sample submission.\n",
        "- Build fast, correct baseline: single strong pretrained CNN (e.g., timm resnet50/efficientnet), 224-384px, focal loss or weighted CE, standard aug.\n",
        "- Robust CV mirroring test distribution: GroupKFold by location/camera_id if available; otherwise stratified with site-aware split from metadata.\n",
        "- Ship working submission ASAP; iterate to medal with improvements and ensembling.\n",
        "\n",
        "Initial Baseline Roadmap:\n",
        "1) Environment:\n",
        "   - Install PyTorch cu121 stack and timm; confirm GPU via nvidia-smi and torch.cuda.is_available().\n",
        "2) Data pipeline:\n",
        "   - Parse iwildcam2020_train_annotations.json to extract image_id, file_name, category_id, location/camera if present.\n",
        "   - Map categories to contiguous labels; build DataFrame.\n",
        "   - For test, read iwildcam2020_test_information.json (file_name list, potentially location).\n",
        "3) Validation:\n",
        "   - If annotations provide location/site/camera, use GroupKFold by location to simulate domain shift.\n",
        "   - Else: StratifiedKFold with careful leakage checks; fix random_state for determinism.\n",
        "4) Modeling:\n",
        "   - Start with timm models: efficientnet_b0 or convnext_tiny at 320px, pretrained=True.\n",
        "   - Augs: RandomResizedCrop, HFlip, ColorJitter, Normalize; use mixup/cutmix small.\n",
        "   - Optim: AdamW, cosine schedule, warmup, label smoothing 0.1; epochs: 5-8 for smoke baseline, early stop on OOF.\n",
        "   - Loss: CrossEntropy with class weights or Focal if imbalance severe.\n",
        "5) Inference:\n",
        "   - TTA x3 (scales/flips) if time allows.\n",
        "   - Save submission.csv with columns [Id,Category].\n",
        "6) Iterations to Medal:\n",
        "   - Scale model/resolution (efficientnet_b3/b4, convnext_base, swin_t).\n",
        "   - Use MegaDetector crops to focus on detected boxes (fallback to full image).\n",
        "   - Pseudo-labeling on confident test predictions if CV aligns; blend full-image and crop models.\n",
        "   - Class-balanced sampling; per-location batch sampling.\n",
        "\n",
        "Risks & Mitigations:\n",
        "- Data leakage via site overlap across folds \u2192 enforce GroupKFold by location if available.\n",
        "- Long training times \u2192 smoke runs first, log per-epoch times, cache datasets, num_workers tuned.\n",
        "- File I/O bottleneck (160k train images) \u2192 use pillow-simd if available, persistent workers, prefetch_factor.\n",
        "\n",
        "Next Actions:\n",
        "A) Add and run GPU/Env check cell.\n",
        "B) Quick EDA: load JSONs; count classes, sites, images; verify file paths.\n",
        "C) Implement training script train.py for clean subprocess runs.\n",
        "D) Ship baseline model with 1-2 folds and generate first submission.\n",
        "\n",
        "Expert Questions:\n",
        "- Recommended CV protocol for iWildCam 2020: group by location vs sequence_id vs camera trap id?\n",
        "- Baseline model/resolution that reliably gets >0.60 accuracy on LB?\n",
        "- Best use of MegaDetector: single crop per image or multi-box with NMS/ensembling?\n",
        "- Any pitfalls with class mapping or missing classes in test?\n",
        "\n",
        "We will request expert review after env check + EDA and again after first baseline OOF/LB."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "62ebaf4c-3960-4fa8-9e35-cc660860e60d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# GPU / Environment check\n",
        "import os, subprocess, sys, time, json\n",
        "print(\"=== nvidia-smi ===\", flush=True)\n",
        "subprocess.run([\"bash\",\"-lc\",\"nvidia-smi || true\"], check=False)\n",
        "print(\"=== CUDA env ===\", flush=True)\n",
        "print(\"CUDA_VISIBLE_DEVICES=\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
        "print(\"=== GPU query ===\", flush=True)\n",
        "subprocess.run([\"bash\",\"-lc\",\"nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv,noheader || true\"], check=False)\n",
        "print(\"=== Done ===\", flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "10cef31f-ca70-4486-9eb6-dc191e0fea73",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install PyTorch cu121 stack and core deps (avoid re-installing torch during later installs)\n",
        "import os, sys, subprocess, shutil\n",
        "from pathlib import Path\n",
        "def pip(*args):\n",
        "    print('> pip', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "\n",
        "# Uninstall any stray torch stacks (idempotent)\n",
        "for pkg in ('torch','torchvision','torchaudio'):\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', pkg], check=False)\n",
        "\n",
        "# Clean potential shadow dirs\n",
        "for d in (\n",
        "    '/app/.pip-target/torch',\n",
        "    '/app/.pip-target/torchvision',\n",
        "    '/app/.pip-target/torchaudio',\n",
        "    '/app/.pip-target/torch-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchvision-0.19.1.dist-info',\n",
        "    '/app/.pip-target/torchaudio-2.4.1.dist-info',\n",
        "    '/app/.pip-target/torchgen',\n",
        "    '/app/.pip-target/functorch',\n",
        "):\n",
        "    if os.path.exists(d):\n",
        "        print('Removing', d)\n",
        "        shutil.rmtree(d, ignore_errors=True)\n",
        "\n",
        "# Install exact cu121 torch stack\n",
        "pip('install',\n",
        "    '--index-url','https://download.pytorch.org/whl/cu121',\n",
        "    '--extra-index-url','https://pypi.org/simple',\n",
        "    'torch==2.4.1','torchvision==0.19.1','torchaudio==2.4.1')\n",
        "\n",
        "# Freeze constraints for later installs\n",
        "Path('constraints.txt').write_text('torch==2.4.1\\ntorchvision==0.19.1\\ntorchaudio==2.4.1\\n')\n",
        "\n",
        "# Install timm without deps to avoid pulling CPU torch wheels\n",
        "pip('install', 'timm==1.0.9', '--no-deps')\n",
        "\n",
        "# Install non-torch deps safely (none of these depend on torch)\n",
        "pip('install','-c','constraints.txt',\n",
        "    'albumentations==1.4.14','opencv-python-headless==4.10.0.84',\n",
        "    'pandas','numpy','scikit-learn',\n",
        "    'tensorboard','einops','pyyaml','matplotlib',\n",
        "    '--upgrade-strategy','only-if-needed')\n",
        "\n",
        "# Sanity check\n",
        "import torch\n",
        "print('torch:', torch.__version__, 'CUDA build:', getattr(torch.version,'cuda',None))\n",
        "print('CUDA available:', torch.cuda.is_available())\n",
        "assert str(getattr(torch.version,'cuda','')).startswith('12.1'), f\"Wrong CUDA build: {torch.version.cuda}\"\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('WARNING: CUDA not available')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "5e9f49a2-0452-4d60-bcb3-f577400cf1c1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# EDA: Load JSONs, build DataFrames, sanity checks, MD coverage\n",
        "import json, os, pandas as pd, numpy as np, math, time\n",
        "from pathlib import Path\n",
        "\n",
        "data_dir = Path('.')\n",
        "train_dir = data_dir / 'train'\n",
        "test_dir = data_dir / 'test'\n",
        "ann_path = data_dir / 'iwildcam2020_train_annotations.json'\n",
        "test_info_path = data_dir / 'iwildcam2020_test_information.json'\n",
        "md_path = data_dir / 'iwildcam2020_megadetector_results.json'\n",
        "sample_sub_path = data_dir / 'sample_submission.csv'\n",
        "\n",
        "t0=time.time()\n",
        "print('Loading train annotations...')\n",
        "with open(ann_path, 'r') as f:\n",
        "    train_json = json.load(f)\n",
        "print('Keys:', list(train_json.keys()))\n",
        "\n",
        "# Expect COCO-like structure\n",
        "images = pd.DataFrame(train_json.get('images', []))\n",
        "ann = pd.DataFrame(train_json.get('annotations', []))\n",
        "cats = pd.DataFrame(train_json.get('categories', []))\n",
        "print('images:', images.shape, 'annotations:', ann.shape, 'categories:', cats.shape)\n",
        "print('images columns:', images.columns.tolist()[:20])\n",
        "print('annotations columns:', ann.columns.tolist())\n",
        "print('categories head:\\n', cats.head(3))\n",
        "\n",
        "# Basic integrity\n",
        "assert 'id' in images.columns and 'file_name' in images.columns, 'images must contain id and file_name'\n",
        "assert 'image_id' in ann.columns and 'category_id' in ann.columns, 'annotations must contain image_id and category_id'\n",
        "assert 'id' in cats.columns, 'categories must contain id'\n",
        "\n",
        "# Merge labels (support seq_id if present)\n",
        "merge_cols = ['id','file_name']\n",
        "if 'location' in images.columns:\n",
        "    merge_cols.append('location')\n",
        "if 'seq_id' in images.columns:\n",
        "    merge_cols.append('seq_id')\n",
        "df = ann.merge(images[merge_cols].rename(columns={'id':'image_id'}), on='image_id', how='left')\n",
        "print('Labeled records:', df.shape, 'unique images in labels:', df['image_id'].nunique())\n",
        "\n",
        "# Location/sequence availability\n",
        "has_location = 'location' in images.columns\n",
        "has_sequence = 'seq_id' in images.columns\n",
        "print('has_location:', has_location, 'has_sequence:', has_sequence)\n",
        "if has_location:\n",
        "    print('unique locations:', images['location'].nunique())\n",
        "    print('location nulls:', images['location'].isna().sum())\n",
        "if has_sequence:\n",
        "    print('unique sequences:', images['seq_id'].nunique())\n",
        "\n",
        "# Category mapping checks\n",
        "cat_ids = cats['id'].tolist()\n",
        "train_cat_min, train_cat_max = min(cat_ids), max(cat_ids)\n",
        "print('Category id range:', train_cat_min, 'to', train_cat_max, 'count:', len(cat_ids))\n",
        "missing_cats = sorted(set(df['category_id'].unique()) - set(cat_ids))\n",
        "print('Missing categories referenced by annotations:', missing_cats[:10], '... count', len(missing_cats))\n",
        "\n",
        "# Verify file paths exist for a small sample\n",
        "exists_sample = df[['file_name']].drop_duplicates().sample(n=min(10, df['file_name'].nunique()), random_state=42)['file_name'].tolist()\n",
        "missing_files = []\n",
        "for fn in exists_sample:\n",
        "    p = train_dir / fn\n",
        "    if not p.exists():\n",
        "        missing_files.append(fn)\n",
        "print('Sample path missing count (train):', len(missing_files))\n",
        "if missing_files[:3]:\n",
        "    print('Missing examples:', missing_files[:3])\n",
        "\n",
        "# Load test info\n",
        "print('\\nLoading test info...')\n",
        "with open(test_info_path, 'r') as f:\n",
        "    test_info = json.load(f)\n",
        "test_images = pd.DataFrame(test_info.get('images', test_info.get('images_info', []))) if isinstance(test_info, dict) else pd.DataFrame(test_info)\n",
        "if test_images.empty and 'images' in train_json:\n",
        "    # some variants store as 'images' key\n",
        "    test_images = pd.DataFrame(test_info.get('images', []))\n",
        "print('test_images shape:', test_images.shape, 'columns:', test_images.columns.tolist()[:20])\n",
        "assert 'file_name' in test_images.columns or 'id' in test_images.columns, 'test info must contain file_name or id'\n",
        "\n",
        "# Sample submission checks\n",
        "sample_sub = pd.read_csv(sample_sub_path)\n",
        "print('sample_submission shape:', sample_sub.shape, 'columns:', sample_sub.columns.tolist())\n",
        "sub_id_col = sample_sub.columns[0]\n",
        "sub_target_col = sample_sub.columns[1]\n",
        "print('Submission Id column:', sub_id_col, 'Target column:', sub_target_col)\n",
        "\n",
        "# Align test id key\n",
        "test_key_col = 'file_name' if 'file_name' in test_images.columns else (sub_id_col if sub_id_col in test_images.columns else None)\n",
        "print('Test key column determined as:', test_key_col)\n",
        "if test_key_col is None:\n",
        "    # try to infer\n",
        "    for c in ['Id','id','image_id','name','file']:\n",
        "        if c in test_images.columns:\n",
        "            test_key_col = c\n",
        "            break\n",
        "print('Final test key column:', test_key_col)\n",
        "assert test_key_col is not None, 'Could not determine test key column'\n",
        "\n",
        "# Verify a few test files exist\n",
        "test_exists_sample = test_images[test_key_col].drop_duplicates().sample(n=min(10, len(test_images)), random_state=42).tolist()\n",
        "missing_test = []\n",
        "for fn in test_exists_sample:\n",
        "    p = test_dir / fn\n",
        "    if not p.exists():\n",
        "        missing_test.append(fn)\n",
        "print('Sample path missing count (test):', len(missing_test))\n",
        "if missing_test[:3]:\n",
        "    print('Missing test examples:', missing_test[:3])\n",
        "\n",
        "# Load MegaDetector results and compute coverage\n",
        "print('\\nLoading MegaDetector results...')\n",
        "with open(md_path, 'r') as f:\n",
        "    md = json.load(f)\n",
        "md_images = md.get('images', md)\n",
        "md_df = pd.DataFrame(md_images)\n",
        "print('MD entries:', md_df.shape, 'columns:', md_df.columns.tolist())\n",
        "\n",
        "# Determine rel_name for MD either via file path present or by joining on id->file_name\n",
        "file_col = 'file' if 'file' in md_df.columns else ('image_path' if 'image_path' in md_df.columns else None)\n",
        "if file_col is not None:\n",
        "    def rel_name(p):\n",
        "        p = str(p)\n",
        "        if p.startswith('train/') or p.startswith('test/'):\n",
        "            return p.split('/',1)[1]\n",
        "        return os.path.basename(p)\n",
        "    md_df['rel_name'] = md_df[file_col].apply(rel_name)\n",
        "else:\n",
        "    # Build id->file_name map from train and test metadata\n",
        "    id_map_cols = ['id','file_name']\n",
        "    id_map = images[id_map_cols].copy()\n",
        "    if ('id' in test_images.columns) and ('file_name' in test_images.columns):\n",
        "        id_map = pd.concat([id_map, test_images[id_map_cols]], ignore_index=True)\n",
        "    md_df = md_df.merge(id_map, on='id', how='left')\n",
        "    assert 'file_name' in md_df.columns, 'MD id could not be mapped to file_name; check schemas'\n",
        "    md_df['rel_name'] = md_df['file_name']\n",
        "\n",
        "# Keep only animal category boxes if present\n",
        "def best_animal_box(recs):\n",
        "    if not isinstance(recs, list) or len(recs)==0:\n",
        "        return None\n",
        "    best = None\n",
        "    for d in recs:\n",
        "        cat = str(d.get('category', ''))\n",
        "        if cat in ('1','animal','animal_person_vehicle'):\n",
        "            if (best is None) or (d.get('conf',0) > best.get('conf',0)):\n",
        "                best = d\n",
        "    return best\n",
        "if 'detections' in md_df.columns:\n",
        "    md_df['best_det'] = md_df['detections'].apply(best_animal_box)\n",
        "else:\n",
        "    md_df['best_det'] = None\n",
        "md_df['has_animal'] = md_df['best_det'].notna()\n",
        "md_cov = md_df.groupby('rel_name')['has_animal'].max().rename('md_has_animal').reset_index()\n",
        "print('MD animal coverage (unique files):', md_cov['md_has_animal'].mean().round(4))\n",
        "\n",
        "# Join MD coverage to train and test samples (by file_name)\n",
        "train_files_unique = images[['file_name']].drop_duplicates().copy()\n",
        "train_md = train_files_unique.merge(md_cov, left_on='file_name', right_on='rel_name', how='left')\n",
        "train_md['md_has_animal'] = train_md['md_has_animal'].fillna(False)\n",
        "print('Train MD coverage:', train_md['md_has_animal'].mean().round(4))\n",
        "test_files_unique = test_images[[test_key_col]].drop_duplicates().copy()\n",
        "test_files_unique.columns = ['file_name_key']\n",
        "test_md = test_files_unique.merge(md_cov, left_on='file_name_key', right_on='rel_name', how='left')\n",
        "test_md['md_has_animal'] = test_md['md_has_animal'].fillna(False)\n",
        "print('Test MD coverage:', test_md['md_has_animal'].mean().round(4))\n",
        "\n",
        "print(f'EDA done in {time.time()-t0:.2f}s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a325bb1a-3023-49ee-aa74-b8503edd18c1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Precompute splits, label maps, and MD best boxes; install missing deps\n",
        "import os, json, math, time, pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import subprocess, sys\n",
        "\n",
        "# Ensure timm deps present (per expert advice)\n",
        "def pip(*args):\n",
        "    print('> pip', *args, flush=True)\n",
        "    subprocess.run([sys.executable, '-m', 'pip', *args], check=True)\n",
        "try:\n",
        "    import huggingface_hub, safetensors\n",
        "except Exception:\n",
        "    pip('install','-c','constraints.txt','huggingface_hub','safetensors','--upgrade-strategy','only-if-needed')\n",
        "\n",
        "data_dir = Path('.')\n",
        "ann_path = data_dir / 'iwildcam2020_train_annotations.json'\n",
        "test_info_path = data_dir / 'iwildcam2020_test_information.json'\n",
        "md_path = data_dir / 'iwildcam2020_megadetector_results.json'\n",
        "\n",
        "with open(ann_path,'r') as f:\n",
        "    train_json = json.load(f)\n",
        "images = pd.DataFrame(train_json['images'])\n",
        "ann = pd.DataFrame(train_json['annotations'])\n",
        "cats = pd.DataFrame(train_json['categories'])\n",
        "train_df = ann.merge(images[['id','file_name','location','seq_id']].rename(columns={'id':'image_id'}), on='image_id', how='left')\n",
        "\n",
        "# Build label maps: category_id -> idx (contiguous) and inverse\n",
        "unique_cat_ids = np.sort(train_df['category_id'].unique())\n",
        "catid2idx = {int(c):i for i,c in enumerate(unique_cat_ids)}\n",
        "idx2catid = {i:int(c) for i,c in enumerate(unique_cat_ids)}\n",
        "print('Num classes:', len(unique_cat_ids))\n",
        "\n",
        "# Class frequencies for weights\n",
        "cls_counts = train_df['category_id'].value_counts().reindex(unique_cat_ids, fill_value=0).values.astype(np.float64)\n",
        "w = 1.0/np.sqrt(np.maximum(1.0, cls_counts))\n",
        "w = w * (len(w)/w.sum())\n",
        "class_weights = w.astype(np.float32)\n",
        "print('Class weight stats min/mean/max:', float(w.min()), float(w.mean()), float(w.max()))\n",
        "\n",
        "# Build 5-fold GroupKFold by location\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "folds = np.full(len(train_df), -1, dtype=np.int16)\n",
        "for fold, (_, val_idx) in enumerate(gkf.split(train_df, groups=train_df['location'])):\n",
        "    folds[val_idx] = fold\n",
        "assert (folds>=0).all()\n",
        "train_df['fold'] = folds\n",
        "fold_sizes = train_df.groupby('fold')['image_id'].nunique().to_dict()\n",
        "print('Fold image counts:', fold_sizes)\n",
        "\n",
        "# Load MegaDetector and compute best box per file (expanded) with guards\n",
        "with open(md_path,'r') as f:\n",
        "    md = json.load(f)\n",
        "md_df = pd.DataFrame(md.get('images', md))\n",
        "def best_animal_box(recs):\n",
        "    if not isinstance(recs, list) or len(recs)==0: return None\n",
        "    best=None\n",
        "    for d in recs:\n",
        "        if str(d.get('category','')) in ('1','animal','animal_person_vehicle'):\n",
        "            if (best is None) or (d.get('conf',0) > best.get('conf',0)): best=d\n",
        "    return best\n",
        "md_df['best_det'] = md_df['detections'].apply(best_animal_box) if 'detections' in md_df.columns else None\n",
        "\n",
        "# Map md id -> file_name via metadata\n",
        "id_map = pd.concat([images[['id','file_name']], pd.DataFrame()], ignore_index=True)\n",
        "md_df = md_df.merge(id_map, on='id', how='left') if 'id' in md_df.columns else md_df\n",
        "assert 'file_name' in md_df.columns, 'Could not map MD entries to file_name'\n",
        "\n",
        "# Build dict: file_name -> {'bbox':[x,y,w,h], 'conf':c} using guards\n",
        "def expand_and_clamp(box, pad, W, H):\n",
        "    x,y,w,h = box\n",
        "    x0 = max(0.0, x - pad*w)\n",
        "    y0 = max(0.0, y - pad*h)\n",
        "    x1 = min(1.0, x + w + pad*w)\n",
        "    y1 = min(1.0, y + h + pad*h)\n",
        "    return [x0, y0, x1-x0, y1-y0]\n",
        "\n",
        "md_best = {}\n",
        "for _, row in md_df.iterrows():\n",
        "    fn = row['file_name']\n",
        "    det = row['best_det'] if isinstance(row.get('best_det',None), dict) else None\n",
        "    if det is None:\n",
        "        continue\n",
        "    conf = float(det.get('conf',0.0))\n",
        "    bbox = det.get('bbox', None)\n",
        "    if not isinstance(bbox, (list,tuple)) or len(bbox)!=4:\n",
        "        continue\n",
        "    x,y,w,h = [float(v) for v in bbox]\n",
        "    area = max(0.0, min(1.0, w))*max(0.0, min(1.0, h))\n",
        "    if (conf < 0.2) or (area < 0.02) or (area > 0.9):\n",
        "        continue\n",
        "    # adaptive padding\n",
        "    pad = 0.35 if conf < 0.3 else (0.25 if conf < 0.7 else 0.15)\n",
        "    eb = expand_and_clamp([x,y,w,h], pad, 1.0, 1.0)\n",
        "    md_best[fn] = {'bbox': eb, 'conf': conf}\n",
        "print('MD best boxes computed:', len(md_best))\n",
        "\n",
        "# Save artifacts\n",
        "art_dir = Path('artifacts')\n",
        "art_dir.mkdir(exist_ok=True)\n",
        "with open(art_dir/'catid2idx.json','w') as f: json.dump({str(k):int(v) for k,v in catid2idx.items()}, f)\n",
        "with open(art_dir/'idx2catid.json','w') as f: json.dump({int(k):int(v) for k,v in idx2catid.items()}, f)\n",
        "np.save(art_dir/'class_weights.npy', class_weights)\n",
        "train_df.to_parquet(art_dir/'train_df.parquet', index=False)\n",
        "with open(art_dir/'md_best.pkl','wb') as f: pickle.dump(md_best, f)\n",
        "print('Saved artifacts to', art_dir)\n",
        "print('Prep done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "63e89290-841b-4784-a9da-fae986f8cc95",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train fold0 convnext_tiny@320 with MD crops; infer test with HFlip TTA + seq averaging; write submission.csv\n",
        "import os, time, math, json, pickle, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageOps, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import timm\n",
        "from timm.utils import ModelEmaV2\n",
        "from timm.data import Mixup\n",
        "from timm.loss import SoftTargetCrossEntropy\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "try:\n",
        "    torch.set_float32_matmul_precision('high')\n",
        "except Exception:\n",
        "    pass\n",
        "os.environ.setdefault('PYTORCH_CUDA_ALLOC_CONF','expandable_segments:True')\n",
        "\n",
        "data_dir = Path('.')\n",
        "train_dir = data_dir/'train'\n",
        "test_dir = data_dir/'test'\n",
        "art_dir = data_dir/'artifacts'\n",
        "\n",
        "# Load artifacts\n",
        "train_df = pd.read_parquet(art_dir/'train_df.parquet')\n",
        "with open(art_dir/'catid2idx.json') as f: catid2idx = {int(k):int(v) for k,v in json.load(f).items()}\n",
        "with open(art_dir/'idx2catid.json') as f: idx2catid = {int(k):int(v) for k,v in json.load(f).items()}\n",
        "class_weights = torch.tensor(np.load(art_dir/'class_weights.npy'), dtype=torch.float32)\n",
        "with open(art_dir/'md_best.pkl','rb') as f: md_best = pickle.load(f)\n",
        "\n",
        "# Load test info and sample submission for keys and seq_id\n",
        "with open(data_dir/'iwildcam2020_test_information.json','r') as f: test_info = json.load(f)\n",
        "test_images = pd.DataFrame(test_info.get('images', test_info.get('images_info', [])))\n",
        "sample_sub = pd.read_csv(data_dir/'sample_submission.csv')\n",
        "sub_id_col, sub_target_col = sample_sub.columns[0], sample_sub.columns[1]\n",
        "\n",
        "# Robustly build test_meta with [Id, file_name, seq_id] using id->file_name mapping\n",
        "if 'id' in test_images.columns and 'file_name' in test_images.columns:\n",
        "    id2file = dict(zip(test_images['id'].tolist(), test_images['file_name'].tolist()))\n",
        "    id2seq = dict(zip(test_images['id'].tolist(), test_images['seq_id'].tolist())) if 'seq_id' in test_images.columns else {}\n",
        "    test_meta = sample_sub[[sub_id_col]].copy()\n",
        "    test_meta = test_meta.rename(columns={sub_id_col: 'Id'})\n",
        "    test_meta['file_name'] = test_meta['Id'].map(id2file)\n",
        "    test_meta['seq_id'] = test_meta['Id'].map(id2seq) if id2seq else -1\n",
        "elif 'file_name' in test_images.columns:\n",
        "    test_meta = sample_sub[[sub_id_col]].copy().rename(columns={sub_id_col: 'Id'})\n",
        "    # Assume Id already equals file_name in this rare schema\n",
        "    test_meta['file_name'] = test_meta['Id']\n",
        "    test_meta['seq_id'] = -1\n",
        "else:\n",
        "    raise AssertionError('Test info must contain id and/or file_name')\n",
        "assert test_meta['file_name'].notna().all(), 'Could not align sample Ids to file_name'\n",
        "\n",
        "# Augment md_best with test crops from MD JSON (guards + adaptive padding)\n",
        "try:\n",
        "    with open(data_dir/'iwildcam2020_megadetector_results.json','r') as f:\n",
        "        md_all = json.load(f)\n",
        "    md_imgs = md_all.get('images', md_all)\n",
        "    test_id2file = dict(zip(test_images['id'].tolist(), test_images['file_name'].tolist())) if 'id' in test_images.columns else {}\n",
        "    def best_animal_box(recs):\n",
        "        if not isinstance(recs, list) or len(recs)==0: return None\n",
        "        best=None\n",
        "        for d in recs:\n",
        "            if str(d.get('category','')) in ('1','animal','animal_person_vehicle'):\n",
        "                if (best is None) or (d.get('conf',0) > best.get('conf',0)): best=d\n",
        "        return best\n",
        "    def expand_and_clamp(box, pad):\n",
        "        x,y,w,h = box\n",
        "        x0 = max(0.0, x - pad*w); y0 = max(0.0, y - pad*h)\n",
        "        x1 = min(1.0, x + w + pad*w); y1 = min(1.0, y + h + pad*h)\n",
        "        return [x0, y0, x1-x0, y1-y0]\n",
        "    added=0\n",
        "    for rec in md_imgs:\n",
        "        rid = rec.get('id', None)\n",
        "        if rid is None or rid not in test_id2file: continue\n",
        "        det = best_animal_box(rec.get('detections', []))\n",
        "        if det is None: continue\n",
        "        conf = float(det.get('conf', 0.0))\n",
        "        bbox = det.get('bbox', None)\n",
        "        if not isinstance(bbox, (list,tuple)) or len(bbox)!=4: continue\n",
        "        x,y,w,h = [float(v) for v in bbox]\n",
        "        area = max(0.0, min(1.0, w))*max(0.0, min(1.0, h))\n",
        "        if (conf < 0.2) or (area < 0.02) or (area > 0.9): continue\n",
        "        pad = 0.35 if conf < 0.3 else (0.25 if conf < 0.7 else 0.15)\n",
        "        eb = expand_and_clamp([x,y,w,h], pad)\n",
        "        fn = test_id2file[rid]\n",
        "        if fn not in md_best:\n",
        "            md_best[fn] = {'bbox': eb, 'conf': conf}\n",
        "            added += 1\n",
        "    print('Augmented md_best with test crops:', added)\n",
        "except Exception as e:\n",
        "    print('MD test augmentation skipped due to error:', e)\n",
        "\n",
        "# Dataset\n",
        "def load_image(path: Path):\n",
        "    with Image.open(path) as im:\n",
        "        im = ImageOps.exif_transpose(im.convert('RGB'))\n",
        "        return im\n",
        "\n",
        "def crop_by_norm_box(im: Image.Image, box):\n",
        "    w, h = im.size\n",
        "    x, y, bw, bh = box\n",
        "    x0 = int(max(0, min(w, x * w)))\n",
        "    y0 = int(max(0, min(h, y * h)))\n",
        "    x1 = int(max(0, min(w, (x + bw) * w)))\n",
        "    y1 = int(max(0, min(h, (y + bh) * h)))\n",
        "    if x1 <= x0 or y1 <= y0:\n",
        "        return im\n",
        "    return im.crop((x0, y0, x1, y1))\n",
        "\n",
        "class IWildCamDataset(Dataset):\n",
        "    def __init__(self, df, root_dir, catid2idx, md_best, is_train=True, img_size=320, md_ignore_p=0.2):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.root = Path(root_dir)\n",
        "        self.catid2idx = catid2idx\n",
        "        self.md_best = md_best\n",
        "        self.is_train = is_train\n",
        "        self.img_size = img_size\n",
        "        self.md_ignore_p = md_ignore_p\n",
        "        mean=(0.485,0.456,0.406); std=(0.229,0.224,0.225)\n",
        "        if is_train:\n",
        "            self.tf = T.Compose([\n",
        "                T.RandomResizedCrop(self.img_size, scale=(0.8, 1.0), ratio=(0.75, 1.333)),\n",
        "                T.RandomHorizontalFlip(p=0.5),\n",
        "                T.ColorJitter(0.2,0.2,0.2,0.0),\n",
        "                T.ToTensor(),\n",
        "                T.RandomErasing(p=0.1, scale=(0.02, 0.33), ratio=(0.3, 3.3), value='random'),\n",
        "                T.Normalize(mean, std),\n",
        "            ])\n",
        "        else:\n",
        "            self.tf = T.Compose([\n",
        "                T.Resize((self.img_size, self.img_size)),\n",
        "                T.ToTensor(),\n",
        "                T.Normalize(mean, std),\n",
        "            ])\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.iloc[idx]\n",
        "        fn = r['file_name']\n",
        "        path = (self.root/fn)\n",
        "        try:\n",
        "            im = load_image(path)\n",
        "            # MD crop logic\n",
        "            use_full = (not self.is_train and fn not in self.md_best) or (self.is_train and (random.random() < self.md_ignore_p or fn not in self.md_best))\n",
        "            if not use_full:\n",
        "                im = crop_by_norm_box(im, self.md_best[fn]['bbox'])\n",
        "        except Exception:\n",
        "            # Fallback: use a solid gray image if the file is corrupted/unreadable\n",
        "            im = Image.new('RGB', (self.img_size, self.img_size), (128,128,128))\n",
        "        out = self.tf(im)\n",
        "        if 'category_id' in r:\n",
        "            y = self.catid2idx[int(r['category_id'])]\n",
        "            return out, torch.tensor(y, dtype=torch.long)\n",
        "        else:\n",
        "            return out, fn  # for test\n",
        "\n",
        "# Model\n",
        "def create_model(num_classes):\n",
        "    model = timm.create_model('convnext_tiny', pretrained=True, num_classes=num_classes, drop_path_rate=0.1)\n",
        "    return model\n",
        "\n",
        "# Train one fold\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_classes = len(idx2catid)\n",
        "fold = 0\n",
        "train_idx = train_df.index[train_df['fold'] != fold].tolist()\n",
        "val_idx = train_df.index[train_df['fold'] == fold].tolist()\n",
        "df_tr = train_df.loc[train_idx, ['file_name','category_id']].copy()\n",
        "df_va = train_df.loc[val_idx, ['file_name','category_id']].copy()\n",
        "print(f'Fold {fold}: train images {df_tr.shape[0]} val images {df_va.shape[0]}')\n",
        "\n",
        "img_size = 320\n",
        "bs = 64\n",
        "epochs = 10\n",
        "use_channels_last = True\n",
        "\n",
        "ds_tr = IWildCamDataset(df_tr, train_dir, catid2idx, md_best, is_train=True, img_size=img_size, md_ignore_p=0.2)\n",
        "ds_va = IWildCamDataset(df_va, train_dir, catid2idx, md_best, is_train=False, img_size=img_size, md_ignore_p=0.0)\n",
        "dl_tr = DataLoader(ds_tr, batch_size=bs, shuffle=True, num_workers=8, pin_memory=True, persistent_workers=True, prefetch_factor=2, drop_last=True)\n",
        "dl_va = DataLoader(ds_va, batch_size=bs, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "\n",
        "model = create_model(num_classes).to(device)\n",
        "if use_channels_last:\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "if hasattr(model, 'set_grad_checkpointing'):\n",
        "    model.set_grad_checkpointing(True)\n",
        "ema = ModelEmaV2(model, decay=0.999)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.05)\n",
        "num_steps = max(1, epochs * math.ceil(len(dl_tr)))\n",
        "warmup_steps = max(1, int(0.2 * math.ceil(len(dl_tr))))\n",
        "def lr_schedule(step):\n",
        "    if step < warmup_steps:\n",
        "        return step / warmup_steps\n",
        "    t = (step - warmup_steps) / max(1, (num_steps - warmup_steps))\n",
        "    return 0.5 * (1 + math.cos(math.pi * t))\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=True)\n",
        "weight = class_weights.to(device)\n",
        "\n",
        "# Mixup + correct loss\n",
        "mixup_fn = Mixup(mixup_alpha=0.2, cutmix_alpha=0.0, prob=0.5, switch_prob=0.0, mode='batch', num_classes=num_classes)\n",
        "crit_soft = SoftTargetCrossEntropy()\n",
        "crit_hard = nn.CrossEntropyLoss(weight=weight, label_smoothing=0.1)\n",
        "\n",
        "best_acc = 0.0\n",
        "best_path = art_dir/f'convnext_tiny_fold{fold}.pt'\n",
        "global_step = 0\n",
        "t_start = time.time()\n",
        "\n",
        "if best_path.exists():\n",
        "    print(f'Found existing model at {best_path}, skipping training.')\n",
        "else:\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        running = 0.0\n",
        "        t0 = time.time()\n",
        "        for i,(x,y) in enumerate(dl_tr):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            if use_channels_last:\n",
        "                x = x.to(memory_format=torch.channels_last)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            lr = 1e-3 * lr_schedule(global_step)\n",
        "            for pg in optimizer.param_groups: pg['lr'] = lr\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast('cuda', dtype=torch.float16):\n",
        "                if mixup_fn is not None:\n",
        "                    x, y_mix = mixup_fn(x, y)\n",
        "                    logits = model(x)\n",
        "                    loss = crit_soft(logits, y_mix)\n",
        "                else:\n",
        "                    logits = model(x)\n",
        "                    loss = crit_hard(logits, y)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            ema.update(model)\n",
        "            running += loss.item() * x.size(0)\n",
        "            global_step += 1\n",
        "            if (i % 100)==0:\n",
        "                print(f'[Ep {ep}] step {i}/{len(dl_tr)} loss {loss.item():.4f} lr {lr:.6f}', flush=True)\n",
        "        tr_loss = running/len(ds_tr)\n",
        "        # Validate\n",
        "        model.eval()\n",
        "        ema_model = ema.module\n",
        "        correct=0; total=0\n",
        "        with torch.no_grad():\n",
        "            for x,y in dl_va:\n",
        "                x = x.to(device, non_blocking=True)\n",
        "                if use_channels_last:\n",
        "                    x = x.to(memory_format=torch.channels_last)\n",
        "                y = y.to(device, non_blocking=True)\n",
        "                with torch.amp.autocast('cuda', dtype=torch.float16):\n",
        "                    logits = ema_model(x)\n",
        "                preds = logits.argmax(1)\n",
        "                correct += (preds==y).sum().item()\n",
        "                total += y.numel()\n",
        "        val_acc = correct/total if total>0 else 0.0\n",
        "        print(f'Epoch {ep}/{epochs} tr_loss {tr_loss:.4f} val_acc {val_acc:.4f} elapsed {(time.time()-t0):.1f}s total {(time.time()-t_start)/60:.1f}m', flush=True)\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save({'model': ema_model.state_dict(), 'acc': best_acc}, best_path)\n",
        "            print(f'New best acc {best_acc:.4f}; saved {best_path}')\n",
        "    print('Best val_acc:', best_acc)\n",
        "\n",
        "assert best_path.exists(), 'No model saved'\n",
        "\n",
        "# Inference on test with HFlip TTA and sequence averaging\n",
        "state = torch.load(best_path, map_location='cpu')\n",
        "model.load_state_dict(state['model'])\n",
        "model.eval()\n",
        "\n",
        "test_ds = IWildCamDataset(test_meta[['file_name']].copy(), test_dir, catid2idx, md_best, is_train=False, img_size=img_size, md_ignore_p=0.0)\n",
        "test_dl = DataLoader(test_ds, batch_size=bs, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "\n",
        "all_logits = []\n",
        "all_files = []\n",
        "with torch.no_grad():\n",
        "    for x, fns in test_dl:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        if use_channels_last:\n",
        "            x = x.to(memory_format=torch.channels_last)\n",
        "        with torch.amp.autocast('cuda', dtype=torch.float16):\n",
        "            logit = model(x)\n",
        "            # HFlip TTA\n",
        "            x_flip = torch.flip(x, dims=[3])\n",
        "            logit_flip = model(x_flip)\n",
        "            logit = (logit + logit_flip) / 2.0\n",
        "        all_logits.append(logit.detach().cpu())\n",
        "        all_files.extend(list(fns))\n",
        "all_logits = torch.cat(all_logits, dim=0).numpy()  # N x C (likely float16 due to autocast)\n",
        "test_pred_df = pd.DataFrame({'file_name': all_files})\n",
        "for i in range(num_classes):\n",
        "    test_pred_df[f'c{i}'] = all_logits[:, i]\n",
        "\n",
        "# Sequence-level averaging (only average valid seqs with count > 1)\n",
        "seq_map = test_meta[['file_name','seq_id']].copy()\n",
        "test_pred_df = test_pred_df.merge(seq_map, on='file_name', how='left')\n",
        "mask = test_pred_df['seq_id'].notna() & (test_pred_df['seq_id'] != -1)\n",
        "logit_cols = [f'c{i}' for i in range(num_classes)]\n",
        "if mask.any():\n",
        "    counts = test_pred_df.loc[mask, 'seq_id'].value_counts()\n",
        "    valid = test_pred_df['seq_id'].isin(counts[counts > 1].index)\n",
        "    if valid.any():\n",
        "        seq_mean = test_pred_df.loc[valid].groupby('seq_id')[logit_cols].mean()\n",
        "        # Match dtype to avoid pandas incompatible dtype warnings (our cols may be float16)\n",
        "        seq_mean = seq_mean.astype(test_pred_df[logit_cols].dtypes.iloc[0])\n",
        "        upd = test_pred_df.loc[valid, ['file_name', 'seq_id']].merge(seq_mean, on='seq_id', how='left').set_index('file_name')[logit_cols]\n",
        "        test_pred_df = test_pred_df.set_index('file_name')\n",
        "        test_pred_df.update(upd)\n",
        "        test_pred_df = test_pred_df.reset_index()\n",
        "\n",
        "# Argmax and map back to original category_id\n",
        "pred_idx = test_pred_df[logit_cols].values.argmax(1)\n",
        "pred_cat = [idx2catid[int(i)] for i in pred_idx]\n",
        "pred_df = pd.DataFrame({'file_name': test_pred_df['file_name'], sub_target_col: pred_cat})\n",
        "\n",
        "# Build submission in sample order (Id from sample_sub, map via test_meta file_name)\n",
        "# Start from Id only to avoid duplicate 'Category' columns\n",
        "sub = sample_sub[[sub_id_col]].copy().rename(columns={sub_id_col: 'Id'})\n",
        "sub = sub.merge(test_meta[['Id','file_name']], on='Id', how='left')\n",
        "sub = sub.merge(pred_df, on='file_name', how='left')\n",
        "sub = sub[['Id', sub_target_col]]\n",
        "assert sub.shape[0] == sample_sub.shape[0], 'Submission row count mismatch'\n",
        "assert sub[sub_target_col].notna().all(), 'Missing predictions in submission'\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with rows:', len(sub))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmented md_best with test crops: 23901\nFold 0: train images 125759 val images 31440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing model at artifacts/convnext_tiny_fold0.pt, skipping training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipykernel_2044/187335788.py:276: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(best_path, map_location='cpu')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}