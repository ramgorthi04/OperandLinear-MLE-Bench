{
  "cells": [
    {
      "id": "b0d3ce89-7f99-4148-bbff-8a6381bec049",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# iNaturalist 2019 FGVC6 - Plan\n",
        "\n",
        "Goal: Ship a strong, GPU-accelerated baseline fast; iterate to medal.\n",
        "\n",
        "Plan:\n",
        "- Environment check: verify GPU and install correct CUDA 12.1 PyTorch stack.\n",
        "- Data audit: inspect train/val/test JSONs; confirm classes and image paths.\n",
        "- Data extraction: untar images into a structured directory if needed.\n",
        "- Validation: Stratified K-Fold on training (or train+val) respecting categories.\n",
        "- Baseline model: timm pretrained ConvNeXt/ResNet at 224px; mixed precision; strong aug.\n",
        "- Training loop: proper logging, early stopping, save OOF and test logits.\n",
        "- Submission: top-1 predictions for test; format: image_id, category_id.\n",
        "- Iterate: improve resolution/architectures, aug, label-smoothing, EMA; ensemble if time.\n",
        "\n",
        "Checkpoints for expert review:\n",
        "- After environment + data audit\n",
        "- After baseline CV setup\n",
        "- After first trained baseline + LB result\n",
        "- Before heavy training runs / ensembling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "4b82cc68-9e53-4036-b354-3b71b3ed6da9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Environment check, Torch install (cu121), and data audit\n",
        "import os, sys, json, time, shutil, subprocess, tarfile\n",
        "from pathlib import Path\n",
        "\n",
        "def run(cmd):\n",
        "    return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True).stdout\n",
        "\n",
        "print('== nvidia-smi ==', flush=True)\n",
        "print(run(['bash','-lc','nvidia-smi || true']))\n",
        "\n",
        "# Install exact cu121 torch stack if missing or wrong build\n",
        "def ensure_torch_cu121():\n",
        "    try:\n",
        "        import torch\n",
        "        ok = str(getattr(torch.version,'cuda','')).startswith('12.1')\n",
        "        if not ok:\n",
        "            raise ImportError('Wrong CUDA build')\n",
        "        print('Torch present:', torch.__version__, 'CUDA build:', torch.version.cuda, 'CUDA avail:', torch.cuda.is_available(), flush=True)\n",
        "        if not torch.cuda.is_available():\n",
        "            raise ImportError('CUDA not available at runtime')\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print('Reinstalling torch stack due to:', e, flush=True)\n",
        "        # Uninstall possibly wrong stacks\n",
        "        for pkg in ('torch','torchvision','torchaudio'):\n",
        "            subprocess.run([sys.executable,'-m','pip','uninstall','-y',pkg], check=False)\n",
        "        # Clean stray site dirs that can shadow wheels\n",
        "        for d in (\n",
        "            '/app/.pip-target/torch','/app/.pip-target/torchvision','/app/.pip-target/torchaudio',\n",
        "            '/app/.pip-target/torch-2.8.0.dist-info','/app/.pip-target/torch-2.4.1.dist-info',\n",
        "            '/app/.pip-target/torchvision-0.23.0.dist-info','/app/.pip-target/torchvision-0.19.1.dist-info',\n",
        "            '/app/.pip-target/torchaudio-2.8.0.dist-info','/app/.pip-target/torchaudio-2.4.1.dist-info',\n",
        "            '/app/.pip-target/torchgen','/app/.pip-target/functorch',\n",
        "        ):\n",
        "            if os.path.exists(d):\n",
        "                shutil.rmtree(d, ignore_errors=True)\n",
        "        # Install\n",
        "        cmd = [sys.executable,'-m','pip','install','--index-url','https://download.pytorch.org/whl/cu121','--extra-index-url','https://pypi.org/simple','torch==2.4.1','torchvision==0.19.1','torchaudio==2.4.1']\n",
        "        print('>', ' '.join(cmd), flush=True)\n",
        "        subprocess.run(cmd, check=True)\n",
        "        import torch\n",
        "        print('torch:', torch.__version__, 'built CUDA:', getattr(torch.version,'cuda',None), flush=True)\n",
        "        print('CUDA available:', torch.cuda.is_available(), flush=True)\n",
        "        assert str(getattr(torch.version,'cuda','')).startswith('12.1')\n",
        "        assert torch.cuda.is_available(), 'CUDA not available after install'\n",
        "        print('GPU:', torch.cuda.get_device_name(0), flush=True)\n",
        "\n",
        "ensure_torch_cu121()\n",
        "\n",
        "print('== Repo listing ==', flush=True)\n",
        "for p in sorted(Path('.').glob('*')):\n",
        "    sz = p.stat().st_size\n",
        "    print(f'{p.name}\\t{sz/1e6:.2f} MB')\n",
        "\n",
        "# Load JSONs\n",
        "def load_json(fp):\n",
        "    with open(fp,'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "train_js = load_json('train2019.json')\n",
        "val_js = load_json('val2019.json')\n",
        "test_js = load_json('test2019.json')\n",
        "\n",
        "def summarize(js, name):\n",
        "    imgs = js.get('images', [])\n",
        "    anns = js.get('annotations', [])\n",
        "    cats = js.get('categories', [])\n",
        "    print(f'-- {name} -- images: {len(imgs)}, annotations: {len(anns)}, categories: {len(cats)}', flush=True)\n",
        "    if imgs:\n",
        "        print('sample image:', imgs[0])\n",
        "    if anns:\n",
        "        print('sample ann:', anns[0])\n",
        "    if cats:\n",
        "        print('sample cat:', cats[0])\n",
        "\n",
        "summarize(train_js, 'train')\n",
        "summarize(val_js, 'val')\n",
        "summarize(test_js, 'test')\n",
        "\n",
        "# Peek into tar files\n",
        "def peek_tar(fp, n=5):\n",
        "    print(f'-- Peek {fp} --', flush=True)\n",
        "    with tarfile.open(fp, 'r:gz') as tf:\n",
        "        names = [m.name for m in tf.getmembers() if m.isfile()]\n",
        "        print('files:', len(names))\n",
        "        for x in names[:n]:\n",
        "            print(' ', x)\n",
        "\n",
        "peek_tar('train_val2019.tar.gz', 5)\n",
        "peek_tar('test2019.tar.gz', 5)\n",
        "\n",
        "print('ENV & data audit complete.', flush=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== nvidia-smi ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 28 22:59:24 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.144.06             Driver Version: 550.144.06     CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA A10-24Q                 On  |   00000002:00:00.0 Off |                    0 |\n| N/A   N/A    P0             N/A /  N/A  |     182MiB /  24512MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n\nReinstalling torch stack due to: No module named 'torch'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torch as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchvision as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> /usr/bin/python3.11 -m pip install --index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://pypi.org/simple torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Skipping torchaudio as it is not installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.org/simple\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (799.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 799.0/799.0 MB 516.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.19.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 7.1/7.1 MB 237.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchaudio==2.4.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 3.4/3.4 MB 352.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec\n  Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 199.3/199.3 KB 7.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusparse-cu12==12.1.0.106\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 196.0/196.0 MB 227.4 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu12==12.1.105\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 823.6/823.6 KB 233.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cusolver-cu12==11.4.5.107\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 124.2/124.2 MB 132.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvtx-cu12==12.1.105\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 99.1/99.1 KB 407.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-cupti-cu12==12.1.105\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 14.1/14.1 MB 214.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sympy\n  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.3/6.3 MB 155.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting filelock\n  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\nCollecting nvidia-curand-cu12==10.3.2.106\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 56.5/56.5 MB 203.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jinja2\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 134.9/134.9 KB 501.8 MB/s eta 0:00:00\nCollecting nvidia-cudnn-cu12==9.1.0.70\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 664.8/664.8 MB 183.7 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nccl-cu12==2.20.5\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 176.2/176.2 MB 92.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 23.7/23.7 MB 178.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cufft-cu12==11.0.2.54\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 121.6/121.6 MB 229.1 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cublas-cu12==12.1.3.1\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 410.6/410.6 MB 222.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton==3.0.0\n  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 209.4/209.4 MB 174.3 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions>=4.8.0\n  Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 44.6/44.6 KB 425.0 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting networkx\n  Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 2.0/2.0 MB 563.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 18.3/18.3 MB 87.5 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pillow!=8.3.*,>=5.3.0\n  Downloading pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 6.6/6.6 MB 279.9 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-nvjitlink-cu12\n  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 39.7/39.7 MB 233.6 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MarkupSafe>=2.0\n  Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpmath<1.4,>=1.1.0\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 536.2/536.2 KB 475.2 MB/s eta 0:00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed MarkupSafe-3.0.3 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 pillow-11.3.0 sympy-1.14.0 torch-2.4.1+cu121 torchaudio-2.4.1+cu121 torchvision-0.19.1+cu121 triton-3.0.0 typing-extensions-4.15.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.4.1+cu121 built CUDA: 12.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: NVIDIA A10-24Q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Repo listing ==\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".00_eda_and_planning_kernel_state.json\t0.00 MB\n00_eda_and_planning.ipynb\t0.01 MB\nagent_metadata\t0.00 MB\ndescription.md\t0.01 MB\ndocker_run.log\t0.04 MB\nkaggle_sample_submission.csv\t0.34 MB\nrequirements.txt\t0.00 MB\nsubmission.csv\t0.34 MB\ntask.txt\t0.00 MB\ntest2019.json\t7.86 MB\ntest2019.tar.gz\t9501.32 MB\ntrain2019.json\t86.20 MB\ntrain_val2019.tar.gz\t68612.51 MB\nval2019.json\t0.84 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- train -- images: 232999, annotations: 232999, categories: 1010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample image: {'file_name': 'train_val2019/Plants/400/5a8f865ac7a3b5f7694e3116198c7564.jpg', 'height': 800, 'id': 36800, 'license': 3, 'rights_holder': 'kerriohara', 'width': 600}\nsample ann: {'category_id': 400, 'id': 36800, 'image_id': 36800}\nsample cat: {'class': 'KSMQKH', 'family': 'RPVDIT', 'genus': 'AIEVWT', 'id': 0, 'kingdom': 'SMHLVG', 'name': 'UYRGAX', 'order': 'GWFTGO', 'phylum': 'QVXHMU'}\n-- val -- images: 3030, annotations: 3030, categories: 1010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample image: {'license': 3, 'file_name': 'train_val2019/Plants/644/716a69838526f3ada3b2fe2e099cfcb6.jpg', 'rights_holder': 'Adrian Stewart', 'height': 618, 'width': 800, 'id': 265213}\nsample ann: {'image_id': 265213, 'category_id': 644, 'id': 265213}\nsample cat: {'kingdom': 'SMHLVG', 'phylum': 'QVXHMU', 'name': 'UYRGAX', 'family': 'RPVDIT', 'genus': 'AIEVWT', 'order': 'GWFTGO', 'id': 0, 'class': 'KSMQKH'}\n-- test -- images: 32214, annotations: 0, categories: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample image: {'file_name': 'test2019/2882396373c6e0f89f755fd5e0e810e5.jpg', 'height': 533, 'id': 177388, 'license': 3, 'rights_holder': 'Mike Hannisian', 'width': 800}\n-- Peek train_val2019.tar.gz --\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ReadError",
          "evalue": "not a gzip file",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mBadGzipFile\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:1705\u001b[39m, in \u001b[36mTarFile.gzopen\u001b[39m\u001b[34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[39m\n\u001b[32m   1704\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1705\u001b[39m     t = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtaropen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:1682\u001b[39m, in \u001b[36mTarFile.taropen\u001b[39m\u001b[34m(cls, name, mode, fileobj, **kwargs)\u001b[39m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mmode must be \u001b[39m\u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:1542\u001b[39m, in \u001b[36mTarFile.__init__\u001b[39m\u001b[34m(self, name, mode, fileobj, format, tarinfo, dereference, ignore_zeros, encoding, errors, pax_headers, debug, errorlevel, copybufsize)\u001b[39m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28mself\u001b[39m.firstmember = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1542\u001b[39m     \u001b[38;5;28mself\u001b[39m.firstmember = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33ma\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1545\u001b[39m     \u001b[38;5;66;03m# Move to the end of the archive,\u001b[39;00m\n\u001b[32m   1546\u001b[39m     \u001b[38;5;66;03m# before the first empty block.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:2377\u001b[39m, in \u001b[36mTarFile.next\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2376\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2377\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2378\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:2350\u001b[39m, in \u001b[36mTarFile.next\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2349\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2350\u001b[39m     tarinfo = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromtarfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2351\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EOFHeaderError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:1122\u001b[39m, in \u001b[36mTarInfo.fromtarfile\u001b[39m\u001b[34m(cls, tarfile)\u001b[39m\n\u001b[32m   1119\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the next TarInfo object from TarFile object\u001b[39;00m\n\u001b[32m   1120\u001b[39m \u001b[33;03m   tarfile.\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1122\u001b[39m buf = \u001b[43mtarfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBLOCKSIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m obj = \u001b[38;5;28mcls\u001b[39m.frombuf(buf, tarfile.encoding, tarfile.errors)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/gzip.py:301\u001b[39m, in \u001b[36mGzipFile.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    300\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno.EBADF, \u001b[33m\"\u001b[39m\u001b[33mread() on write-only GzipFile object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/_compression.py:68\u001b[39m, in \u001b[36mDecompressReader.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view.cast(\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] = data\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/gzip.py:499\u001b[39m, in \u001b[36m_GzipReader.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28mself\u001b[39m._init_read()\n\u001b[32m--> \u001b[39m\u001b[32m499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_gzip_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    500\u001b[39m     \u001b[38;5;28mself\u001b[39m._size = \u001b[38;5;28mself\u001b[39m._pos\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/gzip.py:468\u001b[39m, in \u001b[36m_GzipReader._read_gzip_header\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_gzip_header\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m     last_mtime = \u001b[43m_read_gzip_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m last_mtime \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/gzip.py:428\u001b[39m, in \u001b[36m_read_gzip_header\u001b[39m\u001b[34m(fp)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m magic != \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\037\u001b[39;00m\u001b[38;5;130;01m\\213\u001b[39;00m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadGzipFile(\u001b[33m'\u001b[39m\u001b[33mNot a gzipped file (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m'\u001b[39m % magic)\n\u001b[32m    430\u001b[39m (method, flag, last_mtime) = struct.unpack(\u001b[33m\"\u001b[39m\u001b[33m<BBIxx\u001b[39m\u001b[33m\"\u001b[39m, _read_exact(fp, \u001b[32m8\u001b[39m))\n",
            "\u001b[31mBadGzipFile\u001b[39m: Not a gzipped file (b'./')",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mReadError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 89\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m names[:n]:\n\u001b[32m     87\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m, x)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m \u001b[43mpeek_tar\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain_val2019.tar.gz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m peek_tar(\u001b[33m'\u001b[39m\u001b[33mtest2019.tar.gz\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m5\u001b[39m)\n\u001b[32m     92\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mENV & data audit complete.\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mpeek_tar\u001b[39m\u001b[34m(fp, n)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpeek_tar\u001b[39m(fp, n=\u001b[32m5\u001b[39m):\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m-- Peek \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m --\u001b[39m\u001b[33m'\u001b[39m, flush=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtarfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr:gz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m tf:\n\u001b[32m     84\u001b[39m         names = [m.name \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m tf.getmembers() \u001b[38;5;28;01mif\u001b[39;00m m.isfile()]\n\u001b[32m     85\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mfiles:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(names))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:1652\u001b[39m, in \u001b[36mTarFile.open\u001b[39m\u001b[34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[39m\n\u001b[32m   1650\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1651\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CompressionError(\u001b[33m\"\u001b[39m\u001b[33munknown compression type \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % comptype)\n\u001b[32m-> \u001b[39m\u001b[32m1652\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1654\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m|\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1655\u001b[39m     filemode, comptype = mode.split(\u001b[33m\"\u001b[39m\u001b[33m|\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/tarfile.py:1709\u001b[39m, in \u001b[36mTarFile.gzopen\u001b[39m\u001b[34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[39m\n\u001b[32m   1707\u001b[39m     fileobj.close()\n\u001b[32m   1708\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1709\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ReadError(\u001b[33m\"\u001b[39m\u001b[33mnot a gzip file\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1710\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1711\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
            "\u001b[31mReadError\u001b[39m: not a gzip file"
          ]
        }
      ]
    },
    {
      "id": "366bfe1a-0163-4d2a-b992-65ebaad5052b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extract tar archives (auto-detect compression) and verify file paths\n",
        "import tarfile, os, time\n",
        "from pathlib import Path\n",
        "\n",
        "def extract_tar(fp: str, dest: str = '.'):\n",
        "    t0 = time.time()\n",
        "    print(f'Extracting {fp} -> {dest}', flush=True)\n",
        "    assert Path(fp).exists(), f'Missing archive: {fp}'\n",
        "    assert tarfile.is_tarfile(fp), f'Not a tar archive: {fp}'\n",
        "    with tarfile.open(fp, mode='r:*') as tf:\n",
        "        members = tf.getmembers()\n",
        "        print(f'Members: {len(members)}', flush=True)\n",
        "        tf.extractall(path=dest)\n",
        "    print(f'Done {fp} in {time.time()-t0:.1f}s', flush=True)\n",
        "\n",
        "# Only extract if top-level dirs don't already exist\n",
        "need_train_val = not Path('train_val2019').exists()\n",
        "need_test = not Path('test2019').exists()\n",
        "if need_train_val:\n",
        "    extract_tar('train_val2019.tar.gz', '.')\n",
        "else:\n",
        "    print('train_val2019/ already exists, skip extraction')\n",
        "if need_test:\n",
        "    extract_tar('test2019.tar.gz', '.')\n",
        "else:\n",
        "    print('test2019/ already exists, skip extraction')\n",
        "\n",
        "# Verify JSON file paths exist\n",
        "def check_paths(js, name, n=10):\n",
        "    miss = 0\n",
        "    imgs = js.get('images', [])[:n]\n",
        "    for im in imgs:\n",
        "        fp = im['file_name']\n",
        "        if not Path(fp).exists():\n",
        "            print('MISSING:', fp)\n",
        "            miss += 1\n",
        "    print(f'{name}: checked {len(imgs)} paths, missing {miss}')\n",
        "\n",
        "check_paths(train_js, 'train', 20)\n",
        "check_paths(val_js, 'val', 20)\n",
        "check_paths(test_js, 'test', 20)\n",
        "print('Extraction & path verification complete.', flush=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting train_val2019.tar.gz -> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Members: 232999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done train_val2019.tar.gz in 74.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting test2019.tar.gz -> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Members: 32214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done test2019.tar.gz in 10.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MISSING: train_val2019/Plants/400/5a8f865ac7a3b5f7694e3116198c7564.jpg\nMISSING: train_val2019/Plants/400/b29ce08f0f5e68cd489ee5e1f1469fcc.jpg\nMISSING: train_val2019/Plants/400/545645ddeadacac64926b3bf012916b1.jpg\nMISSING: train_val2019/Plants/400/cb06f47ac10823ee9c051d1027177561.jpg\nMISSING: train_val2019/Plants/400/fedf0f512e9450c32f34f2f0a6788a92.jpg\nMISSING: train_val2019/Plants/400/de45225566c43c17a5c02d1d26c992ec.jpg\nMISSING: train_val2019/Plants/400/af7fdd89518238215b309bfe56e1b3f6.jpg\nMISSING: train_val2019/Plants/400/d61ede7003f14fee1180385e8e3cb654.jpg\nMISSING: train_val2019/Plants/400/6192a801c4bf7f03fa53db9665135c0a.jpg\nMISSING: train_val2019/Plants/400/fa30268fd7f5dff1c97e0ada9896cb94.jpg\nMISSING: train_val2019/Plants/400/07ee66a72874f551069395e4c20bda47.jpg\nMISSING: train_val2019/Plants/400/2648d193906b70c822e373857c339616.jpg\nMISSING: train_val2019/Plants/400/c411577f4f150e6cd771edf1a9c33a50.jpg\nMISSING: train_val2019/Plants/400/f9a35f4afbd6b20d0587ee48c5b3aef7.jpg\nMISSING: train_val2019/Plants/400/ee5d45e10bef92352c6499048e85a8ef.jpg\nMISSING: train_val2019/Plants/400/ed5f9ffb33f9980d996cd2bd06f5ee5c.jpg\nMISSING: train_val2019/Plants/400/a970495f36653009657f393dc8ef7793.jpg\nMISSING: train_val2019/Plants/400/32976bdf6ec1ed7905aa68b61a48ec66.jpg\nMISSING: train_val2019/Plants/400/e27e527103016f554d79cb9a6f7279ca.jpg\nMISSING: train_val2019/Plants/400/8509e21b53f1d85123660667a40a03d0.jpg\ntrain: checked 20 paths, missing 20\nMISSING: train_val2019/Plants/644/716a69838526f3ada3b2fe2e099cfcb6.jpg\nMISSING: train_val2019/Plants/597/0942cc64d2e759c5ee05970d8170942c.jpg\nMISSING: train_val2019/Plants/883/acfdbfd9fa675f1c84558e3b9239db90.jpg\nMISSING: train_val2019/Birds/300/5f3194ff536c7dd31d80b78ef809bc23.jpg\nMISSING: train_val2019/Plants/881/76acaf0b2841f91982d2197cff825014.jpg\nMISSING: train_val2019/Plants/771/5d190fd90da893988a3c9043b607fd24.jpg\nMISSING: train_val2019/Plants/607/8fb0ddfe92dadbf9c575305387f4795d.jpg\nMISSING: train_val2019/Plants/698/6d71521a64d1e2fe8bb34a94dee3d656.jpg\nMISSING: train_val2019/Plants/714/09508f2bf937d21d63297f40b6abc731.jpg\nMISSING: train_val2019/Birds/316/21c700bc90523485af67308cecdf4cd4.jpg\nMISSING: train_val2019/Plants/726/847b2ebf8efc1a528c2d31ac9be2d6ed.jpg\nMISSING: train_val2019/Insects/27/e5d141185a3a50b544d153d8be82c4b7.jpg\nMISSING: train_val2019/Plants/640/cbe5ff1a159b614ae8677bd8bfefdfe2.jpg\nMISSING: train_val2019/Plants/756/a99c33a5f954ffecd73408ea232f6f47.jpg\nMISSING: train_val2019/Insects/73/2fc6b41247af765af9984da1eec3547f.jpg\nMISSING: train_val2019/Plants/594/d98519788816a0f61bd152ed2a961108.jpg\nMISSING: train_val2019/Reptiles/179/914aab5662e77a128c777beef1c36f3a.jpg\nMISSING: train_val2019/Plants/440/02f1f67068df3d885546760852ea84bb.jpg\nMISSING: train_val2019/Plants/859/23ba5d0baf198007ec0978e06a2c4fcf.jpg\nMISSING: train_val2019/Fungi/5/3308225981fc58e6eb6a78891b505fe4.jpg\nval: checked 20 paths, missing 20\nMISSING: test2019/2882396373c6e0f89f755fd5e0e810e5.jpg\nMISSING: test2019/437b7310fe7d060a8a09a50cd8758d66.jpg\nMISSING: test2019/baf96733bdc1eaf9f3ec6eaaea279eb0.jpg\nMISSING: test2019/66d1b4fd021d49a4fb6a1b0cb90a98c8.jpg\nMISSING: test2019/6f82398a4fb93d69f4d348749a170a62.jpg\nMISSING: test2019/b082063c72e3da3cf0c1516e7acde0f6.jpg\nMISSING: test2019/e871a6bb266b253c3752918e0e369cab.jpg\nMISSING: test2019/4bf3e72fe66829af8537bb7b83b0dfac.jpg\nMISSING: test2019/771d337badb6b77d8f291e772df39da3.jpg\nMISSING: test2019/4797149cb68b25835658a1c8ce987a08.jpg\nMISSING: test2019/7a2b3c728e3bd65fad308ec0ec9ff245.jpg\nMISSING: test2019/e2d01856f574c11ab8b6da1993081a88.jpg\nMISSING: test2019/f9e5ca72dc3e15ee8b13c0f05d4b37ef.jpg\nMISSING: test2019/a3324d015210cf8193e7ccd42ba1d866.jpg\nMISSING: test2019/d063e07765608e4e2ab751928476c973.jpg\nMISSING: test2019/2031d008518819471dcbc42cf63567de.jpg\nMISSING: test2019/0777dc139f49b1a094b7b164b3547204.jpg\nMISSING: test2019/f09ebaffbe7f7f4fbb35bf4066f71d3f.jpg\nMISSING: test2019/ea29ed61cdccfd16e589da5bb5194cd6.jpg\nMISSING: test2019/eaae6c7c6c2df2161adeb55ba2ea09a6.jpg\ntest: checked 20 paths, missing 20\nExtraction & path verification complete.\n"
          ]
        }
      ]
    },
    {
      "id": "41193c51-ee5c-47ed-ad04-a39473eaceae",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fix paths: create symlinks so JSON file_name paths resolve\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "def ensure_symlink(link: str, target: str):\n",
        "    lp = Path(link)\n",
        "    tp = Path(target)\n",
        "    if lp.exists() or lp.is_symlink():\n",
        "        try:\n",
        "            # if it's a wrong symlink, remove and recreate\n",
        "            if lp.is_symlink() and os.readlink(lp) != str(tp):\n",
        "                lp.unlink()\n",
        "        except Exception:\n",
        "            pass\n",
        "    if not lp.exists():\n",
        "        print(f'Creating symlink: {link} -> {target}', flush=True)\n",
        "        lp.symlink_to(tp, target_is_directory=True)\n",
        "    else:\n",
        "        print(f'Symlink/dir already present: {link}', flush=True)\n",
        "\n",
        "# The extracted archives placed category folders and test jpgs at repository root.\n",
        "# JSON expects 'train_val2019/... and test2019/...'. Point both to '.' via symlinks.\n",
        "if not Path('train_val2019').exists():\n",
        "    ensure_symlink('train_val2019', '.')\n",
        "else:\n",
        "    print('train_val2019 exists')\n",
        "if not Path('test2019').exists():\n",
        "    ensure_symlink('test2019', '.')\n",
        "else:\n",
        "    print('test2019 exists')\n",
        "\n",
        "# Re-check a handful of paths after symlink fix\n",
        "check_paths(train_js, 'train', 20)\n",
        "check_paths(val_js, 'val', 20)\n",
        "check_paths(test_js, 'test', 20)\n",
        "print('Symlink path fix complete.', flush=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating symlink: train_val2019 -> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating symlink: test2019 -> .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: checked 20 paths, missing 0\nMISSING: train_val2019/Plants/644/716a69838526f3ada3b2fe2e099cfcb6.jpg\nMISSING: train_val2019/Plants/597/0942cc64d2e759c5ee05970d8170942c.jpg\nMISSING: train_val2019/Plants/883/acfdbfd9fa675f1c84558e3b9239db90.jpg\nMISSING: train_val2019/Birds/300/5f3194ff536c7dd31d80b78ef809bc23.jpg\nMISSING: train_val2019/Plants/881/76acaf0b2841f91982d2197cff825014.jpg\nMISSING: train_val2019/Plants/771/5d190fd90da893988a3c9043b607fd24.jpg\nMISSING: train_val2019/Plants/607/8fb0ddfe92dadbf9c575305387f4795d.jpg\nMISSING: train_val2019/Plants/698/6d71521a64d1e2fe8bb34a94dee3d656.jpg\nMISSING: train_val2019/Plants/714/09508f2bf937d21d63297f40b6abc731.jpg\nMISSING: train_val2019/Birds/316/21c700bc90523485af67308cecdf4cd4.jpg\nMISSING: train_val2019/Plants/726/847b2ebf8efc1a528c2d31ac9be2d6ed.jpg\nMISSING: train_val2019/Insects/27/e5d141185a3a50b544d153d8be82c4b7.jpg\nMISSING: train_val2019/Plants/640/cbe5ff1a159b614ae8677bd8bfefdfe2.jpg\nMISSING: train_val2019/Plants/756/a99c33a5f954ffecd73408ea232f6f47.jpg\nMISSING: train_val2019/Insects/73/2fc6b41247af765af9984da1eec3547f.jpg\nMISSING: train_val2019/Plants/594/d98519788816a0f61bd152ed2a961108.jpg\nMISSING: train_val2019/Reptiles/179/914aab5662e77a128c777beef1c36f3a.jpg\nMISSING: train_val2019/Plants/440/02f1f67068df3d885546760852ea84bb.jpg\nMISSING: train_val2019/Plants/859/23ba5d0baf198007ec0978e06a2c4fcf.jpg\nMISSING: train_val2019/Fungi/5/3308225981fc58e6eb6a78891b505fe4.jpg\nval: checked 20 paths, missing 20\ntest: checked 20 paths, missing 0\nSymlink path fix complete.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}