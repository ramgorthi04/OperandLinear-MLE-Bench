{
  "cells": [
    {
      "id": "665a9b0b-91ce-451f-88d3-4e5e47f23e50",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detecting Insults in Social Commentary - Plan and Experiment Log\n",
        "\n",
        "## Plan\n",
        "- Load data (train.csv, test.csv); inspect columns, sizes, target distribution.\n",
        "- Baseline: TF-IDF (word + char n-grams) -> Logistic Regression (linear) with class_weight='balanced'.\n",
        "- Cross-validation: StratifiedKFold (5 folds), AUC-ROC per fold; log timing.\n",
        "- Iterate: try feature tweaks (char_wb 3-5, word 1-2, sublinear TF, min_df), tune C and regularization.\n",
        "- Train on full train with chosen setup; generate test predictions and save submission.csv.\n",
        "- Keep concise logs; avoid long blocking; interrupt if too slow.\n",
        "\n",
        "## Experiment Log\n",
        "- v0: Baseline TF-IDF(word 1-2, char_wb 3-5, sublinear_tf, min_df=2) + LogisticRegression(saga, l2, C=4.0, class_weight='balanced'). 5-fold CV AUC target: >0.78.\n",
        "\n",
        "---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "5c1e9215-bb92-42c9-935a-6edeaacc28f5",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Baseline: TF-IDF (word+char) + Logistic Regression with 5-fold CV\n",
        "import os, re, time, sys, math, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "def normalize_text(s: str) -> str:\n",
        "    if not isinstance(s, str):\n",
        "        s = '' if pd.isna(s) else str(s)\n",
        "    s = s.lower()\n",
        "    # URLs\n",
        "    s = re.sub(r'https?://\\S+|www\\.\\S+', ' URL ', s)\n",
        "    # @mentions\n",
        "    s = re.sub(r'@[A-Za-z0-9_]+', ' USER ', s)\n",
        "    # numbers\n",
        "    s = re.sub(r'\\d+', ' NUM ', s)\n",
        "    return s\n",
        "\n",
        "print('Loading data...')\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "text_col = 'Comment'\n",
        "target_col = 'Insult'\n",
        "id_col = 'id' if 'id' in train.columns else ('Id' if 'Id' in train.columns else train.columns[0])\n",
        "print('Train shape:', train.shape, ' Test shape:', test.shape)\n",
        "print('Columns:', train.columns.tolist())\n",
        "print('Target distribution:')\n",
        "print(train[target_col].value_counts(normalize=True))\n",
        "\n",
        "X_text = train[text_col].astype(str).apply(normalize_text).values\n",
        "y = train[target_col].values.astype(int)\n",
        "X_test_text = test[text_col].astype(str).apply(normalize_text).values\n",
        "\n",
        "# Config\n",
        "n_splits = 5\n",
        "seed = 42\n",
        "word_params = dict(ngram_range=(1,2), min_df=2, strip_accents='unicode', lowercase=True, sublinear_tf=True, analyzer='word')\n",
        "char_params = dict(ngram_range=(3,5), min_df=2, strip_accents='unicode', lowercase=True, sublinear_tf=True, analyzer='char_wb')\n",
        "C_val = 4.0\n",
        "\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "oof = np.zeros(len(train), dtype=float)\n",
        "fold_times = []\n",
        "fold_aucs = []\n",
        "\n",
        "print('Starting 5-fold CV...')\n",
        "t0 = time.time()\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_text, y), 1):\n",
        "    fstart = time.time()\n",
        "    X_tr, X_va = X_text[tr_idx], X_text[va_idx]\n",
        "    y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "\n",
        "    # Vectorizers fit on training fold only\n",
        "    word_vec = TfidfVectorizer(**word_params)\n",
        "    char_vec = TfidfVectorizer(**char_params)\n",
        "    Xw_tr = word_vec.fit_transform(X_tr)\n",
        "    Xw_va = word_vec.transform(X_va)\n",
        "    Xc_tr = char_vec.fit_transform(X_tr)\n",
        "    Xc_va = char_vec.transform(X_va)\n",
        "    X_tr_mat = sparse.hstack([Xw_tr, Xc_tr], format='csr')\n",
        "    X_va_mat = sparse.hstack([Xw_va, Xc_va], format='csr')\n",
        "\n",
        "    clf = LogisticRegression(solver='saga', penalty='l2', C=C_val, max_iter=5000, n_jobs=-1, random_state=seed)\n",
        "    clf.fit(X_tr_mat, y_tr)\n",
        "    va_pred = clf.predict_proba(X_va_mat)[:, 1]\n",
        "    oof[va_idx] = va_pred\n",
        "    auc = roc_auc_score(y_va, va_pred)\n",
        "    fold_aucs.append(auc)\n",
        "    ftime = time.time() - fstart\n",
        "    fold_times.append(ftime)\n",
        "    print(f'Fold {fold}/{n_splits}: AUC={auc:.5f} | time={ftime:.2f}s | tr_n={len(tr_idx)} va_n={len(va_idx)}', flush=True)\n",
        "\n",
        "cv_auc = roc_auc_score(y, oof)\n",
        "elapsed = time.time() - t0\n",
        "print(f'CV AUC (OOF): {cv_auc:.5f} | mean_fold={np.mean(fold_aucs):.5f} \u00b1 {np.std(fold_aucs):.5f} | total_time={elapsed:.2f}s')\n",
        "\n",
        "# Train on full data for baseline submission\n",
        "print('Training full model for submission...')\n",
        "wf = TfidfVectorizer(**word_params)\n",
        "cf = TfidfVectorizer(**char_params)\n",
        "Xw_full = wf.fit_transform(X_text)\n",
        "Xc_full = cf.fit_transform(X_text)\n",
        "X_full = sparse.hstack([Xw_full, Xc_full], format='csr')\n",
        "Xw_test = wf.transform(X_test_text)\n",
        "Xc_test = cf.transform(X_test_text)\n",
        "X_test = sparse.hstack([Xw_test, Xc_test], format='csr')\n",
        "full_clf = LogisticRegression(solver='saga', penalty='l2', C=C_val, max_iter=5000, n_jobs=-1, random_state=seed)\n",
        "full_train_start = time.time()\n",
        "full_clf.fit(X_full, y)\n",
        "print(f'Full fit time: {time.time()-full_train_start:.2f}s')\n",
        "test_pred = full_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "sub = pd.DataFrame({\n",
        "    id_col: test[id_col].values,\n",
        "    'Insult': test_pred\n",
        "})\n",
        "sub_path = 'submission.csv'\n",
        "sub.to_csv(sub_path, index=False)\n",
        "print('Saved submission to', sub_path)\n",
        "\n",
        "# Log to experiment section for traceability\n",
        "print('\\n--- Baseline Summary ---')\n",
        "print(f'Params: word {word_params}, char {char_params}, C={C_val}')\n",
        "print(f'OOF AUC: {cv_auc:.5f}, folds: {fold_aucs}')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\nTrain shape: (3947, 3)  Test shape: (2647, 2)\nColumns: ['Insult', 'Date', 'Comment']\nTarget distribution:\nInsult\n0    0.734229\n1    0.265771\nName: proportion, dtype: float64\nStarting 5-fold CV...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1/5: AUC=0.90745 | time=5.93s | tr_n=3157 va_n=790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2/5: AUC=0.90729 | time=5.36s | tr_n=3157 va_n=790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3/5: AUC=0.91049 | time=5.16s | tr_n=3158 va_n=789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4/5: AUC=0.90757 | time=5.94s | tr_n=3158 va_n=789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5/5: AUC=0.89790 | time=5.68s | tr_n=3158 va_n=789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV AUC (OOF): 0.90588 | mean_fold=0.90614 \u00b1 0.00429 | total_time=28.08s\nTraining full model for submission...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full fit time: 5.48s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Insult'",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'Insult'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 100\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mFull fit time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()-full_train_start\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     97\u001b[39m test_pred = full_clf.predict_proba(X_test)[:, \u001b[32m1\u001b[39m]\n\u001b[32m     99\u001b[39m sub = pd.DataFrame({\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     id_col: \u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[43mid_col\u001b[49m\u001b[43m]\u001b[49m.values,\n\u001b[32m    101\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mInsult\u001b[39m\u001b[33m'\u001b[39m: test_pred\n\u001b[32m    102\u001b[39m })\n\u001b[32m    103\u001b[39m sub_path = \u001b[33m'\u001b[39m\u001b[33msubmission.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    104\u001b[39m sub.to_csv(sub_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'Insult'"
          ]
        }
      ]
    },
    {
      "id": "fdfc34c4-be82-45d7-b137-2044dead567c",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fix submission: detect id column from test and save submission.csv\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Determine id column from test (not train)\n",
        "id_col = 'id' if 'id' in test.columns else ('Id' if 'Id' in test.columns else test.columns[0])\n",
        "print('Using id column:', id_col)\n",
        "\n",
        "def ensure_test_pred():\n",
        "    global test_pred\n",
        "    if 'test_pred' in globals():\n",
        "        return\n",
        "    # Recompute minimal pipeline if needed\n",
        "    wf = TfidfVectorizer(**word_params)\n",
        "    cf = TfidfVectorizer(**char_params)\n",
        "    Xw_full = wf.fit_transform(X_text)\n",
        "    Xc_full = cf.fit_transform(X_text)\n",
        "    X_full = sparse.hstack([Xw_full, Xc_full], format='csr')\n",
        "    Xw_test = wf.transform(X_test_text)\n",
        "    Xc_test = cf.transform(X_test_text)\n",
        "    X_test_mat = sparse.hstack([Xw_test, Xc_test], format='csr')\n",
        "    clf = LogisticRegression(solver='saga', penalty='l2', C=C_val, max_iter=5000, n_jobs=-1, random_state=seed)\n",
        "    clf.fit(X_full, y)\n",
        "    globals()['test_pred'] = clf.predict_proba(X_test_mat)[:, 1]\n",
        "\n",
        "ensure_test_pred()\n",
        "sub = pd.DataFrame({id_col: test[id_col].values, 'Insult': test_pred})\n",
        "sub_path = 'submission.csv'\n",
        "sub.to_csv(sub_path, index=False)\n",
        "print('Saved submission to', sub_path, 'with shape', sub.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using id column: Date\nSaved submission to submission.csv with shape (2647, 2)\n"
          ]
        }
      ]
    },
    {
      "id": "5b2d7d16-fd93-4940-8292-1e10dfc9ca73",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create submission matching sample format: columns ['Insult','Date','Comment']\n",
        "assert 'test_pred' in globals(), 'test_pred missing; run previous cells to compute predictions.'\n",
        "required_cols = ['Insult', 'Date', 'Comment']\n",
        "sub3 = pd.DataFrame({\n",
        "    'Insult': test_pred,\n",
        "    'Date': test['Date'].values,\n",
        "    'Comment': test['Comment'].values\n",
        "})[required_cols]\n",
        "sub3_path = 'submission.csv'\n",
        "sub3.to_csv(sub3_path, index=False)\n",
        "print('Saved submission with shape', sub3.shape, 'and columns', sub3.columns.tolist())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission with shape (2647, 3) and columns ['Insult', 'Date', 'Comment']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}