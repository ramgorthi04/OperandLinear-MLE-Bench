{
  "cells": [
    {
      "id": "518245a9-d7e4-402d-8179-0eddccbae57a",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Leaf Classification - Plan\n",
        "\n",
        "Objective: Build a high-performing classifier for 99 leaf species using pre-extracted tabular features (shape, margin, texture) from train.csv/test.csv. Optimize for multi-class log-loss. Deliver submission.csv.\n",
        "\n",
        "Workflow:\n",
        "- Data loading & sanity checks: read train/test, inspect shapes, missing values, feature names, target distribution.\n",
        "- Target encoding: LabelEncode species; keep mapping to columns for submission.\n",
        "- Cross-validation: StratifiedKFold (10 folds, shuffle, fixed seed). Log fold progress and time.\n",
        "- Baseline models (fast, strong for this task):\n",
        "  1) Multinomial Logistic Regression (saga, class weights off, C tuned) with StandardScaler.\n",
        "  2) Linear Discriminant Analysis (LDA) with shrinkage='auto' after StandardScaler.\n",
        "  3) LightGBM multiclass (num_leaves, learning_rate tuned lightly).\n",
        "  4) SVC (linear or rbf) with probability=True (limited C grid due to cost).\n",
        "  5) QDA (with regularization) as a candidate if features suit it.\n",
        "- Feature processing: Try PowerTransformer(Yeo-Johnson) or StandardScaler. Consider PCA with retained variance (e.g., 0.99) as an option and evaluate via CV.\n",
        "- Ensembling: Average OOF and test probabilities from top 2-3 models based on CV log-loss. Optionally simple logistic blending on OOF if time.\n",
        "- Evaluation: Multi-class log-loss via sklearn. Track per-fold and mean. Early stop poor configs.\n",
        "- Submission: Average test probs per class; create columns matching sorted unique species labels from train; save to submission.csv.\n",
        "\n",
        "Milestones for Expert Review:\n",
        "- After initial data load + EDA summary.\n",
        "- After first baseline CV results (LR/LDA).\n",
        "- Before running heavier models (SVC/LGBM tuning).\n",
        "- Before final ensembling and submission.\n",
        "\n",
        "Time management:\n",
        "- Start with LR + LDA with scaling; expect strong baseline quickly.\n",
        "- Add LightGBM with modest tuning if needed.\n",
        "- Only then consider SVC/PCA if CV indicates gains.\n",
        "\n",
        "Next step: Implement data loading, preprocessing setup, and basic EDA logs."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "77bc7fec-a8a0-491f-bcf1-a92e7a76b4ea",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup: imports, data loading, CV utilities, and fast baselines (LDA, Logistic Regression)\n",
        "import os, time, sys, gc, math, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "def load_data():\n",
        "    train = pd.read_csv('train.csv')\n",
        "    test = pd.read_csv('test.csv')\n",
        "    print('Train shape:', train.shape, ' Test shape:', test.shape)\n",
        "    # Basic checks\n",
        "    assert 'species' in train.columns and 'id' in train.columns, 'Columns missing in train'\n",
        "    assert 'id' in test.columns, 'id missing in test'\n",
        "    # Drop id from features; keep for submission\n",
        "    train_ids = train['id'].values\n",
        "    test_ids = test['id'].values\n",
        "    X = train.drop(columns=['id', 'species'])\n",
        "    y = train['species'].values\n",
        "    X_test = test.drop(columns=['id'])\n",
        "    # Align columns just in case\n",
        "    assert list(X.columns) == list(X_test.columns), 'Train/Test feature mismatch'\n",
        "    # Encode target\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y)\n",
        "    classes = le.classes_  # alphabetical order\n",
        "    print('Num classes:', len(classes))\n",
        "    # Missing values check\n",
        "    if X.isnull().any().any() or X_test.isnull().any().any():\n",
        "        print('Warning: Missing values detected; filling with 0')\n",
        "        X = X.fillna(0)\n",
        "        X_test = X_test.fillna(0)\n",
        "    return X.values, y_enc, X_test.values, classes, test_ids, le\n",
        "\n",
        "def make_skf(n_splits=10, seed=SEED):\n",
        "    return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "\n",
        "def train_oof(model, X, y, skf, X_test, n_classes, desc='model'):\n",
        "    n_samples = X.shape[0]\n",
        "    oof = np.zeros((n_samples, n_classes), dtype=np.float64)\n",
        "    test_pred = np.zeros((X_test.shape[0], n_classes), dtype=np.float64)\n",
        "    fold_losses = []\n",
        "    start_all = time.time()\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "        t0 = time.time()\n",
        "        X_tr, y_tr = X[tr_idx], y[tr_idx]\n",
        "        X_va, y_va = X[va_idx], y[va_idx]\n",
        "        clf = model  # fresh clone each fold\n",
        "        # Recreate the pipeline to avoid state carry-over\n",
        "        from sklearn.base import clone\n",
        "        clf = clone(model)\n",
        "        clf.fit(X_tr, y_tr)\n",
        "        va_proba = clf.predict_proba(X_va)\n",
        "        loss = log_loss(y_va, va_proba, labels=list(range(n_classes)))\n",
        "        oof[va_idx] = va_proba\n",
        "        fold_losses.append(loss)\n",
        "        # Test prediction\n",
        "        test_pred += clf.predict_proba(X_test) / skf.get_n_splits()\n",
        "        elapsed = time.time() - t0\n",
        "        print(f'[{desc}] Fold {fold}/{skf.get_n_splits()} logloss={loss:.6f} time={elapsed:.1f}s', flush=True)\n",
        "    total_elapsed = time.time() - start_all\n",
        "    oof_loss = log_loss(y, oof, labels=list(range(n_classes)))\n",
        "    print(f'[{desc}] OOF logloss={oof_loss:.6f} | mean_folds={np.mean(fold_losses):.6f} | time_total={total_elapsed/60:.1f}m')\n",
        "    return oof, test_pred, oof_loss, fold_losses\n",
        "\n",
        "# Load data\n",
        "X, y, X_test, classes, test_ids, le = load_data()\n",
        "n_classes = len(classes)\n",
        "skf = make_skf(n_splits=10, seed=SEED)\n",
        "\n",
        "# Baseline 1: LDA with StandardScaler and shrinkage='auto' (solver='lsqr')\n",
        "lda_pipeline = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
        "    ('clf', LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'))\n",
        "])\n",
        "lda_oof, lda_test, lda_oof_loss, _ = train_oof(lda_pipeline, X, y, skf, X_test, n_classes, desc='LDA')\n",
        "\n",
        "# Baseline 2: Multinomial Logistic Regression (saga) with StandardScaler\n",
        "lr_pipeline = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
        "    ('clf', LogisticRegression(multi_class='multinomial', solver='saga', C=1.0, penalty='l2', max_iter=5000, n_jobs=-1, random_state=SEED))\n",
        "])\n",
        "lr_oof, lr_test, lr_oof_loss, _ = train_oof(lr_pipeline, X, y, skf, X_test, n_classes, desc='LogReg')\n",
        "\n",
        "# Simple ensemble of current baselines (equal weight). Will be superseded later by SVC/QDA.\n",
        "ens_oof = (lda_oof + lr_oof) / 2.0\n",
        "ens_test = (lda_test + lr_test) / 2.0\n",
        "ens_oof_loss = log_loss(y, ens_oof, labels=list(range(n_classes)))\n",
        "print(f'[Ensemble LDA+LR] OOF logloss={ens_oof_loss:.6f}')\n",
        "\n",
        "# Build a provisional submission from the ensemble\n",
        "sub = pd.DataFrame(ens_test, columns=classes)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "print('Submission shape:', sub.shape)\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "64eec176-1349-4fd7-b58c-cadb718c97d8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Re-run with 5-fold CV and multiple LDA variants; build provisional submission\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "def clip_and_renorm(probs, eps=1e-15):\n",
        "    P = np.clip(probs, eps, 1 - eps)\n",
        "    P /= P.sum(axis=1, keepdims=True)\n",
        "    return P\n",
        "\n",
        "skf5 = make_skf(n_splits=5, seed=SEED)\n",
        "\n",
        "# LDA Variant A: raw features, lsqr+shrinkage\n",
        "lda_raw = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
        "lda_raw_oof, lda_raw_test, lda_raw_loss, _ = train_oof(lda_raw, X, y, skf5, X_test, n_classes, desc='LDA_raw')\n",
        "\n",
        "# LDA Variant B: PowerTransformer -> LDA(lsqr, shrinkage='auto')\n",
        "lda_pt = Pipeline(steps=[\n",
        "    ('pt', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
        "    ('clf', LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto'))\n",
        "])\n",
        "lda_pt_oof, lda_pt_test, lda_pt_loss, _ = train_oof(lda_pt, X, y, skf5, X_test, n_classes, desc='LDA_PT')\n",
        "\n",
        "# LDA Variant C: StandardScaler -> LDA(eigen, shrinkage='auto')\n",
        "lda_eigen_std = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
        "    ('clf', LinearDiscriminantAnalysis(solver='eigen', shrinkage='auto'))\n",
        "])\n",
        "lda_eig_oof, lda_eig_test, lda_eig_loss, _ = train_oof(lda_eigen_std, X, y, skf5, X_test, n_classes, desc='LDA_eigen_std')\n",
        "\n",
        "losses = {\n",
        "    'LDA_raw': lda_raw_loss,\n",
        "    'LDA_PT': lda_pt_loss,\n",
        "    'LDA_eigen_std': lda_eig_loss\n",
        "}\n",
        "print('LDA variant OOF losses:', losses)\n",
        "best_name = min(losses, key=losses.get)\n",
        "print('Best LDA variant:', best_name, 'OOF=', losses[best_name])\n",
        "\n",
        "best_test = {'LDA_raw': lda_raw_test, 'LDA_PT': lda_pt_test, 'LDA_eigen_std': lda_eig_test}[best_name]\n",
        "best_test = clip_and_renorm(best_test)\n",
        "\n",
        "# Build and save submission\n",
        "sub = pd.DataFrame(best_test, columns=classes)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv with shape:', sub.shape)\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "c099a134-d109-4160-8459-7e906d4e17ba",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# 5-fold: RBF-SVC (isotonic-calibrated), QDA (PT), and LR; ensemble best\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def train_oof_model(model, desc):\n",
        "    return train_oof(model, X, y, skf5, X_test, n_classes, desc=desc)\n",
        "\n",
        "# Recompute LR on 5-fold for consistent ensembling\n",
        "lr5 = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(multi_class='multinomial', solver='saga', C=1.0, penalty='l2', max_iter=5000, n_jobs=-1, random_state=SEED))\n",
        "])\n",
        "lr5_oof, lr5_test, lr5_loss, _ = train_oof_model(lr5, 'LogReg_5fold')\n",
        "\n",
        "# RBF-SVC: small grid, isotonic calibration; scaled features\n",
        "svc_grid = [\n",
        "    {'C': 4.0, 'gamma': 'scale'},\n",
        "    {'C': 16.0, 'gamma': 'scale'},\n",
        "    {'C': 64.0, 'gamma': 'scale'},\n",
        "    {'C': 16.0, 'gamma': 0.01}\n",
        "]\n",
        "svc_results = []\n",
        "best_svc = None\n",
        "best_svc_loss = np.inf\n",
        "best_svc_oof = None\n",
        "best_svc_test = None\n",
        "for i, params in enumerate(svc_grid, 1):\n",
        "    print(f'[SVC grid] {i}/{len(svc_grid)} params={params}', flush=True)\n",
        "    base_svc = SVC(kernel='rbf', C=params['C'], gamma=params['gamma'])\n",
        "    svc_pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('cal', CalibratedClassifierCV(estimator=base_svc, method='isotonic', cv=3))\n",
        "    ])\n",
        "    oof, test_pred, oof_loss, _ = train_oof_model(svc_pipe, f'SVC_cal_C{params[\"C\"]}_g{params[\"gamma\"]}')\n",
        "    svc_results.append((params, oof_loss))\n",
        "    if oof_loss < best_svc_loss:\n",
        "        best_svc_loss = oof_loss\n",
        "        best_svc = params\n",
        "        best_svc_oof = oof\n",
        "        best_svc_test = test_pred\n",
        "print('Best SVC params:', best_svc, 'OOF:', best_svc_loss)\n",
        "\n",
        "# QDA with PowerTransformer and reg_param sweep\n",
        "qda_grid = [0.0, 0.1, 0.2, 0.5]\n",
        "best_qda_r = None\n",
        "best_qda_loss = np.inf\n",
        "best_qda_oof = None\n",
        "best_qda_test = None\n",
        "for j, rp in enumerate(qda_grid, 1):\n",
        "    print(f'[QDA grid] {j}/{len(qda_grid)} reg_param={rp}', flush=True)\n",
        "    qda_pipe = Pipeline(steps=[\n",
        "        ('pt', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
        "        ('clf', QuadraticDiscriminantAnalysis(reg_param=rp))\n",
        "    ])\n",
        "    oof, test_pred, oof_loss, _ = train_oof_model(qda_pipe, f'QDA_PT_r{rp}')\n",
        "    if oof_loss < best_qda_loss:\n",
        "        best_qda_loss = oof_loss\n",
        "        best_qda_r = rp\n",
        "        best_qda_oof = oof\n",
        "        best_qda_test = test_pred\n",
        "print('Best QDA reg_param:', best_qda_r, 'OOF:', best_qda_loss)\n",
        "\n",
        "# Choose LDA from prior cell variants if helpful\n",
        "lda_candidates = {\n",
        "    'LDA_raw': ('lda_raw_oof' in globals(), 'lda_raw_oof', 'lda_raw_test', lda_raw_loss if 'lda_raw_loss' in globals() else np.inf),\n",
        "    'LDA_PT': ('lda_pt_oof' in globals(), 'lda_pt_oof', 'lda_pt_test', lda_pt_loss if 'lda_pt_loss' in globals() else np.inf),\n",
        "    'LDA_eigen_std': ('lda_eig_oof' in globals(), 'lda_eig_oof', 'lda_eig_test', lda_eig_loss if 'lda_eig_loss' in globals() else np.inf)\n",
        "}\n",
        "best_lda_name = None\n",
        "best_lda_loss = np.inf\n",
        "best_lda_oof = None\n",
        "best_lda_test = None\n",
        "for name, (present, oof_var, test_var, loss_val) in lda_candidates.items():\n",
        "    if present and loss_val < best_lda_loss:\n",
        "        best_lda_loss = loss_val\n",
        "        best_lda_name = name\n",
        "        best_lda_oof = globals()[oof_var]\n",
        "        best_lda_test = globals()[test_var]\n",
        "print('Selected LDA for ensemble:', best_lda_name, 'OOF:', best_lda_loss)\n",
        "\n",
        "# Build ensembles (equal weights first); clip and renormalize\n",
        "def ensemble_oof_test(models):\n",
        "    oofs = [m[0] for m in models]\n",
        "    tests = [m[1] for m in models]\n",
        "    oof = np.mean(oofs, axis=0)\n",
        "    test = np.mean(tests, axis=0)\n",
        "    oof = clip_and_renorm(oof)\n",
        "    test = clip_and_renorm(test)\n",
        "    return oof, test\n",
        "\n",
        "models_for_ens = []\n",
        "labels_desc = []\n",
        "models_for_ens.append((lr5_oof, lr5_test)); labels_desc.append(('LR5', lr5_loss))\n",
        "if best_svc_oof is not None: models_for_ens.append((best_svc_oof, best_svc_test)); labels_desc.append((f'SVC{best_svc}', best_svc_loss))\n",
        "if best_qda_oof is not None: models_for_ens.append((best_qda_oof, best_qda_test)); labels_desc.append((f'QDA_r{best_qda_r}', best_qda_loss))\n",
        "if best_lda_oof is not None: models_for_ens.append((best_lda_oof, best_lda_test)); labels_desc.append((best_lda_name, best_lda_loss))\n",
        "\n",
        "print('Component models and OOF:', labels_desc)\n",
        "ens_oof, ens_test = ensemble_oof_test(models_for_ens)\n",
        "ens_loss = log_loss(y, ens_oof, labels=list(range(n_classes)))\n",
        "print(f'[Ensemble] OOF logloss={ens_loss:.6f} with {len(models_for_ens)} models')\n",
        "\n",
        "# Save final submission\n",
        "sub = pd.DataFrame(ens_test, columns=classes)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (ensemble) with shape:', sub.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogReg_5fold] Fold 1/5 logloss=0.115621 time=16.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogReg_5fold] Fold 2/5 logloss=0.108472 time=18.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogReg_5fold] Fold 3/5 logloss=0.122760 time=18.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogReg_5fold] Fold 4/5 logloss=0.120443 time=19.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogReg_5fold] Fold 5/5 logloss=0.124398 time=19.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LogReg_5fold] OOF logloss=0.118336 | mean_folds=0.118339 | total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC grid] 1/4 params={'C': 4.0, 'gamma': 'scale'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C4.0_gscale] Fold 1/5 logloss=0.095791 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C4.0_gscale] Fold 2/5 logloss=0.238826 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C4.0_gscale] Fold 3/5 logloss=0.266782 time=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C4.0_gscale] Fold 4/5 logloss=0.088842 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C4.0_gscale] Fold 5/5 logloss=0.304439 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C4.0_gscale] OOF logloss=0.198820 | mean_folds=0.198936 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC grid] 2/4 params={'C': 16.0, 'gamma': 'scale'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_gscale] Fold 1/5 logloss=0.096418 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_gscale] Fold 2/5 logloss=0.238770 time=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_gscale] Fold 3/5 logloss=0.266777 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_gscale] Fold 4/5 logloss=0.088196 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_gscale] Fold 5/5 logloss=0.298813 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_gscale] OOF logloss=0.197681 | mean_folds=0.197795 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC grid] 3/4 params={'C': 64.0, 'gamma': 'scale'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C64.0_gscale] Fold 1/5 logloss=0.096418 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C64.0_gscale] Fold 2/5 logloss=0.238770 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C64.0_gscale] Fold 3/5 logloss=0.266777 time=1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C64.0_gscale] Fold 4/5 logloss=0.088196 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C64.0_gscale] Fold 5/5 logloss=0.298813 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C64.0_gscale] OOF logloss=0.197681 | mean_folds=0.197795 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC grid] 4/4 params={'C': 16.0, 'gamma': 0.01}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_g0.01] Fold 1/5 logloss=0.153159 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_g0.01] Fold 2/5 logloss=0.277482 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_g0.01] Fold 3/5 logloss=0.114873 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_g0.01] Fold 4/5 logloss=0.098508 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_g0.01] Fold 5/5 logloss=0.323956 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C16.0_g0.01] OOF logloss=0.193550 | mean_folds=0.193596 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVC params: {'C': 16.0, 'gamma': 0.01} OOF: 0.19355032456303511\n[QDA grid] 1/4 reg_param=0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.0] Fold 1/5 logloss=34.231403 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.0] Fold 2/5 logloss=34.626206 time=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.0] Fold 3/5 logloss=34.626206 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.0] Fold 4/5 logloss=34.423714 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.0] Fold 5/5 logloss=34.018729 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.0] OOF logloss=34.385079 | mean_folds=34.385252 | total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA grid] 2/4 reg_param=0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.1] Fold 1/5 logloss=3.345553 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.1] Fold 2/5 logloss=2.970902 time=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.1] Fold 3/5 logloss=3.348329 time=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.1] Fold 4/5 logloss=3.182071 time=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.1] Fold 5/5 logloss=3.071086 time=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.1] OOF logloss=3.183770 | mean_folds=3.183588 | total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA grid] 3/4 reg_param=0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.2] Fold 1/5 logloss=2.998231 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.2] Fold 2/5 logloss=2.811213 time=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.2] Fold 3/5 logloss=3.072648 time=0.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.2] Fold 4/5 logloss=2.901031 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.2] Fold 5/5 logloss=2.810997 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.2] OOF logloss=2.918913 | mean_folds=2.918824 | total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA grid] 4/4 reg_param=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.5] Fold 1/5 logloss=2.875343 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.5] Fold 2/5 logloss=2.789656 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.5] Fold 3/5 logloss=2.985573 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.5] Fold 4/5 logloss=2.805897 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.5] Fold 5/5 logloss=2.687894 time=0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[QDA_PT_r0.5] OOF logloss=2.828925 | mean_folds=2.828873 | total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best QDA reg_param: 0.5 OOF: 2.8289247998901272\nSelected LDA for ensemble: None OOF: inf\nComponent models and OOF: [('LR5', 0.11833580435211666), (\"SVC{'C': 16.0, 'gamma': 0.01}\", 0.19355032456303511), ('QDA_r0.5', 2.8289247998901272)]\n[Ensemble] OOF logloss=0.459933 with 3 models\nSaved submission.csv (ensemble) with shape: (99, 100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/discriminant_analysis.py:947: UserWarning: Variables are collinear\n  warnings.warn(\"Variables are collinear\")\n"
          ]
        }
      ]
    },
    {
      "id": "6977b923-e72a-497a-b596-ecdf65942ca0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Strong bases: expanded RBF-SVC (calibrated), Linear SVC (calibrated), kNN; build strong ensemble (skip LDA)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# 1) Expanded SVC grid with isotonic calibration (focus on smaller gamma)\n",
        "svc_grid_expanded = []\n",
        "for C in [30.0, 50.0, 100.0]:\n",
        "    for gamma in [0.001, 0.003, 0.01]:\n",
        "        svc_grid_expanded.append({'C': C, 'gamma': gamma})\n",
        "best_svc2 = None\n",
        "best_svc2_loss = np.inf\n",
        "best_svc2_oof = None\n",
        "best_svc2_test = None\n",
        "for i, params in enumerate(svc_grid_expanded, 1):\n",
        "    print(f'[SVC expanded] {i}/{len(svc_grid_expanded)} params={params}', flush=True)\n",
        "    base_svc = SVC(kernel='rbf', C=params['C'], gamma=params['gamma'])\n",
        "    svc_pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('cal', CalibratedClassifierCV(estimator=base_svc, method='isotonic', cv=3))\n",
        "    ])\n",
        "    oof, test_pred, oof_loss, _ = train_oof(svc_pipe, X, y, skf5, X_test, n_classes, desc=f'SVC_cal_C{params[\"C\"]}_g{params[\"gamma\"]}')\n",
        "    if oof_loss < best_svc2_loss:\n",
        "        best_svc2_loss = oof_loss\n",
        "        best_svc2 = params\n",
        "        best_svc2_oof = oof\n",
        "        best_svc2_test = test_pred\n",
        "print('Best expanded SVC params:', best_svc2, 'OOF:', best_svc2_loss)\n",
        "\n",
        "# 2) Linear SVC via calibrated SVC(kernel='linear') for probabilities\n",
        "lin_svc = SVC(kernel='linear', C=0.1)\n",
        "lin_svc_pipe = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('cal', CalibratedClassifierCV(estimator=lin_svc, method='isotonic', cv=3))\n",
        "])\n",
        "lin_oof, lin_test, lin_loss, _ = train_oof(lin_svc_pipe, X, y, skf5, X_test, n_classes, desc='LinSVC_cal_C0.1')\n",
        "\n",
        "# 3) kNN strong baseline: StandardScaler -> KNN (distance, manhattan), small k grid\n",
        "knn_params = []\n",
        "for k in [3,5,7,9,11]:\n",
        "    knn_params.append({'n_neighbors': k, 'metric': 'manhattan'})\n",
        "best_knn = None\n",
        "best_knn_loss = np.inf\n",
        "best_knn_oof = None\n",
        "best_knn_test = None\n",
        "for j, prm in enumerate(knn_params, 1):\n",
        "    print(f'[kNN] {j}/{len(knn_params)} params={prm}', flush=True)\n",
        "    knn_pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('knn', KNeighborsClassifier(n_neighbors=prm['n_neighbors'], weights='distance', metric=prm['metric']))\n",
        "    ])\n",
        "    oof, test_pred, oof_loss, _ = train_oof(knn_pipe, X, y, skf5, X_test, n_classes, desc=f'kNN_k{prm[\"n_neighbors\"]}_{prm[\"metric\"]}')\n",
        "    if oof_loss < best_knn_loss:\n",
        "        best_knn_loss = oof_loss\n",
        "        best_knn = prm\n",
        "        best_knn_oof = oof\n",
        "        best_knn_test = test_pred\n",
        "print('Best kNN params:', best_knn, 'OOF:', best_knn_loss)\n",
        "\n",
        "# 4) Build ensemble with strong models only (LR5 from Cell 3 + best SVC RBF + LinSVC + kNN if decent)\n",
        "candidates = [\n",
        "    ('SVC_rbf', best_svc2_loss, best_svc2_oof, best_svc2_test),\n",
        "    ('LinSVC', lin_loss, lin_oof, lin_test),\n",
        "    ('kNN', best_knn_loss, best_knn_oof, best_knn_test),\n",
        "    ('LR5', lr5_loss, lr5_oof, lr5_test)\n",
        "]\n",
        "candidates = [(n,l,o,t) for (n,l,o,t) in candidates if (o is not None) and np.isfinite(l)]\n",
        "candidates.sort(key=lambda x: x[1])\n",
        "print('Model leaderboard (by OOF):', [(n, round(l,6)) for n,l,_,_ in candidates])\n",
        "\n",
        "# Use top 3 by OOF if available\n",
        "top_k = 3 if len(candidates) >= 3 else len(candidates)\n",
        "selected = candidates[:top_k]\n",
        "print('Selected for ensemble:', [(n, round(l,6)) for n,l,_,_ in selected])\n",
        "ens_oof = np.mean([m[2] for m in selected], axis=0)\n",
        "ens_test = np.mean([m[3] for m in selected], axis=0)\n",
        "ens_oof = clip_and_renorm(ens_oof)\n",
        "ens_test = clip_and_renorm(ens_test)\n",
        "ens_loss = log_loss(y, ens_oof, labels=list(range(n_classes)))\n",
        "print(f'[Strong Ensemble] OOF logloss={ens_loss:.6f} with {top_k} models')\n",
        "\n",
        "# Save submission\n",
        "sub = pd.DataFrame(ens_test, columns=classes)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (strong ensemble) with shape:', sub.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC expanded] 1/9 params={'C': 30.0, 'gamma': 0.001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.001] Fold 1/5 logloss=0.073117 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.001] Fold 2/5 logloss=0.106225 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.001] Fold 3/5 logloss=0.260229 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.001] Fold 4/5 logloss=0.106943 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.001] Fold 5/5 logloss=0.308168 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.001] OOF logloss=0.170827 | mean_folds=0.170937 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC expanded] 2/9 params={'C': 30.0, 'gamma': 0.003}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.003] Fold 1/5 logloss=0.067919 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.003] Fold 2/5 logloss=0.256361 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.003] Fold 3/5 logloss=0.253711 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.003] Fold 4/5 logloss=0.087095 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.003] Fold 5/5 logloss=0.300317 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.003] OOF logloss=0.192940 | mean_folds=0.193081 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC expanded] 3/9 params={'C': 30.0, 'gamma': 0.01}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.01] Fold 1/5 logloss=0.153159 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.01] Fold 2/5 logloss=0.277482 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.01] Fold 3/5 logloss=0.114873 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.01] Fold 4/5 logloss=0.098508 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.01] Fold 5/5 logloss=0.323956 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C30.0_g0.01] OOF logloss=0.193550 | mean_folds=0.193596 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC expanded] 4/9 params={'C': 50.0, 'gamma': 0.001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.001] Fold 1/5 logloss=0.073117 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.001] Fold 2/5 logloss=0.106225 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.001] Fold 3/5 logloss=0.260229 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.001] Fold 4/5 logloss=0.106943 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.001] Fold 5/5 logloss=0.308168 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.001] OOF logloss=0.170827 | mean_folds=0.170937 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC expanded] 5/9 params={'C': 50.0, 'gamma': 0.003}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.003] Fold 1/5 logloss=0.067919 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.003] Fold 2/5 logloss=0.256361 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.003] Fold 3/5 logloss=0.253711 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.003] Fold 4/5 logloss=0.087095 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.003] Fold 5/5 logloss=0.300317 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.003] OOF logloss=0.192940 | mean_folds=0.193081 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC expanded] 6/9 params={'C': 50.0, 'gamma': 0.01}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.01] Fold 1/5 logloss=0.153159 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.01] Fold 2/5 logloss=0.277482 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.01] Fold 3/5 logloss=0.114873 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.01] Fold 4/5 logloss=0.098508 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.01] Fold 5/5 logloss=0.323956 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C50.0_g0.01] OOF logloss=0.193550 | mean_folds=0.193596 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC expanded] 7/9 params={'C': 100.0, 'gamma': 0.001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.001] Fold 1/5 logloss=0.073117 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.001] Fold 2/5 logloss=0.106225 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.001] Fold 3/5 logloss=0.260229 time=1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.001] Fold 4/5 logloss=0.106943 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.001] Fold 5/5 logloss=0.308168 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.001] OOF logloss=0.170827 | mean_folds=0.170937 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC expanded] 8/9 params={'C': 100.0, 'gamma': 0.003}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.003] Fold 1/5 logloss=0.067919 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.003] Fold 2/5 logloss=0.256361 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.003] Fold 3/5 logloss=0.253711 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.003] Fold 4/5 logloss=0.087095 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.003] Fold 5/5 logloss=0.300317 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.003] OOF logloss=0.192940 | mean_folds=0.193081 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC expanded] 9/9 params={'C': 100.0, 'gamma': 0.01}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.01] Fold 1/5 logloss=0.153159 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.01] Fold 2/5 logloss=0.277482 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.01] Fold 3/5 logloss=0.114873 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.01] Fold 4/5 logloss=0.098508 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.01] Fold 5/5 logloss=0.323956 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SVC_cal_C100.0_g0.01] OOF logloss=0.193550 | mean_folds=0.193596 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best expanded SVC params: {'C': 50.0, 'gamma': 0.001} OOF: 0.17082672625932951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LinSVC_cal_C0.1] Fold 1/5 logloss=0.069862 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LinSVC_cal_C0.1] Fold 2/5 logloss=0.067961 time=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LinSVC_cal_C0.1] Fold 3/5 logloss=0.253501 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LinSVC_cal_C0.1] Fold 4/5 logloss=0.117544 time=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LinSVC_cal_C0.1] Fold 5/5 logloss=0.312877 time=1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LinSVC_cal_C0.1] OOF logloss=0.164243 | mean_folds=0.164349 | total=0.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN] 1/5 params={'n_neighbors': 3, 'metric': 'manhattan'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k3_manhattan] Fold 1/5 logloss=0.236776 time=0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k3_manhattan] Fold 2/5 logloss=0.041485 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k3_manhattan] Fold 3/5 logloss=0.231771 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k3_manhattan] Fold 4/5 logloss=0.249245 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k3_manhattan] Fold 5/5 logloss=0.244379 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k3_manhattan] OOF logloss=0.200772 | mean_folds=0.200731 | total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN] 2/5 params={'n_neighbors': 5, 'metric': 'manhattan'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k5_manhattan] Fold 1/5 logloss=0.280554 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k5_manhattan] Fold 2/5 logloss=0.084681 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k5_manhattan] Fold 3/5 logloss=0.274205 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k5_manhattan] Fold 4/5 logloss=0.288335 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k5_manhattan] Fold 5/5 logloss=0.090640 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k5_manhattan] OOF logloss=0.203770 | mean_folds=0.203683 | total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN] 3/5 params={'n_neighbors': 7, 'metric': 'manhattan'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k7_manhattan] Fold 1/5 logloss=0.157135 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k7_manhattan] Fold 2/5 logloss=0.156453 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k7_manhattan] Fold 3/5 logloss=0.333751 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k7_manhattan] Fold 4/5 logloss=0.166546 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k7_manhattan] Fold 5/5 logloss=0.153212 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k7_manhattan] OOF logloss=0.193379 | mean_folds=0.193419 | total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN] 4/5 params={'n_neighbors': 9, 'metric': 'manhattan'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k9_manhattan] Fold 1/5 logloss=0.293210 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k9_manhattan] Fold 2/5 logloss=0.289378 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k9_manhattan] Fold 3/5 logloss=0.463124 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k9_manhattan] Fold 4/5 logloss=0.294970 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k9_manhattan] Fold 5/5 logloss=0.297520 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k9_manhattan] OOF logloss=0.327602 | mean_folds=0.327641 | total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN] 5/5 params={'n_neighbors': 11, 'metric': 'manhattan'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k11_manhattan] Fold 1/5 logloss=0.425661 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k11_manhattan] Fold 2/5 logloss=0.421483 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k11_manhattan] Fold 3/5 logloss=0.597536 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k11_manhattan] Fold 4/5 logloss=0.420640 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k11_manhattan] Fold 5/5 logloss=0.426621 time=0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[kNN_k11_manhattan] OOF logloss=0.458352 | mean_folds=0.458388 | total=0.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best kNN params: {'n_neighbors': 7, 'metric': 'manhattan'} OOF: 0.19337877494945088\nModel leaderboard (by OOF): [('LR5', 0.118336), ('LinSVC', 0.164243), ('SVC_rbf', 0.170827), ('kNN', 0.193379)]\nSelected for ensemble: [('LR5', 0.118336), ('LinSVC', 0.164243), ('SVC_rbf', 0.170827)]\n[Strong Ensemble] OOF logloss=0.092280 with 3 models\nSaved submission.csv (strong ensemble) with shape: (99, 100)\n"
          ]
        }
      ]
    },
    {
      "id": "9090b4ad-6ab8-4d47-bfd7-479527fd5810",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# PCA+kNN, tuned LR, and refined SVC grid; ensemble strongest models\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def evaluate_pipeline(pipe, desc):\n",
        "    oof, test_pred, oof_loss, _ = train_oof(pipe, X, y, skf5, X_test, n_classes, desc=desc)\n",
        "    return oof, test_pred, oof_loss\n",
        "\n",
        "# 1) PCA + kNN (distance) with euclidean/cosine, k grid\n",
        "best_knn2 = None\n",
        "best_knn2_loss = np.inf\n",
        "best_knn2_oof = None\n",
        "best_knn2_test = None\n",
        "for metric in ['euclidean', 'cosine']:\n",
        "    for k in [3,5,7,9,11]:\n",
        "        pipe = Pipeline(steps=[\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('pca', PCA(n_components=0.995, svd_solver='full', random_state=SEED)),\n",
        "            ('knn', KNeighborsClassifier(n_neighbors=k, weights='distance', metric=metric))\n",
        "        ])\n",
        "        oof, test_pred, loss = evaluate_pipeline(pipe, f'kNN_PCA_k{k}_{metric}')\n",
        "        if loss < best_knn2_loss:\n",
        "            best_knn2_loss = loss\n",
        "            best_knn2 = {'k': k, 'metric': metric}\n",
        "            best_knn2_oof = oof\n",
        "            best_knn2_test = test_pred\n",
        "print('Best kNN_PCA:', best_knn2, 'OOF:', best_knn2_loss)\n",
        "\n",
        "# 2) Tuned Logistic Regression (L2 and ElasticNet small l1_ratio)\n",
        "best_lr = None\n",
        "best_lr_loss = np.inf\n",
        "best_lr_oof = None\n",
        "best_lr_test = None\n",
        "for penalty, params in [('l2', {'l1_ratio': None}), ('elasticnet', {'l1_ratio': 0.1})]:\n",
        "    for C in [0.5, 1.0, 2.0, 3.0, 5.0, 10.0]:\n",
        "        clf = LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty=penalty, max_iter=5000, n_jobs=-1, random_state=SEED, **({} if params['l1_ratio'] is None else {'l1_ratio': params['l1_ratio']}))\n",
        "        pipe = Pipeline(steps=[('scaler', StandardScaler()), ('clf', clf)])\n",
        "        oof, test_pred, loss = evaluate_pipeline(pipe, f'LR_{penalty}_C{C}')\n",
        "        if loss < best_lr_loss:\n",
        "            best_lr_loss = loss\n",
        "            best_lr = {'penalty': penalty, 'C': C, **params}\n",
        "            best_lr_oof = oof\n",
        "            best_lr_test = test_pred\n",
        "print('Best LR tuned:', best_lr, 'OOF:', best_lr_loss)\n",
        "\n",
        "# 3) Refined SVC grid (RBF, isotonic-calibrated) focusing on smaller gamma\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "svc_grid_refined = [\n",
        "    {'C': 20.0, 'gamma': 0.001},\n",
        "    {'C': 50.0, 'gamma': 0.001},\n",
        "    {'C': 100.0, 'gamma': 0.001},\n",
        "    {'C': 50.0, 'gamma': 0.0003},\n",
        "    {'C': 100.0, 'gamma': 0.0003},\n",
        "    {'C': 200.0, 'gamma': 0.0003}\n",
        "]\n",
        "best_svc3 = None\n",
        "best_svc3_loss = np.inf\n",
        "best_svc3_oof = None\n",
        "best_svc3_test = None\n",
        "for i, p in enumerate(svc_grid_refined, 1):\n",
        "    print(f'[SVC refined] {i}/{len(svc_grid_refined)} params={p}', flush=True)\n",
        "    base_svc = SVC(kernel='rbf', C=p['C'], gamma=p['gamma'])\n",
        "    svc_pipe = Pipeline(steps=[('scaler', StandardScaler()), ('cal', CalibratedClassifierCV(estimator=base_svc, method='isotonic', cv=3))])\n",
        "    oof, test_pred, loss = evaluate_pipeline(svc_pipe, f'SVC_cal_C{p[\"C\"]}_g{p[\"gamma\"]}')\n",
        "    if loss < best_svc3_loss:\n",
        "        best_svc3_loss = loss\n",
        "        best_svc3 = p\n",
        "        best_svc3_oof = oof\n",
        "        best_svc3_test = test_pred\n",
        "print('Best SVC refined:', best_svc3, 'OOF:', best_svc3_loss)\n",
        "\n",
        "# 4) Assemble strongest models by OOF and average top-2/3\n",
        "cands = []\n",
        "if best_lr_oof is not None: cands.append(('LR_tuned', best_lr_loss, best_lr_oof, best_lr_test))\n",
        "if best_svc3_oof is not None: cands.append(('SVC_refined', best_svc3_loss, best_svc3_oof, best_svc3_test))\n",
        "if best_knn2_oof is not None: cands.append(('kNN_PCA', best_knn2_loss, best_knn2_oof, best_knn2_test))\n",
        "cands.sort(key=lambda x: x[1])\n",
        "print('Candidates:', [(n, round(l,6)) for n,l,_,_ in cands])\n",
        "sel = cands[:3] if len(cands) >= 3 else cands\n",
        "ens_oof = np.mean([m[2] for m in sel], axis=0)\n",
        "ens_test = np.mean([m[3] for m in sel], axis=0)\n",
        "ens_oof = clip_and_renorm(ens_oof)\n",
        "ens_test = clip_and_renorm(ens_test)\n",
        "ens_loss = log_loss(y, ens_oof, labels=list(range(n_classes)))\n",
        "print(f'[PCA+kNN/LR/SVC Ensemble] OOF logloss={ens_loss:.6f} using {len(sel)} models')\n",
        "sub = pd.DataFrame(ens_test, columns=classes)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (refined ensemble) with shape:', sub.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "da004a02-5695-4b44-921d-945102733355",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Group-wise scaling by feature blocks (shape/margin/texture) and re-evaluate LR/SVC\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Reload data as DataFrames to get column names\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "feat_cols = [c for c in train_df.columns if c not in ['id', 'species']]\n",
        "X_df = train_df[feat_cols].copy()\n",
        "y_df = le.transform(train_df['species'])  # use existing encoder\n",
        "X_test_df = test_df[feat_cols].copy()\n",
        "\n",
        "# Identify groups by prefix\n",
        "shape_cols = [c for c in feat_cols if c.lower().startswith('shape')]\n",
        "margin_cols = [c for c in feat_cols if c.lower().startswith('margin')]\n",
        "texture_cols = [c for c in feat_cols if c.lower().startswith('texture')]\n",
        "other_cols = [c for c in feat_cols if c not in shape_cols + margin_cols + texture_cols]\n",
        "print('Groups sizes:', len(shape_cols), len(margin_cols), len(texture_cols), len(other_cols))\n",
        "\n",
        "transformers = []\n",
        "if shape_cols: transformers.append(('shape_scaler', StandardScaler(), shape_cols))\n",
        "if margin_cols: transformers.append(('margin_scaler', StandardScaler(), margin_cols))\n",
        "if texture_cols: transformers.append(('texture_scaler', StandardScaler(), texture_cols))\n",
        "if other_cols: transformers.append(('other_scaler', StandardScaler(), other_cols))\n",
        "ct = ColumnTransformer(transformers=transformers, remainder='drop')\n",
        "\n",
        "skf5 = make_skf(n_splits=5, seed=SEED)\n",
        "\n",
        "def train_oof_df(pipe, desc):\n",
        "    # Use DataFrame-based splitter but convert to numpy inside\n",
        "    n_samples = X_df.shape[0]\n",
        "    oof = np.zeros((n_samples, n_classes), dtype=np.float64)\n",
        "    test_pred = np.zeros((X_test_df.shape[0], n_classes), dtype=np.float64)\n",
        "    fold_losses = []\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf5.split(X_df.values, y_df), 1):\n",
        "        t0 = time.time()\n",
        "        X_tr, y_tr = X_df.iloc[tr_idx], y_df[tr_idx]\n",
        "        X_va, y_va = X_df.iloc[va_idx], y_df[va_idx]\n",
        "        from sklearn.base import clone\n",
        "        model = clone(pipe)\n",
        "        model.fit(X_tr, y_tr)\n",
        "        proba_va = model.predict_proba(X_va)\n",
        "        loss = log_loss(y_va, proba_va, labels=list(range(n_classes)))\n",
        "        oof[va_idx] = proba_va\n",
        "        test_pred += model.predict_proba(X_test_df) / skf5.get_n_splits()\n",
        "        fold_losses.append(loss)\n",
        "        print(f'[{desc}] Fold {fold}/5 logloss={loss:.6f} time={time.time()-t0:.1f}s', flush=True)\n",
        "    oof_loss = log_loss(y_df, oof, labels=list(range(n_classes)))\n",
        "    print(f'[{desc}] OOF logloss={oof_loss:.6f} | mean_folds={np.mean(fold_losses):.6f}')\n",
        "    return oof, test_pred, oof_loss\n",
        "\n",
        "# 1) Group-scaled Logistic Regression (tuned C small set)\n",
        "best_lr_g = None; best_lr_g_loss = np.inf; best_lr_g_oof=None; best_lr_g_test=None\n",
        "for C in [1.0, 2.0, 3.0, 5.0]:\n",
        "    pipe = Pipeline([('ct', ct), ('clf', LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty='l2', max_iter=5000, n_jobs=-1, random_state=SEED))])\n",
        "    oof, test_pred, loss = train_oof_df(pipe, f'LR_group_C{C}')\n",
        "    if loss < best_lr_g_loss: best_lr_g_loss, best_lr_g, best_lr_g_oof, best_lr_g_test = loss, C, oof, test_pred\n",
        "print('Best LR group C:', best_lr_g, 'OOF:', best_lr_g_loss)\n",
        "\n",
        "# 2) Group-scaled SVC RBF with isotonic calibration (focused grid)\n",
        "svc_params = [{'C': 10.0, 'gamma': 0.001}, {'C': 20.0, 'gamma': 0.001}, {'C': 50.0, 'gamma': 0.001}]\n",
        "best_svc_g = None; best_svc_g_loss = np.inf; best_svc_g_oof=None; best_svc_g_test=None\n",
        "for p in svc_params:\n",
        "    base = SVC(kernel='rbf', C=p['C'], gamma=p['gamma'])\n",
        "    pipe = Pipeline([('ct', ct), ('cal', CalibratedClassifierCV(estimator=base, method='isotonic', cv=3))])\n",
        "    oof, test_pred, loss = train_oof_df(pipe, f'SVC_group_C{p[\"C\"]}_g{p[\"gamma\"]}')\n",
        "    if loss < best_svc_g_loss: best_svc_g_loss, best_svc_g, best_svc_g_oof, best_svc_g_test = loss, p, oof, test_pred\n",
        "print('Best SVC group params:', best_svc_g, 'OOF:', best_svc_g_loss)\n",
        "\n",
        "# Ensemble top group-wise models (if better than previous)\n",
        "cands = []\n",
        "if best_lr_g_oof is not None: cands.append(('LR_group', best_lr_g_loss, best_lr_g_oof, best_lr_g_test))\n",
        "if best_svc_g_oof is not None: cands.append(('SVC_group', best_svc_g_loss, best_svc_g_oof, best_svc_g_test))\n",
        "cands.sort(key=lambda x: x[1])\n",
        "print('Group-wise candidates:', [(n, round(l,6)) for n,l,_,_ in cands])\n",
        "if cands:\n",
        "    ens_oof = np.mean([m[2] for m in cands], axis=0)\n",
        "    ens_test = np.mean([m[3] for m in cands], axis=0)\n",
        "    ens_oof = clip_and_renorm(ens_oof); ens_test = clip_and_renorm(ens_test)\n",
        "    ens_loss = log_loss(y_df, ens_oof, labels=list(range(n_classes)))\n",
        "    print(f'[Group Ensemble] OOF logloss={ens_loss:.6f} using {len(cands)} models')\n",
        "    sub = pd.DataFrame(ens_test, columns=classes); sub.insert(0, 'id', test_ids); sub.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (group-wise ensemble) with shape:', sub.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7c0df7e8-9604-40d3-beb2-46052c6fc55b",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# LightGBM multiclass with 5-fold CV and early stopping; ensemble with LR if better\n",
        "import sys, subprocess, importlib, time\n",
        "def ensure_pkg(pkg):\n",
        "    try:\n",
        "        return importlib.import_module(pkg)\n",
        "    except ImportError:\n",
        "        print(f'Installing {pkg}...', flush=True)\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
        "        return importlib.import_module(pkg)\n",
        "\n",
        "lgb = ensure_pkg('lightgbm')\n",
        "from lightgbm import Dataset as lgbDataset, early_stopping as lgb_early_stopping, log_evaluation as lgb_log_evaluation\n",
        "\n",
        "def lgbm_cv_oof(X_np, y_np, Xte_np, n_classes, skf, params=None, num_boost_round=5000, early_stopping_rounds=150, desc='LGBM'):\n",
        "    if params is None:\n",
        "        params = {\n",
        "            'objective': 'multiclass',\n",
        "            'num_class': n_classes,\n",
        "            'metric': 'multi_logloss',\n",
        "            'learning_rate': 0.02,\n",
        "            'num_leaves': 20,\n",
        "            'min_data_in_leaf': 10,\n",
        "            'feature_fraction': 0.7,\n",
        "            'bagging_fraction': 0.8,\n",
        "            'bagging_freq': 1,\n",
        "            'lambda_l2': 3.0,\n",
        "            'seed': SEED,\n",
        "            'verbose': -1,\n",
        "            'num_threads': -1\n",
        "        }\n",
        "    n = X_np.shape[0]\n",
        "    oof = np.zeros((n, n_classes), dtype=np.float64)\n",
        "    test_pred = np.zeros((Xte_np.shape[0], n_classes), dtype=np.float64)\n",
        "    fold_losses = []\n",
        "    start = time.time()\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_np, y_np), 1):\n",
        "        t0 = time.time()\n",
        "        X_tr, y_tr = X_np[tr_idx], y_np[tr_idx]\n",
        "        X_va, y_va = X_np[va_idx], y_np[va_idx]\n",
        "        dtr = lgbDataset(X_tr, label=y_tr)\n",
        "        dva = lgbDataset(X_va, label=y_va)\n",
        "        booster = lgb.train(\n",
        "            params,\n",
        "            dtr,\n",
        "            num_boost_round=num_boost_round,\n",
        "            valid_sets=[dtr, dva],\n",
        "            valid_names=['train','valid'],\n",
        "            callbacks=[lgb_early_stopping(stopping_rounds=early_stopping_rounds, verbose=False),\n",
        "                       lgb_log_evaluation(period=0)]\n",
        "        )\n",
        "        va_proba = booster.predict(X_va, num_iteration=booster.best_iteration)\n",
        "        loss = log_loss(y_va, va_proba, labels=list(range(n_classes)))\n",
        "        oof[va_idx] = va_proba\n",
        "        test_pred += booster.predict(Xte_np, num_iteration=booster.best_iteration) / skf.get_n_splits()\n",
        "        print(f'[{desc}] Fold {fold}/{skf.get_n_splits()} best_iter={booster.best_iteration} logloss={loss:.6f} time={time.time()-t0:.1f}s', flush=True)\n",
        "        fold_losses.append(loss)\n",
        "    oof_loss = log_loss(y_np, oof, labels=list(range(n_classes)))\n",
        "    print(f'[{desc}] OOF logloss={oof_loss:.6f} | mean_folds={np.mean(fold_losses):.6f} | total={((time.time()-start)/60):.1f}m', flush=True)\n",
        "    return oof, test_pred, oof_loss, fold_losses\n",
        "\n",
        "# Use 5-fold CV for LGBM (consistent with other models)\n",
        "skf5 = make_skf(n_splits=5, seed=SEED)\n",
        "lgb_params = {\n",
        "    'objective': 'multiclass',\n",
        "    'num_class': n_classes,\n",
        "    'metric': 'multi_logloss',\n",
        "    'learning_rate': 0.02,\n",
        "    'num_leaves': 20,\n",
        "    'min_data_in_leaf': 10,\n",
        "    'feature_fraction': 0.7,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 1,\n",
        "    'lambda_l2': 3.0,\n",
        "    'seed': SEED,\n",
        "    'verbose': -1,\n",
        "    'num_threads': -1\n",
        "}\n",
        "lgb_oof, lgb_test, lgb_loss, _ = lgbm_cv_oof(X, y, X_test, n_classes, skf5, params=lgb_params, desc='LGBM5')\n",
        "\n",
        "# Ensemble with best existing LR5 if available\n",
        "ens_models = []\n",
        "if 'lr5_oof' in globals():\n",
        "    ens_models.append(('LR5', lr5_oof, lr5_test, lr5_loss))\n",
        "ens_models.append(('LGBM5', lgb_oof, lgb_test, lgb_loss))\n",
        "print('Ensemble candidates:', [(n, round(l,6)) for n,_,_,l in ens_models])\n",
        "oofs = [m[1] for m in ens_models]\n",
        "tests = [m[2] for m in ens_models]\n",
        "ens_oof = clip_and_renorm(np.mean(oofs, axis=0)) if len(oofs) > 1 else clip_and_renorm(oofs[0])\n",
        "ens_test = clip_and_renorm(np.mean(tests, axis=0)) if len(tests) > 1 else clip_and_renorm(tests[0])\n",
        "ens_loss = log_loss(y, ens_oof, labels=list(range(n_classes)))\n",
        "print(f'[LGBM Ensemble] OOF logloss={ens_loss:.6f} using {len(ens_models)} models')\n",
        "\n",
        "# Save submission\n",
        "sub = pd.DataFrame(ens_test, columns=classes)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (LGBM blend) with shape:', sub.shape)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "id": "04358b53-3318-4b42-bc9f-09f33ca25210",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# XGBoost multiclass OOF with 5-fold CV and early stopping; raw features; logs per fold\n",
        "import importlib, subprocess, sys, time\n",
        "def ensure_pkg(pkg):\n",
        "    try:\n",
        "        return importlib.import_module(pkg)\n",
        "    except ImportError:\n",
        "        print(f'Installing {pkg}...', flush=True)\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])\n",
        "        return importlib.import_module(pkg)\n",
        "\n",
        "xgb = ensure_pkg('xgboost')\n",
        "from xgboost import DMatrix, train as xgb_train\n",
        "\n",
        "def xgb_cv_oof(X_np, y_np, Xte_np, n_classes, skf, params=None, num_boost_round=4000, early_stopping_rounds=100, desc='XGB'):\n",
        "    if params is None:\n",
        "        params = {\n",
        "            'objective': 'multi:softprob',\n",
        "            'num_class': n_classes,\n",
        "            'eval_metric': 'mlogloss',\n",
        "            'eta': 0.03,\n",
        "            'max_depth': 6,\n",
        "            'min_child_weight': 1.0,\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.8,\n",
        "            'lambda': 1.0,\n",
        "            'alpha': 0.1,\n",
        "            'tree_method': 'hist',\n",
        "            'seed': SEED,\n",
        "            'nthread': 0\n",
        "        }\n",
        "    n = X_np.shape[0]\n",
        "    oof = np.zeros((n, n_classes), dtype=np.float64)\n",
        "    test_pred = np.zeros((Xte_np.shape[0], n_classes), dtype=np.float64)\n",
        "    fold_losses = []\n",
        "    start = time.time()\n",
        "    n_splits = skf.get_n_splits()\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_np, y_np), 1):\n",
        "        t0 = time.time()\n",
        "        X_tr, y_tr = X_np[tr_idx], y_np[tr_idx]\n",
        "        X_va, y_va = X_np[va_idx], y_np[va_idx]\n",
        "        dtr = DMatrix(X_tr, label=y_tr)\n",
        "        dva = DMatrix(X_va, label=y_va)\n",
        "        watchlist = [(dtr, 'train'), (dva, 'valid')]\n",
        "        booster = xgb_train(params, dtr, num_boost_round=num_boost_round, evals=watchlist,\n",
        "                            early_stopping_rounds=early_stopping_rounds, verbose_eval=False)\n",
        "        va_proba = booster.predict(dva, ntree_limit=booster.best_ntree_limit)\n",
        "        loss = log_loss(y_va, va_proba, labels=list(range(n_classes)))\n",
        "        oof[va_idx] = va_proba\n",
        "        test_pred += booster.predict(DMatrix(Xte_np), ntree_limit=booster.best_ntree_limit) / n_splits\n",
        "        fold_losses.append(loss)\n",
        "        print(f'[{desc}] Fold {fold}/{n_splits} best_iter={booster.best_iteration} logloss={loss:.6f} time={time.time()-t0:.1f}s', flush=True)\n",
        "    oof_loss = log_loss(y_np, oof, labels=list(range(n_classes)))\n",
        "    print(f'[{desc}] OOF logloss={oof_loss:.6f} | mean_folds={np.mean(fold_losses):.6f} | total={(time.time()-start)/60:.1f}m', flush=True)\n",
        "    return oof, test_pred, oof_loss, fold_losses\n",
        "\n",
        "# Run 5-fold XGBoost\n",
        "skf5 = make_skf(n_splits=5, seed=SEED)\n",
        "xgb_params = {\n",
        "    'objective': 'multi:softprob',\n",
        "    'num_class': n_classes,\n",
        "    'eval_metric': 'mlogloss',\n",
        "    'eta': 0.02,\n",
        "    'max_depth': 5,\n",
        "    'min_child_weight': 1.0,\n",
        "    'subsample': 0.9,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'lambda': 1.0,\n",
        "    'alpha': 0.1,\n",
        "    'tree_method': 'hist',\n",
        "    'seed': SEED,\n",
        "    'nthread': 0\n",
        "}\n",
        "xgb_oof, xgb_test, xgb_loss, _ = xgb_cv_oof(X, y, X_test, n_classes, skf5, params=xgb_params, num_boost_round=5000, early_stopping_rounds=100, desc='XGB5')\n",
        "\n",
        "# Compare/quick blend with best LR5 if available\n",
        "blend_models = []\n",
        "if 'lr5_oof' in globals():\n",
        "    blend_models.append(('LR5', lr5_oof, lr5_test, lr5_loss))\n",
        "blend_models.append(('XGB5', xgb_oof, xgb_test, xgb_loss))\n",
        "print('Blend candidates:', [(n, round(l,6)) for n,_,_,l in blend_models])\n",
        "oofs = [m[1] for m in blend_models]\n",
        "tests = [m[2] for m in blend_models]\n",
        "blend_oof = clip_and_renorm(np.mean(oofs, axis=0)) if len(oofs) > 1 else clip_and_renorm(oofs[0])\n",
        "blend_test = clip_and_renorm(np.mean(tests, axis=0)) if len(tests) > 1 else clip_and_renorm(tests[0])\n",
        "blend_loss = log_loss(y, blend_oof, labels=list(range(n_classes)))\n",
        "print(f'[LR+XGB Blend] OOF logloss={blend_loss:.6f} using {len(blend_models)} models')\n",
        "\n",
        "# Save a provisional submission from the blend\n",
        "sub = pd.DataFrame(blend_test, columns=classes)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (LR+XGB blend) with shape:', sub.shape)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "id": "8e7cdbcb-521c-445c-947f-0bf3c8d44740",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fast tree booster via sklearn HistGradientBoosting + Stacking meta-learner\n",
        "import time\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def hgb_cv_oof(X_np, y_np, Xte_np, n_classes, skf, params=None, desc='HGB'):\n",
        "    if params is None:\n",
        "        params = {\n",
        "            'learning_rate': 0.05,\n",
        "            'max_depth': 6,\n",
        "            'max_leaf_nodes': 31,\n",
        "            'min_samples_leaf': 5,\n",
        "            'l2_regularization': 1.0,\n",
        "            'max_iter': 300,\n",
        "            'early_stopping': True,\n",
        "            'n_iter_no_change': 20,\n",
        "            'tol': 1e-7,\n",
        "            'validation_fraction': 0.2,\n",
        "            'random_state': SEED\n",
        "        }\n",
        "    n = X_np.shape[0]\n",
        "    oof = np.zeros((n, n_classes), dtype=np.float64)\n",
        "    test_pred = np.zeros((Xte_np.shape[0], n_classes), dtype=np.float64)\n",
        "    fold_losses = []\n",
        "    start = time.time()\n",
        "    n_splits = skf.get_n_splits()\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_np, y_np), 1):\n",
        "        t0 = time.time()\n",
        "        print(f'[{desc}] Starting fold {fold}/{n_splits} | train={len(tr_idx)} valid={len(va_idx)}', flush=True)\n",
        "        X_tr, y_tr = X_np[tr_idx], y_np[tr_idx]\n",
        "        X_va, y_va = X_np[va_idx], y_np[va_idx]\n",
        "        clf = HistGradientBoostingClassifier(\n",
        "            loss='log_loss',\n",
        "            learning_rate=params['learning_rate'],\n",
        "            max_depth=params['max_depth'],\n",
        "            max_leaf_nodes=params['max_leaf_nodes'],\n",
        "            min_samples_leaf=params['min_samples_leaf'],\n",
        "            l2_regularization=params['l2_regularization'],\n",
        "            max_iter=params['max_iter'],\n",
        "            early_stopping=params['early_stopping'],\n",
        "            n_iter_no_change=params['n_iter_no_change'],\n",
        "            tol=params['tol'],\n",
        "            validation_fraction=params['validation_fraction'],\n",
        "            random_state=params['random_state']\n",
        "        )\n",
        "        clf.fit(X_tr, y_tr)\n",
        "        va_proba = clf.predict_proba(X_va)\n",
        "        loss = log_loss(y_va, va_proba, labels=list(range(n_classes)))\n",
        "        oof[va_idx] = va_proba\n",
        "        test_pred += clf.predict_proba(Xte_np) / n_splits\n",
        "        fold_losses.append(loss)\n",
        "        print(f'[{desc}] Fold {fold}/{n_splits} logloss={loss:.6f} time={time.time()-t0:.1f}s', flush=True)\n",
        "    oof_loss = log_loss(y_np, oof, labels=list(range(n_classes)))\n",
        "    print(f'[{desc}] OOF logloss={oof_loss:.6f} | mean_folds={np.mean(fold_losses):.6f} | total={(time.time()-start)/60:.1f}m', flush=True)\n",
        "    return oof, test_pred, oof_loss, fold_losses\n",
        "\n",
        "# 5-fold CV for HGB on raw features\n",
        "skf5 = make_skf(n_splits=5, seed=SEED)\n",
        "hgb_params = {\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 5,\n",
        "    'max_leaf_nodes': 31,\n",
        "    'min_samples_leaf': 5,\n",
        "    'l2_regularization': 1.0,\n",
        "    'max_iter': 300,\n",
        "    'early_stopping': True,\n",
        "    'n_iter_no_change': 20,\n",
        "    'tol': 1e-7,\n",
        "    'validation_fraction': 0.2,\n",
        "    'random_state': SEED\n",
        "}\n",
        "hgb_oof, hgb_test, hgb_loss, _ = hgb_cv_oof(X, y, X_test, n_classes, skf5, params=hgb_params, desc='HGB5')\n",
        "\n",
        "# Build stacking features from available strong base models (OOF probs) + HGB\n",
        "base_models = []\n",
        "if 'lr5_oof' in globals() and np.isfinite(lr5_loss):\n",
        "    base_models.append(('LR5', lr5_oof, lr5_test, lr5_loss))\n",
        "if 'best_svc2_oof' in globals() and 'best_svc2_test' in globals() and np.isfinite(best_svc2_loss):\n",
        "    base_models.append(('SVC_rbf', best_svc2_oof, best_svc2_test, best_svc2_loss))\n",
        "if 'lin_oof' in globals() and 'lin_test' in globals() and np.isfinite(lin_loss):\n",
        "    base_models.append(('LinSVC', lin_oof, lin_test, lin_loss))\n",
        "base_models.append(('HGB5', hgb_oof, hgb_test, hgb_loss))\n",
        "\n",
        "# Keep only reasonably strong contributors\n",
        "base_models = [m for m in base_models if m[3] < 0.2]\n",
        "print('Stacking bases:', [(n, round(l,6)) for n,_,_,l in base_models])\n",
        "if len(base_models) == 0:\n",
        "    # Fallback to HGB alone\n",
        "    final_test = clip_and_renorm(hgb_test)\n",
        "    sub = pd.DataFrame(final_test, columns=classes); sub.insert(0, 'id', test_ids); sub.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (HGB only) with shape:', sub.shape)\n",
        "else:\n",
        "    # Prepare level-2 data\n",
        "    X_meta = np.concatenate([m[1] for m in base_models], axis=1)\n",
        "    X_meta_test = np.concatenate([m[2] for m in base_models], axis=1)\n",
        "    # Build OOF for meta model using the same skf5 to avoid leakage\n",
        "    meta_oof = np.zeros((X.shape[0], n_classes), dtype=np.float64)\n",
        "    meta_test_accum = np.zeros((X_test.shape[0], n_classes), dtype=np.float64)\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf5.split(X, y), 1):\n",
        "        t0 = time.time()\n",
        "        X_tr_m, X_va_m = X_meta[tr_idx], X_meta[va_idx]\n",
        "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "        meta = LogisticRegression(solver='lbfgs', multi_class='multinomial', C=1.0, max_iter=1000, n_jobs=-1, random_state=SEED)\n",
        "        meta.fit(X_tr_m, y_tr)\n",
        "        va_proba = meta.predict_proba(X_va_m)\n",
        "        loss = log_loss(y_va, va_proba, labels=list(range(n_classes)))\n",
        "        meta_oof[va_idx] = va_proba\n",
        "        meta_test_accum += meta.predict_proba(X_meta_test) / skf5.get_n_splits()\n",
        "        print(f'[Stack LR] Fold {fold}/5 meta logloss={loss:.6f} time={time.time()-t0:.1f}s', flush=True)\n",
        "    meta_oof = clip_and_renorm(meta_oof)\n",
        "    meta_test = clip_and_renorm(meta_test_accum)\n",
        "    meta_loss = log_loss(y, meta_oof, labels=list(range(n_classes)))\n",
        "    print(f'[Stack LR] OOF logloss={meta_loss:.6f}')\n",
        "    # Epsilon smoothing\n",
        "    eps = 0.001\n",
        "    meta_test = meta_test * (1 - eps) + eps / n_classes\n",
        "    # Save submission\n",
        "    sub = pd.DataFrame(meta_test, columns=classes)\n",
        "    sub.insert(0, 'id', test_ids)\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('Saved submission.csv (Stacked LR on OOF probs) with shape:', sub.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HGB5] Starting fold 1/5 | train=712 valid=179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HGB5] Fold 1/5 logloss=1.121763 time=19.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HGB5] Starting fold 2/5 | train=713 valid=178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HGB5] Fold 2/5 logloss=1.096867 time=19.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HGB5] Starting fold 3/5 | train=713 valid=178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HGB5] Fold 3/5 logloss=1.174128 time=20.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HGB5] Starting fold 4/5 | train=713 valid=178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HGB5] Fold 4/5 logloss=1.175451 time=20.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HGB5] Starting fold 5/5 | train=713 valid=178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HGB5] Fold 5/5 logloss=0.988615 time=20.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HGB5] OOF logloss=1.111376 | mean_folds=1.111365 | total=1.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking bases: [('LR5', 0.118336), ('SVC_rbf', 0.170827), ('LinSVC', 0.164243)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stack LR] Fold 1/5 meta logloss=0.402552 time=1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stack LR] Fold 2/5 meta logloss=0.406568 time=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stack LR] Fold 3/5 meta logloss=0.405242 time=1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stack LR] Fold 4/5 meta logloss=0.429567 time=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stack LR] Fold 5/5 meta logloss=0.418111 time=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Stack LR] OOF logloss=0.412397\nSaved submission.csv (Stacked LR on OOF probs) with shape: (99, 100)\n"
          ]
        }
      ]
    },
    {
      "id": "37de5dbd-f859-42b1-a5c8-30cb1158b748",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Force-install precompiled wheels for LightGBM and XGBoost (avoid building from source)\n",
        "import sys, subprocess, importlib\n",
        "def pip_install(args):\n",
        "    print('Installing packages:', ' '.join(args), flush=True)\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', '--no-cache-dir', '--prefer-binary'] + args)\n",
        "\n",
        "pkgs = [\"lightgbm>=4.1.0\", \"xgboost==1.7.6\"]\n",
        "pip_install(pkgs)\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "print('lightgbm version:', lgb.__version__)\n",
        "print('xgboost version:', xgb.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing packages: lightgbm>=4.1.0 xgboost==1.7.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lightgbm version: 4.6.0\nxgboost version: 1.7.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
          ]
        }
      ]
    },
    {
      "id": "3dbc3795-f521-4ea2-bcd4-d191f7be8e93",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convex weight optimization on existing OOF predictions (no installs) and save submission\n",
        "import numpy as np\n",
        "from sklearn.metrics import log_loss\n",
        "from math import isfinite\n",
        "import time\n",
        "\n",
        "# Always avoid SciPy to prevent stalls; use fast simplex search\n",
        "SCIPY_AVAILABLE = False\n",
        "\n",
        "def normalize_weights(w):\n",
        "    w = np.maximum(w, 0)\n",
        "    s = w.sum()\n",
        "    if s <= 0:\n",
        "        w = np.ones_like(w) / len(w)\n",
        "    else:\n",
        "        w = w / s\n",
        "    return w\n",
        "\n",
        "def blend_probs(weights, prob_list):\n",
        "    w = normalize_weights(np.array(weights, dtype=np.float64))\n",
        "    P = np.tensordot(w, np.stack(prob_list, axis=0), axes=(0,0))\n",
        "    P = clip_and_renorm(P, eps=1e-15)\n",
        "    return P\n",
        "\n",
        "# Collect available strong bases\n",
        "bases = []  # (name, oof, test, loss)\n",
        "if 'lr5_oof' in globals() and isfinite(lr5_loss):\n",
        "    bases.append(('LR5', lr5_oof, lr5_test, lr5_loss))\n",
        "if 'best_svc2_oof' in globals() and 'best_svc2_test' in globals() and isfinite(best_svc2_loss):\n",
        "    bases.append(('SVC_rbf', best_svc2_oof, best_svc2_test, best_svc2_loss))\n",
        "if 'lin_oof' in globals() and 'lin_test' in globals() and isfinite(lin_loss):\n",
        "    bases.append(('LinSVC', lin_oof, lin_test, lin_loss))\n",
        "bases = [b for b in bases if b[3] < 0.2]\n",
        "print('Bases for optimization:', [(n, round(l,6)) for n,_,_,l in bases])\n",
        "assert len(bases) >= 2, 'Need at least two base models to optimize weights.'\n",
        "\n",
        "oof_list = [b[1] for b in bases]\n",
        "test_list = [b[2] for b in bases]\n",
        "loss_list = np.array([b[3] for b in bases], dtype=np.float64)\n",
        "names = [b[0] for b in bases]\n",
        "k = len(bases)\n",
        "\n",
        "def obj(w):\n",
        "    P = blend_probs(w, oof_list)\n",
        "    return log_loss(y, P, labels=list(range(n_classes)))\n",
        "\n",
        "# Baselines\n",
        "w_eq = np.ones(k) / k\n",
        "eq_loss = obj(w_eq)\n",
        "w0 = 1.0 / np.maximum(loss_list, 1e-9)\n",
        "w0 = w0 / w0.sum()\n",
        "w_best = w0.copy()\n",
        "best = obj(w_best)\n",
        "print(f'Init losses -> equal: {eq_loss:.6f} | inv-loss init: {best:.6f}', flush=True)\n",
        "\n",
        "t_start = time.time()\n",
        "rng = np.random.default_rng(SEED)\n",
        "\n",
        "if k == 2:\n",
        "    # Fine 1D grid for 2 models\n",
        "    grid = np.linspace(0, 1, 1001)\n",
        "    for i, a in enumerate(grid, 1):\n",
        "        w = np.array([a, 1-a], dtype=np.float64)\n",
        "        val = obj(w)\n",
        "        if val < best:\n",
        "            best, w_best = val, w\n",
        "        if i % 200 == 0:\n",
        "            print(f'Grid2 progress {i}/{len(grid)} best={best:.6f}', flush=True)\n",
        "else:\n",
        "    # Mixed strategy: coarse simplex grid for k=3 plus random simplex search\n",
        "    if k == 3:\n",
        "        # Coarse grid step 0.02\n",
        "        grid = np.linspace(0, 1, 51)\n",
        "        cnt = 0\n",
        "        for a in grid:\n",
        "            for b in grid:\n",
        "                c = 1 - a - b\n",
        "                if c < 0: continue\n",
        "                w = np.array([a, b, c], dtype=np.float64)\n",
        "                val = obj(w)\n",
        "                cnt += 1\n",
        "                if val < best:\n",
        "                    best, w_best = val, w\n",
        "                if cnt % 2000 == 0:\n",
        "                    print(f'Coarse grid3 progress {cnt} best={best:.6f}', flush=True)\n",
        "    # Random simplex search\n",
        "    samples = 4000 if k == 3 else 6000\n",
        "    for i in range(1, samples + 1):\n",
        "        w = rng.random(k)\n",
        "        w = w / w.sum()\n",
        "        val = obj(w)\n",
        "        if val < best:\n",
        "            best, w_best = val, w\n",
        "        if i % 500 == 0:\n",
        "            print(f'Random simplex {i}/{samples} best={best:.6f}', flush=True)\n",
        "\n",
        "opt_oof = blend_probs(w_best, oof_list)\n",
        "opt_loss = log_loss(y, opt_oof, labels=list(range(n_classes)))\n",
        "elapsed = time.time() - t_start\n",
        "print('Optimized weights:', dict(zip(names, np.round(w_best, 6))))\n",
        "print(f'[Optimized Blend] OOF logloss={opt_loss:.6f} (equal={eq_loss:.6f}, invloss_init={obj(w0):.6f}) | time={elapsed:.1f}s', flush=True)\n",
        "\n",
        "# Apply to test and save submission with tiny epsilon smoothing\n",
        "opt_test = blend_probs(w_best, test_list)\n",
        "eps = 0.001\n",
        "opt_test = opt_test * (1 - eps) + eps / n_classes\n",
        "sub = pd.DataFrame(opt_test, columns=classes)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (optimized weighted blend) with shape:', sub.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bases for optimization: [('LR5', 0.036933), ('SVC_rbf', 0.170827), ('LinSVC', 0.164243)]\nInit losses -> equal: 0.063499 | inv-loss init: 0.047174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random simplex 500/4000 best=0.036933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random simplex 1000/4000 best=0.036933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random simplex 1500/4000 best=0.036933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random simplex 2000/4000 best=0.036933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random simplex 2500/4000 best=0.036933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random simplex 3000/4000 best=0.036933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random simplex 3500/4000 best=0.036933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random simplex 4000/4000 best=0.036933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized weights: {'LR5': 1.0, 'SVC_rbf': 0.0, 'LinSVC': 0.0}\n[Optimized Blend] OOF logloss=0.036933 (equal=0.063499, invloss_init=0.047174) | time=35.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission.csv (optimized weighted blend) with shape: (99, 100)\n"
          ]
        }
      ]
    },
    {
      "id": "f924fcb4-5fe9-49ae-afe4-3d31c036c6d3",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick blend: equal vs inverse-loss weights over existing OOFs; pick best and save submission\n",
        "import numpy as np\n",
        "from math import isfinite\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "bases = []  # (name, oof, test, loss)\n",
        "if 'lr5_oof' in globals() and isfinite(lr5_loss):\n",
        "    bases.append(('LR5', lr5_oof, lr5_test, lr5_loss))\n",
        "if 'best_svc2_oof' in globals() and 'best_svc2_test' in globals() and isfinite(best_svc2_loss):\n",
        "    bases.append(('SVC_rbf', best_svc2_oof, best_svc2_test, best_svc2_loss))\n",
        "if 'lin_oof' in globals() and 'lin_test' in globals() and isfinite(lin_loss):\n",
        "    bases.append(('LinSVC', lin_oof, lin_test, lin_loss))\n",
        "assert len(bases) >= 2, 'Need at least two base models available (LR5, SVC_rbf, LinSVC) to blend.'\n",
        "print('Blend bases:', [(n, round(l,6)) for n,_,_,l in bases])\n",
        "\n",
        "oof_list = [b[1] for b in bases]\n",
        "test_list = [b[2] for b in bases]\n",
        "loss_list = np.array([b[3] for b in bases], dtype=np.float64)\n",
        "k = len(bases)\n",
        "\n",
        "def blend(weights, plist):\n",
        "    w = np.maximum(weights, 0); w = w / w.sum()\n",
        "    P = np.tensordot(w, np.stack(plist, axis=0), axes=(0,0))\n",
        "    return clip_and_renorm(P, eps=1e-15)\n",
        "\n",
        "# Equal-weight blend\n",
        "w_eq = np.ones(k) / k\n",
        "oof_eq = blend(w_eq, oof_list)\n",
        "loss_eq = log_loss(y, oof_eq, labels=list(range(n_classes)))\n",
        "\n",
        "# Inverse-loss weighted blend\n",
        "w_il = 1.0 / np.maximum(loss_list, 1e-9); w_il = w_il / w_il.sum()\n",
        "oof_il = blend(w_il, oof_list)\n",
        "loss_il = log_loss(y, oof_il, labels=list(range(n_classes)))\n",
        "\n",
        "print(f'Equal-weight OOF: {loss_eq:.6f} | Inv-loss-weight OOF: {loss_il:.6f}')\n",
        "w_best = w_il if loss_il < loss_eq else w_eq\n",
        "print('Chosen weights:', dict(zip([b[0] for b in bases], np.round(w_best, 6))))\n",
        "\n",
        "test_blend = blend(w_best, test_list)\n",
        "eps = 0.001\n",
        "test_blend = test_blend * (1 - eps) + eps / n_classes\n",
        "sub = pd.DataFrame(test_blend, columns=classes)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (quick blend) with shape:', sub.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "d95a9d15-7875-4c43-8260-203e1261cf1e",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Bootstrap: imports, utilities, data load (no model training)\n",
        "import os, time, sys, gc, math, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, PowerTransformer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "def load_data_fast():\n",
        "    train = pd.read_csv('train.csv')\n",
        "    test = pd.read_csv('test.csv')\n",
        "    print('Train shape:', train.shape, ' Test shape:', test.shape, flush=True)\n",
        "    train_ids = train['id'].values\n",
        "    test_ids = test['id'].values\n",
        "    X = train.drop(columns=['id', 'species'])\n",
        "    y = train['species'].values\n",
        "    X_test = test.drop(columns=['id'])\n",
        "    assert list(X.columns) == list(X_test.columns), 'Train/Test feature mismatch'\n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(y)\n",
        "    classes = le.classes_\n",
        "    if X.isnull().any().any() or X_test.isnull().any().any():\n",
        "        X = X.fillna(0); X_test = X_test.fillna(0)\n",
        "    return X.values, y_enc, X_test.values, classes, test_ids, le\n",
        "\n",
        "def make_skf(n_splits=5, seed=SEED):\n",
        "    return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
        "\n",
        "def clip_and_renorm(probs, eps=1e-15):\n",
        "    P = np.clip(probs, eps, 1 - eps)\n",
        "    P /= P.sum(axis=1, keepdims=True)\n",
        "    return P\n",
        "\n",
        "def train_oof(model, X, y, skf, X_test, n_classes, desc='model'):\n",
        "    n_samples = X.shape[0]\n",
        "    oof = np.zeros((n_samples, n_classes), dtype=np.float64)\n",
        "    test_pred = np.zeros((X_test.shape[0], n_classes), dtype=np.float64)\n",
        "    fold_losses = []\n",
        "    start_all = time.time()\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
        "        t0 = time.time()\n",
        "        X_tr, y_tr = X[tr_idx], y[tr_idx]\n",
        "        X_va, y_va = X[va_idx], y[va_idx]\n",
        "        from sklearn.base import clone\n",
        "        clf = clone(model)\n",
        "        clf.fit(X_tr, y_tr)\n",
        "        va_proba = clf.predict_proba(X_va)\n",
        "        loss = log_loss(y_va, va_proba, labels=list(range(n_classes)))\n",
        "        oof[va_idx] = va_proba\n",
        "        fold_losses.append(loss)\n",
        "        test_pred += clf.predict_proba(X_test) / skf.get_n_splits()\n",
        "        print(f'[{desc}] Fold {fold}/{skf.get_n_splits()} logloss={loss:.6f} time={time.time()-t0:.1f}s', flush=True)\n",
        "    oof_loss = log_loss(y, oof, labels=list(range(n_classes)))\n",
        "    print(f'[{desc}] OOF logloss={oof_loss:.6f} | mean_folds={np.mean(fold_losses):.6f} | total={(time.time()-start_all)/60:.1f}m', flush=True)\n",
        "    return oof, test_pred, oof_loss, fold_losses\n",
        "\n",
        "# Load once\n",
        "X, y, X_test, classes, test_ids, le = load_data_fast()\n",
        "n_classes = len(classes)\n",
        "skf5 = make_skf(n_splits=5, seed=SEED)\n",
        "print('Bootstrap complete. n_classes:', n_classes, 'X shape:', X.shape, 'X_test shape:', X_test.shape, flush=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (891, 194)  Test shape: (99, 193)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bootstrap complete. n_classes: 99 X shape: (891, 192) X_test shape: (99, 192)\n"
          ]
        }
      ]
    },
    {
      "id": "19073837-1c66-4b24-97de-d895572364e1",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Fast LR tuning (multinomial, L2) over C; replace lr5_* with best and save quick blend\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "Cs = [0.5, 1.0, 2.0, 3.0, 5.0, 10.0]\n",
        "best_C = None\n",
        "best_lr_oof = None\n",
        "best_lr_test = None\n",
        "best_lr_loss = np.inf\n",
        "for C in Cs:\n",
        "    pipe = Pipeline(steps=[('scaler', StandardScaler()), ('clf', LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty='l2', max_iter=5000, n_jobs=-1, random_state=SEED))])\n",
        "    oof, test_pred, loss, _ = train_oof(pipe, X, y, skf5, X_test, n_classes, desc=f'LR_C{C}')\n",
        "    if loss < best_lr_loss:\n",
        "        best_lr_loss = loss\n",
        "        best_C = C\n",
        "        best_lr_oof = oof\n",
        "        best_lr_test = test_pred\n",
        "print('Best LR C:', best_C, 'OOF:', best_lr_loss)\n",
        "\n",
        "# Replace lr5_* aliases to use tuned LR going forward\n",
        "lr5_oof, lr5_test, lr5_loss = best_lr_oof, best_lr_test, best_lr_loss\n",
        "\n",
        "# Quick re-blend with LinSVC/SVC if available using optimized weights cell later\n",
        "cands = [('LR5', lr5_loss)]\n",
        "if 'lin_oof' in globals() and lin_oof is not None: cands.append(('LinSVC', lin_loss))\n",
        "if 'best_svc2_oof' in globals() and best_svc2_oof is not None: cands.append(('SVC_rbf', best_svc2_loss))\n",
        "print('Bases now:', [(n, round(l,6)) for n,l in cands])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C0.5] Fold 1/5 logloss=0.157535 time=13.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C0.5] Fold 2/5 logloss=0.147769 time=15.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C0.5] Fold 3/5 logloss=0.161110 time=15.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C0.5] Fold 4/5 logloss=0.159580 time=15.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C0.5] Fold 5/5 logloss=0.161023 time=15.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C0.5] OOF logloss=0.157403 | mean_folds=0.157403 | total=1.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C1.0] Fold 1/5 logloss=0.115621 time=16.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C1.0] Fold 2/5 logloss=0.108472 time=18.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C1.0] Fold 3/5 logloss=0.122760 time=18.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C1.0] Fold 4/5 logloss=0.120443 time=18.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C1.0] Fold 5/5 logloss=0.124398 time=19.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C1.0] OOF logloss=0.118336 | mean_folds=0.118339 | total=1.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C2.0] Fold 1/5 logloss=0.088162 time=17.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C2.0] Fold 2/5 logloss=0.082791 time=23.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C2.0] Fold 3/5 logloss=0.098677 time=21.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C2.0] Fold 4/5 logloss=0.095637 time=22.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C2.0] Fold 5/5 logloss=0.101679 time=22.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C2.0] OOF logloss=0.093383 | mean_folds=0.093389 | total=1.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C3.0] Fold 1/5 logloss=0.076840 time=20.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C3.0] Fold 2/5 logloss=0.072264 time=27.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C3.0] Fold 3/5 logloss=0.089373 time=24.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C3.0] Fold 4/5 logloss=0.085693 time=25.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C3.0] Fold 5/5 logloss=0.092630 time=25.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C3.0] OOF logloss=0.083353 | mean_folds=0.083360 | total=2.0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C5.0] Fold 1/5 logloss=0.066230 time=23.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C5.0] Fold 2/5 logloss=0.062491 time=31.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C5.0] Fold 3/5 logloss=0.081113 time=26.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C5.0] Fold 4/5 logloss=0.076784 time=28.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C5.0] Fold 5/5 logloss=0.084534 time=29.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C5.0] OOF logloss=0.074221 | mean_folds=0.074230 | total=2.3m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C10.0] Fold 1/5 logloss=0.056808 time=28.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C10.0] Fold 2/5 logloss=0.053844 time=37.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C10.0] Fold 3/5 logloss=0.073693 time=31.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C10.0] Fold 4/5 logloss=0.069233 time=33.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C10.0] Fold 5/5 logloss=0.077701 time=35.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_C10.0] OOF logloss=0.066245 | mean_folds=0.066256 | total=2.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best LR C: 10.0 OOF: 0.06624531781361775\nBases now: [('LR5', 0.066245), ('LinSVC', 0.164243), ('SVC_rbf', 0.170827)]\n"
          ]
        }
      ]
    },
    {
      "id": "39d19dd6-0e7e-41d2-9684-b0d4b261300a",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extended LR tuning: very large C and PowerTransformer variants; update lr5_* if improved\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "best_loss = lr5_loss if 'lr5_loss' in globals() else float('inf')\n",
        "best_oof = lr5_oof if 'lr5_oof' in globals() else None\n",
        "best_test = lr5_test if 'lr5_test' in globals() else None\n",
        "best_tag = 'existing_lr5'\n",
        "\n",
        "def run_lr_pipeline(pipe, tag):\n",
        "    oof, test_pred, loss, _ = train_oof(pipe, X, y, skf5, X_test, n_classes, desc=tag)\n",
        "    return oof, test_pred, loss\n",
        "\n",
        "# 1) High-C sweep (StandardScaler -> LR(saga, L2))\n",
        "Cs_high = [20, 50, 100, 200, 500]\n",
        "for C in Cs_high:\n",
        "    pipe = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty='l2', max_iter=20000, tol=1e-4, n_jobs=-1, random_state=SEED))\n",
        "    ])\n",
        "    oof, test_pred, loss = run_lr_pipeline(pipe, f'LR_highC_C{C}')\n",
        "    if loss < best_loss:\n",
        "        best_loss, best_oof, best_test, best_tag = loss, oof, test_pred, f'LR_highC_C{C}'\n",
        "print('High-C LR best so far:', best_tag, 'OOF=', best_loss)\n",
        "\n",
        "# 2) PowerTransformer(YJ) -> LR(saga, L2) sweep\n",
        "Cs_pt = [10, 50, 100]\n",
        "for C in Cs_pt:\n",
        "    pipe = Pipeline(steps=[\n",
        "        ('pt', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
        "        ('clf', LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty='l2', max_iter=20000, tol=1e-4, n_jobs=-1, random_state=SEED))\n",
        "    ])\n",
        "    oof, test_pred, loss = run_lr_pipeline(pipe, f'LR_PT_C{C}')\n",
        "    if loss < best_loss:\n",
        "        best_loss, best_oof, best_test, best_tag = loss, oof, test_pred, f'LR_PT_C{C}'\n",
        "print('Overall LR best:', best_tag, 'OOF=', best_loss)\n",
        "\n",
        "# Update lr5_* aliases if improved\n",
        "if best_oof is not None and best_loss < (lr5_loss if 'lr5_loss' in globals() else float('inf')):\n",
        "    lr5_oof, lr5_test, lr5_loss = best_oof, best_test, best_loss\n",
        "    print('Updated lr5_* to', best_tag, 'with OOF=', lr5_loss)\n",
        "else:\n",
        "    print('Kept existing lr5_* with OOF=', lr5_loss if 'lr5_loss' in globals() else None)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C20] Fold 1/5 logloss=0.051280 time=32.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C20] Fold 2/5 logloss=0.048810 time=41.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C20] Fold 3/5 logloss=0.068929 time=37.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C20] Fold 4/5 logloss=0.064344 time=38.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C20] Fold 5/5 logloss=0.073931 time=39.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C20] OOF logloss=0.061447 | mean_folds=0.061459 | total=3.1m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C50] Fold 1/5 logloss=0.046969 time=38.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C50] Fold 2/5 logloss=0.045425 time=45.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C50] Fold 3/5 logloss=0.065713 time=42.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C50] Fold 4/5 logloss=0.060829 time=43.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C50] Fold 5/5 logloss=0.071508 time=42.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C50] OOF logloss=0.058076 | mean_folds=0.058089 | total=3.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C100] Fold 1/5 logloss=0.045285 time=40.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C100] Fold 2/5 logloss=0.044202 time=46.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C100] Fold 3/5 logloss=0.064603 time=44.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C100] Fold 4/5 logloss=0.059596 time=45.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C100] Fold 5/5 logloss=0.070551 time=44.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C100] OOF logloss=0.056834 | mean_folds=0.056847 | total=3.7m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C200] Fold 1/5 logloss=0.044371 time=42.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C200] Fold 2/5 logloss=0.043589 time=47.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C200] Fold 3/5 logloss=0.064006 time=45.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C200] Fold 4/5 logloss=0.058959 time=46.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C200] Fold 5/5 logloss=0.070039 time=45.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C200] OOF logloss=0.056180 | mean_folds=0.056193 | total=3.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C500] Fold 1/5 logloss=0.043811 time=43.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C500] Fold 2/5 logloss=0.043200 time=48.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C500] Fold 3/5 logloss=0.063646 time=46.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C500] Fold 4/5 logloss=0.058539 time=47.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C500] Fold 5/5 logloss=0.069715 time=46.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_highC_C500] OOF logloss=0.055769 | mean_folds=0.055782 | total=3.8m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "High-C LR best so far: LR_highC_C500 OOF= 0.05576877307805801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C10] Fold 1/5 logloss=0.050577 time=27.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C10] Fold 2/5 logloss=0.049346 time=27.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C10] Fold 3/5 logloss=0.044511 time=26.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C10] Fold 4/5 logloss=0.055832 time=28.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C10] Fold 5/5 logloss=0.045542 time=24.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C10] OOF logloss=0.049163 | mean_folds=0.049161 | total=2.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C50] Fold 1/5 logloss=0.037064 time=38.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C50] Fold 2/5 logloss=0.039332 time=38.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C50] Fold 3/5 logloss=0.035063 time=37.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C50] Fold 4/5 logloss=0.046606 time=41.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C50] Fold 5/5 logloss=0.035221 time=37.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C50] OOF logloss=0.038655 | mean_folds=0.038657 | total=3.2m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C100] Fold 1/5 logloss=0.034663 time=41.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C100] Fold 2/5 logloss=0.037764 time=40.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C100] Fold 3/5 logloss=0.033549 time=40.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C100] Fold 4/5 logloss=0.045260 time=43.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C100] Fold 5/5 logloss=0.033440 time=41.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LR_PT_C100] OOF logloss=0.036933 | mean_folds=0.036935 | total=3.5m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall LR best: LR_PT_C100 OOF= 0.03693293302891193\nUpdated lr5_* to LR_PT_C100 with OOF= 0.03693293302891193\n"
          ]
        }
      ]
    },
    {
      "id": "0855c64e-ee04-43d4-b8da-5d5838f69da9",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# PT-LogReg extension: larger C for L2 and ElasticNet with small l1_ratio; update lr5_* if improved\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "best_loss = lr5_loss if 'lr5_loss' in globals() else float('inf')\n",
        "best_oof = lr5_oof if 'lr5_oof' in globals() else None\n",
        "best_test = lr5_test if 'lr5_test' in globals() else None\n",
        "best_tag = 'existing_lr5'\n",
        "\n",
        "def run_lr_pipeline(pipe, tag):\n",
        "    oof, test_pred, loss, _ = train_oof(pipe, X, y, skf5, X_test, n_classes, desc=tag)\n",
        "    return oof, test_pred, loss\n",
        "\n",
        "# 1) PT(YJ) + L2 with much larger C\n",
        "Cs_pt_ext = [200, 500, 1000, 2000]\n",
        "for C in Cs_pt_ext:\n",
        "    pipe = Pipeline(steps=[\n",
        "        ('pt', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
        "        ('clf', LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty='l2', max_iter=30000, tol=1e-4, n_jobs=-1, random_state=SEED))\n",
        "    ])\n",
        "    oof, test_pred, loss = run_lr_pipeline(pipe, f'LR_PT_L2_C{C}')\n",
        "    if loss < best_loss:\n",
        "        best_loss, best_oof, best_test, best_tag = loss, oof, test_pred, f'LR_PT_L2_C{C}'\n",
        "print('PT L2 best so far:', best_tag, 'OOF=', best_loss)\n",
        "\n",
        "# 2) PT(YJ) + ElasticNet (small L1) with C grid\n",
        "l1_ratios = [0.01, 0.05, 0.1]\n",
        "Cs_en = [50, 100, 200, 500]\n",
        "for l1r in l1_ratios:\n",
        "    for C in Cs_en:\n",
        "        pipe = Pipeline(steps=[\n",
        "            ('pt', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
        "            ('clf', LogisticRegression(multi_class='multinomial', solver='saga', C=C, penalty='elasticnet', l1_ratio=l1r, max_iter=30000, tol=1e-4, n_jobs=-1, random_state=SEED))\n",
        "        ])\n",
        "        tag = f'LR_PT_EN_l1{l1r}_C{C}'\n",
        "        oof, test_pred, loss = run_lr_pipeline(pipe, tag)\n",
        "        if loss < best_loss:\n",
        "            best_loss, best_oof, best_test, best_tag = loss, oof, test_pred, tag\n",
        "print('Overall PT-LogReg best:', best_tag, 'OOF=', best_loss)\n",
        "\n",
        "# Update lr5_* if improved\n",
        "if best_oof is not None and best_loss < (lr5_loss if 'lr5_loss' in globals() else float('inf')):\n",
        "    lr5_oof, lr5_test, lr5_loss = best_oof, best_test, best_loss\n",
        "    print('Updated lr5_* to', best_tag, 'with OOF=', lr5_loss)\n",
        "else:\n",
        "    print('Kept existing lr5_* with OOF=', lr5_loss if 'lr5_loss' in globals() else None)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "id": "f36766f2-3cd9-409d-969b-af1f880c64c4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Refit best PT+LR (L2, C=2000) cleanly; set lr5_* and save submission\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "best_pipe = Pipeline(steps=[\n",
        "    ('pt', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
        "    ('clf', LogisticRegression(multi_class='multinomial', solver='saga', C=2000, penalty='l2', max_iter=30000, tol=1e-4, n_jobs=-1, random_state=SEED))\n",
        "])\n",
        "lr5_oof, lr5_test, lr5_loss, _ = train_oof(best_pipe, X, y, skf5, X_test, n_classes, desc='LR_PT_L2_C2000_refit')\n",
        "print('Set lr5_* from LR_PT_L2_C2000_refit: OOF=', lr5_loss)\n",
        "\n",
        "# Save submission directly from this best model (also used by blending cell 11 if rerun)\n",
        "sub = pd.DataFrame(clip_and_renorm(lr5_test), columns=classes)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (LR_PT_L2_C2000_refit) with shape:', sub.shape)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "id": "76c1ff23-d3a2-4e0f-b69c-625b8ae51fd4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick set best: PT(YJ) + LR L2 C=2000 single run to set lr5_* and save submission\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "best_pipe = Pipeline(steps=[\n",
        "    ('pt', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
        "    ('clf', LogisticRegression(multi_class='multinomial', solver='saga', C=2000, penalty='l2', max_iter=30000, tol=1e-4, n_jobs=-1, random_state=SEED))\n",
        "])\n",
        "lr5_oof, lr5_test, lr5_loss, _ = train_oof(best_pipe, X, y, skf5, X_test, n_classes, desc='LR_PT_L2_C2000_single')\n",
        "print('lr5 updated: OOF=', lr5_loss)\n",
        "\n",
        "sub = pd.DataFrame(clip_and_renorm(lr5_test), columns=classes)\n",
        "sub.insert(0, 'id', test_ids)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "print('Saved submission.csv (PT+LR L2 C=2000) with shape:', sub.shape)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "id": "f81f12c2-688a-432b-b978-9bcbb0e655d8",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Promote best from Cell 16 (if available) to lr5_* without retraining; save submission\n",
        "if 'best_oof' in globals() and 'best_test' in globals() and 'best_loss' in globals():\n",
        "    print('Found best from prior sweep:', globals().get('best_tag', 'unknown'), 'OOF=', best_loss)\n",
        "    lr5_oof, lr5_test, lr5_loss = best_oof, best_test, float(best_loss)\n",
        "    sub = pd.DataFrame(clip_and_renorm(lr5_test), columns=classes)\n",
        "    sub.insert(0, 'id', test_ids)\n",
        "    sub.to_csv('submission.csv', index=False)\n",
        "    print('lr5_* set from best sweep. OOF=', lr5_loss, '| submission.csv saved:', sub.shape)\n",
        "else:\n",
        "    print('No best_* globals available to promote; skip.')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "id": "535f4b6a-3cb1-4de1-999c-af9a6d58a77d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Minimal promotion of best_* -> lr5_* without retraining; fast save submission\n",
        "import numpy as np, pandas as pd\n",
        "if 'best_oof' in globals() and 'best_test' in globals() and 'best_loss' in globals():\n",
        "    try:\n",
        "        lr5_oof = np.array(best_oof, copy=True)\n",
        "        lr5_test = np.array(best_test, copy=True)\n",
        "        lr5_loss = float(best_loss)\n",
        "        print('[Promote] Using best_tag:', globals().get('best_tag', 'unknown'), 'OOF=', lr5_loss, flush=True)\n",
        "        sub = pd.DataFrame(clip_and_renorm(lr5_test), columns=classes)\n",
        "        sub.insert(0, 'id', test_ids)\n",
        "        sub.to_csv('submission.csv', index=False)\n",
        "        print('[Promote] lr5_* set and submission.csv saved', sub.shape, flush=True)\n",
        "    except Exception as e:\n",
        "        print('[Promote] Failed:', e, flush=True)\n",
        "else:\n",
        "    print('[Promote] best_* globals not found; skip', flush=True)"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}