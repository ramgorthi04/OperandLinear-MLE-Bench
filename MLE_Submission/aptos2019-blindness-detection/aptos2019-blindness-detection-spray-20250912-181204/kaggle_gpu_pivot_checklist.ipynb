{
  "cells": [
    {
      "id": "6ad5b75e-011a-4a99-821c-6c975bacfb1d",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Kaggle GPU pivot: reassemble cache768, set paths, verify GPU\n",
        "import os, sys, glob, subprocess, shutil, time\n",
        "from pathlib import Path\n",
        "\n",
        "IN_BASE = Path('/kaggle/input')\n",
        "WK = Path('/kaggle/working')\n",
        "WK.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) Locate cache768.tar.part** files from added Dataset\n",
        "part_paths = sorted([p for p in IN_BASE.rglob('cache768.tar.part*') if p.is_file()])\n",
        "assert len(part_paths) >= 1, 'Add the aptos-cache768 dataset with cache768.tar.part** files to this notebook (Add Data).'\n",
        "print('Found parts:', len(part_paths))\n",
        "for p in part_paths[:5]:\n",
        "    print('  ', p)\n",
        "\n",
        "# 2) Reassemble into /kaggle/working/cache768.tar\n",
        "tar_path = WK / 'cache768.tar'\n",
        "if not tar_path.exists():\n",
        "    with open(tar_path, 'wb') as fout:\n",
        "        for p in part_paths:\n",
        "            with open(p, 'rb') as fin:\n",
        "                shutil.copyfileobj(fin, fout)\n",
        "    print('Wrote', tar_path, 'size:', round(tar_path.stat().st_size / 1024**3, 2), 'GB')\n",
        "else:\n",
        "    print('Exists:', tar_path)\n",
        "\n",
        "# 3) Extract tar into /kaggle/working\n",
        "cache_dir = WK / 'cache768'\n",
        "if not cache_dir.exists():\n",
        "    import tarfile\n",
        "    t0 = time.time()\n",
        "    with tarfile.open(tar_path, mode='r') as tar:\n",
        "        tar.extractall(path=WK)\n",
        "    print('Extracted to', cache_dir, 'in', f'{time.time()-t0:.1f}s')\n",
        "else:\n",
        "    print('Cache dir already exists:', cache_dir)\n",
        "\n",
        "assert cache_dir.exists(), 'cache768 directory missing after extract'\n",
        "print('CACHE_DIR ready:', cache_dir)\n",
        "\n",
        "# 4) Verify GPU availability\n",
        "try:\n",
        "    import torch\n",
        "    print('torch:', torch.__version__, 'cuda:', getattr(torch.version, 'cuda', None))\n",
        "    assert torch.cuda.is_available(), 'GPU not available. Enable GPU accelerator in Notebook Settings.'\n",
        "    print('CUDA device count:', torch.cuda.device_count())\n",
        "    print('GPU name:', torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    raise SystemExit(f'GPU check failed: {e}')\n",
        "\n",
        "# 5) Paths for training\n",
        "CACHE_DIR = str(cache_dir)\n",
        "OUTPUT_DIR = str(WK)\n",
        "print('Set CACHE_DIR=', CACHE_DIR)\n",
        "print('Set OUTPUT_DIR=', OUTPUT_DIR)\n",
        "\n",
        "# Next steps:\n",
        "# - Add the competition dataset in Add Data (APTOS 2019), ensure /kaggle/input/aptos2019-blindness-detection has train/test csv if needed.\n",
        "# - Copy/paste training pipeline from next24h_plan.ipynb: tf_efficientnetv2_l @768px, AMP on, batch_size 8-12.\n",
        "# - Save OOF/test preds to /kaggle/working and build submission with CDF5 logic if desired."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "3e4253f2-6902-4199-b3a6-6bfd57d6f735",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kaggle GPU Pivot Checklist\n",
        "\n",
        "1) Notebook settings\n",
        "- Accelerator: GPU (T4/P100).\n",
        "- Internet: Off.\n",
        "- High-RAM: On (if available).\n",
        "\n",
        "2) Add Data\n",
        "- Competition: APTOS 2019 Blindness Detection.\n",
        "- Dataset: aptos-cache768 (the one you uploaded with cache768.tar.part**).\n",
        "\n",
        "3) Reassemble cache\n",
        "- Run the first code cell in this notebook to locate parts, reassemble, and extract to /kaggle/working/cache768.\n",
        "- Ensure `torch.cuda.is_available()` prints True and the GPU name.\n",
        "\n",
        "4) Paths\n",
        "- Set `CACHE_DIR = \"/kaggle/working/cache768\"`.\n",
        "- Set `OUTPUT_DIR = \"/kaggle/working\"`.\n",
        "\n",
        "5) Train (tf_efficientnetv2_l @768px)\n",
        "- Library: timm + PyTorch AMP.\n",
        "- Batch size: 8\u201312 (reduce if OOM).\n",
        "- num_workers: 4\u20136, pin_memory=True, persistent_workers=True.\n",
        "- Optim: AdamW, wd\u22481e-5, cosine with warmup.\n",
        "- Loss heads: train both regression (SmoothL1/Huber) and ordinal (cumulative BCE).\n",
        "- Folds: Stratified 5-fold, 8\u201315 epochs; consider 2 seeds.\n",
        "- Progressive resize optional: 640 \u2192 768 (lower LR for the upsize).\n",
        "\n",
        "6) Inference\n",
        "- TTA: 4\u20138 (flips/rotations).\n",
        "- Save OOF and test EVs per model/fold to /kaggle/working.\n",
        "- Calibrate per model with fold-aware isotonic on OOF, apply to test.\n",
        "- Blend EVs (simple average or weight by OOF QWK).\n",
        "\n",
        "7) Submission\n",
        "- Use your CDF5 postprocessing on test:\n",
        "  - Base: 0.7*iso + 0.3*spline.\n",
        "  - CDF-align alpha: 0.85 (map test to OOF quantiles).\n",
        "  - Add 0.01 * rank nudge.\n",
        "  - Tie-breaker: rank-average z-score of [l2xgb_te_ev, test_reg_preds, test_ev_b5_ordinal] (use what\u2019s available).\n",
        "  - Counts (V5): [178, 47, 86, 44, 12] (auto-adjust to M and clip class-4 10\u201315).\n",
        "- Write submission.csv and submit from the notebook.\n",
        "\n",
        "8) If OOM or slow\n",
        "- Lower batch size first; keep AMP on.\n",
        "- Use gradient accumulation (e.g., accum=2).\n",
        "- Reduce TTA to 4.\n",
        "\n",
        "9) Targets\n",
        "- Aim OOF QWK > 0.92 before LB.\n",
        "- If borderline on LB, add 1\u20132 more epochs at 768px or an additional strong backbone (e.g., resnet200d or seresnext101_32x8d) and re-blend.\n",
        "\n",
        "10) Repro tips\n",
        "- Save checkpoints and logs to /kaggle/working.\n",
        "- Print fold times and progress.\n",
        "- Verify submission.csv head/tail and class counts before submitting."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "2719e24d-90c5-4e30-855b-f098c52f93e0",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CDF5 post-processing utility (alpha=0.85, V5 counts) for use after training on Kaggle\n",
        "import numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def cdf5_build_submission(oof_ev_path, te_ev_path, ids_csv='test.csv', out_csv='submission.csv',\n",
        "                          tie_paths=('l2xgb_te_ev.npy','test_reg_preds.npy','test_ev_b5_ordinal.npy'),\n",
        "                          target_counts=(178,47,86,44,12), alpha=0.85):\n",
        "    assert Path(oof_ev_path).exists() and Path(te_ev_path).exists(), 'Missing EV arrays'\n",
        "    oof_ev = np.load(oof_ev_path).astype('float64').ravel()\n",
        "    te_ev = np.load(te_ev_path).astype('float64').ravel()\n",
        "    ids = pd.read_csv(ids_csv)['id_code'].values\n",
        "    M = len(ids)\n",
        "    assert te_ev.shape[0] == M, f'test len mismatch: {te_ev.shape[0]} vs {M}'\n",
        "\n",
        "    # CDF alignment: map test EV distribution to OOF quantiles, then blend with raw (alpha to ref quantiles)\n",
        "    ranks = te_ev.argsort().argsort() / max(1, len(te_ev)-1)\n",
        "    ref_q = np.quantile(oof_ev, ranks, method='linear')\n",
        "    s = (alpha * ref_q + (1.0 - alpha) * te_ev).astype('float64')\n",
        "    # small monotonic rank nudge\n",
        "    s = s + 0.01 * ranks\n",
        "\n",
        "    # Tie-breaker: rank-avg z of available arrays\n",
        "    arrs = []\n",
        "    for p in tie_paths:\n",
        "        if Path(p).exists():\n",
        "            a = np.load(p).astype('float64').ravel()\n",
        "            if a.shape[0] == M:\n",
        "                mu = float(a.mean()); sd = float(a.std() + 1e-9)\n",
        "                arrs.append((a - mu)/sd)\n",
        "    tie = np.mean(np.stack(arrs, 1), 1) if len(arrs) >= 2 else te_ev\n",
        "\n",
        "    # Counts adjustment with guard on class 4\n",
        "    tgt = np.array(target_counts, int).copy()\n",
        "    tgt[4] = int(min(max(tgt[4], 10), 15))\n",
        "    for i in range(4):\n",
        "        if tgt[i] < 1: tgt[i] = 1\n",
        "    diff = int(tgt.sum() - M)\n",
        "    prio = [2, 0, 3, 1]\n",
        "    i = 0; guard = 20000\n",
        "    while diff != 0 and guard > 0:\n",
        "        j = prio[i % len(prio)]\n",
        "        if diff > 0:\n",
        "            if tgt[j] > 1: tgt[j] -= 1; diff -= 1\n",
        "        else:\n",
        "            tgt[j] += 1; diff += 1\n",
        "        i += 1; guard -= 1\n",
        "\n",
        "    # Assign by lexsort order\n",
        "    order = np.lexsort((tie, s))\n",
        "    c0,c1,c2,c3,c4 = tgt.tolist()\n",
        "    cls = np.zeros(M, dtype=np.int64)\n",
        "    cls[order[:c0]] = 0\n",
        "    cls[order[c0:c0+c1]] = 1\n",
        "    cls[order[c0+c1:c0+c1+c2]] = 2\n",
        "    cls[order[c0+c1+c2:c0+c1+c2+c3]] = 3\n",
        "    cls[order[c0+c1+c2+c3:]] = 4\n",
        "\n",
        "    sub = pd.DataFrame({'id_code': ids, 'diagnosis': cls})\n",
        "    sub.to_csv(out_csv, index=False)\n",
        "    print('Wrote', out_csv, 'counts:', sub['diagnosis'].value_counts().sort_index().to_dict())\n",
        "    return sub\n",
        "\n",
        "# Example usage on Kaggle after saving EV arrays:\n",
        "# cdf5_build_submission('/kaggle/working/oof_ev_tfefnv2l_768.npy',\n",
        "#                       '/kaggle/working/test_ev_tfefnv2l_768.npy',\n",
        "#                       ids_csv='/kaggle/input/aptos2019-blindness-detection/test.csv',\n",
        "#                       out_csv='/kaggle/working/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "495ec548-11aa-49e6-bf01-2c2394a8aea4",
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick visual sanity-check: verify circle-cropped cache images (train/test)\n",
        "import os, random, glob, cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "WK = Path('/kaggle/working')\n",
        "CACHE_DIR = WK / 'cache768'\n",
        "assert CACHE_DIR.exists(), 'Run reassembly first to create /kaggle/working/cache768'\n",
        "\n",
        "def show_samples(split='train', n=8):\n",
        "    paths = sorted(glob.glob(str(CACHE_DIR / split / '*.png')))\n",
        "    assert len(paths) > 0, f'No images found in {CACHE_DIR/split}'\n",
        "    sel = random.sample(paths, min(n, len(paths)))\n",
        "    cols = 4\n",
        "    rows = int(np.ceil(len(sel) / cols))\n",
        "    plt.figure(figsize=(3*cols, 3*rows))\n",
        "    for i, p in enumerate(sel):\n",
        "        img = cv2.imread(p, cv2.IMREAD_COLOR)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) if img is not None else None\n",
        "        ax = plt.subplot(rows, cols, i+1); ax.axis('off')\n",
        "        ax.set_title(Path(p).name[:12])\n",
        "        if img is not None:\n",
        "            plt.imshow(img)\n",
        "        else:\n",
        "            ax.text(0.5, 0.5, 'read error', ha='center', va='center')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def border_black_ratio(img, border_px=16, thr=10):\n",
        "    # fraction of near-black pixels in a border frame of width border_px\n",
        "    if img.ndim == 3:\n",
        "        g = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        g = img\n",
        "    h, w = g.shape\n",
        "    mask = np.zeros_like(g, dtype=bool)\n",
        "    mask[:border_px, :] = True; mask[-border_px:, :] = True\n",
        "    mask[:, :border_px] = True; mask[:, -border_px:] = True\n",
        "    border = g[mask]\n",
        "    return float((border < thr).mean()) if border.size else 0.0\n",
        "\n",
        "def audit_black_borders(split='train', k=32, border_px=16, thr=10):\n",
        "    paths = sorted(glob.glob(str(CACHE_DIR / split / '*.png')))\n",
        "    sel = random.sample(paths, min(k, len(paths)))\n",
        "    ratios = []\n",
        "    for p in sel:\n",
        "        img = cv2.imread(p, cv2.IMREAD_COLOR)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        ratios.append(border_black_ratio(img, border_px=border_px, thr=thr))\n",
        "    ratios = np.array(ratios) if ratios else np.array([0.0])\n",
        "    print(f'{split}: mean border-black ratio={ratios.mean():.4f}, max={ratios.max():.4f}, samples={len(ratios)}')\n",
        "    return ratios\n",
        "\n",
        "print('Showing random train samples...')\n",
        "show_samples('train', n=8)\n",
        "print('Showing random test samples...')\n",
        "show_samples('test', n=8)\n",
        "print('Auditing border black ratios (lower is better; expect small if circle-cropped)')\n",
        "audit_black_borders('train', k=48, border_px=16, thr=10)\n",
        "audit_black_borders('test', k=48, border_px=16, thr=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "b5ffe32f-2945-45a8-8b26-380f285874f7",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quick run sequence (after reassembly)\n",
        "\n",
        "1) Open your training notebook (kaggle_train_tfefnv2l_768.ipynb) in the same Kaggle session, add the same Datasets, and run:\n",
        "- Verify GPU in Cell 1 and confirm CACHE_DIR=/kaggle/working/cache768\n",
        "- Then execute:\n",
        "```python\n",
        "fold_scores, oof_all, y_all, te_mean = run_all_folds()\n",
        "```\n",
        "\n",
        "2) Build submission (CDF5, alpha=0.85, auto-adjust counts to test size, rankavg-z tie-break):\n",
        "```python\n",
        "build_and_save_submission_from_artifacts(\n",
        "    OUTPUT_DIR,\n",
        "    alpha=0.85,\n",
        "    target_counts=(178,47,86,44,12),\n",
        "    tie_break='rankavgz',\n",
        "    out_name='submission.csv'\n",
        ")\n",
        "```\n",
        "\n",
        "3) If LB < CV noticeably, re-run step 2 with alpha=0.80:\n",
        "```python\n",
        "build_and_save_submission_from_artifacts(OUTPUT_DIR, alpha=0.80, target_counts=(178,47,86,44,12), tie_break='rankavgz')\n",
        "```\n",
        "\n",
        "Tips\n",
        "- If DataLoader stalls, set persistent_workers=False and/or prefetch_factor=1.\n",
        "- If OOM, set batch_size=6 and grad_accum=3 in CFG, then re-run the fold.\n",
        "- Ensure competition dataset slug is present: /kaggle/input/aptos2019-blindness-detection (or aptos-2019-blindness-detection).\n",
        "- Optional: add a timm-pretrained-models dataset and set hub dir (already guarded in the training notebook)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "a8da1462-4c42-462b-b1db-4b16627063fd",
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Threshold-based submission variant\n",
        "\n",
        "- After training in `kaggle_train_tfefnv2l_768.ipynb`, also build a threshold-optimized submission based on OOF EV.\n",
        "- In that notebook, run:\n",
        "```python\n",
        "sub_thr, edges, oof_qwk_thr = build_and_save_submission_thresholds(OUTPUT_DIR, out_name='submission_thr.csv')\n",
        "```\n",
        "- Submit both:\n",
        "  - CDF5: `submission.csv` with alpha in [0.80, 0.85] (start 0.85).\n",
        "  - Thresholds: `submission_thr.csv`.\n",
        "- Pick the better LB score. If LB underperforms OOF by >0.01\u20130.015, rebuild CDF5 with alpha=0.80."
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}